Title: Speeding up Presto Queries Using Apache Hudi Clustering - Satish Kotha & Nishith Agarwal, Uber
Publication date: 2021-03-27
Playlist: PrestoCon Day 2021 - Virtual
Description: 
	Speeding up Presto Queries Using Apache Hudi Clustering - Satish Kotha & Nishith Agarwal, Uber

Apache Hudi is a data lake platform that supercharges data lakes. Originally created at Uber, Hudi provides various ways to strike trade-offs between ingestion speed and query performance by supporting user defined partitioners, automatic file sizing which are favorable to query performance. Hudi integrates with PrestoDB to make this data available for queries. During ingestion, data is typically co-located based on arrival time. However, query engines perform better when the data frequently queried is co-located together, which may be different from arrival time order. We will discuss a new framework called “data clustering” to make data lakes adaptable to query patterns, thereby improving query latencies. Finally, we will discuss future work to support improving data locality using custom bucketing of data during ingestion, avoiding some of the rewrite costs. 

For more info about Presto, the open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes, see: https://prestodb.io/
Captions: 
	00:00:00,320 --> 00:00:05,120
all right welcome folks um

00:00:03,040 --> 00:00:06,240
to this talk on apache hoodie clustering

00:00:05,120 --> 00:00:09,679
uh to make

00:00:06,240 --> 00:00:12,400
queries faster on presto

00:00:09,679 --> 00:00:12,400
next slide please

00:00:13,200 --> 00:00:16,480
so let's take a look at the agenda for

00:00:14,799 --> 00:00:20,000
today first

00:00:16,480 --> 00:00:22,000
we'll discuss some basics about hoodie

00:00:20,000 --> 00:00:23,279
we'll talk about how we're using to

00:00:22,000 --> 00:00:26,480
evolve our data lake

00:00:23,279 --> 00:00:27,920
using hoodie we'll dive into why we

00:00:26,480 --> 00:00:30,080
build clustering

00:00:27,920 --> 00:00:32,480
and how it's helping improve the

00:00:30,080 --> 00:00:34,480
performance of queries and presto

00:00:32,480 --> 00:00:36,640
and finally we'll briefly touch on some

00:00:34,480 --> 00:00:44,320
of the future work

00:00:36,640 --> 00:00:46,719
next slide please right

00:00:44,320 --> 00:00:48,000
um so yeah my name is nishit i am an

00:00:46,719 --> 00:00:50,399
engineering manager uber

00:00:48,000 --> 00:00:52,000
um you know i manage the data lake team

00:00:50,399 --> 00:00:55,120
and then with the

00:00:52,000 --> 00:00:56,719
hoodie projects it's the beginning my

00:00:55,120 --> 00:00:57,120
team works on many aspects of the data

00:00:56,719 --> 00:00:59,120
lake

00:00:57,120 --> 00:01:00,719
including storage table management data

00:00:59,120 --> 00:01:02,160
consistency and more

00:01:00,719 --> 00:01:03,920
and i have my colleague here with me

00:01:02,160 --> 00:01:06,799
satish who will be covering the second

00:01:03,920 --> 00:01:06,799
half of the presentation

00:01:07,520 --> 00:01:10,159
next slide please

00:01:10,640 --> 00:01:15,439
all right now so uh talking a little bit

00:01:13,680 --> 00:01:16,240
about hoodie hoodie is a data platform

00:01:15,439 --> 00:01:17,840
technology

00:01:16,240 --> 00:01:20,240
and that provides uh several

00:01:17,840 --> 00:01:22,479
functionalities uh that one

00:01:20,240 --> 00:01:23,280
needs to manage and build a data lake at

00:01:22,479 --> 00:01:26,240
its core

00:01:23,280 --> 00:01:26,560
uh it's a storage library that is used

00:01:26,240 --> 00:01:29,600
to

00:01:26,560 --> 00:01:31,520
address a variety of requirements that

00:01:29,600 --> 00:01:34,000
are needed by the data

00:01:31,520 --> 00:01:35,119
some of the notable requirements are you

00:01:34,000 --> 00:01:37,439
know supporting

00:01:35,119 --> 00:01:38,400
efficient ingestion of database change

00:01:37,439 --> 00:01:41,200
logs

00:01:38,400 --> 00:01:42,880
which means supporting uh inserts and

00:01:41,200 --> 00:01:46,399
update type workloads

00:01:42,880 --> 00:01:49,280
um removing uh you know and deduping

00:01:46,399 --> 00:01:50,320
um any duplicates from log events uh

00:01:49,280 --> 00:01:52,399
which would be

00:01:50,320 --> 00:01:53,520
you know millions of events uh at a

00:01:52,399 --> 00:01:56,640
second

00:01:53,520 --> 00:01:58,479
um data lake in general um you know

00:01:56,640 --> 00:02:00,079
is once like needs to provide some

00:01:58,479 --> 00:02:01,680
efficient storage management

00:02:00,079 --> 00:02:04,240
in all of all of the tables and data

00:02:01,680 --> 00:02:06,960
sets but he provides many table services

00:02:04,240 --> 00:02:09,920
uh to let us manage this uh some of

00:02:06,960 --> 00:02:12,560
which we'll discuss in a later slide

00:02:09,920 --> 00:02:14,080
uh we want transactional rights uh you

00:02:12,560 --> 00:02:15,040
know some kind of asset semantics on the

00:02:14,080 --> 00:02:17,360
data lake

00:02:15,040 --> 00:02:19,760
um and we want to be able to provide

00:02:17,360 --> 00:02:23,440
some tight essays on data freshness

00:02:19,760 --> 00:02:24,239
whether it be for faster for derived or

00:02:23,440 --> 00:02:26,640
raw data

00:02:24,239 --> 00:02:27,760
and we need primitives for that um

00:02:26,640 --> 00:02:29,360
beyond that there are some other

00:02:27,760 --> 00:02:31,120
requirements such as compliance

00:02:29,360 --> 00:02:33,920
uh unique key constraints and late

00:02:31,120 --> 00:02:37,120
handling all of which

00:02:33,920 --> 00:02:39,599
we use for the um to help solve next

00:02:37,120 --> 00:02:39,599
slide please

00:02:40,879 --> 00:02:46,800
so some some facts about uh

00:02:44,160 --> 00:02:49,040
we use hoodie to manage about 250

00:02:46,800 --> 00:02:51,040
terabytes of a transaction data lake

00:02:49,040 --> 00:02:54,160
uh that amounts to about eight thousand

00:02:51,040 --> 00:02:55,599
uh tables uh uh ingesting about uh 500

00:02:54,160 --> 00:02:58,400
billion records a day

00:02:55,599 --> 00:02:59,280
um so we're running all of these a

00:02:58,400 --> 00:03:02,080
pretty large scale

00:02:59,280 --> 00:03:04,000
and then as a result obviously our

00:03:02,080 --> 00:03:08,400
queries are also running

00:03:04,000 --> 00:03:08,400
at a large scale across these data sets

00:03:08,800 --> 00:03:13,840
next slide all right so here i'd uh

00:03:11,760 --> 00:03:15,519
quickly like to talk about how we are

00:03:13,840 --> 00:03:17,120
you know reimagining sort of data lakes

00:03:15,519 --> 00:03:18,640
using

00:03:17,120 --> 00:03:20,400
um kodia a canonical data lake

00:03:18,640 --> 00:03:22,080
architecture you know all incoming data

00:03:20,400 --> 00:03:24,080
into the lake or warehouse

00:03:22,080 --> 00:03:26,319
you may have some source typically like

00:03:24,080 --> 00:03:27,040
kafka and then based on use cases and

00:03:26,319 --> 00:03:28,480
preferences

00:03:27,040 --> 00:03:30,319
you may choose a batch or streaming

00:03:28,480 --> 00:03:33,120
oriented model

00:03:30,319 --> 00:03:35,040
now this data ends up landing in uh you

00:03:33,120 --> 00:03:36,239
know data lake uh tables managed by

00:03:35,040 --> 00:03:38,480
hoodie

00:03:36,239 --> 00:03:39,599
uh hoodie internally has a transaction

00:03:38,480 --> 00:03:42,720
log

00:03:39,599 --> 00:03:44,480
pluggable uh primary key indexes and a

00:03:42,720 --> 00:03:46,159
bunch of base and delta files together

00:03:44,480 --> 00:03:49,519
which support the features that

00:03:46,159 --> 00:03:50,319
we discussed earlier uh now this data is

00:03:49,519 --> 00:03:53,519
available

00:03:50,319 --> 00:03:56,400
uh to be queried by uh presto

00:03:53,519 --> 00:03:58,239
um and other query engines right

00:03:56,400 --> 00:04:01,599
generally with the help of a metastore

00:03:58,239 --> 00:04:03,360
this is pretty standard stuff

00:04:01,599 --> 00:04:05,120
now some of the problems we faced with

00:04:03,360 --> 00:04:06,720
this architecture are

00:04:05,120 --> 00:04:08,640
you know who will manage sort of the

00:04:06,720 --> 00:04:09,599
file counts of increasing number of file

00:04:08,640 --> 00:04:11,680
versions

00:04:09,599 --> 00:04:12,799
how do we archive metadata and data that

00:04:11,680 --> 00:04:15,040
is unused

00:04:12,799 --> 00:04:16,560
uh how do we keep the number of data

00:04:15,040 --> 00:04:18,160
files in check

00:04:16,560 --> 00:04:20,560
so this is where we supercharge our data

00:04:18,160 --> 00:04:22,400
lake at uber uh with hoodie

00:04:20,560 --> 00:04:23,840
it supports a number of like in-built

00:04:22,400 --> 00:04:26,479
stable services

00:04:23,840 --> 00:04:28,400
that hoodie manages and these integrated

00:04:26,479 --> 00:04:31,440
table services include cleaning

00:04:28,400 --> 00:04:33,280
removing unwanted and failed files uh

00:04:31,440 --> 00:04:35,120
compaction that keeps the number of

00:04:33,280 --> 00:04:37,680
delta and base files

00:04:35,120 --> 00:04:38,560
in check by intermittently keeping them

00:04:37,680 --> 00:04:40,160
compacted

00:04:38,560 --> 00:04:42,639
and this gives a lot of flexibility for

00:04:40,160 --> 00:04:44,639
us to manage these tables

00:04:42,639 --> 00:04:47,120
so recently we've started to dig deeper

00:04:44,639 --> 00:04:48,639
into how can we help optimize queries on

00:04:47,120 --> 00:04:51,040
kodi based tables

00:04:48,639 --> 00:04:52,400
um and as part of this effort you know

00:04:51,040 --> 00:04:53,680
we contributed a service called

00:04:52,400 --> 00:04:55,360
clustering

00:04:53,680 --> 00:04:57,680
that has helped that is meant to

00:04:55,360 --> 00:05:00,080
optimize uh the data layout

00:04:57,680 --> 00:05:02,000
uh and make it suitable for for query

00:05:00,080 --> 00:05:05,120
patterns

00:05:02,000 --> 00:05:05,520
uh and so uh you know in the next in the

00:05:05,120 --> 00:05:07,840
next

00:05:05,520 --> 00:05:08,840
uh rest of the slides uh you know we

00:05:07,840 --> 00:05:11,680
wanna

00:05:08,840 --> 00:05:13,919
explore how clustering can help optimize

00:05:11,680 --> 00:05:15,759
the data layout

00:05:13,919 --> 00:05:17,840
so before we get there i quickly want to

00:05:15,759 --> 00:05:20,880
go over um

00:05:17,840 --> 00:05:22,639
sort of the uh you know the current

00:05:20,880 --> 00:05:24,800
state of integration between

00:05:22,639 --> 00:05:26,800
hori and pastor db uh just as a

00:05:24,800 --> 00:05:28,639
disclaimer uh the next slide is

00:05:26,800 --> 00:05:31,360
will have some jargons which is very

00:05:28,639 --> 00:05:32,960
related uh which may not be familiar uh

00:05:31,360 --> 00:05:34,400
but if you want more details you can go

00:05:32,960 --> 00:05:37,680
and visit the hoodie apache

00:05:34,400 --> 00:05:38,639
or website for more details next slide

00:05:37,680 --> 00:05:40,960
please

00:05:38,639 --> 00:05:42,000
so at its current state uh you know we

00:05:40,960 --> 00:05:44,560
have uh

00:05:42,000 --> 00:05:45,039
uh you know a copy on right uh on presto

00:05:44,560 --> 00:05:48,240
db

00:05:45,039 --> 00:05:49,840
this uh storage format uh in hoodie is

00:05:48,240 --> 00:05:52,479
meant to be read optimized

00:05:49,840 --> 00:05:54,000
uh it provides all of the popular

00:05:52,479 --> 00:05:56,400
features that you would want like

00:05:54,000 --> 00:05:57,520
uh column you know vectorization uh

00:05:56,400 --> 00:06:01,120
predicate push down

00:05:57,520 --> 00:06:03,039
uh etc um and you know uh

00:06:01,120 --> 00:06:04,800
both kinds of like quizzes supported uh

00:06:03,039 --> 00:06:07,440
you know point in time queries as well

00:06:04,800 --> 00:06:10,240
as incremental queries

00:06:07,440 --> 00:06:11,919
this integration also supports margin

00:06:10,240 --> 00:06:14,720
read tables

00:06:11,919 --> 00:06:16,000
so this storage format is optimized for

00:06:14,720 --> 00:06:19,199
right throughput

00:06:16,000 --> 00:06:22,400
and meant to reduce ingestion latencies

00:06:19,199 --> 00:06:23,759
um obviously these uh these tables also

00:06:22,400 --> 00:06:27,039
run compactions which

00:06:23,759 --> 00:06:28,479
uh help to provide vectorizations and

00:06:27,039 --> 00:06:31,199
particular push down primitives on

00:06:28,479 --> 00:06:31,199
carbon or data

00:06:32,240 --> 00:06:37,520
next slide please so yeah

00:06:35,360 --> 00:06:39,360
at this point i'll hand it over to each

00:06:37,520 --> 00:06:41,759
uh to talk to us through

00:06:39,360 --> 00:06:42,639
uh the use cases and solutions uh that

00:06:41,759 --> 00:06:45,520
led us to

00:06:42,639 --> 00:06:45,520
think about clustering

00:06:46,400 --> 00:06:49,599
hello everyone i hope uh that gave a

00:06:48,240 --> 00:06:52,000
good understanding of how

00:06:49,599 --> 00:06:53,440
uh presto and kodi operate together in

00:06:52,000 --> 00:06:55,199
the rest of the presentation i'm going

00:06:53,440 --> 00:06:56,960
to specifically talk about two important

00:06:55,199 --> 00:06:58,880
goals for this work

00:06:56,960 --> 00:07:00,560
first uh we want to reduce our storage

00:06:58,880 --> 00:07:03,840
and query query cost

00:07:00,560 --> 00:07:06,800
to improve utilization of pesto clusters

00:07:03,840 --> 00:07:08,000
next our users request for fast data

00:07:06,800 --> 00:07:10,479
this means

00:07:08,000 --> 00:07:12,240
two things low end-to-end right latency

00:07:10,479 --> 00:07:14,160
to make the data available

00:07:12,240 --> 00:07:15,599
as quickly as possible and improve

00:07:14,160 --> 00:07:17,360
freshness

00:07:15,599 --> 00:07:19,199
and second once the data is available

00:07:17,360 --> 00:07:22,080
users also want to

00:07:19,199 --> 00:07:23,599
want faster query response times to

00:07:22,080 --> 00:07:25,280
satisfy these requirements on our

00:07:23,599 --> 00:07:27,120
transactional data lake we needed to

00:07:25,280 --> 00:07:28,639
develop a new framework for rewriting

00:07:27,120 --> 00:07:30,479
this data

00:07:28,639 --> 00:07:31,840
let me explain little bit more on why we

00:07:30,479 --> 00:07:32,400
need a new framework for writing the

00:07:31,840 --> 00:07:33,840
data

00:07:32,400 --> 00:07:36,000
so at a high level there are two

00:07:33,840 --> 00:07:37,919
important components uh in the data lake

00:07:36,000 --> 00:07:39,120
uh one is the writer the data engagement

00:07:37,919 --> 00:07:41,840
component that

00:07:39,120 --> 00:07:42,880
writes data to a durable storage and the

00:07:41,840 --> 00:07:45,440
query engines

00:07:42,880 --> 00:07:47,520
that read data from this store now both

00:07:45,440 --> 00:07:50,000
of these components are optimized for

00:07:47,520 --> 00:07:50,960
different things i listed two important

00:07:50,000 --> 00:07:53,280
tradeoffs here

00:07:50,960 --> 00:07:54,560
on the on the first column the data

00:07:53,280 --> 00:07:58,240
locality and the

00:07:54,560 --> 00:08:00,800
file size as you can see in the table

00:07:58,240 --> 00:08:01,520
the data injection typically stores data

00:08:00,800 --> 00:08:04,479
based on the

00:08:01,520 --> 00:08:05,120
arrival time whereas query engines work

00:08:04,479 --> 00:08:07,919
better

00:08:05,120 --> 00:08:09,120
when the data query often is collocated

00:08:07,919 --> 00:08:11,520
together

00:08:09,120 --> 00:08:13,440
similarly data injection prefers small

00:08:11,520 --> 00:08:16,800
files to improve parallelism

00:08:13,440 --> 00:08:18,960
and thereby increasing freshness

00:08:16,800 --> 00:08:20,000
but query engines typically perform sd

00:08:18,960 --> 00:08:21,919
crates when

00:08:20,000 --> 00:08:24,400
there are a large number of small file

00:08:21,919 --> 00:08:27,440
small files

00:08:24,400 --> 00:08:29,840
so with that context i want to introduce

00:08:27,440 --> 00:08:32,000
hoodie clustering uh clustering is a

00:08:29,840 --> 00:08:34,640
general framework we built to change uh

00:08:32,000 --> 00:08:37,519
data layout based on query patterns

00:08:34,640 --> 00:08:39,120
as nishik mentioned we have thousands of

00:08:37,519 --> 00:08:40,640
tables and we want to provide like a

00:08:39,120 --> 00:08:43,279
flexible framework

00:08:40,640 --> 00:08:44,959
that optimizes the data layout for each

00:08:43,279 --> 00:08:47,600
of these tables

00:08:44,959 --> 00:08:48,560
so clustering provides a pluggable

00:08:47,600 --> 00:08:51,600
strategies

00:08:48,560 --> 00:08:54,720
to change or rewrite the data

00:08:51,600 --> 00:08:56,320
on the data lake we provide two

00:08:54,720 --> 00:08:56,640
strategies in the open source the first

00:08:56,320 --> 00:08:59,839
one

00:08:56,640 --> 00:09:01,760
is sorting strategy this is uh

00:08:59,839 --> 00:09:04,000
this the main purpose of this strategy

00:09:01,760 --> 00:09:07,440
is to improve data locality

00:09:04,000 --> 00:09:09,120
by sorting on user specified columns

00:09:07,440 --> 00:09:10,880
this strategy can also control file

00:09:09,120 --> 00:09:12,720
sizes to work around

00:09:10,880 --> 00:09:15,040
small file limitations as mentioned

00:09:12,720 --> 00:09:16,560
earlier

00:09:15,040 --> 00:09:18,560
we also provide stitching strategy in

00:09:16,560 --> 00:09:19,519
open source this as the name indicates

00:09:18,560 --> 00:09:21,920
this is useful

00:09:19,519 --> 00:09:22,720
primarily for controlling file sizes so

00:09:21,920 --> 00:09:24,480
this is

00:09:22,720 --> 00:09:26,000
this assumes that the data locality is

00:09:24,480 --> 00:09:26,880
already taken care of or not as

00:09:26,000 --> 00:09:30,399
important for

00:09:26,880 --> 00:09:32,160
uh for the use case uh during injection

00:09:30,399 --> 00:09:33,920
uh this strategy is often used for like

00:09:32,160 --> 00:09:35,200
micro batching kind of use cases where

00:09:33,920 --> 00:09:37,440
primary goal is

00:09:35,200 --> 00:09:38,880
to improve freshness by writing data in

00:09:37,440 --> 00:09:40,640
small files first

00:09:38,880 --> 00:09:42,640
small files are then stitched together

00:09:40,640 --> 00:09:45,600
using a clustering framework

00:09:42,640 --> 00:09:47,360
to improve the query performance

00:09:45,600 --> 00:09:50,240
clustering also allows for

00:09:47,360 --> 00:09:51,440
flexible policies for example it is easy

00:09:50,240 --> 00:09:53,839
to configure

00:09:51,440 --> 00:09:56,160
the partitions that we want to rewrite

00:09:53,839 --> 00:09:59,360
in each iteration

00:09:56,160 --> 00:09:59,920
we can also choose to use different data

00:09:59,360 --> 00:10:02,240
layouts

00:09:59,920 --> 00:10:03,200
for different partitions this may be

00:10:02,240 --> 00:10:06,079
useful if

00:10:03,200 --> 00:10:06,959
query patterns evolve over time for

00:10:06,079 --> 00:10:09,519
example

00:10:06,959 --> 00:10:11,360
new partitions can be sorted based on

00:10:09,519 --> 00:10:13,519
most frequently used predicates in the

00:10:11,360 --> 00:10:15,440
last few days

00:10:13,519 --> 00:10:17,440
clustering can also can be configured to

00:10:15,440 --> 00:10:18,880
run at different granularities

00:10:17,440 --> 00:10:20,480
so let's take sorting strategy an

00:10:18,880 --> 00:10:22,399
example if you pick

00:10:20,480 --> 00:10:23,600
global granularity all data in the

00:10:22,399 --> 00:10:25,040
partition is read back

00:10:23,600 --> 00:10:26,880
sorted according to the specified

00:10:25,040 --> 00:10:29,680
columns and return

00:10:26,880 --> 00:10:30,959
to the same partition if the local

00:10:29,680 --> 00:10:33,680
option is picked

00:10:30,959 --> 00:10:35,440
then uh sorting is done on an individual

00:10:33,680 --> 00:10:38,000
file level

00:10:35,440 --> 00:10:38,959
users can also specify like custom plans

00:10:38,000 --> 00:10:41,600
and divide

00:10:38,959 --> 00:10:42,800
files in the partition into multiple

00:10:41,600 --> 00:10:45,040
logical groups

00:10:42,800 --> 00:10:47,839
based on either file level metadata or

00:10:45,040 --> 00:10:47,839
table level metadata

00:10:48,240 --> 00:10:52,720
the other nice thing is clustering

00:10:49,680 --> 00:10:55,760
adopts all the uh body transactional

00:10:52,720 --> 00:10:56,480
asset semantics so it provides snapshot

00:10:55,760 --> 00:10:58,320
isolation

00:10:56,480 --> 00:11:00,240
and time time travel for input for

00:10:58,320 --> 00:11:02,399
improving operations

00:11:00,240 --> 00:11:05,200
so this means uh you can restore and

00:11:02,399 --> 00:11:08,880
roll back a table to a previously

00:11:05,200 --> 00:11:12,000
well-known uh state very easily

00:11:08,880 --> 00:11:13,360
hoodie uh clustering also updates hoodie

00:11:12,000 --> 00:11:15,360
internal metadata

00:11:13,360 --> 00:11:16,880
and if an external index is configured

00:11:15,360 --> 00:11:20,320
it invokes updates

00:11:16,880 --> 00:11:20,320
on the on the primary index

00:11:21,040 --> 00:11:25,120
clustering also adopts multi-version

00:11:23,120 --> 00:11:27,120
concurrency control used by hoodie

00:11:25,120 --> 00:11:29,279
at a high level this means clustering

00:11:27,120 --> 00:11:31,040
can run parallel to injection

00:11:29,279 --> 00:11:33,279
and it can also run in parallel with

00:11:31,040 --> 00:11:36,880
other table services such as

00:11:33,279 --> 00:11:36,880
compaction and cleanup

00:11:38,480 --> 00:11:42,079
now let's look into how this sorting

00:11:40,000 --> 00:11:44,480
strategy actually helps improve uh

00:11:42,079 --> 00:11:46,959
perform query performance

00:11:44,480 --> 00:11:47,760
i have a example query here to select

00:11:46,959 --> 00:11:50,560
two columns b

00:11:47,760 --> 00:11:52,160
and c from table t the query also

00:11:50,560 --> 00:11:57,839
specifies two predicates

00:11:52,160 --> 00:11:57,839
on columns a and b

00:11:58,320 --> 00:12:01,760
so uh in the in the bottom left hand

00:12:00,160 --> 00:12:03,200
corner uh you can you can see the

00:12:01,760 --> 00:12:04,000
storage layer where the data is

00:12:03,200 --> 00:12:05,760
organized

00:12:04,000 --> 00:12:07,120
uh in the particular column or format

00:12:05,760 --> 00:12:11,360
files based on

00:12:07,120 --> 00:12:13,440
arrival time to execute this query uh

00:12:11,360 --> 00:12:15,040
a tablespan is required to fetch all

00:12:13,440 --> 00:12:17,200
rows from the table

00:12:15,040 --> 00:12:18,959
for columns referenced in the query

00:12:17,200 --> 00:12:20,880
presto engine then filters the data

00:12:18,959 --> 00:12:22,079
and projects the selected columns to

00:12:20,880 --> 00:12:24,720
satisfy or

00:12:22,079 --> 00:12:26,000
answer the query as you can see this is

00:12:24,720 --> 00:12:27,680
very inefficient

00:12:26,000 --> 00:12:29,200
as we need to fetch all rows from the

00:12:27,680 --> 00:12:32,800
table before we pick

00:12:29,200 --> 00:12:32,800
before we filter on the predicates

00:12:32,880 --> 00:12:36,399
now presto added a nice feature to do a

00:12:35,279 --> 00:12:38,240
predicate push down

00:12:36,399 --> 00:12:40,240
so now let's look into what happens if

00:12:38,240 --> 00:12:41,920
this predicate question is enabled

00:12:40,240 --> 00:12:43,680
at the bottom again we see the storage

00:12:41,920 --> 00:12:46,320
layer where data is stored

00:12:43,680 --> 00:12:47,760
based on arrival time because data is

00:12:46,320 --> 00:12:49,760
stored on arrival time

00:12:47,760 --> 00:12:51,120
it is possible that many data blocks

00:12:49,760 --> 00:12:54,000
still have

00:12:51,120 --> 00:12:55,200
at least one row that matches with given

00:12:54,000 --> 00:12:57,279
predicates

00:12:55,200 --> 00:12:58,959
so even with predicate push-down enabled

00:12:57,279 --> 00:12:59,519
in the worst case we still need to

00:12:58,959 --> 00:13:01,920
process

00:12:59,519 --> 00:13:06,720
all data blocks in the presto engine and

00:13:01,920 --> 00:13:08,480
then filter majority of the rows

00:13:06,720 --> 00:13:09,839
now let us look into the same query

00:13:08,480 --> 00:13:12,399
execution uh

00:13:09,839 --> 00:13:13,360
where data is sorted based on columns a

00:13:12,399 --> 00:13:15,519
and b

00:13:13,360 --> 00:13:16,560
because data is sorted on these columns

00:13:15,519 --> 00:13:19,040
we can guarantee

00:13:16,560 --> 00:13:21,200
only a subset of blocks will have data

00:13:19,040 --> 00:13:23,440
for the specified predicates

00:13:21,200 --> 00:13:25,279
combined with predicate push down this

00:13:23,440 --> 00:13:27,040
basically reduces the amount of data

00:13:25,279 --> 00:13:29,440
that needs to be processed in the in the

00:13:27,040 --> 00:13:31,760
presto engine

00:13:29,440 --> 00:13:34,320
so hope that explains the importance of

00:13:31,760 --> 00:13:36,639
clustering at a high level

00:13:34,320 --> 00:13:37,519
now let's see how this works in practice

00:13:36,639 --> 00:13:39,680
here i have

00:13:37,519 --> 00:13:42,480
a sample query that is often used in a

00:13:39,680 --> 00:13:45,040
popular production table at uber

00:13:42,480 --> 00:13:46,079
i pick one partition from that table for

00:13:45,040 --> 00:13:48,480
this test

00:13:46,079 --> 00:13:50,079
this partition has about five gigabytes

00:13:48,480 --> 00:13:52,560
of logical data

00:13:50,079 --> 00:13:53,279
uh sorry i had to hide the table schema

00:13:52,560 --> 00:13:56,160
and columns

00:13:53,279 --> 00:13:57,600
but the query translates to uh something

00:13:56,160 --> 00:14:00,160
like select two columns

00:13:57,600 --> 00:14:01,040
from the table where uh with the

00:14:00,160 --> 00:14:04,720
predicates on

00:14:01,040 --> 00:14:06,160
two columns now we run the query without

00:14:04,720 --> 00:14:08,720
clustering and you can see the query

00:14:06,160 --> 00:14:08,720
plan below

00:14:09,360 --> 00:14:12,720
there is uh there is a lot of

00:14:10,800 --> 00:14:15,920
information in the query plan

00:14:12,720 --> 00:14:17,440
the first thing to notice is we have a

00:14:15,920 --> 00:14:19,920
scan filter project

00:14:17,440 --> 00:14:21,519
operator so this is basically taking

00:14:19,920 --> 00:14:22,639
advantage of the predicate push-down

00:14:21,519 --> 00:14:25,360
feature

00:14:22,639 --> 00:14:26,240
but because data is stored in arrival

00:14:25,360 --> 00:14:28,399
order

00:14:26,240 --> 00:14:30,560
the query execution required fetching

00:14:28,399 --> 00:14:33,839
almost 2 gigabytes of data

00:14:30,560 --> 00:14:35,680
as highlighted in the red color box here

00:14:33,839 --> 00:14:37,199
also note majority of the rows are

00:14:35,680 --> 00:14:39,440
filtered uh

00:14:37,199 --> 00:14:41,040
by presto query engine and output

00:14:39,440 --> 00:14:43,040
contains only

00:14:41,040 --> 00:14:45,360
approximately one percent of the input

00:14:43,040 --> 00:14:49,760
right so this is about 29 megabytes

00:14:45,360 --> 00:14:51,839
out of uh out of the two gigabytes input

00:14:49,760 --> 00:14:53,920
now this filtering is also expensive uh

00:14:51,839 --> 00:14:56,320
and you can see the total cpu time spent

00:14:53,920 --> 00:14:56,320
on the

00:14:56,480 --> 00:15:02,240
inside the query plan which is about

00:14:58,079 --> 00:15:02,240
like 27 uh 27 seconds

00:15:06,399 --> 00:15:09,519
here you can see the results of the same

00:15:08,079 --> 00:15:12,560
query after uh

00:15:09,519 --> 00:15:13,920
after doing clustering so uh basically

00:15:12,560 --> 00:15:16,720
we use the same partition

00:15:13,920 --> 00:15:18,560
but we sorted the data based on

00:15:16,720 --> 00:15:21,680
predicates used in the query

00:15:18,560 --> 00:15:23,839
columns a and b in this case

00:15:21,680 --> 00:15:25,519
so you can see the query plan again you

00:15:23,839 --> 00:15:27,920
can see that the same scan

00:15:25,519 --> 00:15:29,759
project filter scan filter project is

00:15:27,920 --> 00:15:33,199
operator is used

00:15:29,759 --> 00:15:37,040
but now the input is reduced

00:15:33,199 --> 00:15:38,800
substantially to about 180 megabytes

00:15:37,040 --> 00:15:40,880
compared to like the two gigabytes in

00:15:38,800 --> 00:15:43,920
the previous slide

00:15:40,880 --> 00:15:47,839
because of the reduced in the input size

00:15:43,920 --> 00:15:50,320
the cpu utilization

00:15:47,839 --> 00:15:51,440
is also dropped substantially to about 7

00:15:50,320 --> 00:15:54,639
seconds

00:15:51,440 --> 00:15:57,440
compared to the 27 seconds

00:15:54,639 --> 00:15:57,440
in the previous slide

00:15:58,160 --> 00:16:02,959
note that this is possible because

00:16:01,199 --> 00:16:04,320
both the features predicate push down

00:16:02,959 --> 00:16:09,839
and clustering

00:16:04,320 --> 00:16:09,839
are used together

00:16:10,480 --> 00:16:14,320
so this slide kind of captures summary

00:16:12,240 --> 00:16:15,360
from the previous two slides

00:16:14,320 --> 00:16:17,440
as you can see there is order of

00:16:15,360 --> 00:16:18,320
magnitude difference performance

00:16:17,440 --> 00:16:21,279
difference with

00:16:18,320 --> 00:16:22,160
clustering both input data size and

00:16:21,279 --> 00:16:25,199
input rows

00:16:22,160 --> 00:16:27,199
are reduced by a factor of 10.

00:16:25,199 --> 00:16:29,600
because of that there is a forex

00:16:27,199 --> 00:16:32,959
reduction in the overall cpu cost

00:16:29,600 --> 00:16:32,959
for executing these queries

00:16:33,519 --> 00:16:38,880
and just want to highlight that this

00:16:36,399 --> 00:16:42,160
again is uh run on a small partition

00:16:38,880 --> 00:16:44,000
um but i think uh we were in the process

00:16:42,160 --> 00:16:44,480
of enabling this feature on large data

00:16:44,000 --> 00:16:46,959
sets

00:16:44,480 --> 00:16:49,839
and preliminary preliminary results show

00:16:46,959 --> 00:16:53,920
similar order of magnitude uh savings

00:16:49,839 --> 00:16:55,839
in cpu cpu utilization

00:16:53,920 --> 00:16:57,440
also i want to highlight that because of

00:16:55,839 --> 00:16:58,800
the because of the reduction in the

00:16:57,440 --> 00:17:01,440
input data size

00:16:58,800 --> 00:17:02,560
we have uh we're able to make the

00:17:01,440 --> 00:17:05,360
queries faster

00:17:02,560 --> 00:17:06,640
so we're able to reduce the query

00:17:05,360 --> 00:17:09,760
latency by

00:17:06,640 --> 00:17:09,760
by about 50 percent

00:17:13,360 --> 00:17:16,640
now this slide captures how we run

00:17:15,360 --> 00:17:19,439
clustering in production

00:17:16,640 --> 00:17:21,199
at uber at a high level uh we have

00:17:19,439 --> 00:17:24,720
ingestion pipelines uh that

00:17:21,199 --> 00:17:26,319
write data to kodi table

00:17:24,720 --> 00:17:28,400
this injection pipeline also uses a

00:17:26,319 --> 00:17:30,880
durable config store uh

00:17:28,400 --> 00:17:33,440
basically storing panel files to control

00:17:30,880 --> 00:17:35,919
all the configuration

00:17:33,440 --> 00:17:37,600
now if uh we set up shadow pipelines to

00:17:35,919 --> 00:17:39,919
run this clustering

00:17:37,600 --> 00:17:41,440
uh this shadow pipeline uses the same

00:17:39,919 --> 00:17:44,320
config store to fetch

00:17:41,440 --> 00:17:45,600
uh the metadata and the configuration

00:17:44,320 --> 00:17:48,000
for the table

00:17:45,600 --> 00:17:49,280
and if uh clustering is enabled in the

00:17:48,000 --> 00:17:51,919
configuration

00:17:49,280 --> 00:17:52,960
uh the clustering pipeline can rearrange

00:17:51,919 --> 00:17:55,440
data layout for

00:17:52,960 --> 00:17:56,559
selected partitions of the table so both

00:17:55,440 --> 00:17:58,080
these pipelines can run

00:17:56,559 --> 00:18:00,880
in parallel and they coordinate with

00:17:58,080 --> 00:18:03,200
each other uh while

00:18:00,880 --> 00:18:05,600
providing the same acid semantics of

00:18:03,200 --> 00:18:14,799
consistency and snapshot isolation

00:18:05,600 --> 00:18:17,039
on top of on top of the kodi table

00:18:14,799 --> 00:18:18,480
uh so we have a lot of exciting

00:18:17,039 --> 00:18:19,600
enhancements that are planned on

00:18:18,480 --> 00:18:21,760
clustering

00:18:19,600 --> 00:18:23,520
uh as mentioned earlier we're in process

00:18:21,760 --> 00:18:24,480
of onboarding more tables onto the

00:18:23,520 --> 00:18:26,320
framework

00:18:24,480 --> 00:18:28,160
and because the framework is designed in

00:18:26,320 --> 00:18:30,559
a flat in a flexible way

00:18:28,160 --> 00:18:31,840
to support different strategies we are

00:18:30,559 --> 00:18:34,640
also using this for

00:18:31,840 --> 00:18:35,919
uh improving storage efficiency by

00:18:34,640 --> 00:18:37,120
exploring different compression

00:18:35,919 --> 00:18:39,760
algorithms

00:18:37,120 --> 00:18:40,960
um and we're also using this framework

00:18:39,760 --> 00:18:43,679
for

00:18:40,960 --> 00:18:44,640
encryption to support compliance use

00:18:43,679 --> 00:18:46,880
cases

00:18:44,640 --> 00:18:49,280
and column removal and some other use

00:18:46,880 --> 00:18:49,280
cases

00:18:49,600 --> 00:18:52,799
also right now clustering is provided as

00:18:51,120 --> 00:18:55,760
a library so users still need to

00:18:52,799 --> 00:18:58,559
configure this shadow pipeline and

00:18:55,760 --> 00:18:58,960
do some work to tune the clustering job

00:18:58,559 --> 00:19:01,600
so

00:18:58,960 --> 00:19:03,120
uh we want to make this as a service to

00:19:01,600 --> 00:19:06,160
simplify operations for

00:19:03,120 --> 00:19:07,840
table owners this also helps us

00:19:06,160 --> 00:19:09,200
share like the common validation

00:19:07,840 --> 00:19:11,280
framework on

00:19:09,200 --> 00:19:14,480
monitoring framework across different

00:19:11,280 --> 00:19:14,480
types of related shops

00:19:14,640 --> 00:19:18,160
we are also working on adding priority

00:19:16,320 --> 00:19:19,919
and tiring as i mentioned there are

00:19:18,160 --> 00:19:20,880
multiple jobs trying to change data

00:19:19,919 --> 00:19:23,200
layouts across

00:19:20,880 --> 00:19:24,640
across different tables so we want to

00:19:23,200 --> 00:19:27,039
take advantage of

00:19:24,640 --> 00:19:27,760
this uh economies of scale and schedule

00:19:27,039 --> 00:19:30,320
these uh

00:19:27,760 --> 00:19:31,600
radiant jobs when there is uh when there

00:19:30,320 --> 00:19:34,559
is additional resources

00:19:31,600 --> 00:19:35,120
uh when there's compute issue as long as

00:19:34,559 --> 00:19:40,160
the

00:19:35,120 --> 00:19:40,160
specified sla for regretting is met

00:19:40,400 --> 00:19:44,400
we also want to build a general

00:19:41,520 --> 00:19:48,720
framework uh to analyze all the queries

00:19:44,400 --> 00:19:51,200
on the on the given table and

00:19:48,720 --> 00:19:52,000
propose new data layouts and once it

00:19:51,200 --> 00:19:53,919
goes through a manual

00:19:52,000 --> 00:19:55,120
preview we want to automatically onboard

00:19:53,919 --> 00:19:57,120
that uh

00:19:55,120 --> 00:19:58,240
the table layout and automatically do

00:19:57,120 --> 00:20:02,240
clustering

00:19:58,240 --> 00:20:02,240
for to make operations simpler

00:20:02,559 --> 00:20:06,000
and we are also working on adding

00:20:03,760 --> 00:20:08,320
secondary index support in presto to

00:20:06,000 --> 00:20:09,679
improve query planning time so right now

00:20:08,320 --> 00:20:11,760
the significant portion of query

00:20:09,679 --> 00:20:14,080
planning time is spent on

00:20:11,760 --> 00:20:16,480
reading the column footers reading the

00:20:14,080 --> 00:20:19,679
photos from the parquet files

00:20:16,480 --> 00:20:23,360
so if we build a secondary index

00:20:19,679 --> 00:20:25,679
then we can save up to 10 percent of the

00:20:23,360 --> 00:20:29,200
query planning time and further improve

00:20:25,679 --> 00:20:29,200
the cpu utilization

00:20:29,280 --> 00:20:32,640
lastly we are also working on making

00:20:30,799 --> 00:20:36,400
enhancements to improve

00:20:32,640 --> 00:20:38,000
the efficiency of rewrite so

00:20:36,400 --> 00:20:40,159
for certain strategies for example we

00:20:38,000 --> 00:20:41,280
don't need to serialize and deserialize

00:20:40,159 --> 00:20:43,840
the

00:20:41,280 --> 00:20:45,280
all the contents in the pocket file

00:20:43,840 --> 00:20:46,320
especially for stitching kind of

00:20:45,280 --> 00:20:49,440
strategies

00:20:46,320 --> 00:20:50,400
so we are we're working on removing this

00:20:49,440 --> 00:20:53,440
extra step

00:20:50,400 --> 00:20:55,919
and saving additional additional cpu

00:20:53,440 --> 00:20:55,919
resources

00:20:58,720 --> 00:21:01,679
if any of this work sounds interesting

00:21:00,320 --> 00:21:03,280
to you and if you're interested in

00:21:01,679 --> 00:21:05,679
contributing to hoodie

00:21:03,280 --> 00:21:06,320
or using kodi uh please please please

00:21:05,679 --> 00:21:08,720
reach out

00:21:06,320 --> 00:21:11,880
uh the dev email list or we have also we

00:21:08,720 --> 00:21:14,000
also have a slack channel on the website

00:21:11,880 --> 00:21:16,159
cody.apache.org

00:21:14,000 --> 00:21:17,280
and uber is also hiring uh please reach

00:21:16,159 --> 00:21:20,960
out uh at

00:21:17,280 --> 00:21:24,080
data like jobs over.com uh

00:21:20,960 --> 00:21:25,600
yeah thanks for ending this uh session i

00:21:24,080 --> 00:21:27,200
think we're a little bit early but i

00:21:25,600 --> 00:21:30,320
appreciate any questions

00:21:27,200 --> 00:21:32,159
uh comments or feedback thank you for

00:21:30,320 --> 00:21:34,000
keeping the session on time

00:21:32,159 --> 00:21:35,280
let's give people a couple of minutes to

00:21:34,000 --> 00:21:37,039
you know think about

00:21:35,280 --> 00:21:39,280
any specific question that they might

00:21:37,039 --> 00:21:41,679
have

00:21:39,280 --> 00:21:43,120
okay so i'll read the question out so

00:21:41,679 --> 00:21:44,080
you know other people can hear it as

00:21:43,120 --> 00:21:46,400
well

00:21:44,080 --> 00:21:49,840
so who really decides how to store the

00:21:46,400 --> 00:21:49,840
data during ingestion

00:21:53,840 --> 00:21:57,600
can you get the question sorry yeah it

00:21:55,679 --> 00:22:00,400
says who did decide how to store the

00:21:57,600 --> 00:22:03,360
data during ingestion

00:22:00,400 --> 00:22:04,640
yeah i think there are there are couple

00:22:03,360 --> 00:22:05,919
yeah cody controls the

00:22:04,640 --> 00:22:08,880
decision i think there are two

00:22:05,919 --> 00:22:10,640
strategies here uh we have

00:22:08,880 --> 00:22:12,320
we have basically provide some default

00:22:10,640 --> 00:22:14,720
partitional strategies

00:22:12,320 --> 00:22:15,600
so right now it controls uh the file

00:22:14,720 --> 00:22:18,960
sizing aspect

00:22:15,600 --> 00:22:22,320
during during injection but

00:22:18,960 --> 00:22:23,440
the key aspect here is that we want to

00:22:22,320 --> 00:22:25,679
make the data available

00:22:23,440 --> 00:22:26,960
as as early as possible to the query

00:22:25,679 --> 00:22:29,440
engines right

00:22:26,960 --> 00:22:31,360
so uh we want to make the uh we want to

00:22:29,440 --> 00:22:34,559
write the data to the data like first

00:22:31,360 --> 00:22:35,520
as soon as possible um and we have some

00:22:34,559 --> 00:22:37,840
strategy to

00:22:35,520 --> 00:22:38,559
control the file sizes but right now

00:22:37,840 --> 00:22:40,720
because the

00:22:38,559 --> 00:22:41,600
pattern of how the data arrives from

00:22:40,720 --> 00:22:44,000
upstream

00:22:41,600 --> 00:22:45,360
uh we are not able to guarantee the data

00:22:44,000 --> 00:22:47,520
locality aspect

00:22:45,360 --> 00:22:48,640
so that's why we are uh proposing this

00:22:47,520 --> 00:22:52,240
new or we are

00:22:48,640 --> 00:22:53,520
we worked on this new clustering project

00:22:52,240 --> 00:22:55,520
let me see if anything that you want to

00:22:53,520 --> 00:22:58,799
add

00:22:55,520 --> 00:22:59,360
no i think that just one more thing to

00:22:58,799 --> 00:23:02,559
add is

00:22:59,360 --> 00:23:05,120
uh you do have the option to

00:23:02,559 --> 00:23:07,520
you know manage the data layout you

00:23:05,120 --> 00:23:09,200
ingest but

00:23:07,520 --> 00:23:10,640
depending on sort of your use case that

00:23:09,200 --> 00:23:14,159
may not be possible

00:23:10,640 --> 00:23:16,000
um and also a lot of times

00:23:14,159 --> 00:23:18,960
choices in the past of writing

00:23:16,000 --> 00:23:22,240
historical data in some format whereas

00:23:18,960 --> 00:23:26,080
uh query patterns changing over time

00:23:22,240 --> 00:23:28,640
and tend to like sort of dissociate and

00:23:26,080 --> 00:23:29,600
cause sort of uh degraded curry

00:23:28,640 --> 00:23:31,520
performance

00:23:29,600 --> 00:23:34,159
and that's why sort of clustering comes

00:23:31,520 --> 00:23:34,159
in to help us

00:23:35,679 --> 00:23:38,799
thank you two more questions i see the

00:23:37,520 --> 00:23:41,120
first one was around

00:23:38,799 --> 00:23:43,039
how big are aws contributions given that

00:23:41,120 --> 00:23:46,559
they are using hoodie internally

00:23:43,039 --> 00:23:47,679
have any insights on that um i can take

00:23:46,559 --> 00:23:49,520
this one so i think

00:23:47,679 --> 00:23:50,960
there are uh yeah there are a bunch of

00:23:49,520 --> 00:23:52,080
people there are a few committers we

00:23:50,960 --> 00:23:55,200
have from ews

00:23:52,080 --> 00:23:58,320
who are contributing um they also

00:23:55,200 --> 00:24:01,600
actively work with us to uh

00:23:58,320 --> 00:24:03,440
you know if if aws is updating

00:24:01,600 --> 00:24:05,120
some sort of free version on aws then

00:24:03,440 --> 00:24:06,320
they work with us to understand the new

00:24:05,120 --> 00:24:08,880
features

00:24:06,320 --> 00:24:10,640
but there are like a few competitors who

00:24:08,880 --> 00:24:14,000
from the aws community who are on

00:24:10,640 --> 00:24:15,600
hoodie as well okay

00:24:14,000 --> 00:24:17,200
sounds good and i think there's one more

00:24:15,600 --> 00:24:20,960
question that came in is clustering

00:24:17,200 --> 00:24:22,799
available in the open source hoodie

00:24:20,960 --> 00:24:24,240
yeah the two strategies i've mentioned

00:24:22,799 --> 00:24:27,120
the sorting strategy and stitching

00:24:24,240 --> 00:24:29,520
strategy are available in open source

00:24:27,120 --> 00:24:31,200
and you're always welcome to contribute

00:24:29,520 --> 00:24:33,600
and add additional strategies

00:24:31,200 --> 00:24:34,559
that are specific for for your leaps

00:24:33,600 --> 00:24:37,200
cases

00:24:34,559 --> 00:24:38,640
okay i think similar lines is uh hoodie

00:24:37,200 --> 00:24:41,200
in emr includes

00:24:38,640 --> 00:24:41,200
clustering

00:24:42,320 --> 00:24:46,400
i think right now is in progress they

00:24:44,480 --> 00:24:47,520
are using an earlier version of kodi

00:24:46,400 --> 00:24:49,760
i think they are in the process of

00:24:47,520 --> 00:24:50,159
upgrading to the latest version which

00:24:49,760 --> 00:24:53,360
should

00:24:50,159 --> 00:24:57,279
give this uh give this feature

00:24:53,360 --> 00:24:59,360
okay just want to call out that the

00:24:57,279 --> 00:25:00,720
the general framework and everything is

00:24:59,360 --> 00:25:03,520
available in open source

00:25:00,720 --> 00:25:05,600
um the strategies are just something

00:25:03,520 --> 00:25:09,520
that are more useful use case specific

00:25:05,600 --> 00:25:11,039
um which you know which

00:25:09,520 --> 00:25:13,200
in general use cases strategies are

00:25:11,039 --> 00:25:14,480
available but other specific use case

00:25:13,200 --> 00:25:17,520
strategies are

00:25:14,480 --> 00:25:20,000
uh we keep internally for example we

00:25:17,520 --> 00:25:21,840
also use clustering to serve some other

00:25:20,000 --> 00:25:24,000
use cases such as

00:25:21,840 --> 00:25:25,679
removing older columns that are not

00:25:24,000 --> 00:25:29,120
being used anymore

00:25:25,679 --> 00:25:29,919
we also use it to um we have use cases

00:25:29,120 --> 00:25:32,960
around

00:25:29,919 --> 00:25:34,480
time-based encryption of data at rest

00:25:32,960 --> 00:25:36,240
and we need some sort of framework to

00:25:34,480 --> 00:25:37,440
perform time-based encryption of data

00:25:36,240 --> 00:25:38,720
address and so you can plug in a

00:25:37,440 --> 00:25:40,799
strategy

00:25:38,720 --> 00:25:42,400
and the same thing as you would do for

00:25:40,799 --> 00:25:43,840
other things so that's

00:25:42,400 --> 00:25:45,360
that framework is available in open

00:25:43,840 --> 00:25:48,159
source strategies are available some

00:25:45,360 --> 00:25:48,159
specific strategies

00:25:49,840 --> 00:25:54,080
okay thank you okay we'll wait maybe

00:25:53,440 --> 00:25:56,159
another

00:25:54,080 --> 00:25:58,240
minute if there is a question otherwise

00:25:56,159 --> 00:25:59,840
you know just stay online and see if

00:25:58,240 --> 00:26:00,159
there's something that comes up in the

00:25:59,840 --> 00:26:02,159
chat

00:26:00,159 --> 00:26:04,080
by the session or the event chat and

00:26:02,159 --> 00:26:05,039
feel free to take the question ah deepti

00:26:04,080 --> 00:26:06,640
has a question

00:26:05,039 --> 00:26:08,799
what are the specific plans around

00:26:06,640 --> 00:26:13,520
indexing uh we'll create

00:26:08,799 --> 00:26:13,520
index statement b in presto good one

00:26:14,559 --> 00:26:17,600
do you want to take that one sure um i

00:26:17,039 --> 00:26:20,960
think

00:26:17,600 --> 00:26:24,159
uh we are looking at uh

00:26:20,960 --> 00:26:25,600
some of the so the the next uh sort of

00:26:24,159 --> 00:26:25,919
presto integrations that we're looking

00:26:25,600 --> 00:26:28,640
at

00:26:25,919 --> 00:26:30,400
at least from perspective is um

00:26:28,640 --> 00:26:30,960
eliminating the file listing i think

00:26:30,400 --> 00:26:34,000
that

00:26:30,960 --> 00:26:37,279
that work is already like out but

00:26:34,000 --> 00:26:39,360
um some of the integration um corners

00:26:37,279 --> 00:26:42,080
are to be like sort of ironed out that's

00:26:39,360 --> 00:26:46,159
one the second once indexing is

00:26:42,080 --> 00:26:48,640
uh available uh we will look at how

00:26:46,159 --> 00:26:53,520
to make create statements available but

00:26:48,640 --> 00:26:56,159
there is no specific plan as of now

00:26:53,520 --> 00:26:56,880
okay i hope that helps okay perfect that

00:26:56,159 --> 00:26:59,200
sounds good

00:26:56,880 --> 00:27:00,799
so i think we'll wrap up uh again thank

00:26:59,200 --> 00:27:01,440
you once again for you know spending

00:27:00,799 --> 00:27:03,279
time with us

00:27:01,440 --> 00:27:04,559
and you know sharing details about

00:27:03,279 --> 00:27:07,440
hoodie

00:27:04,559 --> 00:27:07,840
and you can you know turn the mic off or

00:27:07,440 --> 00:27:09,520
you know

00:27:07,840 --> 00:27:11,440
leave the session i'll have the next two

00:27:09,520 --> 00:27:14,320
speakers come in for the lightning talk

00:27:11,440 --> 00:27:16,640
thank you thank you thanks guys for

00:27:14,320 --> 00:27:16,640

YouTube URL: https://www.youtube.com/watch?v=1WSg2aiCwDQ


