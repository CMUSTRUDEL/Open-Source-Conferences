Title: Lightning Talk - Real-time Analytics with Presto and Apache Pinot - Xiang Fu, Stealth Mode Startup
Publication date: 2020-09-30
Playlist: PrestoCon 2020 - Virtual
Description: 
	Lightning Talk - Real-time Analytics with Presto and Apache Pinot - Xiang Fu, Stealth Mode Startup Company

Speakers: Xiang Fu

In this presentation, Xiang Fu shares an overview of Presto Pinot Connector, which bridges the flexibility of Presto's full SQL support to the power of Apache Pinot's real-time analytics, giving you the best of both worlds.
Captions: 
	00:00:01,439 --> 00:00:05,359
this is xiao i'm a commander of the

00:00:03,360 --> 00:00:06,720
metropolitan project i used to work at

00:00:05,359 --> 00:00:09,120
uber and linkedin

00:00:06,720 --> 00:00:10,160
so today i'm going to talk about how we

00:00:09,120 --> 00:00:12,799
use presto and

00:00:10,160 --> 00:00:13,440
you know how to do real-time analytics a

00:00:12,799 --> 00:00:15,599
vacuum

00:00:13,440 --> 00:00:17,680
is an overlapping store used from

00:00:15,599 --> 00:00:20,400
linkedin for low latency elements

00:00:17,680 --> 00:00:21,359
it has been widely adopted in eurovision

00:00:20,400 --> 00:00:24,240
applications

00:00:21,359 --> 00:00:24,560
business analytics use cases and as well

00:00:24,240 --> 00:00:27,039
as

00:00:24,560 --> 00:00:27,920
normally detection use cases but nothing

00:00:27,039 --> 00:00:30,000
low latency

00:00:27,920 --> 00:00:33,440
it includes both the low data ingestion

00:00:30,000 --> 00:00:35,600
latency as well as the low curry lens

00:00:33,440 --> 00:00:38,000
this means that we know countries are

00:00:35,600 --> 00:00:39,440
directly consumed data from the kafka

00:00:38,000 --> 00:00:41,920
and the events will be covered

00:00:39,440 --> 00:00:44,239
immediately apart from kafka

00:00:41,920 --> 00:00:46,480
a user can also batch code data using

00:00:44,239 --> 00:00:49,200
hadoop or spark from like a different

00:00:46,480 --> 00:00:50,079
block store gfs or s3 or google cloud

00:00:49,200 --> 00:00:52,239
storage

00:00:50,079 --> 00:00:54,640
under sure detail peanut itself has

00:00:52,239 --> 00:00:57,199
implemented multiple uh indexes

00:00:54,640 --> 00:00:58,640
for example certain index inverting dex

00:00:57,199 --> 00:01:00,719
computer and surfing

00:00:58,640 --> 00:01:02,960
using that to actually speed up forest

00:01:00,719 --> 00:01:05,199
for aggregation and dubais

00:01:02,960 --> 00:01:06,320
in our production environments pino

00:01:05,199 --> 00:01:09,360
handles the workload of

00:01:06,320 --> 00:01:11,040
ingestion millions events per second and

00:01:09,360 --> 00:01:12,799
serving the thousand quarters per

00:01:11,040 --> 00:01:14,799
segment with medicine's level for the

00:01:12,799 --> 00:01:17,200
core latency

00:01:14,799 --> 00:01:18,880
now let's take a step back and see how

00:01:17,200 --> 00:01:21,920
we can do data analytics

00:01:18,880 --> 00:01:24,799
today so we can either start

00:01:21,920 --> 00:01:27,119
from the raw data or have the data being

00:01:24,799 --> 00:01:29,040
rejoined or pre-aggregated or even all

00:01:27,119 --> 00:01:31,040
we go to like

00:01:29,040 --> 00:01:32,720
depend on our risk there are actually

00:01:31,040 --> 00:01:36,640
two convicting things

00:01:32,720 --> 00:01:39,200
latency and flexibility so in one system

00:01:36,640 --> 00:01:40,720
we can get very good flexibility for

00:01:39,200 --> 00:01:43,520
example in presto

00:01:40,720 --> 00:01:43,920
we'll have a full sequence part we come

00:01:43,520 --> 00:01:46,960
to

00:01:43,920 --> 00:01:47,360
uh drawing some multiple tables however

00:01:46,960 --> 00:01:50,159
from

00:01:47,360 --> 00:01:51,040
latency perspective it may take seconds

00:01:50,159 --> 00:01:53,520
to minutes

00:01:51,040 --> 00:01:55,520
for the query to be processed depending

00:01:53,520 --> 00:01:58,000
on the data volume

00:01:55,520 --> 00:01:59,759
on the other side of the world we can

00:01:58,000 --> 00:02:02,560
get a very good speed

00:01:59,759 --> 00:02:04,320
because there's no flexibility for

00:02:02,560 --> 00:02:07,600
example with like a pre

00:02:04,320 --> 00:02:11,200
pre-cubed data there's no slice and

00:02:07,600 --> 00:02:13,280
dicing uh capabilities here and

00:02:11,200 --> 00:02:15,520
it's also very hard to arbitrary uh

00:02:13,280 --> 00:02:16,000
relaxer and then the middle part let's

00:02:15,520 --> 00:02:18,879
see

00:02:16,000 --> 00:02:20,560
for the systems like you know it will uh

00:02:18,879 --> 00:02:23,120
basically indexing all those

00:02:20,560 --> 00:02:24,879
pre-drawing or pre-aggravated results

00:02:23,120 --> 00:02:28,160
and we have the index

00:02:24,879 --> 00:02:30,560
to speed up this course and the query

00:02:28,160 --> 00:02:32,400
engine is also being optimized

00:02:30,560 --> 00:02:34,160
for those and lingual core patterns like

00:02:32,400 --> 00:02:37,120
elevation device

00:02:34,160 --> 00:02:37,360
it will give some flexibility of slicing

00:02:37,120 --> 00:02:39,599
and

00:02:37,360 --> 00:02:41,599
dicing on the dataset but skill the

00:02:39,599 --> 00:02:44,000
correlation say is proportional

00:02:41,599 --> 00:02:44,879
to the data that has been processed the

00:02:44,000 --> 00:02:47,280
need of

00:02:44,879 --> 00:02:48,480
accelerating the crystal core space and

00:02:47,280 --> 00:02:51,280
the support of

00:02:48,480 --> 00:02:51,760
more functionalities for piano users

00:02:51,280 --> 00:02:54,239
actually

00:02:51,760 --> 00:02:55,200
perfect match here right so that we

00:02:54,239 --> 00:02:59,120
developed depressed

00:02:55,200 --> 00:03:01,760
pinocchio so this will actually be a

00:02:59,120 --> 00:03:03,120
complete system that can cover the

00:03:01,760 --> 00:03:06,319
entire landscape

00:03:03,120 --> 00:03:11,280
for animals and we can leverage

00:03:06,319 --> 00:03:13,519
the best part of presto and the pin

00:03:11,280 --> 00:03:14,640
so in order to build that in our first

00:03:13,519 --> 00:03:17,680
iteration

00:03:14,640 --> 00:03:20,000
of walling presto to pinot

00:03:17,680 --> 00:03:22,400
isn't a super efficient as we only

00:03:20,000 --> 00:03:25,840
increased you know as a water store

00:03:22,400 --> 00:03:28,080
with the predicate the problem

00:03:25,840 --> 00:03:30,319
the performance here is good when the

00:03:28,080 --> 00:03:33,920
quarry is scanning a small set

00:03:30,319 --> 00:03:36,000
of the but for the largest scanning the

00:03:33,920 --> 00:03:37,920
performance is very ideal

00:03:36,000 --> 00:03:40,000
for example in this graph you can see

00:03:37,920 --> 00:03:42,959
that on the upper part

00:03:40,000 --> 00:03:44,640
for an aggregation to buy side so press

00:03:42,959 --> 00:03:46,560
worker will stand with the

00:03:44,640 --> 00:03:47,840
raw data transaction with the price uh

00:03:46,560 --> 00:03:49,920
with the price

00:03:47,840 --> 00:03:51,920
filipino and pino will written all the

00:03:49,920 --> 00:03:54,319
records matching this predicate

00:03:51,920 --> 00:03:55,519
and then presto will do the real uh

00:03:54,319 --> 00:03:59,200
aggregation

00:03:55,519 --> 00:04:03,040
and then go by here so this is a good

00:03:59,200 --> 00:04:05,680
small star dataset but larger set

00:04:03,040 --> 00:04:07,360
so that in order to basically uh fully

00:04:05,680 --> 00:04:08,879
take the power of phenol instrument

00:04:07,360 --> 00:04:10,480
aggregation push down feature

00:04:08,879 --> 00:04:12,799
we should allow suppress the phenol

00:04:10,480 --> 00:04:13,280
connector to do the best effort push

00:04:12,799 --> 00:04:14,799
down

00:04:13,280 --> 00:04:17,120
aggregation functions like penitent

00:04:14,799 --> 00:04:19,919
support without more like the sum

00:04:17,120 --> 00:04:20,560
count main match distinct approximate

00:04:19,919 --> 00:04:23,759
account

00:04:20,560 --> 00:04:25,520
etc and then the press worker actually

00:04:23,759 --> 00:04:27,840
talked to a penal broker

00:04:25,520 --> 00:04:28,960
that will ask for the results when we

00:04:27,840 --> 00:04:31,360
should require it

00:04:28,960 --> 00:04:33,120
so this latency graph actually shows the

00:04:31,360 --> 00:04:36,800
aggregation push down

00:04:33,120 --> 00:04:40,639
really push the limit for analytics

00:04:36,800 --> 00:04:44,320
and allow our users to fully enjoy

00:04:40,639 --> 00:04:47,919
real-time and along with the flexible

00:04:44,320 --> 00:04:49,680
curry capability for eight fifty million

00:04:47,919 --> 00:04:51,919
with aggregation push down you can still

00:04:49,680 --> 00:04:54,639
get less than one second answer

00:04:51,919 --> 00:04:56,800
the question you want because of this

00:04:54,639 --> 00:04:59,680
trial the president

00:04:56,800 --> 00:05:02,000
from this getting started tutorial and

00:04:59,680 --> 00:05:04,639
also please join up in a selection

00:05:02,000 --> 00:05:06,080
if you have any questions or just want

00:05:04,639 --> 00:05:09,120
to see what's the project

00:05:06,080 --> 00:05:10,720
news or updates and any feedbacks and

00:05:09,120 --> 00:05:13,919
contributions that will come

00:05:10,720 --> 00:05:15,759
from our community and lastly i want to

00:05:13,919 --> 00:05:19,120
thank all the contributors

00:05:15,759 --> 00:05:22,240
of this project uh divish direct

00:05:19,120 --> 00:05:25,280
abu james venky and

00:05:22,240 --> 00:05:29,199
jensen and that's pretty much

00:05:25,280 --> 00:05:29,199
for the talk today and thanks for

00:05:30,360 --> 00:05:33,360

YouTube URL: https://www.youtube.com/watch?v=rJJvnlpo4fY


