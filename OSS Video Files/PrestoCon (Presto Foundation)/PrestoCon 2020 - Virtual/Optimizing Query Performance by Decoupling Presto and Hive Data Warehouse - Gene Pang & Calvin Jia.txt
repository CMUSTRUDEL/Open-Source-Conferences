Title: Optimizing Query Performance by Decoupling Presto and Hive Data Warehouse - Gene Pang & Calvin Jia
Publication date: 2020-09-30
Playlist: PrestoCon 2020 - Virtual
Description: 
	Optimizing Query Performance by Decoupling Presto and Hive Data Warehouse - Gene Pang & Calvin Jia, Alluxio, Inc.

Speakers: Calvin Jia, Gene Pang

Presto is commonly used to query existing Hive data warehouses. Due to existing applications, tech debt, or previous operational challenges, Presto may not be able to achieve its full potential but bound and limited by past decisions. Challenges include overloaded Hive Metastore, unoptimized data layouts such as too many small files, or lack of influence over existing Hive applications.

Ideally, Presto would access data independently from how the data was originally managed. Alluxio, as a data orchestration layer provides the physical data independence for Presto to interact with the data more efficiently. In addition to caching, Alluxio provides a catalog service to abstract the table metadata, and transformations to expose compute-optimized data. In this talk, Gene describes the challenges of using Presto with Hive, and discusses how Alluxio data orchestration can solve them.
Captions: 
	00:00:00,640 --> 00:00:04,560
hello everyone welcome to the alexios

00:00:02,720 --> 00:00:05,600
structure data services presentation at

00:00:04,560 --> 00:00:07,200
prestocon

00:00:05,600 --> 00:00:09,280
this presentation will be about how

00:00:07,200 --> 00:00:11,200
we're able to optimize query performance

00:00:09,280 --> 00:00:13,519
by decoupling presto and the hive data

00:00:11,200 --> 00:00:15,679
warehouse

00:00:13,519 --> 00:00:18,000
first a little bit about ourselves i'm

00:00:15,679 --> 00:00:19,119
calvin gia and i'm an alexio pmc and

00:00:18,000 --> 00:00:21,119
core maintainer

00:00:19,119 --> 00:00:22,880
i'm joined today by jean peng who is the

00:00:21,119 --> 00:00:23,840
lead developer of alexios structured

00:00:22,880 --> 00:00:26,320
data services

00:00:23,840 --> 00:00:28,800
and also an alexio pmc member and core

00:00:26,320 --> 00:00:28,800
maintainer

00:00:29,279 --> 00:00:33,280
here's the agenda for the presentation

00:00:30,960 --> 00:00:35,040
today first we'll give an overview of

00:00:33,280 --> 00:00:36,719
alexio and why we set out to build

00:00:35,040 --> 00:00:38,000
structured data services in the first

00:00:36,719 --> 00:00:39,520
place

00:00:38,000 --> 00:00:42,000
then we'll have a deep dive into how

00:00:39,520 --> 00:00:43,280
structured data services work for presto

00:00:42,000 --> 00:00:46,480
and finally we'll finish the

00:00:43,280 --> 00:00:46,480
presentation with a demo

00:00:47,440 --> 00:00:50,879
some of you may be asking just what is

00:00:49,200 --> 00:00:52,480
alexio

00:00:50,879 --> 00:00:54,399
alexio is an open source data

00:00:52,480 --> 00:00:56,399
orchestration framework

00:00:54,399 --> 00:00:59,039
it decouples compute and storage and

00:00:56,399 --> 00:01:01,199
provides an abstraction for both layers

00:00:59,039 --> 00:01:02,879
compute applications like presto can

00:01:01,199 --> 00:01:04,960
access files with the semantics

00:01:02,879 --> 00:01:07,200
latency and throughput expected of

00:01:04,960 --> 00:01:08,960
storage even if the underlying storage

00:01:07,200 --> 00:01:12,799
is not as fast or even providing the

00:01:08,960 --> 00:01:14,880
same apis that presto wants to use

00:01:12,799 --> 00:01:17,439
but while the data orchestration layer

00:01:14,880 --> 00:01:19,280
enables flexibility and compatibility

00:01:17,439 --> 00:01:22,880
performance is often the most compelling

00:01:19,280 --> 00:01:24,560
reason for using something like galaxia

00:01:22,880 --> 00:01:27,280
let's take a look at how alexio can

00:01:24,560 --> 00:01:29,200
improve performance for presto

00:01:27,280 --> 00:01:31,840
alexio accelerates the performance of

00:01:29,200 --> 00:01:33,840
pesto by making file reads faster

00:01:31,840 --> 00:01:35,439
scans of data in memory are an order of

00:01:33,840 --> 00:01:37,600
magnitude faster than

00:01:35,439 --> 00:01:39,360
on disk which are then an order of

00:01:37,600 --> 00:01:44,320
magnitude faster than reading from

00:01:39,360 --> 00:01:46,320
a remote storage like s3 or remote hdfs

00:01:44,320 --> 00:01:47,920
by acting as a data a cache alexio

00:01:46,320 --> 00:01:49,600
improves the i o speed of plasto

00:01:47,920 --> 00:01:54,079
especially in cases where the underlying

00:01:49,600 --> 00:01:55,600
storage is remote or otherwise slow

00:01:54,079 --> 00:01:57,600
an often overlooked aspect of

00:01:55,600 --> 00:01:59,439
performance is metadata performance

00:01:57,600 --> 00:02:00,719
presto queries can request a huge number

00:01:59,439 --> 00:02:02,640
of metadata operations

00:02:00,719 --> 00:02:04,719
especially when the query parallelism is

00:02:02,640 --> 00:02:07,040
high alexia can provide

00:02:04,719 --> 00:02:08,239
latency an order of magnitude less than

00:02:07,040 --> 00:02:09,920
object storage

00:02:08,239 --> 00:02:11,440
object storages in the cloud and with

00:02:09,920 --> 00:02:13,680
much less variance

00:02:11,440 --> 00:02:16,000
in addition alexa metadata operations

00:02:13,680 --> 00:02:16,879
are free as opposed to metadata calls to

00:02:16,000 --> 00:02:19,040
cloud storage

00:02:16,879 --> 00:02:20,720
which unlike data transfer even same

00:02:19,040 --> 00:02:23,840
region metadata operations can still

00:02:20,720 --> 00:02:23,840
incur costs

00:02:26,480 --> 00:02:30,319
however despite these performance

00:02:28,480 --> 00:02:32,239
improvements a common ask from

00:02:30,319 --> 00:02:35,440
our users was to further improve the

00:02:32,239 --> 00:02:37,360
performance of olap workloads on alexio

00:02:35,440 --> 00:02:38,800
and to do that we realized we needed to

00:02:37,360 --> 00:02:41,200
go beyond files

00:02:38,800 --> 00:02:42,720
by just managing file access alexio

00:02:41,200 --> 00:02:44,480
could not impact the portions of the

00:02:42,720 --> 00:02:46,560
query which were slow

00:02:44,480 --> 00:02:48,879
here are some examples if the hive

00:02:46,560 --> 00:02:50,080
metastore was overloaded and it just had

00:02:48,879 --> 00:02:51,680
very high latency

00:02:50,080 --> 00:02:54,480
all the queries would just take a hit in

00:02:51,680 --> 00:02:56,560
performance if the ingested data format

00:02:54,480 --> 00:02:57,280
was unfriendly to query like a csv

00:02:56,560 --> 00:02:58,720
format

00:02:57,280 --> 00:03:00,800
the query plans would not be able to

00:02:58,720 --> 00:03:03,519
take advantage of many optimizations and

00:03:00,800 --> 00:03:05,599
therefore become inefficient

00:03:03,519 --> 00:03:07,360
similarly if the ingested data had tons

00:03:05,599 --> 00:03:08,959
of partitions and small files

00:03:07,360 --> 00:03:11,040
even if your data format was something

00:03:08,959 --> 00:03:11,920
like parquet it still wouldn't be able

00:03:11,040 --> 00:03:15,280
to efficiently

00:03:11,920 --> 00:03:16,959
serve the data for the query to address

00:03:15,280 --> 00:03:18,319
these problems we designed alexios

00:03:16,959 --> 00:03:21,120
structure data services

00:03:18,319 --> 00:03:22,800
a major new component of alexio gene is

00:03:21,120 --> 00:03:23,440
the lead developer of the module and he

00:03:22,800 --> 00:03:24,959
will describe

00:03:23,440 --> 00:03:26,799
how we tackle these problems and the

00:03:24,959 --> 00:03:33,840
benefits of going beyond the file level

00:03:26,799 --> 00:03:33,840
in alexia

00:03:35,040 --> 00:03:39,519
thank you kelvin i'm gene and i'll be

00:03:37,680 --> 00:03:42,319
talking about the alexander structured

00:03:39,519 --> 00:03:42,319
data services

00:03:42,879 --> 00:03:48,239
first before talking about alexio's

00:03:45,599 --> 00:03:50,560
structural benefits is i will talk about

00:03:48,239 --> 00:03:51,280
a little background on the typical

00:03:50,560 --> 00:03:53,840
environment

00:03:51,280 --> 00:03:54,720
of testo so here is a typical

00:03:53,840 --> 00:03:56,640
environment

00:03:54,720 --> 00:03:59,280
we have presta with the tide connector

00:03:56,640 --> 00:04:02,000
and it's communicating and interacting

00:03:59,280 --> 00:04:03,840
with the highest store and the storage

00:04:02,000 --> 00:04:07,360
in order to

00:04:03,840 --> 00:04:09,439
service the queries this is a pretty

00:04:07,360 --> 00:04:12,080
simplistic view

00:04:09,439 --> 00:04:13,680
but in reality a lot of environments

00:04:12,080 --> 00:04:14,000
could look something more like this

00:04:13,680 --> 00:04:17,440
where

00:04:14,000 --> 00:04:20,639
there are a lot more components in the

00:04:17,440 --> 00:04:22,160
ecosystem so it's not just presto and

00:04:20,639 --> 00:04:24,000
the storage but there's

00:04:22,160 --> 00:04:26,000
there may also be other computation

00:04:24,000 --> 00:04:28,720
frameworks like spark and hives

00:04:26,000 --> 00:04:31,120
that is also accessing the storage as

00:04:28,720 --> 00:04:34,000
well as the hive water store

00:04:31,120 --> 00:04:35,600
in addition to that there could be other

00:04:34,000 --> 00:04:39,199
types of applications

00:04:35,600 --> 00:04:42,000
that are ingesting data into the hives

00:04:39,199 --> 00:04:43,520
into the hive warehouse communicating

00:04:42,000 --> 00:04:45,440
both with the storage

00:04:43,520 --> 00:04:47,120
and the hive metastores so there

00:04:45,440 --> 00:04:48,400
actually could be many different

00:04:47,120 --> 00:04:52,639
components

00:04:48,400 --> 00:04:57,199
to the entire

00:04:52,639 --> 00:04:59,600
presto and hive environment

00:04:57,199 --> 00:05:00,320
so with all of these potential

00:04:59,600 --> 00:05:02,720
components

00:05:00,320 --> 00:05:04,000
there are some inefficiencies that might

00:05:02,720 --> 00:05:07,039
be possible

00:05:04,000 --> 00:05:08,960
one might be just an overloaded or a

00:05:07,039 --> 00:05:10,400
slower higher metastore when

00:05:08,960 --> 00:05:13,199
being accessed by many different

00:05:10,400 --> 00:05:16,479
applications another could be

00:05:13,199 --> 00:05:19,919
that there are unoptimized file formats

00:05:16,479 --> 00:05:21,919
for example csv is slower than

00:05:19,919 --> 00:05:24,080
is typically slower than other file

00:05:21,919 --> 00:05:26,560
formats such as parquet orc which are

00:05:24,080 --> 00:05:30,720
more optimized for

00:05:26,560 --> 00:05:34,080
you know analysis there could also be

00:05:30,720 --> 00:05:36,000
inefficient table organization

00:05:34,080 --> 00:05:37,360
and one example of that could be if

00:05:36,000 --> 00:05:39,840
there are just too many directories or

00:05:37,360 --> 00:05:43,360
too many small files like that could

00:05:39,840 --> 00:05:46,960
negatively negatively impact the

00:05:43,360 --> 00:05:51,280
query processing and also

00:05:46,960 --> 00:05:52,400
there may be an inability to be able to

00:05:51,280 --> 00:05:55,360
update

00:05:52,400 --> 00:05:56,960
existing applications and how those

00:05:55,360 --> 00:06:00,080
applications are writing

00:05:56,960 --> 00:06:02,160
the data in the hype in the hybrid house

00:06:00,080 --> 00:06:03,680
so it might be there might be an example

00:06:02,160 --> 00:06:06,000
of

00:06:03,680 --> 00:06:07,280
like a legacy application or a different

00:06:06,000 --> 00:06:09,840
organization

00:06:07,280 --> 00:06:12,240
that is essentially ingesting data into

00:06:09,840 --> 00:06:15,280
the hive warehouse and

00:06:12,240 --> 00:06:16,319
that is not you know that you are not

00:06:15,280 --> 00:06:20,000
able to

00:06:16,319 --> 00:06:22,479
modify how that application is written

00:06:20,000 --> 00:06:24,000
so because of these uh potential

00:06:22,479 --> 00:06:25,600
dependencies there's really like a

00:06:24,000 --> 00:06:29,360
really strong depend

00:06:25,600 --> 00:06:31,280
dependence on from presto to the hive

00:06:29,360 --> 00:06:32,720
warehouse both to the higher metastore

00:06:31,280 --> 00:06:36,319
and the storage

00:06:32,720 --> 00:06:38,880
as i mentioned before you know whether

00:06:36,319 --> 00:06:40,560
the files are in a specific format or

00:06:38,880 --> 00:06:42,800
organizes specific way

00:06:40,560 --> 00:06:44,639
or you know being accessed by the hybrid

00:06:42,800 --> 00:06:47,680
store presto is technically

00:06:44,639 --> 00:06:50,880
dependent on

00:06:47,680 --> 00:06:50,880
those components so

00:06:51,680 --> 00:06:55,280
there isn't very much flexibility so how

00:06:54,240 --> 00:06:59,680
are we how

00:06:55,280 --> 00:07:02,400
can we unlock this type of dependence

00:06:59,680 --> 00:07:05,039
well in order to unlock the potential we

00:07:02,400 --> 00:07:08,560
could use data orchestration

00:07:05,039 --> 00:07:11,360
and there are with data orchestration

00:07:08,560 --> 00:07:11,360
it is able to

00:07:11,840 --> 00:07:16,400
provide decoupling of the compute from

00:07:14,240 --> 00:07:17,360
the high data warehouse so in this

00:07:16,400 --> 00:07:19,039
example would be

00:07:17,360 --> 00:07:20,960
decoupling presto from the high data

00:07:19,039 --> 00:07:24,000
warehouse and this also

00:07:20,960 --> 00:07:24,880
can further enable compute optimized

00:07:24,000 --> 00:07:28,000
data access

00:07:24,880 --> 00:07:28,000
with data orchestration

00:07:28,400 --> 00:07:31,759
so specifically with alexa data

00:07:30,240 --> 00:07:33,039
orchestration this is what the

00:07:31,759 --> 00:07:35,360
environment

00:07:33,039 --> 00:07:36,639
will look like presta would communicate

00:07:35,360 --> 00:07:39,360
with alexio

00:07:36,639 --> 00:07:40,319
and then alexia would help manage the

00:07:39,360 --> 00:07:44,639
access

00:07:40,319 --> 00:07:45,759
and the access to the hyperstore as well

00:07:44,639 --> 00:07:49,199
as to the storage

00:07:45,759 --> 00:07:49,759
and this this um layer in between presto

00:07:49,199 --> 00:07:52,639
and

00:07:49,759 --> 00:07:54,319
the hive warehouse really helps decouple

00:07:52,639 --> 00:07:56,879
the two

00:07:54,319 --> 00:07:59,120
components as well as be able to provide

00:07:56,879 --> 00:08:03,120
compute optimized

00:07:59,120 --> 00:08:03,120
data access for presto

00:08:03,199 --> 00:08:09,599
and so this is a simple overview

00:08:06,319 --> 00:08:13,840
of how alexa data orchestration can

00:08:09,599 --> 00:08:13,840
fit in the ecosystem

00:08:13,919 --> 00:08:18,240
so the types of benefits of data

00:08:16,160 --> 00:08:21,919
orchestration

00:08:18,240 --> 00:08:25,440
are many so here is an example

00:08:21,919 --> 00:08:27,120
of sort of the store systems on the left

00:08:25,440 --> 00:08:29,440
which is the hive warehouse and the sql

00:08:27,120 --> 00:08:32,800
frameworks on the right just presto

00:08:29,440 --> 00:08:35,919
and being able to bridge this gap

00:08:32,800 --> 00:08:38,000
is the luxia data orchestration and uh

00:08:35,919 --> 00:08:39,519
before structured data services alexa

00:08:38,000 --> 00:08:40,000
already provides some of these benefits

00:08:39,519 --> 00:08:41,680
such as

00:08:40,000 --> 00:08:43,599
caching and unified interface and

00:08:41,680 --> 00:08:47,279
namespace these benefits

00:08:43,599 --> 00:08:49,839
already are there with with alexio

00:08:47,279 --> 00:08:50,560
but with structured data services we're

00:08:49,839 --> 00:08:53,040
able to provide

00:08:50,560 --> 00:08:56,080
additional benefits such as schema aware

00:08:53,040 --> 00:08:57,760
optimizations compute optimized formats

00:08:56,080 --> 00:09:01,360
and ultimately physical data

00:08:57,760 --> 00:09:01,360
independence what that means is

00:09:01,519 --> 00:09:09,120
the application like presto is not

00:09:05,440 --> 00:09:09,920
tied down to the physical representation

00:09:09,120 --> 00:09:12,000
of that data

00:09:09,920 --> 00:09:13,040
into the warehouse and there could be

00:09:12,000 --> 00:09:16,320
some sort of

00:09:13,040 --> 00:09:20,839
um you know difference

00:09:16,320 --> 00:09:23,200
in how the application can access that

00:09:20,839 --> 00:09:26,480
data

00:09:23,200 --> 00:09:27,920
so next i will go over what luxo

00:09:26,480 --> 00:09:31,680
structure data services are

00:09:27,920 --> 00:09:31,680
and the different components of it

00:09:35,360 --> 00:09:42,080
so in this diagram we have

00:09:39,200 --> 00:09:42,560
the storage system files and data on the

00:09:42,080 --> 00:09:44,800
left

00:09:42,560 --> 00:09:46,160
and then the sql engine such as presto

00:09:44,800 --> 00:09:49,360
on the right

00:09:46,160 --> 00:09:51,920
and everything in the middle here is

00:09:49,360 --> 00:09:52,560
what are our different components of the

00:09:51,920 --> 00:09:56,560
luxury

00:09:52,560 --> 00:10:00,480
structure data services so

00:09:56,560 --> 00:10:02,000
one component of sds

00:10:00,480 --> 00:10:03,680
is the transformation service and this

00:10:02,000 --> 00:10:05,920
is this helps

00:10:03,680 --> 00:10:06,800
transform the data that's stored in the

00:10:05,920 --> 00:10:09,360
warehouse

00:10:06,800 --> 00:10:10,079
into a format that is more optimized for

00:10:09,360 --> 00:10:13,760
the compute

00:10:10,079 --> 00:10:14,720
engine we also have structured data and

00:10:13,760 --> 00:10:18,640
metadata

00:10:14,720 --> 00:10:21,600
and what this component is is for

00:10:18,640 --> 00:10:22,480
storing and managing the data and

00:10:21,600 --> 00:10:25,680
metadata

00:10:22,480 --> 00:10:28,000
that is relevant for the structured data

00:10:25,680 --> 00:10:28,880
and this could include both the payload

00:10:28,000 --> 00:10:31,760
as well as

00:10:28,880 --> 00:10:34,399
like the metadata such as schemas and

00:10:31,760 --> 00:10:37,120
column information

00:10:34,399 --> 00:10:38,720
and lastly we have the access layer

00:10:37,120 --> 00:10:42,320
which is the structured data client

00:10:38,720 --> 00:10:44,399
and this helps you know read the data

00:10:42,320 --> 00:10:45,680
as well as the metadata that is being

00:10:44,399 --> 00:10:49,120
managed by

00:10:45,680 --> 00:10:49,120
the luxury sds

00:10:50,880 --> 00:10:54,000
so as i mentioned before this is the

00:10:52,800 --> 00:10:57,200
typical

00:10:54,000 --> 00:10:58,079
presta environment and uh you know this

00:10:57,200 --> 00:11:00,079
is also the

00:10:58,079 --> 00:11:02,560
the typical enviro this is the target

00:11:00,079 --> 00:11:05,519
environment for alexa sds

00:11:02,560 --> 00:11:08,000
so the new components uh first is the

00:11:05,519 --> 00:11:10,079
electro connector this is um

00:11:08,000 --> 00:11:12,320
the presto will now use the luxia

00:11:10,079 --> 00:11:15,920
connector in order to communicate with

00:11:12,320 --> 00:11:19,279
the various other services of alexio

00:11:15,920 --> 00:11:21,839
there's also the luxio caching service

00:11:19,279 --> 00:11:23,040
which helps bring the data closer to the

00:11:21,839 --> 00:11:25,760
application

00:11:23,040 --> 00:11:27,519
closer to presto and accelerate the data

00:11:25,760 --> 00:11:29,040
access

00:11:27,519 --> 00:11:31,040
we also have the electric catalog

00:11:29,040 --> 00:11:34,880
service which helps manage the metadata

00:11:31,040 --> 00:11:36,160
for tables and columns and rows

00:11:34,880 --> 00:11:37,920
and we also have the alexa

00:11:36,160 --> 00:11:41,600
transformation service

00:11:37,920 --> 00:11:43,200
which is used it is utilized for

00:11:41,600 --> 00:11:45,839
transforming

00:11:43,200 --> 00:11:46,560
stored data in the warehouse into a

00:11:45,839 --> 00:11:48,800
format

00:11:46,560 --> 00:11:51,519
an organization that is more optimized

00:11:48,800 --> 00:11:51,519
for presto

00:11:52,480 --> 00:11:56,639
so for the elastic catalog service its

00:11:55,200 --> 00:11:58,720
main functionality

00:11:56,639 --> 00:12:00,480
is to manage the metadata for structured

00:11:58,720 --> 00:12:04,399
data and for the tables

00:12:00,480 --> 00:12:05,120
and the the main thing the main concept

00:12:04,399 --> 00:12:08,399
here is

00:12:05,120 --> 00:12:11,760
the under database concept which is

00:12:08,399 --> 00:12:14,160
an abstraction of other types of

00:12:11,760 --> 00:12:15,440
catalogs that can be hooked into a local

00:12:14,160 --> 00:12:19,040
catalog servers

00:12:15,440 --> 00:12:20,959
today we have two types of udvs

00:12:19,040 --> 00:12:22,800
one is the hive of udp which it will

00:12:20,959 --> 00:12:24,800
interact with the hybrid store

00:12:22,800 --> 00:12:26,000
and we have to go to udp which will

00:12:24,800 --> 00:12:30,000
interact with

00:12:26,000 --> 00:12:33,360
the uh aws glue

00:12:30,000 --> 00:12:36,800
and with the catalog service this

00:12:33,360 --> 00:12:38,959
really affects some of the benefits of

00:12:36,800 --> 00:12:41,680
the catalog service is to have

00:12:38,959 --> 00:12:43,040
is to be able to provide schema

00:12:41,680 --> 00:12:46,880
optimizations it also

00:12:43,040 --> 00:12:50,160
improves and simplifies the deployment

00:12:46,880 --> 00:12:54,000
of alexio with custom since

00:12:50,160 --> 00:12:55,519
now um you know restarts

00:12:54,000 --> 00:12:58,000
and reconfigurations are no longer

00:12:55,519 --> 00:13:00,320
required we just need to

00:12:58,000 --> 00:13:02,959
point to the catalog service then the

00:13:00,320 --> 00:13:05,519
logic catalog service will

00:13:02,959 --> 00:13:06,959
do the appropriate thing to map it to

00:13:05,519 --> 00:13:09,680
alexia locations

00:13:06,959 --> 00:13:09,680
for presto

00:13:10,720 --> 00:13:14,160
we also have the alexio presto connector

00:13:13,200 --> 00:13:16,959
and this

00:13:14,160 --> 00:13:18,560
really helps unless you have a tighter

00:13:16,959 --> 00:13:21,600
integration with presto

00:13:18,560 --> 00:13:23,120
and it's a new plug-in connector uh

00:13:21,600 --> 00:13:24,399
based on the existing presta height

00:13:23,120 --> 00:13:28,560
connector

00:13:24,399 --> 00:13:29,279
and the uh the source code has actually

00:13:28,560 --> 00:13:32,399
been merged

00:13:29,279 --> 00:13:35,839
into both crystal sql and plus the db

00:13:32,399 --> 00:13:38,160
um source code and so they are available

00:13:35,839 --> 00:13:40,790
in these versions of crystal sql and

00:13:38,160 --> 00:13:43,600
prestodb

00:13:40,790 --> 00:13:46,560
[Music]

00:13:43,600 --> 00:13:47,760
and lastly we have the transformation

00:13:46,560 --> 00:13:49,040
service and

00:13:47,760 --> 00:13:51,600
ultimately the goal for the

00:13:49,040 --> 00:13:52,800
transformation service is to transform

00:13:51,600 --> 00:13:55,279
the data

00:13:52,800 --> 00:13:57,519
so that it is compute optimized and that

00:13:55,279 --> 00:13:59,839
is that which may be independent from

00:13:57,519 --> 00:14:01,440
the storage optimized format and those

00:13:59,839 --> 00:14:02,240
could be different which is why it is

00:14:01,440 --> 00:14:05,440
important

00:14:02,240 --> 00:14:06,320
for some transformations uh here's one

00:14:05,440 --> 00:14:09,519
example

00:14:06,320 --> 00:14:11,440
transformation that is that is available

00:14:09,519 --> 00:14:12,880
which is the coalesce transformation

00:14:11,440 --> 00:14:15,519
this is where it takes uh

00:14:12,880 --> 00:14:17,120
many smaller files and sort of and then

00:14:15,519 --> 00:14:20,240
coalesces it into

00:14:17,120 --> 00:14:23,440
fewer larger files and this is uh

00:14:20,240 --> 00:14:25,680
typically more efficient to process

00:14:23,440 --> 00:14:26,560
when they are there are fewer larger

00:14:25,680 --> 00:14:30,959
files than

00:14:26,560 --> 00:14:32,880
too many small files and another

00:14:30,959 --> 00:14:34,720
uh transformation that's available is

00:14:32,880 --> 00:14:36,959
the format conversion

00:14:34,720 --> 00:14:38,320
and in this example we have a csv to

00:14:36,959 --> 00:14:40,320
parquet

00:14:38,320 --> 00:14:41,440
format conversion in the transformation

00:14:40,320 --> 00:14:44,240
service and

00:14:41,440 --> 00:14:44,800
uh and this is this can be helpful

00:14:44,240 --> 00:14:48,000
because

00:14:44,800 --> 00:14:52,560
parquet is more efficient to process

00:14:48,000 --> 00:14:56,079
than csv is so this could also help with

00:14:52,560 --> 00:14:56,079
helping the data be more compute

00:14:56,839 --> 00:15:01,680
optimized

00:14:58,160 --> 00:15:04,240
so next i'll go into a short demo of how

00:15:01,680 --> 00:15:04,240
this works

00:15:05,279 --> 00:15:13,920
so for the demo setup we have

00:15:09,600 --> 00:15:15,920
uh we have two isolated clusters

00:15:13,920 --> 00:15:18,240
and each of these clusters are the same

00:15:15,920 --> 00:15:19,519
size uh the only difference is that one

00:15:18,240 --> 00:15:22,560
of the clusters

00:15:19,519 --> 00:15:25,440
um has alexa sds and the other cluster

00:15:22,560 --> 00:15:27,760
doesn't so in one cluster we have presto

00:15:25,440 --> 00:15:29,440
and the height net store and s3 data

00:15:27,760 --> 00:15:31,920
and in the other cluster we have the

00:15:29,440 --> 00:15:35,040
same setup with alexa sds

00:15:31,920 --> 00:15:39,199
and we have some sample

00:15:35,040 --> 00:15:42,800
sample data with tpcds on s3

00:15:39,199 --> 00:15:45,920
and the

00:15:42,800 --> 00:15:47,759
sort of the one the one difference here

00:15:45,920 --> 00:15:51,199
is that some tables in this

00:15:47,759 --> 00:15:55,199
sample data set has

00:15:51,199 --> 00:15:58,880
many as many csv files in it so

00:15:55,199 --> 00:16:01,120
we want to show how an unoptimized

00:15:58,880 --> 00:16:02,959
organization and formats can be

00:16:01,120 --> 00:16:09,839
transformed to be

00:16:02,959 --> 00:16:09,839
more optimized more compute optimized

00:16:12,959 --> 00:16:19,040
so uh here

00:16:16,000 --> 00:16:23,600
is the demo so on this left

00:16:19,040 --> 00:16:27,279
hand side this is the cluster that has

00:16:23,600 --> 00:16:30,720
presto and alexia and on the right

00:16:27,279 --> 00:16:35,519
this is the cluster that has presto

00:16:30,720 --> 00:16:39,120
and just hive hypothesis no alexia

00:16:35,519 --> 00:16:39,120
and so the first thing we will do

00:16:39,680 --> 00:16:43,680
is uh simply i just attach

00:16:43,759 --> 00:16:48,160
attach the data attach the the high

00:16:46,399 --> 00:16:50,480
metastore to alexio

00:16:48,160 --> 00:16:52,399
and what that is doing is making a

00:16:50,480 --> 00:16:55,440
connection and making an association

00:16:52,399 --> 00:16:57,279
for the catalog in order um for the

00:16:55,440 --> 00:16:58,639
catalog to be aware of the hype in the

00:16:57,279 --> 00:17:02,079
store

00:16:58,639 --> 00:17:06,079
and so then we can also list the tables

00:17:02,079 --> 00:17:08,959
in in in the electric catalog and these

00:17:06,079 --> 00:17:14,480
are the two ctf tables

00:17:08,959 --> 00:17:14,480
and next we can even see it on in presto

00:17:15,760 --> 00:17:19,919
we can see the same tables in presto and

00:17:18,319 --> 00:17:21,919
so right now this presto

00:17:19,919 --> 00:17:23,199
show tables command is communicating

00:17:21,919 --> 00:17:26,319
with the luxury catalog

00:17:23,199 --> 00:17:32,880
service and getting and retrieving those

00:17:26,319 --> 00:17:36,240
those table names and we can also

00:17:32,880 --> 00:17:36,559
just do a simple uh small query just to

00:17:36,240 --> 00:17:38,559
see

00:17:36,559 --> 00:17:40,640
that it's grabbing the data so this is

00:17:38,559 --> 00:17:42,400
also um the presto

00:17:40,640 --> 00:17:44,080
is going through the electric connector

00:17:42,400 --> 00:17:44,559
to communicate with alexa to get that

00:17:44,080 --> 00:17:47,120
data

00:17:44,559 --> 00:17:47,679
and the metadata now as i mentioned

00:17:47,120 --> 00:17:52,080
before

00:17:47,679 --> 00:17:52,080
some of the tables um

00:17:52,400 --> 00:17:56,640
are very inefficient meaning that too

00:17:54,480 --> 00:18:00,240
many css small csv files

00:17:56,640 --> 00:18:02,400
so once one of those such tables

00:18:00,240 --> 00:18:03,520
is the storage data stable sales table

00:18:02,400 --> 00:18:06,000
and what we

00:18:03,520 --> 00:18:08,080
just did here is we will initiate a

00:18:06,000 --> 00:18:12,000
transformation

00:18:08,080 --> 00:18:14,799
of that table in the alexio

00:18:12,000 --> 00:18:16,799
structured data services so once that is

00:18:14,799 --> 00:18:19,919
kicked off we can

00:18:16,799 --> 00:18:22,559
check out the status of that

00:18:19,919 --> 00:18:24,080
of that job and right now it is running

00:18:22,559 --> 00:18:25,840
it'll take about 30 seconds so while

00:18:24,080 --> 00:18:28,000
that's happening

00:18:25,840 --> 00:18:30,960
we are going to check out the other

00:18:28,000 --> 00:18:34,160
cluster which just has cluster and hive

00:18:30,960 --> 00:18:35,919
and and just look at and and look at the

00:18:34,160 --> 00:18:39,679
look at the data there

00:18:35,919 --> 00:18:43,600
so we connected to cluster and hives

00:18:39,679 --> 00:18:46,720
we can also do show tables here and

00:18:43,600 --> 00:18:46,720
we can

00:18:49,760 --> 00:18:54,880
also you know do a simple query from

00:18:52,480 --> 00:18:54,880
hive

00:18:55,440 --> 00:18:58,400
and what we're going to do is we're

00:18:56,320 --> 00:19:00,480
going to run what is one of the tpcds

00:18:58,400 --> 00:19:03,039
queries

00:19:00,480 --> 00:19:04,320
and this query is just one of the one of

00:19:03,039 --> 00:19:08,000
the queries and it does

00:19:04,320 --> 00:19:10,480
access um it does access

00:19:08,000 --> 00:19:11,200
the store store sales table which you

00:19:10,480 --> 00:19:14,320
know has

00:19:11,200 --> 00:19:16,320
a lot of small csv files and

00:19:14,320 --> 00:19:18,320
with this query it's actually going to

00:19:16,320 --> 00:19:19,440
be accessing the s3 files directly

00:19:18,320 --> 00:19:23,679
because

00:19:19,440 --> 00:19:26,720
um like it's alexia is not involved

00:19:23,679 --> 00:19:28,880
and so um as you can see it finished

00:19:26,720 --> 00:19:30,640
its access that table uh the store says

00:19:28,880 --> 00:19:31,679
table with many csv files and it took

00:19:30,640 --> 00:19:34,880
about 21

00:19:31,679 --> 00:19:36,559
uh 21 seconds if you go back to the

00:19:34,880 --> 00:19:39,200
luxia cluster here

00:19:36,559 --> 00:19:42,000
and then look at the status of that job

00:19:39,200 --> 00:19:45,600
we can see that it is completed

00:19:42,000 --> 00:19:48,960
we can also take a look um

00:19:45,600 --> 00:19:51,840
a quick look at the files that are there

00:19:48,960 --> 00:19:54,080
and so here we have about one and a half

00:19:51,840 --> 00:19:57,440
gigs of data and actually none of it

00:19:54,080 --> 00:20:01,600
is cached in the log file yet

00:19:57,440 --> 00:20:04,840
so what we'll do now is run that query

00:20:01,600 --> 00:20:06,400
on the luxor cluster after it's been

00:20:04,840 --> 00:20:09,120
transformed

00:20:06,400 --> 00:20:10,480
so now we're running that query um in

00:20:09,120 --> 00:20:13,039
the lecture cluster

00:20:10,480 --> 00:20:14,720
and this is now going to be using the

00:20:13,039 --> 00:20:17,679
transformed data

00:20:14,720 --> 00:20:20,960
in order to satisfy the query and it got

00:20:17,679 --> 00:20:23,520
faster and it took about eight seconds

00:20:20,960 --> 00:20:25,840
so the highest query by itself took

00:20:23,520 --> 00:20:27,520
about 21 22 seconds

00:20:25,840 --> 00:20:29,679
uh with the transformations it took a

00:20:27,520 --> 00:20:34,000
second and then if we take a look at

00:20:29,679 --> 00:20:37,840
the luxio listing again

00:20:34,000 --> 00:20:41,440
here we can see that now all the data

00:20:37,840 --> 00:20:42,320
is cached in alexio so when we run it

00:20:41,440 --> 00:20:44,320
one more time

00:20:42,320 --> 00:20:47,120
on the luxury cluster it's now going to

00:20:44,320 --> 00:20:49,520
read the cached and transform data

00:20:47,120 --> 00:20:52,159
and it's it was faster and it took about

00:20:49,520 --> 00:20:54,720
four seconds

00:20:52,159 --> 00:20:56,240
so this was a quick demo like how the

00:20:54,720 --> 00:20:59,039
luxio sts

00:20:56,240 --> 00:20:59,039
components work

00:20:59,840 --> 00:21:06,400
and then um

00:21:03,120 --> 00:21:06,400
going back to the presentation

00:21:07,360 --> 00:21:10,559
yeah so here's a quick summary of the

00:21:08,960 --> 00:21:12,400
demo that we have

00:21:10,559 --> 00:21:13,600
we attached the hive database to the

00:21:12,400 --> 00:21:15,679
catalog

00:21:13,600 --> 00:21:18,159
and from then on it served all the

00:21:15,679 --> 00:21:21,440
information to presto

00:21:18,159 --> 00:21:24,320
through the luxo alexio

00:21:21,440 --> 00:21:27,520
connector and so without custom without

00:21:24,320 --> 00:21:30,559
luxury it took about 22 to 23 seconds

00:21:27,520 --> 00:21:31,760
with just the transformations it took

00:21:30,559 --> 00:21:33,360
about eight seconds

00:21:31,760 --> 00:21:35,039
and then with the transformations and

00:21:33,360 --> 00:21:36,559
caching it took about three to four

00:21:35,039 --> 00:21:38,880
seconds

00:21:36,559 --> 00:21:40,720
so this is just a simple example of how

00:21:38,880 --> 00:21:45,840
the structured data services

00:21:40,720 --> 00:21:45,840
can help uh with suppressed deployments

00:21:48,320 --> 00:21:54,240
so lastly we have

00:21:51,520 --> 00:21:56,400
future work for the structured data

00:21:54,240 --> 00:21:59,039
services

00:21:56,400 --> 00:21:59,440
we have uh and most of these are

00:21:59,039 --> 00:22:02,400
actually

00:21:59,440 --> 00:22:04,080
from uh the community itself and so we

00:22:02,400 --> 00:22:06,960
have new udb implementations

00:22:04,080 --> 00:22:08,080
we do we did just recently add the aws

00:22:06,960 --> 00:22:11,120
school implementation

00:22:08,080 --> 00:22:12,960
so that is there and um there are also

00:22:11,120 --> 00:22:14,480
additional ones that we have been

00:22:12,960 --> 00:22:16,799
discussing um

00:22:14,480 --> 00:22:18,000
we are also considering additional

00:22:16,799 --> 00:22:21,039
conversion formats such as

00:22:18,000 --> 00:22:23,280
json converting json

00:22:21,039 --> 00:22:24,480
we're also looking into some tdm dml

00:22:23,280 --> 00:22:27,440
workloads

00:22:24,480 --> 00:22:28,640
right now only we the read-only

00:22:27,440 --> 00:22:30,799
workloads are supported

00:22:28,640 --> 00:22:32,240
and we're also looking at arrow for some

00:22:30,799 --> 00:22:36,159
additional uh optimized

00:22:32,240 --> 00:22:36,159
structured data uh apis

00:22:36,960 --> 00:22:42,000
so um yeah this has been available for a

00:22:39,600 --> 00:22:44,480
few versions it's standard 2.3

00:22:42,000 --> 00:22:46,320
um you can check it out and also always

00:22:44,480 --> 00:22:47,360
uh you know providing feedback is very

00:22:46,320 --> 00:22:49,600
important to us

00:22:47,360 --> 00:22:50,720
so you can always talk to us in our

00:22:49,600 --> 00:22:55,360
staff channel

00:22:50,720 --> 00:22:56,400
or um or you know report any issues in

00:22:55,360 --> 00:22:59,679
our github

00:22:56,400 --> 00:23:06,000
issues tracking so um that is it thank

00:22:59,679 --> 00:23:06,000

YouTube URL: https://www.youtube.com/watch?v=hnec7uB5Zko


