Title: Presto at Facebook: Today and Tomorrow - Biswapesh Chattopadhyay, Facebook
Publication date: 2020-09-30
Playlist: PrestoCon 2020 - Virtual
Description: 
	Presto at Facebook: Today and Tomorrow - Biswapesh Chattopadhyay, Facebook

Speakers: Biswapesh Chattopadhyay

The query engine landscape at Facebook, current and upcoming challenges in data, and how we are thinking about evolving Presto over the next few years to take it to the next level"
Captions: 
	00:00:01,599 --> 00:00:04,720
so we're going to talk about um

00:00:03,439 --> 00:00:07,440
what we are doing with presto at

00:00:04,720 --> 00:00:10,400
facebook and um

00:00:07,440 --> 00:00:11,840
i know this is the last session that

00:00:10,400 --> 00:00:13,360
people probably want to be done so i'll

00:00:11,840 --> 00:00:16,480
try to be brief

00:00:13,360 --> 00:00:17,119
um so here's our mission statement which

00:00:16,480 --> 00:00:19,760
essentially

00:00:17,119 --> 00:00:20,960
includes everything except uh solving

00:00:19,760 --> 00:00:24,720
world hunger

00:00:20,960 --> 00:00:29,359
but more realistic rates around

00:00:24,720 --> 00:00:32,640
how do we create things that are fast

00:00:29,359 --> 00:00:34,160
reliable and

00:00:32,640 --> 00:00:36,079
they are it's the best upgrade in the

00:00:34,160 --> 00:00:38,800
industry

00:00:36,079 --> 00:00:41,360
while provide while keeping the openness

00:00:38,800 --> 00:00:44,000
and the community

00:00:41,360 --> 00:00:44,960
that's what we're talking about so i'll

00:00:44,000 --> 00:00:48,160
just go through

00:00:44,960 --> 00:00:51,920
um a few themes really quickly

00:00:48,160 --> 00:00:54,719
i think there are about 10 of them and

00:00:51,920 --> 00:00:56,640
i'll we'll talk briefly about what

00:00:54,719 --> 00:00:58,960
facebook is doing

00:00:56,640 --> 00:01:00,399
for each of these and uh you know how we

00:00:58,960 --> 00:01:03,680
are hoping that take

00:01:00,399 --> 00:01:05,920
place to follow and by the way

00:01:03,680 --> 00:01:06,799
i should uh put a disclaimer that i'm

00:01:05,920 --> 00:01:08,880
not

00:01:06,799 --> 00:01:11,200
responsible for any of this stuff i'm

00:01:08,880 --> 00:01:14,159
merely representing the work of

00:01:11,200 --> 00:01:17,439
a lot of crystal engineers many of whom

00:01:14,159 --> 00:01:17,439
are in this call hopefully

00:01:18,159 --> 00:01:23,759
so um let's start with

00:01:21,520 --> 00:01:24,960
latency i don't know why my font is so

00:01:23,759 --> 00:01:27,439
bad

00:01:24,960 --> 00:01:28,880
maybe i can so i think latency is pretty

00:01:27,439 --> 00:01:30,560
important a lot of us have been talking

00:01:28,880 --> 00:01:32,400
about latency at facebook we want to

00:01:30,560 --> 00:01:33,840
take you to the next level

00:01:32,400 --> 00:01:35,439
where i think girish talked about kind

00:01:33,840 --> 00:01:36,640
of how we can do external serving using

00:01:35,439 --> 00:01:38,560
clusters if you're talking about that

00:01:36,640 --> 00:01:41,520
kind of latency we're talking about

00:01:38,560 --> 00:01:43,759
tens of milliseconds at thousands or

00:01:41,520 --> 00:01:46,240
maybe tens of thousands of qps

00:01:43,759 --> 00:01:47,840
one thing that makes it interesting uh

00:01:46,240 --> 00:01:48,479
here is also that we want to do it with

00:01:47,840 --> 00:01:51,280
the

00:01:48,479 --> 00:01:51,759
fresh data not not just kind of stale

00:01:51,280 --> 00:01:53,600
data

00:01:51,759 --> 00:01:54,960
right which is an interesting challenge

00:01:53,600 --> 00:01:56,000
like real-time data with really fast

00:01:54,960 --> 00:01:58,320
queries

00:01:56,000 --> 00:02:00,640
so what are we doing there uh there's a

00:01:58,320 --> 00:02:02,479
bunch of things

00:02:00,640 --> 00:02:03,680
we are investing in smarter partitioning

00:02:02,479 --> 00:02:05,840
and pruning this is

00:02:03,680 --> 00:02:06,719
i think this is super important because

00:02:05,840 --> 00:02:09,599
uh

00:02:06,719 --> 00:02:12,560
the good partitioning can reduce the fan

00:02:09,599 --> 00:02:14,239
out considerably and you can get like

00:02:12,560 --> 00:02:15,680
many orders of magnitude speed up if you

00:02:14,239 --> 00:02:17,599
get the partitioning right i think we

00:02:15,680 --> 00:02:20,800
know this

00:02:17,599 --> 00:02:23,120
what is smart is essentially we don't

00:02:20,800 --> 00:02:24,720
we don't have to kind of do it in a

00:02:23,120 --> 00:02:26,080
fixed way right you can do it in a more

00:02:24,720 --> 00:02:26,959
dynamic way so that's one of the things

00:02:26,080 --> 00:02:28,879
that we're

00:02:26,959 --> 00:02:30,400
talking about how can we bring to range

00:02:28,879 --> 00:02:33,440
composite range

00:02:30,400 --> 00:02:34,000
z order um this is entire collaboration

00:02:33,440 --> 00:02:35,519
with

00:02:34,000 --> 00:02:37,200
our metadata team and another storage

00:02:35,519 --> 00:02:39,440
teams

00:02:37,200 --> 00:02:40,879
faster eval this is something that i'm

00:02:39,440 --> 00:02:42,319
particularly passionate about

00:02:40,879 --> 00:02:44,480
and i think we are doing a lot of work

00:02:42,319 --> 00:02:45,599
we did a bunch of gadi optimizations we

00:02:44,480 --> 00:02:46,800
are doing a lot of the optimization of

00:02:45,599 --> 00:02:48,000
the java site

00:02:46,800 --> 00:02:49,519
uh what's quite interesting is that

00:02:48,000 --> 00:02:50,239
we're also beginning to look at negative

00:02:49,519 --> 00:02:52,080
code

00:02:50,239 --> 00:02:53,519
how can we use c plus plus and kind of

00:02:52,080 --> 00:02:56,160
llcm and all those

00:02:53,519 --> 00:02:58,640
vectorization techniques to make uh our

00:02:56,160 --> 00:03:00,640
eval really really fast really efficient

00:02:58,640 --> 00:03:01,840
um memory efficiency is really important

00:03:00,640 --> 00:03:05,360
at facebook so we are

00:03:01,840 --> 00:03:07,680
paying particular emphasis on that

00:03:05,360 --> 00:03:08,640
um caching and affinity i think electric

00:03:07,680 --> 00:03:10,720
people

00:03:08,640 --> 00:03:12,000
talked about this been talked about it

00:03:10,720 --> 00:03:13,920
um

00:03:12,000 --> 00:03:16,239
dave talked about it caching is really

00:03:13,920 --> 00:03:18,720
important in order to get caching

00:03:16,239 --> 00:03:20,720
right you're also need affinity you also

00:03:18,720 --> 00:03:22,080
need semantically aware cache you cannot

00:03:20,720 --> 00:03:23,680
just cache blocks

00:03:22,080 --> 00:03:24,879
so we are putting a bunch of work there

00:03:23,680 --> 00:03:26,239
we are working with the lecture on the

00:03:24,879 --> 00:03:29,519
java layer

00:03:26,239 --> 00:03:29,920
uh we are experimenting with different

00:03:29,519 --> 00:03:33,040
things

00:03:29,920 --> 00:03:35,519
internally as well

00:03:33,040 --> 00:03:37,360
format optimizations we talked about how

00:03:35,519 --> 00:03:40,239
we can do

00:03:37,360 --> 00:03:41,920
formats better especially when the data

00:03:40,239 --> 00:03:43,760
layout is complex

00:03:41,920 --> 00:03:45,280
we're talking about many nested repeated

00:03:43,760 --> 00:03:49,920
fields and things like that

00:03:45,280 --> 00:03:52,080
we are doing a lot of push downs etc

00:03:49,920 --> 00:03:53,760
rpcs and protocols uh we talked about

00:03:52,080 --> 00:03:55,439
like how we can leverage

00:03:53,760 --> 00:03:56,959
thrift and kind of binary protocols

00:03:55,439 --> 00:03:59,040
better uh

00:03:56,959 --> 00:04:00,319
we have a lot of json and then that's

00:03:59,040 --> 00:04:01,840
often an overhead

00:04:00,319 --> 00:04:03,840
we also have a very chatty protocol

00:04:01,840 --> 00:04:07,040
today we are looking at like how we can

00:04:03,840 --> 00:04:07,680
make the protocols more uh compact and

00:04:07,040 --> 00:04:11,680
kind of

00:04:07,680 --> 00:04:13,200
less noisy ritual metadata this is again

00:04:11,680 --> 00:04:14,319
going back to our smarter partitioning

00:04:13,200 --> 00:04:15,680
and pruning in order to do good

00:04:14,319 --> 00:04:17,440
decisions both

00:04:15,680 --> 00:04:19,680
in terms of complex queries and cost

00:04:17,440 --> 00:04:21,519
based and things like that also

00:04:19,680 --> 00:04:24,080
uh in terms of better partitioning and

00:04:21,519 --> 00:04:24,880
not spraying every equal to every worker

00:04:24,080 --> 00:04:26,560
we need

00:04:24,880 --> 00:04:28,000
racial metadata this is something that

00:04:26,560 --> 00:04:29,440
we are looking at

00:04:28,000 --> 00:04:31,120
to see how we can maybe we need a

00:04:29,440 --> 00:04:32,880
special metadata server and cluster

00:04:31,120 --> 00:04:34,240
something that can keep this cost-based

00:04:32,880 --> 00:04:36,400
metadata cache it

00:04:34,240 --> 00:04:39,040
cache them and kind of make it aware the

00:04:36,400 --> 00:04:40,400
query planning

00:04:39,040 --> 00:04:42,400
various of the io directions we are

00:04:40,400 --> 00:04:44,320
looking at materialized views looking at

00:04:42,400 --> 00:04:46,560
uh fragmenters of caching and things

00:04:44,320 --> 00:04:47,199
like that we have in fact i think xi jin

00:04:46,560 --> 00:04:48,800
has a

00:04:47,199 --> 00:04:51,280
peer out for the fragmentation crossing

00:04:48,800 --> 00:04:55,280
which is very promising

00:04:51,280 --> 00:04:57,120
um planning and scheduling um

00:04:55,280 --> 00:04:59,600
i think one of the things we talked

00:04:57,120 --> 00:05:00,880
about in the panel was the fact that

00:04:59,600 --> 00:05:03,280
the rest of planning here is kind of

00:05:00,880 --> 00:05:06,800
static how do we make it

00:05:03,280 --> 00:05:09,520
more dynamic how do we kind of situation

00:05:06,800 --> 00:05:10,800
in a more iterative way how can we make

00:05:09,520 --> 00:05:12,800
the planner

00:05:10,800 --> 00:05:14,720
aware of smart decision making as the

00:05:12,800 --> 00:05:16,160
query progresses there's a

00:05:14,720 --> 00:05:18,639
fail or difficult challenge with the

00:05:16,160 --> 00:05:20,639
current cluster architecture

00:05:18,639 --> 00:05:22,320
same with the adaptive optimizer like

00:05:20,639 --> 00:05:24,160
the current optimizer

00:05:22,320 --> 00:05:25,520
makes static decisions before the quiz

00:05:24,160 --> 00:05:27,759
starts we want to change that we want to

00:05:25,520 --> 00:05:29,759
make decisions as the query

00:05:27,759 --> 00:05:32,000
progresses and that is actually that

00:05:29,759 --> 00:05:33,520
requires some fairly fundamental changes

00:05:32,000 --> 00:05:35,680
uh to process so we are looking at that

00:05:33,520 --> 00:05:37,280
we haven't really fully started

00:05:35,680 --> 00:05:38,720
uh scoping or working on it but this is

00:05:37,280 --> 00:05:42,320
something that

00:05:38,720 --> 00:05:43,120
we hope to work on and finally a lot of

00:05:42,320 --> 00:05:44,400
people talked about

00:05:43,120 --> 00:05:46,320
coordinator high availability and

00:05:44,400 --> 00:05:48,320
scalability we have a

00:05:46,320 --> 00:05:49,600
project which uh looks at coordinate

00:05:48,320 --> 00:05:50,720
with this application

00:05:49,600 --> 00:05:52,800
and making the coordinator more

00:05:50,720 --> 00:05:54,479
efficient and scalable

00:05:52,800 --> 00:05:56,240
i think tim talked about it in one of

00:05:54,479 --> 00:05:59,280
the meetups

00:05:56,240 --> 00:05:59,280
so skip that

00:05:59,440 --> 00:06:02,960
on the efficiency side um i think you

00:06:01,280 --> 00:06:05,039
guys know facebook has

00:06:02,960 --> 00:06:06,080
been running a really really large

00:06:05,039 --> 00:06:08,240
crystal cluster

00:06:06,080 --> 00:06:10,720
or a lot of plastic clusters for a while

00:06:08,240 --> 00:06:13,520
now efficiency is super important we do

00:06:10,720 --> 00:06:16,639
spend a lot of money on cluster

00:06:13,520 --> 00:06:16,639
and spark for that matter

00:06:18,800 --> 00:06:22,400
again native code vectorization all

00:06:21,120 --> 00:06:24,800
these things are good

00:06:22,400 --> 00:06:25,520
and we are doing all of them push downs

00:06:24,800 --> 00:06:27,759
are good

00:06:25,520 --> 00:06:28,960
better partitioning physical what we

00:06:27,759 --> 00:06:30,800
call physical design right which is

00:06:28,960 --> 00:06:31,919
around like how do we adaptively layout

00:06:30,800 --> 00:06:34,479
the data

00:06:31,919 --> 00:06:36,800
in a way that makes query processing

00:06:34,479 --> 00:06:39,199
efficient and this is a interesting

00:06:36,800 --> 00:06:40,639
essentially what i call fdo right so

00:06:39,199 --> 00:06:42,000
it's a feedback driven optimization so

00:06:40,639 --> 00:06:43,840
you look at the query patterns and you

00:06:42,000 --> 00:06:45,039
see which queries

00:06:43,840 --> 00:06:46,560
what are your most frequently used

00:06:45,039 --> 00:06:48,080
columns what are the most frequently

00:06:46,560 --> 00:06:49,840
used filter columns

00:06:48,080 --> 00:06:51,680
what are the granularities and use that

00:06:49,840 --> 00:06:52,960
to lay out the data in the right way so

00:06:51,680 --> 00:06:54,479
for example you might put the most

00:06:52,960 --> 00:06:55,919
frequently used columns first when you

00:06:54,479 --> 00:06:57,199
write the column in the file

00:06:55,919 --> 00:06:58,960
so that you know you can do lead

00:06:57,199 --> 00:07:01,120
coalition much better or

00:06:58,960 --> 00:07:02,080
you can dynamically cluster the data so

00:07:01,120 --> 00:07:04,000
that your your

00:07:02,080 --> 00:07:05,120
clustering on the most frequently used

00:07:04,000 --> 00:07:07,360
columns again like

00:07:05,120 --> 00:07:09,120
one of our major challenges is here is i

00:07:07,360 --> 00:07:09,840
think how the metadata system is kind of

00:07:09,120 --> 00:07:11,039
rigid today

00:07:09,840 --> 00:07:13,759
and we're trying to figure out how to

00:07:11,039 --> 00:07:15,520
break that to have richer metadata

00:07:13,759 --> 00:07:18,000
maybe iceberg maybe extending the height

00:07:15,520 --> 00:07:18,000
metals too

00:07:18,160 --> 00:07:22,800
one aspect of efficiency hey sorry i'm

00:07:21,360 --> 00:07:26,720
jumping a lot of people are requesting

00:07:22,800 --> 00:07:26,720
that your presentation is not showing up

00:07:27,360 --> 00:07:31,840
you know the this is

00:07:32,720 --> 00:07:39,840
yep it's perfect yeah that's good

00:07:36,319 --> 00:07:41,520
okay thank you um

00:07:39,840 --> 00:07:44,319
so workload placement is another

00:07:41,520 --> 00:07:46,800
important area like

00:07:44,319 --> 00:07:48,400
currently the scheduler is not

00:07:46,800 --> 00:07:50,080
particularly smart about where it is

00:07:48,400 --> 00:07:51,680
placing certain chunks of data based on

00:07:50,080 --> 00:07:53,759
historical use of

00:07:51,680 --> 00:07:55,440
how much memory that particular split a

00:07:53,759 --> 00:07:57,039
particular task would need

00:07:55,440 --> 00:07:58,639
we have something we feel has a lot of

00:07:57,039 --> 00:08:00,639
potential to

00:07:58,639 --> 00:08:02,240
improve efficiency to make us run on

00:08:00,639 --> 00:08:04,879
fewer resources and also to boost very

00:08:02,240 --> 00:08:08,400
performance and tailored disease

00:08:04,879 --> 00:08:08,400
so we are looking at those

00:08:09,280 --> 00:08:14,639
um scalability is particularly important

00:08:12,879 --> 00:08:16,240
at facebook because we deal with extra

00:08:14,639 --> 00:08:17,840
scale data i think

00:08:16,240 --> 00:08:19,360
people have talked about like exascale

00:08:17,840 --> 00:08:21,599
has uh

00:08:19,360 --> 00:08:23,039
interesting challenges we have several

00:08:21,599 --> 00:08:25,199
large pipelines

00:08:23,039 --> 00:08:26,800
we have long memory machines we need

00:08:25,199 --> 00:08:29,360
them to run reliably cost of failure is

00:08:26,800 --> 00:08:31,039
high both in terms of

00:08:29,360 --> 00:08:33,440
delays in publishing and also in terms

00:08:31,039 --> 00:08:34,640
of wasted compute resources

00:08:33,440 --> 00:08:37,360
and finally we need to do this

00:08:34,640 --> 00:08:39,360
consistently because we don't

00:08:37,360 --> 00:08:41,200
we cannot run it in one hour today and

00:08:39,360 --> 00:08:43,519
then 10 hours the next day because the

00:08:41,200 --> 00:08:46,000
customer has certain expectations

00:08:43,519 --> 00:08:47,839
so we have a bunch of projects here we

00:08:46,000 --> 00:08:48,399
talked about the coordinator scalability

00:08:47,839 --> 00:08:50,800
and

00:08:48,399 --> 00:08:52,320
rpc improvements and dispatchers and

00:08:50,800 --> 00:08:53,519
kind of multiple coordinators that the

00:08:52,320 --> 00:08:56,959
firewall project that tim

00:08:53,519 --> 00:08:58,959
and my uncle also working on um

00:08:56,959 --> 00:09:00,080
one project that i think we have i think

00:08:58,959 --> 00:09:02,160
when in the past has talked about

00:09:00,080 --> 00:09:05,279
unlimited which is a really cool way of

00:09:02,160 --> 00:09:06,720
making plus to scale better uh by kind

00:09:05,279 --> 00:09:10,000
of

00:09:06,720 --> 00:09:12,720
materializing intermediate stages

00:09:10,000 --> 00:09:13,760
i think couple of things that are really

00:09:12,720 --> 00:09:16,080
interesting to me here

00:09:13,760 --> 00:09:17,440
one is the first one smart project which

00:09:16,080 --> 00:09:18,800
i think is very promising and it's a

00:09:17,440 --> 00:09:21,360
great example of open source

00:09:18,800 --> 00:09:23,920
collaboration of how we can use

00:09:21,360 --> 00:09:24,800
the best of breed of open source in one

00:09:23,920 --> 00:09:27,680
domain

00:09:24,800 --> 00:09:28,959
and combine that with another to make a

00:09:27,680 --> 00:09:31,920
product that really is

00:09:28,959 --> 00:09:33,360
kind of best of both worlds right now so

00:09:31,920 --> 00:09:36,880
and on the back side i'm

00:09:33,360 --> 00:09:40,480
very bullish on this project i think uh

00:09:36,880 --> 00:09:42,399
girish mentioned this this is a

00:09:40,480 --> 00:09:43,839
another project i think another couple

00:09:42,399 --> 00:09:46,080
of things is that

00:09:43,839 --> 00:09:48,000
in order to get adaptive execution or in

00:09:46,080 --> 00:09:48,959
order to get kind of recoverability at

00:09:48,000 --> 00:09:51,600
the worker green

00:09:48,959 --> 00:09:53,360
as opposed to the stage grain it is very

00:09:51,600 --> 00:09:56,240
important that we handle

00:09:53,360 --> 00:09:57,920
shuffle in a disaggregated way so we are

00:09:56,240 --> 00:09:59,519
beginning to look at how we can

00:09:57,920 --> 00:10:01,279
disaggregate our shuffle this is a very

00:09:59,519 --> 00:10:02,839
interesting uh

00:10:01,279 --> 00:10:04,720
challenge because of the way cluster

00:10:02,839 --> 00:10:06,399
works

00:10:04,720 --> 00:10:08,160
we're also looking at spelling and skew

00:10:06,399 --> 00:10:10,480
handling and some of the other stuff

00:10:08,160 --> 00:10:11,440
which which is kind of in my mind like

00:10:10,480 --> 00:10:13,440
table sticks

00:10:11,440 --> 00:10:15,120
for most of the engines we need to get

00:10:13,440 --> 00:10:17,200
those right i think most of that work

00:10:15,120 --> 00:10:21,279
has already landed

00:10:17,200 --> 00:10:21,279
but we are continuing to improve this

00:10:22,240 --> 00:10:28,000
so so reliability right

00:10:25,360 --> 00:10:28,560
and in my mind the reliability has two

00:10:28,000 --> 00:10:31,600
aspects

00:10:28,560 --> 00:10:35,279
one is that uh it's idiot proof right

00:10:31,600 --> 00:10:36,560
if if really a person like me maybe who

00:10:35,279 --> 00:10:38,079
doesn't really know how to write

00:10:36,560 --> 00:10:40,399
extremely efficient sql

00:10:38,079 --> 00:10:41,760
but wants to write a lot of people uh

00:10:40,399 --> 00:10:42,800
write source queries they should still

00:10:41,760 --> 00:10:45,519
run well

00:10:42,800 --> 00:10:47,600
and this requires the engine to adapt

00:10:45,519 --> 00:10:49,519
engine to do fine-grained scheduling

00:10:47,600 --> 00:10:52,000
uh to do check pointing and retries and

00:10:49,519 --> 00:10:54,320
dynamically adjust plans as we go

00:10:52,000 --> 00:10:56,079
uh the second one is resilience though

00:10:54,320 --> 00:10:59,279
we operate in a

00:10:56,079 --> 00:11:00,959
very very large cluster where machines

00:10:59,279 --> 00:11:02,480
go up and down all the time

00:11:00,959 --> 00:11:04,959
there are network blips there are file

00:11:02,480 --> 00:11:07,839
system slowness and so on

00:11:04,959 --> 00:11:08,480
you know dc pauses uh we need to make

00:11:07,839 --> 00:11:09,760
sure that

00:11:08,480 --> 00:11:11,360
queries don't fail like if you are

00:11:09,760 --> 00:11:12,800
running a query that is running for

00:11:11,360 --> 00:11:14,160
three hours and one of your workloads

00:11:12,800 --> 00:11:15,200
die in the middle your entire query

00:11:14,160 --> 00:11:16,800
should not hit

00:11:15,200 --> 00:11:18,560
we should be able to recover from those

00:11:16,800 --> 00:11:22,800
things uh

00:11:18,560 --> 00:11:22,800
the third one is isolation i think uh

00:11:23,519 --> 00:11:27,040
i'll leave our people young and cool

00:11:25,519 --> 00:11:28,480
they mentioned this isolation is really

00:11:27,040 --> 00:11:30,320
important when you have a

00:11:28,480 --> 00:11:32,160
large multi-tenant clusters with lots of

00:11:30,320 --> 00:11:33,360
customers trying to run queries on the

00:11:32,160 --> 00:11:35,040
same cluster

00:11:33,360 --> 00:11:37,440
and right now we don't do that greater

00:11:35,040 --> 00:11:39,680
job at isolation like one workers

00:11:37,440 --> 00:11:42,720
uh one bad query can essentially hang a

00:11:39,680 --> 00:11:45,760
cluster or overloaded cluster or one

00:11:42,720 --> 00:11:47,200
kind of bad user can affect other users

00:11:45,760 --> 00:11:49,200
so we are looking a lot into how we can

00:11:47,200 --> 00:11:52,000
make things better through finding

00:11:49,200 --> 00:11:54,079
scheduling accounting and things like

00:11:52,000 --> 00:11:54,079
that

00:11:55,440 --> 00:12:00,240
so expressibility this is something that

00:11:57,200 --> 00:12:02,000
i think we talked about in the panel

00:12:00,240 --> 00:12:03,680
this is mostly about improving the

00:12:02,000 --> 00:12:05,040
developer efficiency of productivity

00:12:03,680 --> 00:12:09,519
like how do we

00:12:05,040 --> 00:12:11,600
get richer sql beyond the built-ins

00:12:09,519 --> 00:12:13,440
uh through udf servers wrong wrong i

00:12:11,600 --> 00:12:15,839
think presented udf servers and

00:12:13,440 --> 00:12:18,240
i'm particularly excited about that

00:12:15,839 --> 00:12:20,720
because it opens up a lot of avenues

00:12:18,240 --> 00:12:22,639
uh for us to kind of run things that

00:12:20,720 --> 00:12:25,600
plastic does cannot run today but cannot

00:12:22,639 --> 00:12:26,480
run in a multi-tenant environment

00:12:25,600 --> 00:12:29,440
are things written in different

00:12:26,480 --> 00:12:29,440
languages for example

00:12:29,680 --> 00:12:33,600
i also mentioned that running over

00:12:32,079 --> 00:12:34,720
complex structured data is becoming

00:12:33,600 --> 00:12:36,240
increasingly important

00:12:34,720 --> 00:12:37,839
as the business evolves and things

00:12:36,240 --> 00:12:39,120
become more complicated on the data

00:12:37,839 --> 00:12:40,959
modeling side

00:12:39,120 --> 00:12:42,720
scalars is not good enough anymore we

00:12:40,959 --> 00:12:44,000
need to run efficiently over steps and

00:12:42,720 --> 00:12:45,920
maps and

00:12:44,000 --> 00:12:47,279
arrays and maps of arrays and arrays of

00:12:45,920 --> 00:12:48,720
maps and things like that

00:12:47,279 --> 00:12:50,720
we have done some good work here as part

00:12:48,720 --> 00:12:51,680
of the rda project we continue to invest

00:12:50,720 --> 00:12:53,200
in this

00:12:51,680 --> 00:12:54,639
and finally we're looking at a bunch of

00:12:53,200 --> 00:12:56,000
extensions these are fairly early like

00:12:54,639 --> 00:13:00,079
the graph one is

00:12:56,000 --> 00:13:01,040
something that we are hacking and uh

00:13:00,079 --> 00:13:03,120
some of the results have been

00:13:01,040 --> 00:13:06,560
interesting um we're looking at

00:13:03,120 --> 00:13:08,880
streaming i think girish mentioned that

00:13:06,560 --> 00:13:10,399
how do we essentially abstract out the

00:13:08,880 --> 00:13:11,600
language to handle some of the streaming

00:13:10,399 --> 00:13:14,560
concepts

00:13:11,600 --> 00:13:16,079
especially around windowed aggregation

00:13:14,560 --> 00:13:18,320
the others are kind of

00:13:16,079 --> 00:13:19,279
uh fairly early in the thought process

00:13:18,320 --> 00:13:22,399
so i don't want to

00:13:19,279 --> 00:13:24,880
spend too much time on those but we want

00:13:22,399 --> 00:13:24,880
to get there

00:13:25,760 --> 00:13:30,320
so freshness is another angle where we

00:13:28,160 --> 00:13:32,800
are actually investing a fair amount of

00:13:30,320 --> 00:13:34,000
resources because we want presto to be

00:13:32,800 --> 00:13:36,079
able to query really fresh

00:13:34,000 --> 00:13:37,920
data in other words like we have these

00:13:36,079 --> 00:13:41,760
logs that are landing like

00:13:37,920 --> 00:13:44,000
every second or every minute and uh

00:13:41,760 --> 00:13:45,760
now we have enabled near real time

00:13:44,000 --> 00:13:46,399
training so these lots can be queried as

00:13:45,760 --> 00:13:47,680
they land

00:13:46,399 --> 00:13:50,000
as opposed to waiting for the full

00:13:47,680 --> 00:13:51,600
partition to land and that opens up some

00:13:50,000 --> 00:13:53,920
really interesting use cases

00:13:51,600 --> 00:13:56,079
around real-time analytics uh it does

00:13:53,920 --> 00:13:57,600
also open up some challenges because

00:13:56,079 --> 00:13:59,279
when people think real-time analytics

00:13:57,600 --> 00:14:01,199
they also mean fast queries not just

00:13:59,279 --> 00:14:04,240
fast data

00:14:01,199 --> 00:14:05,600
so we have to do um some interesting

00:14:04,240 --> 00:14:07,440
optimizations

00:14:05,600 --> 00:14:09,279
uh around com like compactions

00:14:07,440 --> 00:14:10,480
materialize views ritual metadata and

00:14:09,279 --> 00:14:13,760
things like that to make

00:14:10,480 --> 00:14:17,600
these queries work well bunch of these

00:14:13,760 --> 00:14:19,279
things have started so with materialized

00:14:17,600 --> 00:14:21,040
views and fragmentation crashing and

00:14:19,279 --> 00:14:24,480
compactions and things like that uh

00:14:21,040 --> 00:14:28,000
which hopefully will be

00:14:24,480 --> 00:14:28,000
releasing most of these two others and

00:14:28,880 --> 00:14:32,560
they are showing pretty promising early

00:14:30,240 --> 00:14:32,560
results

00:14:33,360 --> 00:14:37,199
um on the security and privacy side we

00:14:36,320 --> 00:14:40,560
continue to

00:14:37,199 --> 00:14:41,920
invest in kind of customers apis like

00:14:40,560 --> 00:14:43,600
to implement complex things like

00:14:41,920 --> 00:14:45,199
differential privacy for example which

00:14:43,600 --> 00:14:48,240
is a

00:14:45,199 --> 00:14:49,519
kind of hard to get right uh end-to-end

00:14:48,240 --> 00:14:50,720
encryption is another thing that is kind

00:14:49,519 --> 00:14:52,399
of tricky to get right

00:14:50,720 --> 00:14:55,040
in prestos case it's probably slightly

00:14:52,399 --> 00:14:58,800
easier because we

00:14:55,040 --> 00:15:00,639
control all access through an api

00:14:58,800 --> 00:15:02,320
this is an area that we are also looking

00:15:00,639 --> 00:15:04,800
at data address using

00:15:02,320 --> 00:15:04,800
encryption

00:15:06,000 --> 00:15:10,480
and finally how do we provide a

00:15:09,360 --> 00:15:12,160
consistent

00:15:10,480 --> 00:15:14,880
interoperable user experience i think we

00:15:12,160 --> 00:15:17,600
talked about shared udfs we talked about

00:15:14,880 --> 00:15:19,040
restaurant spark we talked about kind of

00:15:17,600 --> 00:15:22,480
having a common sequel

00:15:19,040 --> 00:15:23,519
with extensions for streaming graph and

00:15:22,480 --> 00:15:25,839
batch and things like that

00:15:23,519 --> 00:15:28,160
transforms uh one of the things that we

00:15:25,839 --> 00:15:30,480
are doing is this native event that

00:15:28,160 --> 00:15:31,519
we are investing in there is very early

00:15:30,480 --> 00:15:32,959
stage right now but

00:15:31,519 --> 00:15:34,880
we hope to make it a shared developer

00:15:32,959 --> 00:15:37,839
crossover batch and interactive and

00:15:34,880 --> 00:15:38,720
streaming and all the other use cases

00:15:37,839 --> 00:15:40,639
which

00:15:38,720 --> 00:15:42,240
will allow us to kind of accelerate

00:15:40,639 --> 00:15:45,279
development on it because everybody will

00:15:42,240 --> 00:15:45,279
be working on the same code

00:15:46,399 --> 00:15:49,680
and finally i think i want to leave with

00:15:48,880 --> 00:15:51,920
a

00:15:49,680 --> 00:15:54,399
comment and community i think we said

00:15:51,920 --> 00:15:56,480
this in the panel that

00:15:54,399 --> 00:15:59,519
sum is kind of greater than the hole is

00:15:56,480 --> 00:15:59,519
greater than the sum of parts

00:15:59,759 --> 00:16:03,839
with uber and ahana and uh lecture and a

00:16:02,560 --> 00:16:05,199
bunch of like we have done the

00:16:03,839 --> 00:16:06,880
caching work in conjunction with the

00:16:05,199 --> 00:16:10,000
last year uber

00:16:06,880 --> 00:16:11,199
as uh investigating restaurant spark we

00:16:10,000 --> 00:16:12,720
are investigating some of these

00:16:11,199 --> 00:16:14,959
connected things that uber has done to

00:16:12,720 --> 00:16:18,240
make things really fast with pinot

00:16:14,959 --> 00:16:19,120
now there are tons of examples we are

00:16:18,240 --> 00:16:21,360
early

00:16:19,120 --> 00:16:22,959
starting collaborations already there

00:16:21,360 --> 00:16:23,920
are some really really good outcomes for

00:16:22,959 --> 00:16:26,079
everybody

00:16:23,920 --> 00:16:28,000
so again like doing more knowledge

00:16:26,079 --> 00:16:32,399
sharing more joint planning

00:16:28,000 --> 00:16:34,000
more idea exchange around projects is

00:16:32,399 --> 00:16:35,600
really important so i want to emphasize

00:16:34,000 --> 00:16:36,720
that and say hey let's

00:16:35,600 --> 00:16:38,959
if you have an idea if you're going to

00:16:36,720 --> 00:16:41,199
start on the project if you feel like

00:16:38,959 --> 00:16:42,959
some of these things are useful to you

00:16:41,199 --> 00:16:44,639
come and talk to us

00:16:42,959 --> 00:16:46,000
we are in the open source we are in the

00:16:44,639 --> 00:16:50,079
community

00:16:46,000 --> 00:16:53,279
we should make it work together

00:16:50,079 --> 00:16:57,440
and that's it

00:16:53,279 --> 00:17:00,480
thank you hey thank you bishwa

00:16:57,440 --> 00:17:04,160
i only see one question right now which

00:17:00,480 --> 00:17:05,679
is from adi how do you intend to

00:17:04,160 --> 00:17:08,959
integrate the real time

00:17:05,679 --> 00:17:10,799
ingestion oh well i think

00:17:08,959 --> 00:17:13,039
right now what we are doing is really

00:17:10,799 --> 00:17:15,919
producing arc files in real time

00:17:13,039 --> 00:17:17,520
and have some metadata enhancements to

00:17:15,919 --> 00:17:18,799
enable us to know which partitions are

00:17:17,520 --> 00:17:22,000
open

00:17:18,799 --> 00:17:22,720
so we can query those query that data as

00:17:22,000 --> 00:17:25,199
it plans

00:17:22,720 --> 00:17:26,959
as opposed to after the partition closes

00:17:25,199 --> 00:17:28,400
uh we do want to do more

00:17:26,959 --> 00:17:31,200
deeper real-time integration through

00:17:28,400 --> 00:17:33,840
things like push caching and

00:17:31,200 --> 00:17:34,400
notifications or when you get arrived

00:17:33,840 --> 00:17:36,640
but

00:17:34,400 --> 00:17:41,520
we haven't kind of explained that yet so

00:17:36,640 --> 00:17:41,520

YouTube URL: https://www.youtube.com/watch?v=xnWLkyCEQ9o


