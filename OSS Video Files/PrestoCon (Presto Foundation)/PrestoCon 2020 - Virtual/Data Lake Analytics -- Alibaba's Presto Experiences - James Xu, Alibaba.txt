Title: Data Lake Analytics -- Alibaba's Presto Experiences - James Xu, Alibaba
Publication date: 2020-09-30
Playlist: PrestoCon 2020 - Virtual
Description: 
	Data Lake Analytics -- Alibaba's Presto Experiences - James Xu, Alibaba

Speakers: James Xu

Data Lake Analytics(DLA) is a large scale serverless data federation service on Alibaba Cloud. One of its most popular serverless SQL engine is based on the well-customized PrestoDB. DLA integrates with mainstream datasources, and provides easy-to-use mysql protocol to let user interact with. It also added some key features like multi-tenancy, and one-click data warehouse. In this talk, we will introduce the system architecture of DLA SQL engine, as well as some best practice scenarios. Some key features we developed and our future plan will also be covered in this talk.
Captions: 
	00:00:01,280 --> 00:00:07,040
my name is james hu today my topic

00:00:04,080 --> 00:00:09,519
is data lake analytics alibaba's presto

00:00:07,040 --> 00:00:12,400
experience in cloud

00:00:09,519 --> 00:00:14,000
first some information about myself i'm

00:00:12,400 --> 00:00:17,680
a press developer at

00:00:14,000 --> 00:00:19,600
alibaba cloud uh i have been very

00:00:17,680 --> 00:00:20,560
interested in big data programming for

00:00:19,600 --> 00:00:24,160
many years

00:00:20,560 --> 00:00:26,480
have participated in projects like

00:00:24,160 --> 00:00:28,720
apache beam i have storm and became

00:00:26,480 --> 00:00:30,480
commuters of these two projects

00:00:28,720 --> 00:00:33,840
and i have translated an english book

00:00:30,480 --> 00:00:36,000
called color programming into chinese

00:00:33,840 --> 00:00:38,480
the name of our product is italic

00:00:36,000 --> 00:00:42,960
analytics

00:00:38,480 --> 00:00:46,320
here is its business architecture

00:00:42,960 --> 00:00:48,960
on alibaba cloud users data analytic

00:00:46,320 --> 00:00:52,239
data is mainly stored in oss

00:00:48,960 --> 00:00:54,800
due to its scalability and

00:00:52,239 --> 00:00:56,559
cost effective charging model the data

00:00:54,800 --> 00:00:58,480
invoices might come from many sources

00:00:56,559 --> 00:01:01,840
for example archived

00:00:58,480 --> 00:01:06,000
transactional data logs of user

00:01:01,840 --> 00:01:08,799
application or from users current

00:01:06,000 --> 00:01:10,479
to the warehouse since it's very

00:01:08,799 --> 00:01:13,280
scalable and

00:01:10,479 --> 00:01:15,200
about the data lake story engine layer

00:01:13,280 --> 00:01:17,920
we have the data

00:01:15,200 --> 00:01:18,799
computer engine layer which shows dras

00:01:17,920 --> 00:01:22,080
product

00:01:18,799 --> 00:01:23,280
family first we have one click data lake

00:01:22,080 --> 00:01:26,880
solution

00:01:23,280 --> 00:01:30,079
to sync users db data

00:01:26,880 --> 00:01:31,680
into data lake and for streaming data we

00:01:30,079 --> 00:01:34,799
have spark streaming

00:01:31,680 --> 00:01:36,079
to ingest it and for metadata we have

00:01:34,799 --> 00:01:38,640
metadata management

00:01:36,079 --> 00:01:39,119
and the metadata out of this gallery to

00:01:38,640 --> 00:01:42,720
make

00:01:39,119 --> 00:01:45,439
it very easy and if user needs to

00:01:42,720 --> 00:01:46,079
do some etl or things like machine

00:01:45,439 --> 00:01:48,720
learning

00:01:46,079 --> 00:01:51,119
we have service spark and if you use a

00:01:48,720 --> 00:01:54,960
link to do something like ad hoc query

00:01:51,119 --> 00:01:58,320
data exploration or lightweight etl

00:01:54,960 --> 00:02:01,200
we have service sql service sql

00:01:58,320 --> 00:02:02,399
is based on presto and it is the

00:02:01,200 --> 00:02:06,240
protagonist

00:02:02,399 --> 00:02:08,959
of today's topic let's first talk about

00:02:06,240 --> 00:02:09,679
why we choose the preso as the basic

00:02:08,959 --> 00:02:13,200
engine of the

00:02:09,679 --> 00:02:16,319
la sequel there are four reasons i think

00:02:13,200 --> 00:02:17,680
first it is fully memory full memory

00:02:16,319 --> 00:02:20,720
processing engine

00:02:17,680 --> 00:02:23,920
so it is pleasing fast avoid any

00:02:20,720 --> 00:02:26,879
unnecessary io overhead so it is very

00:02:23,920 --> 00:02:28,640
suitable for things like alloquary data

00:02:26,879 --> 00:02:33,680
exploration

00:02:28,640 --> 00:02:36,239
second it supports four sql semantics

00:02:33,680 --> 00:02:36,959
so you do not need to worry that if

00:02:36,239 --> 00:02:41,360
there is

00:02:36,959 --> 00:02:44,800
any sql syntax that it is not supported

00:02:41,360 --> 00:02:47,440
and third is it has a very tangible

00:02:44,800 --> 00:02:50,560
architecture so users can add its own

00:02:47,440 --> 00:02:52,000
connectors to connect to users homemade

00:02:50,560 --> 00:02:55,360
data sources

00:02:52,000 --> 00:02:58,319
if necessary and in the last

00:02:55,360 --> 00:02:59,040
classroom has a very great community it

00:02:58,319 --> 00:03:02,000
is now

00:02:59,040 --> 00:03:03,040
hosted under the linux foundation and

00:03:02,000 --> 00:03:07,200
many

00:03:03,040 --> 00:03:11,200
big companies like facebook alibaba

00:03:07,200 --> 00:03:16,000
twitter amazon jingdong hotel

00:03:11,200 --> 00:03:19,599
all using press to do big data analysis

00:03:16,000 --> 00:03:23,840
and in dla we use presto like this

00:03:19,599 --> 00:03:27,280
this is our full architecture of dla sql

00:03:23,840 --> 00:03:29,360
there are three parts the at the bottom

00:03:27,280 --> 00:03:32,400
is the plastic clusters

00:03:29,360 --> 00:03:34,239
in each alibaba cloud region we have two

00:03:32,400 --> 00:03:36,959
kinds of clusters

00:03:34,239 --> 00:03:38,319
the first one is the default cluster in

00:03:36,959 --> 00:03:41,120
default cluster

00:03:38,319 --> 00:03:42,400
users are charged by the scan of this

00:03:41,120 --> 00:03:46,480
size

00:03:42,400 --> 00:03:49,599
and other clusters we we name it

00:03:46,480 --> 00:03:52,799
cu cluster which is purchased by

00:03:49,599 --> 00:03:55,840
users and a china user by the cpu course

00:03:52,799 --> 00:03:58,400
user required and at the

00:03:55,840 --> 00:03:59,519
top of the architecture is the front

00:03:58,400 --> 00:04:02,959
node

00:03:59,519 --> 00:04:06,159
front node have implemented my sql

00:04:02,959 --> 00:04:08,640
protocol to let user interact with it

00:04:06,159 --> 00:04:09,920
will translate the user's my sql style

00:04:08,640 --> 00:04:13,439
sql statement

00:04:09,920 --> 00:04:16,560
into presto style sql statement and

00:04:13,439 --> 00:04:19,680
it also do query routing to route the

00:04:16,560 --> 00:04:22,320
user's query into the correct cluster

00:04:19,680 --> 00:04:24,160
and on the left side is the unified

00:04:22,320 --> 00:04:26,960
metadata service

00:04:24,160 --> 00:04:29,040
we have it stores all the metadata about

00:04:26,960 --> 00:04:32,800
for example data sources

00:04:29,040 --> 00:04:34,560
schema tables columns so our cluster

00:04:32,800 --> 00:04:36,720
does not let you

00:04:34,560 --> 00:04:39,520
talk directly to the underlying data

00:04:36,720 --> 00:04:39,520
source for matter

00:04:40,720 --> 00:04:45,120
and to host presto as a service there

00:04:43,600 --> 00:04:47,759
are many challenges

00:04:45,120 --> 00:04:48,960
today i will talk three of them money

00:04:47,759 --> 00:04:52,400
coordinators

00:04:48,960 --> 00:04:55,840
multi-tenancy and the coordinate

00:04:52,400 --> 00:04:57,120
connector optimizations we have done

00:04:55,840 --> 00:05:00,479
first

00:04:57,120 --> 00:05:04,560
the first one mata collinators

00:05:00,479 --> 00:05:07,440
so what's wrong with single coordinator

00:05:04,560 --> 00:05:07,759
i think there are three reasons first if

00:05:07,440 --> 00:05:10,240
you

00:05:07,759 --> 00:05:11,360
only have a single coordinator its

00:05:10,240 --> 00:05:14,960
loader will be

00:05:11,360 --> 00:05:16,720
very high because the responsibility our

00:05:14,960 --> 00:05:19,680
coordinator

00:05:16,720 --> 00:05:21,759
is too much but it has medical

00:05:19,680 --> 00:05:24,960
responsibilities for example

00:05:21,759 --> 00:05:28,000
query passing task monitoring

00:05:24,960 --> 00:05:28,639
so it's load they have high correlation

00:05:28,000 --> 00:05:31,919
with

00:05:28,639 --> 00:05:34,960
quality count and worker count

00:05:31,919 --> 00:05:37,039
and second if you have only

00:05:34,960 --> 00:05:38,000
single coordinator it is the single

00:05:37,039 --> 00:05:40,560
point of failure

00:05:38,000 --> 00:05:41,600
in your architecture once your single

00:05:40,560 --> 00:05:44,400
coordinator is down

00:05:41,600 --> 00:05:44,720
your foot class is done it's unusable

00:05:44,400 --> 00:05:48,479
and

00:05:44,720 --> 00:05:51,360
third if you only have a single

00:05:48,479 --> 00:05:52,080
coordinator there it is impossible to

00:05:51,360 --> 00:05:54,240
degrade

00:05:52,080 --> 00:05:56,240
upgrade which means when you need to

00:05:54,240 --> 00:05:59,680
upgrade your cluster

00:05:56,240 --> 00:06:02,560
your full service is done

00:05:59,680 --> 00:06:04,080
so it is unacceptable for an enterprise

00:06:02,560 --> 00:06:06,720
presto service

00:06:04,080 --> 00:06:08,160
so it is a method to implement body

00:06:06,720 --> 00:06:11,680
coordinators

00:06:08,160 --> 00:06:14,880
as a service

00:06:11,680 --> 00:06:17,280
but it is not that easy to implement it

00:06:14,880 --> 00:06:18,160
there are many challenges for example if

00:06:17,280 --> 00:06:21,520
you have

00:06:18,160 --> 00:06:23,520
many coordinators which coordinator

00:06:21,520 --> 00:06:25,199
should the user connect to

00:06:23,520 --> 00:06:26,800
which coordinator should the worker

00:06:25,199 --> 00:06:29,520
report to

00:06:26,800 --> 00:06:30,160
and also there are some global decisions

00:06:29,520 --> 00:06:33,360
to make

00:06:30,160 --> 00:06:36,479
in a presto cluster for example

00:06:33,360 --> 00:06:40,319
when your cluster is overwhelmed

00:06:36,479 --> 00:06:43,440
to make sure the cluster can proceed

00:06:40,319 --> 00:06:45,280
continuously with it to use oil killer

00:06:43,440 --> 00:06:46,880
to kill some other query

00:06:45,280 --> 00:06:49,599
who can make the decision if there are

00:06:46,880 --> 00:06:52,960
many coordinators

00:06:49,599 --> 00:06:55,039
so with these challenges in mind we have

00:06:52,960 --> 00:06:57,280
designed the following architecture

00:06:55,039 --> 00:06:59,599
we have introduced the zookeeper into

00:06:57,280 --> 00:07:03,039
the whole arc

00:06:59,599 --> 00:07:06,880
zookeeper will help us to do the

00:07:03,039 --> 00:07:09,680
call the nature leader election

00:07:06,880 --> 00:07:10,479
it will elect one of the coordinator to

00:07:09,680 --> 00:07:14,000
be the leader

00:07:10,479 --> 00:07:16,240
and the rest will become the follower

00:07:14,000 --> 00:07:17,360
and for the leader for the nature it

00:07:16,240 --> 00:07:20,960
behaves just

00:07:17,360 --> 00:07:24,000
like a community coordinator it

00:07:20,960 --> 00:07:27,919
first starts a discovery service

00:07:24,000 --> 00:07:30,880
in it and all workers will report to

00:07:27,919 --> 00:07:31,680
leadercard coordinator and the leader

00:07:30,880 --> 00:07:34,880
coordinator

00:07:31,680 --> 00:07:36,800
also responsible for global information

00:07:34,880 --> 00:07:39,120
gathering and decision making for

00:07:36,800 --> 00:07:41,440
example worker state monitoring

00:07:39,120 --> 00:07:42,400
and a bigger corridor killing and they

00:07:41,440 --> 00:07:45,360
also

00:07:42,400 --> 00:07:46,160
execute and monitoring the queries

00:07:45,360 --> 00:07:49,840
assigned

00:07:46,160 --> 00:07:52,479
to it and for the forward

00:07:49,840 --> 00:07:53,840
coordinator its responsibility is much

00:07:52,479 --> 00:07:56,160
lighter weight

00:07:53,840 --> 00:07:59,440
it fetches worker list from the leader

00:07:56,160 --> 00:08:03,280
and execute queries nothing more

00:07:59,440 --> 00:08:07,280
so it's very lightweight and about the

00:08:03,280 --> 00:08:10,800
coordinators there are our front node

00:08:07,280 --> 00:08:14,000
our user only connected to front load

00:08:10,800 --> 00:08:17,280
so it is fully transparent to users that

00:08:14,000 --> 00:08:19,919
we have one coordinator of multiple

00:08:17,280 --> 00:08:22,960
coordinator

00:08:19,919 --> 00:08:27,120
and with this architecture

00:08:22,960 --> 00:08:29,120
when we let you when the cluster grows

00:08:27,120 --> 00:08:30,720
we have more queries or we have more

00:08:29,120 --> 00:08:34,640
workers we can add

00:08:30,720 --> 00:08:37,680
more coordinators to distribute the load

00:08:34,640 --> 00:08:40,800
so it is extensible

00:08:37,680 --> 00:08:42,159
it is scalable and with this

00:08:40,800 --> 00:08:44,800
architecture in ma

00:08:42,159 --> 00:08:46,160
in place it is very easy to do grease

00:08:44,800 --> 00:08:49,040
upgrade

00:08:46,160 --> 00:08:55,120
we have a dedicated node we call it

00:08:49,040 --> 00:08:57,760
admin node to upgrade it

00:08:55,120 --> 00:08:59,519
uh the admin node will first send a

00:08:57,760 --> 00:09:01,200
shutting down command to the folder

00:08:59,519 --> 00:09:04,480
coordinator

00:09:01,200 --> 00:09:05,760
the follower coordinator will not shut

00:09:04,480 --> 00:09:07,839
down immediately

00:09:05,760 --> 00:09:11,760
it will wait all the quarries to

00:09:07,839 --> 00:09:11,760
complete before rear shut down

00:09:13,200 --> 00:09:19,360
and when all the queries is complete the

00:09:17,279 --> 00:09:20,320
photo coordinator will go offline for

00:09:19,360 --> 00:09:23,680
real upgrade

00:09:20,320 --> 00:09:24,240
and then now the the cluster looks like

00:09:23,680 --> 00:09:26,399
this

00:09:24,240 --> 00:09:27,839
there's one coordinator and all the

00:09:26,399 --> 00:09:30,720
workers it is still

00:09:27,839 --> 00:09:33,839
a working cluster and the users can

00:09:30,720 --> 00:09:36,160
still issue queries

00:09:33,839 --> 00:09:37,040
and then the photo coordinator will go

00:09:36,160 --> 00:09:39,920
online again

00:09:37,040 --> 00:09:40,720
and now we have multiple coordinates

00:09:39,920 --> 00:09:44,080
multiple

00:09:40,720 --> 00:09:45,600
coordinators again and then

00:09:44,080 --> 00:09:48,480
what do we know that we are doing the

00:09:45,600 --> 00:09:51,680
similar thing to the leader collinator

00:09:48,480 --> 00:09:53,040
just like what have been done to the

00:09:51,680 --> 00:09:55,360
follower of the nature

00:09:53,040 --> 00:09:56,320
one difference is that once the leader

00:09:55,360 --> 00:10:00,160
coordinator is

00:09:56,320 --> 00:10:03,360
down the forum will take over

00:10:00,160 --> 00:10:06,240
but the queries will not be effected

00:10:03,360 --> 00:10:06,240
since it is just

00:10:06,720 --> 00:10:10,640
the leadership is changed by the queries

00:10:09,200 --> 00:10:15,839
will not be affected

00:10:10,640 --> 00:10:15,839
it's not in the control sequence

00:10:16,839 --> 00:10:21,040
and the follower content becomes the

00:10:19,120 --> 00:10:23,120
leader coordinator

00:10:21,040 --> 00:10:26,320
and then the leader coordinator is up

00:10:23,120 --> 00:10:26,320
again and became the follower

00:10:28,000 --> 00:10:32,160
and then let me know that we are doing

00:10:30,240 --> 00:10:34,240
the similar thing to the workers

00:10:32,160 --> 00:10:35,680
but one difference is that because there

00:10:34,240 --> 00:10:38,640
are too many workers

00:10:35,680 --> 00:10:39,760
let me know that we are not upgrading

00:10:38,640 --> 00:10:43,519
them one by one

00:10:39,760 --> 00:10:47,360
instead we will upgrade them one batch

00:10:43,519 --> 00:10:50,320
one one batch by one batch and the

00:10:47,360 --> 00:10:50,959
one consideration is that we need to

00:10:50,320 --> 00:10:53,519
reserve

00:10:50,959 --> 00:10:55,440
enough workers online to make sure that

00:10:53,519 --> 00:10:57,040
the user's query have enough resources

00:10:55,440 --> 00:11:00,000
to execute

00:10:57,040 --> 00:11:01,839
and just like how we upgraded

00:11:00,000 --> 00:11:04,720
coordinator

00:11:01,839 --> 00:11:05,279
when we upgraded the world the worker

00:11:04,720 --> 00:11:08,399
the

00:11:05,279 --> 00:11:11,200
worker will wait for all the tasks

00:11:08,399 --> 00:11:13,519
to complete before real shutdown so make

00:11:11,200 --> 00:11:16,959
sure no quarries will be

00:11:13,519 --> 00:11:20,000
affected so one

00:11:16,959 --> 00:11:21,200
batch by one badge all the workers will

00:11:20,000 --> 00:11:23,200
be upgraded

00:11:21,200 --> 00:11:25,680
and the no queries will be affected

00:11:23,200 --> 00:11:25,680
first of all

00:11:26,839 --> 00:11:29,839
and

00:11:30,800 --> 00:11:34,959
the next one i will talk about is

00:11:32,480 --> 00:11:36,880
multi-tenancy

00:11:34,959 --> 00:11:39,120
why we need to make tenancy if you only

00:11:36,880 --> 00:11:41,839
use presto in your own company

00:11:39,120 --> 00:11:42,720
it is not so important to implement

00:11:41,839 --> 00:11:46,800
multi-tenancy

00:11:42,720 --> 00:11:48,880
but as a web as a cloud service

00:11:46,800 --> 00:11:51,279
there are many tenants who will use our

00:11:48,880 --> 00:11:55,200
service in one

00:11:51,279 --> 00:11:57,760
classroom so we need to make sure that

00:11:55,200 --> 00:11:58,880
one talent can't operate another tenants

00:11:57,760 --> 00:12:01,839
data source

00:11:58,880 --> 00:12:02,399
and the one talent quality shouldn't

00:12:01,839 --> 00:12:05,440
affect

00:12:02,399 --> 00:12:06,720
another tenant's query performance so

00:12:05,440 --> 00:12:08,959
there are meta data

00:12:06,720 --> 00:12:10,880
mastering and computer monitoring will

00:12:08,959 --> 00:12:14,079
let you achieve

00:12:10,880 --> 00:12:17,440
first metadata money tendency here is

00:12:14,079 --> 00:12:20,720
the architecture of community

00:12:17,440 --> 00:12:23,360
presto and the diy's crystal

00:12:20,720 --> 00:12:24,959
architecture one of the big difference

00:12:23,360 --> 00:12:26,720
between

00:12:24,959 --> 00:12:28,399
these two architecture is a unified

00:12:26,720 --> 00:12:34,079
metadata service

00:12:28,399 --> 00:12:34,079
in community presto all the connectors

00:12:34,560 --> 00:12:39,040
retrieve metadata information from

00:12:37,360 --> 00:12:42,320
clusters

00:12:39,040 --> 00:12:44,000
catalog property files so when user led

00:12:42,320 --> 00:12:47,200
to add new data sources

00:12:44,000 --> 00:12:52,079
use a link to add new catalog files

00:12:47,200 --> 00:12:55,600
and and restart the cluster

00:12:52,079 --> 00:12:56,880
uh but in presto but in dies presser we

00:12:55,600 --> 00:13:00,160
have

00:12:56,880 --> 00:13:02,880
optimized this to store all the

00:13:00,160 --> 00:13:03,760
catalogs information in our unified meta

00:13:02,880 --> 00:13:06,240
service

00:13:03,760 --> 00:13:07,680
so when user lets you add a new data

00:13:06,240 --> 00:13:09,680
source he doesn't need to do

00:13:07,680 --> 00:13:11,200
any cluster rebooting it's just the

00:13:09,680 --> 00:13:14,639
issue and

00:13:11,200 --> 00:13:14,639
a ddr command like this

00:13:14,880 --> 00:13:18,240
and with the help of the unified meta

00:13:17,440 --> 00:13:20,720
service

00:13:18,240 --> 00:13:22,000
it is very easy to do global access

00:13:20,720 --> 00:13:26,240
control so we

00:13:22,000 --> 00:13:30,160
have provided a mysql style

00:13:26,240 --> 00:13:32,959
grant revoke access control mechanism

00:13:30,160 --> 00:13:34,160
this is metadata meta tendency oh and

00:13:32,959 --> 00:13:37,440
also

00:13:34,160 --> 00:13:41,760
the unified meta service has built team

00:13:37,440 --> 00:13:44,800
multi-tenant support one talent

00:13:41,760 --> 00:13:48,560
can't operate other tenants data source

00:13:44,800 --> 00:13:51,680
and also a user within one tenant

00:13:48,560 --> 00:13:55,440
can only access the metadata of its

00:13:51,680 --> 00:13:58,399
its own it has access to

00:13:55,440 --> 00:13:58,800
this is metadata multi-tenancy and the

00:13:58,399 --> 00:14:02,160
second

00:13:58,800 --> 00:14:04,320
is computer multi-tenancy and

00:14:02,160 --> 00:14:06,320
the community presto has basic support

00:14:04,320 --> 00:14:08,959
for resource isolation

00:14:06,320 --> 00:14:11,040
which is called resource group it claims

00:14:08,959 --> 00:14:14,399
that it can

00:14:11,040 --> 00:14:17,920
restrict the cpu

00:14:14,399 --> 00:14:22,079
memory usage of each resource group

00:14:17,920 --> 00:14:26,000
but it has shortcomings if

00:14:22,079 --> 00:14:27,040
there are many tenants using the same

00:14:26,000 --> 00:14:30,240
presto

00:14:27,040 --> 00:14:31,839
and one of the tenants have submitted a

00:14:30,240 --> 00:14:35,440
very big query

00:14:31,839 --> 00:14:37,120
into the classroom and the webquery will

00:14:35,440 --> 00:14:39,519
generate a lot of splits

00:14:37,120 --> 00:14:42,079
and this query will use up all the

00:14:39,519 --> 00:14:44,639
resources of the classroom

00:14:42,079 --> 00:14:46,079
and other all other children's quarry

00:14:44,639 --> 00:14:49,519
will be affected

00:14:46,079 --> 00:14:52,800
and no punishment will be put

00:14:49,519 --> 00:14:54,880
to this talent the only punishment is

00:14:52,800 --> 00:14:56,000
new quarries of this talent will be

00:14:54,880 --> 00:14:59,040
blocked but

00:14:56,000 --> 00:15:03,519
the damage is already down other

00:14:59,040 --> 00:15:06,000
challenge is already affected

00:15:03,519 --> 00:15:06,720
so we have designed what we call the

00:15:06,000 --> 00:15:09,600
money talent

00:15:06,720 --> 00:15:12,079
resource use resource manager we have

00:15:09,600 --> 00:15:14,560
introduced a new module called the

00:15:12,079 --> 00:15:17,760
resource manager into the architecture

00:15:14,560 --> 00:15:22,160
the resource manager will

00:15:17,760 --> 00:15:26,240
connect all the tenants resource usage

00:15:22,160 --> 00:15:27,040
and calculate to see if any tenants have

00:15:26,240 --> 00:15:29,360
exceeded

00:15:27,040 --> 00:15:30,959
the resource usage threshold we have

00:15:29,360 --> 00:15:34,480
defined

00:15:30,959 --> 00:15:37,759
if any tenant have exceeded

00:15:34,480 --> 00:15:39,279
we will mark the tenant as to be

00:15:37,759 --> 00:15:41,920
punished

00:15:39,279 --> 00:15:42,320
and the resource manager will notify

00:15:41,920 --> 00:15:44,399
this

00:15:42,320 --> 00:15:46,880
punishment information to all the

00:15:44,399 --> 00:15:46,880
workers

00:15:47,199 --> 00:15:51,279
and again each worker there's a

00:15:49,759 --> 00:15:54,639
scheduler to schedule

00:15:51,279 --> 00:15:58,079
users for it to run when the schedule

00:15:54,639 --> 00:16:01,360
starts to work it will first

00:15:58,079 --> 00:16:02,320
check whether the talent in question is

00:16:01,360 --> 00:16:06,160
punished

00:16:02,320 --> 00:16:09,519
if it is punished all its splits

00:16:06,160 --> 00:16:12,720
will not be scheduled

00:16:09,519 --> 00:16:15,839
and to save the superior resources

00:16:12,720 --> 00:16:15,839
to other tenants

00:16:16,320 --> 00:16:20,320
one difference with the community

00:16:18,720 --> 00:16:20,800
version is that in community version

00:16:20,320 --> 00:16:24,160
there's

00:16:20,800 --> 00:16:24,560
only one global multi-level priority

00:16:24,160 --> 00:16:28,160
queue

00:16:24,560 --> 00:16:31,199
for all the queries in our

00:16:28,160 --> 00:16:34,399
design there's for each challenge

00:16:31,199 --> 00:16:37,600
there's a dedicated

00:16:34,399 --> 00:16:41,360
level priority queue so

00:16:37,600 --> 00:16:44,320
there are the splits of different

00:16:41,360 --> 00:16:47,600
talents are separated

00:16:44,320 --> 00:16:48,959
and within each talent the scheduling

00:16:47,600 --> 00:16:51,680
logic

00:16:48,959 --> 00:16:52,639
is a similar life as a community presto

00:16:51,680 --> 00:16:54,880
so

00:16:52,639 --> 00:16:56,959
a short quarry gets more cpu time and

00:16:54,880 --> 00:17:00,880
the long quarter gets less debut time

00:16:56,959 --> 00:17:00,880
in each scheduling cycle

00:17:01,600 --> 00:17:08,240
and here is a demo it shows how this

00:17:05,360 --> 00:17:09,199
scheduling logic works we can see that

00:17:08,240 --> 00:17:12,240
when

00:17:09,199 --> 00:17:13,120
the cpu the tenant cpu usage is under

00:17:12,240 --> 00:17:16,160
threshold

00:17:13,120 --> 00:17:19,520
the query runs mostly

00:17:16,160 --> 00:17:20,400
oh the x the x-axis is the scheduling

00:17:19,520 --> 00:17:24,880
cycle

00:17:20,400 --> 00:17:28,559
and the y-axis is the cpu threshold

00:17:24,880 --> 00:17:31,440
when the cpu usually is under threshold

00:17:28,559 --> 00:17:32,480
the quality runs smoothly and when the

00:17:31,440 --> 00:17:35,039
cpu use it

00:17:32,480 --> 00:17:36,960
means the full cycle the speed usage

00:17:35,039 --> 00:17:37,840
exceeded the threshold exiting the

00:17:36,960 --> 00:17:41,039
threshold

00:17:37,840 --> 00:17:44,160
but not too much not existed twice

00:17:41,039 --> 00:17:46,640
twice of the threshold the

00:17:44,160 --> 00:17:47,360
talent will not be punished in the next

00:17:46,640 --> 00:17:51,520
cycle

00:17:47,360 --> 00:17:52,640
but the exceeded amount of cpu will be

00:17:51,520 --> 00:17:56,000
accumulated

00:17:52,640 --> 00:17:59,039
to the next cycle and in the next

00:17:56,000 --> 00:18:01,039
cycle the cpu unit exceeded twice of the

00:17:59,039 --> 00:18:03,840
cpa threshold

00:18:01,039 --> 00:18:04,480
so it will be punished in the next cycle

00:18:03,840 --> 00:18:06,559
in the next

00:18:04,480 --> 00:18:08,480
cycle there's no running there's no

00:18:06,559 --> 00:18:12,000
running no scheduling for this

00:18:08,480 --> 00:18:12,320
tenant it is punished so cpu results can

00:18:12,000 --> 00:18:15,360
be

00:18:12,320 --> 00:18:18,320
saved for other well-behaved tenants

00:18:15,360 --> 00:18:19,120
and in the seventh cycle because the

00:18:18,320 --> 00:18:22,720
punishment

00:18:19,120 --> 00:18:25,360
cycle is over the tenant's quarry can

00:18:22,720 --> 00:18:25,360
run again

00:18:26,640 --> 00:18:33,039
and here some evaluation

00:18:29,760 --> 00:18:35,600
we have done this the test server

00:18:33,039 --> 00:18:36,400
setup is like this there are four

00:18:35,600 --> 00:18:39,520
workers

00:18:36,400 --> 00:18:40,880
each with four cores and eight gigabytes

00:18:39,520 --> 00:18:44,400
of memory

00:18:40,880 --> 00:18:47,520
and the test data is tbch 20 gigabyte

00:18:44,400 --> 00:18:50,559
and the sql we used is 20 sql

00:18:47,520 --> 00:18:53,440
of tpch its characteristic

00:18:50,559 --> 00:18:54,160
is that it has joined many tables so it

00:18:53,440 --> 00:18:56,960
will

00:18:54,160 --> 00:18:57,760
use a lot of cpu resource and this

00:18:56,960 --> 00:19:00,960
scenario

00:18:57,760 --> 00:19:04,080
is we use the four tenants a b

00:19:00,960 --> 00:19:07,280
c and d and for abc tenant

00:19:04,080 --> 00:19:10,640
each submitted one sequel and for the d

00:19:07,280 --> 00:19:13,840
talent it is submitted five sequel

00:19:10,640 --> 00:19:16,720
so we expected that the d talent d

00:19:13,840 --> 00:19:16,720
should be punished

00:19:16,799 --> 00:19:20,000
and the on the left is the community

00:19:18,880 --> 00:19:22,320
version

00:19:20,000 --> 00:19:23,679
look in the community version talent d

00:19:22,320 --> 00:19:27,200
the yellow line

00:19:23,679 --> 00:19:31,200
used too much splits it's much higher

00:19:27,200 --> 00:19:33,440
than the average and

00:19:31,200 --> 00:19:34,559
on the right in the diy version we can

00:19:33,440 --> 00:19:37,200
see that

00:19:34,559 --> 00:19:38,000
all the lines have a similar shape which

00:19:37,200 --> 00:19:41,600
means

00:19:38,000 --> 00:19:41,600
computer resource is isolated

00:19:41,679 --> 00:19:46,080
and here's another evaluation from from

00:19:44,559 --> 00:19:48,720
another perspective

00:19:46,080 --> 00:19:49,600
which is correct duration on the left

00:19:48,720 --> 00:19:54,559
side we can see

00:19:49,600 --> 00:19:56,720
all the quarries all the eight quarries

00:19:54,559 --> 00:19:57,600
cost the similar time which means no

00:19:56,720 --> 00:19:59,919
punishment

00:19:57,600 --> 00:20:00,960
even if the d have some emitted five

00:19:59,919 --> 00:20:04,720
queries

00:20:00,960 --> 00:20:06,559
they end up with the same time with

00:20:04,720 --> 00:20:08,400
other quarries and on the left in the

00:20:06,559 --> 00:20:10,880
dos version

00:20:08,400 --> 00:20:13,120
the quarry one two three which

00:20:10,880 --> 00:20:17,200
corresponds to challenge abc

00:20:13,120 --> 00:20:20,080
used last time to finish and the

00:20:17,200 --> 00:20:20,880
chorus four five six seven eight which

00:20:20,080 --> 00:20:24,559
responds

00:20:20,880 --> 00:20:28,880
to talent d used much longer time

00:20:24,559 --> 00:20:32,320
which means energy has been punished

00:20:28,880 --> 00:20:34,159
and with this computer monitoring is in

00:20:32,320 --> 00:20:37,440
place we can safely serve

00:20:34,159 --> 00:20:42,640
all all customers

00:20:37,440 --> 00:20:42,640
within one compressor cluster

00:20:44,480 --> 00:20:49,840
and the next thing i want to talk about

00:20:46,400 --> 00:20:49,840
is connected optimization

00:20:50,080 --> 00:20:56,880
we have added support

00:20:53,280 --> 00:20:59,360
for many data sources on alibaba cloud

00:20:56,880 --> 00:21:01,039
for example alibaba oss which is blob

00:20:59,360 --> 00:21:03,919
store

00:21:01,039 --> 00:21:04,600
we supported read right from it and we

00:21:03,919 --> 00:21:08,240
have an

00:21:04,600 --> 00:21:11,440
optimization that we can reduce

00:21:08,240 --> 00:21:12,880
os api requested down to one tenth to

00:21:11,440 --> 00:21:16,960
one third

00:21:12,880 --> 00:21:19,280
compared to community version

00:21:16,960 --> 00:21:20,960
the second one is alibaba table store

00:21:19,280 --> 00:21:23,039
alabama table store is the most

00:21:20,960 --> 00:21:27,520
extensively used kiwi store

00:21:23,039 --> 00:21:30,720
for alba cloud with dla's integration

00:21:27,520 --> 00:21:34,240
user can use your a sql statement

00:21:30,720 --> 00:21:35,280
to analyze kiwi data stored in table

00:21:34,240 --> 00:21:37,919
stock

00:21:35,280 --> 00:21:41,120
and the doa can also pick the best

00:21:37,919 --> 00:21:45,039
secondary index if applicable

00:21:41,120 --> 00:21:48,720
and the third is alibaba analytical db

00:21:45,039 --> 00:21:51,760
analysis db is the most fast orap data

00:21:48,720 --> 00:21:52,799
warehouse solution on alibaba cloud with

00:21:51,760 --> 00:21:55,280
dls help

00:21:52,799 --> 00:21:56,320
users can pre-process data before

00:21:55,280 --> 00:21:59,280
ingested

00:21:56,320 --> 00:22:00,080
by analytic db and for alibaba max

00:21:59,280 --> 00:22:02,080
compute

00:22:00,080 --> 00:22:03,440
we support a reader write from it and

00:22:02,080 --> 00:22:07,760
also we support a read

00:22:03,440 --> 00:22:08,960
from mass compute external table stored

00:22:07,760 --> 00:22:11,600
on oss

00:22:08,960 --> 00:22:13,919
and we also support all the connectors

00:22:11,600 --> 00:22:17,520
supported by the community presto

00:22:13,919 --> 00:22:22,720
and we have the many optimizations like

00:22:17,520 --> 00:22:22,720
perennial read for rds data sources

00:22:23,360 --> 00:22:27,760
and here i will introduce in detail how

00:22:26,640 --> 00:22:31,360
we have

00:22:27,760 --> 00:22:34,799
saved a lot of earlier oss

00:22:31,360 --> 00:22:37,760
requests we know that when

00:22:34,799 --> 00:22:38,840
oil ap engine like crystal communicate

00:22:37,760 --> 00:22:43,280
with

00:22:38,840 --> 00:22:46,480
oss it use the hadoop file system api

00:22:43,280 --> 00:22:46,480
and in community version

00:22:46,799 --> 00:22:53,840
uh our living osf file system will issue

00:22:49,919 --> 00:22:57,720
a new request in two

00:22:53,840 --> 00:23:00,640
the first is if it has read more than

00:22:57,720 --> 00:23:04,799
512 kilobytes data

00:23:00,640 --> 00:23:06,720
or if there is a c operation

00:23:04,799 --> 00:23:08,320
so we have optimized in the following

00:23:06,720 --> 00:23:11,840
way first

00:23:08,320 --> 00:23:14,960
we will reach as read as much data

00:23:11,840 --> 00:23:18,159
as we can with just one request

00:23:14,960 --> 00:23:21,919
until there is a seek

00:23:18,159 --> 00:23:22,640
but if there is the seek is very small

00:23:21,919 --> 00:23:27,120
for example

00:23:22,640 --> 00:23:29,280
only 100 bytes we will not do a real c

00:23:27,120 --> 00:23:30,640
we will continue reading but discard the

00:23:29,280 --> 00:23:33,200
data

00:23:30,640 --> 00:23:34,080
it will waste some bandwidth but worth

00:23:33,200 --> 00:23:36,559
it

00:23:34,080 --> 00:23:37,679
and we continue to read we can read

00:23:36,559 --> 00:23:40,720
until there is

00:23:37,679 --> 00:23:43,840
another seek and this is very big

00:23:40,720 --> 00:23:48,640
it is 128 megabytes

00:23:43,840 --> 00:23:50,720
we will do a real seek so

00:23:48,640 --> 00:23:51,840
then we we'll start another reading so

00:23:50,720 --> 00:23:54,320
in this

00:23:51,840 --> 00:23:56,240
demo there's another reading in the

00:23:54,320 --> 00:23:59,440
header file system api but

00:23:56,240 --> 00:24:02,480
we only have two read requests

00:23:59,440 --> 00:24:05,679
to the oss api so we have to do

00:24:02,480 --> 00:24:09,600
some tests here is the diagram

00:24:05,679 --> 00:24:12,400
comparison we can reduce the apa

00:24:09,600 --> 00:24:14,559
request account down to when chance for

00:24:12,400 --> 00:24:17,840
data stored in text format

00:24:14,559 --> 00:24:19,760
and down to one third for data storing

00:24:17,840 --> 00:24:22,880
orc or packet format

00:24:19,760 --> 00:24:26,640
so it can on average it can save

00:24:22,880 --> 00:24:30,159
about six percent to 90 percent

00:24:26,640 --> 00:24:30,159
cost for user

00:24:30,640 --> 00:24:34,000
and these are all i want to share today

00:24:32,880 --> 00:24:37,760
and here's

00:24:34,000 --> 00:24:41,760
more information about doa and also

00:24:37,760 --> 00:24:41,760
we're hiring thank you

00:24:42,320 --> 00:24:45,520
thank you so much and looks like we do

00:24:43,919 --> 00:24:48,159
have a connection with james

00:24:45,520 --> 00:24:49,360
shu he's going to be presenting here hey

00:24:48,159 --> 00:24:52,080
are you

00:24:49,360 --> 00:24:53,679
uh i'm good thank you hey thanks so much

00:24:52,080 --> 00:24:57,600
for coming in here

00:24:53,679 --> 00:24:59,760
so data lake analytics alibaba's presto

00:24:57,600 --> 00:25:00,000
experiences we're very curious to hear

00:24:59,760 --> 00:25:03,679
more

00:25:00,000 --> 00:25:07,039
about this yeah data lake analytics

00:25:03,679 --> 00:25:09,120
is the data lake solution we provided in

00:25:07,039 --> 00:25:11,360
alibaba cloud

00:25:09,120 --> 00:25:12,320
and it's based on presto and we have

00:25:11,360 --> 00:25:15,840
done many

00:25:12,320 --> 00:25:15,840
optimizations in it

00:25:16,880 --> 00:25:22,480
and the main the main star

00:25:20,559 --> 00:25:23,919
the main story that people use in

00:25:22,480 --> 00:25:27,279
halloween is

00:25:23,919 --> 00:25:31,039
oss which is a blob store service

00:25:27,279 --> 00:25:35,120
and people also use for example rds

00:25:31,039 --> 00:25:35,120
ots or mongodb etc

00:25:35,440 --> 00:25:39,200
okay the data lake analytics solution

00:25:37,440 --> 00:25:41,600
for alibaba cloud

00:25:39,200 --> 00:25:44,799
how big is that can you give us some

00:25:41,600 --> 00:25:47,840
idea about how much data is in there

00:25:44,799 --> 00:25:50,159
uh i think it's about a

00:25:47,840 --> 00:25:51,360
ev i don't know how to pronounce it

00:25:50,159 --> 00:25:56,720
correctly

00:25:51,360 --> 00:26:00,320
in english

00:25:56,720 --> 00:26:03,520
enormous i think that's the english

00:26:00,320 --> 00:26:08,480
that's the correct word

00:26:03,520 --> 00:26:11,440
okay exabytes you have exabytes of data

00:26:08,480 --> 00:26:12,799
yeah yeah this is very cool tell us a

00:26:11,440 --> 00:26:14,480
bit about yourself and your history

00:26:12,799 --> 00:26:15,919
while we wait for the uh presentation to

00:26:14,480 --> 00:26:18,799
launch

00:26:15,919 --> 00:26:21,200
okay um i'm a presto developer at

00:26:18,799 --> 00:26:25,120
alibaba cloud and um

00:26:21,200 --> 00:26:29,039
committee oh i'm about team understand

00:26:25,120 --> 00:26:32,080
and have done many

00:26:29,039 --> 00:26:33,760
uh interesting things in big data big

00:26:32,080 --> 00:26:37,039
data program programming

00:26:33,760 --> 00:26:41,120
and it's about

00:26:37,039 --> 00:26:43,440
8 1 1 30 am in china but i'm fully awake

00:26:41,120 --> 00:26:45,120
to enjoy the great sessions

00:26:43,440 --> 00:26:48,159
thank you so much for calling in the

00:26:45,120 --> 00:26:48,159

YouTube URL: https://www.youtube.com/watch?v=o20cnFtE4TQ


