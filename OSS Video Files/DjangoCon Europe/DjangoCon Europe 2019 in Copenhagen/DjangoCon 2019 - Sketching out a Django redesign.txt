Title: DjangoCon 2019 - Sketching out a Django redesign
Publication date: 2019-04-23
Playlist: DjangoCon Europe 2019 in Copenhagen
Description: 
	https://2019.djangocon.eu/talks/sketching-out-a-django-redesign/

By Tom Christie: https://twitter.com/_tomchristie
Captions: 
	00:00:00,319 --> 00:00:06,060
we're there okay yeah one last thing

00:00:04,200 --> 00:00:07,589
before I get started I think my kids

00:00:06,060 --> 00:00:12,320
might be watching on the livestream at

00:00:07,589 --> 00:00:17,400
home so hi boys yeah I guess thank you

00:00:12,320 --> 00:00:20,750
okay great hi thank you very much my

00:00:17,400 --> 00:00:23,220
name is Tom Chrissy I've been a longtime

00:00:20,750 --> 00:00:25,710
Python and Django user

00:00:23,220 --> 00:00:28,609
I'm the maintainer of several open

00:00:25,710 --> 00:00:31,769
source projects and I'm most well known

00:00:28,609 --> 00:00:36,030
for being the author of Django rest

00:00:31,769 --> 00:00:38,010
framework now I'm fortunate enough to be

00:00:36,030 --> 00:00:40,579
in a position where I work on open

00:00:38,010 --> 00:00:43,170
source full-time now for my day job

00:00:40,579 --> 00:00:48,210
Django rest framework launched a

00:00:43,170 --> 00:00:50,730
sponsorship program where lots and lots

00:00:48,210 --> 00:00:51,600
of different companies can contribute a

00:00:50,730 --> 00:00:54,629
smaller month

00:00:51,600 --> 00:00:57,360
a small amount per month and this is

00:00:54,629 --> 00:01:02,609
what pays for my day job at the moment

00:00:57,360 --> 00:01:04,559
so and I've been spending as well as

00:01:02,609 --> 00:01:06,750
working on Django rest framework and

00:01:04,559 --> 00:01:09,210
helping manage that spending a lot of

00:01:06,750 --> 00:01:14,490
time recently on async which is what I'm

00:01:09,210 --> 00:01:19,189
going to talk about today so - is at a

00:01:14,490 --> 00:01:23,369
really big crossroads right now python

00:01:19,189 --> 00:01:26,400
3.5 introduced a new functionality in

00:01:23,369 --> 00:01:29,450
the form of the async and awaits

00:01:26,400 --> 00:01:32,310
keywords the async and await keywords

00:01:29,450 --> 00:01:35,759
helped us use an entirely new

00:01:32,310 --> 00:01:38,579
concurrency model that is much much more

00:01:35,759 --> 00:01:41,189
efficient than the existing threaded

00:01:38,579 --> 00:01:42,090
concurrency model and this length is

00:01:41,189 --> 00:01:47,399
going to allow us to do some really

00:01:42,090 --> 00:01:51,149
exciting things for one thing it lets us

00:01:47,399 --> 00:01:54,680
build very very high throughput web

00:01:51,149 --> 00:01:59,159
services it allows us to make

00:01:54,680 --> 00:02:03,719
non-blocking HTTP requests so we can

00:01:59,159 --> 00:02:07,200
build Python gateway api's or proxy

00:02:03,719 --> 00:02:09,869
services that are able to handle very

00:02:07,200 --> 00:02:11,459
high concurrency high throughput which

00:02:09,869 --> 00:02:14,800
is a domain where Python has

00:02:11,459 --> 00:02:20,170
traditionally not excelled in

00:02:14,800 --> 00:02:23,050
and it will also allow us to handle

00:02:20,170 --> 00:02:25,569
real-time Network protocols such as

00:02:23,050 --> 00:02:28,470
WebSockets so we'll be able to start

00:02:25,569 --> 00:02:31,959
building more and more real-time

00:02:28,470 --> 00:02:35,440
responsive web applications chat

00:02:31,959 --> 00:02:40,540
services games real-time monitoring all

00:02:35,440 --> 00:02:44,880
of these kinds of things before we dive

00:02:40,540 --> 00:02:48,750
into this a little bits of groundwork

00:02:44,880 --> 00:02:51,700
concurrency what is concurrency

00:02:48,750 --> 00:02:54,959
concurrency is all about the number of

00:02:51,700 --> 00:02:58,420
tasks that your server is able to handle

00:02:54,959 --> 00:03:02,650
simultaneously in the web development

00:02:58,420 --> 00:03:05,140
land this maps on to how many HTTP

00:03:02,650 --> 00:03:08,440
connections is your server able to hold

00:03:05,140 --> 00:03:11,080
open at the same time and then in turn

00:03:08,440 --> 00:03:13,720
also influences what is the throughput

00:03:11,080 --> 00:03:16,600
that your server is able to achieve how

00:03:13,720 --> 00:03:20,950
many requests per second can each

00:03:16,600 --> 00:03:23,290
individual server handle so what are

00:03:20,950 --> 00:03:26,560
some of the ways that we have to

00:03:23,290 --> 00:03:27,700
increase the concurrency of these web

00:03:26,560 --> 00:03:30,760
services that we're building

00:03:27,700 --> 00:03:34,709
so the bluntest hammer in our toolbox

00:03:30,760 --> 00:03:38,769
our sledgehammer is multi host so

00:03:34,709 --> 00:03:40,959
horizontal scaling where you know you

00:03:38,769 --> 00:03:42,459
add more servers running the same code

00:03:40,959 --> 00:03:44,920
base and you're going to be able to

00:03:42,459 --> 00:03:48,100
handle a greater number of requests per

00:03:44,920 --> 00:03:50,530
second well let's bring that down the

00:03:48,100 --> 00:03:52,750
level to a single server how can we

00:03:50,530 --> 00:03:55,959
increase the concurrency on a single

00:03:52,750 --> 00:03:59,140
server within a single server we'll have

00:03:55,959 --> 00:04:01,329
a number of CPU cores we want to make

00:03:59,140 --> 00:04:03,609
sure that all of those cpu cores are

00:04:01,329 --> 00:04:04,840
fully utilized all the time as much as

00:04:03,609 --> 00:04:08,620
possible

00:04:04,840 --> 00:04:11,890
so we can run multiple processes within

00:04:08,620 --> 00:04:14,380
each machine or all pretty much

00:04:11,890 --> 00:04:17,489
completely independent but all running

00:04:14,380 --> 00:04:21,609
at the same time okay bring that down

00:04:17,489 --> 00:04:24,669
again another level how do we increase

00:04:21,609 --> 00:04:27,110
the concurrency within a single process

00:04:24,669 --> 00:04:29,590
running on a single server

00:04:27,110 --> 00:04:32,330
so traditionally what we've used is

00:04:29,590 --> 00:04:34,580
threaded concurrency and with threaded

00:04:32,330 --> 00:04:38,689
concurrency what happens is we have a

00:04:34,580 --> 00:04:41,659
number of simultaneous flows of control

00:04:38,689 --> 00:04:44,599
running through our program and each

00:04:41,659 --> 00:04:47,479
individual flow of control will have

00:04:44,599 --> 00:04:51,050
large chunks of time where it's not

00:04:47,479 --> 00:04:54,289
utilizing the CPU because it's waiting

00:04:51,050 --> 00:04:57,939
on IO from the rest of the system so

00:04:54,289 --> 00:05:05,259
anytime your program goes off and makes

00:04:57,939 --> 00:05:09,490
an HTTP request makes a database access

00:05:05,259 --> 00:05:12,800
accesses some disk IO there's this

00:05:09,490 --> 00:05:14,569
relatively huge chunk of time when that

00:05:12,800 --> 00:05:16,849
thread of control is not able to do

00:05:14,569 --> 00:05:18,529
anything else until it gets a response

00:05:16,849 --> 00:05:21,319
back from the operating system

00:05:18,529 --> 00:05:24,279
so with multi-threading what the

00:05:21,319 --> 00:05:26,990
operating system does for you is handles

00:05:24,279 --> 00:05:29,960
interleaving several different flows of

00:05:26,990 --> 00:05:31,879
control and switches between them very

00:05:29,960 --> 00:05:34,250
very quickly so it appears as if all

00:05:31,879 --> 00:05:39,860
these throws of control are happening at

00:05:34,250 --> 00:05:41,719
the same time now more recently the

00:05:39,860 --> 00:05:44,779
async model has been introduced and the

00:05:41,719 --> 00:05:48,729
key point to take away at this point in

00:05:44,779 --> 00:05:51,169
time is async is an alternative to

00:05:48,729 --> 00:05:54,229
multi-threading right where they think

00:05:51,169 --> 00:05:57,199
you will have multiple tasks rather than

00:05:54,229 --> 00:05:58,430
multiple threads and your multiple tasks

00:05:57,199 --> 00:06:01,909
will all be running within the single

00:05:58,430 --> 00:06:05,300
thread but you will still have multiple

00:06:01,909 --> 00:06:07,460
processes or running lots and lots of

00:06:05,300 --> 00:06:08,870
little tasks within it and you will

00:06:07,460 --> 00:06:13,789
still be running across multiple

00:06:08,870 --> 00:06:16,339
different hosts and I think is as we

00:06:13,789 --> 00:06:19,580
said far more efficient so what are the

00:06:16,339 --> 00:06:21,949
differences between these two with

00:06:19,580 --> 00:06:26,360
threaded concurrency everything is

00:06:21,949 --> 00:06:28,509
managed by the operating system and the

00:06:26,360 --> 00:06:31,580
or you don't get to see as a programmer

00:06:28,509 --> 00:06:36,310
when am I going to switch between one of

00:06:31,580 --> 00:06:38,990
my two different threads of control in

00:06:36,310 --> 00:06:41,090
async it's a completely different model

00:06:38,990 --> 00:06:45,410
in that it's managed by the

00:06:41,090 --> 00:06:47,810
time it's managed by Python itself or or

00:06:45,410 --> 00:06:53,090
by no dog or whatever runtime you happen

00:06:47,810 --> 00:06:55,280
to be using and the points of context

00:06:53,090 --> 00:06:58,370
switching between these different flows

00:06:55,280 --> 00:07:01,669
of control are still the points at which

00:06:58,370 --> 00:07:05,180
you're performing IO so Network requests

00:07:01,669 --> 00:07:07,400
database accesses disk accesses but they

00:07:05,180 --> 00:07:11,210
have to be explicitly marked in the

00:07:07,400 --> 00:07:13,280
program so that the runtime knows okay

00:07:11,210 --> 00:07:18,800
here's a point at which I can context

00:07:13,280 --> 00:07:23,330
switch so you have this entirely new

00:07:18,800 --> 00:07:27,320
syntax that is introduced the async and

00:07:23,330 --> 00:07:30,470
await keywords and what's problematic is

00:07:27,320 --> 00:07:34,220
that these two models are largely

00:07:30,470 --> 00:07:38,180
incompatible if you're going to have

00:07:34,220 --> 00:07:40,400
explicit context switching then you need

00:07:38,180 --> 00:07:43,900
to have explicit context switching all

00:07:40,400 --> 00:07:46,340
the way through so if your low-level I'm

00:07:43,900 --> 00:07:48,260
making a network request as being

00:07:46,340 --> 00:07:51,380
explicitly more than anything that calls

00:07:48,260 --> 00:07:59,060
into that also needs to be marked up as

00:07:51,380 --> 00:08:01,190
being an async function and although

00:07:59,060 --> 00:08:03,979
there are ways that we can mediate

00:08:01,190 --> 00:08:07,970
between these two styles it's a bit

00:08:03,979 --> 00:08:10,970
fiddly so there's this huge challenge

00:08:07,970 --> 00:08:17,300
for the ecosystem it's it's a little bit

00:08:10,970 --> 00:08:19,340
of a fork in the road and it's important

00:08:17,300 --> 00:08:22,070
to knowledge that as with any new

00:08:19,340 --> 00:08:23,510
technology there are costs as well and

00:08:22,070 --> 00:08:25,490
we need to talk about them upfront and

00:08:23,510 --> 00:08:30,110
recognize them so that we're in a good

00:08:25,490 --> 00:08:36,050
position to judge what the trade-offs

00:08:30,110 --> 00:08:38,630
are alright so there's this huge upfront

00:08:36,050 --> 00:08:40,969
cost in terms of all of the new code

00:08:38,630 --> 00:08:44,000
that needs to be rewritten in order to

00:08:40,969 --> 00:08:45,339
work with async so for one thing all of

00:08:44,000 --> 00:08:48,110
the low-level

00:08:45,339 --> 00:08:52,209
networking stuff all of the database

00:08:48,110 --> 00:08:54,840
drivers or making HTTP requests or

00:08:52,209 --> 00:08:57,960
exactly how do you go about making this

00:08:54,840 --> 00:09:00,360
kiyo people need to write low-level

00:08:57,960 --> 00:09:02,640
async libraries to interact with that

00:09:00,360 --> 00:09:05,690
because it doesn't exist in the standard

00:09:02,640 --> 00:09:11,880
library because it wasn't a thing when

00:09:05,690 --> 00:09:16,260
puffin was not 3.5 not quite true but

00:09:11,880 --> 00:09:19,410
pretty much what else okay well it's a

00:09:16,260 --> 00:09:21,840
different paradigm and there's a little

00:09:19,410 --> 00:09:24,330
bit more to think about as well as a as

00:09:21,840 --> 00:09:25,770
a developer there's two different types

00:09:24,330 --> 00:09:28,400
of function call you've got now you've

00:09:25,770 --> 00:09:31,410
got async function calls which is

00:09:28,400 --> 00:09:33,480
anything that is making IO and you've

00:09:31,410 --> 00:09:36,000
got regular function calls which is only

00:09:33,480 --> 00:09:38,130
allowed to just be doing regular

00:09:36,000 --> 00:09:40,110
programming type stuff it's using the

00:09:38,130 --> 00:09:47,160
CPU and it's performing some kind of

00:09:40,110 --> 00:09:48,960
computation one of the other reasons

00:09:47,160 --> 00:09:51,840
that it's worthwhile being cautious here

00:09:48,960 --> 00:09:53,010
as well is you might not care about

00:09:51,840 --> 00:09:55,920
throughput

00:09:53,010 --> 00:09:59,700
okay so for when you're looking at the

00:09:55,920 --> 00:10:01,740
performance of your web service the

00:09:59,700 --> 00:10:04,800
thing that your users will most care

00:10:01,740 --> 00:10:06,990
about is how long does it take once

00:10:04,800 --> 00:10:08,820
they've made a request for them to get a

00:10:06,990 --> 00:10:12,720
page back in front of them what is the

00:10:08,820 --> 00:10:14,280
latency of the request and async has an

00:10:12,720 --> 00:10:21,570
influence on that but it's more

00:10:14,280 --> 00:10:24,660
complicated and unless you are building

00:10:21,570 --> 00:10:26,300
a very high volume service the

00:10:24,660 --> 00:10:29,010
throughput that it's able to handle

00:10:26,300 --> 00:10:31,470
might not matter that much unless you

00:10:29,010 --> 00:10:33,960
have several app several server

00:10:31,470 --> 00:10:39,120
instances why do you care that it could

00:10:33,960 --> 00:10:41,940
hands are high load fine so that's the

00:10:39,120 --> 00:10:46,340
words that cut you know things to bear

00:10:41,940 --> 00:10:48,510
in mind but the benefits right

00:10:46,340 --> 00:10:56,430
sometimes the performance really does

00:10:48,510 --> 00:10:59,370
matter and in the cases where it does

00:10:56,430 --> 00:11:01,830
it's really really important that this

00:10:59,370 --> 00:11:05,550
should not be a blocker for businesses

00:11:01,830 --> 00:11:08,490
adopting Python we want to be able to

00:11:05,550 --> 00:11:10,860
build hugely scalable

00:11:08,490 --> 00:11:12,630
services with Python and we want the

00:11:10,860 --> 00:11:15,720
mega companies who are developing these

00:11:12,630 --> 00:11:18,240
flagship services to be choosing Python

00:11:15,720 --> 00:11:20,459
right at the start building highly

00:11:18,240 --> 00:11:22,290
successful products with it and being

00:11:20,459 --> 00:11:24,899
able to go to the rest of the world Hey

00:11:22,290 --> 00:11:28,950
look at this awesome thing that company

00:11:24,899 --> 00:11:30,270
XYZ Edge has built-in Python and for

00:11:28,950 --> 00:11:32,399
them to go yeah this was a great

00:11:30,270 --> 00:11:34,080
development experience for our team and

00:11:32,399 --> 00:11:37,160
we're very happy with the choice that we

00:11:34,080 --> 00:11:41,610
made what else

00:11:37,160 --> 00:11:44,490
real-time I think because they think is

00:11:41,610 --> 00:11:48,020
much more resource efficient we're able

00:11:44,490 --> 00:11:51,209
to hold open lots and lots of network

00:11:48,020 --> 00:11:53,339
connections without that having a high

00:11:51,209 --> 00:11:54,990
impact so we can hold open things like

00:11:53,339 --> 00:11:58,980
WebSockets and we could do real-time

00:11:54,990 --> 00:12:03,200
communications non-blocking HTTP

00:11:58,980 --> 00:12:06,270
requests being able to perform

00:12:03,200 --> 00:12:09,080
parallelization within our codes without

00:12:06,270 --> 00:12:13,160
that being a heavy weight thing that

00:12:09,080 --> 00:12:16,200
branching lots of new threads would be

00:12:13,160 --> 00:12:18,089
the explicit IO is actually also a

00:12:16,200 --> 00:12:22,320
benefit as well but we'll come to that

00:12:18,089 --> 00:12:24,690
later in the talk and one other thing to

00:12:22,320 --> 00:12:26,700
say here is performance can mean

00:12:24,690 --> 00:12:30,320
different things in different contexts

00:12:26,700 --> 00:12:34,350
right so being able to build very highly

00:12:30,320 --> 00:12:37,230
concurrent web services well a flip way

00:12:34,350 --> 00:12:39,839
round of looking at it that is on very

00:12:37,230 --> 00:12:42,300
lightly resource systems on embedded

00:12:39,839 --> 00:12:50,430
systems these sorts of things will work

00:12:42,300 --> 00:12:52,290
really really well or suppose you're mmm

00:12:50,430 --> 00:12:53,700
you don't require high throughput on

00:12:52,290 --> 00:12:56,730
your site most of the time but it's only

00:12:53,700 --> 00:12:59,490
get a huge traffic spike your service is

00:12:56,730 --> 00:13:01,770
much much more resilient to that okay so

00:12:59,490 --> 00:13:03,899
it doesn't have to always be about this

00:13:01,770 --> 00:13:06,149
is just about high throughput services

00:13:03,899 --> 00:13:09,240
all the time there are other reasons why

00:13:06,149 --> 00:13:13,320
it's important and there's this other

00:13:09,240 --> 00:13:14,850
thing you know it is something that has

00:13:13,320 --> 00:13:17,820
been said lots of times we've said I'll

00:13:14,850 --> 00:13:19,740
pipe a Python slow just do it we don't

00:13:17,820 --> 00:13:20,880
want to use Python for X Y Zed because

00:13:19,740 --> 00:13:24,960
private and slow

00:13:20,880 --> 00:13:26,970
now yeah okay benchmarks nonsense

00:13:24,960 --> 00:13:29,280
nonsense nonsense though the tech

00:13:26,970 --> 00:13:31,590
empower benchmarks are the least awful

00:13:29,280 --> 00:13:33,710
ones that are around they've got a

00:13:31,590 --> 00:13:39,180
number of different test cases that

00:13:33,710 --> 00:13:42,090
exercise various different bits of do

00:13:39,180 --> 00:13:44,730
some database stuff to do reads to write

00:13:42,090 --> 00:13:47,640
whatever this particular test case I

00:13:44,730 --> 00:13:49,530
think is the most representative of web

00:13:47,640 --> 00:13:52,020
applications because it does a little

00:13:49,530 --> 00:13:53,670
bit of database reading it does a little

00:13:52,020 --> 00:13:58,140
bit of template rendering and it does a

00:13:53,670 --> 00:14:01,740
bit of exercising the web stack and yes

00:13:58,140 --> 00:14:05,790
I've got some go results off of the top

00:14:01,740 --> 00:14:07,320
here and yes I've got lots and lots of

00:14:05,790 --> 00:14:10,200
results from several different

00:14:07,320 --> 00:14:13,170
frameworks off the bottom here but the

00:14:10,200 --> 00:14:16,950
important things to look at are this one

00:14:13,170 --> 00:14:20,550
at the top this is go written against

00:14:16,950 --> 00:14:22,560
the go standard library the ones in

00:14:20,550 --> 00:14:26,720
yellow those are all node based and

00:14:22,560 --> 00:14:29,880
these ones in blue are both Python and

00:14:26,720 --> 00:14:32,340
we've got a single for a beefy server

00:14:29,880 --> 00:14:35,610
there that on its own is servicing

00:14:32,340 --> 00:14:40,160
servicing 70,000 requests per second

00:14:35,610 --> 00:14:45,090
which is probably more than you need so

00:14:40,160 --> 00:14:47,310
it's about making sure that there isn't

00:14:45,090 --> 00:14:50,250
this blocker to business adoption Python

00:14:47,310 --> 00:14:53,160
is in the same ballpark as node and go

00:14:50,250 --> 00:15:00,990
for almost all intents and purposes that

00:14:53,160 --> 00:15:02,250
we in this room would probably need so

00:15:00,990 --> 00:15:04,410
okay great

00:15:02,250 --> 00:15:08,850
we'd like to start taking advantage of

00:15:04,410 --> 00:15:11,400
this what do we need to do the first

00:15:08,850 --> 00:15:16,010
thing in the stack that we've run into

00:15:11,400 --> 00:15:22,080
is whiskey whiskey is the interface that

00:15:16,010 --> 00:15:24,870
exists between the server Ghana corn or

00:15:22,080 --> 00:15:28,710
you whiskey or something like that and

00:15:24,870 --> 00:15:33,750
the the application framework the web

00:15:28,710 --> 00:15:36,780
framework and whiskey

00:15:33,750 --> 00:15:38,790
has a couple of very big constraints for

00:15:36,780 --> 00:15:40,680
what we'd like to be able to do or one

00:15:38,790 --> 00:15:42,810
of which it's inherently a thread

00:15:40,680 --> 00:15:45,480
concurrency in space it doesn't have

00:15:42,810 --> 00:15:47,940
that async definition on there so it's

00:15:45,480 --> 00:15:52,170
not allowed to do any async context

00:15:47,940 --> 00:15:54,660
switching inside it and it's designed

00:15:52,170 --> 00:15:56,370
purely for handling HTTP requests and

00:15:54,660 --> 00:15:58,280
responses so it's got no easy way to

00:15:56,370 --> 00:16:07,190
adapt it for WebSockets

00:15:58,280 --> 00:16:09,900
so lol ASCII along comes Jango channels

00:16:07,190 --> 00:16:20,870
which originally was designed in order

00:16:09,900 --> 00:16:20,870
to keep sep 2 2014 8 connectivity

00:16:27,230 --> 00:16:33,960
evolved under Android Godwin's 1 for

00:16:30,930 --> 00:16:36,750
guidance wherever there we go into

00:16:33,960 --> 00:16:40,380
becoming a general-purpose application

00:16:36,750 --> 00:16:43,380
interface an alternative to whiskey and

00:16:40,380 --> 00:16:48,020
async alternative to whiskey an async

00:16:43,380 --> 00:16:51,960
alternative to whiskey that also handles

00:16:48,020 --> 00:16:55,290
WebSockets that is also able to deal

00:16:51,960 --> 00:16:58,110
with and there is also a more

00:16:55,290 --> 00:17:02,460
general-purpose interface and that is

00:16:58,110 --> 00:17:06,900
more adaptable so this is how the

00:17:02,460 --> 00:17:09,930
interface for ASCII looks as of ASCII 3

00:17:06,900 --> 00:17:13,290
which is we're done now I mean not we're

00:17:09,930 --> 00:17:17,819
done but we're kind of done for the big

00:17:13,290 --> 00:17:19,800
stuff anyway we've got these three

00:17:17,819 --> 00:17:22,020
variables that we call into the function

00:17:19,800 --> 00:17:24,630
with scope receive sense scope is a

00:17:22,020 --> 00:17:27,000
whole bunch of state information about

00:17:24,630 --> 00:17:29,720
the incoming connection in a dictionary

00:17:27,000 --> 00:17:33,420
with are a bunch of keys in it and

00:17:29,720 --> 00:17:35,970
receive and send are two channels on

00:17:33,420 --> 00:17:41,610
which the web application communicates

00:17:35,970 --> 00:17:44,580
with the web server and you use for

00:17:41,610 --> 00:17:47,580
example in the HTTP context you'll use

00:17:44,580 --> 00:17:53,250
the receive channel to do things like

00:17:47,580 --> 00:17:54,840
holding the body of the HTTP request you

00:17:53,250 --> 00:17:56,100
don't want it in the scope because then

00:17:54,840 --> 00:17:57,750
you'd have to have the whole body

00:17:56,100 --> 00:17:59,400
arrived all at once so instead you'd

00:17:57,750 --> 00:18:02,730
like to be able to stream it in in case

00:17:59,400 --> 00:18:13,530
you need to do that and also for sending

00:18:02,730 --> 00:18:15,540
out the outgoing HTTP response ascii

00:18:13,530 --> 00:18:18,870
gives us a lot of a lot of nice things

00:18:15,540 --> 00:18:20,550
so obviously we've got the potential for

00:18:18,870 --> 00:18:23,490
the performance characteristics of a

00:18:20,550 --> 00:18:24,680
sink that we've talked about real-time

00:18:23,490 --> 00:18:25,800
communication so it's not just

00:18:24,680 --> 00:18:28,680
WebSockets

00:18:25,800 --> 00:18:30,720
there's also server sent events which

00:18:28,680 --> 00:18:34,380
are very similar to WebSockets but

00:18:30,720 --> 00:18:37,650
they're over HTTP only and they are

00:18:34,380 --> 00:18:40,470
unidirectional so just sending from the

00:18:37,650 --> 00:18:42,570
server to the clients but they can be a

00:18:40,470 --> 00:18:45,450
nice simple thing to use without having

00:18:42,570 --> 00:18:50,460
to go the WebSocket routes HTTP long

00:18:45,450 --> 00:18:53,070
polling HTTP stew server push where when

00:18:50,460 --> 00:18:56,250
a request is made to your web server

00:18:53,070 --> 00:18:58,050
you've hit the home page the web server

00:18:56,250 --> 00:19:00,900
knows okay I haven't got any cookies

00:18:58,050 --> 00:19:03,180
from this thing it probably is going to

00:19:00,900 --> 00:19:05,820
need all of these other assets on the

00:19:03,180 --> 00:19:08,340
page and I don't want it to have to go

00:19:05,820 --> 00:19:09,720
and do a couple of different round trips

00:19:08,340 --> 00:19:12,990
before it gets them so I'm going to

00:19:09,720 --> 00:19:15,330
preemptively start pushing these assets

00:19:12,990 --> 00:19:17,610
over the connection I'll send back there

00:19:15,330 --> 00:19:19,770
here's the home page and I'm also going

00:19:17,610 --> 00:19:27,720
to start sending down my cat gifts at

00:19:19,770 --> 00:19:30,420
the same time ASCII also has startup and

00:19:27,720 --> 00:19:35,190
shutdown events which gives a more

00:19:30,420 --> 00:19:39,030
nicely managed context for running tasks

00:19:35,190 --> 00:19:42,090
within within that domain then whiskey

00:19:39,030 --> 00:19:43,950
has which don't have any kind of way of

00:19:42,090 --> 00:19:46,620
communicating okay I'm ready to go now

00:19:43,950 --> 00:19:48,330
or okay can you please start shutting

00:19:46,620 --> 00:19:50,190
things down and actually it's pretty

00:19:48,330 --> 00:19:54,720
powerful because it allows us to do

00:19:50,190 --> 00:19:57,960
things like build clock or timer driven

00:19:54,720 --> 00:20:00,270
events and know that the events that

00:19:57,960 --> 00:20:00,770
we're scheduling if they're running then

00:20:00,270 --> 00:20:03,650
when this

00:20:00,770 --> 00:20:06,020
requests when we're requested to shut

00:20:03,650 --> 00:20:07,460
down we can wait until those events are

00:20:06,020 --> 00:20:09,830
finished and then we can send back to

00:20:07,460 --> 00:20:10,820
the server say okay I'm all finished now

00:20:09,830 --> 00:20:16,250
and we know that we're going to

00:20:10,820 --> 00:20:17,900
terminate cleanly which can you know

00:20:16,250 --> 00:20:20,780
potentially allow us to build really

00:20:17,900 --> 00:20:23,840
nice task queues and so on in a much

00:20:20,780 --> 00:20:26,059
more simple way and it's more adaptable

00:20:23,840 --> 00:20:28,790
interface right we can potentially

00:20:26,059 --> 00:20:33,470
extend this into other protocols as well

00:20:28,790 --> 00:20:36,650
so it's here for the long term where's

00:20:33,470 --> 00:20:40,070
the ASCII landscape at the moment okay

00:20:36,650 --> 00:20:42,110
so we've got several different server

00:20:40,070 --> 00:20:45,080
implementations already we've got Daphne

00:20:42,110 --> 00:20:47,360
the original one hype corn somebody uh

00:20:45,080 --> 00:20:50,240
Phil Jones been working on a new becalm

00:20:47,360 --> 00:20:52,520
it's one that I've spent my time on and

00:20:50,240 --> 00:20:54,710
we've also got lots and lots of ASCII

00:20:52,520 --> 00:20:56,179
web frameworks emerging starla it's the

00:20:54,710 --> 00:20:57,830
one that I've been working on and I'm

00:20:56,179 --> 00:20:59,870
going to show you some of how that looks

00:20:57,830 --> 00:21:01,780
a bit different to Django and why that's

00:20:59,870 --> 00:21:03,980
interesting in the moment

00:21:01,780 --> 00:21:06,590
Django channels is slightly the odd one

00:21:03,980 --> 00:21:09,890
out on this list because that's async on

00:21:06,590 --> 00:21:11,540
the on the front but Fred aids most of

00:21:09,890 --> 00:21:13,850
the rest of the way through and we've

00:21:11,540 --> 00:21:18,760
also got other stuff that starting to be

00:21:13,850 --> 00:21:21,050
developed in this area as well so let's

00:21:18,760 --> 00:21:24,679
what I want to do over the next few

00:21:21,050 --> 00:21:28,100
slides is take a look at if we're

00:21:24,679 --> 00:21:29,929
building an async web framework what are

00:21:28,100 --> 00:21:32,000
some of the ways that we could do things

00:21:29,929 --> 00:21:35,210
a little bit differently and I think a

00:21:32,000 --> 00:21:37,790
lot of this can feed into some of the

00:21:35,210 --> 00:21:41,960
work that we're hoping to start doing on

00:21:37,790 --> 00:21:44,870
Django over the coming months now starla

00:21:41,960 --> 00:21:47,270
okay up here this example looks like any

00:21:44,870 --> 00:21:48,530
old standard micro web framework but

00:21:47,270 --> 00:21:50,270
there are a few ways that it's put

00:21:48,530 --> 00:21:53,360
together that I think are a little bit

00:21:50,270 --> 00:21:56,390
interesting now it's one thing that

00:21:53,360 --> 00:21:59,150
we're gonna see a lot it's a ski all the

00:21:56,390 --> 00:22:02,630
way through we use the ASCII interface

00:21:59,150 --> 00:22:06,260
as the primary thing on which the stack

00:22:02,630 --> 00:22:08,540
is built all the way right up to the

00:22:06,260 --> 00:22:11,179
when you when you're working with a view

00:22:08,540 --> 00:22:12,320
and then you're in request/response and

00:22:11,179 --> 00:22:14,310
you're dealing with requests and

00:22:12,320 --> 00:22:16,980
responses but all the way through

00:22:14,310 --> 00:22:19,170
every other part of the system if you

00:22:16,980 --> 00:22:23,310
start to dig into what's happening

00:22:19,170 --> 00:22:26,910
it's based on ascii and here's a good

00:22:23,310 --> 00:22:30,900
example of that is a response installers

00:22:26,910 --> 00:22:35,760
itself exposes the ascii interface so a

00:22:30,900 --> 00:22:38,190
an instance of very response is a valid

00:22:35,760 --> 00:22:41,910
web framework it's a very small one that

00:22:38,190 --> 00:22:42,840
just does one thing but but it is okay

00:22:41,910 --> 00:22:47,160
interesting

00:22:42,840 --> 00:22:49,110
okay just to get a bit of an idea about

00:22:47,160 --> 00:22:50,850
how some of the components look this

00:22:49,110 --> 00:22:53,970
isn't the level that you'll be working

00:22:50,850 --> 00:22:57,330
at normally this is using requests and

00:22:53,970 --> 00:22:59,070
responses within a raw ascii interface

00:22:57,330 --> 00:23:02,340
normally you'd be working within a

00:22:59,070 --> 00:23:04,730
proper request response for you but you

00:23:02,340 --> 00:23:07,830
can see how requests are just an

00:23:04,730 --> 00:23:10,230
interface that is instantiated over the

00:23:07,830 --> 00:23:16,860
ascii state that you can then do stuff

00:23:10,230 --> 00:23:20,070
with okay fine let's have another look

00:23:16,860 --> 00:23:24,300
up ways in which we use ascii all the

00:23:20,070 --> 00:23:27,810
way through the test client the test

00:23:24,300 --> 00:23:31,500
client installer is built upon requests

00:23:27,810 --> 00:23:35,910
it is requests its requests but with an

00:23:31,500 --> 00:23:39,030
as an adapter class an adapter class

00:23:35,910 --> 00:23:45,590
that instead of making raw network

00:23:39,030 --> 00:23:51,030
requests plugs directly into a na NNE

00:23:45,590 --> 00:23:57,060
into an ascii framework and that's great

00:23:51,030 --> 00:24:00,120
because we can use our test clients to

00:23:57,060 --> 00:24:02,010
test any ASCII web framework not just

00:24:00,120 --> 00:24:05,670
Starla but any of the other ones that we

00:24:02,010 --> 00:24:09,240
saw were up on the screen earlier or to

00:24:05,670 --> 00:24:11,640
test any micro you know any ASCII

00:24:09,240 --> 00:24:15,330
component as well so here we've just

00:24:11,640 --> 00:24:17,310
instantiate a response we're making a

00:24:15,330 --> 00:24:19,140
request out to it using the standard

00:24:17,310 --> 00:24:23,720
requests library with all of the

00:24:19,140 --> 00:24:23,720
standard API and behaviors requests

00:24:25,190 --> 00:24:29,809
the next place we said we're using it

00:24:27,919 --> 00:24:34,909
all the way through so of course web

00:24:29,809 --> 00:24:37,999
writing ASCII middleware as well now in

00:24:34,909 --> 00:24:41,659
say Django and lots of other web

00:24:37,999 --> 00:24:43,369
frameworks what happens with the HTTP

00:24:41,659 --> 00:24:45,679
dispatching is that the first thing that

00:24:43,369 --> 00:24:48,769
happens the request comes in we create

00:24:45,679 --> 00:24:51,229
some kind of request instance and then

00:24:48,769 --> 00:24:53,989
we pass our request instance all the way

00:24:51,229 --> 00:24:56,539
through a middleware stack that gets

00:24:53,989 --> 00:24:58,460
request instances calls into the next

00:24:56,539 --> 00:25:03,470
thing in the chain and returns response

00:24:58,460 --> 00:25:07,779
instances why why why wouldn't we want

00:25:03,470 --> 00:25:11,450
to do that sounds fine sounds good well

00:25:07,779 --> 00:25:13,549
what's nice about using ASCII as the

00:25:11,450 --> 00:25:18,909
middleware interface is that your

00:25:13,549 --> 00:25:24,220
middleware implementations are reusable

00:25:18,909 --> 00:25:27,919
across again any ASCII web framework

00:25:24,220 --> 00:25:31,070
they're also independently testable

00:25:27,919 --> 00:25:35,139
using the same test client that you use

00:25:31,070 --> 00:25:37,460
for testing everything else it's also

00:25:35,139 --> 00:25:39,950
important to don't design things in this

00:25:37,460 --> 00:25:42,499
way because if you build your middleware

00:25:39,950 --> 00:25:45,889
as a request response in space what do

00:25:42,499 --> 00:25:47,509
you do when you come to WebSockets we're

00:25:45,889 --> 00:25:50,359
going to build another different type of

00:25:47,509 --> 00:25:52,279
interface if you if you're working

00:25:50,359 --> 00:25:56,169
against the ascii interface it's much

00:25:52,279 --> 00:25:58,700
clearer how to build for example

00:25:56,169 --> 00:26:02,929
middleware that authenticates

00:25:58,700 --> 00:26:07,039
both HTTP and WebSocket requests based

00:26:02,929 --> 00:26:09,200
on the headers in either okay but as a

00:26:07,039 --> 00:26:12,229
developer you don't necessarily want to

00:26:09,200 --> 00:26:15,229
be working at that level or time no

00:26:12,229 --> 00:26:18,739
problem one of the things that starlett

00:26:15,229 --> 00:26:22,909
provides is a class that you can

00:26:18,739 --> 00:26:25,970
subclass that to you the end developer

00:26:22,909 --> 00:26:29,720
provides a request response interface

00:26:25,970 --> 00:26:33,200
but to the outside world provides the as

00:26:29,720 --> 00:26:35,889
ghee interface so when when the request

00:26:33,200 --> 00:26:40,179
comes in it creates a request instance

00:26:35,889 --> 00:26:43,250
sends it off to your dispatch method

00:26:40,179 --> 00:26:45,500
you call in to call next and it does the

00:26:43,250 --> 00:26:47,509
job of inspecting any messages come

00:26:45,500 --> 00:26:51,289
coming back down and marshalling those

00:26:47,509 --> 00:26:53,090
into response instances and that's great

00:26:51,289 --> 00:26:56,470
because you're working at the request

00:26:53,090 --> 00:26:59,090
response level but again you're building

00:26:56,470 --> 00:27:00,980
reusable middleware that we can share

00:26:59,090 --> 00:27:02,330
with the rest of the community and that

00:27:00,980 --> 00:27:06,559
when the rest of the community building

00:27:02,330 --> 00:27:10,519
mil where they can share with us what

00:27:06,559 --> 00:27:13,840
else mountable apps top example here if

00:27:10,519 --> 00:27:17,120
you want to build a file server in

00:27:13,840 --> 00:27:19,340
starlet's that's what you do you can run

00:27:17,120 --> 00:27:24,169
that top example with Daphne with hyper

00:27:19,340 --> 00:27:26,990
comm with you have a calm and and that

00:27:24,169 --> 00:27:30,169
will just work if you want to put that

00:27:26,990 --> 00:27:32,059
within your web application and serve

00:27:30,169 --> 00:27:35,690
static files within your web application

00:27:32,059 --> 00:27:37,669
you mount that to a particular endpoint

00:27:35,690 --> 00:27:40,549
and again we're building more and more

00:27:37,669 --> 00:27:43,580
reusable components a great example of

00:27:40,549 --> 00:27:46,700
this you know talking half an hour ago

00:27:43,580 --> 00:27:48,950
about re adding a graph QL server it so

00:27:46,700 --> 00:27:51,950
it has an ASCII interface you can just

00:27:48,950 --> 00:27:55,129
plug it straight in and it's not coupled

00:27:51,950 --> 00:28:00,340
to a particular web framework it's about

00:27:55,129 --> 00:28:00,340
ASCII another example class-based views

00:28:01,720 --> 00:28:07,340
similar sorts of thing the class-based

00:28:05,509 --> 00:28:10,580
views install xposed to ask Ian's face

00:28:07,340 --> 00:28:12,340
you can do interesting things like it

00:28:10,580 --> 00:28:17,779
you know that allows you to build out

00:28:12,340 --> 00:28:19,309
more high-level variations on this so if

00:28:17,779 --> 00:28:22,490
you want to build something that's like

00:28:19,309 --> 00:28:26,600
rest frameworks view sets or anything

00:28:22,490 --> 00:28:29,360
else like that one of the other things

00:28:26,600 --> 00:28:34,370
that and we'll see it again a bit later

00:28:29,360 --> 00:28:36,289
on is a point of difference is all the

00:28:34,370 --> 00:28:40,940
way through in this style of design

00:28:36,289 --> 00:28:43,940
we're using per component configuration

00:28:40,940 --> 00:28:47,629
okay so we're not using framework level

00:28:43,940 --> 00:28:50,960
settings that are then action over

00:28:47,629 --> 00:28:52,230
distance picked up somewhere inside the

00:28:50,960 --> 00:28:55,860
web framework not quite

00:28:52,230 --> 00:28:58,169
we're and have some kind of effect hard

00:28:55,860 --> 00:29:01,500
to see as a developer if you want to

00:28:58,169 --> 00:29:03,360
kind of plumb into what's happening here

00:29:01,500 --> 00:29:07,260
where where is this getting used and

00:29:03,360 --> 00:29:09,389
we're also not using application wide

00:29:07,260 --> 00:29:11,460
settings where we're plugging all of the

00:29:09,389 --> 00:29:14,190
configuration directly into this one

00:29:11,460 --> 00:29:18,200
single application instance so per

00:29:14,190 --> 00:29:21,299
component configuration which again

00:29:18,200 --> 00:29:23,880
helps with better riu shareable

00:29:21,299 --> 00:29:25,679
components across the ecosystem helps

00:29:23,880 --> 00:29:30,630
with being able to test components in

00:29:25,679 --> 00:29:33,450
isolation so on so what I think is

00:29:30,630 --> 00:29:36,360
interesting about some of the design in

00:29:33,450 --> 00:29:38,820
this is again you know all stuff that I

00:29:36,360 --> 00:29:41,159
hope as we're progressing on Jango can

00:29:38,820 --> 00:29:42,990
feed into some of the ASCII work that's

00:29:41,159 --> 00:29:44,820
going on there and it's all about the

00:29:42,990 --> 00:29:46,980
overall complexity of the stack right

00:29:44,820 --> 00:29:49,230
you've got this one single interface

00:29:46,980 --> 00:29:50,789
dial that runs all the way to very

00:29:49,230 --> 00:29:53,399
consistent you can use a test client

00:29:50,789 --> 00:29:57,360
with lots of different components it's

00:29:53,399 --> 00:29:58,769
very very composable it's also very

00:29:57,360 --> 00:30:01,139
performant because we're not introducing

00:29:58,769 --> 00:30:08,279
any extra abstractions on top of this in

00:30:01,139 --> 00:30:10,080
space staff hui lai me oh yeah I said

00:30:08,279 --> 00:30:12,570
that I say that we're not in the state

00:30:10,080 --> 00:30:16,889
so nobody picks me up for it but there

00:30:12,570 --> 00:30:21,240
we go um okay a sink

00:30:16,889 --> 00:30:31,190
great what about the database blimey

00:30:21,240 --> 00:30:36,029
we've got there is again okay Jango ORM

00:30:31,190 --> 00:30:39,570
SQL alchemy are both thread synchronous

00:30:36,029 --> 00:30:41,789
api's and not just that but if you go

00:30:39,570 --> 00:30:44,669
down to the lower levels there's

00:30:41,789 --> 00:30:47,580
something that is very analogous to

00:30:44,669 --> 00:30:50,970
whiskey in a way is the Python interface

00:30:47,580 --> 00:30:54,960
that is used to separate the database

00:30:50,970 --> 00:30:57,350
driver from the higher-level code that

00:30:54,960 --> 00:31:00,090
is working working with that driver

00:30:57,350 --> 00:31:02,700
it's also a trade synchronous interface

00:31:00,090 --> 00:31:04,950
and we've got lots and lots of folks

00:31:02,700 --> 00:31:06,090
who've been working in the async space

00:31:04,950 --> 00:31:10,170
developing

00:31:06,090 --> 00:31:12,870
database drivers but we don't have a

00:31:10,170 --> 00:31:14,850
standard interface on to them so it's

00:31:12,870 --> 00:31:17,790
difficult to start writing tolling that

00:31:14,850 --> 00:31:21,240
works together with SQL Lite and

00:31:17,790 --> 00:31:23,430
Postgres and MySQL I've recently

00:31:21,240 --> 00:31:27,720
released a package called databases

00:31:23,430 --> 00:31:30,180
which aims to address this it's not just

00:31:27,720 --> 00:31:32,490
to db-api exactly because it's a

00:31:30,180 --> 00:31:37,050
slightly different level of interface

00:31:32,490 --> 00:31:39,090
it's aimed to be something that is you

00:31:37,050 --> 00:31:41,970
know very developer folks facing

00:31:39,090 --> 00:31:44,940
interface you can use it to make raw SQL

00:31:41,970 --> 00:31:49,230
queries to any of those async database

00:31:44,940 --> 00:31:52,440
drivers you can also use it to work

00:31:49,230 --> 00:31:55,310
together with SQL alchemy core so the

00:31:52,440 --> 00:31:59,100
table definitions and the query builder

00:31:55,310 --> 00:32:01,080
which is an absolutely sell at all it's

00:31:59,100 --> 00:32:03,360
not all the way to an RM but it's a

00:32:01,080 --> 00:32:07,700
really productive level to be working at

00:32:03,360 --> 00:32:10,830
nonetheless it's also great because

00:32:07,700 --> 00:32:12,690
because it allows you to use SQL coming

00:32:10,830 --> 00:32:15,030
core if you write your table definitions

00:32:12,690 --> 00:32:19,260
using that you then have support for

00:32:15,030 --> 00:32:22,040
migrations using their Alembic which is

00:32:19,260 --> 00:32:25,560
you know analogous to Django's

00:32:22,040 --> 00:32:28,950
migrations and it provides transaction

00:32:25,560 --> 00:32:31,860
support as well and dealing where

00:32:28,950 --> 00:32:34,290
database connections sensibly and also

00:32:31,860 --> 00:32:39,000
that sort of stuff for you great so

00:32:34,290 --> 00:32:41,510
there's a low level answer to what do we

00:32:39,000 --> 00:32:47,880
need to do in the async land in order to

00:32:41,510 --> 00:32:49,620
address the database there but this

00:32:47,880 --> 00:32:52,110
there's still a component that's missing

00:32:49,620 --> 00:32:54,830
there which is a fully fledged ORM so

00:32:52,110 --> 00:32:57,660
I've also released another package

00:32:54,830 --> 00:33:01,710
independent of databases but built on

00:32:57,660 --> 00:33:06,620
top of it which is a Django like or the

00:33:01,710 --> 00:33:11,760
start of a Django like oh oh are M but

00:33:06,620 --> 00:33:13,710
asynchronous and again because it built

00:33:11,760 --> 00:33:17,070
onto the databases we still got the

00:33:13,710 --> 00:33:19,500
migration supports it's got a very

00:33:17,070 --> 00:33:20,010
Django like API it's not all the way

00:33:19,500 --> 00:33:22,080
there

00:33:20,010 --> 00:33:24,390
got a bunch of stuff in so we've got all

00:33:22,080 --> 00:33:28,290
of the different filter expressions and

00:33:24,390 --> 00:33:30,179
so on we've got support for foreign key

00:33:28,290 --> 00:33:32,880
relationships and we've got support for

00:33:30,179 --> 00:33:35,700
select related we don't have support for

00:33:32,880 --> 00:33:40,440
many to many yet or reverse foreign keys

00:33:35,700 --> 00:33:45,120
or prefetch related and if you're

00:33:40,440 --> 00:33:47,460
building an async ORM because IO always

00:33:45,120 --> 00:33:49,740
needs to be explicit there are a few

00:33:47,460 --> 00:33:54,059
things that we need to to do a little

00:33:49,740 --> 00:33:58,320
bit differently so for example in the

00:33:54,059 --> 00:34:01,230
Django RM if you've fetched a model

00:33:58,320 --> 00:34:04,080
instance you haven't fetched a

00:34:01,230 --> 00:34:06,059
relationship on it and you access that

00:34:04,080 --> 00:34:08,369
relationship on it it will go off and

00:34:06,059 --> 00:34:12,000
generate some SQL and resolve that

00:34:08,369 --> 00:34:18,149
automatically for you can't do that with

00:34:12,000 --> 00:34:20,429
with async you have to either call have

00:34:18,149 --> 00:34:24,899
called select related on it in the first

00:34:20,429 --> 00:34:27,060
place or explicitly load it and say I

00:34:24,899 --> 00:34:30,859
want to resolve this thing now and it

00:34:27,060 --> 00:34:30,859
will raise an error to you otherwise

00:34:31,730 --> 00:34:37,679
similar stuff with paging through query

00:34:35,550 --> 00:34:39,720
sets if you don't want to fetch the

00:34:37,679 --> 00:34:42,149
entire set of results in a query set all

00:34:39,720 --> 00:34:46,169
at once you need to do that explicitly

00:34:42,149 --> 00:34:49,320
than the syntax is it's an async

00:34:46,169 --> 00:34:53,460
iterator so it looks like a sink for

00:34:49,320 --> 00:34:55,080
instance in query sets but it's a bit

00:34:53,460 --> 00:35:00,150
different to being able to just do that

00:34:55,080 --> 00:35:02,720
implicitly in Django as well as looking

00:35:00,150 --> 00:35:05,640
a bit differently there are also

00:35:02,720 --> 00:35:08,460
benefits to this explicit style so I

00:35:05,640 --> 00:35:10,980
think a very large number of people in

00:35:08,460 --> 00:35:14,369
this room will have hid the types of

00:35:10,980 --> 00:35:16,740
cases where maybe you're working with

00:35:14,369 --> 00:35:18,660
your own codebase or you're working with

00:35:16,740 --> 00:35:21,119
a code base that you've recently come

00:35:18,660 --> 00:35:23,280
into and this view is running really

00:35:21,119 --> 00:35:25,500
really slowly why is that and you dig

00:35:23,280 --> 00:35:28,609
into and dig into it and you find that

00:35:25,500 --> 00:35:31,680
somewhere in the template code it's

00:35:28,609 --> 00:35:33,990
iterating over a query set and it's

00:35:31,680 --> 00:35:35,369
accessing some relationship or some

00:35:33,990 --> 00:35:38,670
fields on there that's not there and

00:35:35,369 --> 00:35:39,680
it's generating SQL queries again and

00:35:38,670 --> 00:35:44,369
again and again

00:35:39,680 --> 00:35:48,000
now in async you know in a standard

00:35:44,369 --> 00:35:50,490
starlett setup you can't run database

00:35:48,000 --> 00:35:53,220
queries in the templates at all

00:35:50,490 --> 00:35:55,770
it it stops you from doing that it

00:35:53,220 --> 00:35:57,990
ensures that anything that you're

00:35:55,770 --> 00:36:00,960
accessing you have loaded and if you try

00:35:57,990 --> 00:36:03,990
to load something without explicitly

00:36:00,960 --> 00:36:05,660
doing that it will raise you a great big

00:36:03,990 --> 00:36:08,400
error

00:36:05,660 --> 00:36:11,340
similarly you can't do database lookups

00:36:08,400 --> 00:36:13,890
in straw and you know I've worked with

00:36:11,340 --> 00:36:16,260
clients you go this thing is this bit in

00:36:13,890 --> 00:36:18,720
the admin he's running incredibly slowly

00:36:16,260 --> 00:36:20,369
why is that it's because you're you know

00:36:18,720 --> 00:36:22,350
when you're displaying your model

00:36:20,369 --> 00:36:26,880
instance you're generating sqr Gauri's

00:36:22,350 --> 00:36:30,960
you don't want to do that and having

00:36:26,880 --> 00:36:33,090
that tighter control yeah it's a bit

00:36:30,960 --> 00:36:37,500
more to think about but it's also huge

00:36:33,090 --> 00:36:39,720
benefits as well you know people run

00:36:37,500 --> 00:36:42,359
into this with Django and they go django

00:36:39,720 --> 00:36:45,859
slow well it's not know but it's

00:36:42,359 --> 00:36:48,500
allowing you to not look after yourself

00:36:45,859 --> 00:36:51,240
okay now this is a bit different okay

00:36:48,500 --> 00:36:53,820
but I've been working with it for a

00:36:51,240 --> 00:36:58,260
while and I really really like it now I

00:36:53,820 --> 00:37:01,080
really like it what else yeah there's

00:36:58,260 --> 00:37:02,810
even more to think about so you've gone

00:37:01,080 --> 00:37:04,920
to all this trouble of building

00:37:02,810 --> 00:37:07,470
potentially very high concurrency

00:37:04,920 --> 00:37:10,580
services you might want to be precise

00:37:07,470 --> 00:37:12,780
about how you think about concur

00:37:10,580 --> 00:37:15,480
database connections and database

00:37:12,780 --> 00:37:17,520
transactions so a really good example of

00:37:15,480 --> 00:37:21,060
this is if you are building micro

00:37:17,520 --> 00:37:25,290
services you've got a gateway API and

00:37:21,060 --> 00:37:28,680
the job of the Gateway API is to request

00:37:25,290 --> 00:37:31,470
comes in make a database access in order

00:37:28,680 --> 00:37:34,170
to authenticate the user great users

00:37:31,470 --> 00:37:36,960
authenticated go and sends an HTTP

00:37:34,170 --> 00:37:39,660
request out to some other service wait

00:37:36,960 --> 00:37:42,299
for the response sends it back to the

00:37:39,660 --> 00:37:46,140
end-user and what you don't want

00:37:42,299 --> 00:37:48,689
to do if you want to be able to build

00:37:46,140 --> 00:37:52,559
very high throughput services like that

00:37:48,689 --> 00:37:54,449
is hold on to your database connection

00:37:52,559 --> 00:37:57,029
or your especially not a database

00:37:54,449 --> 00:37:59,279
transaction for the entire duration of

00:37:57,029 --> 00:38:01,769
that HTTP request there's just no need

00:37:59,279 --> 00:38:05,009
you want to acquire your connection

00:38:01,769 --> 00:38:06,449
do your work let go of it then go and

00:38:05,009 --> 00:38:08,789
make your HTTP requests because that is

00:38:06,449 --> 00:38:10,349
a really really slow operation you don't

00:38:08,789 --> 00:38:11,969
want to be hanging on to this valuable

00:38:10,349 --> 00:38:15,209
system resource for the whole duration

00:38:11,969 --> 00:38:16,829
of it so for example databases is

00:38:15,209 --> 00:38:19,679
designed to be very liberal with

00:38:16,829 --> 00:38:22,499
acquiring and releasing connections to

00:38:19,679 --> 00:38:25,559
the connection pool unless you are

00:38:22,499 --> 00:38:28,049
explicitly within a transaction and

00:38:25,559 --> 00:38:32,309
there's other places to think about as

00:38:28,049 --> 00:38:34,829
well so if we want to have a sync HTTP

00:38:32,309 --> 00:38:38,309
requests the requests library doesn't

00:38:34,829 --> 00:38:41,160
give that to us out of the box yet okay

00:38:38,309 --> 00:38:44,880
I've just released a package recently

00:38:41,160 --> 00:38:46,529
requests a sink which is requests with a

00:38:44,880 --> 00:38:51,150
different adapter that makes

00:38:46,529 --> 00:38:52,859
asynchronous Network requests email

00:38:51,150 --> 00:38:56,099
really you want to make non-blocking

00:38:52,859 --> 00:38:58,709
SMTP requests there's a great library

00:38:56,099 --> 00:39:02,549
for that already cashing you're you know

00:38:58,709 --> 00:39:07,969
interacting with Redis or memcache again

00:39:02,549 --> 00:39:10,229
that's a network operation even

00:39:07,969 --> 00:39:12,929
validation right to be a building of

00:39:10,229 --> 00:39:17,099
validation like reformed validation API

00:39:12,929 --> 00:39:19,650
validation if you want to be able to

00:39:17,099 --> 00:39:22,829
perform any database queries within that

00:39:19,650 --> 00:39:24,359
you're going to need to be able to make

00:39:22,829 --> 00:39:28,589
sure that your validation library

00:39:24,359 --> 00:39:32,400
provides support for async methods as

00:39:28,589 --> 00:39:34,079
well and stuff like password hashing so

00:39:32,400 --> 00:39:36,599
password hashing is interesting because

00:39:34,079 --> 00:39:40,199
it's deliberately designed to run slowly

00:39:36,599 --> 00:39:45,509
and if you run something very very very

00:39:40,199 --> 00:39:47,849
very slowly in a single async task then

00:39:45,509 --> 00:39:48,239
what happens is all of that normal very

00:39:47,849 --> 00:39:49,769
fast

00:39:48,239 --> 00:39:52,049
interleaving between all of your

00:39:49,769 --> 00:39:54,269
different tasks stops happening and this

00:39:52,049 --> 00:39:56,140
one task is just hogging everything else

00:39:54,269 --> 00:40:00,040
up and these other tasks

00:39:56,140 --> 00:40:02,020
blocked so two different ways you can

00:40:00,040 --> 00:40:04,210
solve that either you can make sure that

00:40:02,020 --> 00:40:07,090
your password hashing is yielding to the

00:40:04,210 --> 00:40:08,590
other tasks lots of the ways through or

00:40:07,090 --> 00:40:11,050
you can take a simple approach you just

00:40:08,590 --> 00:40:12,670
dispatch it off to a thread you say okay

00:40:11,050 --> 00:40:16,590
go and run this thing enough threads

00:40:12,670 --> 00:40:19,840
don't block the main event loop so hey

00:40:16,590 --> 00:40:22,240
this is the stack of stuff that I've

00:40:19,840 --> 00:40:28,240
been working on recently and trying to

00:40:22,240 --> 00:40:31,000
lay a really healthy kind of groundwork

00:40:28,240 --> 00:40:34,150
for all of the async stuff that I think

00:40:31,000 --> 00:40:37,990
is about to be on the way at a very

00:40:34,150 --> 00:40:40,510
great rate let's take a look at how all

00:40:37,990 --> 00:40:42,250
of this stuff hangs together if you want

00:40:40,510 --> 00:40:46,810
to start building full stack web

00:40:42,250 --> 00:40:48,580
frameworks based on this don't worry if

00:40:46,810 --> 00:40:53,140
you can't read everything in the slide

00:40:48,580 --> 00:40:54,670
here it's not so bad right but it's just

00:40:53,140 --> 00:40:58,690
to give a bit of a flavor of a few

00:40:54,670 --> 00:41:01,300
different points of difference between

00:40:58,690 --> 00:41:05,530
what we're used to in Django and some of

00:41:01,300 --> 00:41:07,090
the design style here settings we're

00:41:05,530 --> 00:41:09,700
still pulling all of our settings

00:41:07,090 --> 00:41:12,340
together in the same place we're still

00:41:09,700 --> 00:41:16,450
using standard 12 factor configuration

00:41:12,340 --> 00:41:19,000
style but with then using those settings

00:41:16,450 --> 00:41:21,400
and pulling them into the components or

00:41:19,000 --> 00:41:23,770
the resources that we're using them

00:41:21,400 --> 00:41:31,480
within so they're less entangled in

00:41:23,770 --> 00:41:34,900
their design models kind of similar

00:41:31,480 --> 00:41:38,610
point here being the async landscape is

00:41:34,900 --> 00:41:42,910
really starting to mature type

00:41:38,610 --> 00:41:45,040
validation type system is a library that

00:41:42,910 --> 00:41:46,600
handles both API validation and former

00:41:45,040 --> 00:41:48,610
entering kind of similar to rest

00:41:46,600 --> 00:41:51,850
frameworks serializers but it's trimmed

00:41:48,610 --> 00:41:53,470
down a bit the difference here being our

00:41:51,850 --> 00:41:58,330
validation libraries need to be able to

00:41:53,470 --> 00:42:00,310
support async methods as well stop on

00:41:58,330 --> 00:42:02,050
install that we call them endpoints or

00:42:00,310 --> 00:42:05,830
in rest framework and glue they're in

00:42:02,050 --> 00:42:09,490
django views the interesting thing to

00:42:05,830 --> 00:42:10,060
kind of note here is it's very very

00:42:09,490 --> 00:42:12,250
clear where

00:42:10,060 --> 00:42:15,580
our database accesses are happening

00:42:12,250 --> 00:42:17,890
--gel or other or Network requests so

00:42:15,580 --> 00:42:19,930
we've got some views which are not async

00:42:17,890 --> 00:42:21,250
there's no database accesses that are

00:42:19,930 --> 00:42:26,590
happening in there they don't need to be

00:42:21,250 --> 00:42:27,880
async we can see exactly where stuffs

00:42:26,590 --> 00:42:33,430
happening with a database which is

00:42:27,880 --> 00:42:35,430
really great routing pretty similar

00:42:33,430 --> 00:42:37,390
we've talked about per component

00:42:35,430 --> 00:42:40,620
configuration and being able to mount

00:42:37,390 --> 00:42:43,570
ASCII apps and pulling it all together

00:42:40,620 --> 00:42:48,610
we've got a single app instance at the

00:42:43,570 --> 00:42:50,320
top which ends up just being a bunch of

00:42:48,610 --> 00:42:53,050
middleware that you pulled into it a

00:42:50,320 --> 00:42:55,000
couple of other default middlewares that

00:42:53,050 --> 00:42:56,770
it will always include because you

00:42:55,000 --> 00:43:00,480
pretty much always want them that deal

00:42:56,770 --> 00:43:04,330
with server errors or exception handling

00:43:00,480 --> 00:43:08,230
so the middleware and then the routing

00:43:04,330 --> 00:43:12,120
and that's it we've got something that's

00:43:08,230 --> 00:43:18,390
quite Django ish this is very very

00:43:12,120 --> 00:43:18,390
decoupled low low impact approach

00:43:19,530 --> 00:43:26,730
performs great in terms of throughputs

00:43:22,360 --> 00:43:30,910
as great as you could reasonably need

00:43:26,730 --> 00:43:35,410
it's able to support WebSockets or

00:43:30,910 --> 00:43:37,270
server sent events and various other

00:43:35,410 --> 00:43:40,660
stuff you know and background tasks we

00:43:37,270 --> 00:43:46,000
mentioned briefly and HTTP over to sort

00:43:40,660 --> 00:43:48,700
of push and it lets us do things that we

00:43:46,000 --> 00:43:53,230
just can't do with Django at the moment

00:43:48,700 --> 00:43:56,980
right so building API gateway services

00:43:53,230 --> 00:43:59,490
that can comfortably handle tens of

00:43:56,980 --> 00:44:04,450
thousands of requests per second

00:43:59,490 --> 00:44:07,180
building proxy services building graph

00:44:04,450 --> 00:44:10,540
QL backends with real-time subscription

00:44:07,180 --> 00:44:16,060
endpoints that can serve thousands of

00:44:10,540 --> 00:44:18,040
clients at the same time all things that

00:44:16,060 --> 00:44:20,650
we would really like to start to be able

00:44:18,040 --> 00:44:22,270
to push Django into the realm of and

00:44:20,650 --> 00:44:23,560
doing all the legwork for this and the

00:44:22,270 --> 00:44:26,170
other things that

00:44:23,560 --> 00:44:27,820
that we have is this very very composed

00:44:26,170 --> 00:44:31,930
style so we can start right at the

00:44:27,820 --> 00:44:35,710
bottom here a raw ASCII interface we can

00:44:31,930 --> 00:44:40,210
work away gradually up using individual

00:44:35,710 --> 00:44:45,370
as key components up to using these

00:44:40,210 --> 00:44:48,430
tools in a very micro framework ish way

00:44:45,370 --> 00:44:51,190
all the way up to using them in the same

00:44:48,430 --> 00:44:54,370
sort of way as a full stack web

00:44:51,190 --> 00:45:03,370
framework so what does this mean for

00:44:54,370 --> 00:45:04,870
Jack got a few things in tandem suppose

00:45:03,370 --> 00:45:06,310
it should be two things in terms and

00:45:04,870 --> 00:45:07,760
really I don't know what a three way

00:45:06,310 --> 00:45:10,050
bike school

00:45:07,760 --> 00:45:13,330
[Music]

00:45:10,050 --> 00:45:15,910
first of all progressively adding ASCII

00:45:13,330 --> 00:45:18,660
into a stack so Andrew Goldwyn has what

00:45:15,910 --> 00:45:21,030
I think is actually a very achievable

00:45:18,660 --> 00:45:24,310
proposal for how we would go about

00:45:21,030 --> 00:45:26,530
getting some aspects of this into Django

00:45:24,310 --> 00:45:28,510
starting off by adding an ASCII

00:45:26,530 --> 00:45:30,370
interface on to Django but running

00:45:28,510 --> 00:45:32,950
everything within thread pools beyond

00:45:30,370 --> 00:45:34,990
that then gradually you iterate and you

00:45:32,950 --> 00:45:37,330
build that out so that the middleware

00:45:34,990 --> 00:45:40,360
stack is ascii-based

00:45:37,330 --> 00:45:44,200
and at that point if you need to be able

00:45:40,360 --> 00:45:47,200
to drop into a sink in a view then you

00:45:44,200 --> 00:45:49,390
can your django components might not

00:45:47,200 --> 00:45:50,830
necessarily support it but you you know

00:45:49,390 --> 00:45:52,450
if you want to do a little bit if you

00:45:50,830 --> 00:45:56,170
don't mind doing a little bit of extra

00:45:52,450 --> 00:45:59,200
work you've got more power available to

00:45:56,170 --> 00:46:01,300
you and then it's rating on from there

00:45:59,200 --> 00:46:04,330
and looking at turning some of the

00:46:01,300 --> 00:46:05,980
components async along the way and the

00:46:04,330 --> 00:46:07,510
other things say you know there's a lot

00:46:05,980 --> 00:46:09,160
of ground work that's been done for this

00:46:07,510 --> 00:46:12,340
already things like the databases

00:46:09,160 --> 00:46:15,070
package could potentially be used in an

00:46:12,340 --> 00:46:17,860
async jungle and maybe we don't need an

00:46:15,070 --> 00:46:19,240
icing Django and maybe a one that just

00:46:17,860 --> 00:46:23,080
dispatches into the thread pool will

00:46:19,240 --> 00:46:25,090
work equally well but we've got a lot of

00:46:23,080 --> 00:46:28,060
groundwork laid as the points and at the

00:46:25,090 --> 00:46:31,090
same time as all of that pushing really

00:46:28,060 --> 00:46:34,300
hard to keep maturing the async

00:46:31,090 --> 00:46:36,830
landscape and in particular pushing

00:46:34,300 --> 00:46:41,060
really hard to do that in a way

00:46:36,830 --> 00:46:44,060
that is something that the whole

00:46:41,060 --> 00:46:46,340
community can share so getting behind as

00:46:44,060 --> 00:46:50,350
keys are standard because it allows us

00:46:46,340 --> 00:46:54,730
to work together really efficiently and

00:46:50,350 --> 00:46:58,540
I think that the Python community has a

00:46:54,730 --> 00:47:01,940
really important message here which is

00:46:58,540 --> 00:47:04,010
you know I don't think there's anything

00:47:01,940 --> 00:47:08,590
out there that beats Python for

00:47:04,010 --> 00:47:13,970
productivity it's absolutely awesome an

00:47:08,590 --> 00:47:16,940
async makes it competitive with the

00:47:13,970 --> 00:47:20,660
other big players in its zone with node

00:47:16,940 --> 00:47:22,640
and we go and bring support for

00:47:20,660 --> 00:47:29,000
real-time protocols and loads of other

00:47:22,640 --> 00:47:31,100
stuff you know to me if we can reach a

00:47:29,000 --> 00:47:33,860
great level of functionality with this

00:47:31,100 --> 00:47:36,370
stuff pythons really hitting the sweet

00:47:33,860 --> 00:47:36,370
spot there

00:47:40,270 --> 00:47:45,620
yeah I think it's a rich it's a really

00:47:43,910 --> 00:47:46,850
simple message and I think it's really

00:47:45,620 --> 00:47:52,220
powerful and I think it's one that we

00:47:46,850 --> 00:47:58,730
still need to start communicating to the

00:47:52,220 --> 00:48:01,580
rest of the world ok quickly all of the

00:47:58,730 --> 00:48:05,150
Django fellows work only ever happens

00:48:01,580 --> 00:48:08,030
because it's sponsored my time only

00:48:05,150 --> 00:48:14,210
happens because it's sponsored I think

00:48:08,030 --> 00:48:16,190
that's the the ask that we have when we

00:48:14,210 --> 00:48:20,150
say hey I want to work for your

00:48:16,190 --> 00:48:23,990
company's full time for 50 euros a month

00:48:20,150 --> 00:48:26,960
or 150 euros a month you know if your

00:48:23,990 --> 00:48:28,910
business is can see the potential of the

00:48:26,960 --> 00:48:32,540
impact that this sort of work

00:48:28,910 --> 00:48:34,430
plus the work on rest framework the 3.10

00:48:32,540 --> 00:48:36,830
that's coming out soon and the open API

00:48:34,430 --> 00:48:38,300
support is going to be in there and your

00:48:36,830 --> 00:48:39,920
companies are going to benefit from

00:48:38,300 --> 00:48:42,050
these things over the next year the next

00:48:39,920 --> 00:48:45,620
two years the next five years and into

00:48:42,050 --> 00:48:48,470
the long term I think the investment is

00:48:45,620 --> 00:48:50,540
just an absolute no-brainer so whether

00:48:48,470 --> 00:48:52,850
that is through the DSF

00:48:50,540 --> 00:48:55,100
through rest framework sponsorships

00:48:52,850 --> 00:48:58,100
whether it's through community events

00:48:55,100 --> 00:49:01,070
like this or django girls or local

00:48:58,100 --> 00:49:03,640
events in you something anything it's so

00:49:01,070 --> 00:49:12,290
important

00:49:03,640 --> 00:49:15,890
III also think in order for us to take

00:49:12,290 --> 00:49:17,870
things to the next level that we're

00:49:15,890 --> 00:49:22,100
going to need to find other monetization

00:49:17,870 --> 00:49:26,240
strategies as well and ones that benefit

00:49:22,100 --> 00:49:31,550
the community and I think for this to

00:49:26,240 --> 00:49:34,960
happen with frameworks like Django and

00:49:31,550 --> 00:49:39,640
like rails they need to be truly

00:49:34,960 --> 00:49:43,550
succeeding in the product space as well

00:49:39,640 --> 00:49:46,820
providing great products that are the

00:49:43,550 --> 00:49:51,020
fastest possible on-ramp for developers

00:49:46,820 --> 00:49:54,020
to get started with Django or with rails

00:49:51,020 --> 00:49:56,660
give developers the ability to start

00:49:54,020 --> 00:49:59,120
mocking out your API your API

00:49:56,660 --> 00:50:01,610
documentation or give developers the

00:49:59,120 --> 00:50:04,610
ability to start sketching out their

00:50:01,610 --> 00:50:07,220
admin and start putting data in there

00:50:04,610 --> 00:50:08,960
yes you might be limited to a certain

00:50:07,220 --> 00:50:10,880
number of rows in there we've got some

00:50:08,960 --> 00:50:13,190
constraints that we're not going to do

00:50:10,880 --> 00:50:15,770
it you know we're only gonna be with you

00:50:13,190 --> 00:50:18,020
for the prototyping stage but the goal

00:50:15,770 --> 00:50:22,010
of our product is to lose you as a user

00:50:18,020 --> 00:50:24,020
we want you to end up taking complete

00:50:22,010 --> 00:50:25,430
control of the framework at the end of

00:50:24,020 --> 00:50:27,740
the day will have a great big button

00:50:25,430 --> 00:50:30,950
there great let's get started on my

00:50:27,740 --> 00:50:32,930
product I'm happy with the prototyping

00:50:30,950 --> 00:50:35,840
stage our front-end teams been working

00:50:32,930 --> 00:50:38,660
against it and you know the end of the

00:50:35,840 --> 00:50:40,400
that's the most efficient thing for us

00:50:38,660 --> 00:50:42,380
to be doing for our developers at a

00:50:40,400 --> 00:50:46,160
certain point in the maturity of these

00:50:42,380 --> 00:50:49,670
frameworks and you know if we can do it

00:50:46,160 --> 00:50:53,810
we can nail it we could have we could

00:50:49,670 --> 00:50:57,620
have a company that just works on Django

00:50:53,810 --> 00:51:00,380
or starlets or the Python ecosystem full

00:50:57,620 --> 00:51:01,700
time and you know the more we can see we

00:51:00,380 --> 00:51:05,080
can succeed with this the more

00:51:01,700 --> 00:51:05,080
developers we can bring on board

00:51:10,790 --> 00:51:16,040
I was chatting over the slides with

00:51:12,740 --> 00:51:21,230
Carlton late last night and we went over

00:51:16,040 --> 00:51:24,070
these last three slides and some some of

00:51:21,230 --> 00:51:27,530
them up to him at the end of the sets

00:51:24,070 --> 00:51:30,620
first one is give us your money next one

00:51:27,530 --> 00:51:33,680
is here's how we make money and the last

00:51:30,620 --> 00:51:37,190
one is it's not about the money right

00:51:33,680 --> 00:51:39,920
and it's not it's really not you know

00:51:37,190 --> 00:51:43,520
the money's at all okay why are we here

00:51:39,920 --> 00:51:46,990
why do we care about open source right

00:51:43,520 --> 00:51:52,220
why have we all come together right our

00:51:46,990 --> 00:51:56,480
guiding light in all of this our thing

00:51:52,220 --> 00:51:59,980
that keeps us focused has to be you know

00:51:56,480 --> 00:52:06,200
impact on society betterment of society

00:51:59,980 --> 00:52:09,740
as this great quote by this an American

00:52:06,200 --> 00:52:12,110
Trappist monk Thomas More which is in a

00:52:09,740 --> 00:52:15,260
whim if we do not do this we may find

00:52:12,110 --> 00:52:18,080
ourselves climbing to the very top of

00:52:15,260 --> 00:52:19,640
the ladder of success only to find that

00:52:18,080 --> 00:52:25,720
the ladder has been leaning against the

00:52:19,640 --> 00:52:30,860
wrong wall okay and if we focus on our

00:52:25,720 --> 00:52:33,860
values rather than allowing them the raw

00:52:30,860 --> 00:52:38,600
power of the market to set the direction

00:52:33,860 --> 00:52:42,140
and the flow then we change the rules of

00:52:38,600 --> 00:52:44,120
the game and you help evolve the very

00:52:42,140 --> 00:52:50,210
currency with which the market actually

00:52:44,120 --> 00:52:51,950
trades in we oh hang on a minute I

00:52:50,210 --> 00:52:56,480
didn't show you my lovely bit that was

00:52:51,950 --> 00:53:03,350
this life or that one you know it's all

00:52:56,480 --> 00:53:09,800
about taking our individual creative

00:53:03,350 --> 00:53:13,490
spark our individual instinctive sense

00:53:09,800 --> 00:53:16,930
of empathy and working together as a

00:53:13,490 --> 00:53:20,750
community as a whole

00:53:16,930 --> 00:53:30,840
and as a society thank you

00:53:20,750 --> 00:53:30,840

YouTube URL: https://www.youtube.com/watch?v=u8GSFEg5lnU


