Title: DjangoCon 2019 - Here Come The Robots - Django and Machine Learning
Publication date: 2019-04-23
Playlist: DjangoCon Europe 2019 in Copenhagen
Description: 
	https://2019.djangocon.eu/talks/here-come-the-robots-django-and-machine-learning/

By Tom Dyson: https://twitter.com/tomd
Captions: 
	00:00:00,380 --> 00:00:07,770
hi everybody so this is me I'm also from

00:00:06,029 --> 00:00:10,019
torch Vox it's a kind of 1/2 thing with

00:00:07,770 --> 00:00:11,580
Neil and me tent this morning I'm the

00:00:10,019 --> 00:00:14,429
technical director at torch box we're a

00:00:11,580 --> 00:00:16,529
UK agency we we've been using Django

00:00:14,429 --> 00:00:18,990
since 2007 I think

00:00:16,529 --> 00:00:23,279
and we've perhaps best known for wagtail

00:00:18,990 --> 00:00:28,590
the the CMS that we made we five years

00:00:23,279 --> 00:00:31,170
ago I want to apologize for my click

00:00:28,590 --> 00:00:35,670
Beatty title this talk isn't really

00:00:31,170 --> 00:00:36,120
about robots or robots taking over the

00:00:35,670 --> 00:00:40,290
world

00:00:36,120 --> 00:00:42,149
but and in fact it's not really even

00:00:40,290 --> 00:00:45,000
about artificial intelligence artificial

00:00:42,149 --> 00:00:46,620
intelligence is just is it kind of

00:00:45,000 --> 00:00:50,579
despite the way it's mixed up in the

00:00:46,620 --> 00:00:52,199
media is a kind of superset of many

00:00:50,579 --> 00:00:55,860
technologies including machine learning

00:00:52,199 --> 00:00:59,000
so machine learning is one but also

00:00:55,860 --> 00:01:04,439
natural language processing translation

00:00:59,000 --> 00:01:07,200
robotics and it's a big area and but I

00:01:04,439 --> 00:01:08,580
do want to to just bend just five

00:01:07,200 --> 00:01:10,350
minutes talking about some of the big

00:01:08,580 --> 00:01:13,530
questions around artificial intelligence

00:01:10,350 --> 00:01:15,540
I have any of you read this book I

00:01:13,530 --> 00:01:18,509
really like this book by Max tegmark

00:01:15,540 --> 00:01:21,930
he's a physics professor at MIT and he

00:01:18,509 --> 00:01:25,290
talks about these three three phases

00:01:21,930 --> 00:01:29,430
like three releases of life

00:01:25,290 --> 00:01:31,590
the first one is version 1.0 this came

00:01:29,430 --> 00:01:35,670
out about four billion years ago I think

00:01:31,590 --> 00:01:38,939
and this is like bacteria or even

00:01:35,670 --> 00:01:40,490
chickens and two of the characteristics

00:01:38,939 --> 00:01:43,860
are going to main characteristics of

00:01:40,490 --> 00:01:47,130
release 1.0 of life or that they are

00:01:43,860 --> 00:01:49,770
unable to to change their own hardware

00:01:47,130 --> 00:01:51,869
their bodies all their software

00:01:49,770 --> 00:01:55,880
apart from by evolving which which takes

00:01:51,869 --> 00:02:00,570
many generations and then version 2

00:01:55,880 --> 00:02:05,670
version 2 is what max tegmark calls the

00:02:00,570 --> 00:02:07,560
the cultural age and with version 2 life

00:02:05,670 --> 00:02:09,840
still has the life form still have this

00:02:07,560 --> 00:02:13,540
limitation of not being able to manage

00:02:09,840 --> 00:02:17,049
its own hardware but version

00:02:13,540 --> 00:02:19,299
to humans and humans have been able to

00:02:17,049 --> 00:02:22,810
to manage to upgrade their own software

00:02:19,299 --> 00:02:25,750
so in this room we probably speak you

00:02:22,810 --> 00:02:28,329
know 15 languages and play 20 different

00:02:25,750 --> 00:02:32,099
musical instruments and have deep

00:02:28,329 --> 00:02:34,810
knowledge of many many various skills

00:02:32,099 --> 00:02:37,569
and these are things that we've in many

00:02:34,810 --> 00:02:40,120
cases decided to do so within our own

00:02:37,569 --> 00:02:41,950
lifetimes we can decide to change the

00:02:40,120 --> 00:02:45,819
way that we operate and pick up new

00:02:41,950 --> 00:02:48,519
skills and then you know affect our

00:02:45,819 --> 00:02:50,290
lives using those skills so that was a

00:02:48,519 --> 00:02:51,669
big change version 2.0 and actually

00:02:50,290 --> 00:02:54,669
there's a kind of side point that

00:02:51,669 --> 00:02:56,379
there's also a quick 2.1 release which

00:02:54,669 --> 00:02:59,290
which kind of maybe came out in the last

00:02:56,379 --> 00:03:01,209
50 50 years or so where humans are

00:02:59,290 --> 00:03:03,760
starting to kind of upgrade their bodies

00:03:01,209 --> 00:03:05,859
a little bit so you know false teeth or

00:03:03,760 --> 00:03:08,079
new knees sort of thing but still it's

00:03:05,859 --> 00:03:09,579
minor generally our Hardware only

00:03:08,079 --> 00:03:12,280
happens you know the changes are

00:03:09,579 --> 00:03:14,879
happening pretty gradually and of course

00:03:12,280 --> 00:03:19,479
the subject of the book is version 3.0

00:03:14,879 --> 00:03:21,970
in with version 3.0 the this this life

00:03:19,479 --> 00:03:24,430
form will also be able to to manage its

00:03:21,970 --> 00:03:27,849
own software but also its own hardware

00:03:24,430 --> 00:03:31,329
and and once that happens then you can

00:03:27,849 --> 00:03:34,530
get this really rapid rapid development

00:03:31,329 --> 00:03:38,019
unfortunately life 3.0 is not human life

00:03:34,530 --> 00:03:40,900
3.0 is this is the robots who are who

00:03:38,019 --> 00:03:43,030
will be able to upgrade themselves and

00:03:40,900 --> 00:03:44,470
and that's the kind of you know the

00:03:43,030 --> 00:03:47,169
premise of our kind of science fiction

00:03:44,470 --> 00:03:49,359
films we've seen about this stuff I find

00:03:47,169 --> 00:03:51,669
it really interesting that we seem to be

00:03:49,359 --> 00:03:54,310
right on the very cusp of this this

00:03:51,669 --> 00:03:57,099
massive change between version 2.0 and

00:03:54,310 --> 00:03:58,659
version 3.0 so the first one like I said

00:03:57,099 --> 00:04:01,959
four billion years ago roughly and then

00:03:58,659 --> 00:04:05,019
2.0 came out around 100,000 years ago

00:04:01,959 --> 00:04:06,729
and then this new phase and and I should

00:04:05,019 --> 00:04:11,109
say this is speculation right so there's

00:04:06,729 --> 00:04:13,859
a there's a lot of AI experts who have

00:04:11,109 --> 00:04:16,959
very different opinions about this but

00:04:13,859 --> 00:04:18,909
someone did a study about the the the

00:04:16,959 --> 00:04:20,709
mean point that way to be like great at

00:04:18,909 --> 00:04:23,620
the average point at which the experts

00:04:20,709 --> 00:04:24,639
think that we will reach this thing

00:04:23,620 --> 00:04:26,830
called artificial general intelligence

00:04:24,639 --> 00:04:28,960
where where can

00:04:26,830 --> 00:04:31,330
users are able to kind of have the sort

00:04:28,960 --> 00:04:34,150
of generalistic general skills that we

00:04:31,330 --> 00:04:38,349
have and the mean point is in about 30

00:04:34,150 --> 00:04:39,939
years time about 2050 and kind of feels

00:04:38,349 --> 00:04:40,990
extraordinary that we know this

00:04:39,939 --> 00:04:43,539
generation is right

00:04:40,990 --> 00:04:46,180
possibly on the cusp of this this like

00:04:43,539 --> 00:04:49,300
extraordinary change I don't know if

00:04:46,180 --> 00:04:51,699
it's and also you know is it a

00:04:49,300 --> 00:04:53,319
coincidence that a around the same time

00:04:51,699 --> 00:04:54,879
is possibly the you know where we're

00:04:53,319 --> 00:04:56,469
starting to feel like the most immediate

00:04:54,879 --> 00:04:58,840
effects of cataclysmic climate change

00:04:56,469 --> 00:05:00,190
and this again this could just be

00:04:58,840 --> 00:05:02,169
coincidence that these two things are

00:05:00,190 --> 00:05:05,219
happening at once or it could be just a

00:05:02,169 --> 00:05:08,560
kind of replay of this like Apocalypse

00:05:05,219 --> 00:05:09,879
Messiah kind of fantasies that people

00:05:08,560 --> 00:05:12,039
have had for the last from many

00:05:09,879 --> 00:05:14,919
millennia anyway I'm not here to talk

00:05:12,039 --> 00:05:18,039
about apocalypses I want to talk about

00:05:14,919 --> 00:05:19,659
machine learning and and so just a

00:05:18,039 --> 00:05:22,270
subset of AI and particularly within

00:05:19,659 --> 00:05:25,389
machine learning I like this this

00:05:22,270 --> 00:05:27,340
definition by Francois Shirley that

00:05:25,389 --> 00:05:29,770
classical programming so I guess the

00:05:27,340 --> 00:05:32,080
programming that most of us have have

00:05:29,770 --> 00:05:34,300
have been learning have we been working

00:05:32,080 --> 00:05:37,270
with uses rules and data to produce

00:05:34,300 --> 00:05:39,879
answers so we know what they're we know

00:05:37,270 --> 00:05:41,919
what the rules are and I will take some

00:05:39,879 --> 00:05:42,240
data and we'll make a decision based on

00:05:41,919 --> 00:05:44,860
that

00:05:42,240 --> 00:05:47,469
whereas machine learning uses data and

00:05:44,860 --> 00:05:49,210
answers and you give it to a computer

00:05:47,469 --> 00:05:50,800
and a computer creates the rules I think

00:05:49,210 --> 00:05:52,300
it's really nice simple definite

00:05:50,800 --> 00:05:53,589
definition that really kind of triggered

00:05:52,300 --> 00:05:57,729
to help them trigger my understanding of

00:05:53,589 --> 00:05:58,659
this instantly I recommend if you if you

00:05:57,729 --> 00:06:00,159
were interested in learning about

00:05:58,659 --> 00:06:00,909
machine learning from the kind of

00:06:00,159 --> 00:06:04,509
fundamentals

00:06:00,909 --> 00:06:06,219
I really recommend Shirley's book he's

00:06:04,509 --> 00:06:09,610
also the author of chaos which is

00:06:06,219 --> 00:06:11,409
perhaps the best-known Python library

00:06:09,610 --> 00:06:12,639
for machine learning and this is an

00:06:11,409 --> 00:06:13,990
excellent book about about the

00:06:12,639 --> 00:06:17,830
fundamentals and they kind of kind of

00:06:13,990 --> 00:06:19,300
the basic maths incidentally surely is

00:06:17,830 --> 00:06:21,460
one of the people who are skeptical

00:06:19,300 --> 00:06:23,620
about the artificial angelica and

00:06:21,460 --> 00:06:26,889
general intelligence he thinks that it's

00:06:23,620 --> 00:06:28,479
he can't see the possibility of making

00:06:26,889 --> 00:06:29,949
the leap between these very specialized

00:06:28,479 --> 00:06:33,310
skills that computers have now and the

00:06:29,949 --> 00:06:34,629
general skills that humans have but on

00:06:33,310 --> 00:06:37,800
the other hand he is very optimistic

00:06:34,629 --> 00:06:40,600
about the immediate effects that the

00:06:37,800 --> 00:06:42,700
beneficial effects of machine

00:06:40,600 --> 00:06:45,340
learning and that's what I'm going to

00:06:42,700 --> 00:06:48,400
talk about in this talk and so I want to

00:06:45,340 --> 00:06:51,550
talk about some really um practical and

00:06:48,400 --> 00:06:53,500
simple ways that we as django developers

00:06:51,550 --> 00:06:58,390
can take advantage of this kind of

00:06:53,500 --> 00:07:00,850
extreme amazing explosion of techniques

00:06:58,390 --> 00:07:03,880
and the first one is image recognition

00:07:00,850 --> 00:07:06,370
so some of you may have been to the the

00:07:03,880 --> 00:07:09,280
workshop yesterday on computer vision

00:07:06,370 --> 00:07:11,950
and and you might have learned how to

00:07:09,280 --> 00:07:15,640
identify shapes in a in a picture and

00:07:11,950 --> 00:07:18,250
and to make to decide whether a picture

00:07:15,640 --> 00:07:22,000
is about you know matches a certain set

00:07:18,250 --> 00:07:23,890
of characteristics but the idea that you

00:07:22,000 --> 00:07:27,040
could just get you know a million

00:07:23,890 --> 00:07:28,270
megapixels and a million pixels and send

00:07:27,040 --> 00:07:29,500
them to a computer and a computer be

00:07:28,270 --> 00:07:31,480
able to tell you what the contents are

00:07:29,500 --> 00:07:32,500
of of something of any angle even seven

00:07:31,480 --> 00:07:35,080
or eight years ago would have seemed

00:07:32,500 --> 00:07:37,980
like a futuristic impossible task but

00:07:35,080 --> 00:07:42,060
now it's something that we can do in

00:07:37,980 --> 00:07:44,830
about 15 lines of pretty cruddy Python

00:07:42,060 --> 00:07:46,780
so I've built a simple django app but

00:07:44,830 --> 00:07:48,370
I'm going to show you and which hooks

00:07:46,780 --> 00:07:49,930
into some of these services and I guess

00:07:48,370 --> 00:07:54,310
they're kind of key point of my talk is

00:07:49,930 --> 00:07:57,100
that you don't need to read Sciales book

00:07:54,310 --> 00:07:58,930
and you don't need to have a have like

00:07:57,100 --> 00:08:00,910
undergraduate level maths in order to do

00:07:58,930 --> 00:08:02,350
this stuff because other people have

00:08:00,910 --> 00:08:04,360
done it for you and you can hook into

00:08:02,350 --> 00:08:06,190
these surveys cheap services which are

00:08:04,360 --> 00:08:07,240
getting faster all the time I'm not

00:08:06,190 --> 00:08:09,610
saying you shouldn't I'm just saying you

00:08:07,240 --> 00:08:10,930
don't need to so in this case most of

00:08:09,610 --> 00:08:12,280
the work is around like reading the

00:08:10,930 --> 00:08:14,680
documentation and working out how to do

00:08:12,280 --> 00:08:16,750
authentication in different ways so

00:08:14,680 --> 00:08:18,820
we're just taking an image and posting

00:08:16,750 --> 00:08:20,650
it off in this case to microsoft's

00:08:18,820 --> 00:08:25,240
service and i'm going to attempt a live

00:08:20,650 --> 00:08:27,940
demo here so this is it robot tom

00:08:25,240 --> 00:08:29,560
dee-dawg you can try this later and i'm

00:08:27,940 --> 00:08:30,880
going to start by what this is an

00:08:29,560 --> 00:08:35,530
interesting image I found what do you

00:08:30,880 --> 00:08:37,300
think this is you're all muttering so I

00:08:35,530 --> 00:08:39,750
can't quite hear you but you probably

00:08:37,300 --> 00:08:45,070
write whatever you said so I'm going to

00:08:39,750 --> 00:08:48,880
post that in here and ask the computer

00:08:45,070 --> 00:08:51,100
to describe it for me and a person

00:08:48,880 --> 00:08:54,030
holding a bird pretty good pretty

00:08:51,100 --> 00:08:56,620
accurate maybe you know maybe

00:08:54,030 --> 00:09:00,490
such a difficult one this is my

00:08:56,620 --> 00:09:01,840
colleague Colin he doesn't actually he

00:09:00,490 --> 00:09:05,080
does have a beautiful red beard but he

00:09:01,840 --> 00:09:07,330
doesn't have those ears this let's try

00:09:05,080 --> 00:09:09,720
this it's going to be a bit more of a

00:09:07,330 --> 00:09:09,720
challenge

00:09:15,500 --> 00:09:21,570
dog in 20 member okay

00:09:18,780 --> 00:09:22,410
I mean you can see I can still have

00:09:21,570 --> 00:09:24,060
understand that they're like the

00:09:22,410 --> 00:09:25,470
bathroom sign in the back looks it makes

00:09:24,060 --> 00:09:26,850
it look like it you know it's one of

00:09:25,470 --> 00:09:29,460
those have a classic bathroom selfie

00:09:26,850 --> 00:09:33,000
shots and you know it's done a pretty

00:09:29,460 --> 00:09:35,930
good guess with that okay his here's a

00:09:33,000 --> 00:09:35,930
photo I took earlier

00:09:42,670 --> 00:09:47,690
Chango pony is it a close-up of logo no

00:09:46,040 --> 00:09:51,260
no it's not not accurate this is a

00:09:47,690 --> 00:09:52,970
distant picture of open or the life sign

00:09:51,260 --> 00:10:02,530
so I'm gonna try something a bit a bit

00:09:52,970 --> 00:10:08,120
more risky now okay take a picture of me

00:10:02,530 --> 00:10:15,920
click a man and a woman so this invasion

00:10:08,120 --> 00:10:20,450
I guess I'm not sure which one's the man

00:10:15,920 --> 00:10:23,780
and which one's a woman I only try down

00:10:20,450 --> 00:10:26,210
in you down this is the hot for me this

00:10:23,780 --> 00:10:27,500
was the hardest bit of the whole this

00:10:26,210 --> 00:10:29,420
whole site is working out how to get

00:10:27,500 --> 00:10:35,170
JavaScript to understand different

00:10:29,420 --> 00:10:40,250
camera types right everybody wave okay

00:10:35,170 --> 00:10:41,540
hey you'll stay pretty good group of

00:10:40,250 --> 00:10:52,040
people sitting front of a cloud pressing

00:10:41,540 --> 00:10:58,490
to the camera alright so that was image

00:10:52,040 --> 00:11:01,250
recognition there's some practical

00:10:58,490 --> 00:11:02,630
applications of this one is content

00:11:01,250 --> 00:11:04,550
management systems and best of all I'm

00:11:02,630 --> 00:11:06,410
going to show you next so cheap this is

00:11:04,550 --> 00:11:09,140
a demo that I built of some code that

00:11:06,410 --> 00:11:11,840
someone in this room wrote who I haven't

00:11:09,140 --> 00:11:13,910
met Martin you hear their ears motors

00:11:11,840 --> 00:11:16,910
put his hand up so this is again this is

00:11:13,910 --> 00:11:19,910
wagtail and I'm uploading the set of

00:11:16,910 --> 00:11:21,320
images from my from my machine and but

00:11:19,910 --> 00:11:24,410
it's moves quite quickly but what you

00:11:21,320 --> 00:11:25,970
can see here is that Wyatt L has taken

00:11:24,410 --> 00:11:28,490
the title and now already knows the

00:11:25,970 --> 00:11:30,800
titles of these images so that's my dog

00:11:28,490 --> 00:11:33,380
a Bracken a Bracken brown dog Nigel

00:11:30,800 --> 00:11:34,970
Farage wearing a bowtie this is some

00:11:33,380 --> 00:11:36,410
sardine heads in my sink that says a

00:11:34,970 --> 00:11:39,020
white plate covered in snow so that

00:11:36,410 --> 00:11:41,540
wasn't so good so clearly you know you

00:11:39,020 --> 00:11:42,850
can't rely on these completely this is

00:11:41,540 --> 00:11:45,020
not terribly aku and that's because

00:11:42,850 --> 00:11:46,160
again I use the Microsoft vision service

00:11:45,020 --> 00:11:48,550
of this Microsoft probably hasn't seen

00:11:46,160 --> 00:11:50,990
doesn't have many reference images of

00:11:48,550 --> 00:11:52,910
sinks filled with sardine heads yeah but

00:11:50,990 --> 00:11:54,500
it you know it will get better but I

00:11:52,910 --> 00:11:55,540
think this is a really used good way of

00:11:54,500 --> 00:11:58,360
using it because

00:11:55,540 --> 00:12:00,250
you don't need in this case we're not

00:11:58,360 --> 00:12:03,550
we're not relying on the machine to make

00:12:00,250 --> 00:12:05,529
exactly the right guess we're using it

00:12:03,550 --> 00:12:06,940
to to help us to sort of augment the

00:12:05,529 --> 00:12:08,199
editor experience and I think a lot of

00:12:06,940 --> 00:12:09,519
the time this these machine learning

00:12:08,199 --> 00:12:12,279
tools can be used in that way as

00:12:09,519 --> 00:12:16,269
substitute to currently to augment the

00:12:12,279 --> 00:12:17,949
ways that we're working already incident

00:12:16,269 --> 00:12:19,240
this this is not so relevant this is

00:12:17,949 --> 00:12:20,620
something that's happening more in the

00:12:19,240 --> 00:12:21,730
last I've seen more in the last couple

00:12:20,620 --> 00:12:23,800
of months so as well as recognition

00:12:21,730 --> 00:12:25,329
we're also seeing image generation

00:12:23,800 --> 00:12:27,459
systems and some of you may have seen

00:12:25,329 --> 00:12:29,290
this site that there was quite popular a

00:12:27,459 --> 00:12:31,269
few months ago a couple months ago this

00:12:29,290 --> 00:12:32,529
is not a real person calm I think so

00:12:31,269 --> 00:12:34,300
here's an example of someone who is not

00:12:32,529 --> 00:12:36,160
a real person and this is not this is

00:12:34,300 --> 00:12:38,019
not someone like this is not a computer

00:12:36,160 --> 00:12:39,940
program piecing together different parts

00:12:38,019 --> 00:12:41,320
of a person this is like building it up

00:12:39,940 --> 00:12:43,240
from the fundamentals and each time you

00:12:41,320 --> 00:12:45,190
refresh it creates a new one and it just

00:12:43,240 --> 00:12:46,570
looks pretty convincing you start to

00:12:45,190 --> 00:12:49,480
recognize the ways that it isn't quite

00:12:46,570 --> 00:12:50,529
right so generally focus on the face but

00:12:49,480 --> 00:12:51,970
you can see around the edges there's

00:12:50,529 --> 00:12:54,760
something pretty crazy going on also

00:12:51,970 --> 00:12:56,110
apparently teeth are hard to computers

00:12:54,760 --> 00:13:00,660
do at the moment so you often get these

00:12:56,110 --> 00:13:02,589
kind of slightly weird central teeth I

00:13:00,660 --> 00:13:04,000
mean normally I would feel rude about

00:13:02,589 --> 00:13:07,660
saying that but this isn't this is not a

00:13:04,000 --> 00:13:08,829
real person someone quickly afterwards

00:13:07,660 --> 00:13:12,420
made up this is not a real cat which I'm

00:13:08,829 --> 00:13:17,139
happy to say has not been so successful

00:13:12,420 --> 00:13:18,370
so you know the computers we're safe

00:13:17,139 --> 00:13:20,199
from the robots for that for the moment

00:13:18,370 --> 00:13:22,149
right the next one is about sentiment

00:13:20,199 --> 00:13:24,639
analysis this is another useful tool

00:13:22,149 --> 00:13:27,490
that you can you can use to add up to to

00:13:24,639 --> 00:13:29,319
augment your your Jango apps so

00:13:27,490 --> 00:13:31,149
sentiment analysis is a fancy way of

00:13:29,319 --> 00:13:33,069
saying what is the author feeling and

00:13:31,149 --> 00:13:35,560
again it isn't like they're like this

00:13:33,069 --> 00:13:37,569
the six lines of Python that you need in

00:13:35,560 --> 00:13:38,800
order to to take your text and send it

00:13:37,569 --> 00:13:40,000
away to this is one of these services in

00:13:38,800 --> 00:13:44,940
this case I'll use the ibm's watson

00:13:40,000 --> 00:13:44,940
service try a demo of this

00:13:54,110 --> 00:13:59,300
so I'll take some feedback and last

00:13:57,090 --> 00:14:02,550
night we went to this beautiful

00:13:59,300 --> 00:14:05,250
Ethiopian restaurant thank you very much

00:14:02,550 --> 00:14:06,480
the organizers for that and so I looked

00:14:05,250 --> 00:14:08,310
at some I looked at some of the reviews

00:14:06,480 --> 00:14:09,810
and there were very few bad reviews

00:14:08,310 --> 00:14:12,270
because it's such a great place but

00:14:09,810 --> 00:14:14,310
here's one there was the the author was

00:14:12,270 --> 00:14:19,350
furious that they only took Danish

00:14:14,310 --> 00:14:22,770
credit cards so we can try seeing what

00:14:19,350 --> 00:14:24,630
Watson thinks about this so Watson has

00:14:22,770 --> 00:14:28,310
understood that there's this you know

00:14:24,630 --> 00:14:30,300
quite a bit of sadness in this statement

00:14:28,310 --> 00:14:32,130
there's a bit of joy which is a bit

00:14:30,300 --> 00:14:33,960
surprising to me I suppose the joy is

00:14:32,130 --> 00:14:38,730
the the city full of wonderful

00:14:33,960 --> 00:14:40,740
restaurant and it's it's analytical on

00:14:38,730 --> 00:14:42,990
the other hand if we take one of the

00:14:40,740 --> 00:14:44,910
many positive reviews interestingly

00:14:42,990 --> 00:14:48,390
there's a there's another one here which

00:14:44,910 --> 00:14:49,560
is positive and just says accepted age

00:14:48,390 --> 00:14:50,700
because gods but there's an ATM just

00:14:49,560 --> 00:14:52,140
down the road so you'd think the first

00:14:50,700 --> 00:14:59,750
person could have I could just walk down

00:14:52,140 --> 00:15:02,160
the road in this case joyous is stronger

00:14:59,750 --> 00:15:03,660
it's a bit tentative I must say I

00:15:02,160 --> 00:15:06,380
haven't been that impressed with the

00:15:03,660 --> 00:15:08,730
with the Watson scores and I've just

00:15:06,380 --> 00:15:12,870
last night did a second one using the

00:15:08,730 --> 00:15:15,500
Google tool which is simpler so Google's

00:15:12,870 --> 00:15:16,950
doesn't doesn't try and work out

00:15:15,500 --> 00:15:18,480
different tones

00:15:16,950 --> 00:15:20,160
it just says whether positive or

00:15:18,480 --> 00:15:23,280
negative and it looks at magnitude as

00:15:20,160 --> 00:15:25,200
well so so magnitude is like the the

00:15:23,280 --> 00:15:26,820
strength of feelings so you might have a

00:15:25,200 --> 00:15:28,470
paragraph where you say I really hated

00:15:26,820 --> 00:15:30,690
this but I loved that and then you'd

00:15:28,470 --> 00:15:31,980
have quite high levels of magnitude but

00:15:30,690 --> 00:15:35,190
but the overall message would be neutral

00:15:31,980 --> 00:15:38,490
and so the Google results able to

00:15:35,190 --> 00:15:42,930
express that so what are some what are

00:15:38,490 --> 00:15:44,820
some practical applications of this so

00:15:42,930 --> 00:15:48,440
customer support is an obvious one -

00:15:44,820 --> 00:15:51,060
well if you get a lot of feedback and

00:15:48,440 --> 00:15:52,590
you want to know you want to maybe be

00:15:51,060 --> 00:15:54,120
get a trigger when this is something

00:15:52,590 --> 00:15:56,790
that's like a particularly angry message

00:15:54,120 --> 00:15:58,620
so you can deal with personally handling

00:15:56,790 --> 00:16:00,570
fake reviews could be good or better but

00:15:58,620 --> 00:16:02,480
so you know this increasing focus on

00:16:00,570 --> 00:16:06,740
bots and one of the things that makes

00:16:02,480 --> 00:16:08,510
a realistic bot is if you can detect the

00:16:06,740 --> 00:16:10,160
tone of the person who's asking you

00:16:08,510 --> 00:16:11,959
questions and that means that you're

00:16:10,160 --> 00:16:14,000
more likely to be able to give a kind of

00:16:11,959 --> 00:16:15,589
more human answer we're using this at

00:16:14,000 --> 00:16:18,620
the moment for one of our clients the

00:16:15,589 --> 00:16:20,600
Samaritans there in the UK a very well

00:16:18,620 --> 00:16:23,720
known organization who helped people in

00:16:20,600 --> 00:16:25,720
in crisis so people people who were you

00:16:23,720 --> 00:16:28,790
know thinking of hurting themselves and

00:16:25,720 --> 00:16:29,690
we are this will die over the phone at

00:16:28,790 --> 00:16:32,269
the moment but we're building an online

00:16:29,690 --> 00:16:34,040
chat service for them and one thing that

00:16:32,269 --> 00:16:36,949
we want to do is to be able to measure

00:16:34,040 --> 00:16:37,970
and I you know this is a surge is not

00:16:36,949 --> 00:16:40,100
going to be very accurate but I think

00:16:37,970 --> 00:16:42,920
over time we hopefully will see trends

00:16:40,100 --> 00:16:44,449
and be able to and start getting some

00:16:42,920 --> 00:16:47,959
data we hope will help them improve the

00:16:44,449 --> 00:16:51,290
service about about the measuring the

00:16:47,959 --> 00:16:53,810
the the state of feeling the sentiments

00:16:51,290 --> 00:16:56,000
during this journey next up is entity

00:16:53,810 --> 00:16:58,310
extraction and this is really about

00:16:56,000 --> 00:16:59,540
identifying proper nouns in a text which

00:16:58,310 --> 00:17:00,529
sounds like a simple thing to do so you

00:16:59,540 --> 00:17:02,209
could write a you know regular

00:17:00,529 --> 00:17:03,949
expression that looks for capital

00:17:02,209 --> 00:17:05,089
letters and tries to work out what your

00:17:03,949 --> 00:17:06,439
proper nouns but it turns out to be

00:17:05,089 --> 00:17:08,829
harder than that and you know different

00:17:06,439 --> 00:17:11,209
languages have different ways of of

00:17:08,829 --> 00:17:16,549
handling understanding what proper noun

00:17:11,209 --> 00:17:18,740
is so let's take some text from this one

00:17:16,549 --> 00:17:23,839
and this one I'm using again the Google

00:17:18,740 --> 00:17:26,419
natural language service and I'm going

00:17:23,839 --> 00:17:29,919
to take the first paragraph from the

00:17:26,419 --> 00:17:31,730
lovely website for this conference and

00:17:29,919 --> 00:17:34,490
Google's going to tell me what it thinks

00:17:31,730 --> 00:17:36,230
it's about so accualy understands that

00:17:34,490 --> 00:17:37,730
it's about Django corn Europe that was

00:17:36,230 --> 00:17:39,140
that was good and that is you know it's

00:17:37,730 --> 00:17:41,410
very much alike the two communities

00:17:39,140 --> 00:17:43,520
since probably something in my code

00:17:41,410 --> 00:17:46,309
there's a mistake obviously the the

00:17:43,520 --> 00:17:47,780
Django Unchained effect so it's it's

00:17:46,309 --> 00:17:49,160
identified the wrong sort of Django

00:17:47,780 --> 00:17:53,809
which is definitely what we don't want

00:17:49,160 --> 00:17:56,030
but interestingly if we then include the

00:17:53,809 --> 00:17:58,490
second paragraph which talks about

00:17:56,030 --> 00:18:04,669
Django is a technology or Conference

00:17:58,490 --> 00:18:07,010
values now extract again this time it

00:18:04,669 --> 00:18:09,169
understands that Django is this Django

00:18:07,010 --> 00:18:10,520
the web framework so I pulled a Google

00:18:09,169 --> 00:18:14,270
also gives you the Wikipedia links for

00:18:10,520 --> 00:18:15,200
each item and I think that's that's

00:18:14,270 --> 00:18:16,070
impressive and that's something that

00:18:15,200 --> 00:18:17,300
would be hard to do

00:18:16,070 --> 00:18:18,110
with a regular expression or hard to do

00:18:17,300 --> 00:18:19,430
if you were building the rules

00:18:18,110 --> 00:18:23,000
themselves it's using the context around

00:18:19,430 --> 00:18:27,760
the paragraph to understand the the what

00:18:23,000 --> 00:18:30,470
those entities are I've got some nice

00:18:27,760 --> 00:18:32,180
demos for this but I'm short on time so

00:18:30,470 --> 00:18:35,330
I'm going to skip this again there's a

00:18:32,180 --> 00:18:37,760
content management tool and we've done

00:18:35,330 --> 00:18:39,200
an integration with white L that tries

00:18:37,760 --> 00:18:41,380
to extract the kind of the themes from

00:18:39,200 --> 00:18:44,840
each piece of each each article and that

00:18:41,380 --> 00:18:47,000
means that you can start allowing users

00:18:44,840 --> 00:18:48,260
to if you're an editor of a website

00:18:47,000 --> 00:18:50,390
you've got a hundred pages you probably

00:18:48,260 --> 00:18:51,590
know you know how those pages link to

00:18:50,390 --> 00:18:52,790
each other how what the relevant themes

00:18:51,590 --> 00:18:54,620
are but if you were running a big news

00:18:52,790 --> 00:18:56,150
site with a million pages then it gets

00:18:54,620 --> 00:18:57,350
harder and harder to to establish the

00:18:56,150 --> 00:18:59,030
connections between all those pieces of

00:18:57,350 --> 00:19:00,800
content and but using tools like this

00:18:59,030 --> 00:19:02,810
auto tagging using entity extraction

00:19:00,800 --> 00:19:04,400
means that you can start creating this

00:19:02,810 --> 00:19:08,360
more kind of thematic natural way of

00:19:04,400 --> 00:19:09,920
browsing and the last wanting to talk

00:19:08,360 --> 00:19:11,240
about is outcome prediction and this is

00:19:09,920 --> 00:19:13,130
the kind of the lowest level one this is

00:19:11,240 --> 00:19:14,570
more like like the basic tools that you

00:19:13,130 --> 00:19:16,490
would use for building your own machine

00:19:14,570 --> 00:19:18,710
learning models and a way of thinking

00:19:16,490 --> 00:19:20,420
about this is just this is the kind of

00:19:18,710 --> 00:19:21,710
prediction so what will happen now given

00:19:20,420 --> 00:19:24,530
what we know about the past it's a bit

00:19:21,710 --> 00:19:27,980
like Shirley's rule is his definition of

00:19:24,530 --> 00:19:29,810
machine learning and you need to carry

00:19:27,980 --> 00:19:32,660
out these steps so this is this is not

00:19:29,810 --> 00:19:34,910
just firing a bit of you know you're a

00:19:32,660 --> 00:19:36,680
blob of text with ten lines of Python

00:19:34,910 --> 00:19:38,750
you need to do a bit more work you have

00:19:36,680 --> 00:19:40,520
to prepare your data then you have to

00:19:38,750 --> 00:19:41,960
train the model and then you have to

00:19:40,520 --> 00:19:43,700
evaluate whether or not that training is

00:19:41,960 --> 00:19:46,820
accurate and once you're happy with its

00:19:43,700 --> 00:19:49,760
accuracy then you can use it for this

00:19:46,820 --> 00:19:50,210
one I used the Amazon service and for

00:19:49,760 --> 00:19:53,330
the test

00:19:50,210 --> 00:19:56,050
I used this quite well known data sample

00:19:53,330 --> 00:19:58,010
so this is about hundreds creatures and

00:19:56,050 --> 00:20:01,220
we can see their names in the first

00:19:58,010 --> 00:20:02,750
column and then we are seeing there it's

00:20:01,220 --> 00:20:06,110
called features with basically their

00:20:02,750 --> 00:20:07,310
attributes so we can see the the blue is

00:20:06,110 --> 00:20:09,170
the hair column whether or not it has

00:20:07,310 --> 00:20:11,480
hair feathers so on whether it's

00:20:09,170 --> 00:20:14,300
airborne and generally when you are

00:20:11,480 --> 00:20:16,070
creating your training set you want to

00:20:14,300 --> 00:20:19,130
try to get the features in this into the

00:20:16,070 --> 00:20:22,280
state so so you where possible or you've

00:20:19,130 --> 00:20:23,510
got binary binary data for each feature

00:20:22,280 --> 00:20:25,100
and sometimes that's not possible but

00:20:23,510 --> 00:20:27,770
that's going to make it quick easier and

00:20:25,100 --> 00:20:29,600
quicker for your training while I was

00:20:27,770 --> 00:20:29,870
well I was doing this at most of the

00:20:29,600 --> 00:20:31,940
work

00:20:29,870 --> 00:20:34,070
around kind of working out how Amazon

00:20:31,940 --> 00:20:35,540
you know reading all the grim Amazon

00:20:34,070 --> 00:20:39,050
documentation and like I came across

00:20:35,540 --> 00:20:40,820
this tweet from Vicki bukas very very

00:20:39,050 --> 00:20:43,550
much recommend following developing

00:20:40,820 --> 00:20:44,780
Philadelphia who said about hottest

00:20:43,550 --> 00:20:49,340
programming skills getting info from AWS

00:20:44,780 --> 00:20:50,900
but I liked the fact that I managed to

00:20:49,340 --> 00:20:53,360
include this in a conference to talk

00:20:50,900 --> 00:20:57,890
about AI so I felt like it was a really

00:20:53,360 --> 00:20:59,300
really hot so this is how it looks in

00:20:57,890 --> 00:21:02,480
AWS once you get there at the right

00:20:59,300 --> 00:21:04,100
features in and then you create a model

00:21:02,480 --> 00:21:08,270
based on that data and you test it and

00:21:04,100 --> 00:21:11,390
then you are able to demo it so here's

00:21:08,270 --> 00:21:14,890
this the last one of our slot so someone

00:21:11,390 --> 00:21:17,030
there's someone suggest an animal animal

00:21:14,890 --> 00:21:24,050
that you're off okay does the draw of

00:21:17,030 --> 00:21:24,530
have hair feathers eggs milk is it

00:21:24,050 --> 00:21:28,850
airborne

00:21:24,530 --> 00:21:31,000
is it aquatic is it predator I don't

00:21:28,850 --> 00:21:33,380
know what is it a predator no tooth

00:21:31,000 --> 00:21:36,470
backbone does it breathe

00:21:33,380 --> 00:21:41,420
is it venomous does it have fins is f a

00:21:36,470 --> 00:21:43,730
tail is it domestic is it cat's eyes

00:21:41,420 --> 00:21:44,150
this is a weird one the cat's eyes all

00:21:43,730 --> 00:21:48,500
right

00:21:44,150 --> 00:21:52,820
see all right 98% confident you're a

00:21:48,500 --> 00:21:57,530
mammal and it's right and a lot of time

00:21:52,820 --> 00:21:58,910
I did this someone someone said well you

00:21:57,530 --> 00:22:01,250
know that's a stupid obviously if it's

00:21:58,910 --> 00:22:02,870
if it's milk it's got mo Venus in map

00:22:01,250 --> 00:22:03,770
mammal we know that right that's in

00:22:02,870 --> 00:22:05,150
there kind of you know we don't need

00:22:03,770 --> 00:22:07,580
computer to tell us that but I think

00:22:05,150 --> 00:22:09,200
that's a really nice example of the the

00:22:07,580 --> 00:22:10,520
Shirley thing right so that's the that's

00:22:09,200 --> 00:22:12,500
the like the classical programming

00:22:10,520 --> 00:22:14,030
version where where we know the rules we

00:22:12,500 --> 00:22:15,800
know that if it's if it is milk then

00:22:14,030 --> 00:22:17,150
it's a mammal but in this case we don't

00:22:15,800 --> 00:22:19,250
we don't know we just we're just giving

00:22:17,150 --> 00:22:25,400
it the data and it's working it out for

00:22:19,250 --> 00:22:26,980
us but giving it the data is something

00:22:25,400 --> 00:22:29,960
that you have to be really careful with

00:22:26,980 --> 00:22:32,360
and this is a section this is a really

00:22:29,960 --> 00:22:35,210
important point so here we can see that

00:22:32,360 --> 00:22:37,670
we look down there that's left here most

00:22:35,210 --> 00:22:39,460
of the bees are mammals most of the

00:22:37,670 --> 00:22:41,410
letters this is the

00:22:39,460 --> 00:22:44,170
the creatures that begin with B or once

00:22:41,410 --> 00:22:47,290
and you know it's possible that the rule

00:22:44,170 --> 00:22:49,900
that the engine could try and establish

00:22:47,290 --> 00:22:51,490
a pattern from that right and this is

00:22:49,900 --> 00:22:53,200
known as overfitting and machine

00:22:51,490 --> 00:22:54,970
learning and actually turns out you had

00:22:53,200 --> 00:22:56,800
to be quite careful not to let that

00:22:54,970 --> 00:22:59,200
happen

00:22:56,800 --> 00:23:00,880
and this this this starts playing out in

00:22:59,200 --> 00:23:02,020
some pretty unpleasant ways so they've

00:23:00,880 --> 00:23:04,380
been a few stories about this recently

00:23:02,020 --> 00:23:06,340
you might have seen this one that Amazon

00:23:04,380 --> 00:23:08,800
weirdly the Amazon would make this

00:23:06,340 --> 00:23:13,120
mistake created a recruiting tool based

00:23:08,800 --> 00:23:14,710
on AI machine learning they wanted an

00:23:13,120 --> 00:23:16,000
engine where it's going to give you 100

00:23:14,710 --> 00:23:17,830
resumes and it's going to spit out the

00:23:16,000 --> 00:23:19,780
top five and they'll hire those but

00:23:17,830 --> 00:23:21,640
basically but they quickly not that

00:23:19,780 --> 00:23:28,210
quickly they realized that the system

00:23:21,640 --> 00:23:30,250
was was becoming prejudiced because of

00:23:28,210 --> 00:23:31,810
course it was observing patterns and

00:23:30,250 --> 00:23:33,310
resumes that had happened before and

00:23:31,810 --> 00:23:34,480
this is you know a general point that we

00:23:33,310 --> 00:23:37,840
all have to be really careful about when

00:23:34,480 --> 00:23:39,610
we're training models the models that we

00:23:37,840 --> 00:23:41,620
use are going to include all the

00:23:39,610 --> 00:23:44,140
prejudices and mistakes that we have

00:23:41,620 --> 00:23:47,350
humans have made in the last in the last

00:23:44,140 --> 00:23:49,870
decades and if we just give that raw

00:23:47,350 --> 00:23:51,730
data to the computers to make new rules

00:23:49,870 --> 00:23:53,500
out of they are going to inherit those

00:23:51,730 --> 00:23:54,310
biases and those prejudices from us so

00:23:53,500 --> 00:23:55,720
this is something that we had to be

00:23:54,310 --> 00:24:00,790
really careful about as we're creating

00:23:55,720 --> 00:24:02,170
these models this this slide came out

00:24:00,790 --> 00:24:03,460
yesterday at Google cloud and it's

00:24:02,170 --> 00:24:05,080
interestingly that interesting to see

00:24:03,460 --> 00:24:07,210
that there's more and more awareness of

00:24:05,080 --> 00:24:09,580
it so they have a sfera where idea that

00:24:07,210 --> 00:24:11,140
and each point of the machine learning

00:24:09,580 --> 00:24:12,670
that the point of that documentation

00:24:11,140 --> 00:24:14,080
they're pointing out ways that you need

00:24:12,670 --> 00:24:16,570
to be careful about this bias which I'm

00:24:14,080 --> 00:24:17,950
really pleased about ok I'm nearly out

00:24:16,570 --> 00:24:19,630
of time I'm just gonna talk about what I

00:24:17,950 --> 00:24:21,670
think might be coming next in this world

00:24:19,630 --> 00:24:24,220
and the first one is around reduced

00:24:21,670 --> 00:24:27,040
complexity so this whole talk has been

00:24:24,220 --> 00:24:28,630
about ways that you can use these tools

00:24:27,040 --> 00:24:30,490
which of all you know they're all super

00:24:28,630 --> 00:24:32,410
cheap they're all like you know free

00:24:30,490 --> 00:24:34,840
tiers and then like thousand requests

00:24:32,410 --> 00:24:36,850
for a few dollars but you can use these

00:24:34,840 --> 00:24:38,260
tools to start injecting amazing

00:24:36,850 --> 00:24:40,540
abilities giving your giving your apps

00:24:38,260 --> 00:24:41,740
amazing abilities but I think the

00:24:40,540 --> 00:24:42,880
complexities are going to come down more

00:24:41,740 --> 00:24:44,080
and more so the Amazon one is the most

00:24:42,880 --> 00:24:47,740
complicated but that's getting simpler

00:24:44,080 --> 00:24:50,440
and simpler last month uber released

00:24:47,740 --> 00:24:52,120
this Ludwick tool and again it's in

00:24:50,440 --> 00:24:52,809
Python I mean we're lucky invited them

00:24:52,120 --> 00:24:54,159
because

00:24:52,809 --> 00:24:56,769
because this is where all the action is

00:24:54,159 --> 00:24:59,950
happening and with this story you you

00:24:56,769 --> 00:25:01,419
can just you just provide a CSV file and

00:24:59,950 --> 00:25:03,340
it will try to do the modeling for you

00:25:01,419 --> 00:25:07,299
so it's kind of just removing all these

00:25:03,340 --> 00:25:08,860
steps last night Google launched

00:25:07,299 --> 00:25:10,509
something similar or two ml tamper

00:25:08,860 --> 00:25:11,679
tables so this is similar you you just

00:25:10,509 --> 00:25:13,450
give some structured data and it will

00:25:11,679 --> 00:25:14,950
try and do it for you again I think if

00:25:13,450 --> 00:25:16,090
you were using these really automated

00:25:14,950 --> 00:25:21,370
tools you have to be very careful about

00:25:16,090 --> 00:25:24,549
not imbuing your past your your models

00:25:21,370 --> 00:25:26,080
with the biases of past generations also

00:25:24,549 --> 00:25:27,789
the generation thing so we looked at

00:25:26,080 --> 00:25:31,629
image generation but text generation is

00:25:27,789 --> 00:25:35,559
is happening to this the open AI group

00:25:31,629 --> 00:25:38,679
who quite controversially didn't open

00:25:35,559 --> 00:25:39,940
their last model called GPT to because

00:25:38,679 --> 00:25:42,369
of their ethical concerns about it

00:25:39,940 --> 00:25:42,850
because this is too good and as an

00:25:42,369 --> 00:25:44,860
example

00:25:42,850 --> 00:25:46,389
so they took 40 million articles from

00:25:44,860 --> 00:25:47,889
the internet and then they start giving

00:25:46,389 --> 00:25:49,659
it some sentences and then it and then

00:25:47,889 --> 00:25:52,330
it spits out more sentences and it they

00:25:49,659 --> 00:25:53,590
give it the sentence retitling is good

00:25:52,330 --> 00:25:54,879
for the world no you could not be more

00:25:53,590 --> 00:25:56,139
and more wrong and then the computer

00:25:54,879 --> 00:25:56,860
came back with we talking it's not good

00:25:56,139 --> 00:25:57,669
for the world it's bad for the

00:25:56,860 --> 00:25:58,990
environment it's bad for our health

00:25:57,669 --> 00:26:00,580
about formal economy I'm not kidding

00:25:58,990 --> 00:26:04,059
recycling is not is this sound like

00:26:00,580 --> 00:26:05,980
anyone to you you know this is scary and

00:26:04,059 --> 00:26:07,990
and it's something that we need to start

00:26:05,980 --> 00:26:11,559
dealing with is like it's understanding

00:26:07,990 --> 00:26:12,850
the fakes and finally I'm just going to

00:26:11,559 --> 00:26:14,710
talk about machine learning at the edge

00:26:12,850 --> 00:26:15,820
I think this isn't going to be a big

00:26:14,710 --> 00:26:17,529
trend in the next couple of years as

00:26:15,820 --> 00:26:19,629
well I have a Google pixel phone which

00:26:17,529 --> 00:26:21,159
and it's got this amazing camera I don't

00:26:19,629 --> 00:26:22,450
know if any of you've got this but the

00:26:21,159 --> 00:26:24,159
the most amazing thing about it is the

00:26:22,450 --> 00:26:26,559
nitesite vision has anyone experienced

00:26:24,159 --> 00:26:29,289
this and you take a picture in almost

00:26:26,559 --> 00:26:31,090
dark and it seems to kind of reveal

00:26:29,289 --> 00:26:32,320
stuff that the eye can't see

00:26:31,090 --> 00:26:35,460
and certainly the lens should be able to

00:26:32,320 --> 00:26:39,100
see and this is a combination of of like

00:26:35,460 --> 00:26:40,299
computer vision but also machine

00:26:39,100 --> 00:26:42,220
learning so it will take lots of little

00:26:40,299 --> 00:26:43,869
pictures it will it will adjust for the

00:26:42,220 --> 00:26:47,049
movement in your hands but then it will

00:26:43,869 --> 00:26:48,850
use machine learning model on the device

00:26:47,049 --> 00:26:50,860
to work out what the lighting should be

00:26:48,850 --> 00:26:52,360
based on all the other images that that

00:26:50,860 --> 00:26:54,369
the model had learned from and you come

00:26:52,360 --> 00:26:56,019
up these extraordinary realistic and

00:26:54,369 --> 00:26:56,259
believable which is that the eye can't

00:26:56,019 --> 00:26:58,389
see

00:26:56,259 --> 00:26:59,499
alright so next steps if you want to

00:26:58,389 --> 00:27:01,269
learn machine learning I really

00:26:59,499 --> 00:27:02,710
recommend France wash Allah's book deep

00:27:01,269 --> 00:27:04,240
learning with Python there's an amazing

00:27:02,710 --> 00:27:05,259
online resource called kaggle if you

00:27:04,240 --> 00:27:05,760
want to do something with machine

00:27:05,259 --> 00:27:07,320
learning there

00:27:05,760 --> 00:27:08,760
I should just read the docs of these

00:27:07,320 --> 00:27:10,310
various services and build something

00:27:08,760 --> 00:27:11,470
amazing thank you very much

00:27:10,310 --> 00:27:14,829
[Applause]

00:27:11,470 --> 00:27:14,829

YouTube URL: https://www.youtube.com/watch?v=6Z7uqx2lqT0


