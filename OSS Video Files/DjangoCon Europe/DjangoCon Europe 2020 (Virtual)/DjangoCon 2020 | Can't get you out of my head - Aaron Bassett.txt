Title: DjangoCon 2020 | Can't get you out of my head - Aaron Bassett
Publication date: 2020-09-30
Playlist: DjangoCon Europe 2020 (Virtual)
Description: 
	DjangoCon Europe 2020 (Virtual)
September 18, 2020 - 16h30 (GMT+1)

"Can't get you out of my head" by Aaron Bassett

Our devices are continually sending and receiving a complex set of instructions and information every time they interact over HTTP. While this mostly invisible interaction is primarily made up of the same standard set of attributes what oddities would we discover if we spidered 10,000,000 domains?
Captions: 
	00:00:07,040 --> 00:00:09,920
so

00:00:07,839 --> 00:00:11,280
i'm not sure if i was getting intro i

00:00:09,920 --> 00:00:12,000
wasn't sure about that part so i'm just

00:00:11,280 --> 00:00:14,639
going to go ahead

00:00:12,000 --> 00:00:15,920
i got my 3 2 1. um so hey everyone

00:00:14,639 --> 00:00:17,760
thanks joining me today for what i think

00:00:15,920 --> 00:00:18,640
you'll find is a bit of a different sort

00:00:17,760 --> 00:00:20,400
of talk

00:00:18,640 --> 00:00:21,760
but hopefully enjoyable and useful

00:00:20,400 --> 00:00:22,960
before i get started i'd just like to

00:00:21,760 --> 00:00:23,760
say a very big thank you to all the

00:00:22,960 --> 00:00:25,840
organizers

00:00:23,760 --> 00:00:26,960
and volunteers behind djangocon europe

00:00:25,840 --> 00:00:27,920
this has been an incredibly difficult

00:00:26,960 --> 00:00:29,599
year for everyone

00:00:27,920 --> 00:00:31,199
and also have the stress of having to

00:00:29,599 --> 00:00:32,480
switch from an in-person to totally

00:00:31,199 --> 00:00:35,360
virtual conference

00:00:32,480 --> 00:00:36,880
must have been an incredible burden but

00:00:35,360 --> 00:00:38,320
they've done a fantastic job

00:00:36,880 --> 00:00:40,719
and i just want to pause for a moment

00:00:38,320 --> 00:00:42,800
and just recognize that

00:00:40,719 --> 00:00:44,800
okay so i'm our ambassador you can find

00:00:42,800 --> 00:00:46,239
me online at most places twitter github

00:00:44,800 --> 00:00:48,640
etc as ironbox

00:00:46,239 --> 00:00:50,079
i know i'm so original i'm a giant ghost

00:00:48,640 --> 00:00:51,520
software foundation board member

00:00:50,079 --> 00:00:53,199
and a senior developer advocate with

00:00:51,520 --> 00:00:54,719
mongodb

00:00:53,199 --> 00:00:56,559
i think ic was one of my colleagues at

00:00:54,719 --> 00:00:57,920
mongodb and fellow conference speaker

00:00:56,559 --> 00:00:58,640
mark smith he come up with the title for

00:00:57,920 --> 00:01:00,160
this talk

00:00:58,640 --> 00:01:02,079
when i was telling him about my idea to

00:01:00,160 --> 00:01:03,359
attempt to catalog the most common http

00:01:02,079 --> 00:01:05,360
headers

00:01:03,359 --> 00:01:07,280
for those for anyone who doesn't

00:01:05,360 --> 00:01:09,200
recognize it can't get out of my head is

00:01:07,280 --> 00:01:10,080
the title of a 2001 track from kylie

00:01:09,200 --> 00:01:11,760
minogue

00:01:10,080 --> 00:01:13,920
and was i ever attempted to make this

00:01:11,760 --> 00:01:16,080
entire slide that kylie themed

00:01:13,920 --> 00:01:16,960
she's such a huge discography to draw

00:01:16,080 --> 00:01:19,920
inspiration from

00:01:16,960 --> 00:01:22,080
it would have been wild or could have

00:01:19,920 --> 00:01:23,680
gone like right back to her roots

00:01:22,080 --> 00:01:25,680
you know maybe look at some neighbors

00:01:23,680 --> 00:01:26,479
kind of stuff but talk takes a long time

00:01:25,680 --> 00:01:28,880
to repair

00:01:26,479 --> 00:01:30,720
and the ear room i would had to have the

00:01:28,880 --> 00:01:32,400
entire time would be horrendous

00:01:30,720 --> 00:01:33,840
so forgive me for going with this more

00:01:32,400 --> 00:01:35,360
mutual theme

00:01:33,840 --> 00:01:37,040
also this talk could have had a few

00:01:35,360 --> 00:01:40,960
different names

00:01:37,040 --> 00:01:44,159
um aaron sucks at estimates

00:01:40,960 --> 00:01:45,040
big numbers are hard when life gives you

00:01:44,159 --> 00:01:47,280
lemons

00:01:45,040 --> 00:01:48,720
write a conference talk you see when i

00:01:47,280 --> 00:01:50,479
first started to think about this

00:01:48,720 --> 00:01:51,600
project i really didn't appreciate just

00:01:50,479 --> 00:01:53,759
how many

00:01:51,600 --> 00:01:55,439
10 million domains is i knew it was a

00:01:53,759 --> 00:01:56,079
lot but after a certain number your

00:01:55,439 --> 00:01:57,759
brain just

00:01:56,079 --> 00:01:59,520
can't really estimate correctly or at

00:01:57,759 --> 00:02:00,719
least mine can't

00:01:59,520 --> 00:02:02,399
if you're being generous you could

00:02:00,719 --> 00:02:04,719
describe my approach to programming as

00:02:02,399 --> 00:02:06,079
explorative and results-orientated

00:02:04,719 --> 00:02:08,800
what that really means is i just chuck

00:02:06,079 --> 00:02:10,959
stuff at the wall and what sticks is

00:02:08,800 --> 00:02:12,000
hopefully normally good enough but when

00:02:10,959 --> 00:02:14,080
you're dealing with such a

00:02:12,000 --> 00:02:15,599
large starting data set even minor

00:02:14,080 --> 00:02:17,040
impacts and performance can create huge

00:02:15,599 --> 00:02:18,000
delays

00:02:17,040 --> 00:02:20,080
i've actually been working on this

00:02:18,000 --> 00:02:22,480
project on and off for over a year now

00:02:20,080 --> 00:02:25,200
i'm not a data scientist i've never done

00:02:22,480 --> 00:02:27,200
any major web scraping before i started

00:02:25,200 --> 00:02:28,879
like many of my ideas it started as a

00:02:27,200 --> 00:02:30,640
small curiosity what do

00:02:28,879 --> 00:02:32,000
other developers hide in their headers

00:02:30,640 --> 00:02:34,080
and then grew into

00:02:32,000 --> 00:02:35,360
quite a large undertaking it was a big

00:02:34,080 --> 00:02:36,959
learning curve for

00:02:35,360 --> 00:02:38,480
many false starts and lots of attempts

00:02:36,959 --> 00:02:40,000
which just didn't work

00:02:38,480 --> 00:02:42,160
so rather than just present the results

00:02:40,000 --> 00:02:43,519
of what i find in my final method

00:02:42,160 --> 00:02:46,400
i wanted to take you through the entire

00:02:43,519 --> 00:02:48,080
process problems mistakes and all

00:02:46,400 --> 00:02:49,840
it's not going to be a color by numbers

00:02:48,080 --> 00:02:50,400
guide for writing your own bret first

00:02:49,840 --> 00:02:52,319
web

00:02:50,400 --> 00:02:53,519
spider but instead i hope it will give

00:02:52,319 --> 00:02:54,640
you some insight into the overall

00:02:53,519 --> 00:02:56,480
approaches that worked

00:02:54,640 --> 00:02:58,080
and just as importantly the ones which

00:02:56,480 --> 00:02:59,920
didn't

00:02:58,080 --> 00:03:01,440
okay so let's start at the beginning

00:02:59,920 --> 00:03:02,159
where did i get the list of 10 million

00:03:01,440 --> 00:03:04,239
domains

00:03:02,159 --> 00:03:05,920
this is csv provided by domcot which

00:03:04,239 --> 00:03:08,480
they've compiled from common crawl

00:03:05,920 --> 00:03:09,840
and common search open data i can't say

00:03:08,480 --> 00:03:10,480
how accurate the data is and to be

00:03:09,840 --> 00:03:12,560
honest

00:03:10,480 --> 00:03:14,159
i wasn't overly concerned by that in

00:03:12,560 --> 00:03:15,440
this instance i was more interested in

00:03:14,159 --> 00:03:16,959
quantity over quality

00:03:15,440 --> 00:03:18,560
as long as majority of the domains

00:03:16,959 --> 00:03:20,959
existed and were active

00:03:18,560 --> 00:03:22,159
that was all i needed i wanted to see

00:03:20,959 --> 00:03:22,879
what developers were hiding in their

00:03:22,159 --> 00:03:24,799
headers

00:03:22,879 --> 00:03:26,799
i didn't care if those developers worked

00:03:24,799 --> 00:03:29,280
for the number one ranked website or the

00:03:26,799 --> 00:03:30,720
two million and fourth ranked actually

00:03:29,280 --> 00:03:32,319
if anything i assumed the higher ranked

00:03:30,720 --> 00:03:33,599
websites would be less likely to contain

00:03:32,319 --> 00:03:35,599
anything interesting

00:03:33,599 --> 00:03:38,400
as they wouldn't want to waste the bytes

00:03:35,599 --> 00:03:40,000
or be able to get it free code review

00:03:38,400 --> 00:03:42,080
with my starting data set of 10 million

00:03:40,000 --> 00:03:44,799
domains to begin working from

00:03:42,080 --> 00:03:46,560
i jump straight into the code so let's

00:03:44,799 --> 00:03:49,519
look at some of the ways that i

00:03:46,560 --> 00:03:50,959
totally messed that up okay so this is

00:03:49,519 --> 00:03:52,720
my very first attempt

00:03:50,959 --> 00:03:54,080
or an outline of it my plan is to use

00:03:52,720 --> 00:03:55,439
django management commands to read the

00:03:54,080 --> 00:03:57,200
domains from the csv

00:03:55,439 --> 00:03:58,879
fetch each with requests and store the

00:03:57,200 --> 00:04:00,560
headers returned in the response using

00:03:58,879 --> 00:04:03,200
the django orm

00:04:00,560 --> 00:04:04,799
a straightforward but ridiculously naive

00:04:03,200 --> 00:04:06,799
plan

00:04:04,799 --> 00:04:08,480
my script choked before i had a chance

00:04:06,799 --> 00:04:10,000
to get started

00:04:08,480 --> 00:04:11,680
apparently reading the entire 10 million

00:04:10,000 --> 00:04:14,560
line csv into memory

00:04:11,680 --> 00:04:16,079
wasn't a very good idea no big deal a

00:04:14,560 --> 00:04:18,560
quick google for read million row

00:04:16,079 --> 00:04:19,600
csv python i copy and paste from stack

00:04:18,560 --> 00:04:21,519
overflow

00:04:19,600 --> 00:04:23,280
install pandas and i was back in

00:04:21,519 --> 00:04:24,720
business

00:04:23,280 --> 00:04:26,479
i watched my script started fetching the

00:04:24,720 --> 00:04:28,560
first domains and i was happy that it

00:04:26,479 --> 00:04:30,160
was all working so i headed to bed

00:04:28,560 --> 00:04:33,120
a good night's sleep and i'd awake to a

00:04:30,160 --> 00:04:34,320
database of headers ready to explore

00:04:33,120 --> 00:04:36,479
i went to bed feeling good like

00:04:34,320 --> 00:04:38,080
everything was right with the world

00:04:36,479 --> 00:04:40,080
i think my script probably ran for about

00:04:38,080 --> 00:04:42,080
15 minutes before it totally died

00:04:40,080 --> 00:04:43,840
i'd made no attempt to cleanse the data

00:04:42,080 --> 00:04:45,600
i received an unchecked md value and

00:04:43,840 --> 00:04:47,199
that caused an exception

00:04:45,600 --> 00:04:49,680
so instead of awakening to a ready-to-go

00:04:47,199 --> 00:04:52,320
data set i was faced with a dead script

00:04:49,680 --> 00:04:54,240
and no easy way to resume it so let's

00:04:52,320 --> 00:04:55,840
give it another go

00:04:54,240 --> 00:04:57,199
this time i added some basic error

00:04:55,840 --> 00:04:58,240
checking and decided to run it while i

00:04:57,199 --> 00:04:59,520
was awake

00:04:58,240 --> 00:05:00,800
at least for a little while so i could

00:04:59,520 --> 00:05:02,160
deal with any exceptions as they

00:05:00,800 --> 00:05:05,280
occurred

00:05:02,160 --> 00:05:06,560
and it seemed to be running fine i

00:05:05,280 --> 00:05:08,240
checked the database

00:05:06,560 --> 00:05:10,400
did a quick calculation on how fast it

00:05:08,240 --> 00:05:12,240
was able to make requests and it seemed

00:05:10,400 --> 00:05:15,120
to be around 20 requests per minute or

00:05:12,240 --> 00:05:16,479
one every 30 seconds or so

00:05:15,120 --> 00:05:18,560
okay so i knew this wasn't exactly

00:05:16,479 --> 00:05:20,880
blazingly fast but i wasn't in a

00:05:18,560 --> 00:05:22,240
super big hurry either i could afford to

00:05:20,880 --> 00:05:24,240
leave it running for a couple of nights

00:05:22,240 --> 00:05:27,680
maybe a weekend and then get started in

00:05:24,240 --> 00:05:27,680
the fun part querying the data

00:05:27,919 --> 00:05:31,759
i was doing 20 requests per minute and i

00:05:30,000 --> 00:05:33,280
thought that might take a few days

00:05:31,759 --> 00:05:35,759
at most to go through like the 10

00:05:33,280 --> 00:05:38,240
million domains this is how bad i was at

00:05:35,759 --> 00:05:40,240
estimating big numbers

00:05:38,240 --> 00:05:41,600
you see 20 requests per minute means

00:05:40,240 --> 00:05:43,520
that it will take 500

00:05:41,600 --> 00:05:45,039
000 minutes to complete 10 million

00:05:43,520 --> 00:05:47,120
requests

00:05:45,039 --> 00:05:48,800
but how long is 500 000 minutes and days

00:05:47,120 --> 00:05:52,560
like i can't even fathom that

00:05:48,800 --> 00:05:53,759
well what's up it's about 347 days

00:05:52,560 --> 00:05:55,520
if i left the script running

00:05:53,759 --> 00:05:56,560
uninterrupted and if my throughput

00:05:55,520 --> 00:05:58,880
remained constant

00:05:56,560 --> 00:06:00,720
it would take almost a year to make my

00:05:58,880 --> 00:06:04,240
first pass over the demands

00:06:00,720 --> 00:06:05,919
but i had an epiphany i don't actually

00:06:04,240 --> 00:06:06,800
need to get the entire page in my

00:06:05,919 --> 00:06:08,560
request

00:06:06,800 --> 00:06:10,319
i don't care about the page content i

00:06:08,560 --> 00:06:11,039
just want the headers so i can use a

00:06:10,319 --> 00:06:12,639
head request

00:06:11,039 --> 00:06:15,120
and drastically reduce the size of my

00:06:12,639 --> 00:06:17,039
response like most people are aware of

00:06:15,120 --> 00:06:18,639
like get and post requests

00:06:17,039 --> 00:06:20,479
they probably make up like 90 of the

00:06:18,639 --> 00:06:22,880
requests performed every day but there

00:06:20,479 --> 00:06:24,880
are other http methods too

00:06:22,880 --> 00:06:26,000
you know put is number one you know put

00:06:24,880 --> 00:06:28,479
method will replace

00:06:26,000 --> 00:06:30,319
all current representations of a target

00:06:28,479 --> 00:06:32,160
with the request payload

00:06:30,319 --> 00:06:33,759
whereas the patch method is similar but

00:06:32,160 --> 00:06:34,720
it's used to apply a partial

00:06:33,759 --> 00:06:37,280
modification

00:06:34,720 --> 00:06:38,960
to the resource options method is used

00:06:37,280 --> 00:06:41,199
to describe the communication

00:06:38,960 --> 00:06:42,880
options available at the resource but

00:06:41,199 --> 00:06:44,720
one more interest in its head

00:06:42,880 --> 00:06:47,120
the head method asks for a response

00:06:44,720 --> 00:06:48,720
identical to that of a get request

00:06:47,120 --> 00:06:50,800
but we'll fight the response body

00:06:48,720 --> 00:06:53,520
amazing all the information we need

00:06:50,800 --> 00:06:55,280
nothing else i thought modify my script

00:06:53,520 --> 00:06:57,520
and try it again

00:06:55,280 --> 00:06:59,039
now we're at 30 requests a minute it's a

00:06:57,520 --> 00:07:02,560
considerable reduction

00:06:59,039 --> 00:07:06,319
one small change i'm already 30 faster

00:07:02,560 --> 00:07:09,440
my time had dropped to 333 333 minutes

00:07:06,319 --> 00:07:12,639
or 231 days which is

00:07:09,440 --> 00:07:14,160
still incredibly slow also my error rate

00:07:12,639 --> 00:07:15,759
had increased

00:07:14,160 --> 00:07:17,199
not all websites understand head

00:07:15,759 --> 00:07:19,360
requests so now

00:07:17,199 --> 00:07:20,639
i would have to retry my errors as get

00:07:19,360 --> 00:07:21,840
to be safe

00:07:20,639 --> 00:07:24,080
if anything this is going to make my

00:07:21,840 --> 00:07:25,759
overall time slower

00:07:24,080 --> 00:07:27,440
optimisation optimizations like changing

00:07:25,759 --> 00:07:29,360
the head just weren't going to be enough

00:07:27,440 --> 00:07:31,039
to cut it

00:07:29,360 --> 00:07:32,400
now i want to preface this by saying i'm

00:07:31,039 --> 00:07:34,160
a dsf board member and an active

00:07:32,400 --> 00:07:35,440
participant in django community

00:07:34,160 --> 00:07:37,280
if i'm starting a new web project

00:07:35,440 --> 00:07:38,160
there's a high chance i'll do it with

00:07:37,280 --> 00:07:40,639
django

00:07:38,160 --> 00:07:41,520
i'm a passionate django user i've been

00:07:40,639 --> 00:07:44,400
using django's

00:07:41,520 --> 00:07:45,840
before version one i built a range of

00:07:44,400 --> 00:07:47,039
applications of all shapes and sizes

00:07:45,840 --> 00:07:48,479
with it

00:07:47,039 --> 00:07:50,960
am i making it clear that i really like

00:07:48,479 --> 00:07:52,800
django but for this job it just wasn't

00:07:50,960 --> 00:07:55,840
the right tool

00:07:52,800 --> 00:07:57,120
so i rewrote the script and go i'm just

00:07:55,840 --> 00:07:58,800
kidding

00:07:57,120 --> 00:08:00,479
not about the jungle part that part's

00:07:58,800 --> 00:08:01,919
real but i didn't switch programming

00:08:00,479 --> 00:08:05,360
languages

00:08:01,919 --> 00:08:07,199
all i really needed was async

00:08:05,360 --> 00:08:08,960
python support for async programming has

00:08:07,199 --> 00:08:11,120
come on leaps and binds

00:08:08,960 --> 00:08:13,360
and it's an area which is seeming a lot

00:08:11,120 --> 00:08:16,319
of uptick in demand

00:08:13,360 --> 00:08:16,879
my script didn't use any async it was a

00:08:16,319 --> 00:08:19,360
single

00:08:16,879 --> 00:08:20,479
lone little worker bee a very hard

00:08:19,360 --> 00:08:21,840
working bee

00:08:20,479 --> 00:08:24,479
there's only so much they can do on

00:08:21,840 --> 00:08:26,400
their own so much of what i was doing

00:08:24,479 --> 00:08:28,560
was blocking as well including the two

00:08:26,400 --> 00:08:31,520
slowest parts making the hdp request

00:08:28,560 --> 00:08:33,919
and accessing the orm now hopefully this

00:08:31,520 --> 00:08:35,680
won't be the case in the future

00:08:33,919 --> 00:08:37,680
following our annual djangocon europe

00:08:35,680 --> 00:08:40,479
edition andrew godwin has already begun

00:08:37,680 --> 00:08:42,080
writing codes to make my talk obsolete

00:08:40,479 --> 00:08:43,519
i highly recommend you read his jungle

00:08:42,080 --> 00:08:45,360
enhancement proposal

00:08:43,519 --> 00:08:48,160
and then watch his talk tomorrow on how

00:08:45,360 --> 00:08:49,360
to break django with async

00:08:48,160 --> 00:08:51,200
i'm very much looking forward to it

00:08:49,360 --> 00:08:53,519
myself

00:08:51,200 --> 00:08:54,560
but at present django support for async

00:08:53,519 --> 00:08:56,320
isn't there

00:08:54,560 --> 00:08:57,600
i'm confident that it will be and i want

00:08:56,320 --> 00:09:00,320
to express my full backing for the

00:08:57,600 --> 00:09:01,600
workers going into making django wasting

00:09:00,320 --> 00:09:03,360
i look forward to when i can rewrite

00:09:01,600 --> 00:09:04,959
this project using django

00:09:03,360 --> 00:09:06,880
but for now i have to leave the safety

00:09:04,959 --> 00:09:07,440
of what i know behind and try something

00:09:06,880 --> 00:09:09,120
else

00:09:07,440 --> 00:09:10,800
for web scripting and their

00:09:09,120 --> 00:09:14,000
recommendations all seem to be

00:09:10,800 --> 00:09:15,760
scripting scrub is a python framework

00:09:14,000 --> 00:09:19,440
for building and running web spiders

00:09:15,760 --> 00:09:20,399
which sounds perfect maybe not quite

00:09:19,440 --> 00:09:22,560
actually you see

00:09:20,399 --> 00:09:24,000
scrippy is designed for depth not

00:09:22,560 --> 00:09:26,000
breadth

00:09:24,000 --> 00:09:27,279
what that means is that given a starting

00:09:26,000 --> 00:09:28,800
url and at depth

00:09:27,279 --> 00:09:30,720
sweeper will find and follow links and

00:09:28,800 --> 00:09:32,080
pages exploring deeper and deeper into a

00:09:30,720 --> 00:09:34,080
website

00:09:32,080 --> 00:09:36,000
but i'm not interested in depth my def

00:09:34,080 --> 00:09:37,200
is one maybe i actually have not point

00:09:36,000 --> 00:09:38,320
five i don't actually care about the

00:09:37,200 --> 00:09:41,120
page itself

00:09:38,320 --> 00:09:43,120
all i want is the headers when

00:09:41,120 --> 00:09:44,480
conducting a breadth crawl with scraping

00:09:43,120 --> 00:09:45,680
rather than giving it a small number of

00:09:44,480 --> 00:09:47,040
starting urls

00:09:45,680 --> 00:09:49,279
and letting it discover link server

00:09:47,040 --> 00:09:52,240
pages to crawl you must provide it with

00:09:49,279 --> 00:09:53,680
all the urls to crawl at the start

00:09:52,240 --> 00:09:55,600
the good news is i had a list of the

00:09:53,680 --> 00:09:58,000
urls i wanted the spider all

00:09:55,600 --> 00:09:59,600
10 million of them but i couldn't just

00:09:58,000 --> 00:10:00,000
read the csv and at the start of the

00:09:59,600 --> 00:10:01,279
crawl

00:10:00,000 --> 00:10:04,079
like i had attempted to do with my

00:10:01,279 --> 00:10:06,000
management come out

00:10:04,079 --> 00:10:07,279
would remove one of the main benefits of

00:10:06,000 --> 00:10:09,120
using scraping

00:10:07,279 --> 00:10:11,600
i wanted to give my little lone worker

00:10:09,120 --> 00:10:13,440
bee some friends

00:10:11,600 --> 00:10:15,120
with scraping i can run multiple spiders

00:10:13,440 --> 00:10:16,399
at the same time sharing the workload

00:10:15,120 --> 00:10:17,920
across them all

00:10:16,399 --> 00:10:19,760
but to do so they need to be able to

00:10:17,920 --> 00:10:20,720
claim a domain before they begin

00:10:19,760 --> 00:10:22,000
processing it

00:10:20,720 --> 00:10:23,760
so that multiple spiders are not

00:10:22,000 --> 00:10:25,279
fetching the same domain and wasting

00:10:23,760 --> 00:10:27,040
their effort

00:10:25,279 --> 00:10:28,320
a csv just wasn't going to cut it

00:10:27,040 --> 00:10:31,120
anymore

00:10:28,320 --> 00:10:33,040
so i imported it into mongodb i should

00:10:31,120 --> 00:10:35,519
point out this but i did use atlas

00:10:33,040 --> 00:10:36,160
my project atlas is mongodb's cloud

00:10:35,519 --> 00:10:38,640
managed

00:10:36,160 --> 00:10:39,839
database product it has a free tier but

00:10:38,640 --> 00:10:41,760
i had to use a paid tier

00:10:39,839 --> 00:10:43,200
through the volume of data i had however

00:10:41,760 --> 00:10:44,640
you can do all this open source

00:10:43,200 --> 00:10:46,720
community server edition

00:10:44,640 --> 00:10:47,839
or be there's nothing i'm doing here

00:10:46,720 --> 00:10:49,600
that is unique to atlas

00:10:47,839 --> 00:10:51,120
i'm just shifting the management of the

00:10:49,600 --> 00:10:52,560
server and backups to some of my

00:10:51,120 --> 00:10:54,320
colleagues

00:10:52,560 --> 00:10:55,680
it also means that after this talk i can

00:10:54,320 --> 00:10:57,680
make the data set public

00:10:55,680 --> 00:10:59,360
i'll be moving all 10 million domains

00:10:57,680 --> 00:11:01,760
and the complete results of my spider

00:10:59,360 --> 00:11:03,279
into our public open data project so

00:11:01,760 --> 00:11:04,320
anyone will have read access and be able

00:11:03,279 --> 00:11:07,440
to use the data

00:11:04,320 --> 00:11:09,200
in their own projects okay

00:11:07,440 --> 00:11:11,360
so with my domains in the database i can

00:11:09,200 --> 00:11:13,519
start to use it as a task queue

00:11:11,360 --> 00:11:15,120
this is the main part of my spider code

00:11:13,519 --> 00:11:15,760
it does it find in the database for the

00:11:15,120 --> 00:11:17,600
next domain

00:11:15,760 --> 00:11:19,200
list which is not complete and which is

00:11:17,600 --> 00:11:21,360
not currently in process

00:11:19,200 --> 00:11:22,880
and sets its processing status as true

00:11:21,360 --> 00:11:25,040
that way other spiders won't try and

00:11:22,880 --> 00:11:26,480
perform the same task

00:11:25,040 --> 00:11:28,160
once it spirals the headers for that

00:11:26,480 --> 00:11:29,360
domain it will see the results to the

00:11:28,160 --> 00:11:30,640
database and mark the domain is

00:11:29,360 --> 00:11:33,519
completed

00:11:30,640 --> 00:11:35,200
at this point the spider will go idle in

00:11:33,519 --> 00:11:36,800
scrapy once the spider goes idle if it

00:11:35,200 --> 00:11:37,839
doesn't receive any more jobs it will

00:11:36,800 --> 00:11:40,560
shut down

00:11:37,839 --> 00:11:41,200
i don't want this instead we use idle

00:11:40,560 --> 00:11:42,640
signal

00:11:41,200 --> 00:11:43,920
to request the next domain from the

00:11:42,640 --> 00:11:45,200
database it's not complete and

00:11:43,920 --> 00:11:46,560
non-process

00:11:45,200 --> 00:11:47,920
and we continue with this loop until

00:11:46,560 --> 00:11:49,360
there's no more incomplete domains to

00:11:47,920 --> 00:11:51,519
process

00:11:49,360 --> 00:11:53,519
nine even which is a single spider

00:11:51,519 --> 00:11:55,279
running like my request per minute

00:11:53,519 --> 00:11:57,519
increased a lot

00:11:55,279 --> 00:11:59,680
it tripled my speed and i started to

00:11:57,519 --> 00:12:00,880
feel much better about the time

00:11:59,680 --> 00:12:03,279
although i started to celebrate a little

00:12:00,880 --> 00:12:04,800
bit too early yes i was under a second

00:12:03,279 --> 00:12:05,920
per request on average but with 10

00:12:04,800 --> 00:12:09,040
million requests to do

00:12:05,920 --> 00:12:11,360
that still came out in 77 days why was

00:12:09,040 --> 00:12:13,680
it still so slow

00:12:11,360 --> 00:12:15,519
okay so i hadn't gone fully async the

00:12:13,680 --> 00:12:17,200
pymongo driver is blocking

00:12:15,519 --> 00:12:19,120
there is an async driver for

00:12:17,200 --> 00:12:20,480
called motor but i'd never attempted to

00:12:19,120 --> 00:12:22,079
use it with scrapy

00:12:20,480 --> 00:12:23,360
so i took the easy way out and decided

00:12:22,079 --> 00:12:24,959
to change my spider so instead of

00:12:23,360 --> 00:12:28,399
grabbing one url

00:12:24,959 --> 00:12:30,639
it would grab a batch of 2000 now

00:12:28,399 --> 00:12:32,240
when i was grabbing a single url i could

00:12:30,639 --> 00:12:33,360
use find one and update that would find

00:12:32,240 --> 00:12:35,519
a matching record

00:12:33,360 --> 00:12:38,880
update its processing status and return

00:12:35,519 --> 00:12:40,800
it all in a single transaction

00:12:38,880 --> 00:12:42,800
unfortunately mongodb doesn't have a

00:12:40,800 --> 00:12:45,920
find many an update method

00:12:42,800 --> 00:12:47,920
so i had to get a little hacky after i

00:12:45,920 --> 00:12:49,680
find my batch i take a list of the main

00:12:47,920 --> 00:12:51,440
ids and perform a second query

00:12:49,680 --> 00:12:53,360
to mark all the mains in the list is in

00:12:51,440 --> 00:12:55,120
process now there is a chance that

00:12:53,360 --> 00:12:56,639
spider could grab its own batch

00:12:55,120 --> 00:12:59,200
in the time between the separate find

00:12:56,639 --> 00:13:00,480
and update queries so added a very short

00:12:59,200 --> 00:13:01,760
random sleep at the start hopefully

00:13:00,480 --> 00:13:02,560
stagger when inspired a queries of

00:13:01,760 --> 00:13:03,920
database

00:13:02,560 --> 00:13:06,000
even if they're all spun up at exactly

00:13:03,920 --> 00:13:07,440
the same time

00:13:06,000 --> 00:13:09,279
but even with this hack and the

00:13:07,440 --> 00:13:10,800
potential for repeating work

00:13:09,279 --> 00:13:12,480
not having to query the database every

00:13:10,800 --> 00:13:13,519
single time caused another major

00:13:12,480 --> 00:13:16,480
performance bump

00:13:13,519 --> 00:13:17,519
this time up to 350 requests per minute

00:13:16,480 --> 00:13:18,959
that's

00:13:17,519 --> 00:13:20,800
two twenty eight thousand five percent

00:13:18,959 --> 00:13:22,800
one minutes to process all twen million

00:13:20,800 --> 00:13:23,839
domains which is roughly twenty days

00:13:22,800 --> 00:13:26,320
so we're not done in less than three

00:13:23,839 --> 00:13:27,680
weeks not quite a single weekend level i

00:13:26,320 --> 00:13:29,360
was aiming for but we're moving in the

00:13:27,680 --> 00:13:30,959
right direction

00:13:29,360 --> 00:13:32,720
we didn't think it would be that easy

00:13:30,959 --> 00:13:34,079
did you

00:13:32,720 --> 00:13:36,560
i began to notice that my spider's

00:13:34,079 --> 00:13:39,760
memory usage would increase over time

00:13:36,560 --> 00:13:41,120
i had a memory leak stopping the spider

00:13:39,760 --> 00:13:43,199
allowing it to begin from where it left

00:13:41,120 --> 00:13:45,040
off would solve the issue temporarily

00:13:43,199 --> 00:13:47,120
but it would only be a short time before

00:13:45,040 --> 00:13:48,800
it began to creep back up

00:13:47,120 --> 00:13:50,800
but if i stopped and started the spider

00:13:48,800 --> 00:13:52,560
often enough then the leak wouldn't have

00:13:50,800 --> 00:13:55,600
a chance to get too bad

00:13:52,560 --> 00:13:56,240
so that's exactly what i did it looked

00:13:55,600 --> 00:13:57,920
like two

00:13:56,240 --> 00:13:59,839
thousand domains was a sweet spot for

00:13:57,920 --> 00:14:01,920
harmony at spider process before the

00:13:59,839 --> 00:14:03,680
leak got too bad so i just had each

00:14:01,920 --> 00:14:05,199
spider pose as a single batch

00:14:03,680 --> 00:14:06,720
but i wouldn't have it fetched anymore

00:14:05,199 --> 00:14:08,079
when it became idle

00:14:06,720 --> 00:14:09,920
instead i allowed the spider to shut

00:14:08,079 --> 00:14:12,160
down once it finished the current batch

00:14:09,920 --> 00:14:13,839
and in a cron job running every minute

00:14:12,160 --> 00:14:15,519
would restart those spiders that it had

00:14:13,839 --> 00:14:17,120
stopped

00:14:15,519 --> 00:14:18,560
this means that no spider was ever awake

00:14:17,120 --> 00:14:19,920
for long enough for the memory to become

00:14:18,560 --> 00:14:22,000
a strain on my machine

00:14:19,920 --> 00:14:23,920
or even slow down the spider probably

00:14:22,000 --> 00:14:25,519
not the most efficient way though

00:14:23,920 --> 00:14:27,760
but i also moved my spiders to scraping

00:14:25,519 --> 00:14:30,000
hub scrubbing hub is a paid service for

00:14:27,760 --> 00:14:32,399
running imagining scrubby spiders

00:14:30,000 --> 00:14:33,760
it's not cheap but with scraping hub i

00:14:32,399 --> 00:14:35,600
could very quickly spin up multiple

00:14:33,760 --> 00:14:37,279
spiders and get my time down even

00:14:35,600 --> 00:14:39,279
further

00:14:37,279 --> 00:14:40,720
so assuming i get the cm 350 requests

00:14:39,279 --> 00:14:43,519
from minute on scraping hub is my local

00:14:40,720 --> 00:14:45,040
machine and i spin up six spiders

00:14:43,519 --> 00:14:47,360
then i could be finished in my three

00:14:45,040 --> 00:14:50,639
days i'd finally hit my target of

00:14:47,360 --> 00:14:53,199
done in a weekend again or

00:14:50,639 --> 00:14:54,959
like had i you see i had a bug in my

00:14:53,199 --> 00:14:56,560
code a really nasty one

00:14:54,959 --> 00:14:58,399
even when you work with a library every

00:14:56,560 --> 00:15:00,480
day it can be easy to overlook things

00:14:58,399 --> 00:15:02,560
the mongodb update method does not

00:15:00,480 --> 00:15:03,199
update all matches it only updates the

00:15:02,560 --> 00:15:04,639
first

00:15:03,199 --> 00:15:05,760
so when you give it that list of ids for

00:15:04,639 --> 00:15:07,279
all of the means in the batch it would

00:15:05,760 --> 00:15:10,839
only say the first one it matched

00:15:07,279 --> 00:15:12,320
is in process this was a really bad

00:15:10,839 --> 00:15:14,240
mistake

00:15:12,320 --> 00:15:15,680
okay so let's break down how my task was

00:15:14,240 --> 00:15:16,880
meant to work i'm going to look at what

00:15:15,680 --> 00:15:18,880
went wrong

00:15:16,880 --> 00:15:21,440
so each stack task starts like completed

00:15:18,880 --> 00:15:23,519
and processing set to false

00:15:21,440 --> 00:15:25,360
when a spider pulled a task to work on

00:15:23,519 --> 00:15:27,120
it was meant to set processing to true

00:15:25,360 --> 00:15:28,639
so other spiders wouldn't pull the same

00:15:27,120 --> 00:15:30,240
task

00:15:28,639 --> 00:15:31,839
then when a task was completed the

00:15:30,240 --> 00:15:34,240
spider would set processing back to

00:15:31,839 --> 00:15:36,160
false and completed the true

00:15:34,240 --> 00:15:37,759
there was a chance the task could feel

00:15:36,160 --> 00:15:38,560
and that instance completed would say as

00:15:37,759 --> 00:15:41,600
false

00:15:38,560 --> 00:15:43,199
and processing is true each task also

00:15:41,600 --> 00:15:43,440
had the date and time the spider pulled

00:15:43,199 --> 00:15:44,560
it

00:15:43,440 --> 00:15:47,279
along with a kind of a number of

00:15:44,560 --> 00:15:48,639
attempts the plan was that i would write

00:15:47,279 --> 00:15:50,480
a second spider

00:15:48,639 --> 00:15:52,639
which would find these stuck tasks and

00:15:50,480 --> 00:15:55,040
retry them until a number of attempts

00:15:52,639 --> 00:15:57,120
crossed some threshold i set

00:15:55,040 --> 00:15:59,759
but this would only work if processing

00:15:57,120 --> 00:16:01,600
was set to true when a task was pulled

00:15:59,759 --> 00:16:02,959
but because of my bug only the first

00:16:01,600 --> 00:16:04,880
matching matching task would be

00:16:02,959 --> 00:16:06,639
updated the rest would stay as false

00:16:04,880 --> 00:16:08,160
false

00:16:06,639 --> 00:16:10,959
so not only could spiders pull the same

00:16:08,160 --> 00:16:12,639
task to work on but of a task field

00:16:10,959 --> 00:16:15,040
that become permanently stuck up in the

00:16:12,639 --> 00:16:16,639
queue being pulled time and time again

00:16:15,040 --> 00:16:18,160
and blocking a valid task from taking

00:16:16,639 --> 00:16:20,959
the slot

00:16:18,160 --> 00:16:22,079
a bit like this so imagine this is our

00:16:20,959 --> 00:16:23,440
cue

00:16:22,079 --> 00:16:25,519
the green squares are tasks that will

00:16:23,440 --> 00:16:28,000
complete successfully the red squares or

00:16:25,519 --> 00:16:30,079
tasks which will always fail

00:16:28,000 --> 00:16:32,000
our worker lists tasks in batches of 15

00:16:30,079 --> 00:16:33,839
or one row at a time

00:16:32,000 --> 00:16:36,639
and those which which succeed are then

00:16:33,839 --> 00:16:38,880
removed from the pool we can see we have

00:16:36,639 --> 00:16:40,320
a lot more good tasks than bad

00:16:38,880 --> 00:16:42,959
but watch what happens after our first

00:16:40,320 --> 00:16:44,639
batch already that next match is

00:16:42,959 --> 00:16:45,920
starting to fill up with bad tasks

00:16:44,639 --> 00:16:47,680
which have no chance of ever being

00:16:45,920 --> 00:16:49,199
removed from the pool

00:16:47,680 --> 00:16:52,399
each time we pull a new batch we're

00:16:49,199 --> 00:16:54,160
getting fewer and fewer good tasks

00:16:52,399 --> 00:16:55,440
but even though we only have three good

00:16:54,160 --> 00:16:57,279
tasks in this batch

00:16:55,440 --> 00:16:58,800
our worker doesn't know that and will

00:16:57,279 --> 00:17:02,320
still attempt the process of 12

00:16:58,800 --> 00:17:03,680
bad tasks wasting even more time

00:17:02,320 --> 00:17:05,679
by now our error rates are through the

00:17:03,680 --> 00:17:06,319
roof and as bad tasks take longer than

00:17:05,679 --> 00:17:09,199
goods

00:17:06,319 --> 00:17:10,640
our requests for minutes plummeted our

00:17:09,199 --> 00:17:12,559
workers are still running but our queue

00:17:10,640 --> 00:17:15,439
is completely blocked

00:17:12,559 --> 00:17:18,400
no more good tasks can be completed it

00:17:15,439 --> 00:17:19,520
took me three days to spot that bug

00:17:18,400 --> 00:17:20,880
i originally thought that it was a

00:17:19,520 --> 00:17:22,480
problem with the dependability of the

00:17:20,880 --> 00:17:23,919
web the one she got beyond the top

00:17:22,480 --> 00:17:24,240
quarter million websites that it was

00:17:23,919 --> 00:17:27,120
just

00:17:24,240 --> 00:17:28,319
unreliable servers and dodgy connections

00:17:27,120 --> 00:17:29,919
because of course

00:17:28,319 --> 00:17:31,440
nine million seven hundred and fifty

00:17:29,919 --> 00:17:33,280
thousand developers had their servers

00:17:31,440 --> 00:17:35,200
configured wrong

00:17:33,280 --> 00:17:36,480
not that i had messed up my code that's

00:17:35,200 --> 00:17:38,000
definitely sounds like the more likely

00:17:36,480 --> 00:17:39,679
scenario

00:17:38,000 --> 00:17:41,360
it wasn't so i noticed that every spider

00:17:39,679 --> 00:17:42,000
was raising hundreds of exceptions each

00:17:41,360 --> 00:17:43,360
crawl

00:17:42,000 --> 00:17:45,360
but the number of domains stuck in

00:17:43,360 --> 00:17:49,039
processing was reasonably static

00:17:45,360 --> 00:17:51,039
but i realized why it happened but

00:17:49,039 --> 00:17:52,320
with update replaced by update many the

00:17:51,039 --> 00:17:53,840
crawl is finally able

00:17:52,320 --> 00:17:56,799
to process the mains at a reasonable

00:17:53,840 --> 00:17:58,080
speed it took a long time to get here

00:17:56,799 --> 00:17:59,919
and the spider is still running even as

00:17:58,080 --> 00:18:00,960
i'm speaking right now so was it worth

00:17:59,919 --> 00:18:04,640
it

00:18:00,960 --> 00:18:05,919
what sort of things did i find well

00:18:04,640 --> 00:18:07,679
even with the crawl only partially

00:18:05,919 --> 00:18:09,760
complete there's already millions upon

00:18:07,679 --> 00:18:10,880
millions of headers recorded

00:18:09,760 --> 00:18:13,520
checking each one for something

00:18:10,880 --> 00:18:15,600
interesting just isn't feasible

00:18:13,520 --> 00:18:16,960
but we can probably safely ignore the

00:18:15,600 --> 00:18:18,640
really common ones

00:18:16,960 --> 00:18:20,640
these will be the boring default headers

00:18:18,640 --> 00:18:22,320
that every response sends

00:18:20,640 --> 00:18:24,080
we can also probably ignore headers that

00:18:22,320 --> 00:18:26,000
appear only once

00:18:24,080 --> 00:18:27,360
sure we're likely to miss some things

00:18:26,000 --> 00:18:28,559
that might be interesting but the few

00:18:27,360 --> 00:18:30,160
interesting headers will likely be

00:18:28,559 --> 00:18:30,799
drawing out a number of auto-generated

00:18:30,160 --> 00:18:33,840
keys

00:18:30,799 --> 00:18:35,120
containing ids or etc

00:18:33,840 --> 00:18:37,360
we'll also only look at headers which

00:18:35,120 --> 00:18:38,559
begin with the x dash convention

00:18:37,360 --> 00:18:40,480
if someone is knowledgeable enough to

00:18:38,559 --> 00:18:41,760
add their own custom headers

00:18:40,480 --> 00:18:44,240
they'll probably also know about the

00:18:41,760 --> 00:18:46,080
convention this should give us a good

00:18:44,240 --> 00:18:47,600
starting point

00:18:46,080 --> 00:18:49,360
nine our headers are still stored as a

00:18:47,600 --> 00:18:50,720
dictionary so probably want to transform

00:18:49,360 --> 00:18:52,320
that into an array first to make it

00:18:50,720 --> 00:18:55,520
easier to run queries against dictionary

00:18:52,320 --> 00:18:56,880
keys as well as the values

00:18:55,520 --> 00:18:58,160
this is an example of an aggregation i

00:18:56,880 --> 00:18:59,360
wrote to perform the steps we've just

00:18:58,160 --> 00:19:02,400
talked about

00:18:59,360 --> 00:19:03,840
each aggregation runs in multiple stages

00:19:02,400 --> 00:19:06,240
first i did the transformation to an

00:19:03,840 --> 00:19:08,080
array then i unwind it so each header is

00:19:06,240 --> 00:19:09,919
in his own document

00:19:08,080 --> 00:19:11,840
i match only those headers which start

00:19:09,919 --> 00:19:13,600
with an x dash

00:19:11,840 --> 00:19:15,520
something and then i group them all by

00:19:13,600 --> 00:19:16,720
their keys and count how many of each

00:19:15,520 --> 00:19:18,240
there are

00:19:16,720 --> 00:19:20,160
finally i use that kind to filter the

00:19:18,240 --> 00:19:22,240
headers which occur only once

00:19:20,160 --> 00:19:25,280
and those which are too popular to give

00:19:22,240 --> 00:19:26,960
this hopefully an interesting set

00:19:25,280 --> 00:19:28,640
so running this query the first thing i

00:19:26,960 --> 00:19:29,280
noticed was a lot of cache management

00:19:28,640 --> 00:19:31,440
headers

00:19:29,280 --> 00:19:33,120
it's almost as if every cache middleware

00:19:31,440 --> 00:19:34,320
has their own header format

00:19:33,120 --> 00:19:36,160
i really expect to see a lot more

00:19:34,320 --> 00:19:37,440
standardization to be honest

00:19:36,160 --> 00:19:39,760
for the most part the cache headers were

00:19:37,440 --> 00:19:43,600
incredibly dull with the exception of

00:19:39,760 --> 00:19:45,120
back cache whose header no no no no no

00:19:43,600 --> 00:19:46,559
although next i'll probably add and not

00:19:45,120 --> 00:19:48,400
close my query to filter out these cache

00:19:46,559 --> 00:19:50,720
headers and clear out some of the noise

00:19:48,400 --> 00:19:52,880
even if it did mean missing out on a bit

00:19:50,720 --> 00:19:55,520
of a

00:19:52,880 --> 00:19:56,320
there's also a lot of power by headers

00:19:55,520 --> 00:19:58,960
mostly

00:19:56,320 --> 00:20:00,720
php and wordpress and i did spot a few

00:19:58,960 --> 00:20:01,840
empowered by headers though these were

00:20:00,720 --> 00:20:04,320
cute

00:20:01,840 --> 00:20:07,360
the few that i saw seem to be from some

00:20:04,320 --> 00:20:09,360
in high cms called freedom

00:20:07,360 --> 00:20:11,840
sony has an easter egg in their headers

00:20:09,360 --> 00:20:14,159
across several of their sites

00:20:11,840 --> 00:20:15,679
searches for the value of the easter egg

00:20:14,159 --> 00:20:17,360
bring back nothing

00:20:15,679 --> 00:20:19,120
so take a look at the headers on pro dot

00:20:17,360 --> 00:20:21,360
sony and maybe you could be the first to

00:20:19,120 --> 00:20:23,520
solve it

00:20:21,360 --> 00:20:24,400
a lot of different seemingly unrelated

00:20:23,520 --> 00:20:26,799
sites as an ex

00:20:24,400 --> 00:20:27,760
olaf header with the value of an emoji

00:20:26,799 --> 00:20:29,280
snowman

00:20:27,760 --> 00:20:31,760
i have to admit i had no idea what it

00:20:29,280 --> 00:20:33,840
could mean until i googled it

00:20:31,760 --> 00:20:36,159
this do not hack header points to a

00:20:33,840 --> 00:20:39,120
sanction in a legal document

00:20:36,159 --> 00:20:40,480
u.s code title 18 crimes and criminal

00:20:39,120 --> 00:20:42,720
procedure part 1

00:20:40,480 --> 00:20:44,720
crimes chapter 47 fraud and false

00:20:42,720 --> 00:20:46,320
statements section 1030

00:20:44,720 --> 00:20:48,640
fraud and related activity in connection

00:20:46,320 --> 00:20:49,919
with computers a full-proof method of

00:20:48,640 --> 00:20:51,360
preventing hacking attempts

00:20:49,919 --> 00:20:52,880
just highlight the pertinent law in your

00:20:51,360 --> 00:20:53,919
headers and i'll stop any would-be

00:20:52,880 --> 00:20:56,640
hacker

00:20:53,919 --> 00:20:58,240
why has no one thought of that before

00:20:56,640 --> 00:20:59,280
when i saw this header i knew exactly

00:20:58,240 --> 00:21:01,120
what they had done

00:20:59,280 --> 00:21:02,640
both the key and the value look very

00:21:01,120 --> 00:21:04,240
much like the sort of placeholders a

00:21:02,640 --> 00:21:06,480
developer would use when explaining how

00:21:04,240 --> 00:21:08,080
to set custom headers

00:21:06,480 --> 00:21:10,000
and here's the exact same key and value

00:21:08,080 --> 00:21:11,360
on stack overflow

00:21:10,000 --> 00:21:12,880
you can basically do this for any answer

00:21:11,360 --> 00:21:14,640
in stack overflow which shows how to set

00:21:12,880 --> 00:21:17,760
custom headers

00:21:14,640 --> 00:21:19,600
and you'll be able to find a result this

00:21:17,760 --> 00:21:22,000
tony from denmark appeared a lot

00:21:19,600 --> 00:21:23,919
sometimes i would just say tony was here

00:21:22,000 --> 00:21:25,919
but it was his quotes which are my

00:21:23,919 --> 00:21:27,760
favorite now these were originally were

00:21:25,919 --> 00:21:29,440
in the initial values so please excuse

00:21:27,760 --> 00:21:30,720
any translation errors

00:21:29,440 --> 00:21:33,600
but some of the quotes are it's

00:21:30,720 --> 00:21:37,440
sebastian's turn to pick up donuts

00:21:33,600 --> 00:21:39,280
who has cake today and i hate them

00:21:37,440 --> 00:21:41,200
soundcloud includes ex-plants header of

00:21:39,280 --> 00:21:41,919
an incredibly cryptic value of distant

00:21:41,200 --> 00:21:43,039
towel

00:21:41,919 --> 00:21:44,720
this does not seem to be randomly

00:21:43,039 --> 00:21:46,480
generated i couldn't get it to change on

00:21:44,720 --> 00:21:48,320
different devices and connections

00:21:46,480 --> 00:21:50,000
so what does it mean there is some talk

00:21:48,320 --> 00:21:51,280
and they don't really want to know

00:21:50,000 --> 00:21:52,960
so if anyone watching works at

00:21:51,280 --> 00:21:54,640
soundcloud please tweet me and put me

00:21:52,960 --> 00:21:56,080
out of my misery

00:21:54,640 --> 00:21:59,440
there's quite a few sql injection

00:21:56,080 --> 00:22:02,000
attempts i'm one or two xss

00:21:59,440 --> 00:22:03,840
this was an odd one nlm is a national

00:22:02,000 --> 00:22:05,120
library of medicine and nih is the

00:22:03,840 --> 00:22:07,120
national institute of health

00:22:05,120 --> 00:22:08,640
the ip addresses and the value did point

00:22:07,120 --> 00:22:09,840
at some servers but it just served up

00:22:08,640 --> 00:22:12,240
blank pages

00:22:09,840 --> 00:22:13,520
or that's why i'm guessing of course i

00:22:12,240 --> 00:22:14,559
didn't try and visit some random

00:22:13,520 --> 00:22:16,880
government website

00:22:14,559 --> 00:22:17,760
for those that consider vip and whose

00:22:16,880 --> 00:22:22,000
addresses were

00:22:17,760 --> 00:22:25,520
hidden in the headers tattler

00:22:22,000 --> 00:22:28,159
wired glamour housing gardens

00:22:25,520 --> 00:22:28,960
all have an ex-irony header the value

00:22:28,159 --> 00:22:29,760
changes each time you look at a

00:22:28,960 --> 00:22:32,000
different page

00:22:29,760 --> 00:22:34,080
and it's got some kind of weird examples

00:22:32,000 --> 00:22:37,840
nice night for a walk

00:22:34,080 --> 00:22:39,600
what the hell are you your luggage

00:22:37,840 --> 00:22:41,120
hey claudius you killed my father big

00:22:39,600 --> 00:22:44,559
mistake

00:22:41,120 --> 00:22:45,919
get your ass to mars your levity is good

00:22:44,559 --> 00:22:48,720
it relieves tension and the fear of

00:22:45,919 --> 00:22:50,480
death did anyone recognize them

00:22:48,720 --> 00:22:52,080
they're all arnold schwarzenegger quotes

00:22:50,480 --> 00:22:54,240
and these are just a few they're

00:22:52,080 --> 00:22:55,840
none the most least vulgar ones most of

00:22:54,240 --> 00:22:57,440
them are very not safe for work

00:22:55,840 --> 00:22:59,039
they also included a sequel injection in

00:22:57,440 --> 00:23:00,320
each response a trend i think was

00:22:59,039 --> 00:23:02,480
started by reddit

00:23:00,320 --> 00:23:03,919
oh on an x-men header which earned an

00:23:02,480 --> 00:23:06,400
eye roll first time i saw it

00:23:03,919 --> 00:23:08,559
someone at connest is really enjoying

00:23:06,400 --> 00:23:10,320
their job it's not just

00:23:08,559 --> 00:23:12,080
um irony as well he's got quotes bender

00:23:10,320 --> 00:23:13,919
from futurama is a popular one

00:23:12,080 --> 00:23:15,120
there's multiple unrelated sites of an

00:23:13,919 --> 00:23:16,960
ex-bender header

00:23:15,120 --> 00:23:18,559
again earliest mention i can find of it

00:23:16,960 --> 00:23:19,679
is from reddit which looks to spread

00:23:18,559 --> 00:23:21,200
from there

00:23:19,679 --> 00:23:22,720
probably the weirdest one i found in my

00:23:21,200 --> 00:23:24,320
initial search was birchbox

00:23:22,720 --> 00:23:26,159
it's a monthly subscription box of

00:23:24,320 --> 00:23:28,400
cosmetics and video products

00:23:26,159 --> 00:23:31,919
and their smooth header contains an

00:23:28,400 --> 00:23:33,520
unlisted youtube link to this video

00:23:31,919 --> 00:23:35,440
now you'll not be able to hear the music

00:23:33,520 --> 00:23:38,799
playing right now um

00:23:35,440 --> 00:23:41,120
but it's a song i believe i can fly

00:23:38,799 --> 00:23:42,400
i did attempt to find more hidden

00:23:41,120 --> 00:23:46,000
youtube videos

00:23:42,400 --> 00:23:48,159
but without any success smugmug includes

00:23:46,000 --> 00:23:49,760
one of their values in each response

00:23:48,159 --> 00:23:51,440
i had to refresh a bunch of times as

00:23:49,760 --> 00:23:53,120
they appear to be random but thankfully

00:23:51,440 --> 00:23:54,559
they were numbered so i knew when i got

00:23:53,120 --> 00:23:56,799
them all

00:23:54,559 --> 00:23:57,840
one grow together two thrill our

00:23:56,799 --> 00:24:00,960
customers

00:23:57,840 --> 00:24:04,000
three deliver awesome ford there and

00:24:00,960 --> 00:24:05,200
five empire passion

00:24:04,000 --> 00:24:07,760
another header i noticed in the smug

00:24:05,200 --> 00:24:09,600
blog was for recruitment

00:24:07,760 --> 00:24:11,039
they had this like title of what you do

00:24:09,600 --> 00:24:11,919
header which was like a link to their

00:24:11,039 --> 00:24:13,840
jobs board

00:24:11,919 --> 00:24:15,279
but they weren't the only ones either i

00:24:13,840 --> 00:24:16,559
did a certain and there was literally

00:24:15,279 --> 00:24:17,679
hundreds of companies recruiting by

00:24:16,559 --> 00:24:20,000
their hdb headers

00:24:17,679 --> 00:24:23,279
flickers zappos dollar shave club con

00:24:20,000 --> 00:24:24,720
nas ha proxy backer kit just name a few

00:24:23,279 --> 00:24:26,960
this one i tried on a hunch and

00:24:24,720 --> 00:24:29,200
thankfully it didn't work out

00:24:26,960 --> 00:24:31,440
these are regexes for detecting aws

00:24:29,200 --> 00:24:32,960
secrets taking from the aws labs get

00:24:31,440 --> 00:24:35,360
secrets project

00:24:32,960 --> 00:24:36,799
the query i did find a few but there

00:24:35,360 --> 00:24:38,000
were false positives no actual keys

00:24:36,799 --> 00:24:39,440
which is good

00:24:38,000 --> 00:24:41,919
although i still have a lot of headers

00:24:39,440 --> 00:24:41,919
to spider

00:24:43,600 --> 00:24:46,400
okay admit this one's a little bit

00:24:44,640 --> 00:24:46,799
childish i'm not going to show the swear

00:24:46,400 --> 00:24:49,279
word

00:24:46,799 --> 00:24:50,559
list i use you can find these bandwidth

00:24:49,279 --> 00:24:52,559
lists in google

00:24:50,559 --> 00:24:54,640
um but unfortunately suffered badly from

00:24:52,559 --> 00:24:56,400
the scunfort problem

00:24:54,640 --> 00:24:58,320
but is it the regex was far too broad it

00:24:56,400 --> 00:24:59,279
would match the naughty word in a larger

00:24:58,320 --> 00:25:02,320
word

00:24:59,279 --> 00:25:03,760
assumption for example

00:25:02,320 --> 00:25:05,760
powered by was probably one of the most

00:25:03,760 --> 00:25:08,000
common headers i saw and also probably

00:25:05,760 --> 00:25:11,120
the most likely to be custom

00:25:08,000 --> 00:25:12,000
alongside usual php and wordpress some

00:25:11,120 --> 00:25:14,159
websites

00:25:12,000 --> 00:25:15,200
are powered by a range of things

00:25:14,159 --> 00:25:16,320
sacrifice

00:25:15,200 --> 00:25:18,559
i don't know there is just somebody

00:25:16,320 --> 00:25:23,360
else's commodore 64 which i

00:25:18,559 --> 00:25:26,000
really hope is true coffee with puppies

00:25:23,360 --> 00:25:27,679
one was powered by isles everyone

00:25:26,000 --> 00:25:29,600
spawned the viles whiskey sneaky octopus

00:25:27,679 --> 00:25:31,679
pineapple and sloth

00:25:29,600 --> 00:25:32,640
and yes emojis were in the header value

00:25:31,679 --> 00:25:36,080
too

00:25:32,640 --> 00:25:38,400
bananas and rum my crazy smart brain

00:25:36,080 --> 00:25:39,840
i'm that person's not powered by modesty

00:25:38,400 --> 00:25:41,360
blurry cat pictures which i think

00:25:39,840 --> 00:25:43,279
accounts for 98 of

00:25:41,360 --> 00:25:45,760
the powered by an internet and finally

00:25:43,279 --> 00:25:47,200
the pyre of grayscale

00:25:45,760 --> 00:25:48,799
before 20 million headers already in the

00:25:47,200 --> 00:25:49,440
dataset and probably many many millions

00:25:48,799 --> 00:25:50,880
more to add

00:25:49,440 --> 00:25:52,720
this is only scripting the surface of

00:25:50,880 --> 00:25:53,919
what i'm hoping to uncover

00:25:52,720 --> 00:25:55,760
unfortunately even with the company i

00:25:53,919 --> 00:25:56,880
work for i'm not a data scientist or

00:25:55,760 --> 00:25:58,480
even a dba

00:25:56,880 --> 00:26:00,080
i'm much more towards the developer end

00:25:58,480 --> 00:26:02,159
of the spectrum

00:26:00,080 --> 00:26:03,360
so data set still needs some work before

00:26:02,159 --> 00:26:04,320
it's in condition to make it fully

00:26:03,360 --> 00:26:06,559
public

00:26:04,320 --> 00:26:07,919
i'll need to get some of my more learned

00:26:06,559 --> 00:26:09,360
colleagues create the correct indexes

00:26:07,919 --> 00:26:10,960
and things for me first

00:26:09,360 --> 00:26:12,320
however that said if you would like to

00:26:10,960 --> 00:26:13,600
take a sneak peek at the data before the

00:26:12,320 --> 00:26:14,960
public launch

00:26:13,600 --> 00:26:17,120
i'm happy to provide read access to

00:26:14,960 --> 00:26:18,799
anyone watching

00:26:17,120 --> 00:26:22,320
you can reach me on twitter to ask for

00:26:18,799 --> 00:26:24,559
that access my dms are always open

00:26:22,320 --> 00:26:25,679
so thank you so much for your time today

00:26:24,559 --> 00:26:27,520
i know this was a little different from

00:26:25,679 --> 00:26:29,360
age of djangocon talks but i hope i've

00:26:27,520 --> 00:26:31,120
helped make the case for white async

00:26:29,360 --> 00:26:33,679
and all the work andrew godwin ours is

00:26:31,120 --> 00:26:35,120
so important the teacher of django

00:26:33,679 --> 00:26:37,120
i really hope you'll attend his talk

00:26:35,120 --> 00:26:40,799
tomorrow and

00:26:37,120 --> 00:26:40,799
personally thank you again for listening

00:26:45,840 --> 00:26:50,320
so there was so there's obviously one i

00:26:48,799 --> 00:26:52,080
kind of like skipped over i

00:26:50,320 --> 00:26:53,679
take the slide out to be honest um

00:26:52,080 --> 00:26:56,480
because

00:26:53,679 --> 00:26:57,840
i'm actually responsible for it and i

00:26:56,480 --> 00:26:59,840
only really remembered

00:26:57,840 --> 00:27:01,760
when i came to to write so when i

00:26:59,840 --> 00:27:05,120
actually saw they had to appear a lot

00:27:01,760 --> 00:27:09,039
and it's the um the clacks overhead

00:27:05,120 --> 00:27:11,279
uh package so it was

00:27:09,039 --> 00:27:12,960
um terry pratchett's uh people are not

00:27:11,279 --> 00:27:14,640
aware as an english author he wrote the

00:27:12,960 --> 00:27:17,679
discworld series of books

00:27:14,640 --> 00:27:19,679
and it was created as a memorial to him

00:27:17,679 --> 00:27:21,279
essentially there's the packages for

00:27:19,679 --> 00:27:23,520
most different frameworks and web

00:27:21,279 --> 00:27:26,640
servers etc that will set this

00:27:23,520 --> 00:27:28,720
clacks overhead uh header and

00:27:26,640 --> 00:27:29,679
the value which will be uh terry

00:27:28,720 --> 00:27:31,760
pratchett

00:27:29,679 --> 00:27:33,120
it's it's actually i think it's on like

00:27:31,760 --> 00:27:35,520
all the mozilla websites and things like

00:27:33,120 --> 00:27:37,600
that and there's a django package for it

00:27:35,520 --> 00:27:39,120
but i said i wrote it six years ago and

00:27:37,600 --> 00:27:40,399
the way in which you modify headers and

00:27:39,120 --> 00:27:42,080
django has changed since then so i

00:27:40,399 --> 00:27:44,000
didn't want to put it in this talk

00:27:42,080 --> 00:27:45,679
before i have a chance to go in and fix

00:27:44,000 --> 00:27:49,440
it um so that's one

00:27:45,679 --> 00:27:51,600
ware up for django uh

00:27:49,440 --> 00:27:53,600
not too many more than that to be honest

00:27:51,600 --> 00:27:55,279
i know there was

00:27:53,600 --> 00:27:57,919
there's been a couple of like modified

00:27:55,279 --> 00:28:00,320
headers um

00:27:57,919 --> 00:28:01,440
i think there's like a target one and

00:28:00,320 --> 00:28:04,799
things like that but

00:28:01,440 --> 00:28:07,360
in django world it's mostly to be honest

00:28:04,799 --> 00:28:07,919
people like writing themselves or making

00:28:07,360 --> 00:28:10,000
like

00:28:07,919 --> 00:28:11,440
small kind of in-jokes or or little

00:28:10,000 --> 00:28:13,200
comments for them

00:28:11,440 --> 00:28:14,840
um the recruitment one seems to be the

00:28:13,200 --> 00:28:17,919
one that everybody's doing

00:28:14,840 --> 00:28:20,240
like uh i would love to be able to

00:28:17,919 --> 00:28:22,640
figure out how i can actually track the

00:28:20,240 --> 00:28:24,159
amount of bandwidth that is used by the

00:28:22,640 --> 00:28:27,399
x hacker

00:28:24,159 --> 00:28:29,360
uh header that is sent by all

00:28:27,399 --> 00:28:32,559
wordpress.com sites

00:28:29,360 --> 00:28:34,720
to advertise coming to work for

00:28:32,559 --> 00:28:36,159
the parent company of wordpress like

00:28:34,720 --> 00:28:37,760
every single one of their sites on every

00:28:36,159 --> 00:28:39,279
page load sends this header it's like an

00:28:37,760 --> 00:28:40,960
x hacker header and then

00:28:39,279 --> 00:28:42,799
this like sentence saying why you

00:28:40,960 --> 00:28:44,080
shouldn't work for them and with

00:28:42,799 --> 00:28:45,360
how much of the web is powered by

00:28:44,080 --> 00:28:46,720
wordpress it's like that must be a

00:28:45,360 --> 00:28:50,080
considerable amount of bytes that's

00:28:46,720 --> 00:28:50,080
transferred every day just for that

00:28:51,440 --> 00:29:00,559
yeah that's crazy thanks

00:28:58,480 --> 00:29:00,559

YouTube URL: https://www.youtube.com/watch?v=i0WkpgLwtoA


