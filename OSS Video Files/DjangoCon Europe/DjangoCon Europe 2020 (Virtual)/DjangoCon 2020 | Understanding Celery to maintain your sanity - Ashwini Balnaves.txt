Title: DjangoCon 2020 | Understanding Celery to maintain your sanity - Ashwini Balnaves
Publication date: 2020-09-30
Playlist: DjangoCon Europe 2020 (Virtual)
Description: 
	DjangoCon Europe 2020 (Virtual)
September 19, 2020 - 11h55 (GMT+1)

"Understanding Celery to maintain your sanity" by Ashwini Balnaves

Many Django apps use Celery as a task queue for long running tasks. Many talks and blogs focus on how to use Celery. But we can't stop there. Once you're actually using Celery it's time to understand what it is actually doing so you can be prepared for when things go wrong and know what tools are out there to help you troubleshoot any issues.
Captions: 
	00:00:05,200 --> 00:00:08,480
my name is ashwini

00:00:06,399 --> 00:00:11,120
and my talk is called understanding

00:00:08,480 --> 00:00:12,880
salary to maintain your sanity

00:00:11,120 --> 00:00:15,280
i had the idea for this talk after we

00:00:12,880 --> 00:00:17,039
had a critical issue in production

00:00:15,280 --> 00:00:18,880
i work as a full-time software engineer

00:00:17,039 --> 00:00:21,359
at a company called capisce

00:00:18,880 --> 00:00:22,640
and i was fairly new to the company at

00:00:21,359 --> 00:00:25,199
the time but

00:00:22,640 --> 00:00:26,560
i had read the docs on how to use celery

00:00:25,199 --> 00:00:30,080
i'd even

00:00:26,560 --> 00:00:32,000
written a few tasks but now that things

00:00:30,080 --> 00:00:34,640
had gone really wrong

00:00:32,000 --> 00:00:36,399
and nothing was working i needed to know

00:00:34,640 --> 00:00:39,440
exactly how everything worked

00:00:36,399 --> 00:00:40,079
so that i could jump in and see what was

00:00:39,440 --> 00:00:43,440
happening

00:00:40,079 --> 00:00:44,000
and try to fix it quickly that was a

00:00:43,440 --> 00:00:47,200
very

00:00:44,000 --> 00:00:49,039
stressful way to learn how salary works

00:00:47,200 --> 00:00:50,719
especially since a lot of the online

00:00:49,039 --> 00:00:53,360
resources that i found

00:00:50,719 --> 00:00:55,199
focused on which methods to call and how

00:00:53,360 --> 00:00:57,760
to get started

00:00:55,199 --> 00:00:59,440
i would recommend to anyone who has

00:00:57,760 --> 00:01:00,079
salary in their stack that they invest

00:00:59,440 --> 00:01:02,559
in the time

00:01:00,079 --> 00:01:03,680
to understand salary before it goes

00:01:02,559 --> 00:01:05,600
wrong which

00:01:03,680 --> 00:01:08,320
is what i hope to help you achieve uh

00:01:05,600 --> 00:01:08,320
with this talk

00:01:08,640 --> 00:01:12,240
so the first thing to know is that

00:01:10,400 --> 00:01:13,119
celery is an implementation of a

00:01:12,240 --> 00:01:16,479
distributed

00:01:13,119 --> 00:01:18,560
asynchronous task you in my case

00:01:16,479 --> 00:01:20,000
we have these very long batches of work

00:01:18,560 --> 00:01:22,560
that need to be done

00:01:20,000 --> 00:01:24,240
like i was saying before i work at a

00:01:22,560 --> 00:01:27,520
startup called capiche

00:01:24,240 --> 00:01:29,600
based in brisbane australia we process

00:01:27,520 --> 00:01:30,720
huge amounts of customer data in order

00:01:29,600 --> 00:01:33,600
to uncover

00:01:30,720 --> 00:01:36,000
customer insights this means uploading

00:01:33,600 --> 00:01:36,799
and handling csv files with hundreds of

00:01:36,000 --> 00:01:40,320
columns

00:01:36,799 --> 00:01:43,360
and millions of rows and updating large

00:01:40,320 --> 00:01:45,360
natural language processing topic models

00:01:43,360 --> 00:01:47,200
so we have a lot of work to do that

00:01:45,360 --> 00:01:49,280
takes quite a while

00:01:47,200 --> 00:01:51,360
but why do we want to do these tasks in

00:01:49,280 --> 00:01:53,840
the background as opposed to

00:01:51,360 --> 00:01:56,719
in a django view after all doesn't

00:01:53,840 --> 00:01:58,960
django have everything i need

00:01:56,719 --> 00:01:58,960
well

00:02:00,320 --> 00:02:03,520
the thing with doing things in the

00:02:01,680 --> 00:02:05,840
background means that you can respond

00:02:03,520 --> 00:02:07,600
back to your client very quickly

00:02:05,840 --> 00:02:10,239
otherwise you're going to make your

00:02:07,600 --> 00:02:12,560
client and ultimately your users

00:02:10,239 --> 00:02:14,640
wait for pages to load or for actions to

00:02:12,560 --> 00:02:16,400
complete

00:02:14,640 --> 00:02:18,160
this is going to consume a connection in

00:02:16,400 --> 00:02:19,280
your django app and limits the

00:02:18,160 --> 00:02:21,520
responsiveness

00:02:19,280 --> 00:02:22,560
of your application if that doesn't

00:02:21,520 --> 00:02:24,319
convince you

00:02:22,560 --> 00:02:26,400
i found out the hard way that browsers

00:02:24,319 --> 00:02:28,720
have timeouts so there's a hard limit on

00:02:26,400 --> 00:02:32,239
how long a request handler can take

00:02:28,720 --> 00:02:34,879
to process a request anyway

00:02:32,239 --> 00:02:36,000
so if we have salary doing all this work

00:02:34,879 --> 00:02:39,040
instead of doing it in our

00:02:36,000 --> 00:02:41,599
views we also get another huge benefit

00:02:39,040 --> 00:02:43,200
which is we decouple that work from the

00:02:41,599 --> 00:02:45,920
django app

00:02:43,200 --> 00:02:46,959
decoupling gives us two main benefits

00:02:45,920 --> 00:02:49,760
the first is

00:02:46,959 --> 00:02:52,400
to horizontally scale independently of

00:02:49,760 --> 00:02:55,440
the main django application

00:02:52,400 --> 00:02:57,040
for us specifically this means i can add

00:02:55,440 --> 00:02:59,200
more salary services

00:02:57,040 --> 00:03:00,319
to our kubernetes cluster without

00:02:59,200 --> 00:03:03,440
impacting the django

00:03:00,319 --> 00:03:05,519
app at all this also gives us the

00:03:03,440 --> 00:03:07,760
ability to restart the django app

00:03:05,519 --> 00:03:10,480
for example for a deployment without

00:03:07,760 --> 00:03:12,400
having to wait for tasks to complete

00:03:10,480 --> 00:03:13,840
for us this is very useful considering

00:03:12,400 --> 00:03:16,959
some of our tasks can take

00:03:13,840 --> 00:03:18,159
several hours there are many other

00:03:16,959 --> 00:03:20,159
reasons as well

00:03:18,159 --> 00:03:21,840
when i was putting together this talk i

00:03:20,159 --> 00:03:23,760
asked some of my other developer friends

00:03:21,840 --> 00:03:26,239
what they use celery for

00:03:23,760 --> 00:03:26,799
and there were many other reasons most

00:03:26,239 --> 00:03:28,720
of them were

00:03:26,799 --> 00:03:30,640
also using celery for long-running

00:03:28,720 --> 00:03:32,560
cpu-bounded tasks

00:03:30,640 --> 00:03:33,840
but other reasons include managing

00:03:32,560 --> 00:03:36,000
resource contention

00:03:33,840 --> 00:03:38,799
and parallelizing work as an

00:03:36,000 --> 00:03:38,799
optimization

00:03:39,440 --> 00:03:45,120
so why celery i use celery because it

00:03:42,400 --> 00:03:47,360
was part of the stack that i inherited

00:03:45,120 --> 00:03:49,440
a lot of us as developers don't work on

00:03:47,360 --> 00:03:52,000
greenville projects most of the time

00:03:49,440 --> 00:03:54,560
and due to celery's popularity a lot of

00:03:52,000 --> 00:03:57,599
django applications involve salary

00:03:54,560 --> 00:03:59,280
it is by far the most popular of all the

00:03:57,599 --> 00:04:01,040
task queues

00:03:59,280 --> 00:04:03,200
i think its popularity comes from the

00:04:01,040 --> 00:04:04,879
fact that it's a very mature project

00:04:03,200 --> 00:04:07,760
it has many integrations with different

00:04:04,879 --> 00:04:09,840
frameworks message queues and databases

00:04:07,760 --> 00:04:11,280
it's included in many tutorials and

00:04:09,840 --> 00:04:12,720
markets itself is very simple and

00:04:11,280 --> 00:04:14,640
powerful

00:04:12,720 --> 00:04:15,840
i would agree that it's very simple for

00:04:14,640 --> 00:04:17,519
simple use cases

00:04:15,840 --> 00:04:19,040
and it also has very many powerful

00:04:17,519 --> 00:04:21,199
features but

00:04:19,040 --> 00:04:23,120
with those come quite a dramatic

00:04:21,199 --> 00:04:25,280
increase in complexity when using it in

00:04:23,120 --> 00:04:26,960
more advanced situations

00:04:25,280 --> 00:04:28,560
specifically when you start changing

00:04:26,960 --> 00:04:30,080
some of the default values for the

00:04:28,560 --> 00:04:33,199
configuration settings

00:04:30,080 --> 00:04:35,280
there's so many levers that you can pull

00:04:33,199 --> 00:04:36,639
it's really important to understand what

00:04:35,280 --> 00:04:39,680
you're doing

00:04:36,639 --> 00:04:41,360
but it's by far the most popular

00:04:39,680 --> 00:04:43,040
but there are alternatives such as the

00:04:41,360 --> 00:04:46,000
ones that i've listed here in no

00:04:43,040 --> 00:04:46,000
particular order

00:04:47,520 --> 00:04:52,720
so what is it actually doing let's talk

00:04:50,639 --> 00:04:54,639
about some definitions

00:04:52,720 --> 00:04:56,160
we're going to go over each part of the

00:04:54,639 --> 00:04:57,199
system there's going to be a little bit

00:04:56,160 --> 00:04:59,600
of code

00:04:57,199 --> 00:05:01,199
but our main focus is going to be how

00:04:59,600 --> 00:05:04,320
everything is working together

00:05:01,199 --> 00:05:06,320
so a bit more of a systems view

00:05:04,320 --> 00:05:08,160
first we have the client this is the

00:05:06,320 --> 00:05:10,479
service that wants to submit work

00:05:08,160 --> 00:05:12,240
to be done and in our case this is the

00:05:10,479 --> 00:05:14,639
django view

00:05:12,240 --> 00:05:15,759
then we have that work that actually

00:05:14,639 --> 00:05:19,360
needs to be done

00:05:15,759 --> 00:05:21,680
and in salary these are called tasks

00:05:19,360 --> 00:05:22,720
finally we have the workers and they are

00:05:21,680 --> 00:05:27,600
ultimately what

00:05:22,720 --> 00:05:27,600
executes the work or the tasks

00:05:28,560 --> 00:05:32,000
you can see here on the right we have a

00:05:30,720 --> 00:05:33,919
little bit of code

00:05:32,000 --> 00:05:35,199
we can see that tasks are defined as

00:05:33,919 --> 00:05:37,919
python functions

00:05:35,199 --> 00:05:39,919
in a tasks file within our django app

00:05:37,919 --> 00:05:42,240
using the shared task decorator

00:05:39,919 --> 00:05:43,520
so the shared task decorator is unique

00:05:42,240 --> 00:05:47,199
to django apps

00:05:43,520 --> 00:05:49,199
so when you see celery tutorials

00:05:47,199 --> 00:05:50,639
that are using other frameworks other

00:05:49,199 --> 00:05:52,720
than django you might see

00:05:50,639 --> 00:05:55,199
a slightly different decorator which is

00:05:52,720 --> 00:05:57,520
the app.task decorator

00:05:55,199 --> 00:06:00,080
this is a little bit of a side note but

00:05:57,520 --> 00:06:03,680
because celery app

00:06:00,080 --> 00:06:07,039
celery only has one instance

00:06:03,680 --> 00:06:07,520
enabled to expose all the sub modules or

00:06:07,039 --> 00:06:09,600
the sub

00:06:07,520 --> 00:06:13,039
apps in django to that single celery

00:06:09,600 --> 00:06:14,720
instance we need the special decorator

00:06:13,039 --> 00:06:17,199
then we have the client and the client

00:06:14,720 --> 00:06:18,639
imports the tasks and calls them using

00:06:17,199 --> 00:06:20,960
the delay method

00:06:18,639 --> 00:06:22,479
so i've taken this code snippet from the

00:06:20,960 --> 00:06:25,199
django official docs

00:06:22,479 --> 00:06:26,960
one of their very first examples and

00:06:25,199 --> 00:06:30,400
this is the simplest way

00:06:26,960 --> 00:06:32,639
that you can call a task celery

00:06:30,400 --> 00:06:33,520
has a lot of powerful features

00:06:32,639 --> 00:06:35,840
especially

00:06:33,520 --> 00:06:37,039
when it comes to the ways that you can

00:06:35,840 --> 00:06:39,600
call tasks

00:06:37,039 --> 00:06:41,600
there's the ability to link them

00:06:39,600 --> 00:06:43,600
together so they execute one after each

00:06:41,600 --> 00:06:44,319
other or we can send them all off in a

00:06:43,600 --> 00:06:46,080
group

00:06:44,319 --> 00:06:48,400
we can even attach callbacks to that

00:06:46,080 --> 00:06:50,319
group but i'm not going to go too much

00:06:48,400 --> 00:06:52,639
into that there are some really good

00:06:50,319 --> 00:06:55,120
resources online

00:06:52,639 --> 00:06:57,520
search for what celery calls canvas

00:06:55,120 --> 00:06:57,520
design

00:06:59,039 --> 00:07:04,319
and then we have workers so a worker

00:07:01,919 --> 00:07:05,759
spawns sub-processes in order to execute

00:07:04,319 --> 00:07:08,560
the tasks

00:07:05,759 --> 00:07:09,440
the number of sub-processes defaults to

00:07:08,560 --> 00:07:12,479
the number of

00:07:09,440 --> 00:07:14,160
cpus available on the machine on which

00:07:12,479 --> 00:07:15,840
the worker is running

00:07:14,160 --> 00:07:18,479
but if you want you can change that with

00:07:15,840 --> 00:07:20,000
a dash c argument

00:07:18,479 --> 00:07:21,520
in our example here we have three

00:07:20,000 --> 00:07:24,000
workers but

00:07:21,520 --> 00:07:24,720
one of the big value of what celery has

00:07:24,000 --> 00:07:26,639
to offer

00:07:24,720 --> 00:07:27,840
is that it is distributed so these

00:07:26,639 --> 00:07:30,160
workers can be

00:07:27,840 --> 00:07:31,919
and in fact usually are on different

00:07:30,160 --> 00:07:34,400
machines

00:07:31,919 --> 00:07:36,319
each one will have as many sub processes

00:07:34,400 --> 00:07:37,599
as is available on the box on which it's

00:07:36,319 --> 00:07:40,639
running

00:07:37,599 --> 00:07:42,080
so there are three workers three worker

00:07:40,639 --> 00:07:44,160
boxes in this picture but there could

00:07:42,080 --> 00:07:46,879
potentially be more sub processors

00:07:44,160 --> 00:07:46,879
actually running

00:07:48,639 --> 00:07:55,360
so there's a little bit more

00:07:51,840 --> 00:07:55,840
going on how does the client actually

00:07:55,360 --> 00:07:58,960
get

00:07:55,840 --> 00:08:02,560
the task to the worker to execute well

00:07:58,960 --> 00:08:04,560
we use a broker or a message transport

00:08:02,560 --> 00:08:06,080
this is the way that the messages get

00:08:04,560 --> 00:08:07,199
communicated between the clients of the

00:08:06,080 --> 00:08:09,199
workers

00:08:07,199 --> 00:08:12,000
the client will submit a task to the

00:08:09,199 --> 00:08:14,240
broker and the workers will subscribe to

00:08:12,000 --> 00:08:18,720
the broker and fetch tasks off

00:08:14,240 --> 00:08:21,280
of its queue once a worker has process

00:08:18,720 --> 00:08:22,720
has executed a task they then write the

00:08:21,280 --> 00:08:25,759
results of that task

00:08:22,720 --> 00:08:27,120
into the results store

00:08:25,759 --> 00:08:29,599
so let's talk a little bit more about

00:08:27,120 --> 00:08:32,959
the broker just

00:08:29,599 --> 00:08:34,240
as well um the documentation and a lot

00:08:32,959 --> 00:08:36,080
of tutorials use

00:08:34,240 --> 00:08:37,360
the word broker and message queue

00:08:36,080 --> 00:08:39,440
interchangeably which

00:08:37,360 --> 00:08:40,479
i will admit confuse me a little bit at

00:08:39,440 --> 00:08:41,839
first but

00:08:40,479 --> 00:08:44,240
we're just going to stick with broker to

00:08:41,839 --> 00:08:46,320
keep it consistent

00:08:44,240 --> 00:08:47,519
so there are several services that

00:08:46,320 --> 00:08:50,399
celery can use

00:08:47,519 --> 00:08:51,519
as a broker rabbitmq is the service that

00:08:50,399 --> 00:08:54,160
celery

00:08:51,519 --> 00:08:55,600
docs put up to you first but redis is

00:08:54,160 --> 00:08:59,440
also a popular opinion

00:08:55,600 --> 00:08:59,440
and redis is what i use

00:09:00,000 --> 00:09:03,839
when the task is submitted to the broker

00:09:01,920 --> 00:09:05,839
it's given an id and it's stored in a

00:09:03,839 --> 00:09:07,279
serialized format

00:09:05,839 --> 00:09:10,320
salary supports many different

00:09:07,279 --> 00:09:13,040
serialization formats as well

00:09:10,320 --> 00:09:14,320
but you might also be limited by what

00:09:13,040 --> 00:09:17,040
serialization

00:09:14,320 --> 00:09:18,480
format your broker supports in my case

00:09:17,040 --> 00:09:22,320
we use both pickle

00:09:18,480 --> 00:09:24,480
and json

00:09:22,320 --> 00:09:26,800
then there's the result store so also

00:09:24,480 --> 00:09:27,200
the result store is used interchangeably

00:09:26,800 --> 00:09:29,360
with

00:09:27,200 --> 00:09:31,839
the word results backend we're going to

00:09:29,360 --> 00:09:34,399
be sticking with store

00:09:31,839 --> 00:09:35,200
i use the django orm which has a nice

00:09:34,399 --> 00:09:37,200
integration

00:09:35,200 --> 00:09:39,360
called jingo's salary results but as you

00:09:37,200 --> 00:09:41,360
can see there are many options that you

00:09:39,360 --> 00:09:43,839
can choose from

00:09:41,360 --> 00:09:47,120
django salary results even gives you an

00:09:43,839 --> 00:09:49,839
interface through the django admin panel

00:09:47,120 --> 00:09:51,680
you can see here where each row is a

00:09:49,839 --> 00:09:54,959
completed task that's been written

00:09:51,680 --> 00:09:54,959
into the results back end

00:09:56,560 --> 00:10:00,000
so now it's time for a story of how

00:09:58,480 --> 00:10:02,160
things go wrong

00:10:00,000 --> 00:10:05,440
and with the tool so configurable it

00:10:02,160 --> 00:10:08,160
probably will

00:10:05,440 --> 00:10:09,120
so there are quite a few stories that i

00:10:08,160 --> 00:10:12,160
could have chosen

00:10:09,120 --> 00:10:14,160
to tell for example

00:10:12,160 --> 00:10:15,839
we had problems with growing memory

00:10:14,160 --> 00:10:18,160
requirements in redis

00:10:15,839 --> 00:10:19,920
because i was passing the entire

00:10:18,160 --> 00:10:21,040
contents of a file through the task

00:10:19,920 --> 00:10:23,600
parameters

00:10:21,040 --> 00:10:25,360
because i was treating tasks as if they

00:10:23,600 --> 00:10:27,040
were regular functions

00:10:25,360 --> 00:10:28,959
i didn't realize that the function

00:10:27,040 --> 00:10:32,240
parameters were being serialized

00:10:28,959 --> 00:10:34,800
and stored in redis as well

00:10:32,240 --> 00:10:36,079
we also had a lot of fun when we found

00:10:34,800 --> 00:10:39,440
out that workers

00:10:36,079 --> 00:10:41,760
will pre-fetch a certain number of tasks

00:10:39,440 --> 00:10:43,279
that means if you have tasks that long

00:10:41,760 --> 00:10:46,240
run for a long time

00:10:43,279 --> 00:10:46,880
which we do a worker could potentially

00:10:46,240 --> 00:10:50,000
fetch

00:10:46,880 --> 00:10:52,800
a batch of them let's say three um

00:10:50,000 --> 00:10:54,000
and it will go through and execute each

00:10:52,800 --> 00:10:57,360
of those

00:10:54,000 --> 00:11:00,640
um while perhaps there are other workers

00:10:57,360 --> 00:11:03,120
that are available um so

00:11:00,640 --> 00:11:04,959
let's say it's it's fetch three and the

00:11:03,120 --> 00:11:06,320
first one takes a long time

00:11:04,959 --> 00:11:07,920
task two and three are sitting there

00:11:06,320 --> 00:11:09,839
waiting to be run even though there's

00:11:07,920 --> 00:11:13,040
other workers available

00:11:09,839 --> 00:11:14,880
so if you do have quite long running

00:11:13,040 --> 00:11:17,040
tasks the doc

00:11:14,880 --> 00:11:18,959
the suggestion is that you run with the

00:11:17,040 --> 00:11:20,880
flag dash oh fair

00:11:18,959 --> 00:11:22,880
that way there will be no prefetching of

00:11:20,880 --> 00:11:28,160
tasks and workers only grab them

00:11:22,880 --> 00:11:30,640
one at a time we've also had fun when

00:11:28,160 --> 00:11:31,760
tasks have failed to change as expected

00:11:30,640 --> 00:11:33,760
because

00:11:31,760 --> 00:11:35,839
there are immutable signature types that

00:11:33,760 --> 00:11:38,160
behave differently to mutable ones

00:11:35,839 --> 00:11:40,399
this is because tasks created using the

00:11:38,160 --> 00:11:42,959
immutable signatures

00:11:40,399 --> 00:11:44,800
don't require the task previous results

00:11:42,959 --> 00:11:47,040
and if you use the linking method

00:11:44,800 --> 00:11:48,560
and examples in the salary docs it

00:11:47,040 --> 00:11:52,560
doesn't actually wait

00:11:48,560 --> 00:11:54,399
and they're not executed sequentially

00:11:52,560 --> 00:11:56,079
a lot of these stories are result of me

00:11:54,399 --> 00:11:57,680
not understanding how celery actually

00:11:56,079 --> 00:11:59,200
works because since everything was

00:11:57,680 --> 00:12:01,760
working when i got there

00:11:59,200 --> 00:12:02,880
i found the documentation to be a little

00:12:01,760 --> 00:12:05,760
overwhelming

00:12:02,880 --> 00:12:07,120
so i didn't really feel the need to i

00:12:05,760 --> 00:12:08,079
assumed that everything was set up

00:12:07,120 --> 00:12:11,839
optimally

00:12:08,079 --> 00:12:13,440
and it was running fine but what i found

00:12:11,839 --> 00:12:15,920
out was that celery's default

00:12:13,440 --> 00:12:18,959
configuration settings are set up

00:12:15,920 --> 00:12:21,760
for a high frequency shortish

00:12:18,959 --> 00:12:23,040
amount of tasks what i mean is a lot of

00:12:21,760 --> 00:12:26,560
tasks that

00:12:23,040 --> 00:12:29,040
are taking a shortish amount of time

00:12:26,560 --> 00:12:31,040
as our company began to grow though and

00:12:29,040 --> 00:12:32,639
gain more and more customers with larger

00:12:31,040 --> 00:12:35,839
and larger data sets

00:12:32,639 --> 00:12:37,200
our tasks became longer and longer

00:12:35,839 --> 00:12:39,440
we needed to change the default

00:12:37,200 --> 00:12:42,720
configuration settings

00:12:39,440 --> 00:12:44,720
away from what the default values were

00:12:42,720 --> 00:12:46,320
however because celery has so many

00:12:44,720 --> 00:12:47,920
leaves you can pull we started to get

00:12:46,320 --> 00:12:50,079
ourselves into trouble

00:12:47,920 --> 00:12:51,279
as we change settings without realizing

00:12:50,079 --> 00:12:53,120
the impact

00:12:51,279 --> 00:12:54,320
of what it was going to have on the

00:12:53,120 --> 00:12:55,760
whole system

00:12:54,320 --> 00:12:58,000
we didn't have a comprehensive

00:12:55,760 --> 00:13:00,480
understanding of how all the levers

00:12:58,000 --> 00:13:01,920
impacted each other but by the way i

00:13:00,480 --> 00:13:03,760
would say i still don't have a

00:13:01,920 --> 00:13:06,720
comprehensive understanding

00:13:03,760 --> 00:13:09,680
of how all the different configuration

00:13:06,720 --> 00:13:13,360
works within celery

00:13:09,680 --> 00:13:16,720
but i kind of glossed through those

00:13:13,360 --> 00:13:17,440
stories and some of them probably didn't

00:13:16,720 --> 00:13:20,720
even

00:13:17,440 --> 00:13:23,200
make much sense if you're new to salary

00:13:20,720 --> 00:13:25,680
but we're going to go through one in a

00:13:23,200 --> 00:13:28,720
little bit more detail

00:13:25,680 --> 00:13:30,399
one which i was referencing in the

00:13:28,720 --> 00:13:32,839
beginning of this talk

00:13:30,399 --> 00:13:35,040
that made me have to learn a lot about

00:13:32,839 --> 00:13:38,240
salary

00:13:35,040 --> 00:13:40,639
so how did it all begin well the

00:13:38,240 --> 00:13:43,680
defaults for salary are configured

00:13:40,639 --> 00:13:45,279
to have a lower reliability than what we

00:13:43,680 --> 00:13:48,320
really wanted as a team

00:13:45,279 --> 00:13:50,720
so we turned on the task acts late

00:13:48,320 --> 00:13:51,600
to increase reliability well what does

00:13:50,720 --> 00:13:54,160
that mean

00:13:51,600 --> 00:13:54,160
i'll tell you

00:13:55,279 --> 00:13:59,360
it means that a worker can acknowledge

00:13:57,600 --> 00:14:02,000
the message from the broker

00:13:59,360 --> 00:14:04,079
before or after the worker actually

00:14:02,000 --> 00:14:07,680
executes the task

00:14:04,079 --> 00:14:08,959
so the client submits the task to the

00:14:07,680 --> 00:14:12,000
broker

00:14:08,959 --> 00:14:13,519
and the worker pulls off the task and

00:14:12,000 --> 00:14:16,079
acknowledges it

00:14:13,519 --> 00:14:17,279
and then that task is no longer in the

00:14:16,079 --> 00:14:20,320
broker's queue

00:14:17,279 --> 00:14:21,680
while that task is executing on the

00:14:20,320 --> 00:14:25,760
worker

00:14:21,680 --> 00:14:28,800
however the non-default behavior

00:14:25,760 --> 00:14:29,440
is which we turned on is that when the

00:14:28,800 --> 00:14:31,680
task

00:14:29,440 --> 00:14:34,160
is sitting in the broker's queue and the

00:14:31,680 --> 00:14:36,240
worker pulls off the task

00:14:34,160 --> 00:14:38,000
it waits until the execution of that

00:14:36,240 --> 00:14:41,040
task has finished

00:14:38,000 --> 00:14:41,680
before sending the ack so the task is

00:14:41,040 --> 00:14:44,240
sitting

00:14:41,680 --> 00:14:47,040
in the broker's queue while it's

00:14:44,240 --> 00:14:50,800
executing and only gets finished

00:14:47,040 --> 00:14:52,240
when it's done this means that if

00:14:50,800 --> 00:14:53,760
something happened to the process while

00:14:52,240 --> 00:14:55,440
the task was executing

00:14:53,760 --> 00:14:57,680
and the task was never acknowledged then

00:14:55,440 --> 00:14:59,360
the broker would retire the task again

00:14:57,680 --> 00:15:00,959
the idea here is that we would be

00:14:59,360 --> 00:15:04,160
protected from data loss

00:15:00,959 --> 00:15:04,160
due to worker failure

00:15:05,120 --> 00:15:08,639
everything seemed to be going well but

00:15:07,199 --> 00:15:11,680
then we kept growing

00:15:08,639 --> 00:15:12,399
and the tasks were getting longer and

00:15:11,680 --> 00:15:16,079
our

00:15:12,399 --> 00:15:17,279
tasks started to time out we could tell

00:15:16,079 --> 00:15:19,760
this because

00:15:17,279 --> 00:15:21,440
well none of our tasks were completing

00:15:19,760 --> 00:15:23,040
but we could also see the timeout in the

00:15:21,440 --> 00:15:25,440
logs and we could see that the default

00:15:23,040 --> 00:15:27,279
was set for 300 seconds

00:15:25,440 --> 00:15:28,959
so we figured we could simply up this

00:15:27,279 --> 00:15:32,079
time limit and our tasks

00:15:28,959 --> 00:15:32,880
would complete we knew that most of our

00:15:32,079 --> 00:15:35,120
tasks

00:15:32,880 --> 00:15:36,560
took in the order of hours and so we set

00:15:35,120 --> 00:15:38,240
it to 24 hours

00:15:36,560 --> 00:15:39,440
even though it was a little overkill

00:15:38,240 --> 00:15:40,000
because we knew it would be definitely

00:15:39,440 --> 00:15:44,000
long enough

00:15:40,000 --> 00:15:44,000
for even our longest task to complete

00:15:45,120 --> 00:15:50,720
all seemed well again until

00:15:48,320 --> 00:15:53,279
we discovered through a customer report

00:15:50,720 --> 00:15:55,279
that nothing was working

00:15:53,279 --> 00:15:57,440
in our ui the new file uploads were

00:15:55,279 --> 00:16:00,560
being marked as queued and were not

00:15:57,440 --> 00:16:02,800
being processed this is a

00:16:00,560 --> 00:16:04,000
actually another pretty good tip is if

00:16:02,800 --> 00:16:06,560
you can surface

00:16:04,000 --> 00:16:08,000
the state of your tasks within your ui

00:16:06,560 --> 00:16:09,600
to reflect the state that that

00:16:08,000 --> 00:16:11,839
they have in celery that can be very

00:16:09,600 --> 00:16:13,199
useful in this case we could see that

00:16:11,839 --> 00:16:16,639
they were being queued

00:16:13,199 --> 00:16:18,160
but not being executed this was not a

00:16:16,639 --> 00:16:21,040
good situation to be in

00:16:18,160 --> 00:16:23,839
the pressure was on to fix the downtime

00:16:21,040 --> 00:16:23,839
in our system

00:16:24,320 --> 00:16:28,720
so we could see that the tasks were

00:16:26,480 --> 00:16:31,120
being sent by the client but

00:16:28,720 --> 00:16:32,160
where could the blockage be was it in

00:16:31,120 --> 00:16:33,600
the broker

00:16:32,160 --> 00:16:36,000
were the workers not picking up the

00:16:33,600 --> 00:16:39,120
tasks were the workers themselves

00:16:36,000 --> 00:16:39,120
failing in some way

00:16:39,360 --> 00:16:45,199
well income salary cli

00:16:42,880 --> 00:16:47,199
so this is a great tool to be able to

00:16:45,199 --> 00:16:50,240
see what's happening within

00:16:47,199 --> 00:16:51,199
celery celery cli has many great

00:16:50,240 --> 00:16:52,959
commands

00:16:51,199 --> 00:16:54,720
but rather than reading the docs i would

00:16:52,959 --> 00:16:56,240
recommend you have a play with it to see

00:16:54,720 --> 00:17:00,480
what it's capable of

00:16:56,240 --> 00:17:02,000
in some sort of environment that's safe

00:17:00,480 --> 00:17:05,039
we're going to have a look at just how

00:17:02,000 --> 00:17:07,039
useful it is in solving our problem

00:17:05,039 --> 00:17:09,439
so the first thing we needed to do is

00:17:07,039 --> 00:17:10,480
just get some visibility on what was

00:17:09,439 --> 00:17:13,839
going on

00:17:10,480 --> 00:17:17,439
and so the prime

00:17:13,839 --> 00:17:19,919
command for that is inspect active

00:17:17,439 --> 00:17:21,839
i've included a little example here of

00:17:19,919 --> 00:17:22,720
what the celery workers would look like

00:17:21,839 --> 00:17:26,160
if they had no

00:17:22,720 --> 00:17:28,799
tasks but

00:17:26,160 --> 00:17:30,840
back in our story this is what the

00:17:28,799 --> 00:17:34,080
result was to inspect

00:17:30,840 --> 00:17:36,960
active you can see that our

00:17:34,080 --> 00:17:38,799
salary workers are very busy and not

00:17:36,960 --> 00:17:42,240
only are they busy

00:17:38,799 --> 00:17:44,880
they're all busy with the same task

00:17:42,240 --> 00:17:46,640
this is actually a response well like

00:17:44,880 --> 00:17:49,200
sanitize and simplified version of what

00:17:46,640 --> 00:17:50,240
the actual commands output was on that

00:17:49,200 --> 00:17:53,360
day

00:17:50,240 --> 00:17:57,360
so they're all busy with the same task

00:17:53,360 --> 00:18:00,640
which was very confusing because

00:17:57,360 --> 00:18:02,880
not only was it strange to have them

00:18:00,640 --> 00:18:04,640
all executing the same task but i could

00:18:02,880 --> 00:18:06,400
see that that task was masked as

00:18:04,640 --> 00:18:09,440
successfully completed

00:18:06,400 --> 00:18:09,440
in the results store

00:18:09,919 --> 00:18:13,600
this must have meant that the broker is

00:18:12,480 --> 00:18:17,600
keeping the task

00:18:13,600 --> 00:18:19,679
in the message queue and allowing

00:18:17,600 --> 00:18:22,160
workers to retry it and pull it off the

00:18:19,679 --> 00:18:24,960
broker again and again

00:18:22,160 --> 00:18:25,679
so why aren't the messages on the broker

00:18:24,960 --> 00:18:28,000
being

00:18:25,679 --> 00:18:31,360
act when we know that the task was

00:18:28,000 --> 00:18:31,360
successfully executed

00:18:31,679 --> 00:18:39,200
well there's a little bit of a clue here

00:18:35,919 --> 00:18:42,880
which is that the acknowledged is marked

00:18:39,200 --> 00:18:45,360
false so

00:18:42,880 --> 00:18:46,640
we do have we had confirmation that the

00:18:45,360 --> 00:18:50,000
task was in fact

00:18:46,640 --> 00:18:51,520
sitting in the broker and the new tasks

00:18:50,000 --> 00:18:56,640
that needed to get executed

00:18:51,520 --> 00:18:59,039
were just piling up behind it

00:18:56,640 --> 00:18:59,760
i really want to know what's going on

00:18:59,039 --> 00:19:02,799
but

00:18:59,760 --> 00:19:05,840
because it's our production system and

00:19:02,799 --> 00:19:08,559
it's currently not working we

00:19:05,840 --> 00:19:10,320
had to look at fixing that before

00:19:08,559 --> 00:19:12,160
investigating what could possibly have

00:19:10,320 --> 00:19:15,760
caused this

00:19:12,160 --> 00:19:18,480
celery cli comes to the rescue again

00:19:15,760 --> 00:19:20,480
now i wasn't sure at the time what the

00:19:18,480 --> 00:19:22,160
difference between revoke and terminate

00:19:20,480 --> 00:19:24,559
was

00:19:22,160 --> 00:19:25,600
and it's still kind of hard to find this

00:19:24,559 --> 00:19:27,600
information

00:19:25,600 --> 00:19:29,440
um the monitoring and management guide

00:19:27,600 --> 00:19:32,400
has a lot about the

00:19:29,440 --> 00:19:33,520
um ability to examine tasks but not so

00:19:32,400 --> 00:19:35,760
much control them

00:19:33,520 --> 00:19:36,960
and even the command line interface docs

00:19:35,760 --> 00:19:40,880
don't really

00:19:36,960 --> 00:19:43,039
specify exactly what everything does

00:19:40,880 --> 00:19:44,080
that's why i suggest if you can play

00:19:43,039 --> 00:19:47,200
around and use

00:19:44,080 --> 00:19:48,799
the dash help option that's a great way

00:19:47,200 --> 00:19:52,240
to learn about the capabilities

00:19:48,799 --> 00:19:55,200
of salary cli so

00:19:52,240 --> 00:19:56,080
revoking a task versus terminating a

00:19:55,200 --> 00:19:58,880
task

00:19:56,080 --> 00:20:01,280
revoking a task what it actually does is

00:19:58,880 --> 00:20:04,159
it adds that task's id

00:20:01,280 --> 00:20:06,320
to a set of task ids within the salary

00:20:04,159 --> 00:20:08,720
workers in memory set

00:20:06,320 --> 00:20:09,520
so whenever a salary worker pulls off a

00:20:08,720 --> 00:20:13,679
new task

00:20:09,520 --> 00:20:15,840
from the broker's message queue

00:20:13,679 --> 00:20:17,120
it checks whether it's in that set or

00:20:15,840 --> 00:20:20,480
not and

00:20:17,120 --> 00:20:22,960
if it is it won't run it

00:20:20,480 --> 00:20:24,240
as you can see if you're already running

00:20:22,960 --> 00:20:25,919
it it's

00:20:24,240 --> 00:20:28,000
already way past that check and so

00:20:25,919 --> 00:20:30,720
revoking a task is not going to affect a

00:20:28,000 --> 00:20:32,720
task that is already running

00:20:30,720 --> 00:20:34,320
as a side note as well because this set

00:20:32,720 --> 00:20:37,039
is in memory

00:20:34,320 --> 00:20:37,840
in the salary worker not in redis our

00:20:37,039 --> 00:20:40,000
broker

00:20:37,840 --> 00:20:43,120
any restarts mean that the tasks will

00:20:40,000 --> 00:20:45,840
effectively be unrevoked and if you want

00:20:43,120 --> 00:20:46,640
your revokes to be persistent you have

00:20:45,840 --> 00:20:49,120
to set up

00:20:46,640 --> 00:20:49,679
that set to exist on disk on the machine

00:20:49,120 --> 00:20:52,240
that your

00:20:49,679 --> 00:20:53,120
worker is running on but that's a side

00:20:52,240 --> 00:20:56,880
note

00:20:53,120 --> 00:21:00,480
so what we want to do is terminate

00:20:56,880 --> 00:21:03,679
so we terminated our

00:21:00,480 --> 00:21:05,360
task that was running on all the workers

00:21:03,679 --> 00:21:06,880
it killed all the processes that were

00:21:05,360 --> 00:21:08,400
executing our task

00:21:06,880 --> 00:21:10,960
and it's important to know that it does

00:21:08,400 --> 00:21:14,240
actually then acknowledge the task

00:21:10,960 --> 00:21:15,039
so it's no longer cued this is dangerous

00:21:14,240 --> 00:21:16,400
though

00:21:15,039 --> 00:21:18,960
and the reason for that is that it kills

00:21:16,400 --> 00:21:20,880
the process not just the task

00:21:18,960 --> 00:21:22,799
this means if there is anything in

00:21:20,880 --> 00:21:24,400
memory on your salary worker that is

00:21:22,799 --> 00:21:27,760
important such as prefetch

00:21:24,400 --> 00:21:27,760
tasks they could go missing

00:21:28,640 --> 00:21:35,039
so what was happening well

00:21:32,080 --> 00:21:35,360
after we managed to unblock the system

00:21:35,039 --> 00:21:39,039
we

00:21:35,360 --> 00:21:42,240
found out that the reason

00:21:39,039 --> 00:21:44,480
um for this problem was that the broker

00:21:42,240 --> 00:21:46,640
can't wait indefinitely for the

00:21:44,480 --> 00:21:48,880
acknowledgement to eventually come

00:21:46,640 --> 00:21:50,080
as you can see i've got here the broker

00:21:48,880 --> 00:21:51,760
is thinking

00:21:50,080 --> 00:21:53,520
how long should i wait for my

00:21:51,760 --> 00:21:54,159
acknowledgement before i decide that

00:21:53,520 --> 00:21:56,320
something hap

00:21:54,159 --> 00:21:57,600
has happened to the celery worker and

00:21:56,320 --> 00:21:58,480
the acknowledgement is never going to

00:21:57,600 --> 00:22:01,919
come

00:21:58,480 --> 00:22:05,120
and i need to retry the task

00:22:01,919 --> 00:22:09,200
well turns out there is a setting

00:22:05,120 --> 00:22:11,120
in redis for this it even turns out

00:22:09,200 --> 00:22:13,120
that there's a caveat section under the

00:22:11,120 --> 00:22:14,880
brokers section of the celery

00:22:13,120 --> 00:22:18,159
documentation

00:22:14,880 --> 00:22:19,520
but none of us in our team had read the

00:22:18,159 --> 00:22:23,200
entire documentation

00:22:19,520 --> 00:22:25,520
in order to know this so in the end

00:22:23,200 --> 00:22:28,400
we set the visibility time out to 24

00:22:25,520 --> 00:22:28,400
hours as well

00:22:29,520 --> 00:22:33,440
under a time crunch we got a lot of

00:22:32,720 --> 00:22:37,200
value

00:22:33,440 --> 00:22:40,799
out of celery cli but

00:22:37,200 --> 00:22:41,440
there is a wonderful um graphical user

00:22:40,799 --> 00:22:43,600
interface

00:22:41,440 --> 00:22:44,799
that you can use called flower and this

00:22:43,600 --> 00:22:47,520
just gives you

00:22:44,799 --> 00:22:49,360
the same functionality as celery cli but

00:22:47,520 --> 00:22:51,520
a much nicer interface

00:22:49,360 --> 00:22:53,520
and with the benefit of foresight you

00:22:51,520 --> 00:22:55,919
can set it up

00:22:53,520 --> 00:22:56,640
if you're using a distributed system

00:22:55,919 --> 00:22:59,440
adding

00:22:56,640 --> 00:23:01,120
tracing and having good lugging is also

00:22:59,440 --> 00:23:02,799
incredibly valuable

00:23:01,120 --> 00:23:04,960
i actually cannot recommend it high

00:23:02,799 --> 00:23:07,120
enough our tracing system

00:23:04,960 --> 00:23:08,080
i love we use honeycomb and it's

00:23:07,120 --> 00:23:10,960
dramatically

00:23:08,080 --> 00:23:12,880
increased my ability to gain visibility

00:23:10,960 --> 00:23:14,559
over what on earth is going on within

00:23:12,880 --> 00:23:17,679
our system

00:23:14,559 --> 00:23:18,159
but that's another talk i hope that this

00:23:17,679 --> 00:23:21,360
talk

00:23:18,159 --> 00:23:23,200
though has helped you with your um

00:23:21,360 --> 00:23:24,960
will help you with your celery issues

00:23:23,200 --> 00:23:25,360
and will give you a foundation to draw

00:23:24,960 --> 00:23:28,960
upon

00:23:25,360 --> 00:23:28,960
when you're reading the celery ducks

00:23:29,360 --> 00:23:31,840
thank you

00:23:35,440 --> 00:23:38,960
oh just for the sake of the recording

00:23:37,520 --> 00:23:41,600
i'll repeat the question which is

00:23:38,960 --> 00:23:42,640
the django community is moving towards

00:23:41,600 --> 00:23:45,200
using django q

00:23:42,640 --> 00:23:46,640
what are they missing out on um i'm

00:23:45,200 --> 00:23:48,559
probably not the best person

00:23:46,640 --> 00:23:50,159
to ask this question to because i

00:23:48,559 --> 00:23:53,840
haven't had much experience with

00:23:50,159 --> 00:23:56,080
django q i think really one of the main

00:23:53,840 --> 00:23:57,279
focuses that i wanted for my talk was

00:23:56,080 --> 00:23:58,400
for people who are in a similar

00:23:57,279 --> 00:24:01,200
situation like me

00:23:58,400 --> 00:24:02,880
who have inherited a project with uh

00:24:01,200 --> 00:24:07,039
celery already in it

00:24:02,880 --> 00:24:09,520
and maybe didn't feel it necessary to

00:24:07,039 --> 00:24:11,919
learn the underlyings of how it worked

00:24:09,520 --> 00:24:14,880
because it was all just

00:24:11,919 --> 00:24:16,720
being happy and and chugging along

00:24:14,880 --> 00:24:19,760
successfully

00:24:16,720 --> 00:24:22,720
until something goes wrong in

00:24:19,760 --> 00:24:24,000
a way that requires you to jump in so i

00:24:22,720 --> 00:24:32,480
personally haven't been able to look

00:24:24,000 --> 00:24:47,840
into the other task used very much

00:24:32,480 --> 00:24:47,840
are there any other questions

00:24:55,840 --> 00:24:59,120
what were some of the reasons that

00:24:57,840 --> 00:25:02,320
caused you guys to

00:24:59,120 --> 00:25:05,279
start changing more of the uh background

00:25:02,320 --> 00:25:09,120
settings that you were warning against

00:25:05,279 --> 00:25:11,200
yeah so um i guess it's important to

00:25:09,120 --> 00:25:13,039
context for this conversation is the

00:25:11,200 --> 00:25:16,080
startup that i work in

00:25:13,039 --> 00:25:17,440
our workout is quite small but we're

00:25:16,080 --> 00:25:19,760
really

00:25:17,440 --> 00:25:21,039
starting at the scaling up phase of our

00:25:19,760 --> 00:25:23,360
journey so

00:25:21,039 --> 00:25:25,440
our engineering team at the moment is

00:25:23,360 --> 00:25:29,200
three people

00:25:25,440 --> 00:25:32,640
and um

00:25:29,200 --> 00:25:35,200
what that means is for us we are still

00:25:32,640 --> 00:25:36,240
finding product market fit and what we

00:25:35,200 --> 00:25:38,480
were testing with

00:25:36,240 --> 00:25:40,799
and what we thought our the kind of data

00:25:38,480 --> 00:25:42,559
that our customers would have would be

00:25:40,799 --> 00:25:44,799
much smaller we thought we were going to

00:25:42,559 --> 00:25:45,600
be dealing with a couple hundred rows in

00:25:44,799 --> 00:25:48,559
a spreadsheet

00:25:45,600 --> 00:25:49,840
sort of thing and the code was written

00:25:48,559 --> 00:25:50,799
with that in mind that's what we were

00:25:49,840 --> 00:25:54,000
testing against

00:25:50,799 --> 00:25:57,520
and then as we started to work out that

00:25:54,000 --> 00:26:02,480
enterprise level customers were um

00:25:57,520 --> 00:26:04,400
much more of our ideal customer profile

00:26:02,480 --> 00:26:06,320
what that means is they came with way

00:26:04,400 --> 00:26:06,799
more data than we ever expected and so

00:26:06,320 --> 00:26:09,600
our

00:26:06,799 --> 00:26:10,000
tasks and everything were set up without

00:26:09,600 --> 00:26:11,840
that really

00:26:10,000 --> 00:26:13,279
being in mind and they were really long

00:26:11,840 --> 00:26:16,400
running and

00:26:13,279 --> 00:26:18,640
ultimately we had to support those sales

00:26:16,400 --> 00:26:21,520
as they came on and that meant

00:26:18,640 --> 00:26:22,000
just tweaking things as we go to try and

00:26:21,520 --> 00:26:23,600
make

00:26:22,000 --> 00:26:25,279
the current system that we have work for

00:26:23,600 --> 00:26:28,159
it because we don't have

00:26:25,279 --> 00:26:28,640
like six months to um really make sure

00:26:28,159 --> 00:26:31,200
that

00:26:28,640 --> 00:26:31,679
we were being really precise and careful

00:26:31,200 --> 00:26:34,240
with

00:26:31,679 --> 00:26:34,960
everything it's kind of uh one of the

00:26:34,240 --> 00:26:38,159
joys of

00:26:34,960 --> 00:26:41,200
the startup lifestyle

00:26:38,159 --> 00:26:43,440
did that answer your question

00:26:41,200 --> 00:26:45,200
it did and i've got a quick follow on to

00:26:43,440 --> 00:26:48,000
that then which is

00:26:45,200 --> 00:26:50,080
do you have any insight then on on

00:26:48,000 --> 00:26:52,960
understanding when you should be

00:26:50,080 --> 00:26:54,480
looking at actually you know your django

00:26:52,960 --> 00:26:56,480
code or you know whatever

00:26:54,480 --> 00:27:00,720
whatever celery is running with or

00:26:56,480 --> 00:27:00,720
looking at celery for the optimizations

00:27:01,120 --> 00:27:06,720
yeah that's a great um that's a great

00:27:04,320 --> 00:27:06,720
point

00:27:08,880 --> 00:27:11,279
i think

00:27:15,120 --> 00:27:17,600
i think

00:27:18,799 --> 00:27:23,440
for us a lot of it has to do with

00:27:21,600 --> 00:27:25,919
profiling and trying to work out what's

00:27:23,440 --> 00:27:29,279
the quickest way to

00:27:25,919 --> 00:27:31,600
to get these gains um

00:27:29,279 --> 00:27:32,720
at the moment a lot we're focusing a lot

00:27:31,600 --> 00:27:36,080
on performance work

00:27:32,720 --> 00:27:39,279
and a lot of that isn't even in the

00:27:36,080 --> 00:27:40,399
django level or the uh celery level it's

00:27:39,279 --> 00:27:42,080
more

00:27:40,399 --> 00:27:43,600
the shape of our data and making sure

00:27:42,080 --> 00:27:44,720
it's coming out efficiently out of the

00:27:43,600 --> 00:27:48,320
database

00:27:44,720 --> 00:27:50,080
so even now we still have quite long

00:27:48,320 --> 00:27:53,279
running tasks and

00:27:50,080 --> 00:27:56,480
um we are just making it work

00:27:53,279 --> 00:27:59,279
i guess until we have time to optimize

00:27:56,480 --> 00:27:59,279
those as well

00:28:01,520 --> 00:28:06,799
thank you no worries

00:28:05,279 --> 00:28:08,880
um tim asks do you have any

00:28:06,799 --> 00:28:10,000
recommendations for any tutorials on

00:28:08,880 --> 00:28:13,600
learning celery

00:28:10,000 --> 00:28:17,440
i actually do um and there's actually

00:28:13,600 --> 00:28:20,559
uh quite a few good um

00:28:17,440 --> 00:28:22,399
common gotcha articles and i think i'll

00:28:20,559 --> 00:28:25,360
i'll link them in the slack

00:28:22,399 --> 00:28:26,240
if anybody else so everybody else can uh

00:28:25,360 --> 00:28:27,760
have a look at them

00:28:26,240 --> 00:28:31,840
i came across quite a few while i was

00:28:27,760 --> 00:28:31,840
researching for this talk as well

00:28:37,840 --> 00:28:44,720
i would love that no problem

00:28:43,200 --> 00:28:47,520
hey thank you very much for your talk

00:28:44,720 --> 00:28:49,679
great talk um i have question regarding

00:28:47,520 --> 00:28:51,679
uh flower i didn't get to play around

00:28:49,679 --> 00:28:54,080
with it too much but i noticed it only

00:28:51,679 --> 00:28:55,679
works if it's already been running for a

00:28:54,080 --> 00:28:56,559
while like it's keeping its own log or

00:28:55,679 --> 00:28:58,240
something

00:28:56,559 --> 00:29:00,320
do you know where it stores it and do i

00:28:58,240 --> 00:29:02,080
need to worry if i keep it running a

00:29:00,320 --> 00:29:02,880
long time that at some point something

00:29:02,080 --> 00:29:06,159
will

00:29:02,880 --> 00:29:07,919
just store too much um

00:29:06,159 --> 00:29:09,279
i'm not totally sure and the reason for

00:29:07,919 --> 00:29:12,559
that is because

00:29:09,279 --> 00:29:14,640
uh we have it set up um in our local

00:29:12,559 --> 00:29:17,760
environment at the moment so we have

00:29:14,640 --> 00:29:19,840
um it running as a service uh in our

00:29:17,760 --> 00:29:22,080
docker compose for our local environment

00:29:19,840 --> 00:29:23,200
but we haven't managed to get it for our

00:29:22,080 --> 00:29:25,440
production system

00:29:23,200 --> 00:29:26,790
yet i don't take my own advice

00:29:25,440 --> 00:29:28,159
apparently

00:29:26,790 --> 00:29:30,640
[Music]

00:29:28,159 --> 00:29:30,640
cool thanks

00:29:31,279 --> 00:29:34,320
i did see in the slack that a lot of

00:29:32,960 --> 00:29:36,000
other people have had some experience

00:29:34,320 --> 00:29:40,320
with flowers so it might be worth having

00:29:36,000 --> 00:29:42,640
um a discussion there yeah sure

00:29:40,320 --> 00:29:42,640
thank you

00:29:49,279 --> 00:29:53,279
hi hello uh first of all thank you for

00:29:51,679 --> 00:29:55,520
the great talk

00:29:53,279 --> 00:29:56,320
um perhaps this is kind of a new

00:29:55,520 --> 00:29:59,440
question but

00:29:56,320 --> 00:30:00,080
um when should we start considering

00:29:59,440 --> 00:30:03,520
using

00:30:00,080 --> 00:30:08,240
salary tasks instead of crunches

00:30:03,520 --> 00:30:11,760
thank you oh that's a good question so

00:30:08,240 --> 00:30:14,640
um celery does have a

00:30:11,760 --> 00:30:15,840
quite robust uh periodic tasks

00:30:14,640 --> 00:30:18,240
functionality as well

00:30:15,840 --> 00:30:20,960
um you run it as a separate service

00:30:18,240 --> 00:30:24,159
called celery beat

00:30:20,960 --> 00:30:24,880
i have had some pretty good experiences

00:30:24,159 --> 00:30:28,000
with that

00:30:24,880 --> 00:30:33,120
uh we use it pretty extensively

00:30:28,000 --> 00:30:33,120
um in in our environment and

00:30:34,080 --> 00:30:40,559
i think there is a lot that

00:30:37,679 --> 00:30:42,080
the periodic tasks framework gives you

00:30:40,559 --> 00:30:44,720
you can configure it um

00:30:42,080 --> 00:30:46,640
in the admin django admin as well you

00:30:44,720 --> 00:30:50,640
can manually run tasks

00:30:46,640 --> 00:30:52,240
you can disable them and enable them

00:30:50,640 --> 00:30:53,840
from the django admin and that's one of

00:30:52,240 --> 00:30:56,159
the like

00:30:53,840 --> 00:30:58,399
biggest pros that i found with using

00:30:56,159 --> 00:30:58,399
that

00:31:00,640 --> 00:31:04,640
yeah that that sounds really cool being

00:31:02,720 --> 00:31:06,559
able to configure it from the admin

00:31:04,640 --> 00:31:09,039
thank you

00:31:06,559 --> 00:31:10,240
no problem we did actually we did

00:31:09,039 --> 00:31:13,760
actually

00:31:10,240 --> 00:31:16,399
just uh just yesterday have issues with

00:31:13,760 --> 00:31:18,720
um with that though because we had set

00:31:16,399 --> 00:31:21,679
up one kubernetes cluster

00:31:18,720 --> 00:31:23,360
and then upgraded kubernetes cluster and

00:31:21,679 --> 00:31:25,760
they were sharing the database

00:31:23,360 --> 00:31:27,279
and we were planning on uh running them

00:31:25,760 --> 00:31:28,559
both at the same time and then switching

00:31:27,279 --> 00:31:31,200
over but

00:31:28,559 --> 00:31:32,960
we forgot that our periodic tasks we're

00:31:31,200 --> 00:31:34,480
reading from the database and so we had

00:31:32,960 --> 00:31:37,120
two sets of

00:31:34,480 --> 00:31:38,559
salary tasks going at once and it was

00:31:37,120 --> 00:31:41,600
only by

00:31:38,559 --> 00:31:45,279
pure pure coincidence that we had

00:31:41,600 --> 00:31:48,720
not set up the gcp permissions correctly

00:31:45,279 --> 00:31:51,120
on the second cluster's nodes so all

00:31:48,720 --> 00:31:52,240
the uploads failed thankfully otherwise

00:31:51,120 --> 00:31:54,000
we would have been cleaning out

00:31:52,240 --> 00:32:01,840
duplicated data

00:31:54,000 --> 00:32:01,840
all day yesterday

00:32:15,919 --> 00:32:22,080
hi hi ashuni yeah yeah i think uh

00:32:19,279 --> 00:32:23,919
yeah uh adding on to uh to the question

00:32:22,080 --> 00:32:24,799
about cron crown and sultry i think cron

00:32:23,919 --> 00:32:27,200
is model used

00:32:24,799 --> 00:32:29,200
where uh we can rate through our system

00:32:27,200 --> 00:32:30,640
level i think salary is used where we

00:32:29,200 --> 00:32:33,200
can relate to the application

00:32:30,640 --> 00:32:34,799
of regarding maybe there's a task and

00:32:33,200 --> 00:32:36,320
python application where you want it to

00:32:34,799 --> 00:32:38,559
run

00:32:36,320 --> 00:32:40,880
i think kron wouldn't be able to figure

00:32:38,559 --> 00:32:43,120
out what to do it is basically con

00:32:40,880 --> 00:32:44,880
like schedule task for the system level

00:32:43,120 --> 00:32:46,880
and salary is mainly used for scheduled

00:32:44,880 --> 00:32:49,760
tasks for the application level

00:32:46,880 --> 00:32:51,120
so i think that might help add up to the

00:32:49,760 --> 00:32:53,039
question too

00:32:51,120 --> 00:32:55,840
yeah that's a really good point thanks

00:32:53,039 --> 00:32:55,840

YouTube URL: https://www.youtube.com/watch?v=v1m-jbPrYfw


