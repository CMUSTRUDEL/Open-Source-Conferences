Title: Blaze: crunching data in different formats through a single API. by Lex Hider
Publication date: 2015-08-06
Playlist: PyCon Australia 2015 Science & Data Miniconf
Description: 
	Blaze allows you to use a pandas/numpy like interface to query your data, whether it be in CSV format, SQL database, noSQL database.

Odo allows you to easily migrate your data between most formats, be it JSON, SQL database, CSV, python data structures with just a few lines of code.

Come learn about these exciting new parts of the python data ecosystem.
Learn how to crunch your data, and not necessarily have to learn SQL or mongodb to do so.

PyCon Australia is the national conference for users of the Python Programming Language. In 2015, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

July 31-August 4, Brisbane, Queensland, Australia
Captions: 
	00:00:09,700 --> 00:00:16,000
our next speaker is lex and he's talking

00:00:13,930 --> 00:00:22,869
on blaze crunching data in different

00:00:16,000 --> 00:00:27,689
formats through one API hi there can

00:00:22,869 --> 00:00:31,329
everyone hear me okay yep great okay so

00:00:27,689 --> 00:00:34,570
as we were spoke about I'm going to talk

00:00:31,329 --> 00:00:36,040
about a technology called blaze and at

00:00:34,570 --> 00:00:38,140
the style of morning grain kind of gave

00:00:36,040 --> 00:00:41,260
a bit of an overview of the scientific

00:00:38,140 --> 00:00:44,050
Python sort of landscapers it's down

00:00:41,260 --> 00:00:46,390
stands that kind of now and interesting

00:00:44,050 --> 00:00:47,980
things on the horizon and I think sort

00:00:46,390 --> 00:00:50,140
of blaze is another one that's kind of

00:00:47,980 --> 00:00:52,329
on the horizon that's quite interesting

00:00:50,140 --> 00:00:55,690
to have a look at so we'll give you guys

00:00:52,329 --> 00:01:00,579
if you have an idea of that in the next

00:00:55,690 --> 00:01:03,310
half hour or so so yeah and when I'm

00:01:00,579 --> 00:01:05,920
select save your work professionally in

00:01:03,310 --> 00:01:09,040
Python and data for us sort of forest so

00:01:05,920 --> 00:01:12,070
years ago that's where you can find me

00:01:09,040 --> 00:01:15,579
on github and Twitter the slides are up

00:01:12,070 --> 00:01:25,060
online and I might tweak them a bit

00:01:15,579 --> 00:01:28,090
after the talk when we're done so who is

00:01:25,060 --> 00:01:34,209
plays for so if I could just briefly

00:01:28,090 --> 00:01:37,600
poll the audience who would say that

00:01:34,209 --> 00:01:40,090
they're you know a programmer or a coda

00:01:37,600 --> 00:01:41,950
first and you know that you would have

00:01:40,090 --> 00:01:45,399
studied computer science so that's kind

00:01:41,950 --> 00:01:48,189
of your your main day job and that sort

00:01:45,399 --> 00:01:50,560
of your data science component is is you

00:01:48,189 --> 00:01:53,069
know secondary to that put your hand up

00:01:50,560 --> 00:01:57,549
if you put yourself in that category

00:01:53,069 --> 00:01:58,959
that's probably a fair majority I would

00:01:57,549 --> 00:02:00,219
actually say it and who would say the

00:01:58,959 --> 00:02:04,170
other way around that they're kind of a

00:02:00,219 --> 00:02:06,429
scientist or a data person and then they

00:02:04,170 --> 00:02:08,140
programmed to get to you know what they

00:02:06,429 --> 00:02:10,319
want to do I was probably more than I

00:02:08,140 --> 00:02:15,400
that's probably almost half half maybe

00:02:10,319 --> 00:02:20,000
64 do something on not exactly sure

00:02:15,400 --> 00:02:22,850
yeah I'd say 5050 em so really I would

00:02:20,000 --> 00:02:25,040
say that the people in that second

00:02:22,850 --> 00:02:29,660
audience which is you know your data

00:02:25,040 --> 00:02:32,690
person you know programs to to get what

00:02:29,660 --> 00:02:37,220
they need the you're the biggest

00:02:32,690 --> 00:02:42,620
audience for something like blaze in a

00:02:37,220 --> 00:02:47,830
nutshell the sort of TL DR is it allows

00:02:42,620 --> 00:02:47,830
you to sort of use a panda's like API on

00:02:48,010 --> 00:02:55,390
different backends though so you can

00:02:49,940 --> 00:03:00,500
talk to a sequel database MongoDB CSVs

00:02:55,390 --> 00:03:05,420
all that kind of thing but it makes it

00:03:00,500 --> 00:03:08,150
really easy and so something that a

00:03:05,420 --> 00:03:10,850
model a to do is prototype on your

00:03:08,150 --> 00:03:12,350
laptop you know using your csv with a

00:03:10,850 --> 00:03:16,010
few hundred lines or a few thousand

00:03:12,350 --> 00:03:18,980
lines and then deploy when you actually

00:03:16,010 --> 00:03:21,709
need to run your solution on something

00:03:18,980 --> 00:03:23,959
like red shift or post squares or

00:03:21,709 --> 00:03:27,799
whatever it may be using the exact same

00:03:23,959 --> 00:03:29,570
code and sort of one of the key sort of

00:03:27,799 --> 00:03:32,170
ideas behind it is that it's up to foot

00:03:29,570 --> 00:03:43,870
optimize the people not necessarily for

00:03:32,170 --> 00:03:43,870
dad for people not performance sorry

00:03:57,480 --> 00:03:59,540
you

00:04:05,710 --> 00:04:11,150
okay apologies I just have to keep

00:04:08,630 --> 00:04:17,959
pressing a button every couple of

00:04:11,150 --> 00:04:19,100
seconds yes I'd say that you know the

00:04:17,959 --> 00:04:22,040
biggest people are going to have a win

00:04:19,100 --> 00:04:25,580
from this as people who you know code a

00:04:22,040 --> 00:04:27,770
second data people first you might

00:04:25,580 --> 00:04:29,750
already know pandas or pandas is quite

00:04:27,770 --> 00:04:31,370
often you know one of the first ways of

00:04:29,750 --> 00:04:33,620
kind of getting your heads around that

00:04:31,370 --> 00:04:35,150
kind of thing does does anyone what I'm

00:04:33,620 --> 00:04:37,100
talking about Pam this is anyone in the

00:04:35,150 --> 00:04:39,950
audience that hasn't got some familiar

00:04:37,100 --> 00:04:46,310
without hasn't used it before my wheel

00:04:39,950 --> 00:04:50,930
on the same page okay so I guess there's

00:04:46,310 --> 00:04:55,520
a few ways of talking about that one is

00:04:50,930 --> 00:04:58,570
sort of for those people who may be

00:04:55,520 --> 00:04:58,570
familiar with something like are

00:04:58,600 --> 00:05:04,690
essentially pandas is our for Python

00:05:01,730 --> 00:05:09,260
people if you're not familiar with that

00:05:04,690 --> 00:05:15,050
pandas is like a spreadsheet on steroids

00:05:09,260 --> 00:05:18,140
or if you're a database person pandas is

00:05:15,050 --> 00:05:23,530
you know like a sequel table but again

00:05:18,140 --> 00:05:23,530
in Python are quite nice and so lots of

00:05:28,900 --> 00:05:33,770
lots of data things are happening with

00:05:31,400 --> 00:05:38,330
you know parents being behind the scenes

00:05:33,770 --> 00:05:44,030
and it allows you to kind of express

00:05:38,330 --> 00:05:45,560
your your data really elderly so

00:05:44,030 --> 00:05:47,600
essentially what it gives you as a 2d

00:05:45,560 --> 00:05:51,110
data structure that's just like think of

00:05:47,600 --> 00:05:53,720
it like a spreadsheet and it allows you

00:05:51,110 --> 00:05:57,200
to think about your data at a higher

00:05:53,720 --> 00:05:59,630
level of abstraction I gave a talk at

00:05:57,200 --> 00:06:02,660
this exact same mini conf last year it's

00:05:59,630 --> 00:06:04,070
online at YouTube 45 minutes if you're

00:06:02,660 --> 00:06:07,520
one of those people who haven't heard

00:06:04,070 --> 00:06:09,470
about it before go have a look I think

00:06:07,520 --> 00:06:12,710
it sort of gave a pretty good sort of

00:06:09,470 --> 00:06:19,060
half hour 45 minute intro on to that so

00:06:12,710 --> 00:06:19,060
maybe check that out okay

00:06:22,620 --> 00:06:29,530
so why Python so obviously speaking to

00:06:26,289 --> 00:06:33,009
the choir but you know people might talk

00:06:29,530 --> 00:06:42,759
about the elegant code or the libraries

00:06:33,009 --> 00:06:46,660
that exists sorry my answer that one is

00:06:42,759 --> 00:06:48,220
because i'm lazy because you know when

00:06:46,660 --> 00:06:49,720
you're writing python code and using

00:06:48,220 --> 00:06:54,220
summer libraries you know it feels like

00:06:49,720 --> 00:06:55,180
you're cheating and I think kind of once

00:06:54,220 --> 00:06:57,520
you've got your head around blaze a

00:06:55,180 --> 00:06:59,669
little bit it's sort of a same kind of

00:06:57,520 --> 00:06:59,669
idea

00:07:13,310 --> 00:07:18,010
sorry she technical problem just going

00:07:15,470 --> 00:07:18,010
to switch browsers

00:07:33,150 --> 00:07:40,990
okay that's gotta hold use why pen is

00:07:39,310 --> 00:07:44,200
because it really lets you succinctly

00:07:40,990 --> 00:07:48,220
kind of explain what you're trying to do

00:07:44,200 --> 00:07:50,650
so here we have a data frame and we want

00:07:48,220 --> 00:07:59,950
to calculate what who are cool people

00:07:50,650 --> 00:08:01,390
and really laziness is a virtue and as I

00:07:59,950 --> 00:08:03,870
said with a lot of people here who

00:08:01,390 --> 00:08:06,520
aren't you know software people first

00:08:03,870 --> 00:08:08,910
you know you want to spend as least

00:08:06,520 --> 00:08:12,100
amount of time reading API documentation

00:08:08,910 --> 00:08:16,840
and more time looking and playing with

00:08:12,100 --> 00:08:19,690
your data so about with a background

00:08:16,840 --> 00:08:23,800
with blaze there's a company called

00:08:19,690 --> 00:08:25,330
continuing with IO one of the big people

00:08:23,800 --> 00:08:29,170
behind that is a guy called trellis

00:08:25,330 --> 00:08:31,110
sorry Travis oliphant if you haven't

00:08:29,170 --> 00:08:36,310
heard of him he's sort of one of the

00:08:31,110 --> 00:08:39,370
initial waters of numpy and the same

00:08:36,310 --> 00:08:41,919
company continuum io is also behind and

00:08:39,370 --> 00:08:47,310
other technologies like bouquet which is

00:08:41,919 --> 00:08:49,030
a graphing library but and also anaconda

00:08:47,310 --> 00:08:51,790
that will given a three-million-dollar

00:08:49,030 --> 00:08:54,310
DARPA grep back in 2013 to work on some

00:08:51,790 --> 00:08:56,140
of this data stuff and so sort of i

00:08:54,310 --> 00:08:57,610
think most of what I've going to speak

00:08:56,140 --> 00:09:04,180
about has sort of come out of that as

00:08:57,610 --> 00:09:05,440
well as a few other projects and so

00:09:04,180 --> 00:09:07,660
really even though that my title of my

00:09:05,440 --> 00:09:09,280
talk is about blaze really that's kind

00:09:07,660 --> 00:09:10,810
of been splitting it to kind of a few

00:09:09,280 --> 00:09:13,270
different sub projects so i'm going to

00:09:10,810 --> 00:09:14,950
talk about essentially three different

00:09:13,270 --> 00:09:18,640
things that are all kind of closely

00:09:14,950 --> 00:09:20,110
interrelated so we'll get into the

00:09:18,640 --> 00:09:26,110
details of each of these as we go along

00:09:20,110 --> 00:09:32,500
but one is called odo one is called data

00:09:26,110 --> 00:09:34,180
shape and one is called blaze and we

00:09:32,500 --> 00:09:37,680
might touch on blaze server at the very

00:09:34,180 --> 00:09:37,680
end if we have some some extra tile

00:09:39,979 --> 00:09:47,159
and so if we cover those those libraries

00:09:42,749 --> 00:09:48,779
and what problems that are solving so

00:09:47,159 --> 00:09:51,959
touched on blades and really it gives

00:09:48,779 --> 00:09:58,229
you a panda's like a PA to query your

00:09:51,959 --> 00:09:59,759
data or you know Mungiu data we have odo

00:09:58,229 --> 00:10:03,989
which can easily move your data between

00:09:59,759 --> 00:10:05,699
different formats but I can also easily

00:10:03,989 --> 00:10:10,769
move your data from place to place for

00:10:05,699 --> 00:10:12,479
you and we have data shape which is a

00:10:10,769 --> 00:10:14,309
sort of a technology agnostic way of

00:10:12,479 --> 00:10:18,479
describing you know what kind of format

00:10:14,309 --> 00:10:20,459
you or your data looks like and another

00:10:18,479 --> 00:10:22,349
thing that Blair's can do is it's got

00:10:20,459 --> 00:10:24,479
some technology there where it can do

00:10:22,349 --> 00:10:27,149
things like process the data set that's

00:10:24,479 --> 00:10:35,909
you know say a CSV that's larger than

00:10:27,149 --> 00:10:42,119
the ran in your laptop okay so moving on

00:10:35,909 --> 00:10:46,109
to odo and again speaking to the program

00:10:42,119 --> 00:10:47,549
a second crowd you know databases I only

00:10:46,109 --> 00:10:51,119
know Excel I don't want to know

00:10:47,549 --> 00:10:53,009
databases SQL you know I've learnt some

00:10:51,119 --> 00:10:55,069
pandas I've got that under my belt now I

00:10:53,009 --> 00:11:00,709
have to learn a whole other language to

00:10:55,069 --> 00:11:05,219
to do what I want json what's that

00:11:00,709 --> 00:11:11,849
Adamus s3 bodo these are all you know

00:11:05,219 --> 00:11:13,709
more things for you to learn so by

00:11:11,849 --> 00:11:16,469
learning odo kind of means that you may

00:11:13,709 --> 00:11:18,059
not have to what you at least can

00:11:16,469 --> 00:11:23,429
postpone having to learn the details of

00:11:18,059 --> 00:11:24,929
some of these things so for all the

00:11:23,429 --> 00:11:29,999
things I'm speaking about this is how

00:11:24,929 --> 00:11:33,899
you install it can use all the Condor

00:11:29,999 --> 00:11:35,339
pip pip install blaze and these are the

00:11:33,899 --> 00:11:38,519
libraries that i'm talking about there

00:11:35,339 --> 00:11:40,289
that we pull you in its dependencies i'm

00:11:38,519 --> 00:11:41,789
giving another talk on sunday about

00:11:40,289 --> 00:11:44,009
Condor and Anna Connor if you're

00:11:41,789 --> 00:11:46,489
interested kind of a look at that one

00:11:44,009 --> 00:11:46,489
should be good

00:11:49,300 --> 00:11:59,120
okay so we have a function called odo

00:11:53,320 --> 00:12:02,270
it's very simple odo is given a source

00:11:59,120 --> 00:12:05,570
and a target and it will take the sauce

00:12:02,270 --> 00:12:09,680
and put it where you tell it that the

00:12:05,570 --> 00:12:12,050
target is so the example here we're

00:12:09,680 --> 00:12:21,530
giving it a pants data frame and we're

00:12:12,050 --> 00:12:27,340
saying put that in a CSV file so as well

00:12:21,530 --> 00:12:31,430
as being a Python function there's also

00:12:27,340 --> 00:12:33,680
a command-line interface tool that gets

00:12:31,430 --> 00:12:39,620
installed with that install called odo

00:12:33,680 --> 00:12:42,140
so this example here is loading all the

00:12:39,620 --> 00:12:46,250
data CSVs in this directory that start

00:12:42,140 --> 00:12:50,120
with data 2015 and it's going to store

00:12:46,250 --> 00:12:51,890
it into a single white OS so you can see

00:12:50,120 --> 00:12:53,900
from the the sequel white example there

00:12:51,890 --> 00:12:57,580
that essentially what you're passing to

00:12:53,900 --> 00:13:00,710
odo is these things that look like URLs

00:12:57,580 --> 00:13:07,340
and it figures out what what that refers

00:13:00,710 --> 00:13:08,750
to so I'm just going to load this up I'm

00:13:07,340 --> 00:13:13,520
not expecting that you be able to see

00:13:08,750 --> 00:13:14,720
anything on this graph but you can see

00:13:13,520 --> 00:13:19,820
that it's a big graph which is really

00:13:14,720 --> 00:13:21,320
all i want you to see if you go into it

00:13:19,820 --> 00:13:25,090
we might see some things that we

00:13:21,320 --> 00:13:30,110
recognize we can see a pandas dataframe

00:13:25,090 --> 00:13:33,320
we can see a CSV on it on s3 there's

00:13:30,110 --> 00:13:41,570
some JSON what else have we got we've

00:13:33,320 --> 00:13:43,040
got some SSH datetime so really when

00:13:41,570 --> 00:13:46,190
we're talking about it moving data

00:13:43,040 --> 00:13:48,470
around and converting it under the hood

00:13:46,190 --> 00:13:50,630
what it's doing when you say okay give

00:13:48,470 --> 00:13:55,370
me one I have it in this format give it

00:13:50,630 --> 00:13:58,220
to me over here is it figures out the

00:13:55,370 --> 00:14:00,250
best path to use along this graph with

00:13:58,220 --> 00:14:04,060
the west cost

00:14:00,250 --> 00:14:06,570
and the cost is the performance how fast

00:14:04,060 --> 00:14:06,570
can it do that

00:14:13,699 --> 00:14:16,480
ok

00:14:16,730 --> 00:14:20,300
okay so we're going to go through a

00:14:18,769 --> 00:14:22,190
number of examples it will give you some

00:14:20,300 --> 00:14:26,089
of the ideas of some things that odo can

00:14:22,190 --> 00:14:32,420
do so you can load up my CSV into a data

00:14:26,089 --> 00:14:37,100
frame you can save my CSV into different

00:14:32,420 --> 00:14:40,820
databases sequel light postgres again

00:14:37,100 --> 00:14:43,519
for people who actually there's with

00:14:40,820 --> 00:14:44,870
databases databases have a common

00:14:43,519 --> 00:14:47,810
language that you query them was called

00:14:44,870 --> 00:14:51,350
SQL technology been around since the 70s

00:14:47,810 --> 00:14:54,410
and there's different sort of varieties

00:14:51,350 --> 00:14:57,560
of databases there's some of the more

00:14:54,410 --> 00:14:59,329
popular ones being sequel light which is

00:14:57,560 --> 00:15:02,360
really easy to get started with and you

00:14:59,329 --> 00:15:04,339
can run easily on your laptop postgres

00:15:02,360 --> 00:15:06,440
is probably you know the people in the

00:15:04,339 --> 00:15:09,889
Django room next door you know got to

00:15:06,440 --> 00:15:13,130
tell you that's you know the one one one

00:15:09,889 --> 00:15:18,889
to use for open source databases there's

00:15:13,130 --> 00:15:22,180
mice there's Microsoft sequel server and

00:15:18,889 --> 00:15:24,110
then a lot of these big sort of big data

00:15:22,180 --> 00:15:29,029
cluster type things will quite often

00:15:24,110 --> 00:15:32,269
have a SQL interface to them as well so

00:15:29,029 --> 00:15:33,860
here we can save our sales fee into a

00:15:32,269 --> 00:15:38,389
database or we can read from a database

00:15:33,860 --> 00:15:44,420
and get a CSV without having to know any

00:15:38,389 --> 00:15:48,110
details whatsoever we can give it

00:15:44,420 --> 00:15:51,170
multiple files and it you know joins

00:15:48,110 --> 00:15:59,540
them all up together and we can give it

00:15:51,170 --> 00:16:05,000
a compressed files as well it knows JSON

00:15:59,540 --> 00:16:06,800
as well with cs fees so again I can give

00:16:05,000 --> 00:16:10,310
it a JSON file loaded into the database

00:16:06,800 --> 00:16:12,680
or vice versa and we can see here that

00:16:10,310 --> 00:16:18,529
this gives us a few different options on

00:16:12,680 --> 00:16:20,630
what our Jason might look like and just

00:16:18,529 --> 00:16:24,860
to give you kind of reiterate what's

00:16:20,630 --> 00:16:26,930
what odo was doing you know you if you

00:16:24,860 --> 00:16:28,399
ask someone who is familiar with pandas

00:16:26,930 --> 00:16:30,310
on what it what it can do you know you

00:16:28,399 --> 00:16:34,460
might think okay I can

00:16:30,310 --> 00:16:36,860
reading a CSV Candace and then save it

00:16:34,460 --> 00:16:42,020
into sequel with a couple of lines of

00:16:36,860 --> 00:16:43,820
pandas code especially there's a you

00:16:42,020 --> 00:16:47,090
know in the doctor talks about

00:16:43,820 --> 00:16:49,850
especially with sequel and says fees is

00:16:47,090 --> 00:16:53,840
it can use the fastest possible Theme

00:16:49,850 --> 00:16:56,180
Building to the database so it's going

00:16:53,840 --> 00:17:00,380
to use the features built into the

00:16:56,180 --> 00:17:03,020
database that la to you know wait up

00:17:00,380 --> 00:17:07,850
gigabytes worth of data as fast as it

00:17:03,020 --> 00:17:09,830
can and under the hood it's using super

00:17:07,850 --> 00:17:14,900
welcome you say anything that sigil well

00:17:09,830 --> 00:17:16,580
could we can do rodo can do and for

00:17:14,900 --> 00:17:19,190
people again who don't know a lot about

00:17:16,580 --> 00:17:21,200
databases you've got all these different

00:17:19,190 --> 00:17:24,589
types of databases that are very similar

00:17:21,200 --> 00:17:26,540
but just a little bit different sig well

00:17:24,589 --> 00:17:30,490
can we use a Python library that kind of

00:17:26,540 --> 00:17:32,150
abstract SAT a waste for you so you can

00:17:30,490 --> 00:17:38,750
not have to worry about those

00:17:32,150 --> 00:17:41,570
differences so much so that was really a

00:17:38,750 --> 00:17:44,960
sort of about changing formats and movie

00:17:41,570 --> 00:17:47,690
around it can also move it up on s3 for

00:17:44,960 --> 00:17:49,850
you that's somewhere on amazon's cloud

00:17:47,690 --> 00:17:53,090
that can store your data for you so you

00:17:49,850 --> 00:17:57,320
can read it from s3 or you can upload it

00:17:53,090 --> 00:18:00,790
to s3 again with a single line missing a

00:17:57,320 --> 00:18:00,790
bracket there apologies

00:18:04,260 --> 00:18:10,540
or if you need to download your file

00:18:07,270 --> 00:18:14,020
from another server first it can handle

00:18:10,540 --> 00:18:17,020
it for you as well so it can ssh onto a

00:18:14,020 --> 00:18:23,740
server and and download it it will copy

00:18:17,020 --> 00:18:25,510
it across for you quite easily so i can

00:18:23,740 --> 00:18:27,370
do quite a lot and it's easily

00:18:25,510 --> 00:18:29,260
extendable this is all different sort of

00:18:27,370 --> 00:18:35,380
format static that it knows about at the

00:18:29,260 --> 00:18:37,720
moment and can handle but it's not this

00:18:35,380 --> 00:18:39,160
massive library that knows about all

00:18:37,720 --> 00:18:41,020
these different data formats it just

00:18:39,160 --> 00:18:43,000
call that to the rest library that kind

00:18:41,020 --> 00:18:45,670
of exists so you know if it's ready in a

00:18:43,000 --> 00:18:47,350
CSV it's going to do pan der stadt read

00:18:45,670 --> 00:18:49,810
CSV and if you need to be a bit more

00:18:47,350 --> 00:18:51,490
precise about how you want the data

00:18:49,810 --> 00:18:52,630
reading then you can pass in some

00:18:51,490 --> 00:19:01,630
keyword arguments and that will get

00:18:52,630 --> 00:19:02,920
passed to the underlying method so we'll

00:19:01,630 --> 00:19:04,780
talk about odo which is essentially you

00:19:02,920 --> 00:19:08,950
know copy from here to here change the

00:19:04,780 --> 00:19:11,850
format if need be or weighted into you

00:19:08,950 --> 00:19:15,130
know variable that I want you can also

00:19:11,850 --> 00:19:16,960
drop it so if you've copied it from

00:19:15,130 --> 00:19:19,720
somewhere and you don't need anymore you

00:19:16,960 --> 00:19:27,040
can say okay get rid of it drop just you

00:19:19,720 --> 00:19:28,210
know database speak for delete so one

00:19:27,040 --> 00:19:30,550
thing you may have noticed though was

00:19:28,210 --> 00:19:34,060
you know the where a passing these two

00:19:30,550 --> 00:19:37,600
things which is you know why CSV put it

00:19:34,060 --> 00:19:41,730
into the database how does it know what

00:19:37,600 --> 00:19:43,990
format to to give each column of my data

00:19:41,730 --> 00:19:46,840
how do I tell it that it's a date and

00:19:43,990 --> 00:19:53,980
not a string in the you know sign up

00:19:46,840 --> 00:19:57,430
date column and that's where data shape

00:19:53,980 --> 00:19:59,020
comes in so we have a few things that

00:19:57,430 --> 00:20:01,300
already exists that kind of talk about

00:19:59,020 --> 00:20:03,910
okay here's the structure of my data

00:20:01,300 --> 00:20:07,390
here are the columns here's the types of

00:20:03,910 --> 00:20:11,650
my columns we have sequel schemas we

00:20:07,390 --> 00:20:13,630
have handers d types and what data data

00:20:11,650 --> 00:20:18,540
shape essentially does is kind of

00:20:13,630 --> 00:20:18,540
abstract away those ideas

00:20:19,169 --> 00:20:29,799
into kind of a high level abstraction so

00:20:28,360 --> 00:20:33,820
essentially what we do is you create a

00:20:29,799 --> 00:20:37,210
string that describes what your data

00:20:33,820 --> 00:20:38,830
looks like and what the types are so

00:20:37,210 --> 00:20:41,950
really that this the second line on that

00:20:38,830 --> 00:20:45,789
slide is really all you need to know to

00:20:41,950 --> 00:20:48,909
get going which is the vast star is just

00:20:45,789 --> 00:20:50,679
saying there's going to be could be any

00:20:48,909 --> 00:20:54,279
number of rows there could be ten a

00:20:50,679 --> 00:20:58,899
hundred thousand there's three columns

00:20:54,279 --> 00:21:01,179
named joined and credit and in turn that

00:20:58,899 --> 00:21:07,899
name is the string joined as a date time

00:21:01,179 --> 00:21:09,850
and credit is a decimal number if you do

00:21:07,899 --> 00:21:11,889
want to be more precise and it's you

00:21:09,850 --> 00:21:15,820
know there's going to be 10 rows you can

00:21:11,889 --> 00:21:20,679
specify it that as well but that's what

00:21:15,820 --> 00:21:22,840
you do different backends perform better

00:21:20,679 --> 00:21:24,669
if you can tell it how long you know the

00:21:22,840 --> 00:21:28,360
biggest string can be so you can specify

00:21:24,669 --> 00:21:30,580
that and if you give it a question mark

00:21:28,360 --> 00:21:33,279
at the at the beginning of the type then

00:21:30,580 --> 00:21:40,000
it means this can be an empty value can

00:21:33,279 --> 00:21:44,820
be null so now our example we can say

00:21:40,000 --> 00:21:48,720
okay here's what the data types are and

00:21:44,820 --> 00:21:53,100
this whirlwind up with a database kong

00:21:48,720 --> 00:21:53,100
that fits with our data is

00:21:59,780 --> 00:22:04,080
yeah so you know I'm going to talk about

00:22:02,100 --> 00:22:05,990
three libraries in this talk one risotto

00:22:04,080 --> 00:22:08,190
which we've covered which is you know

00:22:05,990 --> 00:22:11,640
moving your data around and changing

00:22:08,190 --> 00:22:16,050
formats for you and data shape that

00:22:11,640 --> 00:22:19,740
helps you abstractly say what your data

00:22:16,050 --> 00:22:22,200
looks like and what blaze does is let

00:22:19,740 --> 00:22:24,690
you sort of separate what you want to

00:22:22,200 --> 00:22:29,280
calculate from what your data is and and

00:22:24,690 --> 00:22:32,429
to be able to do that with an API that

00:22:29,280 --> 00:22:36,720
looks like pandas and you do that by

00:22:32,429 --> 00:22:41,820
building expressions it'll only

00:22:36,720 --> 00:22:43,020
calculate when it needs to and once

00:22:41,820 --> 00:22:45,030
you've built your expression you can

00:22:43,020 --> 00:22:49,050
switch the backend seamlessly so you can

00:22:45,030 --> 00:22:54,809
develop on a CSV and then you can run it

00:22:49,050 --> 00:22:59,910
on a database or wherever else that is

00:22:54,809 --> 00:23:02,790
supported so see this is some of the

00:22:59,910 --> 00:23:05,040
backends that it currently exists so it

00:23:02,790 --> 00:23:10,130
can work in pure python you can just

00:23:05,040 --> 00:23:13,890
lists and iterators it can use pandas

00:23:10,130 --> 00:23:18,000
it's got quite a few smarts around some

00:23:13,890 --> 00:23:20,480
panas things that it can do where can do

00:23:18,000 --> 00:23:26,730
it in the chunked fashion so for example

00:23:20,480 --> 00:23:32,309
I've got 100 / CSVs and I want to know

00:23:26,730 --> 00:23:35,820
the sum of the transaction amount column

00:23:32,309 --> 00:23:38,880
for all of them I can just sort of in

00:23:35,820 --> 00:23:40,290
one line or in a couple of lines tell it

00:23:38,880 --> 00:23:43,320
the calculation what it will do is

00:23:40,290 --> 00:23:45,929
already 20 in turn calculate some of

00:23:43,320 --> 00:23:47,670
each one keep track of all that Sun them

00:23:45,929 --> 00:23:50,850
all together to get the grand sum and

00:23:47,670 --> 00:23:57,540
they'll do that without having to eat up

00:23:50,850 --> 00:24:00,570
all you or your memory necessarily it

00:23:57,540 --> 00:24:03,450
can do SQL so you know without having to

00:24:00,570 --> 00:24:05,580
know SQL you can communicate and do a

00:24:03,450 --> 00:24:07,030
lot of stuff that you would do in a

00:24:05,580 --> 00:24:10,100
normal database

00:24:07,030 --> 00:24:13,730
so if you do a bit of research after

00:24:10,100 --> 00:24:16,190
this talk and find some some of the blog

00:24:13,730 --> 00:24:17,990
post by the the author so should give a

00:24:16,190 --> 00:24:21,500
shout out I think that the the main

00:24:17,990 --> 00:24:27,890
author of this project is a guy called

00:24:21,500 --> 00:24:30,740
Matthew Rockland and there's a few

00:24:27,890 --> 00:24:33,830
interesting blog post one is an example

00:24:30,740 --> 00:24:36,890
where they've got the exact same data

00:24:33,830 --> 00:24:38,840
set in different formats and they're

00:24:36,890 --> 00:24:41,059
running it on these different formats

00:24:38,840 --> 00:24:42,850
and seeing what the speedup is and so he

00:24:41,059 --> 00:24:45,260
writes his calculation once you know

00:24:42,850 --> 00:24:47,120
what he wants to figure out and then he

00:24:45,260 --> 00:24:49,190
just switches back ends and sees how

00:24:47,120 --> 00:24:51,530
much faster would be if he had it you

00:24:49,190 --> 00:24:54,380
know database instead of a CSV let

00:24:51,530 --> 00:24:57,470
me just laptop or if you put it on to

00:24:54,380 --> 00:25:05,059
sigalert or let's say he's got any

00:24:57,470 --> 00:25:07,450
Starbase and so hey I think it's going

00:25:05,059 --> 00:25:07,450
to come back

00:25:14,559 --> 00:25:17,660
the other thing you can do when you

00:25:16,340 --> 00:25:21,710
switch back ends is you can do things

00:25:17,660 --> 00:25:23,360
like add a database index on specific

00:25:21,710 --> 00:25:26,240
columns that might make sense and it

00:25:23,360 --> 00:25:34,309
will figure that out for you that might

00:25:26,240 --> 00:25:37,040
make a big performance difference and

00:25:34,309 --> 00:25:38,720
just a note my first example is going to

00:25:37,040 --> 00:25:40,400
be kind of quite explicit about saying

00:25:38,720 --> 00:25:42,679
okay here's what the types are in the

00:25:40,400 --> 00:25:44,240
columns but there's a lot of sort of

00:25:42,679 --> 00:25:46,490
smarts here where it can figure that out

00:25:44,240 --> 00:25:48,200
for you and if it guesses it wrong you

00:25:46,490 --> 00:25:52,250
can sort of tweak it but you don't have

00:25:48,200 --> 00:26:01,429
to kind of be so explicit in saying all

00:25:52,250 --> 00:26:06,919
that so people who know some some pandas

00:26:01,429 --> 00:26:08,720
this should look pretty familiar so we

00:26:06,919 --> 00:26:11,030
create our accounts object here which is

00:26:08,720 --> 00:26:13,730
kind of that's our data set and it's a

00:26:11,030 --> 00:26:18,290
data set that we're calling it accounts

00:26:13,730 --> 00:26:22,070
it has this D shape data shape which is

00:26:18,290 --> 00:26:24,919
any number of rows with an ID which is

00:26:22,070 --> 00:26:30,169
an integer a name which is a string and

00:26:24,919 --> 00:26:32,210
an amount again which is an integer and

00:26:30,169 --> 00:26:34,700
we're caught we're calculating cool

00:26:32,210 --> 00:26:40,280
people which is people with the name Lex

00:26:34,700 --> 00:26:42,230
and just to kind of highlight that this

00:26:40,280 --> 00:26:45,260
isn't this hasn't calculate anything

00:26:42,230 --> 00:26:47,600
this is just saying this is an

00:26:45,260 --> 00:26:49,850
expression this is a calculation that

00:26:47,600 --> 00:26:53,380
we're going to run on some data set that

00:26:49,850 --> 00:26:53,380
we haven't you haven't seen yet

00:26:56,000 --> 00:27:01,380
so let's run it against the pure python

00:26:58,230 --> 00:27:06,060
list he's our data set it's got some IDs

00:27:01,380 --> 00:27:08,130
some names and some amounts say

00:27:06,060 --> 00:27:10,590
everything happens with this computer

00:27:08,130 --> 00:27:14,820
function that we say give compute our

00:27:10,590 --> 00:27:18,900
expression in our data set and it'll

00:27:14,820 --> 00:27:20,820
figure out by which type of data set

00:27:18,900 --> 00:27:25,250
that I give it whether or not to use

00:27:20,820 --> 00:27:29,010
Python code panda's code sequel code etc

00:27:25,250 --> 00:27:31,320
and so you can see here it's figure out

00:27:29,010 --> 00:27:32,760
the result and I've r up there in the

00:27:31,320 --> 00:27:38,490
list because otherwise it's going to

00:27:32,760 --> 00:27:41,550
return me an iterator so now we can run

00:27:38,490 --> 00:27:43,590
our calculation on any native vacuum

00:27:41,550 --> 00:27:44,910
that we choose we can run it in pandas

00:27:43,590 --> 00:27:47,130
we can run it against the sequel

00:27:44,910 --> 00:27:55,440
database and MongoDB database all those

00:27:47,130 --> 00:27:56,940
backends that we spoke about so here's

00:27:55,440 --> 00:27:59,490
some more examples we're running an

00:27:56,940 --> 00:28:05,490
exact same calculation but now we're

00:27:59,490 --> 00:28:07,790
training in pandas and then about

00:28:05,490 --> 00:28:16,410
another example we just load up our

00:28:07,790 --> 00:28:19,680
database and you know this looks like

00:28:16,410 --> 00:28:21,480
it's you know pandas or some dumb play

00:28:19,680 --> 00:28:23,010
code but under the hood what that's

00:28:21,480 --> 00:28:27,300
going to do is connect to the database

00:28:23,010 --> 00:28:29,150
and give it a sequel query and if you've

00:28:27,300 --> 00:28:32,310
got lots of database well you've got a

00:28:29,150 --> 00:28:35,100
powerful database server and a crappy

00:28:32,310 --> 00:28:40,250
laptop that could be you know much much

00:28:35,100 --> 00:28:40,250
faster perhaps than the alternatives

00:28:42,300 --> 00:28:48,730
so now you know what your API we can use

00:28:47,170 --> 00:28:50,650
your sort of panners like a PIAA on any

00:28:48,730 --> 00:28:53,140
back-end now all you need to do is learn

00:28:50,650 --> 00:28:54,520
the API which if you know pandas he

00:28:53,140 --> 00:28:56,260
almost do it's like a little bit

00:28:54,520 --> 00:28:58,450
different in some places but it's

00:28:56,260 --> 00:29:00,390
essentially the same if you check out

00:28:58,450 --> 00:29:02,800
these two links it gives a really good

00:29:00,390 --> 00:29:05,800
overview of people who already know

00:29:02,800 --> 00:29:07,510
either pandas or sequel how to do some

00:29:05,800 --> 00:29:11,670
things in blaze I'll give you a quick

00:29:07,510 --> 00:29:13,780
call out of those and then wrap it up

00:29:11,670 --> 00:29:15,480
since these are some of the main ones

00:29:13,780 --> 00:29:17,950
you've got buyer which is for doing

00:29:15,480 --> 00:29:20,650
essentially group by operations you've

00:29:17,950 --> 00:29:29,530
got joined for joining different data

00:29:20,650 --> 00:29:31,240
sets on a particular column and just

00:29:29,530 --> 00:29:33,310
prefer i go over that some other smart

00:29:31,240 --> 00:29:34,360
things that this technology do that i'm

00:29:33,310 --> 00:29:37,210
not really going to be able to cover in

00:29:34,360 --> 00:29:39,480
depth is kind of touched on the first

00:29:37,210 --> 00:29:42,100
one you can sort of chunk your data and

00:29:39,480 --> 00:29:46,750
be able to told you about doing that for

00:29:42,100 --> 00:29:49,660
larger data sets i can use task which is

00:29:46,750 --> 00:29:52,840
a new sort of fancy pants numpy out of

00:29:49,660 --> 00:29:54,940
core technology and it does have some

00:29:52,840 --> 00:29:58,900
things at work and paralyze your code so

00:29:54,940 --> 00:30:03,730
here we're calling the map function and

00:29:58,900 --> 00:30:05,230
if we first create this multiprocessing

00:30:03,730 --> 00:30:08,770
pool then it's going to run over

00:30:05,230 --> 00:30:10,570
multiple calls I should call out though

00:30:08,770 --> 00:30:12,070
that you know these things aren't magic

00:30:10,570 --> 00:30:15,520
civil BOTS where it's going to speed up

00:30:12,070 --> 00:30:20,200
every situation but in particular cases

00:30:15,520 --> 00:30:22,150
it might make a big difference so this

00:30:20,200 --> 00:30:26,350
looks like dental two pandas you can

00:30:22,150 --> 00:30:29,620
refer to a column this either like a

00:30:26,350 --> 00:30:32,320
dictionary type or as an attribute you

00:30:29,620 --> 00:30:36,280
can do maths in line you can call the

00:30:32,320 --> 00:30:38,080
map function this is how you were

00:30:36,280 --> 00:30:40,500
gripped by so here we're grouping by

00:30:38,080 --> 00:30:44,610
person what was their total amount spent

00:30:40,500 --> 00:30:44,610
what was the average amount spent

00:30:47,330 --> 00:30:52,430
we can add ghee columns from dry from

00:30:50,510 --> 00:30:54,290
other columns so you could do a ratio

00:30:52,430 --> 00:30:56,480
between columns here I've got the amount

00:30:54,290 --> 00:30:58,700
incensed by just timesing it by 100 and

00:30:56,480 --> 00:31:03,320
say imagine now has a new column in it

00:30:58,700 --> 00:31:07,190
that accounts dinner we can rename our

00:31:03,320 --> 00:31:10,250
columns this is doing some string

00:31:07,190 --> 00:31:18,050
matching what's matching we're stereo

00:31:10,250 --> 00:31:22,040
licks we can join them together I think

00:31:18,050 --> 00:31:23,840
of cover that enough so I haven't got

00:31:22,040 --> 00:31:26,810
time to go over bleh server check it out

00:31:23,840 --> 00:31:29,210
is it allows you to create a server that

00:31:26,810 --> 00:31:31,070
then allows other people to connect to

00:31:29,210 --> 00:31:37,390
it and interface it just by writing

00:31:31,070 --> 00:31:39,410
blast code essentially so if I wrap up

00:31:37,390 --> 00:31:42,140
when I first heard about this I thought

00:31:39,410 --> 00:31:44,300
it was quite it's quite exciting

00:31:42,140 --> 00:31:45,950
technology and you know I've spent a lot

00:31:44,300 --> 00:31:49,700
of time learning those libraries that I

00:31:45,950 --> 00:31:52,280
said that the non copal don't have to

00:31:49,700 --> 00:31:57,080
and you know now maybe I can forget them

00:31:52,280 --> 00:31:59,240
and just use your stuff but yeah this

00:31:57,080 --> 00:32:00,770
isn't a magic bullet but at the moment

00:31:59,240 --> 00:32:03,560
it can really only do the things that

00:32:00,770 --> 00:32:06,380
all those technologies can do do in

00:32:03,560 --> 00:32:08,180
common however I think that will might

00:32:06,380 --> 00:32:11,480
can in many cases can give you an awful

00:32:08,180 --> 00:32:15,680
long way it's not the answer to every

00:32:11,480 --> 00:32:18,380
problem but at work you know I deal with

00:32:15,680 --> 00:32:20,180
sort of analysts who are programmers but

00:32:18,380 --> 00:32:21,440
they're you know they know Excel and you

00:32:20,180 --> 00:32:23,180
know you think about okay should I teach

00:32:21,440 --> 00:32:24,650
them some Python should I teach them

00:32:23,180 --> 00:32:27,650
some pandas should I teach them some

00:32:24,650 --> 00:32:30,580
sequel what should I shall we get them a

00:32:27,650 --> 00:32:32,840
bit using some more powerful tools I

00:32:30,580 --> 00:32:35,900
think if you use this technology you can

00:32:32,840 --> 00:32:39,560
teach them blaze and pandas and they can

00:32:35,900 --> 00:32:42,680
interface through sequel or data or s3

00:32:39,560 --> 00:32:45,320
really easily I think it might be a nice

00:32:42,680 --> 00:32:47,690
idea if pandas could adopt some of the

00:32:45,320 --> 00:32:49,310
api's which I think some of them are a

00:32:47,690 --> 00:32:52,240
little bit nicer than pandas but even

00:32:49,310 --> 00:32:52,240
though they're very similar and

00:32:52,630 --> 00:32:57,740
separating your data from your

00:32:54,710 --> 00:32:59,000
computation is a good idea and the docs

00:32:57,740 --> 00:33:03,700
are really good

00:32:59,000 --> 00:33:03,700
and questions

00:33:07,620 --> 00:33:09,680
you

00:33:19,090 --> 00:33:21,150

YouTube URL: https://www.youtube.com/watch?v=Ie7XdxTL5MY


