Title: Predicting sports winners using data analytics with pandas and scikit-learn by Robert Layton
Publication date: 2015-08-06
Playlist: PyCon Australia 2015 Science & Data Miniconf
Description: 
	The pandas and scikit-learn packages combine together to produce a powerful toolkit for data analytics. In this talk, we will be using them together to analyse the outcome of NBA games, trying to predict the winner of a match. There is plenty of data out there to allow us to create good predictions â€“ the key is getting it in the right format and building the right model.

In this talk we will go through importing data from the net, cleaning it up, creating new features, and building a predictive model. We then evaluate how well we did, using recent NBA data. The model we use will be a decision tree ensemble called a random forest.

PyCon Australia is the national conference for users of the Python Programming Language. In 2015, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

July 31-August 4, Brisbane, Queensland, Australia
Captions: 
	00:00:10,289 --> 00:00:15,070
all right good afternoon everyone for no

00:00:13,179 --> 00:00:17,740
reason in particular I'm helping with

00:00:15,070 --> 00:00:19,449
the introductions this afternoon our

00:00:17,740 --> 00:00:21,460
first speakers Robert Leighton Roberts

00:00:19,449 --> 00:00:23,140
been giving the same presentation for

00:00:21,460 --> 00:00:25,779
about four years now I think the content

00:00:23,140 --> 00:00:27,880
keeps changing but he's a regular

00:00:25,779 --> 00:00:29,410
so yeah the feet the feedback I get to

00:00:27,880 --> 00:00:31,929
see some of the post conference feedback

00:00:29,410 --> 00:00:34,300
Roberts feedbacks always very strong

00:00:31,929 --> 00:00:36,430
learned a lot so I don't think he can

00:00:34,300 --> 00:00:38,079
get a much stronger indication that he's

00:00:36,430 --> 00:00:49,170
going to be a competent speaker so

00:00:38,079 --> 00:00:51,699
everyone have a good session yes soft

00:00:49,170 --> 00:00:53,739
okay I'll just talk louder all right

00:00:51,699 --> 00:00:56,079
yeah so my name is Robert Leighton I

00:00:53,739 --> 00:00:58,390
wear a number of hats I run my own

00:00:56,079 --> 00:01:00,640
consultancy firm called data pipeline

00:00:58,390 --> 00:01:02,890
I'm also a research fellow at Federation

00:01:00,640 --> 00:01:06,070
University where I look at applying data

00:01:02,890 --> 00:01:08,619
analytics to cyber crimes particularly

00:01:06,070 --> 00:01:11,770
around attribution I've also been doing

00:01:08,619 --> 00:01:13,990
some training for Python charmers and

00:01:11,770 --> 00:01:15,610
I'm also a hacker at the Ballarat hacker

00:01:13,990 --> 00:01:18,190
space so it's where I'm learning

00:01:15,610 --> 00:01:21,190
hardware and I integrated chip

00:01:18,190 --> 00:01:23,020
development and stuff like that and I

00:01:21,190 --> 00:01:25,030
got an email this morning saying the my

00:01:23,020 --> 00:01:28,239
new book is out so learning garden

00:01:25,030 --> 00:01:34,750
mining with pythons yeah so feel free to

00:01:28,239 --> 00:01:36,580
grab three or four copies so today the

00:01:34,750 --> 00:01:41,649
task is to predict the winner of an NBA

00:01:36,580 --> 00:01:46,300
game so MBA is the American Basketball

00:01:41,649 --> 00:01:48,819
League it is it has a couple of unique

00:01:46,300 --> 00:01:49,989
but perhaps not unique properties but

00:01:48,819 --> 00:01:53,170
some special properties are worth

00:01:49,989 --> 00:01:55,509
mentioning the first is a lot of NBA

00:01:53,170 --> 00:01:57,940
games to play throughout the season for

00:01:55,509 --> 00:02:00,940
those that probably don't follow it

00:01:57,940 --> 00:02:04,720
there are 30 teams 29 from the America

00:02:00,940 --> 00:02:07,869
and one from Canada they play several

00:02:04,720 --> 00:02:10,030
times a week for about three months or

00:02:07,869 --> 00:02:12,280
something like that most teams play

00:02:10,030 --> 00:02:16,270
about 80 game I think it's 80 games us

00:02:12,280 --> 00:02:18,909
on my head and we have 1230 games per

00:02:16,270 --> 00:02:20,140
season before the playoffs and then

00:02:18,909 --> 00:02:23,019
there's a whole bunch of playoff games

00:02:20,140 --> 00:02:23,530
sort of played as well so as far as

00:02:23,019 --> 00:02:27,150
sports

00:02:23,530 --> 00:02:30,360
goes actually a pretty rich dataset and

00:02:27,150 --> 00:02:36,130
one difficult thing about MBA games is

00:02:30,360 --> 00:02:38,560
most games will in most games the score

00:02:36,130 --> 00:02:42,580
is something around the lines of 100 to

00:02:38,560 --> 00:02:44,350
90 with some variation both ways a huge

00:02:42,580 --> 00:02:47,200
percentage of games are decided by less

00:02:44,350 --> 00:02:48,489
than 10 points and when you take those

00:02:47,200 --> 00:02:53,709
percentages and compare it to other

00:02:48,489 --> 00:02:56,320
sports the MBA is a very close game so

00:02:53,709 --> 00:02:58,720
our task say is not particularly an easy

00:02:56,320 --> 00:02:59,980
one but what we're going to do today is

00:02:58,720 --> 00:03:01,950
we're going to extract some features

00:02:59,980 --> 00:03:04,480
from the standard dataset we're going to

00:03:01,950 --> 00:03:06,250
create some new features using pandas

00:03:04,480 --> 00:03:08,319
we're going to chuck that into

00:03:06,250 --> 00:03:10,989
scikit-learn we're going to use our

00:03:08,319 --> 00:03:14,380
previous newly learned information about

00:03:10,989 --> 00:03:17,290
random forests and and then build a

00:03:14,380 --> 00:03:20,220
classifier and see how well it does so

00:03:17,290 --> 00:03:23,470
that's what we're aiming to do today and

00:03:20,220 --> 00:03:27,310
this material is also loosely based on

00:03:23,470 --> 00:03:29,860
chapter 3 my book in him so the data

00:03:27,310 --> 00:03:32,709
we're getting can be found from

00:03:29,860 --> 00:03:35,620
Basketball Reference com it is very

00:03:32,709 --> 00:03:39,730
comprehensive it contains a results from

00:03:35,620 --> 00:03:44,280
games going back 40 years it has place

00:03:39,730 --> 00:03:48,760
that's location stats league standings

00:03:44,280 --> 00:03:50,320
who the most valuable player was it is

00:03:48,760 --> 00:03:52,510
very comprehensive the one thing it

00:03:50,320 --> 00:03:54,100
doesn't have and I'm just pre-empting a

00:03:52,510 --> 00:03:57,160
question for the end here is it doesn't

00:03:54,100 --> 00:03:59,350
have the odds of who of the the team's

00:03:57,160 --> 00:04:00,910
going into the match so I can't answer

00:03:59,350 --> 00:04:06,280
the question of how much money this

00:04:00,910 --> 00:04:07,390
would have made yep so so if you want to

00:04:06,280 --> 00:04:11,100
replicate the data

00:04:07,390 --> 00:04:13,840
I'm not going to distribute the files

00:04:11,100 --> 00:04:15,549
because I'm not sure I'm allowed to but

00:04:13,840 --> 00:04:17,289
you basically go to one of these pages

00:04:15,549 --> 00:04:19,209
and you click this export button here

00:04:17,289 --> 00:04:28,510
and you get exactly the father I used to

00:04:19,209 --> 00:04:32,320
load up we are using Python 3.4 pandas

00:04:28,510 --> 00:04:35,289
which is pretty much recent 3.5 still

00:04:32,320 --> 00:04:37,449
heavily heavily development Panda is

00:04:35,289 --> 00:04:41,789
0.16 which I think

00:04:37,449 --> 00:04:44,830
fairly recent and scikit-learn 0.16

00:04:41,789 --> 00:04:47,889
there's not a whole lot in this talk

00:04:44,830 --> 00:04:50,379
that requires such recent versions both

00:04:47,889 --> 00:04:52,629
pens and scikit-learn can probably go

00:04:50,379 --> 00:04:57,789
down a few versions so don't worry too

00:04:52,629 --> 00:05:02,620
much so the first thing we do is we load

00:04:57,789 --> 00:05:07,809
this file which is MBA 2014 gains gains

00:05:02,620 --> 00:05:08,949
dot CSV and what that what that is going

00:05:07,809 --> 00:05:10,779
to give us is it's going to give us

00:05:08,949 --> 00:05:13,689
what's called the box scores for each of

00:05:10,779 --> 00:05:15,490
the NBA games in that season which is

00:05:13,689 --> 00:05:16,930
basically for the home team was who the

00:05:15,490 --> 00:05:22,180
visitor team was and how many points

00:05:16,930 --> 00:05:24,099
each of them scored and it's always

00:05:22,180 --> 00:05:26,620
important to start with the end with the

00:05:24,099 --> 00:05:28,749
end in mind and for that reason we're

00:05:26,620 --> 00:05:31,529
going to create our scoring mechanism

00:05:28,749 --> 00:05:34,509
we're going to use the f1 score

00:05:31,529 --> 00:05:38,439
predominantly in this talk the f1 score

00:05:34,509 --> 00:05:40,449
is the for those with them for those

00:05:38,439 --> 00:05:42,819
with some data mining experience block

00:05:40,449 --> 00:05:44,589
your ears for those with no data mining

00:05:42,819 --> 00:05:47,439
experience it's loosely correlated to

00:05:44,589 --> 00:05:53,080
the accuracy but it's less likely to

00:05:47,439 --> 00:05:54,729
biased by by certain factors all we're

00:05:53,080 --> 00:05:58,149
doing here is we're creating a scoring

00:05:54,729 --> 00:06:01,659
function which is the f1 score we care

00:05:58,149 --> 00:06:04,899
about both wins and losses for the home

00:06:01,659 --> 00:06:06,459
team which we'll get to in a second if

00:06:04,899 --> 00:06:10,659
we don't have this at all I only care

00:06:06,459 --> 00:06:14,159
about wins and we want average weighted

00:06:10,659 --> 00:06:17,189
so we care about the results overall

00:06:14,159 --> 00:06:19,539
it's not a horrible set important just

00:06:17,189 --> 00:06:22,749
just let it be no and it's roughly

00:06:19,539 --> 00:06:28,659
accuracy so this is what our data looks

00:06:22,749 --> 00:06:31,419
like date teams their scores a none

00:06:28,659 --> 00:06:32,949
couple of our names columns one which is

00:06:31,419 --> 00:06:38,110
completely pointless it just says box

00:06:32,949 --> 00:06:40,810
score and two columns at the end I don't

00:06:38,110 --> 00:06:42,849
think this is used at all and all this

00:06:40,810 --> 00:06:45,009
column here is indicates whether there

00:06:42,849 --> 00:06:46,659
was an overtime another property about

00:06:45,009 --> 00:06:48,669
MBO matches is

00:06:46,659 --> 00:06:50,530
there are never drawers

00:06:48,669 --> 00:06:52,539
if there's a draw at the end of

00:06:50,530 --> 00:06:56,159
regulation time they'll just keep

00:06:52,539 --> 00:06:59,590
playing overtime until there's a winner

00:06:56,159 --> 00:07:01,300
so it makes it a bit easy whereas with

00:06:59,590 --> 00:07:03,490
an AFL match for instance we would have

00:07:01,300 --> 00:07:05,740
to factor in draws into our calculations

00:07:03,490 --> 00:07:08,039
teams are the win or lose so that's

00:07:05,740 --> 00:07:08,039
pretty easy

00:07:08,490 --> 00:07:14,860
so once we've loaded our data set into

00:07:11,110 --> 00:07:16,990
pandas using the read CSV function it's

00:07:14,860 --> 00:07:19,479
had a look at our date column and didn't

00:07:16,990 --> 00:07:21,699
quite know the format so we just read it

00:07:19,479 --> 00:07:25,900
all the strings we're not going to use

00:07:21,699 --> 00:07:28,840
the date at all today but but I do would

00:07:25,900 --> 00:07:34,479
like to fix that and we'll also fix up

00:07:28,840 --> 00:07:36,599
the headings so to do that we can set

00:07:34,479 --> 00:07:38,919
the date column to be passed as a date

00:07:36,599 --> 00:07:44,139
and that means it will just try a bit

00:07:38,919 --> 00:07:47,169
harder and and you can see there that I

00:07:44,139 --> 00:07:48,789
think I don't show the d-types but the

00:07:47,169 --> 00:07:50,800
date in the different formats what it is

00:07:48,789 --> 00:07:53,110
in the file it was represented as a day

00:07:50,800 --> 00:07:58,650
time object so we could now for instance

00:07:53,110 --> 00:08:02,469
compare two dates if we wanted to and

00:07:58,650 --> 00:08:04,810
and also our heading names of a bit

00:08:02,469 --> 00:08:09,490
better now so we can work out what this

00:08:04,810 --> 00:08:11,440
column is so what we're gonna do now is

00:08:09,490 --> 00:08:13,750
we're going to create the thing that

00:08:11,440 --> 00:08:16,750
we're going to try and predict we're

00:08:13,750 --> 00:08:18,219
going to take this data set and we're

00:08:16,750 --> 00:08:20,319
going to create a classifier that will

00:08:18,219 --> 00:08:22,539
determine whether the home team is going

00:08:20,319 --> 00:08:24,219
to win that game or not so we're going

00:08:22,539 --> 00:08:27,669
to create a new feature which is called

00:08:24,219 --> 00:08:29,589
home win and it's going to be the result

00:08:27,669 --> 00:08:32,620
of whether visitors points was less than

00:08:29,589 --> 00:08:35,849
home points it will be true if the home

00:08:32,620 --> 00:08:38,709
team won it'll be false if they did not

00:08:35,849 --> 00:08:41,260
so you can see there with the first game

00:08:38,709 --> 00:08:43,870
indiana pacers where the home team

00:08:41,260 --> 00:08:48,370
they score more points in orlando so

00:08:43,870 --> 00:08:50,620
they won pretty straightforward and the

00:08:48,370 --> 00:08:53,769
next thing we do here is we grab those

00:08:50,620 --> 00:08:55,990
values so why true equals we grab the

00:08:53,769 --> 00:08:59,410
values here and we and that's going to

00:08:55,990 --> 00:09:00,630
be an UMP numpy array and that those are

00:08:59,410 --> 00:09:09,149
the values we're going to try and

00:09:00,630 --> 00:09:10,949
oh those are the types and also when you

00:09:09,149 --> 00:09:13,709
started on my own chart it's important

00:09:10,949 --> 00:09:15,810
to know what the baseline is very simple

00:09:13,709 --> 00:09:17,730
base line here is chance if we will just

00:09:15,810 --> 00:09:21,949
predict randomly how accurate or do we

00:09:17,730 --> 00:09:24,389
get the answer to that is 50% which is

00:09:21,949 --> 00:09:25,829
not quite the f measure but we'll just

00:09:24,389 --> 00:09:29,339
ignore that for now

00:09:25,829 --> 00:09:32,759
a better baseline for sports is the home

00:09:29,339 --> 00:09:34,649
team winning for most sports the home

00:09:32,759 --> 00:09:37,639
team will win more games than the

00:09:34,649 --> 00:09:43,050
visitor team this has been widely

00:09:37,639 --> 00:09:47,850
recognized and is also true of MBA so

00:09:43,050 --> 00:09:51,389
the home team will win 58% of matches so

00:09:47,850 --> 00:09:53,970
if we want our model to be useful at all

00:09:51,389 --> 00:09:57,089
we need to beat that that measure so if

00:09:53,970 --> 00:10:00,329
we convert that to an F measure all

00:09:57,089 --> 00:10:03,089
we're doing here is predicting home team

00:10:00,329 --> 00:10:04,949
wins so you can think of this as a very

00:10:03,089 --> 00:10:08,329
simple classifier which is predict home

00:10:04,949 --> 00:10:10,769
team wins all the time and then we use L

00:10:08,329 --> 00:10:14,220
not quite the score we code before but

00:10:10,769 --> 00:10:18,959
the same parameters we calculate our f1

00:10:14,220 --> 00:10:21,300
score and we get 0.42 or 0.4 3 if we're

00:10:18,959 --> 00:10:26,399
going to round that way so that's a

00:10:21,300 --> 00:10:27,720
score we need to be so we're going to

00:10:26,399 --> 00:10:28,920
create some more features because we're

00:10:27,720 --> 00:10:30,230
going to make a classifier that's a

00:10:28,920 --> 00:10:34,769
little bit better than that

00:10:30,230 --> 00:10:37,319
so the first first features are thought

00:10:34,769 --> 00:10:41,339
about where what did the team's win

00:10:37,319 --> 00:10:43,410
their previous game so we're going to

00:10:41,339 --> 00:10:46,050
create this in a very inefficient wave

00:10:43,410 --> 00:10:48,360
here and I'll show you how to create it

00:10:46,050 --> 00:10:52,410
more efficiently or create a similar

00:10:48,360 --> 00:10:54,449
feature more efficiently in a minute so

00:10:52,410 --> 00:10:57,779
what we do here is we create a default

00:10:54,449 --> 00:11:00,329
dict which will default to 0 the first

00:10:57,779 --> 00:11:01,589
time a team is asked for and that's

00:11:00,329 --> 00:11:04,050
going to be whether the team won their

00:11:01,589 --> 00:11:06,630
last game we then iterate over all the

00:11:04,050 --> 00:11:08,250
rows we get the home team in the visitor

00:11:06,630 --> 00:11:10,319
team and then we look them up in there

00:11:08,250 --> 00:11:15,000
one last dictionary to see whether they

00:11:10,319 --> 00:11:18,180
won their last game so if they won their

00:11:15,000 --> 00:11:21,660
last game home one last will be 1 or

00:11:18,180 --> 00:11:24,899
true and if they didn't win their last

00:11:21,660 --> 00:11:29,160
game it'll be false so we grabbed those

00:11:24,899 --> 00:11:32,660
values set that to home last win and

00:11:29,160 --> 00:11:35,339
visitor last win and then set that row

00:11:32,660 --> 00:11:37,860
and then we update our home one last

00:11:35,339 --> 00:11:39,180
with whoever won the current game so

00:11:37,860 --> 00:11:42,360
what we're doing here it'll rain through

00:11:39,180 --> 00:11:45,689
the games creating these new features

00:11:42,360 --> 00:11:48,899
which screen was a little bit off here

00:11:45,689 --> 00:11:50,970
but you know creating these new features

00:11:48,899 --> 00:11:52,740
which is whether the home team won their

00:11:50,970 --> 00:11:54,540
last game and then updating our

00:11:52,740 --> 00:11:56,220
dictionary so that the next game we come

00:11:54,540 --> 00:12:04,350
across we know whether they won their

00:11:56,220 --> 00:12:07,130
last game honor and how many people were

00:12:04,350 --> 00:12:10,050
here for the random first talk before

00:12:07,130 --> 00:12:15,360
great so for those that weren't here

00:12:10,050 --> 00:12:18,720
sorry but we're gonna start off by using

00:12:15,360 --> 00:12:21,350
a basic decision tree classifier and all

00:12:18,720 --> 00:12:24,059
that does is just look for a value and

00:12:21,350 --> 00:12:26,100
split at that point so if they won their

00:12:24,059 --> 00:12:27,420
last game we'll go down this path if

00:12:26,100 --> 00:12:30,449
they didn't win their last game we'll go

00:12:27,420 --> 00:12:35,189
down this path and decide from there so

00:12:30,449 --> 00:12:36,949
using just these two features not even

00:12:35,189 --> 00:12:40,230
taking into consideration the home team

00:12:36,949 --> 00:12:42,180
explicitly we can we've already improved

00:12:40,230 --> 00:12:49,860
upon our baseline with an f1 score of

00:12:42,180 --> 00:12:51,750
0.5 so the sons get somewhere so the

00:12:49,860 --> 00:12:53,730
next thing we're going to do is extend

00:12:51,750 --> 00:12:55,079
that feature a little bit whether it not

00:12:53,730 --> 00:12:56,930
just whether they win their last game

00:12:55,079 --> 00:13:00,300
but whether they're on a winning streak

00:12:56,930 --> 00:13:03,959
winning streaks the NBA a batik a little

00:13:00,300 --> 00:13:05,550
bit troublesome to consider the team has

00:13:03,959 --> 00:13:07,529
won three or four games on the tribe

00:13:05,550 --> 00:13:11,040
that might actually fatigue them and be

00:13:07,529 --> 00:13:13,889
a negative thing but but let's have a

00:13:11,040 --> 00:13:17,010
look anyway so same same procedure the

00:13:13,889 --> 00:13:19,290
only difference so we we look up their

00:13:17,010 --> 00:13:20,850
win streak here the only difference is

00:13:19,290 --> 00:13:23,990
rather than just set whether they won

00:13:20,850 --> 00:13:25,680
their last game or not we increment the

00:13:23,990 --> 00:13:29,040
counter

00:13:25,680 --> 00:13:31,380
for the winner and we set it to zero for

00:13:29,040 --> 00:13:35,370
the loser so this is their win streak no

00:13:31,380 --> 00:13:37,950
other change from before and it's a

00:13:35,370 --> 00:13:40,710
slightly better but we use a couple more

00:13:37,950 --> 00:13:43,800
features so we include the last win for

00:13:40,710 --> 00:13:46,100
both teams and the win streak and then

00:13:43,800 --> 00:13:50,760
we create a new decision tree classifier

00:13:46,100 --> 00:13:52,770
and we're slightly better so at this

00:13:50,760 --> 00:13:55,770
point I'll explain two more things about

00:13:52,770 --> 00:13:58,220
what I've done here the first is a small

00:13:55,770 --> 00:14:00,360
point I've set the random state to be 14

00:13:58,220 --> 00:14:02,490
this means that you should be able to

00:14:00,360 --> 00:14:06,810
take this code with this data and get

00:14:02,490 --> 00:14:09,800
exactly that score so decision trees

00:14:06,810 --> 00:14:13,200
have some element of randomness in them

00:14:09,800 --> 00:14:16,140
not much but it this is more important

00:14:13,200 --> 00:14:19,830
when we get to random forests by setting

00:14:16,140 --> 00:14:21,270
the random state to a specific value all

00:14:19,830 --> 00:14:23,400
that randomness will happen in a

00:14:21,270 --> 00:14:27,330
terminus tic way and you'll get the

00:14:23,400 --> 00:14:28,680
results I do across fears the other

00:14:27,330 --> 00:14:30,240
thing we're going to do which is

00:14:28,680 --> 00:14:33,029
somewhere where I've forgotten to set

00:14:30,240 --> 00:14:36,260
the random state is crossbell score so

00:14:33,029 --> 00:14:38,220
this is where we do cross-validation a

00:14:36,260 --> 00:14:41,220
couple of talks have previously

00:14:38,220 --> 00:14:44,820
mentioned it basically what we do here

00:14:41,220 --> 00:14:47,100
and is split out data into chunks which

00:14:44,820 --> 00:14:48,810
we call folds we keep one of them out as

00:14:47,100 --> 00:14:51,209
our test data we're trained on the

00:14:48,810 --> 00:14:52,980
others and test it on that test data and

00:14:51,209 --> 00:14:55,320
then we change which fold means for our

00:14:52,980 --> 00:14:58,529
test data and we do that until all folds

00:14:55,320 --> 00:15:00,990
have been used as test data once so then

00:14:58,529 --> 00:15:04,500
that's why we have this line here which

00:15:00,990 --> 00:15:06,510
does the mean of the scores because our

00:15:04,500 --> 00:15:09,150
scores coming from Cross Fit valve score

00:15:06,510 --> 00:15:12,570
will be the test the evaluation on each

00:15:09,150 --> 00:15:21,630
of those folds as a test set so we get

00:15:12,570 --> 00:15:23,070
the mean that way so just using features

00:15:21,630 --> 00:15:24,750
that we derived from basic game

00:15:23,070 --> 00:15:28,350
information nothing about players

00:15:24,750 --> 00:15:30,360
nothing about any sort of context that

00:15:28,350 --> 00:15:33,690
the things were able to already improve

00:15:30,360 --> 00:15:38,000
upon our baseline but I thought what

00:15:33,690 --> 00:15:38,000
about general standings so

00:15:38,240 --> 00:15:44,089
the MBA calls it a standings AFL calls

00:15:41,000 --> 00:15:45,680
on a ladder so I'll use word ladder but

00:15:44,089 --> 00:15:47,240
basically what this is is where the

00:15:45,680 --> 00:15:49,730
where the teams ranked in the previous

00:15:47,240 --> 00:15:54,529
season whether they were where they had

00:15:49,730 --> 00:15:56,330
the best win-loss ratio or not so what

00:15:54,529 --> 00:15:58,300
we've done here is we've had a look at

00:15:56,330 --> 00:16:03,680
the standings for the previous year

00:15:58,300 --> 00:16:05,540
loaded that using pandas as before I've

00:16:03,680 --> 00:16:07,730
had to skip the first two rows because

00:16:05,540 --> 00:16:10,120
they were mostly blank well the first

00:16:07,730 --> 00:16:12,709
row was blank in the second row had some

00:16:10,120 --> 00:16:15,339
needless information and the other thing

00:16:12,709 --> 00:16:19,130
I've done here is set the index column

00:16:15,339 --> 00:16:21,740
without that pandas will create a new

00:16:19,130 --> 00:16:24,680
index down the lock down here starting

00:16:21,740 --> 00:16:26,959
at zero and then in order to still look

00:16:24,680 --> 00:16:29,089
up for a team to see what their ranking

00:16:26,959 --> 00:16:30,860
was we would have to basically iterate

00:16:29,089 --> 00:16:33,410
through everything - to find that team

00:16:30,860 --> 00:16:35,630
and then see what their ranking was we

00:16:33,410 --> 00:16:37,700
set the index column to be the team and

00:16:35,630 --> 00:16:40,339
that allows us to look up the pandas

00:16:37,700 --> 00:16:42,560
dataframe directly by the team name and

00:16:40,339 --> 00:16:45,550
get their rank so that makes the

00:16:42,560 --> 00:16:48,200
following code a little bit easier so

00:16:45,550 --> 00:16:52,220
this is the standings from the previous

00:16:48,200 --> 00:16:54,320
season so this is all information that

00:16:52,220 --> 00:16:58,970
you would have coming into a game to try

00:16:54,320 --> 00:17:01,640
and predict who's going to win so we're

00:16:58,970 --> 00:17:03,709
going to do another feature which is

00:17:01,640 --> 00:17:06,410
very similar to our home team one last

00:17:03,709 --> 00:17:08,150
feature but instead of looping through

00:17:06,410 --> 00:17:09,800
all the rows directly we're going to use

00:17:08,150 --> 00:17:13,880
the apply method in pandas

00:17:09,800 --> 00:17:16,550
so what apply does and start with this

00:17:13,880 --> 00:17:19,420
line yeah we take our data frame and

00:17:16,550 --> 00:17:22,520
we're going to apply this function

00:17:19,420 --> 00:17:24,559
across each row so axes equals one we'll

00:17:22,520 --> 00:17:26,660
go through each row for us apply the

00:17:24,559 --> 00:17:29,870
function to the row and then get the

00:17:26,660 --> 00:17:33,080
result the result from here is a series

00:17:29,870 --> 00:17:38,360
which will give venues to create a new

00:17:33,080 --> 00:17:41,600
feature which is this one here so our

00:17:38,360 --> 00:17:43,460
function looks like this we take our

00:17:41,600 --> 00:17:46,190
role as a parameter we get who the home

00:17:43,460 --> 00:17:48,260
team and the visitor team are we ignore

00:17:46,190 --> 00:17:51,520
the first we ignore the next four lines

00:17:48,260 --> 00:17:54,320
for now we get the ranks for each team

00:17:51,520 --> 00:17:58,730
these two here and then we see which one

00:17:54,320 --> 00:18:02,930
was better lower numbers mean a better

00:17:58,730 --> 00:18:05,630
rank so the result here is if one team

00:18:02,930 --> 00:18:07,640
ranks better than the other this will be

00:18:05,630 --> 00:18:08,870
if the home team ranks better than the

00:18:07,640 --> 00:18:12,820
other this will be true and false

00:18:08,870 --> 00:18:15,770
otherwise the four lines in the middle

00:18:12,820 --> 00:18:17,750
is just a little annoyance of the NBA

00:18:15,770 --> 00:18:19,790
seasons across those two years at least

00:18:17,750 --> 00:18:24,290
from a data perspective there was a team

00:18:19,790 --> 00:18:26,840
name that changed so the pelicans turns

00:18:24,290 --> 00:18:30,560
into the Hornets or the other way around

00:18:26,840 --> 00:18:35,630
I forget so we just have to fix that

00:18:30,560 --> 00:18:37,730
so so where we see oh that's right yeah

00:18:35,630 --> 00:18:42,290
Hornets turn into pelicans so don't know

00:18:37,730 --> 00:18:44,930
why so where we see the Hornets where we

00:18:42,290 --> 00:18:47,060
see the pelicans as a team name from the

00:18:44,930 --> 00:18:49,220
2014 season we have to convert that to

00:18:47,060 --> 00:18:54,380
the Hornets to look it up in the 2013

00:18:49,220 --> 00:18:56,600
season so with this bit here we've added

00:18:54,380 --> 00:18:59,030
out the results here as a new feature

00:18:56,600 --> 00:19:01,370
and if we print out our results we can

00:18:59,030 --> 00:19:08,120
see home team ranks higher as a new

00:19:01,370 --> 00:19:12,280
feature for us to try it out so using

00:19:08,120 --> 00:19:14,390
the decision tree classifier again we

00:19:12,280 --> 00:19:20,030
really increase new I think the last one

00:19:14,390 --> 00:19:22,940
was much lower than this so so same as

00:19:20,030 --> 00:19:26,590
this classifiers before cross validation

00:19:22,940 --> 00:19:32,060
score on our new data and

00:19:26,590 --> 00:19:35,890
0.59 so so just these basic features

00:19:32,060 --> 00:19:35,890
already getting this quite a good model

00:19:40,190 --> 00:19:45,300
the other thing to note about the

00:19:42,420 --> 00:19:46,980
previous model is we used all defaults

00:19:45,300 --> 00:19:48,480
for the decision tree classifier no

00:19:46,980 --> 00:19:50,130
point did we try and change any

00:19:48,480 --> 00:19:54,030
parameters try and improve the model

00:19:50,130 --> 00:19:56,220
there for decision trees this doesn't

00:19:54,030 --> 00:19:59,610
matter too much there's not a huge

00:19:56,220 --> 00:20:01,890
amount of impact the different

00:19:59,610 --> 00:20:03,720
parameters don't make as huge impact as

00:20:01,890 --> 00:20:07,140
say a support vector machine or

00:20:03,720 --> 00:20:10,020
something like that does but we can have

00:20:07,140 --> 00:20:11,820
a look so something that was alluded to

00:20:10,020 --> 00:20:15,000
in some previous talks was this good

00:20:11,820 --> 00:20:16,800
search CV what this will do is it will

00:20:15,000 --> 00:20:18,390
take some sort of parameter space where

00:20:16,800 --> 00:20:20,670
we list the parameters in all possible

00:20:18,390 --> 00:20:23,250
values and it will try all different

00:20:20,670 --> 00:20:25,410
combinations so in this example we've

00:20:23,250 --> 00:20:31,050
just got the one parameter with values

00:20:25,410 --> 00:20:32,520
from 1 to 20 this the prat that values

00:20:31,050 --> 00:20:36,330
above 4 won't be used in this particular

00:20:32,520 --> 00:20:39,870
case but we then apply grid search CV

00:20:36,330 --> 00:20:42,510
here taking our model our decision tree

00:20:39,870 --> 00:20:44,130
classifier our parameter space and it

00:20:42,510 --> 00:20:45,600
will use cross-validation and try all

00:20:44,130 --> 00:20:48,090
the different parameters and see which

00:20:45,600 --> 00:20:50,640
models the best because the old

00:20:48,090 --> 00:20:52,230
parameter space is small because our

00:20:50,640 --> 00:20:53,730
data set is relatively small but this

00:20:52,230 --> 00:20:55,980
can all happen in memory so we don't

00:20:53,730 --> 00:20:58,230
need to worry about like the random

00:20:55,980 --> 00:21:01,170
walks of some of the other talk because

00:20:58,230 --> 00:21:02,910
I spoke about so we can just do it all

00:21:01,170 --> 00:21:06,870
in memory and we don't have too much of

00:21:02,910 --> 00:21:10,440
an issue we get a very small increase

00:21:06,870 --> 00:21:14,370
here but five nine to five five nine

00:21:10,440 --> 00:21:16,650
four five so a little bit of evidence

00:21:14,370 --> 00:21:19,440
towards my claim that parameters in

00:21:16,650 --> 00:21:25,440
decision trees don't add it too much but

00:21:19,440 --> 00:21:28,800
it's not a hard century the next feature

00:21:25,440 --> 00:21:30,510
and the last one of the normal features

00:21:28,800 --> 00:21:32,640
we'll have a look at is whether the home

00:21:30,510 --> 00:21:33,350
team won the last game between these two

00:21:32,640 --> 00:21:36,480
teams

00:21:33,350 --> 00:21:37,800
so the previous home team won last only

00:21:36,480 --> 00:21:40,380
looked at whether they won their last

00:21:37,800 --> 00:21:42,750
game regardless of Hills ends this one

00:21:40,380 --> 00:21:44,340
just looks at the two teams specifically

00:21:42,750 --> 00:21:47,580
and whether they won their last

00:21:44,340 --> 00:21:51,570
encounter this is not a lot different

00:21:47,580 --> 00:21:53,790
here I use the tupple

00:21:51,570 --> 00:21:56,220
and thought the team name so that we get

00:21:53,790 --> 00:21:58,380
a consistent key so we're always looking

00:21:56,220 --> 00:22:00,090
up regardless of who the tome team and

00:21:58,380 --> 00:22:01,350
the visitor team is it sorts of

00:22:00,090 --> 00:22:07,290
alphabetically so we're always going to

00:22:01,350 --> 00:22:09,120
look up together so usually the home

00:22:07,290 --> 00:22:12,300
team the visitor team will spot spot

00:22:09,120 --> 00:22:15,690
between encounters anyway so we then

00:22:12,300 --> 00:22:18,150
apply this to each row as before get a

00:22:15,690 --> 00:22:20,850
new feature and call it home team one

00:22:18,150 --> 00:22:29,190
last and this is our home team one last

00:22:20,850 --> 00:22:31,980
encounter it'll be zero zero if the home

00:22:29,190 --> 00:22:36,300
team one and the last encounter and one

00:22:31,980 --> 00:22:38,310
otherwise grabbing all this information

00:22:36,300 --> 00:22:40,950
out we can see this gives us a bit more

00:22:38,310 --> 00:22:43,920
information using the same testing

00:22:40,950 --> 00:22:46,260
framework we're up a little bit so but

00:22:43,920 --> 00:22:49,050
the the changed at this point hasn't

00:22:46,260 --> 00:22:49,980
been all that significant so you know

00:22:49,050 --> 00:22:51,870
you wouldn't run to your boss and

00:22:49,980 --> 00:22:53,400
exclaim that you've solved their problem

00:22:51,870 --> 00:22:56,220
at this point we've just got a little

00:22:53,400 --> 00:22:57,900
bit better and it may just be due to

00:22:56,220 --> 00:23:04,050
noise so we would have to test our other

00:22:57,900 --> 00:23:08,610
seasons so that's basic information with

00:23:04,050 --> 00:23:09,960
just the just the box scores just the

00:23:08,610 --> 00:23:12,000
history that we have from the single

00:23:09,960 --> 00:23:15,420
season and the standings from the

00:23:12,000 --> 00:23:17,730
previous year it's actually a lot more

00:23:15,420 --> 00:23:21,210
information in this data set even though

00:23:17,730 --> 00:23:24,090
it's looks very simple it's also

00:23:21,210 --> 00:23:26,880
possible that some teams have a bit of a

00:23:24,090 --> 00:23:28,920
curse against other teams or something

00:23:26,880 --> 00:23:30,540
like that where a normally low ranked

00:23:28,920 --> 00:23:32,610
team might do very well against a

00:23:30,540 --> 00:23:37,110
specific team maybe the coaching styles

00:23:32,610 --> 00:23:39,120
and match up better so what we're going

00:23:37,110 --> 00:23:42,630
to do now is encode the actual teams as

00:23:39,120 --> 00:23:44,700
features but this actually causes a bit

00:23:42,630 --> 00:23:49,050
of an issue because our home teams as

00:23:44,700 --> 00:23:50,340
you can see here are just strings the

00:23:49,050 --> 00:23:53,880
bag of words model was brought up

00:23:50,340 --> 00:23:56,190
earlier this doesn't apply here these

00:23:53,880 --> 00:23:59,010
team names are specifically categorical

00:23:56,190 --> 00:24:03,270
values but I'll classify still won't

00:23:59,010 --> 00:24:05,429
taken so a naive weight here would be to

00:24:03,270 --> 00:24:07,919
just give them all numerical value

00:24:05,429 --> 00:24:10,349
such as the indiana pacers being set as

00:24:07,919 --> 00:24:12,989
one Los Angeles Lakers - Miami Heat

00:24:10,349 --> 00:24:16,049
three and so on the trouble with this

00:24:12,989 --> 00:24:19,259
encoding is that our classifier is going

00:24:16,049 --> 00:24:20,700
to consider if we do exactly that the

00:24:19,259 --> 00:24:22,679
classifier is going to think Indiana

00:24:20,700 --> 00:24:24,840
Pacers and Los Angeles Lakers only have

00:24:22,679 --> 00:24:26,460
a difference of one whereas the Indiana

00:24:24,840 --> 00:24:29,759
Pacers are mainly Heat have a difference

00:24:26,460 --> 00:24:32,869
of two so it's going to infer

00:24:29,759 --> 00:24:35,639
information that's not accurate there

00:24:32,869 --> 00:24:39,090
but it is our first step so we use

00:24:35,639 --> 00:24:43,619
what's called a label encoder this is a

00:24:39,090 --> 00:24:46,590
transformer in scikit-learn we fit it by

00:24:43,619 --> 00:24:50,489
giving it the all the team names it will

00:24:46,590 --> 00:24:52,700
assign a number to each team we then get

00:24:50,489 --> 00:24:55,109
the home team numbers for each gang and

00:24:52,700 --> 00:24:59,279
the visitor team numbers and then we do

00:24:55,109 --> 00:25:03,570
a V stack so these are the numerical

00:24:59,279 --> 00:25:05,039
values assigned to each home team and

00:25:03,570 --> 00:25:08,309
these are the numerical values assigned

00:25:05,039 --> 00:25:11,729
to each visit a team so this by itself

00:25:08,309 --> 00:25:13,169
has that issue I just explained but it

00:25:11,729 --> 00:25:16,229
is at least a numerical value that we

00:25:13,169 --> 00:25:19,489
can start with but that's one ever need

00:25:16,229 --> 00:25:23,279
to at least address that little concern

00:25:19,489 --> 00:25:26,249
from here and we can use what's called a

00:25:23,279 --> 00:25:28,289
one hot encoder and what this will do is

00:25:26,249 --> 00:25:31,710
it will take each of our features such

00:25:28,289 --> 00:25:34,200
as the number seven for Chicago Bulls

00:25:31,710 --> 00:25:36,899
for instance Krone new feature called

00:25:34,200 --> 00:25:39,330
was the time team Chicago Bulls and

00:25:36,899 --> 00:25:42,989
it'll be one if it was in zero if it

00:25:39,330 --> 00:25:49,529
wasn't so if we have a look at the

00:25:42,989 --> 00:25:52,169
result the result here for our home team

00:25:49,529 --> 00:25:54,210
features it created is zeros all the way

00:25:52,169 --> 00:25:55,979
because it wasn't any of those teams so

00:25:54,210 --> 00:25:58,559
it was this team so whatever team this

00:25:55,979 --> 00:26:00,450
was like Chicago Bulls it said a 1 here

00:25:58,559 --> 00:26:03,210
that the home team was Chicago Bulls and

00:26:00,450 --> 00:26:05,849
the visitor team was not any of these

00:26:03,210 --> 00:26:11,190
teams but it was say the Los Angeles

00:26:05,849 --> 00:26:13,019
Lakers this encoding has the property

00:26:11,190 --> 00:26:14,410
that you measure the distance between

00:26:13,019 --> 00:26:17,140
two things

00:26:14,410 --> 00:26:18,760
if they're the same it'll be a 1 if it's

00:26:17,140 --> 00:26:23,080
that if they're different it'll be a

00:26:18,760 --> 00:26:24,730
zero or someday like that and that's

00:26:23,080 --> 00:26:26,860
what we sort of want we want to be able

00:26:24,730 --> 00:26:30,010
to compare these two things and get a

00:26:26,860 --> 00:26:31,570
same or a different day so that's a one

00:26:30,010 --> 00:26:33,220
hot encoding and that's the most

00:26:31,570 --> 00:26:35,290
straightforward way to take some sort of

00:26:33,220 --> 00:26:36,640
categorical feature like team names and

00:26:35,290 --> 00:26:43,240
turn into something that done minor

00:26:36,640 --> 00:26:44,920
rhythms can understand just using the

00:26:43,240 --> 00:26:47,830
team so we haven't used our features

00:26:44,920 --> 00:26:50,890
from before we get nearly at that point

00:26:47,830 --> 00:26:55,030
six mark which is we've got a bit over

00:26:50,890 --> 00:26:57,670
it before we're a bit under it now so so

00:26:55,030 --> 00:26:59,200
we can see that there's information of a

00:26:57,670 --> 00:27:03,160
different type but it's still getting to

00:26:59,200 --> 00:27:05,050
about the same mark but then what if we

00:27:03,160 --> 00:27:09,280
try and use a better classifier for

00:27:05,050 --> 00:27:11,620
instance so decision tree here random

00:27:09,280 --> 00:27:14,910
forest here again you using the default

00:27:11,620 --> 00:27:19,120
values at this point slightly better

00:27:14,910 --> 00:27:21,220
wouldn't go wouldn't be too excited by

00:27:19,120 --> 00:27:23,500
this yet but still around that point six

00:27:21,220 --> 00:27:26,770
mark using just default values but can

00:27:23,500 --> 00:27:29,560
we do better so here what I've done is

00:27:26,770 --> 00:27:32,560
create a parameter space that has a few

00:27:29,560 --> 00:27:34,660
more features for the random forest and

00:27:32,560 --> 00:27:37,210
we're applying a grid search again so

00:27:34,660 --> 00:27:40,510
what this will do we will take this this

00:27:37,210 --> 00:27:42,700
this and this parameter try it see the

00:27:40,510 --> 00:27:45,130
score then go this this this and this

00:27:42,700 --> 00:27:47,020
parameter combination and try to get the

00:27:45,130 --> 00:27:50,890
score and do that for all different

00:27:47,020 --> 00:27:52,570
combinations and get the best result and

00:27:50,890 --> 00:27:58,630
we can see there the result is much

00:27:52,570 --> 00:28:01,830
better if I've it says accuracy but I

00:27:58,630 --> 00:28:03,670
haven't updated that a bit f1 score of

00:28:01,830 --> 00:28:06,730
0.6 for 36

00:28:03,670 --> 00:28:12,240
I think it's protrude it's graph time no

00:28:06,730 --> 00:28:16,060
not yet so now what we're going to do is

00:28:12,240 --> 00:28:18,130
combine those team scores are the team

00:28:16,060 --> 00:28:21,130
features which we got from the one hot

00:28:18,130 --> 00:28:24,130
encoder with our other features that we

00:28:21,130 --> 00:28:26,080
extracted before and then do some

00:28:24,130 --> 00:28:27,940
classification on that and we get around

00:28:26,080 --> 00:28:30,129
that 0.6 mark again

00:28:27,940 --> 00:28:31,570
and then putting that into the full

00:28:30,129 --> 00:28:33,460
thing we actually see a small drop in

00:28:31,570 --> 00:28:36,519
performance this could be randomness

00:28:33,460 --> 00:28:39,370
related it could be that some of the

00:28:36,519 --> 00:28:41,919
features weren't used properly but but

00:28:39,370 --> 00:28:43,389
it is about the same mark so whenever

00:28:41,919 --> 00:28:45,090
you're doing data mining don't get too

00:28:43,389 --> 00:28:46,600
excited by small differences

00:28:45,090 --> 00:28:48,399
particularly if you haven't done a

00:28:46,600 --> 00:28:50,799
robust statistical framework to test

00:28:48,399 --> 00:28:52,559
whether it's significant or not and we

00:28:50,799 --> 00:28:57,789
haven't done that here

00:28:52,559 --> 00:29:01,350
good Childress graph time so we can see

00:28:57,789 --> 00:29:04,600
here that when we use all the features

00:29:01,350 --> 00:29:07,360
and this is first the previous one where

00:29:04,600 --> 00:29:09,580
the six board didn't happen with random

00:29:07,360 --> 00:29:13,269
forests because I didn't set the random

00:29:09,580 --> 00:29:15,009
state properly so we can see here that

00:29:13,269 --> 00:29:18,700
change random forest will do better

00:29:15,009 --> 00:29:19,659
using all features so these results are

00:29:18,700 --> 00:29:23,860
actually a little out of date

00:29:19,659 --> 00:29:27,399
ignore that but but generally that that

00:29:23,860 --> 00:29:28,929
will be the case so but chinder EFT ran

00:29:27,399 --> 00:29:32,500
a first you'd do better than the

00:29:28,929 --> 00:29:35,110
decision tree and using more data is

00:29:32,500 --> 00:29:36,970
better than less as a general rule one

00:29:35,110 --> 00:29:39,669
of the advantages of random forests is

00:29:36,970 --> 00:29:42,039
that while it it there is a huge amount

00:29:39,669 --> 00:29:43,509
of randomness to it it better features

00:29:42,039 --> 00:29:46,029
will tend to bubble to the top and get

00:29:43,509 --> 00:29:49,480
used more frequently so adding data will

00:29:46,029 --> 00:29:51,970
rarely well it will rarely make it what

00:29:49,480 --> 00:29:57,870
or worse even if that data is noisy but

00:29:51,970 --> 00:30:02,529
do be do be wary so we have a model

00:29:57,870 --> 00:30:05,620
tested on the 2014 data that does fairly

00:30:02,529 --> 00:30:07,990
well the real test here is can we go one

00:30:05,620 --> 00:30:10,659
season forward and test it on the next

00:30:07,990 --> 00:30:13,720
season so what I've done here is I've

00:30:10,659 --> 00:30:18,899
grabbed the recent games from the

00:30:13,720 --> 00:30:23,350
recently completed 2014-2015 season and

00:30:18,899 --> 00:30:26,980
load them as before we create we get the

00:30:23,350 --> 00:30:29,080
standings from the 2014 season later

00:30:26,980 --> 00:30:32,049
those before create our features as

00:30:29,080 --> 00:30:35,230
before still going with the features

00:30:32,049 --> 00:30:37,090
I've copied the code from before changed

00:30:35,230 --> 00:30:39,179
a few things but this is all just doing

00:30:37,090 --> 00:30:41,590
the same feature creation we did before

00:30:39,179 --> 00:30:43,240
if you want to do this properly

00:30:41,590 --> 00:30:44,920
and I haven't done it here and you'll

00:30:43,240 --> 00:30:48,400
create a pipeline like we saw in some

00:30:44,920 --> 00:30:51,130
previous talks set set all this up to be

00:30:48,400 --> 00:30:52,330
separate steps in the pipeline and then

00:30:51,130 --> 00:30:56,590
you wouldn't have to do the copy and

00:30:52,330 --> 00:31:03,640
paste the new code so we have our data

00:30:56,590 --> 00:31:06,670
set here now this is important the

00:31:03,640 --> 00:31:09,070
encoding of the team's have to be done

00:31:06,670 --> 00:31:12,730
with the same encoding that was used

00:31:09,070 --> 00:31:14,710
earlier the reason for this so what so

00:31:12,730 --> 00:31:17,440
what this code does we take out ink

00:31:14,710 --> 00:31:20,920
label encoder from before we take our

00:31:17,440 --> 00:31:24,220
one hot encoder from before and reuse

00:31:20,920 --> 00:31:25,930
those to transform the 2015 data this

00:31:24,220 --> 00:31:29,920
doesn't matter so much on the other

00:31:25,930 --> 00:31:31,900
features like home team one last because

00:31:29,920 --> 00:31:35,080
they get recreated and putting the same

00:31:31,900 --> 00:31:38,410
spot anyway but if you were to create

00:31:35,080 --> 00:31:41,260
new label encoders here the teams might

00:31:38,410 --> 00:31:43,090
be assigned different numbers and if

00:31:41,260 --> 00:31:44,830
they're assigned different numbers then

00:31:43,090 --> 00:31:47,800
the one holding coding will create a

00:31:44,830 --> 00:31:51,370
different feature for that team in a

00:31:47,800 --> 00:31:53,710
different spot that will be one the

00:31:51,370 --> 00:31:55,930
won't match up to the previous data so

00:31:53,710 --> 00:31:57,700
we'll train on the 2014 data that will

00:31:55,930 --> 00:32:01,330
expect the Chicago Bulls to be feature

00:31:57,700 --> 00:32:03,760
70 we'll test on 2015 data where the

00:32:01,330 --> 00:32:06,880
Chicago Bulls are 15 and those rows

00:32:03,760 --> 00:32:11,230
won't match and I'll classify won't be

00:32:06,880 --> 00:32:13,510
able to use that information so that's

00:32:11,230 --> 00:32:17,500
why we reused the encoder and the one

00:32:13,510 --> 00:32:21,220
hot transformer from before so we've

00:32:17,500 --> 00:32:23,290
created our new 2015 data set and

00:32:21,220 --> 00:32:26,220
importantly we test the baseline it's

00:32:23,290 --> 00:32:28,420
about the same as it was which is

00:32:26,220 --> 00:32:32,980
actually pretty amazing that it was so

00:32:28,420 --> 00:32:34,090
consistent 58 percent again of 58

00:32:32,980 --> 00:32:41,200
percent of games are won by the home

00:32:34,090 --> 00:32:44,410
team so drumroll we do a fit and we do a

00:32:41,200 --> 00:32:46,720
predict and we get an f1 score of 0.76

00:32:44,410 --> 00:32:49,090
so significantly higher than our

00:32:46,720 --> 00:32:53,100
training data that's a little bit

00:32:49,090 --> 00:32:55,460
confusing but this is a great result so

00:32:53,100 --> 00:32:57,110
things to keep in mind with this you

00:32:55,460 --> 00:32:58,490
was higher than our trading training

00:32:57,110 --> 00:33:00,679
data so we probably need to do a bit

00:32:58,490 --> 00:33:04,610
more testing work out what was the cause

00:33:00,679 --> 00:33:09,130
of this whether it was just a fluke that

00:33:04,610 --> 00:33:13,130
2015 was easier to predict in 2014

00:33:09,130 --> 00:33:14,539
intuitively I think that's true but we

00:33:13,130 --> 00:33:17,000
might need to go back to previous

00:33:14,539 --> 00:33:21,799
seasons and try the same workflow out

00:33:17,000 --> 00:33:23,390
for there so an f1 score it's sort of

00:33:21,799 --> 00:33:25,190
like an accuracy but it's not quite an

00:33:23,390 --> 00:33:28,700
accuracy so I've also calculated the

00:33:25,190 --> 00:33:31,340
actual accuracy so it is exactly the

00:33:28,700 --> 00:33:33,679
same in this scenario though so just

00:33:31,340 --> 00:33:37,010
having a look at where our prediction is

00:33:33,679 --> 00:33:42,230
equal to the actual outcome we get 76%

00:33:37,010 --> 00:33:45,350
of MBA gains predicted correctly so I

00:33:42,230 --> 00:33:46,880
think that's pretty good result so the

00:33:45,350 --> 00:33:49,190
next steps here are into court

00:33:46,880 --> 00:33:49,760
incorporate very nods I see if we can

00:33:49,190 --> 00:33:52,130
win money

00:33:49,760 --> 00:33:54,830
these are surprisingly difficult to find

00:33:52,130 --> 00:33:56,690
I have not been able to find a rip free

00:33:54,830 --> 00:33:58,640
resource that gives these odds so if you

00:33:56,690 --> 00:34:02,270
know one or know someone that has them

00:33:58,640 --> 00:34:05,120
let me know the other thing to consider

00:34:02,270 --> 00:34:08,149
is to go much deeper into the data set

00:34:05,120 --> 00:34:11,690
we can get information for how much each

00:34:08,149 --> 00:34:14,990
player played in each match and their

00:34:11,690 --> 00:34:16,790
record leading up into that match so we

00:34:14,990 --> 00:34:19,669
could incorporate that data trying to

00:34:16,790 --> 00:34:21,440
keep in mind that we have to bet before

00:34:19,669 --> 00:34:23,030
a match so we have to only use

00:34:21,440 --> 00:34:24,859
information that we had before a match

00:34:23,030 --> 00:34:26,659
so we can't use how well the player did

00:34:24,859 --> 00:34:29,149
during the match but we can use how well

00:34:26,659 --> 00:34:30,679
a player did in the previous match but

00:34:29,149 --> 00:34:32,960
we do know which players are going to be

00:34:30,679 --> 00:34:35,300
in the team so for instance if LeBron

00:34:32,960 --> 00:34:38,419
James is playing the Cavs have a much

00:34:35,300 --> 00:34:40,659
higher chance of winning but if he's not

00:34:38,419 --> 00:34:43,040
playing they're probably going to lose

00:34:40,659 --> 00:34:44,629
so knowing whether he's playing or not

00:34:43,040 --> 00:34:47,859
it's going to be a significant impact on

00:34:44,629 --> 00:34:51,649
whether the Cleveland Cavaliers win and

00:34:47,859 --> 00:34:54,109
finally AFL is the next thing so sports

00:34:51,649 --> 00:34:57,080
betting see I am holding a competition

00:34:54,109 --> 00:35:00,830
for AFL prediction the winner will get

00:34:57,080 --> 00:35:02,810
five grand but more importantly the

00:35:00,830 --> 00:35:09,090
winner will have won a competition like

00:35:02,810 --> 00:35:15,690
this so so I delink stare but see I

00:35:09,090 --> 00:35:20,520
oh yeah I'll show you the URL Sportsbet

00:35:15,690 --> 00:35:22,290
CI km 15.com so basically they've given

00:35:20,520 --> 00:35:24,810
us information about the games from the

00:35:22,290 --> 00:35:27,570
AFL season and the players and stuff

00:35:24,810 --> 00:35:29,580
like that your goal is to predict the

00:35:27,570 --> 00:35:32,670
winners and predict the final season

00:35:29,580 --> 00:35:35,430
from this yeah so this competition ends

00:35:32,670 --> 00:35:37,590
just before the final season starts and

00:35:35,430 --> 00:35:41,810
then the winner is determined by who

00:35:37,590 --> 00:35:44,190
predicts the final season best so yeah

00:35:41,810 --> 00:35:54,900
so that's my talk thank you for

00:35:44,190 --> 00:36:02,100
listening thanks very much Robert can we

00:35:54,900 --> 00:36:04,080
take a few questions no questions or I

00:36:02,100 --> 00:36:07,380
got a question well we've got one

00:36:04,080 --> 00:36:10,800
brilliant I may be the same question

00:36:07,380 --> 00:36:14,010
have you used this algorithm yourself to

00:36:10,800 --> 00:36:18,890
bet and have you been successful no I

00:36:14,010 --> 00:36:22,940
have a low tolerance to risk so

00:36:18,890 --> 00:36:24,470
but but with the figures I feel it's

00:36:22,940 --> 00:36:32,990
pretty good I think I'll try next year

00:36:24,470 --> 00:36:34,819
yeah cool was this question not really a

00:36:32,990 --> 00:36:37,990
question more of a comment um you can

00:36:34,819 --> 00:36:40,099
actually think about using true skill

00:36:37,990 --> 00:36:40,369
I'm not sure if you know what true skill

00:36:40,099 --> 00:36:42,289
is uh

00:36:40,369 --> 00:36:46,579
SSF feature it could be quite

00:36:42,289 --> 00:36:50,240
interesting yeah that's a good idea

00:36:46,579 --> 00:36:53,359
MBA do record the offensive and

00:36:50,240 --> 00:36:55,460
defensive ratings for players so I

00:36:53,359 --> 00:36:59,930
forget the exact definition but it's

00:36:55,460 --> 00:37:02,420
something like 100 is the median so a

00:36:59,930 --> 00:37:04,579
player on 100 is average and play it

00:37:02,420 --> 00:37:07,039
better than 100 for offensive is will

00:37:04,579 --> 00:37:08,960
score more points in either player lower

00:37:07,039 --> 00:37:10,519
than 100 for defensive will stop born

00:37:08,960 --> 00:37:13,430
points than not so it's better in that

00:37:10,519 --> 00:37:14,599
way but I think it's a similar thing and

00:37:13,430 --> 00:37:16,700
that would be the most straightforward

00:37:14,599 --> 00:37:18,920
way to incorporate player data into this

00:37:16,700 --> 00:37:20,950
model you get that put offensive and

00:37:18,920 --> 00:37:29,420
defensive rating and put that in there

00:37:20,950 --> 00:37:33,109
yeah school work - it's just a for your

00:37:29,420 --> 00:37:36,170
information odds portal comm all their

00:37:33,109 --> 00:37:42,980
history oh yeah pretty much every sport

00:37:36,170 --> 00:37:46,549
great thank you wait for my talk next

00:37:42,980 --> 00:37:48,259
year then I'm not really too familiar

00:37:46,549 --> 00:37:50,299
with random forest but does the

00:37:48,259 --> 00:37:57,529
classifier output a probability of the

00:37:50,299 --> 00:38:05,539
win or does it give a binary can you use

00:37:57,529 --> 00:38:06,680
the actual win or loss but I think this

00:38:05,539 --> 00:38:10,460
is probably gonna have to be the last

00:38:06,680 --> 00:38:12,470
one and just wondering why when you were

00:38:10,460 --> 00:38:15,049
comparing the ranking tables did you

00:38:12,470 --> 00:38:17,000
just do a binary feature like are they

00:38:15,049 --> 00:38:19,759
better on the standings

00:38:17,000 --> 00:38:23,660
versus how far above me or below me are

00:38:19,759 --> 00:38:26,960
they yeah that that could work as well

00:38:23,660 --> 00:38:29,359
yeah yeah a significant gap would be

00:38:26,960 --> 00:38:31,320
better than a lower gap and that would

00:38:29,359 --> 00:38:35,340
be a good continuous feature to use

00:38:31,320 --> 00:38:38,460
yeah that's good idea okay everyone and

00:38:35,340 --> 00:38:40,410
so we'll be back here at 25 pastors push

00:38:38,460 --> 00:38:43,340
at by five minutes but one more final

00:38:40,410 --> 00:38:43,340
round for Rob

00:38:52,230 --> 00:38:54,290

YouTube URL: https://www.youtube.com/watch?v=k7hSD_-gWMw


