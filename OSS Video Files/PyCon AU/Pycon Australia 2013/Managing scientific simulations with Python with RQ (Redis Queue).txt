Title: Managing scientific simulations with Python with RQ (Redis Queue)
Publication date: 2013-07-10
Playlist: Pycon Australia 2013
Description: 
	Andrew Walker
http://2013.pycon-au.org/schedule/30037/view_talk
Writing scientific software in support of experimentation and simulation is a challenging task. It is even more challenging in cases where such software must be distributed across multiple machines.  Existing methods for addressing this problem can require either significant effort to maintain and extend. Alternative approaches such as message queues can be incredibly difficult to install for novices.

This presentation will demon
Captions: 
	00:00:00,140 --> 00:00:05,400
okay welcome to the our last session for

00:00:02,730 --> 00:00:07,020
today so our next presenter is currently

00:00:05,400 --> 00:00:09,330
employed as a research scientist

00:00:07,020 --> 00:00:11,820
specializing modeling and simulation of

00:00:09,330 --> 00:00:13,740
physical systems with robotics being his

00:00:11,820 --> 00:00:15,990
first love in 2011 he finished his

00:00:13,740 --> 00:00:17,850
dissertation on hard real-time motion

00:00:15,990 --> 00:00:24,119
planning for autonomous vehicles please

00:00:17,850 --> 00:00:24,800
welcome Andrew Walker thanks very much

00:00:24,119 --> 00:00:27,539
everybody

00:00:24,800 --> 00:00:29,820
so my talk today is about managing

00:00:27,539 --> 00:00:32,700
scientific simulations with ret askew

00:00:29,820 --> 00:00:35,160
and so I have to kind of disclaimers at

00:00:32,700 --> 00:00:37,620
the start of my talk the first is that

00:00:35,160 --> 00:00:40,680
this is most definitely a beginner talk

00:00:37,620 --> 00:00:43,020
if you've done any parallel computing or

00:00:40,680 --> 00:00:45,840
distributed computing stuff all of this

00:00:43,020 --> 00:00:48,570
should be pretty much old hat the other

00:00:45,840 --> 00:00:50,700
kind of caveat is that I'm certainly not

00:00:48,570 --> 00:00:52,260
the developer of read askew but I

00:00:50,700 --> 00:00:53,910
certainly think you should go and check

00:00:52,260 --> 00:00:55,500
it out it's a fantastic module that's

00:00:53,910 --> 00:00:59,820
really useful for doing this kind of

00:00:55,500 --> 00:01:01,230
stuff so just to give you a quick

00:00:59,820 --> 00:01:03,359
outline of this stuff that I want to

00:01:01,230 --> 00:01:06,479
talk about today I'm gonna give you a

00:01:03,359 --> 00:01:09,360
quick rundown on some of my thoughts on

00:01:06,479 --> 00:01:11,189
scientific simulation talk about some

00:01:09,360 --> 00:01:15,110
Python tools for doing that kind of

00:01:11,189 --> 00:01:17,369
stuff talk about Redis and Redis queue

00:01:15,110 --> 00:01:19,259
but probably more importantly I just

00:01:17,369 --> 00:01:21,840
wanna for those of you who don't do a

00:01:19,259 --> 00:01:23,130
lot of this type of work I want to make

00:01:21,840 --> 00:01:25,860
it very clear what the difference

00:01:23,130 --> 00:01:28,020
between parallel simulations and

00:01:25,860 --> 00:01:29,970
distributed simulations are so the

00:01:28,020 --> 00:01:32,280
picture up the top is very much the

00:01:29,970 --> 00:01:34,829
parallel case where you have a single

00:01:32,280 --> 00:01:37,650
Python process that will spin up a

00:01:34,829 --> 00:01:39,479
number of worker nodes and that's all

00:01:37,650 --> 00:01:42,090
running on a single machine in a single

00:01:39,479 --> 00:01:43,890
physical machine the second diagram is

00:01:42,090 --> 00:01:46,439
very much the distributed simulation

00:01:43,890 --> 00:01:48,840
case where you've got a single Python

00:01:46,439 --> 00:01:51,540
process that spins up multiple worker

00:01:48,840 --> 00:01:53,579
nodes and some of those nodes could

00:01:51,540 --> 00:01:57,780
potentially be on a physically different

00:01:53,579 --> 00:02:00,360
box give you a quick rundown on some of

00:01:57,780 --> 00:02:01,950
the things that relate to building

00:02:00,360 --> 00:02:03,780
robust simulations although there's

00:02:01,950 --> 00:02:05,939
probably not time to do too much of that

00:02:03,780 --> 00:02:09,140
and talk about some of the caveats of

00:02:05,939 --> 00:02:11,830
solving this problem the way that I have

00:02:09,140 --> 00:02:13,780
so I'm

00:02:11,830 --> 00:02:16,260
lucky to have the position that I do I

00:02:13,780 --> 00:02:20,260
get to work with some absolutely amazing

00:02:16,260 --> 00:02:22,780
scientists and they work in a huge

00:02:20,260 --> 00:02:24,960
number of fields I work with chemists

00:02:22,780 --> 00:02:27,850
biologists physicists mathematic

00:02:24,960 --> 00:02:32,980
mathematicians engineers and a few

00:02:27,850 --> 00:02:34,300
computer scientists not too many but the

00:02:32,980 --> 00:02:37,660
one thing that they all have in common

00:02:34,300 --> 00:02:39,820
is that they solve big problems not

00:02:37,660 --> 00:02:40,420
necessarily computationally big problems

00:02:39,820 --> 00:02:42,370
all the time

00:02:40,420 --> 00:02:46,390
but they're certainly big science

00:02:42,370 --> 00:02:49,030
problems one thing that I have learnt is

00:02:46,390 --> 00:02:51,250
that scientists really just want to do

00:02:49,030 --> 00:02:53,380
science and they certainly don't care

00:02:51,250 --> 00:02:57,330
how I help them when we collaborate

00:02:53,380 --> 00:02:57,330
together get solutions to their problems

00:02:57,450 --> 00:03:02,170
which is fantastic for me because it

00:02:59,860 --> 00:03:06,730
lets me pick the tools that that help me

00:03:02,170 --> 00:03:08,800
solve my problems in the simplest way so

00:03:06,730 --> 00:03:12,040
what's a scientific simulation so this

00:03:08,800 --> 00:03:14,440
is the Wikipedia definition simulation

00:03:12,040 --> 00:03:17,130
is the imitation of the operation of a

00:03:14,440 --> 00:03:20,230
real-world process or system over time

00:03:17,130 --> 00:03:23,260
so at the simplest level you can think

00:03:20,230 --> 00:03:25,660
of a simulation like flipping a coin and

00:03:23,260 --> 00:03:26,950
you can imagine some kind of things that

00:03:25,660 --> 00:03:29,590
you might want to observe in such a

00:03:26,950 --> 00:03:32,739
simulation like how often does it come

00:03:29,590 --> 00:03:34,900
up heads or on average how many coins do

00:03:32,739 --> 00:03:37,660
I need to toss before I'll see three

00:03:34,900 --> 00:03:39,880
heads come up in a row at the very other

00:03:37,660 --> 00:03:42,160
end of the spectrum simulation covers

00:03:39,880 --> 00:03:43,930
things like say I want to spend several

00:03:42,160 --> 00:03:46,660
billion dollars building a Large Hadron

00:03:43,930 --> 00:03:48,550
Collider you know I really want to know

00:03:46,660 --> 00:03:50,350
before I go building something like that

00:03:48,550 --> 00:03:56,019
that it's absolutely definitely going to

00:03:50,350 --> 00:03:58,750
work okay so this class of solutions

00:03:56,019 --> 00:04:02,080
using red askew solves a fairly niche

00:03:58,750 --> 00:04:04,540
problem so we're really not interested

00:04:02,080 --> 00:04:07,000
in the case where you can solve problems

00:04:04,540 --> 00:04:09,070
with a single Python process although

00:04:07,000 --> 00:04:12,280
Python is great for doing that already

00:04:09,070 --> 00:04:14,380
we've got tools like numpy side pie size

00:04:12,280 --> 00:04:16,570
and number and a whole host of other

00:04:14,380 --> 00:04:19,120
optimization of profiling tools

00:04:16,570 --> 00:04:21,250
we're not even interested in that single

00:04:19,120 --> 00:04:23,650
machine case although that's mainly what

00:04:21,250 --> 00:04:26,380
my demonstration will focus on today

00:04:23,650 --> 00:04:29,949
Python ships with the multiprocessing

00:04:26,380 --> 00:04:31,690
module so battery is included and so

00:04:29,949 --> 00:04:35,050
there's not a whole lot of need to talk

00:04:31,690 --> 00:04:37,509
too much about that coming from a

00:04:35,050 --> 00:04:39,759
predominantly academic background and

00:04:37,509 --> 00:04:41,500
I'm sure this people in the room who

00:04:39,759 --> 00:04:43,180
come from similar kinds of backgrounds

00:04:41,500 --> 00:04:45,130
I'm not interested in talking about

00:04:43,180 --> 00:04:48,669
supercomputers either most

00:04:45,130 --> 00:04:51,960
supercomputers rely on very specialized

00:04:48,669 --> 00:04:56,740
scheduling tools and and and job queues

00:04:51,960 --> 00:04:58,300
and at least from my perspective a lot

00:04:56,740 --> 00:05:00,610
of the problems that I need to deal with

00:04:58,300 --> 00:05:02,650
it's not really appropriate to solve

00:05:00,610 --> 00:05:05,289
them in the cloud mainly for business

00:05:02,650 --> 00:05:09,100
reasons that relate to IP or security

00:05:05,289 --> 00:05:11,530
issues so this is kind of the case that

00:05:09,100 --> 00:05:14,350
I find myself in a lot of the time we've

00:05:11,530 --> 00:05:17,139
got about 20 to 50 cores on something

00:05:14,350 --> 00:05:18,760
like 5 to 10 physical machines so if

00:05:17,139 --> 00:05:21,220
you've got a rack you can imagine that's

00:05:18,760 --> 00:05:22,990
about one rack worth of gear or you know

00:05:21,220 --> 00:05:24,280
if you even if you've got desktop

00:05:22,990 --> 00:05:29,050
machines now you can imagine that

00:05:24,280 --> 00:05:30,340
fitting on one or two desks all right so

00:05:29,050 --> 00:05:37,990
what's out there for doing this in

00:05:30,340 --> 00:05:43,300
Python so has anybody used live Python

00:05:37,990 --> 00:05:45,580
parallel okay one person if you're a

00:05:43,300 --> 00:05:48,280
science person the absolute first place

00:05:45,580 --> 00:05:50,530
to go to to do any parallelization if

00:05:48,280 --> 00:05:53,080
you're an experienced developer is

00:05:50,530 --> 00:05:54,940
ipython parallel there have been a

00:05:53,080 --> 00:05:58,030
number of really great talks at the last

00:05:54,940 --> 00:05:59,590
couple of us PI cons about high

00:05:58,030 --> 00:06:01,210
performance computing and I strongly

00:05:59,590 --> 00:06:04,599
recommend you go and have a look at that

00:06:01,210 --> 00:06:07,479
and the ipython talks as well it will

00:06:04,599 --> 00:06:11,620
give you access to a cluster of machines

00:06:07,479 --> 00:06:14,099
using SSH MPI PBS and a number of other

00:06:11,620 --> 00:06:16,990
scheduling and communication mechanisms

00:06:14,099 --> 00:06:19,479
has anybody used celery people coming

00:06:16,990 --> 00:06:23,680
from the web development area so there's

00:06:19,479 --> 00:06:25,240
a there's a few hands go up celery is a

00:06:23,680 --> 00:06:28,060
bit more like what I'm going to talk

00:06:25,240 --> 00:06:31,479
about today it's a job scheduling queue

00:06:28,060 --> 00:06:33,310
most of the time you attach a decorator

00:06:31,479 --> 00:06:35,620
to a Python function

00:06:33,310 --> 00:06:37,120
that will actually push that when you

00:06:35,620 --> 00:06:39,370
call a function that will push it into a

00:06:37,120 --> 00:06:42,040
cube that a number of workers can come

00:06:39,370 --> 00:06:45,010
along and consume there's a number of

00:06:42,040 --> 00:06:46,410
other options but again my suggestion is

00:06:45,010 --> 00:06:49,180
that you go and have a look at

00:06:46,410 --> 00:06:53,020
particularly in Oswald's high

00:06:49,180 --> 00:06:56,230
performance computing in notes from Euro

00:06:53,020 --> 00:06:57,880
scifi 2011 there's a couple of other

00:06:56,230 --> 00:07:01,840
Message Queuing based systems as well

00:06:57,880 --> 00:07:03,960
that might be interesting so why might

00:07:01,840 --> 00:07:07,120
you choose not to do something like that

00:07:03,960 --> 00:07:09,640
well it turns out that quite often

00:07:07,120 --> 00:07:11,170
there's a fair bit of configuration and

00:07:09,640 --> 00:07:14,410
tweaking that you need to go through

00:07:11,170 --> 00:07:15,910
even for the ipython parallel stuff

00:07:14,410 --> 00:07:19,420
you've actually got to go and find the

00:07:15,910 --> 00:07:24,880
specific configuration file set it up to

00:07:19,420 --> 00:07:26,890
use your transport mechanism celery can

00:07:24,880 --> 00:07:28,600
be even worse I spent a week fiddling

00:07:26,890 --> 00:07:31,140
with the internals of celery trying to

00:07:28,600 --> 00:07:33,600
match up some kind of storage mechanism

00:07:31,140 --> 00:07:36,430
with the right kind of message queues

00:07:33,600 --> 00:07:38,950
and and maybe this perception of being

00:07:36,430 --> 00:07:41,020
difficult to get up and running is just

00:07:38,950 --> 00:07:43,030
something that applies to me but I've

00:07:41,020 --> 00:07:44,350
seen other people really great

00:07:43,030 --> 00:07:46,590
developers in the Python community

00:07:44,350 --> 00:07:49,660
struggle with some of this stuff even

00:07:46,590 --> 00:07:52,390
worse from my perspective because I work

00:07:49,660 --> 00:07:54,700
with scientists if I get something like

00:07:52,390 --> 00:07:55,930
this set up and running for them they

00:07:54,700 --> 00:07:58,060
don't want to have to sit there and

00:07:55,930 --> 00:08:02,620
babysit my work making sure that their

00:07:58,060 --> 00:08:04,810
simulations haven't fallen over okay so

00:08:02,620 --> 00:08:07,350
what was I looking for in that kind of

00:08:04,810 --> 00:08:09,790
ideal tool for solving these problems

00:08:07,350 --> 00:08:11,800
it's really something that you can get

00:08:09,790 --> 00:08:13,360
going in and afternoon so I figure

00:08:11,800 --> 00:08:15,430
that's about the length of time that

00:08:13,360 --> 00:08:17,770
I've got to actually teach somebody how

00:08:15,430 --> 00:08:20,230
to understand something really well and

00:08:17,770 --> 00:08:21,940
if it's that short they've got some

00:08:20,230 --> 00:08:25,090
chance of actually remembering how to do

00:08:21,940 --> 00:08:27,490
it ideally it had to have no

00:08:25,090 --> 00:08:29,320
configuration file editing and the only

00:08:27,490 --> 00:08:30,970
thing I had to do to get my demos up and

00:08:29,320 --> 00:08:34,750
going was I had to open an exception in

00:08:30,970 --> 00:08:35,920
my firewall and the absolute one thing

00:08:34,750 --> 00:08:40,410
that I didn't want to have to do is

00:08:35,920 --> 00:08:43,060
configure that message broker okay so

00:08:40,410 --> 00:08:45,870
that's what I wanted and this is kind of

00:08:43,060 --> 00:08:50,460
the solution that I ended up with

00:08:45,870 --> 00:08:53,760
Redis is the core forms the core of the

00:08:50,460 --> 00:08:56,850
Redis Q module it's actually a data

00:08:53,760 --> 00:09:00,029
structure server that lets you associate

00:08:56,850 --> 00:09:02,760
values with keys now I can honestly say

00:09:00,029 --> 00:09:04,860
that I know almost nothing about Redis

00:09:02,760 --> 00:09:06,270
and in this case it's probably an

00:09:04,860 --> 00:09:08,610
advantage that I don't know anything

00:09:06,270 --> 00:09:10,470
because it just hasn't fallen over it

00:09:08,610 --> 00:09:15,270
almost always stays up and it's just

00:09:10,470 --> 00:09:17,370
worked it's written in C bindings to

00:09:15,270 --> 00:09:19,890
mouth link most popular languages and

00:09:17,370 --> 00:09:22,080
certainly easy to access from Python if

00:09:19,890 --> 00:09:24,150
you're going to use Redis just raw Redis

00:09:22,080 --> 00:09:27,029
it looks something like this so if I'm

00:09:24,150 --> 00:09:29,820
trying to bind to a Redis server running

00:09:27,029 --> 00:09:32,370
on localhost I open my connection and

00:09:29,820 --> 00:09:35,910
then I can associate some kind of value

00:09:32,370 --> 00:09:38,279
in this case a string with a key and I

00:09:35,910 --> 00:09:39,900
can then pull that key back out if I

00:09:38,279 --> 00:09:42,540
need to do that later I can actually

00:09:39,900 --> 00:09:44,310
close my Python session and then open it

00:09:42,540 --> 00:09:49,950
back up and pull the same value back out

00:09:44,310 --> 00:09:52,709
with that key alright so what's this

00:09:49,950 --> 00:09:54,420
Redis queue so one of the great things

00:09:52,709 --> 00:09:56,880
about Redis is that it actually lets you

00:09:54,420 --> 00:10:01,020
use multiple data structures so I can

00:09:56,880 --> 00:10:03,600
associate a list a mapping a set or a

00:10:01,020 --> 00:10:05,250
queue with one of those keys and that

00:10:03,600 --> 00:10:08,880
means that I can actually push a job

00:10:05,250 --> 00:10:10,920
which a job in this context is just a

00:10:08,880 --> 00:10:14,279
function and it's arguments that you're

00:10:10,920 --> 00:10:16,500
going to call with that function the

00:10:14,279 --> 00:10:18,510
beauty of Redis is that it's pure Python

00:10:16,500 --> 00:10:20,100
that means anybody can actually read and

00:10:18,510 --> 00:10:21,990
understand the code which makes it

00:10:20,100 --> 00:10:24,290
perfect for scientists and trying to

00:10:21,990 --> 00:10:27,990
debug the harder things and it also

00:10:24,290 --> 00:10:29,580
provides a really clean API and what

00:10:27,990 --> 00:10:32,690
Kenneth reads would call an API for

00:10:29,580 --> 00:10:35,520
humans so one of the simplest examples

00:10:32,690 --> 00:10:39,270
just in case all my demos fall over

00:10:35,520 --> 00:10:41,700
looks like this so you actually you set

00:10:39,270 --> 00:10:45,480
up a queue and connect to Redis on

00:10:41,700 --> 00:10:47,580
localhost you look up some you have a

00:10:45,480 --> 00:10:50,160
string to the name of the function so in

00:10:47,580 --> 00:10:52,620
this case look up the module operator

00:10:50,160 --> 00:10:56,579
and the add function in that module and

00:10:52,620 --> 00:10:59,180
then you can pass it some arguments that

00:10:56,579 --> 00:11:00,650
gives you a handle to the job which is

00:10:59,180 --> 00:11:03,110
some languages you might call that a

00:11:00,650 --> 00:11:04,850
future it's a promise that you're going

00:11:03,110 --> 00:11:07,370
it or a promise that you're going to get

00:11:04,850 --> 00:11:09,350
an answer back at some later time so I

00:11:07,370 --> 00:11:10,820
can wait a little while because you know

00:11:09,350 --> 00:11:12,980
hopefully it won't take more than a

00:11:10,820 --> 00:11:17,390
second to calculate two plus three and

00:11:12,980 --> 00:11:19,430
then I can I can print out my answer to

00:11:17,390 --> 00:11:20,900
have all this work I actually need to

00:11:19,430 --> 00:11:22,730
have something that's coming along and

00:11:20,900 --> 00:11:24,920
consuming those jobs that I'm pushing

00:11:22,730 --> 00:11:28,010
into the queue so I can launch some

00:11:24,920 --> 00:11:30,440
workers so by default Redis queue

00:11:28,010 --> 00:11:33,140
workers will listen on localhost to the

00:11:30,440 --> 00:11:35,360
default queue if I want to do something

00:11:33,140 --> 00:11:37,820
a bit different I can launch the worker

00:11:35,360 --> 00:11:39,470
on a simulation queue at a particular

00:11:37,820 --> 00:11:45,470
and pointing at it at a particular

00:11:39,470 --> 00:11:47,300
instance of Redis so once you've got a

00:11:45,470 --> 00:11:48,500
whole bunch of these workers spun up one

00:11:47,300 --> 00:11:50,810
of the things that you really want to

00:11:48,500 --> 00:11:52,580
know is have any of them fallen over are

00:11:50,810 --> 00:11:55,010
my jobs passing or failing are they

00:11:52,580 --> 00:11:57,890
throwing exceptions so an important part

00:11:55,010 --> 00:12:00,770
of any parallel simulation is some kind

00:11:57,890 --> 00:12:02,900
of monitoring tool Redis comes with two

00:12:00,770 --> 00:12:04,880
two solutions for that one on the

00:12:02,900 --> 00:12:07,430
command line which is our queue info and

00:12:04,880 --> 00:12:10,400
the other is the our queue dashboard

00:12:07,430 --> 00:12:13,010
which is a little web app so fingers

00:12:10,400 --> 00:12:21,080
crossed my live demo is actually going

00:12:13,010 --> 00:12:25,100
to work all right does anybody here use

00:12:21,080 --> 00:12:26,660
team arcs just a couple of people so

00:12:25,100 --> 00:12:27,350
this might be a bit interesting for some

00:12:26,660 --> 00:12:30,980
of you

00:12:27,350 --> 00:12:34,250
Tmax is a terminal multiplexer it lets

00:12:30,980 --> 00:12:36,170
me run multiple terminal sessions on the

00:12:34,250 --> 00:12:37,880
screen at one time it's going to be

00:12:36,170 --> 00:12:39,380
great for this because I need to try and

00:12:37,880 --> 00:12:42,190
get as much stuff squashed onto the

00:12:39,380 --> 00:12:42,190
screen as I can

00:12:44,620 --> 00:12:51,130
all right so I can fire up my red askew

00:12:49,480 --> 00:12:52,750
worker and you can see that it's

00:12:51,130 --> 00:12:55,960
listening on the default Q and it's

00:12:52,750 --> 00:12:57,910
connected to Redis on localhost and you

00:12:55,960 --> 00:13:00,430
can imagine that in my second terminal

00:12:57,910 --> 00:13:02,650
session I could easily SSH out to

00:13:00,430 --> 00:13:06,940
another machine and I could run our Q

00:13:02,650 --> 00:13:08,260
worker on that machine so just to show

00:13:06,940 --> 00:13:10,960
you what that might look like there you

00:13:08,260 --> 00:13:13,390
go I'm connecting to the Redis running

00:13:10,960 --> 00:13:15,610
on localhost so very much the same as

00:13:13,390 --> 00:13:19,000
the first one just slightly different

00:13:15,610 --> 00:13:21,970
syntax all right so now I need something

00:13:19,000 --> 00:13:23,560
to actually push jobs into my workers so

00:13:21,970 --> 00:13:28,960
I'll fire up a quick session of of

00:13:23,560 --> 00:13:33,480
ipython can everybody read that yep all

00:13:28,960 --> 00:13:33,480
right so some basic imports

00:13:40,700 --> 00:13:51,930
create my queue link it to my connection

00:13:46,560 --> 00:13:53,730
to Redis and at this point I've actually

00:13:51,930 --> 00:13:56,970
got enough stuff to actually sending

00:13:53,730 --> 00:13:59,250
jobs to my workers now the great thing

00:13:56,970 --> 00:14:00,510
about this is that's pretty much the

00:13:59,250 --> 00:14:02,280
same amount of code that you would have

00:14:00,510 --> 00:14:04,200
needed to do this with multiprocessing

00:14:02,280 --> 00:14:06,840
there's a little bit more set up outside

00:14:04,200 --> 00:14:08,820
of Python but I figure that I can teach

00:14:06,840 --> 00:14:11,220
pretty much anybody those three lines of

00:14:08,820 --> 00:14:20,910
code all right so let's actually in

00:14:11,220 --> 00:14:22,890
queue a job and you can actually see

00:14:20,910 --> 00:14:25,350
that on one of the workers the job has

00:14:22,890 --> 00:14:28,620
actually run and you can see the result

00:14:25,350 --> 00:14:30,390
that's a bit hard to see I can run a

00:14:28,620 --> 00:14:31,830
second job and you'll see that it'll

00:14:30,390 --> 00:14:33,540
actually try and balance that out

00:14:31,830 --> 00:14:42,420
between the different workers a little

00:14:33,540 --> 00:14:47,070
bit so do something a bit different so

00:14:42,420 --> 00:14:51,780
just run asleep and eventually it will

00:14:47,070 --> 00:14:56,150
finish but the other thing is that I can

00:14:51,780 --> 00:15:00,930
actually create that the job in queueing

00:14:56,150 --> 00:15:04,140
functions or tasks into the queue hands

00:15:00,930 --> 00:15:09,240
me back a job handle which I can then

00:15:04,140 --> 00:15:10,380
pull the results out of alright so

00:15:09,240 --> 00:15:12,780
that's not really a scientific

00:15:10,380 --> 00:15:15,120
simulation it's just kind of executing

00:15:12,780 --> 00:15:18,089
stuff one thing at a time so let's kind

00:15:15,120 --> 00:15:19,589
of scale this up a little bit just to

00:15:18,089 --> 00:15:23,760
make this a bit easier for me to manage

00:15:19,589 --> 00:15:25,230
I've kind of prepared one earlier has

00:15:23,760 --> 00:15:28,440
anybody heard of the Traveling Salesman

00:15:25,230 --> 00:15:30,630
problem there's a problem from graph

00:15:28,440 --> 00:15:34,950
theory and optimization and complexity

00:15:30,630 --> 00:15:37,080
theory that's that's pretty common so

00:15:34,950 --> 00:15:40,080
the basic idea is that you set up a

00:15:37,080 --> 00:15:44,250
graph and each of the nodes in the graph

00:15:40,080 --> 00:15:46,710
represent a city and each of the edges

00:15:44,250 --> 00:15:49,709
in the graph actually represent some

00:15:46,710 --> 00:15:51,510
cost of traversing between those cities

00:15:49,709 --> 00:15:53,089
and what you're trying to do is actually

00:15:51,510 --> 00:15:55,879
find a tour that

00:15:53,089 --> 00:15:57,829
a path that visits every single city in

00:15:55,879 --> 00:16:01,129
the graph and returns back to the

00:15:57,829 --> 00:16:04,009
starting city really what we're looking

00:16:01,129 --> 00:16:05,779
for though is which of those or which of

00:16:04,009 --> 00:16:10,160
all possible tours is actually the

00:16:05,779 --> 00:16:11,720
shortest so you know it's not hard to

00:16:10,160 --> 00:16:12,920
imagine what kind of things that you

00:16:11,720 --> 00:16:15,199
would have to do to actually make

00:16:12,920 --> 00:16:17,329
something like this work so there's just

00:16:15,199 --> 00:16:20,120
a little blob of code that calculates

00:16:17,329 --> 00:16:22,160
the length of a tour and there's

00:16:20,120 --> 00:16:25,040
something that actually given a bunch of

00:16:22,160 --> 00:16:28,660
Tours and a graph which one is which one

00:16:25,040 --> 00:16:28,660
of those tours is actually the shortest

00:16:28,779 --> 00:16:34,100
okay and so this is the naive solution

00:16:31,279 --> 00:16:37,009
which is basically to enumerate all

00:16:34,100 --> 00:16:38,870
possible permutations of cities that

00:16:37,009 --> 00:16:41,689
gives me all the tours that I could ever

00:16:38,870 --> 00:16:43,999
want to run and then I can actually just

00:16:41,689 --> 00:16:46,730
calculate which one is the shortest so

00:16:43,999 --> 00:16:49,279
let me let me do this now and so that

00:16:46,730 --> 00:16:51,829
was pretty quick right so that was with

00:16:49,279 --> 00:16:55,339
a graph a complete graph with eight

00:16:51,829 --> 00:16:58,990
nodes so let's make this twenty okay you

00:16:55,339 --> 00:17:02,420
can see my kernel busy flag in in I -

00:16:58,990 --> 00:17:04,939
busy busy busy alright let's just say

00:17:02,420 --> 00:17:07,549
for the moment that that's way too slow

00:17:04,939 --> 00:17:08,659
for my purposes and this is this is what

00:17:07,549 --> 00:17:11,149
tends to happen when you're actually

00:17:08,659 --> 00:17:13,159
building up these simulations you start

00:17:11,149 --> 00:17:15,260
with a really simple small problem and

00:17:13,159 --> 00:17:16,730
you grow it to a certain extent and then

00:17:15,260 --> 00:17:19,640
you can't grow it any further because

00:17:16,730 --> 00:17:21,949
it's too slow so what's a different way

00:17:19,640 --> 00:17:25,189
of solving this problem okay well one

00:17:21,949 --> 00:17:27,439
way to do it is to actually start

00:17:25,189 --> 00:17:30,740
looking at all right I don't have to

00:17:27,439 --> 00:17:32,450
explicitly enumerate all permutations I

00:17:30,740 --> 00:17:34,970
can just randomly generate a whole bunch

00:17:32,450 --> 00:17:37,100
of them so these great tools in numpy

00:17:34,970 --> 00:17:40,159
for generating random permutations and

00:17:37,100 --> 00:17:42,830
so if I do that on on that big graph

00:17:40,159 --> 00:17:46,130
again what I can get is an approximate

00:17:42,830 --> 00:17:47,630
solution and in many cases that's that's

00:17:46,130 --> 00:17:51,049
enough that your scientists will be

00:17:47,630 --> 00:17:53,059
happy with that anybody who's actually

00:17:51,049 --> 00:17:54,740
done this for real and understands the

00:17:53,059 --> 00:17:56,690
Traveling Salesman problem this is

00:17:54,740 --> 00:17:59,120
absolutely not the right way to solve

00:17:56,690 --> 00:18:00,710
this problem there's dynamic programming

00:17:59,120 --> 00:18:02,240
techniques that will solve it much more

00:18:00,710 --> 00:18:04,340
efficiently and there's really great

00:18:02,240 --> 00:18:05,600
tools out there for doing it what what

00:18:04,340 --> 00:18:07,669
this does show though

00:18:05,600 --> 00:18:09,500
is it shows how the class of problems

00:18:07,669 --> 00:18:13,070
that I'm interested in and care about

00:18:09,500 --> 00:18:16,280
scales right so that's that's a

00:18:13,070 --> 00:18:22,490
simulation but let's actually throw that

00:18:16,280 --> 00:18:23,809
at rata skew all right the only change

00:18:22,490 --> 00:18:26,929
that I really had to make to the

00:18:23,809 --> 00:18:29,450
previous code was to refactor it out

00:18:26,929 --> 00:18:34,580
into a into a module so it's sitting in

00:18:29,450 --> 00:18:36,230
that naive TSP module you then have to

00:18:34,580 --> 00:18:40,610
make that code available to all the

00:18:36,230 --> 00:18:42,740
workers one way to do that is by running

00:18:40,610 --> 00:18:45,020
all your local your workers locally like

00:18:42,740 --> 00:18:46,820
I'm doing now if you were running

00:18:45,020 --> 00:18:48,890
distributed you can use network file

00:18:46,820 --> 00:18:50,630
systems you can actually install the

00:18:48,890 --> 00:18:53,390
module on all the machines that you care

00:18:50,630 --> 00:18:54,980
about how you do that will depend a

00:18:53,390 --> 00:18:56,380
little bit on how you're set up to do

00:18:54,980 --> 00:19:00,289
this

00:18:56,380 --> 00:19:01,880
the other comment about this is actually

00:19:00,289 --> 00:19:04,070
polling and waiting on some of these

00:19:01,880 --> 00:19:07,460
jobs is probably not an ideal way to do

00:19:04,070 --> 00:19:09,590
this an alternative is to actually get

00:19:07,460 --> 00:19:11,330
them to write out results files to disk

00:19:09,590 --> 00:19:13,280
somewhere again if you've got a network

00:19:11,330 --> 00:19:15,520
file system or a database that you can

00:19:13,280 --> 00:19:18,740
drop your results into that's perfect

00:19:15,520 --> 00:19:21,470
alright so I'm going to fire this up and

00:19:18,740 --> 00:19:22,760
you can see the kernels busy and if

00:19:21,470 --> 00:19:24,200
you're standing next to me you could

00:19:22,760 --> 00:19:26,929
probably actually hear the fan on my

00:19:24,200 --> 00:19:29,179
computer go crazy you can actually see

00:19:26,929 --> 00:19:32,059
the results of some of the nodes start

00:19:29,179 --> 00:19:35,809
to show up and what I'm going to do is

00:19:32,059 --> 00:19:39,950
fire up our cue info so you can actually

00:19:35,809 --> 00:19:41,870
see the state of the master cue and what

00:19:39,950 --> 00:19:45,140
each of the workers is doing so both of

00:19:41,870 --> 00:19:46,610
them are busy at the moment okay so

00:19:45,140 --> 00:19:48,980
that's kind of a boring command-line

00:19:46,610 --> 00:19:52,010
interface to that let's let's see if we

00:19:48,980 --> 00:19:54,409
can get a bit more information so this

00:19:52,010 --> 00:19:56,600
is the our cue dashboard and again you

00:19:54,409 --> 00:19:59,840
can see the same kind of things there

00:19:56,600 --> 00:20:04,190
are my workers there's my cues there's

00:19:59,840 --> 00:20:05,929
some jobs left in there and then these

00:20:04,190 --> 00:20:10,400
are the actual functions that are that

00:20:05,929 --> 00:20:14,049
are still left to run in my queue all

00:20:10,400 --> 00:20:14,049
right so we'll let that run

00:20:14,700 --> 00:20:20,259
so even though this approach is really

00:20:18,399 --> 00:20:22,149
simple and it's it's great for teaching

00:20:20,259 --> 00:20:24,700
to scientists because they can get going

00:20:22,149 --> 00:20:28,509
in a really short space of time it's got

00:20:24,700 --> 00:20:30,850
a few limitations you really do have to

00:20:28,509 --> 00:20:34,240
intervene to add robustness one of the

00:20:30,850 --> 00:20:36,399
great things about Python is that doing

00:20:34,240 --> 00:20:39,039
that is actually fairly easy you can

00:20:36,399 --> 00:20:41,350
write some decorators that will abstract

00:20:39,039 --> 00:20:45,100
away things like writing cue database or

00:20:41,350 --> 00:20:48,909
writing to a file system or augmenting

00:20:45,100 --> 00:20:50,620
your results with some extra data you do

00:20:48,909 --> 00:20:54,850
have to actually distribute that source

00:20:50,620 --> 00:20:56,559
code to all the workers this is one

00:20:54,850 --> 00:20:58,000
thing that's a bit curly it shows up

00:20:56,559 --> 00:20:59,470
sometimes when you're working with

00:20:58,000 --> 00:21:01,870
salary as well and some of the other

00:20:59,470 --> 00:21:04,870
Message Queuing tools everything that

00:21:01,870 --> 00:21:07,750
you pass across to a remote machine has

00:21:04,870 --> 00:21:09,519
to be serializable so that means that

00:21:07,750 --> 00:21:11,950
you can't have used closures you can't

00:21:09,519 --> 00:21:14,250
have captured variables from the Scopes

00:21:11,950 --> 00:21:17,379
that you've defined your functions in

00:21:14,250 --> 00:21:20,379
and and that applies to arguments to

00:21:17,379 --> 00:21:22,809
those functions as well it can

00:21:20,379 --> 00:21:25,960
potentially be just a bit memory hungry

00:21:22,809 --> 00:21:28,600
so if I went back to my last simulation

00:21:25,960 --> 00:21:31,600
I'd actually created my graph and then

00:21:28,600 --> 00:21:33,759
basically made 500 pickled copies of it

00:21:31,600 --> 00:21:35,950
and stuffed them in to Redis so that's

00:21:33,759 --> 00:21:37,899
not the greatest way to do this so you

00:21:35,950 --> 00:21:40,149
may want to think about slightly more

00:21:37,899 --> 00:21:44,740
efficient ways to actually transmit that

00:21:40,149 --> 00:21:47,320
information around for me this is a bit

00:21:44,740 --> 00:21:49,539
of a pro and a con so each of those

00:21:47,320 --> 00:21:52,090
Redis workers every time it starts to

00:21:49,539 --> 00:21:55,179
run a job it will actually fork a new

00:21:52,090 --> 00:21:58,120
copy of Python now some of my stuff

00:21:55,179 --> 00:21:59,889
tends to be see extensions which can be

00:21:58,120 --> 00:22:01,870
buggy they can leak the file handles

00:21:59,889 --> 00:22:03,730
they can leak socket handles and they

00:22:01,870 --> 00:22:05,500
can leak memory and so it's nice that

00:22:03,730 --> 00:22:07,299
the operating system just comes along

00:22:05,500 --> 00:22:11,500
after each job has finished and cleans

00:22:07,299 --> 00:22:14,649
everything up there's a couple of other

00:22:11,500 --> 00:22:16,899
little kind of corner cases about Redis

00:22:14,649 --> 00:22:18,639
queue workers that get killed off too

00:22:16,899 --> 00:22:21,009
aggressively you know leave some

00:22:18,639 --> 00:22:22,690
resources lying around so there is a bit

00:22:21,009 --> 00:22:25,680
of work that you need to do to tidy this

00:22:22,690 --> 00:22:29,550
up too to make it a finished solution

00:22:25,680 --> 00:22:31,980
and as is the case with anything that is

00:22:29,550 --> 00:22:33,450
effectively an optimization you really

00:22:31,980 --> 00:22:35,580
need to think about whether you want to

00:22:33,450 --> 00:22:39,090
go go to the extent of doing this stuff

00:22:35,580 --> 00:22:42,120
first you know if you have one core and

00:22:39,090 --> 00:22:43,620
you add you know nine more cause the

00:22:42,120 --> 00:22:45,840
best that you're going to hope to

00:22:43,620 --> 00:22:50,550
improve your performance by as a factor

00:22:45,840 --> 00:22:54,060
of 10 make sure that you know what you

00:22:50,550 --> 00:22:56,400
have really is a problem is that if you

00:22:54,060 --> 00:22:58,800
actually use something like night numpy

00:22:56,400 --> 00:23:00,600
or Syfy or some smarter duct data

00:22:58,800 --> 00:23:02,190
structures and algorithms can you

00:23:00,600 --> 00:23:03,990
actually remove the need to go to a

00:23:02,190 --> 00:23:06,960
parallel simulation in the first place

00:23:03,990 --> 00:23:10,020
and understand that doing this stuff

00:23:06,960 --> 00:23:12,750
actually is expensive so everything can

00:23:10,020 --> 00:23:15,480
fail now so your worker nodes can fail

00:23:12,750 --> 00:23:17,010
the network connections can fail and

00:23:15,480 --> 00:23:19,710
you've got to actually make sure that

00:23:17,010 --> 00:23:21,360
all of that stuff stays in a sufficient

00:23:19,710 --> 00:23:25,320
state of readiness that your simulations

00:23:21,360 --> 00:23:26,970
will run and make sure you can't cheat

00:23:25,320 --> 00:23:29,370
because you know a lot of times

00:23:26,970 --> 00:23:36,530
especially with this class of problem

00:23:29,370 --> 00:23:36,530
there are better solutions any questions

00:23:39,900 --> 00:23:49,050
I just have a question about serializing

00:23:47,040 --> 00:23:52,470
the functions or methods that you pass

00:23:49,050 --> 00:23:54,060
in yeah can you get around that two

00:23:52,470 --> 00:23:56,190
questions first does it throw an

00:23:54,060 --> 00:23:58,650
exception or something if you try and

00:23:56,190 --> 00:24:01,830
pass it will tell you that it's not pick

00:23:58,650 --> 00:24:03,900
libel there there are some ways to work

00:24:01,830 --> 00:24:08,220
around that to a certain extent if

00:24:03,900 --> 00:24:10,500
you've decorated a function so if I go

00:24:08,220 --> 00:24:12,720
back so yeah the second part was Kenyon

00:24:10,500 --> 00:24:14,490
can you pass in a callable class object

00:24:12,720 --> 00:24:18,270
or something like that to avoid that

00:24:14,490 --> 00:24:21,300
constraint the callable classes I'm not

00:24:18,270 --> 00:24:23,490
not I'm not entirely sure one of the

00:24:21,300 --> 00:24:25,050
reasons to actually use the strings to

00:24:23,490 --> 00:24:27,030
actually refer to the functions is that

00:24:25,050 --> 00:24:29,880
it works around some of those problems

00:24:27,030 --> 00:24:32,280
about pickable functions it will

00:24:29,880 --> 00:24:35,370
actually go look the final function with

00:24:32,280 --> 00:24:37,500
any decorators up and so that that helps

00:24:35,370 --> 00:24:39,780
there but the callable class I'm not

00:24:37,500 --> 00:24:42,540
sure it may be that you can subclass

00:24:39,780 --> 00:24:44,280
some of the internals of ret askew and

00:24:42,540 --> 00:24:45,750
make that work yeah I'm just wondering

00:24:44,280 --> 00:24:47,250
about if you had algorithms that

00:24:45,750 --> 00:24:49,110
required a lot of configuration or

00:24:47,250 --> 00:24:52,560
something like that how you'd pass that

00:24:49,110 --> 00:24:56,010
around it may just be easy to transmit

00:24:52,560 --> 00:24:59,400
those things as files or or as entries

00:24:56,010 --> 00:25:01,170
into a database or in fact given that

00:24:59,400 --> 00:25:03,540
you've got Redis running it may be just

00:25:01,170 --> 00:25:07,470
as easy to stuff those arguments into

00:25:03,540 --> 00:25:10,070
Redis were there any more questions we

00:25:07,470 --> 00:25:10,070
could a couple more minutes

00:25:14,999 --> 00:25:20,349
hello this might not be intended to use

00:25:18,039 --> 00:25:22,239
of this but have you encountered any

00:25:20,349 --> 00:25:24,639
synchronization problems does this do

00:25:22,239 --> 00:25:28,179
synchronization properly sorry can you

00:25:24,639 --> 00:25:31,029
say synchronization like is there any

00:25:28,179 --> 00:25:34,779
issues with that and and so one of the

00:25:31,029 --> 00:25:36,969
things that I try to do with a lot of

00:25:34,779 --> 00:25:39,039
these things is you try and break each

00:25:36,969 --> 00:25:41,320
of your jobs down into atomic work

00:25:39,039 --> 00:25:43,599
packages that don't rely on anything

00:25:41,320 --> 00:25:44,709
else and so you've kind of avoided

00:25:43,599 --> 00:25:46,899
you've stepped around the

00:25:44,709 --> 00:25:49,690
synchronization problem now that

00:25:46,899 --> 00:25:51,729
certainly won't work in every case but

00:25:49,690 --> 00:25:54,249
given that most of my simulations are

00:25:51,729 --> 00:25:56,469
Monte Carlo simulations where the units

00:25:54,249 --> 00:26:00,309
of work really are atomic and not

00:25:56,469 --> 00:26:01,749
interdependent I don't care so again it

00:26:00,309 --> 00:26:08,679
depends a little bit on your problem

00:26:01,749 --> 00:26:10,539
space so one other thing that comes to

00:26:08,679 --> 00:26:12,940
my mind when we speak about the word

00:26:10,539 --> 00:26:14,799
simulation as trying to run the same

00:26:12,940 --> 00:26:16,959
thing on so many different set of input

00:26:14,799 --> 00:26:18,909
values yeah which could also be looked

00:26:16,959 --> 00:26:22,179
at another way as a different test cases

00:26:18,909 --> 00:26:23,799
yes so have you ever had a chance where

00:26:22,179 --> 00:26:25,839
any have used something like a test run

00:26:23,799 --> 00:26:27,789
or maybe PI tests in order to do these

00:26:25,839 --> 00:26:29,289
simulations and then generate report no

00:26:27,789 --> 00:26:30,459
but that that actually sounds like a

00:26:29,289 --> 00:26:32,739
good idea

00:26:30,459 --> 00:26:34,809
we certainly have lots of test cases for

00:26:32,739 --> 00:26:37,599
some of the scientific software and it

00:26:34,809 --> 00:26:39,399
probably just does make sense to reduce

00:26:37,599 --> 00:26:41,169
the time that it takes to check

00:26:39,399 --> 00:26:43,649
everything by doing something like that

00:26:41,169 --> 00:26:43,649
yeah

00:26:47,350 --> 00:26:55,010
hey thanks great talk

00:26:50,900 --> 00:26:57,110
when you use threading yep you you get

00:26:55,010 --> 00:27:00,980
trouble with with debugging when you try

00:26:57,110 --> 00:27:02,299
to import PDB pdbs that trace is it is

00:27:00,980 --> 00:27:05,270
it easy to just put your breakpoints

00:27:02,299 --> 00:27:06,140
here if I don't think that that would

00:27:05,270 --> 00:27:09,860
work at all

00:27:06,140 --> 00:27:13,789
I'm honestly not sure most of my

00:27:09,860 --> 00:27:18,010
experience with this has been write test

00:27:13,789 --> 00:27:21,260
debug on a very simple test case first

00:27:18,010 --> 00:27:22,970
and and you know one of the places where

00:27:21,260 --> 00:27:26,419
something like that might be interesting

00:27:22,970 --> 00:27:31,549
is if I have a case simulation that

00:27:26,419 --> 00:27:33,020
fails it's my you can see that when it

00:27:31,549 --> 00:27:35,990
was running there was actually a default

00:27:33,020 --> 00:27:38,000
Q jobs that fail will actually jump into

00:27:35,990 --> 00:27:39,770
the failed queue and I can actually go

00:27:38,000 --> 00:27:42,080
back in and pull out the arguments that

00:27:39,770 --> 00:27:44,299
I pass to those things now all things

00:27:42,080 --> 00:27:46,220
being equal I should just be able to

00:27:44,299 --> 00:27:48,230
copy those arguments and try running

00:27:46,220 --> 00:27:50,950
that particular case on my local machine

00:27:48,230 --> 00:27:53,570
again and it should behave the same way

00:27:50,950 --> 00:27:54,940
for Monte Carlo simulations or things

00:27:53,570 --> 00:27:59,110
where there's some randomness involved

00:27:54,940 --> 00:27:59,110
there's some works of doing that

00:28:05,669 --> 00:28:11,529
this is more of a statement than a

00:28:07,899 --> 00:28:14,259
question there is a library called PI

00:28:11,529 --> 00:28:15,669
cloud the idea being you write functions

00:28:14,259 --> 00:28:16,899
on your local machine you push them off

00:28:15,669 --> 00:28:19,299
to some remote service to actually

00:28:16,899 --> 00:28:22,479
execute them yeah as part of that

00:28:19,299 --> 00:28:23,950
library they reimplemented part of

00:28:22,479 --> 00:28:26,589
pickle that should allow you to

00:28:23,950 --> 00:28:29,619
serialize things such as functions etc I

00:28:26,589 --> 00:28:31,779
know that the ipython parallel does a

00:28:29,619 --> 00:28:34,749
bit more of that kind of thing as well

00:28:31,779 --> 00:28:37,450
so you know this is very much a first

00:28:34,749 --> 00:28:39,279
cut solution that you can start

00:28:37,450 --> 00:28:41,619
prototyping and playing with some of

00:28:39,279 --> 00:28:44,169
these ideas at the point where you've

00:28:41,619 --> 00:28:46,149
got it going and and it doesn't work any

00:28:44,169 --> 00:28:49,859
longer for you it's definitely worth

00:28:46,149 --> 00:28:49,859
upgrading to one of these better tools

00:28:50,279 --> 00:28:55,239
thank you for your talk Andrew so you

00:28:53,679 --> 00:28:56,859
say thanks we've got some coffee

00:28:55,239 --> 00:29:00,389
and the coffee mug and if you could join

00:28:56,859 --> 00:29:00,389

YouTube URL: https://www.youtube.com/watch?v=Ttw816mwnQY


