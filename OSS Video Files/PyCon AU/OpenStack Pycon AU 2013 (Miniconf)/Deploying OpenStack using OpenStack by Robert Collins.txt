Title: Deploying OpenStack using OpenStack by Robert Collins
Publication date: 2013-07-12
Playlist: OpenStack Pycon AU 2013 (Miniconf)
Description: 
	PyCon Australia is the national conference for users of the Python Programming Language. In July 2013, we're returning to Hobart, bringing together students, enthusiasts, and professionals with a love of Python from around Australia, and from all over the World. 

July 5--7 2013, Hobart, Tasmania
Captions: 
	00:00:00,000 --> 00:00:04,980
everyone thank you for coming back on

00:00:01,620 --> 00:00:06,750
time this is excellent it's now two time

00:00:04,980 --> 00:00:08,910
to hand over back again to the robert

00:00:06,750 --> 00:00:11,370
collins to teach us about business the

00:00:08,910 --> 00:00:21,080
openstack on OpenStack talk indeed it is

00:00:11,370 --> 00:00:23,670
please welcome in testing testing right

00:00:21,080 --> 00:00:29,910
if you can't hear me there's something

00:00:23,670 --> 00:00:32,070
wrong with you this time not me right so

00:00:29,910 --> 00:00:40,440
I did the slide before if you've come

00:00:32,070 --> 00:00:42,090
into the room since I did it tough and I

00:00:40,440 --> 00:00:44,219
seem to have deleted on my slides which

00:00:42,090 --> 00:00:50,070
is going to make this a very interesting

00:00:44,219 --> 00:00:52,020
thought you wanted a white background

00:00:50,070 --> 00:00:57,270
for testing with the recording so I

00:00:52,020 --> 00:01:00,270
think we've achieved that so the sounds

00:00:57,270 --> 00:01:02,309
awfully loud to me some is that better

00:01:00,270 --> 00:01:06,570
okay I can just hear it echoing back

00:01:02,309 --> 00:01:09,060
from from somewhere oh yeah Django well

00:01:06,570 --> 00:01:13,380
yeah let's all go there again no

00:01:09,060 --> 00:01:15,750
seriously so the open second OpenStack

00:01:13,380 --> 00:01:17,479
project we're about to at the moment I'm

00:01:15,750 --> 00:01:20,670
actually writing a mission statement for

00:01:17,479 --> 00:01:22,470
the upstream engagement is to turn it

00:01:20,670 --> 00:01:25,619
into a program until now we've just been

00:01:22,470 --> 00:01:27,450
a effort HP's been funding and some

00:01:25,619 --> 00:01:29,070
other organizations have joined in as

00:01:27,450 --> 00:01:31,560
we've gathered some momentum and some

00:01:29,070 --> 00:01:33,770
some capability what we're trying to do

00:01:31,560 --> 00:01:37,049
is to make OpenStack easy to deploy

00:01:33,770 --> 00:01:40,110
because opens Dec as you know par this

00:01:37,049 --> 00:01:43,170
hole cloud focus on automating all of

00:01:40,110 --> 00:01:44,310
the things on that cloud thing I'm sorry

00:01:43,170 --> 00:01:46,680
it's going to be the standing joke for

00:01:44,310 --> 00:01:48,210
the day and since I'm giving about for

00:01:46,680 --> 00:01:53,850
talks you're going to get very bored of

00:01:48,210 --> 00:01:55,259
it if you can't deploy open stat you

00:01:53,850 --> 00:01:56,909
can't get any of the benefits of it

00:01:55,259 --> 00:01:59,549
unless you go to someone else to a cloud

00:01:56,909 --> 00:02:01,170
provider and while there's lots of cloud

00:01:59,549 --> 00:02:03,540
providers around now and there are going

00:02:01,170 --> 00:02:05,909
to be more in future it's actually quite

00:02:03,540 --> 00:02:07,530
useful to be able to do it yourself many

00:02:05,909 --> 00:02:09,660
people already have how we're inside the

00:02:07,530 --> 00:02:11,280
data centers that they're using for

00:02:09,660 --> 00:02:12,150
testing or for their production

00:02:11,280 --> 00:02:14,730
deployment they want to be able to

00:02:12,150 --> 00:02:16,770
repurpose it reuse it consolidate it and

00:02:14,730 --> 00:02:22,170
and would like to make that really

00:02:16,770 --> 00:02:24,860
really easy to do the big big thing for

00:02:22,170 --> 00:02:26,970
me I have a long history in testing

00:02:24,860 --> 00:02:31,500
software testings being a bit of a

00:02:26,970 --> 00:02:34,470
passion of mine for a long time and if

00:02:31,500 --> 00:02:36,569
you don't have the ability to set up a

00:02:34,470 --> 00:02:38,819
clean dedicated test environment and do

00:02:36,569 --> 00:02:40,980
that in a repeatable way really really

00:02:38,819 --> 00:02:43,970
quickly it becomes very very hard to get

00:02:40,980 --> 00:02:47,340
good serious confidence in your software

00:02:43,970 --> 00:02:48,989
so one of the things we want to be able

00:02:47,340 --> 00:02:50,370
to do when we talk about the deployment

00:02:48,989 --> 00:02:52,650
is you want to be confident the

00:02:50,370 --> 00:02:54,959
deployments going to work so you want to

00:02:52,650 --> 00:02:57,340
develop and test the cloud layer itself

00:02:54,959 --> 00:03:02,689
as well as the software that runs on

00:02:57,340 --> 00:03:05,569
and this is the actual plumbing involved

00:03:02,689 --> 00:03:07,250
in OpenStack this is a simplified

00:03:05,569 --> 00:03:12,319
version of the plumbing involved in

00:03:07,250 --> 00:03:14,239
OpenStack the slide that was deleted is

00:03:12,319 --> 00:03:16,879
a very pretty slide that says you have

00:03:14,239 --> 00:03:19,040
compute you have network you have a UI

00:03:16,879 --> 00:03:21,769
you have storage you know it's like the

00:03:19,040 --> 00:03:24,319
big block diagrams that term was shown

00:03:21,769 --> 00:03:25,579
before this is the actual dirty secret

00:03:24,319 --> 00:03:27,590
and as I say this is a simplified

00:03:25,579 --> 00:03:29,750
version because it doesn't show the fact

00:03:27,590 --> 00:03:36,799
that nearly any one of these individual

00:03:29,750 --> 00:03:39,579
components the if I got my oh nope it's

00:03:36,799 --> 00:03:51,049
going to be one of those days isn't that

00:03:39,579 --> 00:03:52,849
one of these buttons now I'm going to

00:03:51,049 --> 00:03:55,370
give up on that yes so if you look at

00:03:52,849 --> 00:03:57,680
one of these buttons here quantum

00:03:55,370 --> 00:03:59,000
plugins here that actually says there's

00:03:57,680 --> 00:04:01,790
about 20 different things you could have

00:03:59,000 --> 00:04:02,989
substituted for that box so your ability

00:04:01,790 --> 00:04:04,400
to predict weather is configured

00:04:02,989 --> 00:04:06,139
correctly and is going to work well is

00:04:04,400 --> 00:04:07,790
hugely dependent on exactly what

00:04:06,139 --> 00:04:10,519
components you've picked from the whole

00:04:07,790 --> 00:04:14,780
ecosystem to be your quantum plugin or

00:04:10,519 --> 00:04:16,430
to be your nova driver plugin tristan

00:04:14,780 --> 00:04:19,340
can I relate the issue you had with it

00:04:16,430 --> 00:04:21,769
yeah so when Tristan tried to run up

00:04:19,340 --> 00:04:23,530
three VMs before and that failed that

00:04:21,769 --> 00:04:26,270
was because he's got a different plugin

00:04:23,530 --> 00:04:29,030
for his virtualization layer he's

00:04:26,270 --> 00:04:31,400
talking to vm z and vm sphere has a

00:04:29,030 --> 00:04:33,919
limit under how long an instance name

00:04:31,400 --> 00:04:36,590
can be when you boot multiple instances

00:04:33,919 --> 00:04:37,820
in OpenStack to differentiate them they

00:04:36,590 --> 00:04:39,919
don't all end up with the same hostname

00:04:37,820 --> 00:04:42,409
they get a Huard appended to the

00:04:39,919 --> 00:04:45,199
hostname and this combination was longer

00:04:42,409 --> 00:04:48,440
than the length of sphere allows so that

00:04:45,199 --> 00:04:49,699
driver has a bug big deal but your

00:04:48,440 --> 00:04:51,080
ability to predict with it you're going

00:04:49,699 --> 00:04:52,400
to have that bug or not is dependent on

00:04:51,080 --> 00:04:56,840
the fact that this is an abstraction

00:04:52,400 --> 00:04:59,150
layer so when you actually go to deploy

00:04:56,840 --> 00:05:02,599
this huge fragile thing whose behavior

00:04:59,150 --> 00:05:04,009
you can't predict it can break it can

00:05:02,599 --> 00:05:05,779
break when you install it it can break

00:05:04,009 --> 00:05:07,009
when you reconfigure it and it can break

00:05:05,779 --> 00:05:11,629
when you up greater

00:05:07,009 --> 00:05:14,479
it can break due to bugs like the one we

00:05:11,629 --> 00:05:16,580
just have it can also break due to

00:05:14,479 --> 00:05:18,559
entropy if you have an environment where

00:05:16,580 --> 00:05:19,909
someone has logged in and done some

00:05:18,559 --> 00:05:21,830
debugging on a node and they've

00:05:19,909 --> 00:05:23,479
installed a debug package they've

00:05:21,830 --> 00:05:25,699
updated the kernel that week to drive a

00:05:23,479 --> 00:05:27,529
configuration and you've got 400 nose

00:05:25,699 --> 00:05:30,050
with one of them that has this slightly

00:05:27,529 --> 00:05:31,399
different behavior it's a pretty short

00:05:30,050 --> 00:05:32,899
bit at some point that nodes going to

00:05:31,399 --> 00:05:34,849
break and everything running on that

00:05:32,899 --> 00:05:36,139
node is going to fall over and disappear

00:05:34,849 --> 00:05:38,779
and your client tenants I'm going to be

00:05:36,139 --> 00:05:40,699
going hey I thought this was reliable

00:05:38,779 --> 00:05:43,219
infrastructure or at least reasonably

00:05:40,699 --> 00:05:45,020
reliable I mean and so one of the things

00:05:43,219 --> 00:05:46,370
that's not always talked about in the

00:05:45,020 --> 00:05:49,849
cloud when you look at the different

00:05:46,370 --> 00:05:51,020
layers of the cloud and application as a

00:05:49,849 --> 00:05:52,729
service you expect to be always

00:05:51,020 --> 00:05:57,620
available everywhere as long as the

00:05:52,729 --> 00:05:59,240
internet is working great a platform as

00:05:57,620 --> 00:06:01,789
a service you don't have that

00:05:59,240 --> 00:06:04,189
expectation you expect that the platform

00:06:01,789 --> 00:06:06,409
as a whole will be available but any

00:06:04,189 --> 00:06:08,930
individual instance of software running

00:06:06,409 --> 00:06:10,939
within it might get crashed might get

00:06:08,930 --> 00:06:13,639
terminate it might get swapped out it's

00:06:10,939 --> 00:06:15,949
got no reliability as at all so what you

00:06:13,639 --> 00:06:17,870
do is you run five or ten Django

00:06:15,949 --> 00:06:21,559
instances in parallel in that platform

00:06:17,870 --> 00:06:23,330
and as a whole you're now highly

00:06:21,559 --> 00:06:25,580
available you have your databases

00:06:23,330 --> 00:06:26,959
clustered you have everything with

00:06:25,580 --> 00:06:28,789
redundancy but the individual components

00:06:26,959 --> 00:06:30,229
are allowed to fail gracefully and when

00:06:28,789 --> 00:06:31,999
you go down to the infrastructure of the

00:06:30,229 --> 00:06:33,289
service layer which is the one that

00:06:31,999 --> 00:06:35,360
platform-as-a-service layers are

00:06:33,289 --> 00:06:37,729
generally implemented on top of you also

00:06:35,360 --> 00:06:39,499
have that expectation that virtual

00:06:37,729 --> 00:06:40,909
machines are not reliable they're not

00:06:39,499 --> 00:06:43,969
the same as physical machines they don't

00:06:40,909 --> 00:06:45,589
have innate redundancy so they might get

00:06:43,969 --> 00:06:48,259
migrated they might suffer computation

00:06:45,589 --> 00:06:49,610
pauses for you know a couple of seconds

00:06:48,259 --> 00:06:51,289
while they get live migrated somewhere

00:06:49,610 --> 00:06:52,819
and you meant to architect your

00:06:51,289 --> 00:06:57,439
applications and the things you build on

00:06:52,819 --> 00:06:59,269
it to deal with that so while in theory

00:06:57,439 --> 00:07:00,919
everyone has this expectation everyone

00:06:59,269 --> 00:07:02,689
understands this trade-off the reality

00:07:00,919 --> 00:07:04,909
is no one does and everyone gets

00:07:02,689 --> 00:07:06,409
extremely unhappy when their vm suddenly

00:07:04,909 --> 00:07:08,539
stops working because the computer host

00:07:06,409 --> 00:07:10,219
that was on has suffered the kernel

00:07:08,539 --> 00:07:11,479
fault because there was a third-party

00:07:10,219 --> 00:07:12,860
driver there that nobody knew about

00:07:11,479 --> 00:07:15,319
those put there a year and a half ago

00:07:12,860 --> 00:07:18,079
and this is the sort of thing I've seen

00:07:15,319 --> 00:07:19,020
happen I'm not making out random stories

00:07:18,079 --> 00:07:21,900
this is

00:07:19,020 --> 00:07:24,629
how things break and lastly of course

00:07:21,900 --> 00:07:26,819
you can actually have hardware fail it's

00:07:24,629 --> 00:07:28,889
a kind of hard to live my greater

00:07:26,819 --> 00:07:31,650
physical machine somewhere else you need

00:07:28,889 --> 00:07:37,289
to buy one walk it and plug it in and

00:07:31,650 --> 00:07:39,139
then we're back in the data across so

00:07:37,289 --> 00:07:42,000
what we're trying to do with triple 0 is

00:07:39,139 --> 00:07:44,280
to bring continuous integration so

00:07:42,000 --> 00:07:46,620
testing the configuration testing the

00:07:44,280 --> 00:07:52,020
software testing the whole running

00:07:46,620 --> 00:07:54,180
production quality stack testing the

00:07:52,020 --> 00:07:55,919
delivery of it how you get it onto the

00:07:54,180 --> 00:07:58,650
metal making sure it's productive or

00:07:55,919 --> 00:08:02,940
reliable robust make it easy to install

00:07:58,650 --> 00:08:04,259
make it easier to maintain you know

00:08:02,940 --> 00:08:05,639
you're still going to need knowledge

00:08:04,259 --> 00:08:10,349
about what you're doing but it shouldn't

00:08:05,639 --> 00:08:11,729
be a learning curve like it is today we

00:08:10,349 --> 00:08:14,009
want to encapsulate the installation

00:08:11,729 --> 00:08:15,539
upgrade process so that we can test it

00:08:14,009 --> 00:08:17,569
so that we can gain confidence is going

00:08:15,539 --> 00:08:21,360
to work and we want to be able to test

00:08:17,569 --> 00:08:26,460
the actual impact of a migration of an

00:08:21,360 --> 00:08:28,560
upgrade in real time and one of the

00:08:26,460 --> 00:08:32,760
things that were using to do that is the

00:08:28,560 --> 00:08:34,200
same api's so the existing deployment

00:08:32,760 --> 00:08:37,020
technologies you can download things

00:08:34,200 --> 00:08:39,479
like crowbar or juju use different

00:08:37,020 --> 00:08:41,099
plumbing to deploy OpenStack then you

00:08:39,479 --> 00:08:43,560
use to deploy virtual machines in

00:08:41,099 --> 00:08:45,029
OpenStack and this means that if you're

00:08:43,560 --> 00:08:48,000
writing a script for example that

00:08:45,029 --> 00:08:49,410
deploys OpenStack in your production

00:08:48,000 --> 00:08:51,930
environment you now have to have a

00:08:49,410 --> 00:08:53,940
different script or at very least a

00:08:51,930 --> 00:08:55,950
different plugin for your deployment

00:08:53,940 --> 00:08:57,720
engine to test it inside a virtual

00:08:55,950 --> 00:08:59,520
machine environment and that means you

00:08:57,720 --> 00:09:01,260
can no longer gain any confidence or

00:08:59,520 --> 00:09:04,050
it's reduced the confidence you can gain

00:09:01,260 --> 00:09:05,880
a less extreme position by virtual

00:09:04,050 --> 00:09:10,470
testing of your deployment capabilities

00:09:05,880 --> 00:09:13,260
so we have a strategic focus that every

00:09:10,470 --> 00:09:15,720
thing that OpenStack offers we will use

00:09:13,260 --> 00:09:18,270
that offering so you have the same API

00:09:15,720 --> 00:09:19,589
whether you're testing doing a test

00:09:18,270 --> 00:09:21,540
deployment to be a medal or production

00:09:19,589 --> 00:09:23,760
deployment same API every step along the

00:09:21,540 --> 00:09:25,800
way reduce the number of variables you

00:09:23,760 --> 00:09:28,620
have to consider when analyzing whether

00:09:25,800 --> 00:09:35,970
something is a good indicator and and as

00:09:28,620 --> 00:09:38,640
ready to go live to tackle these

00:09:35,970 --> 00:09:40,950
different sorts of failure modes we've

00:09:38,640 --> 00:09:43,230
got different strategies for bugs we

00:09:40,950 --> 00:09:45,360
think CRS CD is a good strategy for cut

00:09:43,230 --> 00:09:46,500
uncovering bugs we're going to find out

00:09:45,360 --> 00:09:48,600
what's going to go wrong if we have

00:09:46,500 --> 00:09:50,310
reasonable test coverage it won't help

00:09:48,600 --> 00:09:51,630
us with deal with craft at all or won't

00:09:50,310 --> 00:09:53,550
help us deal with hardware failure

00:09:51,630 --> 00:09:57,780
doesn't give any sort of indicator for

00:09:53,550 --> 00:10:02,640
them who here is not familiar with the

00:09:57,780 --> 00:10:04,850
concept of golden image right ok so the

00:10:02,640 --> 00:10:07,500
idea of a golden image is that you

00:10:04,850 --> 00:10:15,450
actually I describe it about three sides

00:10:07,500 --> 00:10:18,120
so the core concept though is that we

00:10:15,450 --> 00:10:20,190
build something that has reduced

00:10:18,120 --> 00:10:22,320
opportunity for entropy and then we use

00:10:20,190 --> 00:10:24,510
that to do the deployments and obviously

00:10:22,320 --> 00:10:26,670
we need a highly available setup of all

00:10:24,510 --> 00:10:28,080
of OpenStack and that means all of opens

00:10:26,670 --> 00:10:30,480
that needs to be able to be deployed in

00:10:28,080 --> 00:10:34,740
an H a fashion which is kind of true

00:10:30,480 --> 00:10:37,140
today so the overall triple o deployment

00:10:34,740 --> 00:10:39,840
story for an organization of us to

00:10:37,140 --> 00:10:41,280
deploy open season triple o is that you

00:10:39,840 --> 00:10:43,440
would start with a developer uploading

00:10:41,280 --> 00:10:46,140
the change now we're focused on trunk

00:10:43,440 --> 00:10:50,550
open stack because releases are just a

00:10:46,140 --> 00:10:52,200
great way to keep bugs right when the

00:10:50,550 --> 00:10:56,310
soft is released all the existing bugs

00:10:52,200 --> 00:10:57,810
stay there of course you avoid the risk

00:10:56,310 --> 00:10:59,040
that new bugs or the adders which is why

00:10:57,810 --> 00:11:01,950
a lot of organizations that are

00:10:59,040 --> 00:11:04,820
risk-averse want to consume releases but

00:11:01,950 --> 00:11:09,150
from our perspective we know just how

00:11:04,820 --> 00:11:11,640
many ways there are that a cloud

00:11:09,150 --> 00:11:13,200
environment can decay like hardware

00:11:11,640 --> 00:11:15,180
changes out from under you drivers

00:11:13,200 --> 00:11:16,920
change the virtualization engines people

00:11:15,180 --> 00:11:19,050
are using a change the standards people

00:11:16,920 --> 00:11:20,730
are writing to change we think it's a

00:11:19,050 --> 00:11:23,820
much better trade off to take the

00:11:20,730 --> 00:11:25,860
possibility of new bugs and the absolute

00:11:23,820 --> 00:11:27,450
confidence that existing buzzing fixed

00:11:25,860 --> 00:11:29,460
then the other way around at least today

00:11:27,450 --> 00:11:32,340
maybe in two years time there'll be a

00:11:29,460 --> 00:11:33,780
different story we start with a change

00:11:32,340 --> 00:11:36,150
coming in that might be coming in to

00:11:33,780 --> 00:11:37,920
upstream OpenStack and where we're

00:11:36,150 --> 00:11:41,440
aiming to have this be part of the

00:11:37,920 --> 00:11:44,090
gating process for OpenStack itself

00:11:41,440 --> 00:11:45,980
but also within your own organization if

00:11:44,090 --> 00:11:47,720
you are picking effects from upstream

00:11:45,980 --> 00:11:49,220
over second bringing it in you'd run

00:11:47,720 --> 00:11:51,530
through this process locally as well so

00:11:49,220 --> 00:11:52,910
there's no no no change you take that

00:11:51,530 --> 00:11:55,340
and you build a disk image a machine

00:11:52,910 --> 00:11:56,840
image that you can boot that has the

00:11:55,340 --> 00:11:59,570
OpenStack code with that change

00:11:56,840 --> 00:12:02,900
incorporated in it on the image you then

00:11:59,570 --> 00:12:06,080
deploy that and test it on the small

00:12:02,900 --> 00:12:07,610
scale just that thing in isolation you

00:12:06,080 --> 00:12:09,790
put the result to the side if it fails

00:12:07,610 --> 00:12:12,530
you know there's obviously a problem

00:12:09,790 --> 00:12:15,140
tell the user you failed your test run

00:12:12,530 --> 00:12:17,330
you can't land this command if it works

00:12:15,140 --> 00:12:20,360
we go to a more sophisticated tests

00:12:17,330 --> 00:12:23,570
where we build a whole cloud from

00:12:20,360 --> 00:12:26,840
scratch we deploy a bare metal cloud

00:12:23,570 --> 00:12:29,390
that can deploy physical nodes and we

00:12:26,840 --> 00:12:31,520
give that be a middle cloud the computer

00:12:29,390 --> 00:12:33,080
image or the control plane image or

00:12:31,520 --> 00:12:35,210
whatever image was affected by this code

00:12:33,080 --> 00:12:36,860
change and we ask at the scale there

00:12:35,210 --> 00:12:39,620
that onto a machine we give it a

00:12:36,860 --> 00:12:41,390
workload we migrate it from the previous

00:12:39,620 --> 00:12:43,190
version of these images to the new

00:12:41,390 --> 00:12:45,650
version so we can see that vibrations

00:12:43,190 --> 00:12:47,570
work there's a certain amount of science

00:12:45,650 --> 00:12:53,330
fiction here but it's all coming

00:12:47,570 --> 00:12:55,460
together this is an impro cess thing the

00:12:53,330 --> 00:12:57,530
we use heat which is that the

00:12:55,460 --> 00:12:59,840
orchestration tool with an OpenStack to

00:12:57,530 --> 00:13:01,490
coordinate all of this workflow so we

00:12:59,840 --> 00:13:03,440
don't have lots of little custom bits of

00:13:01,490 --> 00:13:05,240
code right into the Nova API we just

00:13:03,440 --> 00:13:07,040
have one description of heat and we say

00:13:05,240 --> 00:13:12,080
hey here's your initial description

00:13:07,040 --> 00:13:13,610
here's a new description go at the end

00:13:12,080 --> 00:13:15,380
of the process of law work we say yep

00:13:13,610 --> 00:13:18,080
we've got great confidence that's ready

00:13:15,380 --> 00:13:20,360
for production use and we then go to the

00:13:18,080 --> 00:13:22,730
production copy of heat and we say

00:13:20,360 --> 00:13:24,350
please deploy this cloud using the same

00:13:22,730 --> 00:13:26,630
images so we're not recompiling or

00:13:24,350 --> 00:13:29,630
rebuilding anything if those images

00:13:26,630 --> 00:13:30,980
worked and test it's pretty easy to say

00:13:29,630 --> 00:13:33,700
the same images should work in

00:13:30,980 --> 00:13:33,700
production

00:13:36,440 --> 00:13:41,540
now I haven't really talked about things

00:13:39,980 --> 00:13:42,920
like share for popular anything so far

00:13:41,540 --> 00:13:47,800
and they're actually not part of our

00:13:42,920 --> 00:13:52,820
story at all and here's why when you

00:13:47,800 --> 00:13:55,120
look at the problems that we need to

00:13:52,820 --> 00:13:59,930
solve in deploying a multi-node

00:13:55,120 --> 00:14:01,460
multi-tier application on bare metal we

00:13:59,930 --> 00:14:02,840
need to solve machine provisioning we've

00:14:01,460 --> 00:14:04,340
got to be able to take a whole bunch of

00:14:02,840 --> 00:14:06,560
machines and convert them into parts of

00:14:04,340 --> 00:14:08,300
that cluster we've got to get softer on

00:14:06,560 --> 00:14:09,740
those machines so more than just having

00:14:08,300 --> 00:14:11,240
the machine configured correctly at the

00:14:09,740 --> 00:14:13,520
Russell you know raid controller level

00:14:11,240 --> 00:14:14,330
we have to have the right us on it we

00:14:13,520 --> 00:14:17,510
have to have the right configuration

00:14:14,330 --> 00:14:19,490
within that we have diminished state

00:14:17,510 --> 00:14:21,650
there's local state that gets stored in

00:14:19,490 --> 00:14:23,540
these machines the database files things

00:14:21,650 --> 00:14:24,980
like Swift that store persistent storage

00:14:23,540 --> 00:14:27,710
on the machine that needs to be taken

00:14:24,980 --> 00:14:29,870
care of and finally we need to glue them

00:14:27,710 --> 00:14:31,850
all together we need to take the fact

00:14:29,870 --> 00:14:33,200
the one machine is a compute node and

00:14:31,850 --> 00:14:35,180
other machines need to be aware of that

00:14:33,200 --> 00:14:38,270
so they put it in the right nagios

00:14:35,180 --> 00:14:39,980
monitoring group load balancers need to

00:14:38,270 --> 00:14:46,160
know where they back in traffic to that

00:14:39,980 --> 00:14:48,860
sort of thing who here is in sort of in

00:14:46,160 --> 00:14:51,200
an ops or sysadmin or DevOps kind of

00:14:48,860 --> 00:14:56,840
role all right so I'll spend a little

00:14:51,200 --> 00:14:59,600
bit more more more terminus so from our

00:14:56,840 --> 00:15:01,490
perspective things like chef and puppet

00:14:59,600 --> 00:15:03,500
really don't help with service

00:15:01,490 --> 00:15:05,570
orchestration or Hardware provisional

00:15:03,500 --> 00:15:06,950
you can build stuff on top of them to do

00:15:05,570 --> 00:15:08,540
both of those things but that doesn't

00:15:06,950 --> 00:15:11,150
mean they're actively helping you the

00:15:08,540 --> 00:15:14,560
kind of fear but they're not directly

00:15:11,150 --> 00:15:14,560
supporting they weren't designed for it

00:15:16,440 --> 00:15:23,230
have-have we compared salt to chef and

00:15:19,420 --> 00:15:28,149
puppet yes and I believe it fits exactly

00:15:23,230 --> 00:15:30,010
in the same category it's got a somewhat

00:15:28,149 --> 00:15:32,320
better design in a number of ways but

00:15:30,010 --> 00:15:34,480
it's not actually trying to solve these

00:15:32,320 --> 00:15:36,370
other problems now I'm not saying it

00:15:34,480 --> 00:15:37,779
should solve the other problems that's

00:15:36,370 --> 00:15:39,699
the next point I'm going to get to

00:15:37,779 --> 00:15:41,649
things like juju and mares tried to

00:15:39,699 --> 00:15:45,630
solve too many problems they try and

00:15:41,649 --> 00:15:47,649
solve everything all at once and just

00:15:45,630 --> 00:15:49,420
personal engineering preference I prefer

00:15:47,649 --> 00:15:52,420
a small tool that does one thing well

00:15:49,420 --> 00:15:53,709
which I can easily understand if I if I

00:15:52,420 --> 00:15:56,130
if there's something going wrong with it

00:15:53,709 --> 00:15:58,420
I have a small manual I need to read a

00:15:56,130 --> 00:16:00,880
small amount of CO need to look through

00:15:58,420 --> 00:16:06,430
our like a bunch of those tools that

00:16:00,880 --> 00:16:08,320
cooperate well together and so triple o

00:16:06,430 --> 00:16:10,240
is built in on using Nova to do machine

00:16:08,320 --> 00:16:12,579
provisioning both physical machines and

00:16:10,240 --> 00:16:14,170
VMS we use a thing called disk image

00:16:12,579 --> 00:16:16,510
builder to do the software installation

00:16:14,170 --> 00:16:21,190
now disk image builder is a very thin

00:16:16,510 --> 00:16:22,990
wrapper around to root and make x4 file

00:16:21,190 --> 00:16:24,910
system and copy the two things together

00:16:22,990 --> 00:16:28,480
we don't actually run an operating

00:16:24,910 --> 00:16:30,550
system installer ever what we do is take

00:16:28,480 --> 00:16:32,649
a vendor provided image like the ax

00:16:30,550 --> 00:16:34,480
bunch of cloud images or recently Red

00:16:32,649 --> 00:16:36,670
Hat have got cloud images available and

00:16:34,480 --> 00:16:38,760
we suck that down in through disk image

00:16:36,670 --> 00:16:41,019
builder and then we customize it the

00:16:38,760 --> 00:16:43,990
customization to add an ethernet card

00:16:41,019 --> 00:16:45,820
that Tristan did just in time as he did

00:16:43,990 --> 00:16:47,380
the deploy that's the sort of thing you

00:16:45,820 --> 00:16:49,180
can do in disk image builder to

00:16:47,380 --> 00:16:52,000
transform your input image to one that's

00:16:49,180 --> 00:16:53,320
suitable for your environment and the

00:16:52,000 --> 00:16:54,760
reason you might want to do that as a

00:16:53,320 --> 00:16:56,920
part of building a new home and rather

00:16:54,760 --> 00:16:59,079
than doing it just in time is because

00:16:56,920 --> 00:17:00,160
you want to be sure that it's there that

00:16:59,079 --> 00:17:02,019
there's no opportunity for it to go

00:17:00,160 --> 00:17:03,730
wrong if the metadata server isn't

00:17:02,019 --> 00:17:05,919
available you still want to be able to

00:17:03,730 --> 00:17:09,910
get to the instance on your management

00:17:05,919 --> 00:17:13,240
Network it removes the opportunity for a

00:17:09,910 --> 00:17:15,130
number of failures to occur it also

00:17:13,240 --> 00:17:17,890
means you're not shipping multiple

00:17:15,130 --> 00:17:19,299
kilobytes of arbitrary code out to an

00:17:17,890 --> 00:17:21,490
instance and hoping that it does the

00:17:19,299 --> 00:17:24,179
right thing all the code is there on the

00:17:21,490 --> 00:17:27,419
instance in advance

00:17:24,179 --> 00:17:29,519
for configuration the last mile tuning

00:17:27,419 --> 00:17:31,470
of the instance we don't do any software

00:17:29,519 --> 00:17:32,999
installation so this is a principle

00:17:31,470 --> 00:17:35,759
thing software installation is part of

00:17:32,999 --> 00:17:37,499
software image building configuration is

00:17:35,759 --> 00:17:41,100
telling the software that's already

00:17:37,499 --> 00:17:42,960
installed what to do and this is also a

00:17:41,100 --> 00:17:44,879
performance thing if you're doing lots

00:17:42,960 --> 00:17:46,769
of deployments you can spend in very

00:17:44,879 --> 00:17:50,820
very large amount of time and D package

00:17:46,769 --> 00:17:53,460
your rpm very very easily we do it once

00:17:50,820 --> 00:17:54,869
and then we forget about it never have

00:17:53,460 --> 00:17:56,759
to do it again until we've actually got

00:17:54,869 --> 00:17:59,759
a new version and then we push out a new

00:17:56,759 --> 00:18:01,649
image things like a sink for for live

00:17:59,759 --> 00:18:06,869
machine updates are very very efficient

00:18:01,649 --> 00:18:08,879
at just copying the changed files for

00:18:06,869 --> 00:18:10,769
state management so this commercial to

00:18:08,879 --> 00:18:13,169
ask apply configure NOS refresh

00:18:10,769 --> 00:18:15,749
configure just small tools that know how

00:18:13,169 --> 00:18:17,580
to build a disk image take a

00:18:15,749 --> 00:18:19,139
configuration metadata description in

00:18:17,580 --> 00:18:21,840
Jason and write it down to etcetera

00:18:19,139 --> 00:18:23,909
files on disk and run migration script

00:18:21,840 --> 00:18:27,059
so the Aastra fresh config knows how to

00:18:23,909 --> 00:18:29,279
run a sysadmin script that's involved in

00:18:27,059 --> 00:18:32,190
updating for example the schemer of a

00:18:29,279 --> 00:18:34,950
database or something so that's the

00:18:32,190 --> 00:18:38,909
place that you hook in your Nova DB sync

00:18:34,950 --> 00:18:42,440
commands or whatever else and heat is

00:18:38,909 --> 00:18:42,440
service orchestration so

00:18:45,390 --> 00:18:50,140
when we started this project there was

00:18:47,680 --> 00:18:52,090
no bare metal driver in Nova so if you

00:18:50,140 --> 00:18:54,160
wanted to do physical machines you have

00:18:52,090 --> 00:18:57,370
no no options but there was a patch set

00:18:54,160 --> 00:18:59,650
there ntt docomo and is I had been

00:18:57,370 --> 00:19:01,840
working on that added such a driver and

00:18:59,650 --> 00:19:04,690
we were like yes this is great we'll use

00:19:01,840 --> 00:19:06,070
this a year later and it's been

00:19:04,690 --> 00:19:11,320
completely rewritten and it's nearly

00:19:06,070 --> 00:19:17,350
usable more seriously though it's it's

00:19:11,320 --> 00:19:18,790
the initial patch set worked but there

00:19:17,350 --> 00:19:20,470
was a lot of friction in the design

00:19:18,790 --> 00:19:22,090
between the Wayne over thought about

00:19:20,470 --> 00:19:24,010
things in the way this patch that wanted

00:19:22,090 --> 00:19:25,510
to think about things in particular if

00:19:24,010 --> 00:19:28,570
you think about the problem of a vm

00:19:25,510 --> 00:19:30,520
creation system you've got a big compute

00:19:28,570 --> 00:19:33,610
node it might have let's call it 100 gig

00:19:30,520 --> 00:19:35,440
of ram that might have 50 CPUs in it I

00:19:33,610 --> 00:19:36,730
know these numbers aren't exact ones

00:19:35,440 --> 00:19:37,900
because of the way the architecture

00:19:36,730 --> 00:19:40,660
works but it's easier to talk about

00:19:37,900 --> 00:19:43,300
round numbers 100 gig around 50 CPUs and

00:19:40,660 --> 00:19:45,490
you can subdivide this you can subdivide

00:19:43,300 --> 00:19:47,740
it down to fractions of a cpu because

00:19:45,490 --> 00:19:50,320
you've got your host hypervisor was able

00:19:47,740 --> 00:19:52,120
to time slice between the m's and you

00:19:50,320 --> 00:19:53,470
can slice it down to very small amounts

00:19:52,120 --> 00:19:55,150
of that Ram although you probably don't

00:19:53,470 --> 00:19:56,200
want to force VMs to actually be

00:19:55,150 --> 00:19:59,560
swapping when they're running because

00:19:56,200 --> 00:20:00,970
that would that would be bad they forgot

00:19:59,560 --> 00:20:02,980
physical machine and you're going to put

00:20:00,970 --> 00:20:07,960
a physical work load onto it you can't

00:20:02,980 --> 00:20:10,030
do that it's not subdivided so if you

00:20:07,960 --> 00:20:13,440
model a collection of physical machines

00:20:10,030 --> 00:20:16,180
as one big machine maybe that will work

00:20:13,440 --> 00:20:18,220
it turns out that doesn't because you

00:20:16,180 --> 00:20:19,900
can't subdivide arbitrarily each

00:20:18,220 --> 00:20:22,120
individual machine has to come out as

00:20:19,900 --> 00:20:25,930
exactly its size if you try and schedule

00:20:22,120 --> 00:20:28,570
a a vm with one cpu and a gig of ram

00:20:25,930 --> 00:20:30,550
into a cluster is made up for 24 core

00:20:28,570 --> 00:20:31,990
machines of 100 google ramage the

00:20:30,550 --> 00:20:33,790
numbers aren't going to add up and the

00:20:31,990 --> 00:20:37,630
nova scheduler gets very very very

00:20:33,790 --> 00:20:40,000
confused so there's a bunch of work that

00:20:37,630 --> 00:20:41,290
had to be done there anyway the the up

00:20:40,000 --> 00:20:43,420
shoulders we now have this project

00:20:41,290 --> 00:20:46,270
called ironic which is probably going to

00:20:43,420 --> 00:20:49,860
be just usable in Havana and really

00:20:46,270 --> 00:20:52,120
really good in ice house and it's

00:20:49,860 --> 00:20:55,030
abstracted out that beer middle driver

00:20:52,120 --> 00:20:56,560
to a separate project because it turns

00:20:55,030 --> 00:20:57,549
out that we actually want to be able to

00:20:56,560 --> 00:20:58,989
talk to sender

00:20:57,549 --> 00:21:01,210
for block storage and we want to be able

00:20:58,989 --> 00:21:03,519
to talk directly for Neutron to be able

00:21:01,210 --> 00:21:05,649
to do physical reconfiguration of your

00:21:03,519 --> 00:21:07,600
actual network infrastructure rather

00:21:05,649 --> 00:21:10,690
than an overlay Network we want to

00:21:07,600 --> 00:21:13,179
reconfigure your actual fabric to say

00:21:10,690 --> 00:21:14,830
this machine is now part of that 10 and

00:21:13,179 --> 00:21:18,909
can't see anyone elses broadcast traffic

00:21:14,830 --> 00:21:20,679
thanks so rather than Barry there's a

00:21:18,909 --> 00:21:24,039
small by the know that we actually need

00:21:20,679 --> 00:21:27,249
to set up at a more directly a visible

00:21:24,039 --> 00:21:32,759
layer we've got the three projects i

00:21:27,249 --> 00:21:39,879
just mentioned and and heat now the way

00:21:32,759 --> 00:21:41,769
no the bare metal works is it's got

00:21:39,879 --> 00:21:43,389
pluggable backends itself and this is

00:21:41,769 --> 00:21:45,119
another reason to move it out to a

00:21:43,389 --> 00:21:47,889
separate component to ironic because

00:21:45,119 --> 00:21:49,629
Nova's pluggable with different virtual

00:21:47,889 --> 00:21:52,049
drivers having a virtual driver that

00:21:49,629 --> 00:21:53,980
itself as sub pluggable didn't really

00:21:52,049 --> 00:21:56,980
kind of hinted that there was something

00:21:53,980 --> 00:21:59,249
a bit wrong but the default the

00:21:56,980 --> 00:22:02,529
reference implementation is just pxe and

00:21:59,249 --> 00:22:05,169
ipmi now the sysadmin is here we go near

00:22:02,529 --> 00:22:07,989
you on this is like 1996 it was working

00:22:05,169 --> 00:22:10,539
why we but it's kind of useful to put an

00:22:07,989 --> 00:22:12,970
AP honor the same API the boots a nova

00:22:10,539 --> 00:22:15,009
vm will boot a physical machine because

00:22:12,970 --> 00:22:20,259
we take care of all of the plumbing to

00:22:15,009 --> 00:22:24,399
to tie it together the specific

00:22:20,259 --> 00:22:26,200
mechanism is that we pxe boot up we use

00:22:24,399 --> 00:22:29,529
IP my to tell it that we want to pxe

00:22:26,200 --> 00:22:32,559
boot and we deliver a disk image a

00:22:29,529 --> 00:22:34,720
ramdisk and kernel for the boot that

00:22:32,559 --> 00:22:38,799
will then talk back to our server and

00:22:34,720 --> 00:22:41,289
say hey I'm available here's my I scuzzy

00:22:38,799 --> 00:22:44,559
endpoint details we then talk to it over

00:22:41,289 --> 00:22:47,230
I scuzzy weary petition it with DD the

00:22:44,559 --> 00:22:50,559
disk image onto it and then we rebooted

00:22:47,230 --> 00:22:51,879
the game now an implementation quick

00:22:50,559 --> 00:22:54,309
today is that we don't actually reboot

00:22:51,879 --> 00:22:55,720
it off the local disk we reboot it over

00:22:54,309 --> 00:22:57,730
the network again and this time we give

00:22:55,720 --> 00:23:00,609
her the RAM disk and kernel for the end

00:22:57,730 --> 00:23:02,529
user supply now arguably we should allow

00:23:00,609 --> 00:23:04,389
local boot blocks but it's actually a

00:23:02,529 --> 00:23:07,539
lot easier to keep net booting working

00:23:04,389 --> 00:23:09,580
every time than to recover something

00:23:07,539 --> 00:23:10,659
that's got a bad boot block when the end

00:23:09,580 --> 00:23:12,039
user doesn't have con

00:23:10,659 --> 00:23:15,099
physical console access to the machine

00:23:12,039 --> 00:23:16,359
and you probably don't want to give them

00:23:15,099 --> 00:23:18,789
physical console access to the machine

00:23:16,359 --> 00:23:20,499
so while we may change it to make it

00:23:18,789 --> 00:23:24,509
optional this is actually the preferred

00:23:20,499 --> 00:23:24,509
way that we have for deploying OpenStack

00:23:25,049 --> 00:23:29,080
with two exceptions and those are the

00:23:27,700 --> 00:23:30,759
two machines needed to bootstrap

00:23:29,080 --> 00:23:43,929
everything back up again after you turn

00:23:30,759 --> 00:23:45,639
the whole day to Center off Tim is

00:23:43,929 --> 00:23:49,710
saying that crowbar does the same thing

00:23:45,639 --> 00:23:52,570
for much the same reasons yep ok so

00:23:49,710 --> 00:23:54,159
Godin images coming back to that I must

00:23:52,570 --> 00:23:55,779
apologize to degree this isn't all about

00:23:54,159 --> 00:23:57,149
Python but that is all about opens Dec

00:23:55,779 --> 00:24:01,149
on the service step mini conference so

00:23:57,149 --> 00:24:03,609
please do share about questions so a

00:24:01,149 --> 00:24:06,460
golden image encapsulates unknown good

00:24:03,609 --> 00:24:07,690
set of software when you start with an

00:24:06,460 --> 00:24:09,249
image that you haven't blessed you

00:24:07,690 --> 00:24:11,019
that's not golden it's just a disk image

00:24:09,249 --> 00:24:14,559
once it's once you convince this good

00:24:11,019 --> 00:24:18,220
then it becomes the golden image we

00:24:14,559 --> 00:24:20,649
exclude configuration and persistent

00:24:18,220 --> 00:24:23,979
state from the image now the way we do

00:24:20,649 --> 00:24:25,899
this is it's not kind of pure we don't

00:24:23,979 --> 00:24:27,519
delete every single configuration file

00:24:25,899 --> 00:24:29,499
and then say hey there's no

00:24:27,519 --> 00:24:31,840
configuration there what we do is that

00:24:29,499 --> 00:24:33,099
we don't generate the configuration

00:24:31,840 --> 00:24:36,669
files that we're going to use for our

00:24:33,099 --> 00:24:38,590
actual cause key services things like

00:24:36,669 --> 00:24:39,789
ntp you'll just leave in the image but

00:24:38,590 --> 00:24:42,970
things you're going to reconfigure will

00:24:39,789 --> 00:24:48,159
be able to tune or tweak we generate at

00:24:42,970 --> 00:24:49,809
runtime today the separate state

00:24:48,159 --> 00:24:51,700
partition thing is hypothetical but

00:24:49,809 --> 00:24:57,369
we've we've got proof for concepts we

00:24:51,700 --> 00:24:59,440
just haven't polished it the LSB and you

00:24:57,369 --> 00:25:00,369
know it's a well-known so seven thing to

00:24:59,440 --> 00:25:01,989
be able to put these things on different

00:25:00,369 --> 00:25:04,779
partitions so we're just going to be

00:25:01,989 --> 00:25:07,419
digging that up and polishing it in the

00:25:04,779 --> 00:25:10,330
OpenStack context the interesting

00:25:07,419 --> 00:25:11,769
tweakers we want to make the base image

00:25:10,330 --> 00:25:14,679
itself when it's mounted on a machine

00:25:11,769 --> 00:25:16,840
read-only so that we can be confident

00:25:14,679 --> 00:25:18,879
that we switch it out at any point in

00:25:16,840 --> 00:25:21,669
time with a new image everything should

00:25:18,879 --> 00:25:23,529
be good because nothing valuable has

00:25:21,669 --> 00:25:24,490
been written there we want to make it an

00:25:23,529 --> 00:25:25,960
era to try and

00:25:24,490 --> 00:25:27,730
something valuable something you want to

00:25:25,960 --> 00:25:29,710
keep to the place they'll be replaced

00:25:27,730 --> 00:25:34,090
when we redeploy the machine with a new

00:25:29,710 --> 00:25:35,650
image the way I think about golden

00:25:34,090 --> 00:25:37,480
images is the kind of like packages

00:25:35,650 --> 00:25:39,400
packages that you customized a machine

00:25:37,480 --> 00:25:44,110
golden images that you customize a

00:25:39,400 --> 00:25:46,270
cluster and they can be tested as an

00:25:44,110 --> 00:25:48,160
atom they can be deployed as an atom and

00:25:46,270 --> 00:25:50,770
there's no change between your tests and

00:25:48,160 --> 00:25:53,320
deployment cycles so it's exactly

00:25:50,770 --> 00:26:10,540
analogous I mentioned the toolchain

00:25:53,320 --> 00:26:11,830
stuff before sorry I did a really silly

00:26:10,540 --> 00:26:15,300
thing I started flipping with my mouse

00:26:11,830 --> 00:26:15,300
rather than listening to your question

00:26:17,940 --> 00:26:29,500
yep yep I would put that in the golden

00:26:23,440 --> 00:26:33,610
image yeah so the way so let's talk

00:26:29,500 --> 00:26:34,750
about that the Aastra fresh conflict

00:26:33,610 --> 00:26:38,590
cycle because that will speak to your

00:26:34,750 --> 00:26:39,790
question when you boot the machine the

00:26:38,590 --> 00:26:42,880
first thing it does it connects the

00:26:39,790 --> 00:26:45,190
metadata server and pulls down enough

00:26:42,880 --> 00:26:47,260
configuration data from that the easy to

00:26:45,190 --> 00:26:48,610
compare the world metadata server pulls

00:26:47,260 --> 00:26:50,740
down configuration from that to have to

00:26:48,610 --> 00:26:54,040
talk to heat once it talks to heat it

00:26:50,740 --> 00:26:55,690
then gets you in your topology the

00:26:54,040 --> 00:26:59,380
configuration data for the machine and

00:26:55,690 --> 00:27:04,000
it runs offs refresh config us refresh

00:26:59,380 --> 00:27:05,590
config runs a series of strip directory

00:27:04,000 --> 00:27:07,059
so it has a pre-configured directory and

00:27:05,590 --> 00:27:10,179
it runs everything in that directory a

00:27:07,059 --> 00:27:15,520
configured directory post configure and

00:27:10,179 --> 00:27:16,809
the migrations the the steps I've got up

00:27:15,520 --> 00:27:18,550
here are talking about these are what we

00:27:16,809 --> 00:27:20,530
do using that framework using that

00:27:18,550 --> 00:27:23,140
framework we cuius the fragile services

00:27:20,530 --> 00:27:24,790
using that framework we upgrade the disk

00:27:23,140 --> 00:27:26,590
image by copying it out a glance and

00:27:24,790 --> 00:27:28,240
overlaying it onto the current machine

00:27:26,590 --> 00:27:29,559
if we need to so we don't need to reboot

00:27:28,240 --> 00:27:32,530
unless you've actually changed the

00:27:29,559 --> 00:27:35,020
colonel and sometimes you need to rip it

00:27:32,530 --> 00:27:36,940
so the way configuration gets written is

00:27:35,020 --> 00:27:37,840
for something like rid us is that you

00:27:36,940 --> 00:27:41,080
would say

00:27:37,840 --> 00:27:42,669
well let's assume that Redis handles you

00:27:41,080 --> 00:27:46,330
editing the configuration files while

00:27:42,669 --> 00:27:47,830
it's running most services do when you

00:27:46,330 --> 00:27:49,510
first put the machinery this will fail

00:27:47,830 --> 00:27:51,010
to boost start up properly so I don't

00:27:49,510 --> 00:27:52,630
care because the very first thing the

00:27:51,010 --> 00:27:55,510
machine does is goes back and says

00:27:52,630 --> 00:27:56,830
phones Houmas is giving my config rights

00:27:55,510 --> 00:27:59,110
the conflict down to this going to runs

00:27:56,830 --> 00:28:00,400
through the pre-configure there we

00:27:59,110 --> 00:28:02,049
nothing specific for readers and

00:28:00,400 --> 00:28:03,340
pre-configure because Redis doesn't care

00:28:02,049 --> 00:28:04,900
if you change the config while it's

00:28:03,340 --> 00:28:08,049
running it takes a fit when you tell it

00:28:04,900 --> 00:28:09,159
to reload the configured step probably

00:28:08,049 --> 00:28:11,470
doesn't have anything specific to

00:28:09,159 --> 00:28:13,960
readers either because readers just

00:28:11,470 --> 00:28:16,450
takes a template a conflict father's

00:28:13,960 --> 00:28:19,960
plain text so you'll have a config file

00:28:16,450 --> 00:28:22,419
and opt stack or supply config templates

00:28:19,960 --> 00:28:26,350
etc reduce reduce comp something like

00:28:22,419 --> 00:28:29,679
that and that's a mustache template so

00:28:26,350 --> 00:28:30,880
you've got things that are always going

00:28:29,679 --> 00:28:33,130
to be true for your readers will be

00:28:30,880 --> 00:28:34,299
fixed values and things that are going

00:28:33,130 --> 00:28:37,750
to be coming out of the heat meta data

00:28:34,299 --> 00:28:41,830
will be Jason lookups so just the dotted

00:28:37,750 --> 00:28:44,500
path through to the object you want when

00:28:41,830 --> 00:28:45,580
us refresh config runs the configure set

00:28:44,500 --> 00:28:47,200
one of the steps we have in there is the

00:28:45,580 --> 00:28:49,929
thing that says rewrite all the config

00:28:47,200 --> 00:28:52,270
files so new config files blesseth out

00:28:49,929 --> 00:28:55,390
in the post configured step you'll say I

00:28:52,270 --> 00:28:57,010
always want red is running so check of

00:28:55,390 --> 00:28:59,890
us running for not running started if it

00:28:57,010 --> 00:29:01,570
doesn't start properly era and at the

00:28:59,890 --> 00:29:03,940
end of the whole process if an error

00:29:01,570 --> 00:29:07,149
occurred or if it didn't we tell he

00:29:03,940 --> 00:29:08,470
where we got to if a deployment fails on

00:29:07,149 --> 00:29:10,149
the node you don't want to keep rolling

00:29:08,470 --> 00:29:12,070
out that new deployment to all the rest

00:29:10,149 --> 00:29:16,720
of your cluster you want to stop and fix

00:29:12,070 --> 00:29:18,700
it or even roll back and if it did work

00:29:16,720 --> 00:29:24,880
you want to go on to the next one does

00:29:18,700 --> 00:29:26,679
that yeah so the popular chef thing we

00:29:24,880 --> 00:29:30,159
want to work with people that need

00:29:26,679 --> 00:29:32,049
puppet or chef or need complex system

00:29:30,159 --> 00:29:33,520
management capabilities we don't want to

00:29:32,049 --> 00:29:35,679
cut anyone off from what we're trying to

00:29:33,520 --> 00:29:38,230
do so the tools we've got a deliberately

00:29:35,679 --> 00:29:39,610
really really narrow like they may be do

00:29:38,230 --> 00:29:42,669
ten percent of what share for puppet

00:29:39,610 --> 00:29:44,529
assault does and that's great use your

00:29:42,669 --> 00:29:48,060
puppet or salt or what's the other one

00:29:44,529 --> 00:29:50,580
that's ansible young

00:29:48,060 --> 00:29:52,680
use a user in collaboration what we've

00:29:50,580 --> 00:29:54,630
got thus the templates we are producing

00:29:52,680 --> 00:29:56,250
the base capability we are producing

00:29:54,630 --> 00:29:58,050
should be completely compatible someone

00:29:56,250 --> 00:30:00,810
overlaying share for puppet on top of it

00:29:58,050 --> 00:30:02,880
you could even use one of those tools to

00:30:00,810 --> 00:30:04,680
deliver the metadata the machine because

00:30:02,880 --> 00:30:05,790
we've got small tools plugging in a

00:30:04,680 --> 00:30:12,180
different front end for one of those

00:30:05,790 --> 00:30:14,340
tools is really easy the way heat works

00:30:12,180 --> 00:30:15,960
is that there's an API server you talk

00:30:14,340 --> 00:30:18,570
to the API and the API can give you

00:30:15,960 --> 00:30:20,610
metadata when it boots the machine that

00:30:18,570 --> 00:30:22,020
creates a temporary token for that one

00:30:20,610 --> 00:30:23,940
machine to be able to talk to this

00:30:22,020 --> 00:30:26,700
metadata server and ask for data and

00:30:23,940 --> 00:30:28,260
also to feed data back and say hey this

00:30:26,700 --> 00:30:37,200
is a configuration value i'm exporting

00:30:28,260 --> 00:30:38,910
out to the cluster so heat so i guess

00:30:37,200 --> 00:30:41,670
there's one of the things heat has no

00:30:38,910 --> 00:30:42,780
role within a machine there are tools

00:30:41,670 --> 00:30:44,040
that work with heat that you can run

00:30:42,780 --> 00:30:46,230
within a machine but the heat server

00:30:44,040 --> 00:30:48,180
itself is completely decoupled there's a

00:30:46,230 --> 00:30:49,770
really clear abstraction layer you can

00:30:48,180 --> 00:30:51,570
write alternative tools to talk to the

00:30:49,770 --> 00:30:52,920
heat API and you can also write

00:30:51,570 --> 00:30:55,620
alternative implementations of a heat

00:30:52,920 --> 00:30:58,820
API and heat itself is a reemployment

00:30:55,620 --> 00:31:02,100
ation of the amazon cloud formation api

00:30:58,820 --> 00:31:04,620
but has grown and matured and has got a

00:31:02,100 --> 00:31:07,680
different and I think cleaner kind of

00:31:04,620 --> 00:31:13,200
focus to it over time I started by red

00:31:07,680 --> 00:31:14,190
hat in fact this is the bit one out so

00:31:13,200 --> 00:31:15,120
we've talked through all the plumbing

00:31:14,190 --> 00:31:17,150
now going to talk about some of the

00:31:15,120 --> 00:31:20,940
stuff that we do with them so a

00:31:17,150 --> 00:31:22,740
deployment is really quite simple he has

00:31:20,940 --> 00:31:24,090
the metadata describes how many machines

00:31:22,740 --> 00:31:27,390
there are under class to what discourage

00:31:24,090 --> 00:31:30,600
the running so the whole topology right

00:31:27,390 --> 00:31:32,310
you heat will drive than over API and

00:31:30,600 --> 00:31:34,170
say please boot machine with this image

00:31:32,310 --> 00:31:36,000
and thus initial metadata connected to

00:31:34,170 --> 00:31:38,490
these networks and these block storage

00:31:36,000 --> 00:31:40,200
devices for me and about and so it just

00:31:38,490 --> 00:31:42,590
iterates over your whole definition

00:31:40,200 --> 00:31:45,420
doing that until it's all up and running

00:31:42,590 --> 00:31:47,640
really easy you can run heat and

00:31:45,420 --> 00:31:50,400
devstack on your local machine so you

00:31:47,640 --> 00:31:52,020
still use heat to do this testing

00:31:50,400 --> 00:31:54,270
locally but rather than deploying to

00:31:52,020 --> 00:31:58,240
physical machines you deploy it to VMS

00:31:54,270 --> 00:32:00,230
on your meat on your laptop did easy

00:31:58,240 --> 00:32:01,940
and this is one of the benefits of

00:32:00,230 --> 00:32:06,140
having the same API that I was talking

00:32:01,940 --> 00:32:07,820
about before and yeah for actual final

00:32:06,140 --> 00:32:09,200
pre-production testing you probably want

00:32:07,820 --> 00:32:12,710
to be always be deploying to be a medal

00:32:09,200 --> 00:32:16,100
so bare metal for CI CD and for

00:32:12,710 --> 00:32:18,169
production deployments now I think this

00:32:16,100 --> 00:32:19,970
is still kind of slow but that's mainly

00:32:18,169 --> 00:32:22,880
because the biases on server class

00:32:19,970 --> 00:32:24,260
machines are really really slow and at

00:32:22,880 --> 00:32:25,730
least it's better now than it used to be

00:32:24,260 --> 00:32:31,070
it used to be that big enterprise class

00:32:25,730 --> 00:32:33,169
harbor would take an hour to post so

00:32:31,070 --> 00:32:36,410
yeah we put together a proof of concept

00:32:33,169 --> 00:32:39,410
in a test record HP we've got 40 odd

00:32:36,410 --> 00:32:41,630
machines running grizzly it took us

00:32:39,410 --> 00:32:43,340
about a week to work through bugs will

00:32:41,630 --> 00:32:45,410
she hadn't fixed the news cases we

00:32:43,340 --> 00:32:47,900
hadn't quite got right an hour in our

00:32:45,410 --> 00:32:50,210
code base but once we actually had the

00:32:47,900 --> 00:32:51,410
oh and we were doing the full thing so

00:32:50,210 --> 00:32:52,940
we weren't cheating and just sort of

00:32:51,410 --> 00:32:54,440
manually installing it as each point we

00:32:52,940 --> 00:32:55,580
were fixing little bits of automation or

00:32:54,440 --> 00:32:58,250
templates or signs that were actually

00:32:55,580 --> 00:33:02,210
just manually walking through the the

00:32:58,250 --> 00:33:05,270
talling we have so brought up an under

00:33:02,210 --> 00:33:08,240
cloud in fact this is I may have to come

00:33:05,270 --> 00:33:09,890
back to some stuff we brought up to

00:33:08,240 --> 00:33:11,809
clouds of beer middle cloud and a

00:33:09,890 --> 00:33:13,520
virtual cloud and the beer middle class

00:33:11,809 --> 00:33:15,140
is like one machine that just has the

00:33:13,520 --> 00:33:18,320
control plane to be able to the pxe and

00:33:15,140 --> 00:33:22,130
ipmi stuff and then the the virtualized

00:33:18,320 --> 00:33:24,140
cloud is the other 39 mumble except a

00:33:22,130 --> 00:33:25,340
bunch of the how we was misconfigured

00:33:24,140 --> 00:33:29,540
and we didn't have the right ipmi

00:33:25,340 --> 00:33:31,070
details so we ended up with 20 but once

00:33:29,540 --> 00:33:33,530
we had that under cloud control plane

00:33:31,070 --> 00:33:37,130
and we got the over cloud control plane

00:33:33,530 --> 00:33:41,740
in place I could then drop and rebuild

00:33:37,130 --> 00:33:46,400
the whole thing in about 10 minutes so I

00:33:41,740 --> 00:33:48,110
think that's pretty good I think that

00:33:46,400 --> 00:33:49,850
this is it was really really nice

00:33:48,110 --> 00:33:51,169
sweetie belle say that this is very

00:33:49,850 --> 00:33:53,809
competitive with the performance people

00:33:51,169 --> 00:33:57,460
get our chef or puppet and by

00:33:53,809 --> 00:33:57,460
competitive I mean much faster

00:33:59,010 --> 00:34:06,910
here it is I really should tweak these

00:34:01,090 --> 00:34:09,970
slides around so the undercard Nova

00:34:06,910 --> 00:34:12,040
cloud the under cloud is your admin

00:34:09,970 --> 00:34:13,960
owned cloud it owns the hardware atones

00:34:12,040 --> 00:34:16,090
delivering anything it can deliver

00:34:13,960 --> 00:34:18,149
Hadoop as well as OpenStack doesn't

00:34:16,090 --> 00:34:20,560
matter it's your bare metal cloud and

00:34:18,149 --> 00:34:22,149
for a number of reasons we keep it

00:34:20,560 --> 00:34:23,770
completely separate from the over cloud

00:34:22,149 --> 00:34:26,530
and the over cloud is the actual end

00:34:23,770 --> 00:34:29,800
user cloud that's got kvm instances and

00:34:26,530 --> 00:34:33,190
that you you put workloads on the reason

00:34:29,800 --> 00:34:34,200
we keep it separate is twofold one is at

00:34:33,190 --> 00:34:37,240
least from a public health perspective

00:34:34,200 --> 00:34:39,340
you really can't do bare metal end-user

00:34:37,240 --> 00:34:41,320
tenants today there are so many ways

00:34:39,340 --> 00:34:43,510
people can gain permanent control of a

00:34:41,320 --> 00:34:45,580
machine if they ever run and ring 0 it

00:34:43,510 --> 00:34:48,669
is just not funny it is a security

00:34:45,580 --> 00:34:50,679
nightmare they can rewrite the firmware

00:34:48,669 --> 00:34:52,570
on an esoteric little device somewhere

00:34:50,679 --> 00:34:54,909
in the corner of the Machine and then on

00:34:52,570 --> 00:34:59,500
every boot that code will run in ring 0

00:34:54,909 --> 00:35:02,050
and game over and that's without you

00:34:59,500 --> 00:35:04,240
know they get potentially they can do

00:35:02,050 --> 00:35:06,490
that to the hard drive firmware on one

00:35:04,240 --> 00:35:07,840
of the hard drives like when I say

00:35:06,490 --> 00:35:09,220
something in the corner that you won't

00:35:07,840 --> 00:35:13,540
notice I mean really mean it can be way

00:35:09,220 --> 00:35:16,120
down in the corner separately the

00:35:13,540 --> 00:35:17,980
hypervisor scheduler issue i was talking

00:35:16,120 --> 00:35:19,660
about before is still present it's still

00:35:17,980 --> 00:35:21,340
not easily worked around so even if we

00:35:19,660 --> 00:35:24,400
thought security wise it's completely

00:35:21,340 --> 00:35:26,080
fine it's actually really tricky to make

00:35:24,400 --> 00:35:27,430
it run properly reliably you might be

00:35:26,080 --> 00:35:29,980
able to run separate and OVA cells

00:35:27,430 --> 00:35:33,280
oneself of being metal oneself or

00:35:29,980 --> 00:35:35,620
virtual but I'm not sure that's enough

00:35:33,280 --> 00:35:37,480
of the gain over just running to clouds

00:35:35,620 --> 00:35:40,740
if deploying a cloud is easy just deploy

00:35:37,480 --> 00:35:44,200
to clouds and since deploying a cloud is

00:35:40,740 --> 00:35:46,450
pretty easy so this command line in the

00:35:44,200 --> 00:35:54,550
bottom right here you can't see that can

00:35:46,450 --> 00:35:58,590
you yeah the very bottom line there that

00:35:54,550 --> 00:35:58,590
deploys a new cloud using heat

00:36:00,849 --> 00:36:05,160
it's now in the middle of the screen

00:36:06,839 --> 00:36:11,799
create a cloud I want an under cloud

00:36:09,700 --> 00:36:13,450
power user is just a parameter I'm

00:36:11,799 --> 00:36:15,999
passing and decide this is how you I'm

00:36:13,450 --> 00:36:20,319
talked to verse on my test environment

00:36:15,999 --> 00:36:21,910
and it's it's one command so you can get

00:36:20,319 --> 00:36:23,680
down to that easy who cares about the

00:36:21,910 --> 00:36:24,910
fact you've got two clouds you've got a

00:36:23,680 --> 00:36:27,519
little bit of administrative overhead

00:36:24,910 --> 00:36:29,619
but since the beer middle cloud is only

00:36:27,519 --> 00:36:31,210
used by your sauce admins you don't have

00:36:29,619 --> 00:36:33,670
the same churn on that that you might

00:36:31,210 --> 00:36:36,609
amongst the end user population wow this

00:36:33,670 --> 00:36:41,859
is going to be a sprint to the end I

00:36:36,609 --> 00:36:43,150
think so the interesting thing for me

00:36:41,859 --> 00:36:45,640
about this arrangement is that you can

00:36:43,150 --> 00:36:48,759
run a pre private cloud as just another

00:36:45,640 --> 00:36:50,140
tenant on your under cloud well if you

00:36:48,759 --> 00:36:52,269
had one cloud you tie them together

00:36:50,140 --> 00:36:55,359
that's actually much harder to say I

00:36:52,269 --> 00:36:57,460
will safely run an experimental test of

00:36:55,359 --> 00:36:58,720
my next deployed cloud in that

00:36:57,460 --> 00:37:00,009
environment because it's actually going

00:36:58,720 --> 00:37:01,779
to be interoperating with the same

00:37:00,009 --> 00:37:04,029
control plane services for

00:37:01,779 --> 00:37:06,279
authentication or for scheduling and is

00:37:04,029 --> 00:37:07,779
if you manage to trigger a bug with your

00:37:06,279 --> 00:37:09,969
new version particularly an interrupt

00:37:07,779 --> 00:37:12,160
rossford and interoperability bug you

00:37:09,969 --> 00:37:13,569
could take down everything whereas if

00:37:12,160 --> 00:37:15,190
you say we've got completely separate

00:37:13,569 --> 00:37:16,989
clouds one that owns the bare metal and

00:37:15,190 --> 00:37:19,900
one that's deployed on the bare metal

00:37:16,989 --> 00:37:22,059
then you can just run three tenants of

00:37:19,900 --> 00:37:31,960
the under cloud one production one pre

00:37:22,059 --> 00:37:35,259
Prague 1c icd done where so it's kind of

00:37:31,960 --> 00:37:37,119
describe that this this is the under

00:37:35,259 --> 00:37:38,859
cloud at the moment the way we deploy

00:37:37,119 --> 00:37:40,900
this is where you have another cloud

00:37:38,859 --> 00:37:42,759
down the bottom here the seed cloud and

00:37:40,900 --> 00:37:44,380
the seed ploughed lives is a vm on

00:37:42,759 --> 00:37:46,569
somebody's laptop and you walk into the

00:37:44,380 --> 00:37:48,190
data center you run the seat cloud you

00:37:46,569 --> 00:37:50,279
register a bare metal machine with it

00:37:48,190 --> 00:37:52,269
you use that to deploy the under cloud

00:37:50,279 --> 00:37:55,479
then you use the under clouds at deploy

00:37:52,269 --> 00:37:56,799
everything else okay but the problem is

00:37:55,479 --> 00:37:58,089
that you Nana can't take that laptop

00:37:56,799 --> 00:37:59,769
away what you can things will keep

00:37:58,089 --> 00:38:01,059
running but you need to walk it back in

00:37:59,769 --> 00:38:03,400
every time you want to change your under

00:38:01,059 --> 00:38:04,719
cloud get a new version of software onto

00:38:03,400 --> 00:38:06,369
of that sort of thing which can be

00:38:04,719 --> 00:38:08,859
fairly rare because all it's doing is

00:38:06,369 --> 00:38:11,619
deploying to machines you've already got

00:38:08,859 --> 00:38:14,109
right it probably doesn't need to change

00:38:11,619 --> 00:38:15,880
capabilities that often what we want to

00:38:14,109 --> 00:38:17,680
do is want to make the BM mental cloud

00:38:15,880 --> 00:38:19,569
there the under cloud completely

00:38:17,680 --> 00:38:20,950
self-contained and to make itself

00:38:19,569 --> 00:38:23,950
contain what we need to do is make it

00:38:20,950 --> 00:38:27,839
both high available and we need to make

00:38:23,950 --> 00:38:30,069
it do its own deployments to itself so

00:38:27,839 --> 00:38:31,749
all of the services involved in doing an

00:38:30,069 --> 00:38:33,819
employment need to be able to be taken

00:38:31,749 --> 00:38:36,759
down mid deployment and brought back up

00:38:33,819 --> 00:38:38,259
again and transfer the workload over so

00:38:36,759 --> 00:38:40,269
they need to be stateless API web

00:38:38,259 --> 00:38:41,950
services basically with a stateful back

00:38:40,269 --> 00:38:43,480
end and then the only but that gets

00:38:41,950 --> 00:38:45,489
really hairy is moving your stateful

00:38:43,480 --> 00:38:50,200
back end you'll my sequel cluster stuff

00:38:45,489 --> 00:38:51,789
around today we do that by hand and that

00:38:50,200 --> 00:38:54,009
we don't do full hae because we're not

00:38:51,789 --> 00:38:56,920
finished but we've got scripts that go

00:38:54,009 --> 00:38:58,450
most of the way and what we want do in

00:38:56,920 --> 00:39:01,599
future those who want to use trove the

00:38:58,450 --> 00:39:03,549
OpenStack DB API which runs on top of

00:39:01,599 --> 00:39:05,410
Nova so we want to have trove running on

00:39:03,549 --> 00:39:09,279
Nova to providing the databases for the

00:39:05,410 --> 00:39:11,259
under cloud Nova API implementation we

00:39:09,279 --> 00:39:12,910
want to make it you know I think we can

00:39:11,259 --> 00:39:14,230
break the dependency loop at the install

00:39:12,910 --> 00:39:16,809
well enough because we've separated

00:39:14,230 --> 00:39:20,170
configuration installation that's fine

00:39:16,809 --> 00:39:22,390
conceptually good it's going to be fun

00:39:20,170 --> 00:39:25,480
and this is why in here because this is

00:39:22,390 --> 00:39:27,220
just fun stuff right over cloud have

00:39:25,480 --> 00:39:28,749
talked about our because the over cloud

00:39:27,220 --> 00:39:31,119
is running as a tenant on the bare metal

00:39:28,749 --> 00:39:32,499
the same image that provides the Nova

00:39:31,119 --> 00:39:34,690
control plane for the under cloud can

00:39:32,499 --> 00:39:36,789
provide the Nova control plane for the

00:39:34,690 --> 00:39:38,470
over cloud if you're running the under

00:39:36,789 --> 00:39:39,819
cloud as one machine probably not

00:39:38,470 --> 00:39:41,950
because you've got beer middle rather

00:39:39,819 --> 00:39:43,029
than kvm but if you split out the under

00:39:41,950 --> 00:39:45,519
cloud because you've got tens of

00:39:43,029 --> 00:39:49,119
thousands of nodes then you can reuse

00:39:45,519 --> 00:39:50,890
the images i just mentioned this the

00:39:49,119 --> 00:39:52,450
deployment so the way we're going to get

00:39:50,890 --> 00:39:54,609
rid of the seed node is will deploy the

00:39:52,450 --> 00:39:56,230
scene node will walk in rather than

00:39:54,609 --> 00:40:00,279
deploying a separate cloud with it will

00:39:56,230 --> 00:40:02,589
just scale it out or we might deploy a

00:40:00,279 --> 00:40:04,930
separate cloud but the supra cloud we

00:40:02,589 --> 00:40:08,410
deploy rather than using the heat from

00:40:04,930 --> 00:40:10,569
the seed cloud to the plot will migrate

00:40:08,410 --> 00:40:13,239
that heat into the under cloud and then

00:40:10,569 --> 00:40:16,380
scout out 22 notes so it's a by your

00:40:13,239 --> 00:40:16,380
bootstraps kind of operation

00:40:22,640 --> 00:40:31,650
and so I'm i hope there are questions

00:40:25,830 --> 00:40:33,090
got five minutes to fill there is

00:40:31,650 --> 00:40:38,430
something really fun about the acoustics

00:40:33,090 --> 00:40:40,110
yet okay and these slides are so I I

00:40:38,430 --> 00:40:42,120
must admit I've given this talk a few

00:40:40,110 --> 00:40:44,400
times because it's a very interesting

00:40:42,120 --> 00:40:47,690
lots of people interested in so the

00:40:44,400 --> 00:40:50,670
slides are all up on my Twitter stream

00:40:47,690 --> 00:40:53,520
yeah so I'm at our BTW Collins on

00:40:50,670 --> 00:40:55,410
twitter and if you go back far enough

00:40:53,520 --> 00:40:58,140
you'll find a link this is you know

00:40:55,410 --> 00:41:01,710
triple eye on triple a triple o talk

00:40:58,140 --> 00:41:06,180
slides and I mean you're welcome to copy

00:41:01,710 --> 00:41:07,620
them down just saying well sort of

00:41:06,180 --> 00:41:11,240
fronting function and use kiss between

00:41:07,620 --> 00:41:11,240
heat and something like zookeeper

00:41:16,240 --> 00:41:23,900
so heat is the main specific zookeepers

00:41:20,450 --> 00:41:27,320
general infrastructure zookeeper so that

00:41:23,900 --> 00:41:29,450
the the zookeeper is a distributed

00:41:27,320 --> 00:41:33,800
database hierarchical with a kanay cl's

00:41:29,450 --> 00:41:35,570
on and events heat is I am a template

00:41:33,800 --> 00:41:37,579
engine that takes a template description

00:41:35,570 --> 00:41:40,369
of a cloud and I know about rolling

00:41:37,579 --> 00:41:42,020
deploys for example these features are

00:41:40,369 --> 00:41:43,250
all in heat but it's clear that if you

00:41:42,020 --> 00:41:45,170
said to zookeeper I want to talk about

00:41:43,250 --> 00:41:57,619
rolling deploys they're going to go

00:41:45,170 --> 00:41:59,390
ahead air make sense thanks so I know

00:41:57,619 --> 00:42:02,270
there was a gentleman of the audience

00:41:59,390 --> 00:42:04,970
was very interested in deploying Django

00:42:02,270 --> 00:42:08,980
on top of Alex see on top of OpenStack

00:42:04,970 --> 00:42:08,980
it must be a question from him

00:42:17,010 --> 00:42:21,100
just a random comment your six minutes

00:42:19,420 --> 00:42:25,660
is way faster than anything I ever saw

00:42:21,100 --> 00:42:28,600
with kroeber told you Tim and I talked

00:42:25,660 --> 00:42:30,190
about this back at LCA and I didn't have

00:42:28,600 --> 00:42:31,990
timing data they are just like this is

00:42:30,190 --> 00:42:35,770
how we're going to tackle the problem

00:42:31,990 --> 00:42:37,869
and now we have and yeah that there by

00:42:35,770 --> 00:42:43,150
the way that is about ninety-five

00:42:37,869 --> 00:42:44,410
percent post we should get down to three

00:42:43,150 --> 00:42:46,150
and a half minutes when we start using

00:42:44,410 --> 00:42:47,800
kegs at rather than doing a full reboot

00:42:46,150 --> 00:42:51,760
to go between the deployment and the

00:42:47,800 --> 00:42:55,869
product deployed instance I just wasn't

00:42:51,760 --> 00:42:58,750
too sure about how you deal with servers

00:42:55,869 --> 00:43:01,810
that have raid controllers and lots of

00:42:58,750 --> 00:43:04,960
disks or change arrangements of disks

00:43:01,810 --> 00:43:06,820
that's I think so yeah this is this is

00:43:04,960 --> 00:43:07,960
the problem that basically to describe

00:43:06,820 --> 00:43:10,210
this fully I need to go through the

00:43:07,960 --> 00:43:12,090
whole OpenStack API say well this bit of

00:43:10,210 --> 00:43:15,040
the API we use in this way and so

00:43:12,090 --> 00:43:16,240
there's an API on certain novica in open

00:43:15,040 --> 00:43:19,690
set called cinder which talks about

00:43:16,240 --> 00:43:22,240
block storage and when you think about

00:43:19,690 --> 00:43:23,650
raid on a machine the same things you

00:43:22,240 --> 00:43:25,420
might want to do for block storage i

00:43:23,650 --> 00:43:27,400
want highly available like stories or

00:43:25,420 --> 00:43:28,930
i'm very fast by can tolerate failures

00:43:27,400 --> 00:43:30,510
those are the same trade-offs you make

00:43:28,930 --> 00:43:33,250
when you reconfigure a raid controller

00:43:30,510 --> 00:43:36,190
so what we want to do is we want to have

00:43:33,250 --> 00:43:38,170
a stub driver and center that will talk

00:43:36,190 --> 00:43:41,710
to ironic so you can say to sender i

00:43:38,170 --> 00:43:44,410
want a volume and I want it in raid 5 or

00:43:41,710 --> 00:43:46,300
raid 6 and i want at least 20 spindles

00:43:44,410 --> 00:43:49,210
and i want at least four terabytes of

00:43:46,300 --> 00:43:51,670
data and then when you say to know the

00:43:49,210 --> 00:43:55,540
please boot either with volume or from

00:43:51,670 --> 00:43:58,660
volume with that volume ID ironic will

00:43:55,540 --> 00:44:00,670
say hey that volume mmm i haven't

00:43:58,660 --> 00:44:01,900
allocated it to a machine yet so a look

00:44:00,670 --> 00:44:04,050
at the pool of machines from a machine

00:44:01,900 --> 00:44:06,280
that can be reconfigured to that and

00:44:04,050 --> 00:44:08,380
then tie them together in its database

00:44:06,280 --> 00:44:11,830
so that you always have to use that

00:44:08,380 --> 00:44:14,020
volume ID to land on that machine and in

00:44:11,830 --> 00:44:16,000
its deploy roundest before it actually

00:44:14,020 --> 00:44:18,130
copies the image on it would run a

00:44:16,000 --> 00:44:20,530
vendor specific tool for that raid card

00:44:18,130 --> 00:44:22,210
to reconfigure it and the way will arc

00:44:20,530 --> 00:44:25,180
orchestrated editors will pass the

00:44:22,210 --> 00:44:26,020
description into the RAM disk and then

00:44:25,180 --> 00:44:27,970
you can

00:44:26,020 --> 00:44:33,700
Brandes interprets that description in

00:44:27,970 --> 00:44:35,230
any way you want the current status of

00:44:33,700 --> 00:44:37,450
it is that this is all completely manual

00:44:35,230 --> 00:44:39,400
so you can't do the stuff with cinder so

00:44:37,450 --> 00:44:41,530
the way you do it today is you just

00:44:39,400 --> 00:44:42,790
change your RAM disk to look at the

00:44:41,530 --> 00:44:44,890
machine and to reconfigure raid

00:44:42,790 --> 00:44:47,980
controller which is nowhere near as

00:44:44,890 --> 00:44:49,930
graceful but it you know it does the job

00:44:47,980 --> 00:44:52,420
or if you're buying some some vendors

00:44:49,930 --> 00:44:55,180
like HP Howard just defaults to a fairly

00:44:52,420 --> 00:44:56,920
sensible raid 5 over everything kind of

00:44:55,180 --> 00:45:00,460
set up so you can often just ignore it

00:44:56,920 --> 00:45:02,260
with a lot of hardware some use cases

00:45:00,460 --> 00:45:03,760
though will depend very heavily on heavy

00:45:02,260 --> 00:45:06,000
configured the way they need to

00:45:03,760 --> 00:45:06,000
configure

00:45:20,360 --> 00:45:26,220
this this is from a full from it so some

00:45:24,270 --> 00:45:28,290
dude this like three presentations ago

00:45:26,220 --> 00:45:35,550
and it's been update yeah there's an SVG

00:45:28,290 --> 00:45:40,050
out there for it um I don't think

00:45:35,550 --> 00:45:41,970
anyone's crazy enough more seriously I

00:45:40,050 --> 00:45:43,830
don't think it's useful I mean the point

00:45:41,970 --> 00:45:45,840
of this is to communicate the overall

00:45:43,830 --> 00:45:48,060
structure the people the factor that is

00:45:45,840 --> 00:45:51,120
more complex because the interactions

00:45:48,060 --> 00:45:52,590
between components is kind of implied by

00:45:51,120 --> 00:45:54,990
the time you needed a diagram that's

00:45:52,590 --> 00:45:56,250
busy to describe what's going on you can

00:45:54,990 --> 00:46:02,970
be fairly sure that their stuff being

00:45:56,250 --> 00:46:05,640
skipped and so leading on from the guy

00:46:02,970 --> 00:46:08,730
gentlemen in the France question with

00:46:05,640 --> 00:46:12,780
the undeclared especially all ironic

00:46:08,730 --> 00:46:15,930
going straight on to on to bare metal it

00:46:12,780 --> 00:46:17,850
seems it would be much easier on much

00:46:15,930 --> 00:46:22,850
more generic hardware across the board

00:46:17,850 --> 00:46:26,190
rather than like a bunch of servers that

00:46:22,850 --> 00:46:28,410
like that are all different is that is

00:46:26,190 --> 00:46:33,750
that the case or does it not really

00:46:28,410 --> 00:46:35,310
matter so so there's two answers there

00:46:33,750 --> 00:46:39,030
today it matters a great deal because

00:46:35,310 --> 00:46:41,010
Nova bare metal is was the right one to

00:46:39,030 --> 00:46:44,400
throw away that's never be a metal right

00:46:41,010 --> 00:46:47,190
no ironic understands that each

00:46:44,400 --> 00:46:49,980
individual node so its individual thing

00:46:47,190 --> 00:46:51,720
you can address as a machine might

00:46:49,980 --> 00:46:54,450
attitude part of a chassis containing

00:46:51,720 --> 00:46:56,790
mini machines and each chassis might

00:46:54,450 --> 00:46:59,730
need a different way of talking to it to

00:46:56,790 --> 00:47:02,600
turn machines on or off to configure

00:46:59,730 --> 00:47:04,950
things and and so on that's one

00:47:02,600 --> 00:47:06,840
dimension and then another dimension is

00:47:04,950 --> 00:47:08,130
that your how were within the machine

00:47:06,840 --> 00:47:12,090
there might be different architectures

00:47:08,130 --> 00:47:14,250
so might be armed I 36 x86 64 they might

00:47:12,090 --> 00:47:15,920
need different raid drivers and so on so

00:47:14,250 --> 00:47:18,690
the way we handle those things today

00:47:15,920 --> 00:47:20,160
Nova be a middle you have one driver for

00:47:18,690 --> 00:47:23,089
the lock you're screwed if you have any

00:47:20,160 --> 00:47:25,430
variation there deal

00:47:23,089 --> 00:47:27,200
but what you can do is run multiple Nova

00:47:25,430 --> 00:47:29,630
computes configure for bare metal with a

00:47:27,200 --> 00:47:31,849
separate bare metal database separate

00:47:29,630 --> 00:47:34,369
configuration file each and this

00:47:31,849 --> 00:47:36,019
configuration file will is then specific

00:47:34,369 --> 00:47:37,609
to that type of hardware and when you

00:47:36,019 --> 00:47:39,200
register the hardware another beam until

00:47:37,609 --> 00:47:41,089
you tell it which compute node is going

00:47:39,200 --> 00:47:44,509
to own that hardware so you can deal

00:47:41,089 --> 00:47:47,089
with different architectures it sorry

00:47:44,509 --> 00:47:51,319
you can deal with different control

00:47:47,089 --> 00:47:53,029
drivers chassis drivers there to deal

00:47:51,319 --> 00:47:54,950
with different architectures when you

00:47:53,029 --> 00:47:57,130
describe the bare metal node to know

00:47:54,950 --> 00:47:59,539
that you say this is of this

00:47:57,130 --> 00:48:01,969
architecture that's fine that's handled

00:47:59,539 --> 00:48:03,589
in bare metal and and I wrote to deal

00:48:01,969 --> 00:48:06,200
with different raid controllers and so

00:48:03,589 --> 00:48:07,489
on basically use a good operating system

00:48:06,200 --> 00:48:08,989
like Linux where you can throw every

00:48:07,489 --> 00:48:10,400
single driver under the Sun into the one

00:48:08,989 --> 00:48:13,549
image as long as it's for that

00:48:10,400 --> 00:48:17,359
architecture every driver done then you

00:48:13,549 --> 00:48:19,519
have one ramdisk deployment renders and

00:48:17,359 --> 00:48:24,049
Colonel pepper architecture so one farm

00:48:19,519 --> 00:48:26,329
one for a threat right and the tag on

00:48:24,049 --> 00:48:29,779
the machine that says it's means only

00:48:26,329 --> 00:48:33,259
arm in addition to that tab we also have

00:48:29,779 --> 00:48:35,839
a description of which renders to use to

00:48:33,259 --> 00:48:39,589
provision that machine so anything that

00:48:35,839 --> 00:48:42,589
matches that flavor okay that matches

00:48:39,589 --> 00:48:46,369
arm you're fine and the flavor defines

00:48:42,589 --> 00:48:48,259
the deployment ramdisk so it's there is

00:48:46,369 --> 00:48:50,900
some complexity there but actually the

00:48:48,259 --> 00:48:52,640
complexity doesn't grow beyond having

00:48:50,900 --> 00:48:54,019
one beer mental machine at all to do a

00:48:52,640 --> 00:48:55,219
be a metal machine you need to create a

00:48:54,019 --> 00:49:00,739
deploy around us you need to put your

00:48:55,219 --> 00:49:02,900
tools in it cool now I know a couple of

00:49:00,739 --> 00:49:04,339
you still have questions for Robert but

00:49:02,900 --> 00:49:06,170
we are over time for this presentation

00:49:04,339 --> 00:49:08,380
i'm sure everyone wants to get lunch

00:49:06,170 --> 00:49:11,950
before the django people steal all of it

00:49:08,380 --> 00:49:11,950

YouTube URL: https://www.youtube.com/watch?v=qUF8azA1cfs


