Title: Lrparsing, when regular expressions aren't enough by Clinton Roy
Publication date: 2015-08-04
Playlist: PyCon Australia 2015
Description: 
	Lrparsing is a fast, well documented and tested parsing infrastructure for Python. Parsing infrastructures are used when the input to be parsed is too complex to be done by regular expressions alone. Parsing infrastructures are ideally suited to parsing programming languages and configuration files. Lrparsing is roughly equivalent to the combination of Flex and Bison, except completely implemented in Python, and is thus very Pythonic.

The rest of the abstract uses the following Python snippet as an example:

1 if option else 2

lrparsing provides both a lexer (which breaks the input down into tokens, e.g.:

 ['1', 'if' , 'option',  'else', '2']

and a parser generator, which produces a concrete parse tree:

(«ternary», («bool», 'option'), («expr», '1')), («expr», '2')))

 Lrparsing provides Pythonic syntax support to easily construct parsers for programming languages, Domain Specific Languages and configuration file formats.

Lrparsing is very well suited to constructing Concrete Parse Trees but has little support for creating Abstract Syntax Trees (AST), which are much easier to use: My work has added Abstract Syntax Tree support to lrparsing, yielding exactly the same AST nodes that the Python AST module supports:

IfExp(condition, 1, 2)

This talk will give an overview of the major features of Lrparsing, then look at my work to add AST support. 

PyCon Australia is the national conference for users of the Python Programming Language. In 2015, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

July 31-August 4, Brisbane, Queensland, Australia
Captions: 
	00:00:10,950 --> 00:00:16,439
okay ladies and gentlemen I present to

00:00:14,490 --> 00:00:18,000
your man he net may not need much of an

00:00:16,439 --> 00:00:22,439
introduction but I'll give a short one

00:00:18,000 --> 00:00:23,970
anyway Clinton Roy Clinton is an

00:00:22,439 --> 00:00:26,009
open-source engineer who does a lot of

00:00:23,970 --> 00:00:27,930
low-level networking and operating

00:00:26,009 --> 00:00:37,230
systems level work you may have seen him

00:00:27,930 --> 00:00:39,989
around um please give it up good morning

00:00:37,230 --> 00:00:42,629
everyone before I start I have to say

00:00:39,989 --> 00:00:45,840
that this talk that I put in was an

00:00:42,629 --> 00:00:47,550
attempt to get the author of the library

00:00:45,840 --> 00:00:51,270
that i'm talking about to put in a much

00:00:47,550 --> 00:00:53,310
better talk proposal that attempt failed

00:00:51,270 --> 00:00:55,140
he called my bluff but all of the work

00:00:53,310 --> 00:00:56,940
and most of the slides are actually due

00:00:55,140 --> 00:01:04,530
to rustle up the front so round of

00:00:56,940 --> 00:01:06,509
applause for Russell as well please all

00:01:04,530 --> 00:01:08,700
right so we're talking about pausing

00:01:06,509 --> 00:01:10,680
things a lot of people are comfortable

00:01:08,700 --> 00:01:13,590
pausing things with regular expressions

00:01:10,680 --> 00:01:23,719
this talk is about what to do when

00:01:13,590 --> 00:01:27,719
regular expressions aren't enough okay

00:01:23,719 --> 00:01:29,399
so if you hunt around on the web you'll

00:01:27,719 --> 00:01:31,979
find a lot of people have asked many

00:01:29,399 --> 00:01:34,700
many times how to pass things like xml

00:01:31,979 --> 00:01:38,310
and HTML with regular expressions

00:01:34,700 --> 00:01:46,170
there's a fairly famous quote and it

00:01:38,310 --> 00:01:49,859
ends like this in short you can but you

00:01:46,170 --> 00:01:54,179
really really really shouldn't it's the

00:01:49,859 --> 00:01:56,810
wrong tool for the problem so a lot of

00:01:54,179 --> 00:02:00,389
the nice things with parsing is that it

00:01:56,810 --> 00:02:04,799
is to a large extent and academically

00:02:00,389 --> 00:02:07,229
solved problem the problem with that is

00:02:04,799 --> 00:02:10,890
that you get a lot of strange words when

00:02:07,229 --> 00:02:13,680
they're describing a problem so HTML is

00:02:10,890 --> 00:02:16,290
a Chomsky skype to grammar otherwise

00:02:13,680 --> 00:02:18,630
known as context-free and reg ex is a

00:02:16,290 --> 00:02:21,840
Chomsky type 3 grammar which is regular

00:02:18,630 --> 00:02:24,569
and these are two different classes of

00:02:21,840 --> 00:02:26,129
languages so a tool that compiles one

00:02:24,569 --> 00:02:33,829
won't necessarily be able to pass the

00:02:26,129 --> 00:02:36,870
other so there is an answer to pausing

00:02:33,829 --> 00:02:38,639
most of HTML / XML with regular

00:02:36,870 --> 00:02:49,650
expressions and it's down here at the

00:02:38,639 --> 00:02:55,439
bottom and boots it's down there at the

00:02:49,650 --> 00:02:59,189
bottom and it's quite a while and this

00:02:55,439 --> 00:03:02,280
passes most of HTML not not all of it

00:02:59,189 --> 00:03:04,349
but a fair chunk of it so if you just

00:03:02,280 --> 00:03:10,889
copy and paste that into your web app

00:03:04,349 --> 00:03:12,389
you'll be good to go so the obvious that

00:03:10,889 --> 00:03:13,980
the takeaway point there is if you're

00:03:12,389 --> 00:03:20,489
doing in that in regular expressions

00:03:13,980 --> 00:03:22,889
it's the wrong tool for the problem so

00:03:20,489 --> 00:03:24,900
if you want to break it down into the

00:03:22,889 --> 00:03:30,449
things that the classes of languages

00:03:24,900 --> 00:03:34,859
that regular expressions can't pars its

00:03:30,449 --> 00:03:39,979
structure its counting so for example

00:03:34,859 --> 00:03:43,439
with a simple nested list here of HTML

00:03:39,979 --> 00:03:46,079
you can get kind of clothes with pausing

00:03:43,439 --> 00:03:48,449
bits and pieces of it but the things

00:03:46,079 --> 00:03:51,209
that you can't do is you can't check

00:03:48,449 --> 00:03:53,189
that you've opened and closed your list

00:03:51,209 --> 00:03:55,889
properly regular expressions just can't

00:03:53,189 --> 00:03:57,509
do that they can match the opening they

00:03:55,889 --> 00:04:02,060
can match the closing but they can't

00:03:57,509 --> 00:04:02,060
match the closing and the opening up

00:04:04,760 --> 00:04:10,709
so the typical example you use when

00:04:07,940 --> 00:04:13,790
pausing something is a mathematical

00:04:10,709 --> 00:04:17,160
expression and the reason we do that is

00:04:13,790 --> 00:04:20,070
it is a free form text string but we

00:04:17,160 --> 00:04:22,560
have a lot of history in mass of using

00:04:20,070 --> 00:04:24,360
particular conventions and so the job of

00:04:22,560 --> 00:04:27,770
the parser is to take what is

00:04:24,360 --> 00:04:30,000
essentially a free-form string and apply

00:04:27,770 --> 00:04:32,190
the conventions that we would normally

00:04:30,000 --> 00:04:42,690
apply to it and make that a computer

00:04:32,190 --> 00:04:46,590
program so so what we what we see there

00:04:42,690 --> 00:04:48,750
is a set of strings is actually a set of

00:04:46,590 --> 00:04:50,940
operations applied in a certain order

00:04:48,750 --> 00:04:53,220
and that the job of the positive rate

00:04:50,940 --> 00:04:56,130
that string up into a data structure

00:04:53,220 --> 00:04:58,669
that represents the order of those

00:04:56,130 --> 00:04:58,669
instructions

00:05:02,190 --> 00:05:10,260
so that large expression we can break

00:05:07,740 --> 00:05:14,460
that down into a smaller expression so

00:05:10,260 --> 00:05:18,660
on the Left four and a plus and a larger

00:05:14,460 --> 00:05:21,300
expression so at the top of our data

00:05:18,660 --> 00:05:28,290
structure that explains that we might

00:05:21,300 --> 00:05:30,030
have that tree there so you've got the

00:05:28,290 --> 00:05:33,390
root the root of the tree being the plus

00:05:30,030 --> 00:05:36,000
and the left being the number four which

00:05:33,390 --> 00:05:40,560
is an expression and the right being all

00:05:36,000 --> 00:05:43,200
of that and then we take this large

00:05:40,560 --> 00:05:45,210
expression on the right and weary pause

00:05:43,200 --> 00:05:53,910
that and we break it down until we've

00:05:45,210 --> 00:05:56,880
broken down all of the components so if

00:05:53,910 --> 00:06:00,330
we keep doing that we turn that string

00:05:56,880 --> 00:06:06,270
into this data structure so this is a

00:06:00,330 --> 00:06:08,910
tree represented as a Python couple so

00:06:06,270 --> 00:06:11,970
we've broken it down into an expression

00:06:08,910 --> 00:06:13,800
of the entire tree with the number the

00:06:11,970 --> 00:06:19,700
plus and then the expression on the

00:06:13,800 --> 00:06:24,470
right and the power operator and the

00:06:19,700 --> 00:06:28,200
plus+ operator on the right there and

00:06:24,470 --> 00:06:31,770
the important point here is that we have

00:06:28,200 --> 00:06:33,750
broken this input down into a data

00:06:31,770 --> 00:06:36,690
structure that follows the conventions

00:06:33,750 --> 00:06:38,460
that we following maths it's relatively

00:06:36,690 --> 00:06:40,110
easy to break that string down into a

00:06:38,460 --> 00:06:41,760
data structure that doesn't follow the

00:06:40,110 --> 00:06:45,030
conventions of maths and that's what

00:06:41,760 --> 00:06:46,840
this talk is going to try to explain how

00:06:45,030 --> 00:06:50,690
not to do that

00:06:46,840 --> 00:06:53,569
so regular expressions are still used in

00:06:50,690 --> 00:06:56,389
parsers you very much think in most

00:06:53,569 --> 00:06:58,130
passes you can think of the regular

00:06:56,389 --> 00:07:00,710
expressions as being your basic level

00:06:58,130 --> 00:07:03,830
and then on top of that the parser so

00:07:00,710 --> 00:07:06,500
inside a pausing engine we use the

00:07:03,830 --> 00:07:09,560
regular expression to break up the input

00:07:06,500 --> 00:07:17,270
into a bunch of tokens so that the

00:07:09,560 --> 00:07:22,639
smallest bits of your language so

00:07:17,270 --> 00:07:24,949
there's some terms here so tokenizer and

00:07:22,639 --> 00:07:26,570
lexa pretty much the same thing you feed

00:07:24,949 --> 00:07:29,150
in the input and it breaks it up into

00:07:26,570 --> 00:07:31,610
the smallest tokens the grammar is a

00:07:29,150 --> 00:07:34,160
bunch of rules that describe how to take

00:07:31,610 --> 00:07:35,630
those tokens and join them up into a

00:07:34,160 --> 00:07:39,259
data structure that describes your

00:07:35,630 --> 00:07:40,789
language your PA's a generator takes

00:07:39,259 --> 00:07:42,710
your description of your language and

00:07:40,789 --> 00:07:44,120
generates the computer program the

00:07:42,710 --> 00:07:46,930
parser that will actually do the work

00:07:44,120 --> 00:07:46,930
that you wanted to do

00:07:52,320 --> 00:07:59,800
so inside your grammar your grammar is a

00:07:55,690 --> 00:08:05,740
list of rules so one of the rules that

00:07:59,800 --> 00:08:09,070
we can see here is that an expression is

00:08:05,740 --> 00:08:13,300
an expression with a divided by token

00:08:09,070 --> 00:08:14,860
and another expression and in a grimmer

00:08:13,300 --> 00:08:17,800
we'll have a whole bunch of rules and

00:08:14,860 --> 00:08:23,440
this one is one of those rules and

00:08:17,800 --> 00:08:25,060
that's a pattern so grammar is just a

00:08:23,440 --> 00:08:28,000
collection of those sort of productions

00:08:25,060 --> 00:08:30,610
and you can see the recursive nature of

00:08:28,000 --> 00:08:32,169
the parser we're not in each production

00:08:30,610 --> 00:08:33,760
we're not trying to solve the entire

00:08:32,169 --> 00:08:37,020
pausing problem we're only trying to

00:08:33,760 --> 00:08:43,450
solve one part of the parsing problem so

00:08:37,020 --> 00:08:46,810
here we've got addition power positive

00:08:43,450 --> 00:08:49,510
numbers negative numbers bracketing and

00:08:46,810 --> 00:08:52,600
then down to numbers and the job of the

00:08:49,510 --> 00:08:54,220
parser is to see those little bits and

00:08:52,600 --> 00:08:55,810
put them all together into a data

00:08:54,220 --> 00:09:02,410
structure that describes your entire

00:08:55,810 --> 00:09:07,270
input now there are a lot of tools out

00:09:02,410 --> 00:09:10,300
there that will take your language rules

00:09:07,270 --> 00:09:14,890
and generate a positive or you you might

00:09:10,300 --> 00:09:17,470
have heard of the standard UNIX ones yak

00:09:14,890 --> 00:09:20,740
and bison and they will generate C and

00:09:17,470 --> 00:09:24,250
C++ houses for you there are a lot of

00:09:20,740 --> 00:09:26,350
libraries out there that will generate

00:09:24,250 --> 00:09:29,530
Python code for you but they're all

00:09:26,350 --> 00:09:32,170
awful Russell has written one which is

00:09:29,530 --> 00:09:36,370
wonderful I'm his number one fan of this

00:09:32,170 --> 00:09:38,950
library you write it in Python it

00:09:36,370 --> 00:09:46,540
generates Python you write it in Python

00:09:38,950 --> 00:09:48,520
syntax as well so this here is a very it

00:09:46,540 --> 00:09:52,420
would be the starting point for writing

00:09:48,520 --> 00:09:57,640
a grammar that passes our mathematical

00:09:52,420 --> 00:10:04,150
expressions so we import a few special

00:09:57,640 --> 00:10:07,090
things we define our language expression

00:10:04,150 --> 00:10:11,590
around it's a subclass of generic

00:10:07,090 --> 00:10:14,080
grammar class and as class level

00:10:11,590 --> 00:10:16,180
attributes we're defining an expression

00:10:14,080 --> 00:10:21,040
to be all of those rules that we

00:10:16,180 --> 00:10:24,040
previously looked at this is a special

00:10:21,040 --> 00:10:28,600
token that just means at this point in

00:10:24,040 --> 00:10:31,030
the data structure and we also have the

00:10:28,600 --> 00:10:34,150
tokenizer rule there so the re is a

00:10:31,030 --> 00:10:37,110
regular expression so when we when we're

00:10:34,150 --> 00:10:41,770
trying to match a number we are matching

00:10:37,110 --> 00:10:44,410
0-9 + and everywhere in here where we

00:10:41,770 --> 00:10:49,090
see a literal string that is also a

00:10:44,410 --> 00:10:53,460
token now this is the beginning of a

00:10:49,090 --> 00:10:56,890
language that will pass it if you throw

00:10:53,460 --> 00:11:00,640
a lot of mathematical expressions at

00:10:56,890 --> 00:11:03,040
this parser some it will pass some it

00:11:00,640 --> 00:11:06,850
won't pass and it definitely won't

00:11:03,040 --> 00:11:08,800
follow the conventions that we would

00:11:06,850 --> 00:11:10,540
normally apply so things like

00:11:08,800 --> 00:11:14,020
multiplication coming first in addition

00:11:10,540 --> 00:11:17,350
going last now what we're basically

00:11:14,020 --> 00:11:20,950
saying here is that this grammar is

00:11:17,350 --> 00:11:23,110
ambiguous and that's a particular bit of

00:11:20,950 --> 00:11:26,770
terminology that we're using and it

00:11:23,110 --> 00:11:29,290
means that to take this grammar and

00:11:26,770 --> 00:11:31,720
produce a computer program that will

00:11:29,290 --> 00:11:34,810
only generate one data structure we need

00:11:31,720 --> 00:11:36,640
to give it some more rules well we need

00:11:34,810 --> 00:11:39,210
to give it some more hints about how to

00:11:36,640 --> 00:11:39,210
apply these rules

00:11:42,400 --> 00:11:51,440
so the when all of your literal strings

00:11:48,170 --> 00:11:55,690
and all of your tokens internally they

00:11:51,440 --> 00:11:55,690
get put together in one big expression

00:11:57,850 --> 00:12:05,330
so there are some special cases for

00:12:02,930 --> 00:12:08,450
dealing with this so on this previous

00:12:05,330 --> 00:12:11,300
example it will take all of these little

00:12:08,450 --> 00:12:13,160
strings and these tokens and put them in

00:12:11,300 --> 00:12:15,830
one worker expression and just go this a

00:12:13,160 --> 00:12:17,750
will be will c or d and that's the first

00:12:15,830 --> 00:12:25,100
step that we use to break up your input

00:12:17,750 --> 00:12:28,190
string down into the tokens so you can

00:12:25,100 --> 00:12:31,250
use regular expressions you've got the

00:12:28,190 --> 00:12:33,800
idea of keywords which are literals but

00:12:31,250 --> 00:12:36,350
it also means that if you're writing a

00:12:33,800 --> 00:12:40,190
language that's got variables and you

00:12:36,350 --> 00:12:41,750
declare a token to be a keyword you

00:12:40,190 --> 00:12:46,060
won't be allowed to use a variable

00:12:41,750 --> 00:12:50,570
called and for example that it and the

00:12:46,060 --> 00:12:55,720
grammar will not allow you to do that if

00:12:50,570 --> 00:13:00,080
you if you want that to be the case and

00:12:55,720 --> 00:13:01,610
if your password is given a program and

00:13:00,080 --> 00:13:05,050
it can't understand something it will

00:13:01,610 --> 00:13:05,050
raise the unrecognized token

00:13:11,220 --> 00:13:19,799
right so when we said that this was the

00:13:15,549 --> 00:13:23,949
start of the production of of a passer

00:13:19,799 --> 00:13:27,100
the thing the parser generator ello

00:13:23,949 --> 00:13:29,290
pausing will look at our rules and it

00:13:27,100 --> 00:13:32,350
will try to generate a program and it

00:13:29,290 --> 00:13:35,139
will discover that it's really easy to

00:13:32,350 --> 00:13:36,999
give it a string and not and to be able

00:13:35,139 --> 00:13:41,170
to generate two different data

00:13:36,999 --> 00:13:42,850
structures for that same string so it's

00:13:41,170 --> 00:13:45,730
an ambiguous grammar and it won't let

00:13:42,850 --> 00:13:50,230
you generate a puzzle that so it will

00:13:45,730 --> 00:13:52,089
give you an error message attempting to

00:13:50,230 --> 00:13:57,369
explain what the issue with your grammar

00:13:52,089 --> 00:14:02,379
is so we've given it these two rules

00:13:57,369 --> 00:14:09,009
here and the carrot is indicating that

00:14:02,379 --> 00:14:14,499
that's where the ambiguity is so if we

00:14:09,009 --> 00:14:17,439
see a literal plus we are could be in

00:14:14,499 --> 00:14:18,850
one of two rules and we really only want

00:14:17,439 --> 00:14:22,860
to be in a state where if we see a

00:14:18,850 --> 00:14:22,860
particular token we're only in one rule

00:14:23,309 --> 00:14:30,100
and it's being as helpful as it can be

00:14:27,579 --> 00:14:32,339
to describe the problem with the grammar

00:14:30,100 --> 00:14:32,339
here

00:14:34,460 --> 00:14:47,550
so this gets into a little bit of the

00:14:41,340 --> 00:14:50,880
internals of writing a grammar but you

00:14:47,550 --> 00:14:54,450
can map these rules back to the rules

00:14:50,880 --> 00:15:01,650
that you've added and the idea here is

00:14:54,450 --> 00:15:06,270
that if you've given us this input it

00:15:01,650 --> 00:15:09,420
could generate a party here or it could

00:15:06,270 --> 00:15:11,460
generate a parse tree there and the

00:15:09,420 --> 00:15:13,350
grammar doesn't like to guess who wants

00:15:11,460 --> 00:15:20,100
to know so you need to give it an extra

00:15:13,350 --> 00:15:24,210
hint and the extra hint here is in this

00:15:20,100 --> 00:15:26,610
priority list so this means that instead

00:15:24,210 --> 00:15:30,300
of a set of rules that can be applied

00:15:26,610 --> 00:15:36,810
it's a list of rules with a priority so

00:15:30,300 --> 00:15:39,630
if you can apply the brackets rule match

00:15:36,810 --> 00:15:41,790
that one and then the number rule and

00:15:39,630 --> 00:15:47,160
then them up the power rule and then the

00:15:41,790 --> 00:15:49,770
plus and the minus rule so that will

00:15:47,160 --> 00:15:54,120
reduce that will remove one sort of

00:15:49,770 --> 00:15:58,170
ambiguity you know grammar unfortunately

00:15:54,120 --> 00:15:59,910
we fix that sort of ambiguity but the

00:15:58,170 --> 00:16:04,530
the thing to notice there is that that

00:15:59,910 --> 00:16:07,380
priority is a that is a feature of ello

00:16:04,530 --> 00:16:09,980
pausing that lets it that makes it easy

00:16:07,380 --> 00:16:12,660
for you to add priority to a rules

00:16:09,980 --> 00:16:14,760
instead of having to do all sorts of

00:16:12,660 --> 00:16:17,820
horrible things with your grammar you

00:16:14,760 --> 00:16:19,740
just say these list of rules run them in

00:16:17,820 --> 00:16:22,850
this priority so it's a very nice

00:16:19,740 --> 00:16:26,550
feature available housing unfortunately

00:16:22,850 --> 00:16:29,690
once you fix those grammar problems we

00:16:26,550 --> 00:16:29,690
come up with some more grammar problems

00:16:31,870 --> 00:16:40,330
now the problem here is that it again it

00:16:36,460 --> 00:16:43,150
tells you exactly which rules it's seen

00:16:40,330 --> 00:16:45,130
the problem in its going to get a token

00:16:43,150 --> 00:16:49,750
and it's not going to know which rule to

00:16:45,130 --> 00:16:51,670
go with the problem is that the rules

00:16:49,750 --> 00:16:53,800
that it's talking about are internally

00:16:51,670 --> 00:16:58,210
generated once they're not ones that

00:16:53,800 --> 00:16:59,589
we've written so we have to go in and

00:16:58,210 --> 00:17:06,850
ask for a little bit of debugging

00:16:59,589 --> 00:17:09,040
information so this is the language that

00:17:06,850 --> 00:17:13,030
we've got with the priority and this one

00:17:09,040 --> 00:17:16,020
has still has a language ambiguity so we

00:17:13,030 --> 00:17:20,280
run it we try to compile our grammar and

00:17:16,020 --> 00:17:23,319
we catch the problem and then we will

00:17:20,280 --> 00:17:24,880
show the internal productions and that

00:17:23,319 --> 00:17:29,170
will make it a little bit easier to work

00:17:24,880 --> 00:17:34,720
out where the issues are and you can see

00:17:29,170 --> 00:17:36,670
here that the expressions and the

00:17:34,720 --> 00:17:39,460
priority so those are the ones that

00:17:36,670 --> 00:17:41,380
we've input and then internally LR

00:17:39,460 --> 00:17:44,860
parsing has generated these internal

00:17:41,380 --> 00:17:46,300
states and those are the states those

00:17:44,860 --> 00:17:51,010
are the production rules that it's

00:17:46,300 --> 00:17:54,370
having problems with so when you have a

00:17:51,010 --> 00:17:56,470
look at that the problem here is when it

00:17:54,370 --> 00:18:01,059
gets into this state and it sees a slash

00:17:56,470 --> 00:18:07,890
it's not sure which rule to use when it

00:18:01,059 --> 00:18:07,890
sees the slash so if you substitute

00:18:08,220 --> 00:18:12,790
substitute in that token into your rules

00:18:10,750 --> 00:18:16,720
you'll see that you've got two patterns

00:18:12,790 --> 00:18:21,130
that try to match and again it means

00:18:16,720 --> 00:18:25,540
that we could match that or that or we

00:18:21,130 --> 00:18:26,980
could match that all that and it won't

00:18:25,540 --> 00:18:29,110
let you compile a grammar with that

00:18:26,980 --> 00:18:34,840
ambiguity so we have to give it some

00:18:29,110 --> 00:18:41,520
more hints so this is basically do we

00:18:34,840 --> 00:18:45,040
mean a plus B brackets plus C or a plus

00:18:41,520 --> 00:18:45,400
brackets B plus C it's just deciphering

00:18:45,040 --> 00:18:51,670
between

00:18:45,400 --> 00:18:55,090
those two so the hints that we've added

00:18:51,670 --> 00:19:01,180
here the shift operators and they define

00:18:55,090 --> 00:19:03,010
your associativity so in the maths

00:19:01,180 --> 00:19:05,410
operations we're just defining the

00:19:03,010 --> 00:19:07,810
associativity so in the + example here

00:19:05,410 --> 00:19:10,540
it just pushes the associativity let's

00:19:07,810 --> 00:19:13,230
left so if you've got a plus B plus C

00:19:10,540 --> 00:19:16,870
it'll just put the brackets on the left

00:19:13,230 --> 00:19:19,810
if you've got the power operator so

00:19:16,870 --> 00:19:22,360
we've got a power B power see it will

00:19:19,810 --> 00:19:23,890
use the rules from the rights and put

00:19:22,360 --> 00:19:28,720
the brackets on the right and go back

00:19:23,890 --> 00:19:31,480
left now some of these things are

00:19:28,720 --> 00:19:33,940
specific to mathematics annotation you

00:19:31,480 --> 00:19:37,330
won't always get these problems in a

00:19:33,940 --> 00:19:42,570
regular a regular programming language

00:19:37,330 --> 00:19:44,710
but you do you do get things in regular

00:19:42,570 --> 00:19:47,910
regular problems we're trying to parse

00:19:44,710 --> 00:19:51,850
things and things become ambiguous and

00:19:47,910 --> 00:19:54,190
when you're explaining these hints it's

00:19:51,850 --> 00:19:55,690
often the only common denominator that

00:19:54,190 --> 00:20:00,550
people understand is a mathematical

00:19:55,690 --> 00:20:02,380
language but all of these tools do get

00:20:00,550 --> 00:20:08,320
used outside of the mathematical

00:20:02,380 --> 00:20:12,790
grammars so after we've fixed those two

00:20:08,320 --> 00:20:17,110
ambiguities we now have a final path

00:20:12,790 --> 00:20:21,570
street so this is a tree it's

00:20:17,110 --> 00:20:24,130
represented as a nested list of tuples

00:20:21,570 --> 00:20:27,100
now I've done some work to turn this

00:20:24,130 --> 00:20:28,720
into a Python ast tree that might even

00:20:27,100 --> 00:20:34,540
be ready to actually give a proper talk

00:20:28,720 --> 00:20:37,990
about next year maybe but we are able

00:20:34,540 --> 00:20:42,010
now that the thing here is now that

00:20:37,990 --> 00:20:44,980
we've got that grammar any any input

00:20:42,010 --> 00:20:49,120
string that only has the tokens that

00:20:44,980 --> 00:20:53,110
we've allowed we'll only we can pass

00:20:49,120 --> 00:20:55,840
that and it will only generate one pass

00:20:53,110 --> 00:20:57,220
tree and we guaranteed that for all

00:20:55,840 --> 00:20:59,320
inputs

00:20:57,220 --> 00:21:02,350
that's the really important thing once

00:20:59,320 --> 00:21:05,710
we've got a grammar parsing LR parsing

00:21:02,350 --> 00:21:16,179
ambiguous checks it will work for every

00:21:05,710 --> 00:21:18,880
single input so LR parsing comes with a

00:21:16,179 --> 00:21:21,669
number of optional extras that make

00:21:18,880 --> 00:21:24,850
typical things easier to do in passing

00:21:21,669 --> 00:21:28,390
than you otherwise would so if you are

00:21:24,850 --> 00:21:30,309
writing something that took a list of

00:21:28,390 --> 00:21:32,010
arguments so like a Python function

00:21:30,309 --> 00:21:35,860
taking on an arbitrary list of things

00:21:32,010 --> 00:21:38,500
you can say instead of defining a

00:21:35,860 --> 00:21:43,440
pattern to match an object followed by

00:21:38,500 --> 00:21:46,990
comma followed by a another object and

00:21:43,440 --> 00:21:50,470
possibly having a final comma or not you

00:21:46,990 --> 00:21:55,090
can just use a list so we'll take a list

00:21:50,470 --> 00:21:59,289
of say a list of say expressions will

00:21:55,090 --> 00:22:01,390
delimit them by commas you can have an

00:21:59,289 --> 00:22:03,940
empty list or not you can have a maximum

00:22:01,390 --> 00:22:07,299
number of those lists and the optional

00:22:03,940 --> 00:22:09,669
trailing comma that's not hard to write

00:22:07,299 --> 00:22:11,590
by hand in lr pausing but it's a common

00:22:09,669 --> 00:22:16,030
enough thing that Russell's just put in

00:22:11,590 --> 00:22:18,549
a bit of syntactic sugar for you it's

00:22:16,030 --> 00:22:21,429
common when writing your rules to want

00:22:18,549 --> 00:22:25,780
to write your rules your patterns in

00:22:21,429 --> 00:22:28,570
such a way in your code that you write

00:22:25,780 --> 00:22:31,150
the outermost rules so the rule that

00:22:28,570 --> 00:22:34,929
describes your entire input language up

00:22:31,150 --> 00:22:40,750
the top and then break it down below the

00:22:34,929 --> 00:22:43,000
problem with that is that you often hit

00:22:40,750 --> 00:22:47,970
an issue where you want to use something

00:22:43,000 --> 00:22:50,080
before you've defined it so here

00:22:47,970 --> 00:22:53,460
actually sure that one's right is it

00:22:50,080 --> 00:22:53,460
with the reference

00:22:54,170 --> 00:23:01,970
okay but it's defined it there as well

00:22:57,710 --> 00:23:05,190
all right yes right yet here we're

00:23:01,970 --> 00:23:07,800
defining we're saying that we are going

00:23:05,190 --> 00:23:10,230
to define the rule expression further on

00:23:07,800 --> 00:23:13,710
but for now we're just letting you know

00:23:10,230 --> 00:23:16,110
that it's there so in this call we can

00:23:13,710 --> 00:23:20,220
use expression and then later on we can

00:23:16,110 --> 00:23:22,740
actually define expression so that's

00:23:20,220 --> 00:23:25,680
just that just lets you reorganize the

00:23:22,740 --> 00:23:27,240
patterns in the Python program in a way

00:23:25,680 --> 00:23:29,550
that makes sense when you're defining

00:23:27,240 --> 00:23:33,000
the language doesn't change the grammar

00:23:29,550 --> 00:23:34,800
at all you could move that expression up

00:23:33,000 --> 00:23:37,200
above there and not have that reference

00:23:34,800 --> 00:23:39,870
but it often makes more sense to go from

00:23:37,200 --> 00:23:41,550
the big objects big objects at the top

00:23:39,870 --> 00:23:46,590
of your grammar and the smaller objects

00:23:41,550 --> 00:23:55,970
at the bottom and similarly another bit

00:23:46,590 --> 00:23:58,620
of syntax for repeating symbols and

00:23:55,970 --> 00:24:04,650
there's a couple of couple of rules for

00:23:58,620 --> 00:24:06,150
that so you can have optional symbols so

00:24:04,650 --> 00:24:09,020
you can have this you can have this

00:24:06,150 --> 00:24:12,920
expression or not have this expression

00:24:09,020 --> 00:24:17,880
you can have some of these many of these

00:24:12,920 --> 00:24:20,130
and it's a naming convention for this so

00:24:17,880 --> 00:24:23,370
if you want to say that you can have

00:24:20,130 --> 00:24:29,480
this keyword multiple times you can say

00:24:23,370 --> 00:24:29,480
keyword times and or you can say many

00:24:31,370 --> 00:24:39,480
you can use the Python syntactic sugar

00:24:35,310 --> 00:24:42,480
or you can use a function so if you want

00:24:39,480 --> 00:24:45,900
to say a or b or c you can do that like

00:24:42,480 --> 00:24:53,460
that or use that syntax and similarly

00:24:45,900 --> 00:24:56,370
for this and there's a simple way for

00:24:53,460 --> 00:25:00,030
defining tokens as well where you just

00:24:56,370 --> 00:25:03,600
pass in a string and it will break it up

00:25:00,030 --> 00:25:06,930
on the white space it doesn't change the

00:25:03,600 --> 00:25:14,960
language it's just being it's just a

00:25:06,930 --> 00:25:17,310
sure for doing things slightly easier so

00:25:14,960 --> 00:25:20,180
this is where we start to get into the

00:25:17,310 --> 00:25:22,290
guts of the parse tree and showing you

00:25:20,180 --> 00:25:24,540
parts of the token I'm running a little

00:25:22,290 --> 00:25:26,810
short on time so I'll skip past some of

00:25:24,540 --> 00:25:26,810
that

00:25:32,380 --> 00:25:45,280
so right yes so because it's a Python

00:25:42,000 --> 00:25:47,410
because it's a Python parser it makes it

00:25:45,280 --> 00:25:49,840
easy to pass out comments and white

00:25:47,410 --> 00:25:52,150
space so you can relatively easy pass

00:25:49,840 --> 00:25:55,150
pison with it but it means that if

00:25:52,150 --> 00:25:57,940
you're writing a programming language or

00:25:55,150 --> 00:26:02,080
you're writing a configuration file

00:25:57,940 --> 00:26:04,330
format for it for configuration files

00:26:02,080 --> 00:26:06,160
and you want to add comments LR parsing

00:26:04,330 --> 00:26:08,260
makes it really easy to add comments to

00:26:06,160 --> 00:26:09,730
it and strip them out and so you don't

00:26:08,260 --> 00:26:17,440
have to worry about it in the rest of

00:26:09,730 --> 00:26:22,540
your grammar rules so if you wanted to

00:26:17,440 --> 00:26:26,380
run your calculator you can add options

00:26:22,540 --> 00:26:31,120
to your you can add code to the nodes in

00:26:26,380 --> 00:26:35,310
your tree so for example when you've

00:26:31,120 --> 00:26:43,210
passed the work when you've passed the

00:26:35,310 --> 00:26:47,080
binary you can run the run the code

00:26:43,210 --> 00:26:51,120
associated within its tree and if the

00:26:47,080 --> 00:26:55,630
operator is a plus use operator add and

00:26:51,120 --> 00:26:58,000
divide so you only want to use this on

00:26:55,630 --> 00:27:00,640
small examples like the calculator but

00:26:58,000 --> 00:27:03,490
essentially it's a quick and handy way

00:27:00,640 --> 00:27:07,500
of turning your parser into all turning

00:27:03,490 --> 00:27:10,480
your calculator into an actual program

00:27:07,500 --> 00:27:14,670
error messages are reasonable they're

00:27:10,480 --> 00:27:21,760
not great but they're pretty good so

00:27:14,670 --> 00:27:23,860
here two plus we divided by minus one to

00:27:21,760 --> 00:27:27,400
match by expression state

00:27:23,860 --> 00:27:29,559
so that's the sort of class of error

00:27:27,400 --> 00:27:31,299
message that you'll get and you get all

00:27:29,559 --> 00:27:35,620
the information about exactly where in

00:27:31,299 --> 00:27:37,450
the string that is so you can put up a

00:27:35,620 --> 00:27:46,179
string saying a carrot saying i was

00:27:37,450 --> 00:27:50,080
expecting this in this value it's it is

00:27:46,179 --> 00:27:52,120
quite quick to make a passer so for the

00:27:50,080 --> 00:27:54,190
stuff that i do i make the parser on the

00:27:52,120 --> 00:27:56,110
fly if you've got a large language and

00:27:54,190 --> 00:27:58,809
you want to prove and pilot LR parsing

00:27:56,110 --> 00:28:00,640
supports that so will generate compiled

00:27:58,809 --> 00:28:06,070
Python code and then you can import that

00:28:00,640 --> 00:28:09,040
later at runtime LR parsing is very

00:28:06,070 --> 00:28:12,549
quick as well as being elegant well

00:28:09,040 --> 00:28:15,480
documented and it is also very quick so

00:28:12,549 --> 00:28:18,610
here's some quick comparisons with other

00:28:15,480 --> 00:28:25,169
pausing suites for defining a particular

00:28:18,610 --> 00:28:29,020
grammar and LR parsing is the shortest

00:28:25,169 --> 00:28:30,700
everything else is much much slower LR

00:28:29,020 --> 00:28:32,679
parsing comes with the tokenizer built

00:28:30,700 --> 00:28:34,480
in all these other ones you've got to do

00:28:32,679 --> 00:28:36,429
the tokenization yourself as a separate

00:28:34,480 --> 00:28:41,770
step and we have copious amounts of

00:28:36,429 --> 00:28:45,940
documentation so that's the information

00:28:41,770 --> 00:28:50,679
for the talk and hopefully I'll be able

00:28:45,940 --> 00:28:52,330
to pull up documentation and what

00:28:50,679 --> 00:28:56,230
Russell is basically done here is

00:28:52,330 --> 00:28:58,990
written a book about pausing and as

00:28:56,230 --> 00:29:01,330
footnotes on each page it's here's how

00:28:58,990 --> 00:29:05,590
you do this standard pausing task in LR

00:29:01,330 --> 00:29:10,419
parsing so this is the very extensive

00:29:05,590 --> 00:29:13,080
documentation for LR parsing it is it is

00:29:10,419 --> 00:29:16,690
basically a little mini book on pausing

00:29:13,080 --> 00:29:20,770
and there are some really good examples

00:29:16,690 --> 00:29:25,740
that come with LR parsing he's got an

00:29:20,770 --> 00:29:31,530
example of where his parsing SQL and

00:29:25,740 --> 00:29:35,950
he's using the SQL Lite test suite too

00:29:31,530 --> 00:29:36,780
so all of the SQL Lite test suite he

00:29:35,950 --> 00:29:40,830
runs that through

00:29:36,780 --> 00:29:43,530
partha and what's the one that you he's

00:29:40,830 --> 00:29:49,710
also got who could also got in one of

00:29:43,530 --> 00:29:52,860
his examples pausing Lua and translating

00:29:49,710 --> 00:29:57,960
that to Python so that's a fairly

00:29:52,860 --> 00:30:04,500
extensive example that is got which

00:29:57,960 --> 00:30:06,270
works yes no it works lures are much

00:30:04,500 --> 00:30:07,530
simpler language than Python so it's

00:30:06,270 --> 00:30:08,760
much easier to go from one way to the

00:30:07,530 --> 00:30:12,120
other if it was going from Python to

00:30:08,760 --> 00:30:15,900
lure that'll be a little bit more fun so

00:30:12,120 --> 00:30:18,990
in short LR parsing is a wonderful

00:30:15,900 --> 00:30:20,760
Python project for doing pausing so if

00:30:18,990 --> 00:30:22,080
you're bumping up against something and

00:30:20,760 --> 00:30:24,090
you're trying to pass it with regular

00:30:22,080 --> 00:30:26,190
expressions and it's too hard have a

00:30:24,090 --> 00:30:29,040
look at LR parsing it's the pythonic

00:30:26,190 --> 00:30:31,590
solution for parsing it's fast it's easy

00:30:29,040 --> 00:30:41,600
it's very well documented thank you very

00:30:31,590 --> 00:30:41,600
much thank you Clinton and Russell

00:30:41,639 --> 00:30:48,149
I don't have any questions yeah come on

00:30:44,459 --> 00:30:52,649
up come on down um Russell you should

00:30:48,149 --> 00:31:04,709
probably answer questions thanks for a

00:30:52,649 --> 00:31:09,169
great talk I take on an are pausing in

00:31:04,709 --> 00:31:13,379
terms of how they actually catch

00:31:09,169 --> 00:31:17,329
productions to to my my apology so I

00:31:13,379 --> 00:31:20,279
have my deposit weekends I have certain

00:31:17,329 --> 00:31:22,349
productions for different routes and I

00:31:20,279 --> 00:31:25,169
will actually want to go and apply this

00:31:22,349 --> 00:31:29,549
pausing feed to the paddock productions

00:31:25,169 --> 00:31:31,499
based on my possibly so if I understand

00:31:29,549 --> 00:31:33,539
the question correctly what you're

00:31:31,499 --> 00:31:35,909
asking is I've got my passing trio now I

00:31:33,539 --> 00:31:38,700
want to use it to generate some code or

00:31:35,909 --> 00:31:40,979
do something like that yeah you saw a

00:31:38,700 --> 00:31:44,159
simple example with the arithmetic one

00:31:40,979 --> 00:31:47,579
but only works for simple there is

00:31:44,159 --> 00:31:53,429
another example which I use with lua

00:31:47,579 --> 00:31:55,649
which you set up a parallel tree you

00:31:53,429 --> 00:31:59,609
define the same symbol names in the tree

00:31:55,649 --> 00:32:03,419
and what happens in is in that class

00:31:59,609 --> 00:32:08,429
they get called so as soon as the paths

00:32:03,419 --> 00:32:11,099
that recognizes a unity expert it calls

00:32:08,429 --> 00:32:13,320
your function passing it whatever you've

00:32:11,099 --> 00:32:17,339
generated so far and then you turn it

00:32:13,320 --> 00:32:18,809
into code it's a it there's a bit of

00:32:17,339 --> 00:32:21,149
boilerplate you've got to do to get

00:32:18,809 --> 00:32:24,229
going but once you've done that this is

00:32:21,149 --> 00:32:24,229
the technique are useful lure

00:32:25,330 --> 00:32:33,050
so the aspect of LR parsing that I would

00:32:29,330 --> 00:32:36,080
like to improve is to generate a sts and

00:32:33,050 --> 00:32:38,480
I've got some code that generates a sts

00:32:36,080 --> 00:32:41,000
using the Python AST classes and then

00:32:38,480 --> 00:32:44,840
you can use the same asd war functions

00:32:41,000 --> 00:32:46,520
that the python is here uses I don't

00:32:44,840 --> 00:32:49,520
have a nice generic solution for that

00:32:46,520 --> 00:32:51,530
I've got a st generation for specific

00:32:49,520 --> 00:32:56,960
classes and types of languages but not

00:32:51,530 --> 00:32:59,000
for everything at this point in time hi

00:32:56,960 --> 00:33:01,940
thanks for the talk I just have one

00:32:59,000 --> 00:33:03,730
probably annoying question but I see a

00:33:01,940 --> 00:33:07,160
lot of print statements without brackets

00:33:03,730 --> 00:33:10,550
does it support Python 3 same code works

00:33:07,160 --> 00:33:13,490
both Python to python 3 the examples you

00:33:10,550 --> 00:33:15,590
saw there because the slides were done

00:33:13,490 --> 00:33:20,330
in Python 2 but it's completely

00:33:15,590 --> 00:33:24,980
compatible with both there is full code

00:33:20,330 --> 00:33:26,960
coverage for all of the code in both

00:33:24,980 --> 00:33:30,470
Python 2 & 3 you run the test suite all

00:33:26,960 --> 00:33:32,510
the code is tested ok so no further

00:33:30,470 --> 00:33:35,140
questions all right well let's show our

00:33:32,510 --> 00:33:38,140
rowdy side once more for Clinton and

00:33:35,140 --> 00:33:38,140
Russell

00:33:39,110 --> 00:33:41,170
you

00:33:48,370 --> 00:33:50,430

YouTube URL: https://www.youtube.com/watch?v=9PQsCmOeYwU


