Title: Unicode and Python: the absolute minimum you need to know
Publication date: 2018-08-26
Playlist: PyCon Australia 2018
Description: 
	Raphaël Merx

https://2018.pycon-au.org/talks/44562-unicode-and-python-the-absolute-minimum-you-need-to-know/

Born from parents who don't mind string encoding, my name has an "ë". How can your code handle that character? How does Unicode handle it? If you see "ë" in a stack trace, does that mean your encoding is broken?

Ignoring unicode often backfires. This talk is about preventing Unicode burns.

Python, PyCon, PyConAU, australia, programming, sydney

This video is licensed under CC BY 3.0 AU - https://creativecommons.org/licenses/by/3.0/au/

PyCon Australia (“PyCon AU”) is the national conference for the Python Programming Community, bringing together professional, student and enthusiast developers with a love for developing with Python.

PyCon AU, the national Python Language conference, is on again this August in Sydney, at the International Convention Centre, Sydney, August 24 - 28 2018.

Python, PyCon, PyConAU
Captions: 
	00:00:01,220 --> 00:00:08,099
okay welcome everyone to the last

00:00:04,290 --> 00:00:11,280
session of this bracket before we break

00:00:08,099 --> 00:00:13,920
for our afternoon tea we are now going

00:00:11,280 --> 00:00:17,460
to hear from Raphael about Unicode which

00:00:13,920 --> 00:00:30,810
often mystifies but hopefully will be no

00:00:17,460 --> 00:00:32,759
longer welcome Raphael but then yeah so

00:00:30,810 --> 00:00:35,329
hello everyone my name is Raphael and

00:00:32,759 --> 00:00:39,750
today we're gonna talk about unicode and

00:00:35,329 --> 00:00:40,290
python support for Unicode so I come

00:00:39,750 --> 00:00:43,829
from France

00:00:40,290 --> 00:00:45,960
and so it turns out my name has unicode

00:00:43,829 --> 00:00:48,629
inside of it which makes me very aware

00:00:45,960 --> 00:00:51,420
of the problems of unicode I was

00:00:48,629 --> 00:00:53,870
actually born like two months after the

00:00:51,420 --> 00:00:56,910
Unicode consortium was first formed and

00:00:53,870 --> 00:00:59,070
I like to believe that my parents seeing

00:00:56,910 --> 00:01:00,660
that you know finally something was

00:00:59,070 --> 00:01:03,570
being done about standardization for

00:01:00,660 --> 00:01:08,430
Unicode strings chose to just put an

00:01:03,570 --> 00:01:09,930
umlaut in my name I think maybe at first

00:01:08,430 --> 00:01:12,210
they were gonna kill me like Murphy or

00:01:09,930 --> 00:01:13,049
Donald but then they were like no this

00:01:12,210 --> 00:01:17,009
is not possible

00:01:13,049 --> 00:01:18,360
this is not us and so and so yeah they

00:01:17,009 --> 00:01:19,979
went with Raphael and they were very

00:01:18,360 --> 00:01:22,350
hopeful that you know this would be

00:01:19,979 --> 00:01:23,009
solved and yet several decades later

00:01:22,350 --> 00:01:26,400
here we are

00:01:23,009 --> 00:01:28,259
I still receive emails that look like

00:01:26,400 --> 00:01:31,979
this and so this talk is gonna be a lot

00:01:28,259 --> 00:01:33,750
about how you can prevent people like me

00:01:31,979 --> 00:01:36,150
from receiving emails coming from your

00:01:33,750 --> 00:01:41,670
server that look like that

00:01:36,150 --> 00:01:44,070
I at first I guess I'm from France I

00:01:41,670 --> 00:01:47,040
moved to the US and I was using Python 2

00:01:44,070 --> 00:01:49,350
at the time and so I didn't really care

00:01:47,040 --> 00:01:51,420
about all this I chose to just strip the

00:01:49,350 --> 00:01:54,960
umlaut out I was just spelling my name

00:01:51,420 --> 00:01:56,909
in pure ASCII and as far as I was

00:01:54,960 --> 00:01:58,950
concerned strings were ASCII and they

00:01:56,909 --> 00:02:01,979
were easily incredible 2 bytes and that

00:01:58,950 --> 00:02:04,619
was it but then two years ago I moved to

00:02:01,979 --> 00:02:06,450
Timor Leste you also call it East Timor

00:02:04,619 --> 00:02:09,330
so an hour and a half north of Darwin

00:02:06,450 --> 00:02:11,849
and this is where I work now for an NGO

00:02:09,330 --> 00:02:12,300
called catalpa you know I really like my

00:02:11,849 --> 00:02:13,800
job

00:02:12,300 --> 00:02:16,350
please come talk to me if your

00:02:13,800 --> 00:02:18,270
curious are interested but yeah the

00:02:16,350 --> 00:02:21,390
national language of East Timor is stay

00:02:18,270 --> 00:02:22,770
tuned and tetouan has accents on some of

00:02:21,390 --> 00:02:25,980
the letters so I can't ignore this

00:02:22,770 --> 00:02:26,700
problem anymore so let's start at the

00:02:25,980 --> 00:02:30,030
beginning

00:02:26,700 --> 00:02:32,790
what is Unicode so Unicode associates a

00:02:30,030 --> 00:02:35,340
good point with each character and that

00:02:32,790 --> 00:02:37,830
good point is a number so for example

00:02:35,340 --> 00:02:42,600
the letter e is associated with number

00:02:37,830 --> 00:02:45,330
101 and Unicode strives to support any

00:02:42,600 --> 00:02:47,010
of the world's writing systems so any of

00:02:45,330 --> 00:02:49,440
the characters that can be used in any

00:02:47,010 --> 00:02:51,840
language is supposed to have a code

00:02:49,440 --> 00:02:55,650
point associated with it and Unicode is

00:02:51,840 --> 00:02:57,960
constantly releasing new versions for

00:02:55,650 --> 00:03:00,870
example Unicode 11 was released in June

00:02:57,960 --> 00:03:03,210
this year they added support for Mecca

00:03:00,870 --> 00:03:06,000
saris which is a language spoken in the

00:03:03,210 --> 00:03:08,280
island of Sulawesi in Indonesia they

00:03:06,000 --> 00:03:10,950
also added like the kangaroo emoji or

00:03:08,280 --> 00:03:13,830
they added an emoji for a mosquito to

00:03:10,950 --> 00:03:15,000
like raise the awareness of you know the

00:03:13,830 --> 00:03:17,820
health hazards associated with

00:03:15,000 --> 00:03:21,510
mosquitoes and so when you're iterating

00:03:17,820 --> 00:03:25,770
over a string in Python 3 you are really

00:03:21,510 --> 00:03:27,690
just iterating over good points so the

00:03:25,770 --> 00:03:30,450
snake emoji has another code points it's

00:03:27,690 --> 00:03:33,330
a little longer than the e but it's just

00:03:30,450 --> 00:03:34,739
a good points of its own itself and I'm

00:03:33,330 --> 00:03:37,080
gonna pause here for a minute and

00:03:34,739 --> 00:03:38,760
mention that I'm simplifying the problem

00:03:37,080 --> 00:03:41,850
a little bit by saying that one

00:03:38,760 --> 00:03:44,520
character equals one code point that's

00:03:41,850 --> 00:03:47,100
not always true and one place where

00:03:44,520 --> 00:03:49,020
you've seen these characters that

00:03:47,100 --> 00:03:50,820
contain multiple code points is with

00:03:49,020 --> 00:03:54,810
skin color emojis

00:03:50,820 --> 00:03:58,140
so if Unicode was to associate one code

00:03:54,810 --> 00:04:00,930
point per emoji per skin color it would

00:03:58,140 --> 00:04:03,930
use a lot of code points for all of the

00:04:00,930 --> 00:04:05,670
emojis so what it does instead is if you

00:04:03,930 --> 00:04:09,720
want like a fair-skinned baby emoji or

00:04:05,670 --> 00:04:13,050
dark skinned baby emoji is you have what

00:04:09,720 --> 00:04:14,730
is called a combining character which is

00:04:13,050 --> 00:04:17,010
associated with a base character and so

00:04:14,730 --> 00:04:19,049
the combining character would be light

00:04:17,010 --> 00:04:20,370
skin color or dark skin color and then

00:04:19,049 --> 00:04:22,650
the base character will be the baby

00:04:20,370 --> 00:04:24,990
emoji and you will see the association

00:04:22,650 --> 00:04:27,750
of the two but actually in Python if you

00:04:24,990 --> 00:04:30,720
were to call for example n on the

00:04:27,750 --> 00:04:32,670
fair skinned emoji baby it would return

00:04:30,720 --> 00:04:35,100
to because this is using two code points

00:04:32,670 --> 00:04:39,270
and as far as python is concerned this

00:04:35,100 --> 00:04:42,170
is this is just about code points and

00:04:39,270 --> 00:04:46,440
python has some utilities for supporting

00:04:42,170 --> 00:04:50,970
unicode so you can import the flip

00:04:46,440 --> 00:04:55,830
operator or no you can you do there's

00:04:50,970 --> 00:04:59,000
the old and the car functions so the old

00:04:55,830 --> 00:05:01,320
function you pass it a character and it

00:04:59,000 --> 00:05:04,740
returns the code point associated with

00:05:01,320 --> 00:05:06,720
that character the car function you it's

00:05:04,740 --> 00:05:09,150
exactly the inverse so you pass it a

00:05:06,720 --> 00:05:10,440
code point and then it returns the

00:05:09,150 --> 00:05:15,120
character associated with that code

00:05:10,440 --> 00:05:16,740
point okay so so far everything I've

00:05:15,120 --> 00:05:18,900
been talking about so far is not

00:05:16,740 --> 00:05:20,550
necessarily related to bytes I'm just

00:05:18,900 --> 00:05:23,160
saying this is a number it's associated

00:05:20,550 --> 00:05:25,560
with a character and so when you want to

00:05:23,160 --> 00:05:27,270
convert a string to binary because this

00:05:25,560 --> 00:05:30,150
is the whole problem right when you send

00:05:27,270 --> 00:05:31,740
a request over the network you're

00:05:30,150 --> 00:05:32,970
sending bytes or when you're storing

00:05:31,740 --> 00:05:34,979
things on your computer you're also

00:05:32,970 --> 00:05:38,729
storing bytes so the problem is how do

00:05:34,979 --> 00:05:40,350
we represent strings as bytes and I

00:05:38,729 --> 00:05:42,510
guess the most natural thing to say is

00:05:40,350 --> 00:05:43,919
well here you've got a number this is a

00:05:42,510 --> 00:05:46,770
number isn't base 10 but you could just

00:05:43,919 --> 00:05:50,400
represent that number in hexadecimal or

00:05:46,770 --> 00:05:52,740
just in in binary and 101 in base ten

00:05:50,400 --> 00:05:54,120
equals six five in hexadecimal so there

00:05:52,740 --> 00:05:55,640
you go you've got your bytes and then

00:05:54,120 --> 00:05:58,590
you can just send this over the way and

00:05:55,640 --> 00:05:59,040
this is exactly what happens for ASCII

00:05:58,590 --> 00:06:02,850
encoding

00:05:59,040 --> 00:06:04,740
so all of the ASCII letters when you

00:06:02,850 --> 00:06:07,800
encode them they're just purely

00:06:04,740 --> 00:06:09,540
converting the code points to the binary

00:06:07,800 --> 00:06:11,790
representation it's actually more like

00:06:09,540 --> 00:06:13,590
in Reverse like unicode when they

00:06:11,790 --> 00:06:16,440
created the standard try to make it

00:06:13,590 --> 00:06:18,510
compatible with ascii and so unicode

00:06:16,440 --> 00:06:21,210
chose the right code point so that all

00:06:18,510 --> 00:06:24,510
of those would be exactly the related

00:06:21,210 --> 00:06:26,520
ask you bytes and but then the problem

00:06:24,510 --> 00:06:29,070
becomes okay can we just extend that

00:06:26,520 --> 00:06:31,860
behavior for any code point right so our

00:06:29,070 --> 00:06:34,860
snake emoji it also has a good point

00:06:31,860 --> 00:06:37,500
and you can convert that code point to

00:06:34,860 --> 00:06:39,510
binary I get you would need like three

00:06:37,500 --> 00:06:41,220
bytes but then most memory addresses

00:06:39,510 --> 00:06:43,230
don't work well with three bytes

00:06:41,220 --> 00:06:48,150
so you can go okay well we'll use four

00:06:43,230 --> 00:06:51,030
bytes and actually unicode total has 1.1

00:06:48,150 --> 00:06:52,560
million code points only like twelve

00:06:51,030 --> 00:06:55,710
percent of those are allocated but

00:06:52,560 --> 00:06:57,900
eventually you should try to support 1.1

00:06:55,710 --> 00:07:00,210
million and so four bytes is enough to

00:06:57,900 --> 00:07:03,540
represent that and what I'm describing

00:07:00,210 --> 00:07:06,060
here is exactly what utf-32 does which

00:07:03,540 --> 00:07:08,520
say they basically say okay like one

00:07:06,060 --> 00:07:10,230
character four bytes and then it doesn't

00:07:08,520 --> 00:07:12,690
matter if you only needed one byte per

00:07:10,230 --> 00:07:15,420
character we're just not going to care

00:07:12,690 --> 00:07:18,330
too much about space but there's

00:07:15,420 --> 00:07:20,910
problems related to this in particular

00:07:18,330 --> 00:07:23,520
like if you're sending English text over

00:07:20,910 --> 00:07:26,910
the wire you're only using one-fourth of

00:07:23,520 --> 00:07:28,860
the bytes that you're sending and this

00:07:26,910 --> 00:07:31,440
brings me to the fact that you should

00:07:28,860 --> 00:07:34,110
try to use utf-8 as much as possible

00:07:31,440 --> 00:07:35,669
because it does something that I'm not

00:07:34,110 --> 00:07:37,290
going to go into the detail of this but

00:07:35,669 --> 00:07:40,400
it does something more complicated than

00:07:37,290 --> 00:07:44,010
utf-8 to convert these code points in

00:07:40,400 --> 00:07:45,330
binary format and in particular it's

00:07:44,010 --> 00:07:47,370
going to be compatible with ASCII

00:07:45,330 --> 00:07:50,340
meaning if you're just sending English

00:07:47,370 --> 00:07:51,810
text the ASCII the binary ASCII

00:07:50,340 --> 00:07:54,090
representation of that text is going to

00:07:51,810 --> 00:07:56,729
be the same as the utf-8 representation

00:07:54,090 --> 00:07:59,880
of that text it tries to be efficient

00:07:56,729 --> 00:08:02,100
like if a certain code point is low it

00:07:59,880 --> 00:08:03,990
doesn't use too many bytes but if a good

00:08:02,100 --> 00:08:07,919
point is high then it will use a lot of

00:08:03,990 --> 00:08:09,690
bytes and it doesn't have any embedded 0

00:08:07,919 --> 00:08:11,850
bytes in in the slide I've been showing

00:08:09,690 --> 00:08:13,830
you before there were a bunch of 0 bytes

00:08:11,850 --> 00:08:15,540
and some C functions will interpret

00:08:13,830 --> 00:08:21,090
these 0 bytes as the end of the string

00:08:15,540 --> 00:08:23,040
and so utf-8 doesn't do that so if you

00:08:21,090 --> 00:08:26,460
have a null byte in utf-8 it can only

00:08:23,040 --> 00:08:27,840
represent the null by itself so this is

00:08:26,460 --> 00:08:29,580
my first rule for you today

00:08:27,840 --> 00:08:31,680
you should try as much as possible to

00:08:29,580 --> 00:08:33,839
use utf-8 when you send when your server

00:08:31,680 --> 00:08:37,140
is sending responses or when it's

00:08:33,839 --> 00:08:39,690
writing to a file these these bytes that

00:08:37,140 --> 00:08:44,030
go out of your program should be text

00:08:39,690 --> 00:08:46,700
encoded using utf-8 and the Internet is

00:08:44,030 --> 00:08:51,930
pretty much converging towards using

00:08:46,700 --> 00:08:54,690
purely utf-8 and Python itself by

00:08:51,930 --> 00:08:56,730
default uses utf-8 so when you pass

00:08:54,690 --> 00:08:59,220
string when you call the encode method

00:08:56,730 --> 00:09:02,340
on a string with without giving an

00:08:59,220 --> 00:09:04,620
argument to that method this will return

00:09:02,340 --> 00:09:08,250
the bytes that are the utf-8

00:09:04,620 --> 00:09:10,080
representation for that string but you

00:09:08,250 --> 00:09:11,880
can pass a different character encoding

00:09:10,080 --> 00:09:14,130
to that method for example you can pass

00:09:11,880 --> 00:09:16,260
at latin-1 and then that will give you

00:09:14,130 --> 00:09:16,850
the bytes for this string encoded to

00:09:16,260 --> 00:09:20,250
latin-1

00:09:16,850 --> 00:09:22,820
and i think there's something pretty

00:09:20,250 --> 00:09:25,530
interesting here because we can see that

00:09:22,820 --> 00:09:27,780
the e with an umlaut is taking one byte

00:09:25,530 --> 00:09:31,800
in Latin one but it's taking two bytes

00:09:27,780 --> 00:09:34,440
in utf-8 and in the email I've been

00:09:31,800 --> 00:09:37,320
showing you in the beginning that letter

00:09:34,440 --> 00:09:40,320
was ended up somehow being too weird

00:09:37,320 --> 00:09:44,340
characters instead of one and so indeed

00:09:40,320 --> 00:09:45,870
if we try to encode this e to utf-8 and

00:09:44,340 --> 00:09:47,970
then decode it to Latin one we get

00:09:45,870 --> 00:09:53,220
exactly the letters that were in this

00:09:47,970 --> 00:09:54,780
email and and this right here the reason

00:09:53,220 --> 00:09:56,580
why there's only this letter that is

00:09:54,780 --> 00:09:59,760
causing problems is not because only

00:09:56,580 --> 00:10:02,460
this letter was somehow mismatched it's

00:09:59,760 --> 00:10:05,430
because the person that sent that email

00:10:02,460 --> 00:10:07,410
encoded all of it to utf-8 somehow my

00:10:05,430 --> 00:10:10,320
email client is trying to decode all of

00:10:07,410 --> 00:10:13,500
it using Latin 1 but because utf-8 and

00:10:10,320 --> 00:10:15,690
Latin 1 are both compatible with ASCII

00:10:13,500 --> 00:10:18,390
any of the ASCII letters that were sent

00:10:15,690 --> 00:10:21,420
are just reappearing as they were sent

00:10:18,390 --> 00:10:22,950
but any known as key letters will not go

00:10:21,420 --> 00:10:26,190
through properly so if this whole email

00:10:22,950 --> 00:10:30,330
was in Chinese probably like very little

00:10:26,190 --> 00:10:33,570
letters would go through so it's just I

00:10:30,330 --> 00:10:35,820
guess a convenience of Unicode that it

00:10:33,570 --> 00:10:37,380
will work well with that a lot of

00:10:35,820 --> 00:10:42,510
character encodings will work well with

00:10:37,380 --> 00:10:44,730
ASCII so this is my sis be to my second

00:10:42,510 --> 00:10:46,170
rule for you today is don't infer the

00:10:44,730 --> 00:10:48,240
string encoding if you have a match of

00:10:46,170 --> 00:10:51,900
bytes and you want to convert these

00:10:48,240 --> 00:10:53,670
bytes to a string you need to find what

00:10:51,900 --> 00:10:56,310
character encoding was used for these

00:10:53,670 --> 00:10:58,440
bytes and you cannot just assume that

00:10:56,310 --> 00:11:06,630
this is utf-8 by calling the decode

00:10:58,440 --> 00:11:08,430
method and for most cases trying to find

00:11:06,630 --> 00:11:10,980
out what what is the string good

00:11:08,430 --> 00:11:13,050
we will mean read the headers so for

00:11:10,980 --> 00:11:15,600
HTTP headers you have the content type

00:11:13,050 --> 00:11:18,270
header that has a car set section and

00:11:15,600 --> 00:11:20,610
that will tell you the string encoding

00:11:18,270 --> 00:11:23,339
that was used to put the body of that

00:11:20,610 --> 00:11:26,970
request into bytes if that body

00:11:23,339 --> 00:11:30,060
represents text you in HTML in the HTML

00:11:26,970 --> 00:11:31,740
5 you have this meta tag that is

00:11:30,060 --> 00:11:36,029
supposed to tell you the character

00:11:31,740 --> 00:11:38,700
encoding for all of the HTML but if

00:11:36,029 --> 00:11:40,350
you're following here this is weird

00:11:38,700 --> 00:11:42,510
isn't it because I'm basically tell you

00:11:40,350 --> 00:11:45,649
I'm basically telling you okay read the

00:11:42,510 --> 00:11:49,680
text to find out what encoding was used

00:11:45,649 --> 00:11:51,209
to like encode this very text but it's

00:11:49,680 --> 00:11:53,520
like wait I mean I'm getting a bunch of

00:11:51,209 --> 00:11:55,320
bytes coming through and I cannot read

00:11:53,520 --> 00:11:57,360
the text containing these bytes and

00:11:55,320 --> 00:12:00,510
unless I know the encoding that was used

00:11:57,360 --> 00:12:02,370
to generate this bytes right and so the

00:12:00,510 --> 00:12:05,250
way a lot of browsers work is that

00:12:02,370 --> 00:12:07,830
they'll maybe assume that this is utf-8

00:12:05,250 --> 00:12:09,930
and start reading new HTML and when they

00:12:07,830 --> 00:12:11,490
run into this tag they're like up maybe

00:12:09,930 --> 00:12:13,620
if this text says Latino and they're

00:12:11,490 --> 00:12:15,000
like oh actually the encoding is

00:12:13,620 --> 00:12:17,790
different than the one we thought it was

00:12:15,000 --> 00:12:21,060
so we'll just start over and try to

00:12:17,790 --> 00:12:23,760
decipher using Latin one in particular

00:12:21,060 --> 00:12:26,070
this is a problem we've had in one of

00:12:23,760 --> 00:12:27,990
our mobile apps because it's a hybrid

00:12:26,070 --> 00:12:30,420
app meaning it's actually a web view

00:12:27,990 --> 00:12:32,250
that's rendering HTML files that are on

00:12:30,420 --> 00:12:33,420
the phones file system and because

00:12:32,250 --> 00:12:36,180
they're on the file system there is no

00:12:33,420 --> 00:12:38,790
HTTP header and so when we included some

00:12:36,180 --> 00:12:42,779
JavaScript files that themselves were

00:12:38,790 --> 00:12:45,870
encoded using utf-8 somehow the browser

00:12:42,779 --> 00:12:48,300
thought that the whole app was in Latin

00:12:45,870 --> 00:12:49,890
one and so the JavaScript when we were

00:12:48,300 --> 00:12:52,890
including this JavaScript inside of the

00:12:49,890 --> 00:12:55,200
HTML it didn't appear properly and when

00:12:52,890 --> 00:12:58,850
we put this tag inside of the like index

00:12:55,200 --> 00:12:58,850
that HTML everything went back to order

00:12:59,310 --> 00:13:06,140
I think in many cases when you're using

00:13:03,450 --> 00:13:09,240
some reasonably high level libraries

00:13:06,140 --> 00:13:11,940
they do this for you so reading the

00:13:09,240 --> 00:13:15,000
string encoding and trying to convert

00:13:11,940 --> 00:13:17,430
bytes to string using the actual string

00:13:15,000 --> 00:13:20,520
encoding that was used is given to you

00:13:17,430 --> 00:13:22,320
and so when projects are migrated from

00:13:20,520 --> 00:13:24,839
Python to to Python 3

00:13:22,320 --> 00:13:27,449
something I've seen a lot is so you know

00:13:24,839 --> 00:13:29,490
it raises an error because now Python 3

00:13:27,449 --> 00:13:31,709
is not implicitly converting bytes to

00:13:29,490 --> 00:13:33,630
string you have to do this yourself and

00:13:31,709 --> 00:13:36,449
then people look like ah I'm just gonna

00:13:33,630 --> 00:13:39,569
try encode knows it decode ok decode and

00:13:36,449 --> 00:13:42,209
there we go now we got the string but by

00:13:39,569 --> 00:13:44,880
saying this this means you know these

00:13:42,209 --> 00:13:46,470
bytes were encoded using utf-8 and in

00:13:44,880 --> 00:13:47,910
most cases you don't know and especially

00:13:46,470 --> 00:13:49,800
if these bytes are coming from some user

00:13:47,910 --> 00:13:51,930
you don't know that the user is using

00:13:49,800 --> 00:13:54,569
utf-8 to send you a bunch of bytes and

00:13:51,930 --> 00:13:58,500
so the request library gives you this

00:13:54,569 --> 00:14:01,380
nice little text property and what this

00:13:58,500 --> 00:14:04,350
text probably does in the background is

00:14:01,380 --> 00:14:06,899
that it will try to find out the string

00:14:04,350 --> 00:14:09,680
encoding using the headers and if there

00:14:06,899 --> 00:14:12,810
is no such header and will try to guess

00:14:09,680 --> 00:14:16,639
and indeed there's many cases where

00:14:12,810 --> 00:14:18,779
you'll have to guess encoding I guess

00:14:16,639 --> 00:14:20,519
optimally you would always have some

00:14:18,779 --> 00:14:22,290
kind of header that specifies what

00:14:20,519 --> 00:14:24,959
encoding was used to generate a bunch of

00:14:22,290 --> 00:14:27,810
bytes but there are cases where maybe

00:14:24,959 --> 00:14:29,190
the header that the HTTP requests that

00:14:27,810 --> 00:14:31,350
people are sending to you doesn't have

00:14:29,190 --> 00:14:33,540
headers specifying the string encoding

00:14:31,350 --> 00:14:35,370
or when you're reading from a CSV file

00:14:33,540 --> 00:14:37,529
as far as I'm aware there is no header

00:14:35,370 --> 00:14:41,370
in CSV that lets you say okay this is

00:14:37,529 --> 00:14:42,750
the the encoding that was used or or

00:14:41,370 --> 00:14:44,279
maybe when you're naming a child there's

00:14:42,750 --> 00:14:46,170
no way to go to the City Council and be

00:14:44,279 --> 00:14:51,810
like oh this child's name is like meta

00:14:46,170 --> 00:14:53,940
car set utf-8 choleric so for cases like

00:14:51,810 --> 00:14:58,589
this there's a library in Python called

00:14:53,940 --> 00:15:00,660
car debt and it just detects the most

00:14:58,589 --> 00:15:02,250
likely string encoding that was used to

00:15:00,660 --> 00:15:05,519
generate a bunch of bytes and actually

00:15:02,250 --> 00:15:07,380
in the previous slide response that text

00:15:05,519 --> 00:15:09,839
the text properly what it's doing to

00:15:07,380 --> 00:15:12,269
guess the string encoding that was used

00:15:09,839 --> 00:15:14,040
for a bunch of bytes is they use car

00:15:12,269 --> 00:15:19,410
debt and so they take just like the

00:15:14,040 --> 00:15:21,600
highest likelihood encoding there is a

00:15:19,410 --> 00:15:24,480
lot of moving parts to all of this and I

00:15:21,600 --> 00:15:25,829
think you can only be reasonably

00:15:24,480 --> 00:15:27,689
confident that your program is going to

00:15:25,829 --> 00:15:31,589
work well with Unicode if you test using

00:15:27,689 --> 00:15:34,260
Unicode and this can be really simple

00:15:31,589 --> 00:15:35,880
like maybe inside of your test instead

00:15:34,260 --> 00:15:37,350
of using foo bar you use

00:15:35,880 --> 00:15:39,420
some Chinese characters or you use some

00:15:37,350 --> 00:15:40,890
emojis and then you make sure that you

00:15:39,420 --> 00:15:42,710
know things are coming through correctly

00:15:40,890 --> 00:15:45,660
or at least that noise are being raised

00:15:42,710 --> 00:15:47,940
so yeah you just try testing using known

00:15:45,660 --> 00:15:50,070
as key strings I think it's also

00:15:47,940 --> 00:15:51,930
important to test what happens when

00:15:50,070 --> 00:15:54,420
someone sends you a request that is not

00:15:51,930 --> 00:15:56,850
encoded using utf-8 it's especially true

00:15:54,420 --> 00:15:58,590
in Python because python just assumes

00:15:56,850 --> 00:16:02,850
utf-8 if you're not passing the right

00:15:58,590 --> 00:16:04,440
arguments to encode and decode and at

00:16:02,850 --> 00:16:06,840
the very least so you could say you know

00:16:04,440 --> 00:16:09,060
well if people are like not encoding

00:16:06,840 --> 00:16:11,010
using utf-8 and also not sending us

00:16:09,060 --> 00:16:12,390
their string encoding like I'm not going

00:16:11,010 --> 00:16:16,560
to support this right this is such a

00:16:12,390 --> 00:16:19,740
niche behavior but at least you want to

00:16:16,560 --> 00:16:21,660
make sure that the bytes these bytes

00:16:19,740 --> 00:16:23,490
will not raise an error because if

00:16:21,660 --> 00:16:26,270
people just send you a bunch of bytes

00:16:23,490 --> 00:16:29,270
and you try to decode them using utf-8

00:16:26,270 --> 00:16:29,270
utf-16

00:16:32,820 --> 00:16:40,590
maybe at least they should return a 400

00:16:34,950 --> 00:16:44,130
response and one way to do this would be

00:16:40,590 --> 00:16:49,040
to basically do a soft unicode decoder

00:16:44,130 --> 00:16:53,010
so the the default behavior in python is

00:16:49,040 --> 00:16:55,200
you if you try to decode some bytes that

00:16:53,010 --> 00:16:57,840
cannot be decoded using that specific

00:16:55,200 --> 00:17:00,870
that specific string encoding it raises

00:16:57,840 --> 00:17:03,000
a unicode decoder but actually decode as

00:17:00,870 --> 00:17:04,620
a second argument you can pass in the

00:17:03,000 --> 00:17:06,810
behavior then it should have when there

00:17:04,620 --> 00:17:10,709
are errors like this and so the default

00:17:06,810 --> 00:17:13,290
behavior is string strict mode but you

00:17:10,709 --> 00:17:15,120
can set that default behavior to be for

00:17:13,290 --> 00:17:17,430
example replace instead and what this is

00:17:15,120 --> 00:17:19,500
going to do is that it's going to put

00:17:17,430 --> 00:17:21,900
this little question mark instead of a

00:17:19,500 --> 00:17:23,970
square that is the Unicode replacement

00:17:21,900 --> 00:17:27,030
character and that this is not here

00:17:23,970 --> 00:17:28,980
because eight zero somehow maps to the

00:17:27,030 --> 00:17:31,950
code point for this character this is

00:17:28,980 --> 00:17:33,780
here because your decoder is saying I

00:17:31,950 --> 00:17:36,000
don't know what these bytes are so I'm

00:17:33,780 --> 00:17:39,720
just going to replace them with this

00:17:36,000 --> 00:17:41,610
character this is a nice character he

00:17:39,720 --> 00:17:43,320
used by the way if you think like your

00:17:41,610 --> 00:17:45,180
competitors are being a little too fast

00:17:43,320 --> 00:17:46,980
at building features like you just open

00:17:45,180 --> 00:17:48,520
their forms and enter a bunch of

00:17:46,980 --> 00:17:51,490
replacement characters

00:17:48,520 --> 00:17:54,670
and then said nits then you did this

00:17:51,490 --> 00:18:02,050
from like an IE 8 vm you know during

00:17:54,670 --> 00:18:05,170
Christmas one thing I want to mention is

00:18:02,050 --> 00:18:07,450
the escape characters that Python gives

00:18:05,170 --> 00:18:10,059
to you and I think especially the

00:18:07,450 --> 00:18:11,470
backslash egg ex can be a little

00:18:10,059 --> 00:18:13,390
confusing and the reason why it's

00:18:11,470 --> 00:18:16,300
confusing is because it can be used in

00:18:13,390 --> 00:18:18,970
both strings and bytes and it means

00:18:16,300 --> 00:18:20,800
different things in both cases so

00:18:18,970 --> 00:18:25,450
imagine that you're building a string

00:18:20,800 --> 00:18:27,760
with backslash x DB that doesn't mean

00:18:25,450 --> 00:18:30,160
that this string is made of bytes what

00:18:27,760 --> 00:18:32,500
you're saying here is insert here

00:18:30,160 --> 00:18:35,140
whatever character has good point

00:18:32,500 --> 00:18:36,940
associated with EB EB being the

00:18:35,140 --> 00:18:39,490
hexadecimal representation of that code

00:18:36,940 --> 00:18:41,830
point and so there is nothing wrong with

00:18:39,490 --> 00:18:44,620
this there's a bunch of characters even

00:18:41,830 --> 00:18:46,210
in ASCII that cannot be displayed like

00:18:44,620 --> 00:18:48,850
the form feed character and so sometimes

00:18:46,210 --> 00:18:52,270
python will render them like this in

00:18:48,850 --> 00:18:54,790
your stack trace but if you put this

00:18:52,270 --> 00:18:59,440
inside of a byte what you're saying in

00:18:54,790 --> 00:19:02,950
effect is put here the literal bite EB

00:18:59,440 --> 00:19:05,950
and I mean I don't know maybe this byte

00:19:02,950 --> 00:19:10,090
using utf-8 maps to the character that

00:19:05,950 --> 00:19:11,650
has code point EB but maybe not there

00:19:10,090 --> 00:19:14,679
are more escape characters that you can

00:19:11,650 --> 00:19:17,650
use to insert Unicode inside of your

00:19:14,679 --> 00:19:21,429
strings so you have the backslash you

00:19:17,650 --> 00:19:24,160
that you use when a certain character

00:19:21,429 --> 00:19:26,320
needs more than one byte like when it's

00:19:24,160 --> 00:19:28,929
good point needs more than one buy to be

00:19:26,320 --> 00:19:31,570
represented in hexadecimal

00:19:28,929 --> 00:19:33,820
there is backslash capital u that does

00:19:31,570 --> 00:19:36,490
the same thing so backslash user it was

00:19:33,820 --> 00:19:42,010
for 2 bytes backslash capital u will be

00:19:36,490 --> 00:19:46,690
like four four bytes and lastly Unicode

00:19:42,010 --> 00:19:48,490
Associates a name with each with each

00:19:46,690 --> 00:19:51,190
character and so for example the snake

00:19:48,490 --> 00:19:52,900
emoji got the name snake and so you can

00:19:51,190 --> 00:19:55,420
do backslash N and then in brackets you

00:19:52,900 --> 00:19:58,510
enter snake and Python will just insert

00:19:55,420 --> 00:20:01,020
here whatever code point is associated

00:19:58,510 --> 00:20:01,020
with this name

00:20:01,290 --> 00:20:06,240
there's a lot more to unicode than what

00:20:04,500 --> 00:20:08,280
i've just talked about so I've talked

00:20:06,240 --> 00:20:10,140
about combining characters and here you

00:20:08,280 --> 00:20:13,530
can see them in action

00:20:10,140 --> 00:20:15,360
there is normalization because the e

00:20:13,530 --> 00:20:18,930
with an umlaut you could represent it as

00:20:15,360 --> 00:20:22,980
one code point or as a combination of

00:20:18,930 --> 00:20:25,680
umlaut plus e and the two will appear

00:20:22,980 --> 00:20:28,230
exactly the same to you user but if you

00:20:25,680 --> 00:20:29,910
were to try doing equal equal between

00:20:28,230 --> 00:20:32,460
the two in Python because their code

00:20:29,910 --> 00:20:34,650
point representation is different Python

00:20:32,460 --> 00:20:36,660
will return false and so Unicode

00:20:34,650 --> 00:20:38,580
normalization is about trying to

00:20:36,660 --> 00:20:41,610
normalize this before you make string

00:20:38,580 --> 00:20:43,920
comparisons there's the bum by author

00:20:41,610 --> 00:20:48,330
mark and then there's the concept of

00:20:43,920 --> 00:20:50,850
graphing I really recommend the talk

00:20:48,330 --> 00:20:53,670
given by Ned Batchelder about Unicode

00:20:50,850 --> 00:20:56,820
and then Python also has a full how-to

00:20:53,670 --> 00:21:00,650
page for Unicode that is really handy to

00:20:56,820 --> 00:21:00,650
read thank you very much

00:21:06,630 --> 00:21:10,590
we do have some time for questions so if

00:21:08,610 --> 00:21:11,370
you have a question please raise your

00:21:10,590 --> 00:21:19,710
hand

00:21:11,370 --> 00:21:22,700
oh hi good talk you mentioned that

00:21:19,710 --> 00:21:24,600
Unicode will sort of try and compress

00:21:22,700 --> 00:21:26,640
certain characters so it weren't

00:21:24,600 --> 00:21:30,480
actually pad with zeros to make up for

00:21:26,640 --> 00:21:32,460
bytes for example how does it know like

00:21:30,480 --> 00:21:35,970
what to interpret as a character if we

00:21:32,460 --> 00:21:40,980
know from a stream of bytes yeah so what

00:21:35,970 --> 00:21:45,600
utf-8 does is that basically the bytes

00:21:40,980 --> 00:21:47,340
will contain metadata about where they

00:21:45,600 --> 00:21:49,920
can find a good point

00:21:47,340 --> 00:21:51,630
so I don't I don't remember the

00:21:49,920 --> 00:21:53,910
specifics but basically it'll be like

00:21:51,630 --> 00:21:58,320
okay if the byte that you see is one

00:21:53,910 --> 00:21:59,900
plus seven zeroes then the next byte

00:21:58,320 --> 00:22:03,390
should be interpreted as a code point

00:21:59,900 --> 00:22:04,740
and if it's I'm making something up

00:22:03,390 --> 00:22:07,860
right now but this is basically how it

00:22:04,740 --> 00:22:10,950
works or if the first byte that you see

00:22:07,860 --> 00:22:12,660
is like one one plus six zeroes then it

00:22:10,950 --> 00:22:14,730
knows that okay the next two bytes

00:22:12,660 --> 00:22:17,940
should be interpreted as

00:22:14,730 --> 00:22:20,250
good point so I think there is a

00:22:17,940 --> 00:22:22,860
trade-off here between space and

00:22:20,250 --> 00:22:24,299
performance because if you really don't

00:22:22,860 --> 00:22:27,000
care about space you could just use

00:22:24,299 --> 00:22:29,460
utf-32 because it doesn't need to

00:22:27,000 --> 00:22:32,190
interpret it just needs to convert the

00:22:29,460 --> 00:22:33,750
bytes into code points versus utf-8

00:22:32,190 --> 00:22:35,820
there is actually information inside of

00:22:33,750 --> 00:22:38,880
the bytes about how the each individual

00:22:35,820 --> 00:22:41,220
byte should be read but yeah it tries to

00:22:38,880 --> 00:22:46,919
be smart about space and and performance

00:22:41,220 --> 00:22:49,230
at the same time with you mentioned that

00:22:46,919 --> 00:22:50,730
there's names for the emojis like the

00:22:49,230 --> 00:22:52,350
the snake one and all of that and a

00:22:50,730 --> 00:22:54,179
lookup is there like a reference inside

00:22:52,350 --> 00:22:56,100
of Python or someone else somewhere else

00:22:54,179 --> 00:22:59,250
where you can look up the actual where

00:22:56,100 --> 00:23:02,340
the names are so you can know what what

00:22:59,250 --> 00:23:05,070
names to use yeah there is

00:23:02,340 --> 00:23:08,540
I'm personally using this website called

00:23:05,070 --> 00:23:11,220
file format a lot that has one page per

00:23:08,540 --> 00:23:13,140
character per Unicode character and so

00:23:11,220 --> 00:23:15,480
they give you the name they give you

00:23:13,140 --> 00:23:18,540
like an SVG representation in case you

00:23:15,480 --> 00:23:21,090
know your your font cannot render that

00:23:18,540 --> 00:23:25,260
character and they give you things like

00:23:21,090 --> 00:23:28,130
how you can insert it in HTML yeah

00:23:25,260 --> 00:23:28,130
things like this

00:23:35,880 --> 00:23:39,460
thanks Richard thank you for the talk

00:23:38,140 --> 00:23:43,720
and just on that point

00:23:39,460 --> 00:23:45,309
it's the Unicode data module or like in

00:23:43,720 --> 00:23:55,390
Python you've important you're spending

00:23:45,309 --> 00:23:57,610
money okay I think that's all the

00:23:55,390 --> 00:23:59,650
questions obviously if you have any more

00:23:57,610 --> 00:24:02,290
questions you can probably come and

00:23:59,650 --> 00:24:05,160
catch Raphael during the break but I

00:24:02,290 --> 00:24:07,480
think on that we will call it time and

00:24:05,160 --> 00:24:09,420
thank you again Raphael here is a

00:24:07,480 --> 00:24:16,799
present from the organizers

00:24:09,420 --> 00:24:16,799

YouTube URL: https://www.youtube.com/watch?v=oXVmZGN6plY


