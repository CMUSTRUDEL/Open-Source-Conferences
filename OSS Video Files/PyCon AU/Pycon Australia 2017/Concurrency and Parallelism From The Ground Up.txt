Title: Concurrency and Parallelism From The Ground Up
Publication date: 2017-08-05
Playlist: Pycon Australia 2017
Description: 
	Amber Brown

http://2017.pycon-au.org/schedule/presentation/38/

#pyconau

This talk was given at PyCon Australia 2017 which was held from 3-8 August, 2017 in Melbourne, Victoria.

PyCon Australia is the national conference for users of the Python Programming Language. In August 2017, we're returning to Melbourne, bringing together students, enthusiasts, and professionals with a love of Python from around Australia, and from all over the World. 

August 3-8 2017, Melbourne, Victoria

Python, PyCon, PyConAU
Captions: 
	00:00:00,060 --> 00:00:07,500
I thank you very much for being here um

00:00:03,929 --> 00:00:09,690
next speaker will talk about concurrency

00:00:07,500 --> 00:00:12,420
and parallelism from the ground up

00:00:09,690 --> 00:00:17,130
she's amber Brown she's very well known

00:00:12,420 --> 00:00:20,070
to Python and as a computer all all who

00:00:17,130 --> 00:00:21,779
works in Python networking and data so

00:00:20,070 --> 00:00:23,189
she's been a fixture in the past

00:00:21,779 --> 00:00:24,660
conferences so you've probably seen her

00:00:23,189 --> 00:00:27,180
speak already and that's why you're here

00:00:24,660 --> 00:00:29,670
she's the twisted release manager and

00:00:27,180 --> 00:00:51,300
she's a general code troublemaker please

00:00:29,670 --> 00:00:54,870
welcome and brown technical issues ok

00:00:51,300 --> 00:00:57,480
cool well I'll just speak louder hello

00:00:54,870 --> 00:00:59,280
everyone today I'm here to talk about

00:00:57,480 --> 00:01:02,340
implementing concurrency and parallelism

00:00:59,280 --> 00:01:04,199
parallelism from the ground up this

00:01:02,340 --> 00:01:05,670
means less about what Python module when

00:01:04,199 --> 00:01:07,380
you import and more about how it's

00:01:05,670 --> 00:01:09,479
actually done at the level of the CPU

00:01:07,380 --> 00:01:12,060
the operating system and then onwards

00:01:09,479 --> 00:01:13,590
into user space I believe this is

00:01:12,060 --> 00:01:15,600
important because it might not be clear

00:01:13,590 --> 00:01:17,340
how when you're developing a concurrent

00:01:15,600 --> 00:01:21,330
application in Python how it's actually

00:01:17,340 --> 00:01:23,070
handled underneath you the techniques to

00:01:21,330 --> 00:01:24,659
run software concurrently in it and in

00:01:23,070 --> 00:01:28,200
parallel have been around since the 60s

00:01:24,659 --> 00:01:29,790
on computers as old as the PDP 1 but it

00:01:28,200 --> 00:01:31,680
was much longer until such features came

00:01:29,790 --> 00:01:34,200
to consumer hardware and consumer

00:01:31,680 --> 00:01:36,600
operating systems both mac OS and

00:01:34,200 --> 00:01:38,159
windows had similar paths but I'm going

00:01:36,600 --> 00:01:40,920
with Windows as the context as I

00:01:38,159 --> 00:01:42,570
personal background with it it is rather

00:01:40,920 --> 00:01:44,310
fortunate that sequential consumer

00:01:42,570 --> 00:01:45,869
versions of Windows gradually introduce

00:01:44,310 --> 00:01:47,970
concurrency features as it got more

00:01:45,869 --> 00:01:50,490
advanced so you can use it as a good

00:01:47,970 --> 00:01:54,600
sort of viewpoint for explaining how and

00:01:50,490 --> 00:01:57,180
why things are today on one computers so

00:01:54,600 --> 00:01:58,740
I am brown I'm best probably best known

00:01:57,180 --> 00:02:00,930
for my work on twisted and related

00:01:58,740 --> 00:02:02,850
projects during the day I work at jelly

00:02:00,930 --> 00:02:05,310
Australia on renewable energy and

00:02:02,850 --> 00:02:10,459
storage and you can find me at Twitter

00:02:05,310 --> 00:02:13,180
at an Tokyo or hawk out on github

00:02:10,459 --> 00:02:17,370
so it's 1983

00:02:13,180 --> 00:02:17,370
there was nothing just to das prompt I

00:02:17,519 --> 00:02:21,519
don't expect you to understand all the

00:02:19,599 --> 00:02:24,939
lingo as well so let's have a quick

00:02:21,519 --> 00:02:26,590
primer on terms the most important two

00:02:24,939 --> 00:02:29,200
terms in this talk are concurrency and

00:02:26,590 --> 00:02:31,120
parallelism they are similar to the user

00:02:29,200 --> 00:02:34,180
but vastly different in requirements and

00:02:31,120 --> 00:02:35,950
operation but to the user they both

00:02:34,180 --> 00:02:39,489
achieve for any multiple things at the

00:02:35,950 --> 00:02:41,530
same time concurrency is where multiple

00:02:39,489 --> 00:02:42,909
tasks front interleaved each tasks

00:02:41,530 --> 00:02:44,590
running for a small enough amount of

00:02:42,909 --> 00:02:47,109
time that all tasks have some work done

00:02:44,590 --> 00:02:48,819
on them on a human time scale you never

00:02:47,109 --> 00:02:51,090
actually run two things at the same time

00:02:48,819 --> 00:02:53,680
but it's a good enough illusion

00:02:51,090 --> 00:02:56,620
parallelism is where two tasks actually

00:02:53,680 --> 00:03:00,489
run at the same time this necessitates

00:02:56,620 --> 00:03:02,349
two or more processing units so let's

00:03:00,489 --> 00:03:04,209
have a look at how programs run to

00:03:02,349 --> 00:03:08,049
understand why running and running them

00:03:04,209 --> 00:03:10,450
concurrently can be hard programs are

00:03:08,049 --> 00:03:12,010
stored in an executable format a little

00:03:10,450 --> 00:03:15,069
and a little more than a sequence of

00:03:12,010 --> 00:03:17,530
instructions the central processing unit

00:03:15,069 --> 00:03:20,709
or CPU executes these instructions in

00:03:17,530 --> 00:03:22,930
sequence as an example here's an excerpt

00:03:20,709 --> 00:03:25,540
of the instructions that make up part of

00:03:22,930 --> 00:03:28,019
Python what ran here is the disassembled

00:03:25,540 --> 00:03:30,280
machine code organized into instructions

00:03:28,019 --> 00:03:31,750
something to note is that nearly every

00:03:30,280 --> 00:03:33,729
instruction relies on the previous one

00:03:31,750 --> 00:03:35,319
succeeding you can't run them in a

00:03:33,729 --> 00:03:36,419
different order as each instruction

00:03:35,319 --> 00:03:43,449
relies on the state of the application

00:03:36,419 --> 00:03:45,370
being what it expects on a higher level

00:03:43,449 --> 00:03:47,319
in programming languages the underlying

00:03:45,370 --> 00:03:49,750
machine code is hidden from us as it's

00:03:47,319 --> 00:03:51,879
transformed into a program like from a

00:03:49,750 --> 00:03:53,019
program code like this into the machine

00:03:51,879 --> 00:03:56,229
code that does what the program

00:03:53,019 --> 00:03:57,699
represents you can see the usage of two

00:03:56,229 --> 00:04:00,280
functions here in this Q basic

00:03:57,699 --> 00:04:02,500
application there is print which prints

00:04:00,280 --> 00:04:04,299
X as a terminal and end which finishes

00:04:02,500 --> 00:04:07,269
execution of the program and returns to

00:04:04,299 --> 00:04:09,759
the operating system if we were to

00:04:07,269 --> 00:04:11,290
compile and run it we would get this the

00:04:09,759 --> 00:04:13,269
print functions in the exact order we

00:04:11,290 --> 00:04:14,919
programmed them one will always come

00:04:13,269 --> 00:04:17,199
before the other and end will always

00:04:14,919 --> 00:04:21,700
come at the end nothing in between in

00:04:17,199 --> 00:04:23,349
old in the same order always classical

00:04:21,700 --> 00:04:25,150
desktop operating systems like ms-dos

00:04:23,349 --> 00:04:26,950
only supported one application at once

00:04:25,150 --> 00:04:28,930
you type the application name

00:04:26,950 --> 00:04:30,880
hit enter and the application ran until

00:04:28,930 --> 00:04:33,340
it finished allowing nothing else to

00:04:30,880 --> 00:04:34,810
happen on the machine this is fine for

00:04:33,340 --> 00:04:36,880
things like games when playing King's

00:04:34,810 --> 00:04:38,620
Quest you wanted to play the game but

00:04:36,880 --> 00:04:40,780
this was a sticking point for general

00:04:38,620 --> 00:04:42,250
and office computing in the business

00:04:40,780 --> 00:04:43,780
world you want to run many things at

00:04:42,250 --> 00:04:45,190
once checking to see if you have an

00:04:43,780 --> 00:04:46,510
email shouldn't involve completely

00:04:45,190 --> 00:04:49,810
shutting down the word processor you are

00:04:46,510 --> 00:04:54,130
writing a report in let's fast forward

00:04:49,810 --> 00:04:58,990
to 1985 what is the future the future of

00:04:54,130 --> 00:05:01,410
course is Windows Windows is named after

00:04:58,990 --> 00:05:03,730
the thing it brought to the IBM PC world

00:05:01,410 --> 00:05:05,410
these windows were little containers

00:05:03,730 --> 00:05:06,610
they held an application so you could

00:05:05,410 --> 00:05:08,950
display multiple on the screen at once

00:05:06,610 --> 00:05:11,950
or minimize one but keep it running

00:05:08,950 --> 00:05:13,750
while you looked at something else at

00:05:11,950 --> 00:05:14,710
this time we didn't have multiple CPUs

00:05:13,750 --> 00:05:16,690
and desktop computers

00:05:14,710 --> 00:05:19,390
so using parallelism to run all of these

00:05:16,690 --> 00:05:21,550
applications at once was out we needed

00:05:19,390 --> 00:05:23,950
concurrency which was it exactly what

00:05:21,550 --> 00:05:25,660
Microsoft provided so how did Microsoft

00:05:23,950 --> 00:05:29,740
run multiple applications at once in

00:05:25,660 --> 00:05:31,930
Windows Windows 1.0 implementable words

00:05:29,740 --> 00:05:33,670
called cooperative multitasking each

00:05:31,930 --> 00:05:36,130
application had to specifically support

00:05:33,670 --> 00:05:38,380
Windows using its API so cooperate with

00:05:36,130 --> 00:05:40,420
the rest of the system this was built on

00:05:38,380 --> 00:05:41,950
trust a trust from the application that

00:05:40,420 --> 00:05:44,320
will get time to run frequently enough

00:05:41,950 --> 00:05:46,120
to provide a good user experience and we

00:05:44,320 --> 00:05:50,230
just would trust the application to not

00:05:46,120 --> 00:05:52,020
monopolize run time the API that Windows

00:05:50,230 --> 00:05:54,970
implemented looked kind of like this

00:05:52,020 --> 00:05:56,320
Windows implemented a message queue in

00:05:54,970 --> 00:05:58,420
which an application would periodically

00:05:56,320 --> 00:06:00,970
ask for a message while running using

00:05:58,420 --> 00:06:02,950
the get message function the system call

00:06:00,970 --> 00:06:04,510
would transfer control to Windows which

00:06:02,950 --> 00:06:06,130
would either provide a message or

00:06:04,510 --> 00:06:08,590
suspend the application and pass control

00:06:06,130 --> 00:06:10,480
to to another causing Apple original

00:06:08,590 --> 00:06:13,210
applications thread to block until

00:06:10,480 --> 00:06:16,600
Windows was given control back later and

00:06:13,210 --> 00:06:18,580
provided a message the application could

00:06:16,600 --> 00:06:21,190
potentially use a different API called

00:06:18,580 --> 00:06:22,600
peek message which would not work this

00:06:21,190 --> 00:06:24,610
allowed an application doing heavy

00:06:22,600 --> 00:06:26,380
processing to still be notified about

00:06:24,610 --> 00:06:29,550
events from Windows such as key presses

00:06:26,380 --> 00:06:32,020
without giving up control

00:06:29,550 --> 00:06:33,280
this gave absolute control to the

00:06:32,020 --> 00:06:35,410
application when it should allow

00:06:33,280 --> 00:06:36,250
absolutely anything else to run and on

00:06:35,410 --> 00:06:37,930
the machine

00:06:36,250 --> 00:06:40,479
not even Windows could wrest control

00:06:37,930 --> 00:06:41,710
from the application once it was running

00:06:40,479 --> 00:06:44,319
and there's some form of interrupts

00:06:41,710 --> 00:06:46,210
called into it this model meant that you

00:06:44,319 --> 00:06:47,770
had to explicitly write applications for

00:06:46,210 --> 00:06:49,240
Windows which meant a larger map

00:06:47,770 --> 00:06:51,610
locations had to be rewritten or

00:06:49,240 --> 00:06:53,680
modified not only to support concurrency

00:06:51,610 --> 00:06:56,529
but also we doses graphics libraries and

00:06:53,680 --> 00:06:58,449
if you if the application didn't yield

00:06:56,529 --> 00:07:00,339
enough control to Windows other

00:06:58,449 --> 00:07:01,599
applications could seem laggy or even

00:07:00,339 --> 00:07:04,629
things like cursor movement could be

00:07:01,599 --> 00:07:06,999
affected the implementation however is

00:07:04,629 --> 00:07:08,469
simple relatively easy to implement on

00:07:06,999 --> 00:07:10,479
the operating and applique operating

00:07:08,469 --> 00:07:14,139
system and application side and doesn't

00:07:10,479 --> 00:07:16,180
have a lot of overhead one important

00:07:14,139 --> 00:07:17,889
thing that that window is 1.0 had their

00:07:16,180 --> 00:07:20,229
most versions of ms-dos didn't is a

00:07:17,889 --> 00:07:21,849
virtual memory when running concurrent

00:07:20,229 --> 00:07:24,039
applications you mainly want two things

00:07:21,849 --> 00:07:26,020
the first is that you want applications

00:07:24,039 --> 00:07:27,789
to be portable this means that the

00:07:26,020 --> 00:07:30,550
application doesn't have to rely on any

00:07:27,789 --> 00:07:32,020
certain memory segments being free or or

00:07:30,550 --> 00:07:34,360
it being placed in certain region of

00:07:32,020 --> 00:07:36,009
memory if multiple applications access

00:07:34,360 --> 00:07:38,620
to fixed points of regal memory

00:07:36,009 --> 00:07:42,039
it could mean chaos we've one or both

00:07:38,620 --> 00:07:43,300
application stopping working the second

00:07:42,039 --> 00:07:44,860
is that you don't want any one

00:07:43,300 --> 00:07:46,749
application to be able to mess with the

00:07:44,860 --> 00:07:49,270
memory of any other application by

00:07:46,749 --> 00:07:51,189
default keep the applications separating

00:07:49,270 --> 00:07:55,439
memory means that no one corrupt

00:07:51,189 --> 00:07:55,439
application could affect anything else

00:07:58,949 --> 00:08:04,240
virtual memory is generally implemented

00:08:01,419 --> 00:08:05,560
by a memory management unit this MMU

00:08:04,240 --> 00:08:07,870
when or referencing blocks of memory

00:08:05,560 --> 00:08:11,259
will refer to a page table to find where

00:08:07,870 --> 00:08:12,819
the memory actually is in RAM this means

00:08:11,259 --> 00:08:15,610
every application on the system could

00:08:12,819 --> 00:08:17,139
put something at 0 X 0 but it will

00:08:15,610 --> 00:08:20,199
actually be put somewhere else with the

00:08:17,139 --> 00:08:22,029
application none the wiser this is also

00:08:20,199 --> 00:08:24,099
useful for older applications that may

00:08:22,029 --> 00:08:26,050
expect to control all of the memory

00:08:24,099 --> 00:08:27,279
virtual memory is invisible to the

00:08:26,050 --> 00:08:29,819
application so it doubles as a

00:08:27,279 --> 00:08:33,130
compatibility shim

00:08:29,819 --> 00:08:34,899
so we have multiple applications now and

00:08:33,130 --> 00:08:36,339
with virtual memory they mostly none the

00:08:34,899 --> 00:08:37,440
wiser about each other it all play

00:08:36,339 --> 00:08:40,180
nicely

00:08:37,440 --> 00:08:42,699
however the software kind of has to

00:08:40,180 --> 00:08:46,660
behave in its in how it does concurrency

00:08:42,699 --> 00:08:47,800
and software doesn't behave a lot so say

00:08:46,660 --> 00:08:50,660
it's 1994

00:08:47,800 --> 00:08:53,519
what's the feature

00:08:50,660 --> 00:08:56,100
windows 95 is my favorite operating

00:08:53,519 --> 00:08:58,410
system I say this without any irony

00:08:56,100 --> 00:09:00,569
because it really was one of the turning

00:08:58,410 --> 00:09:03,239
points in life it was a very wonderful

00:09:00,569 --> 00:09:08,279
thing to get to see just look at the

00:09:03,239 --> 00:09:11,059
maze graphics so cool remember that

00:09:08,279 --> 00:09:14,549
we're in 1984 this is impressive

00:09:11,059 --> 00:09:16,799
anyway Windows 95 is advertising focus

00:09:14,549 --> 00:09:19,230
on two things the first was multitasking

00:09:16,799 --> 00:09:20,670
and the upper was the Internet the

00:09:19,230 --> 00:09:22,529
internet didn't really do much but cause

00:09:20,670 --> 00:09:23,220
problems for Windows for the next decade

00:09:22,529 --> 00:09:27,839
and a half

00:09:23,220 --> 00:09:29,629
but the multitasking was arrived windows

00:09:27,839 --> 00:09:31,980
95 implements pre-emptive multitasking

00:09:29,629 --> 00:09:34,019
this is where the operating system takes

00:09:31,980 --> 00:09:36,089
control from the application pre-empting

00:09:34,019 --> 00:09:37,170
it rather than the application giving

00:09:36,089 --> 00:09:40,949
control back to the operating system

00:09:37,170 --> 00:09:43,110
like in Windows 1.0 the operating system

00:09:40,949 --> 00:09:44,579
gains control gains back control through

00:09:43,110 --> 00:09:47,579
the use of interrupts from a real-time

00:09:44,579 --> 00:09:49,019
clock interrupts or a cpu feature that

00:09:47,579 --> 00:09:51,449
allows the code routine to be ran

00:09:49,019 --> 00:09:52,980
according to some trigger and modern CPU

00:09:51,449 --> 00:09:54,389
ship with a real-time clock that can

00:09:52,980 --> 00:09:57,779
provide that trigger after a certain

00:09:54,389 --> 00:09:59,459
amount of time when we scheduled the

00:09:57,779 --> 00:10:00,779
runtime of different threads the

00:09:59,459 --> 00:10:02,790
operating system needs to decide how

00:10:00,779 --> 00:10:05,279
long to let it run or for switching

00:10:02,790 --> 00:10:07,980
control to another its amount of time is

00:10:05,279 --> 00:10:11,399
called a time slice or in Windows lingo

00:10:07,980 --> 00:10:13,649
a quantum changing between threads is

00:10:11,399 --> 00:10:15,089
expensive as we'll see but if you don't

00:10:13,649 --> 00:10:16,529
switch frequency the illusion of

00:10:15,089 --> 00:10:19,619
concurrency becomes obvious to the user

00:10:16,529 --> 00:10:21,029
and applications seem unresponsive so

00:10:19,619 --> 00:10:24,329
picking the right time slice length is

00:10:21,029 --> 00:10:27,509
important on Windows XP time slices are

00:10:24,329 --> 00:10:29,519
generally 15 to 60 milliseconds and on

00:10:27,509 --> 00:10:32,610
windows server they are affixed to 120

00:10:29,519 --> 00:10:34,379
milliseconds the length of this time

00:10:32,610 --> 00:10:35,999
slice has a bottom limit which is the

00:10:34,379 --> 00:10:38,309
tick rate of the operating system kernel

00:10:35,999 --> 00:10:40,199
this tick is what is set in the real

00:10:38,309 --> 00:10:41,999
time clock and hence control back to the

00:10:40,199 --> 00:10:44,069
OS every softened update things like the

00:10:41,999 --> 00:10:46,049
system clock process internal events and

00:10:44,069 --> 00:10:49,769
most importantly reduce the running

00:10:46,049 --> 00:10:51,149
threads time slice operating systems of

00:10:49,769 --> 00:10:53,220
the time would have a server desktop

00:10:51,149 --> 00:10:55,649
kernel with different text sizes for

00:10:53,220 --> 00:10:57,929
each every tick which is about fifteen

00:10:55,649 --> 00:10:59,939
point six milliseconds on Windows four

00:10:57,929 --> 00:11:02,040
milliseconds on all the desktop versions

00:10:59,939 --> 00:11:03,379
of Linux and ten milliseconds on the

00:11:02,040 --> 00:11:06,769
server veterans of Linux

00:11:03,379 --> 00:11:09,739
sinn windows's tick is 15.6 milliseconds

00:11:06,769 --> 00:11:12,410
that determinant determines the minimum

00:11:09,739 --> 00:11:15,229
time slice it can allocate to 15.6

00:11:12,410 --> 00:11:17,119
milliseconds Linux had a configurable

00:11:15,229 --> 00:11:21,799
tick and therefore configurable minimum

00:11:17,119 --> 00:11:23,299
time slices overall the operating system

00:11:21,799 --> 00:11:25,220
has to be careful about what time slice

00:11:23,299 --> 00:11:27,499
it allocates to applications that a user

00:11:25,220 --> 00:11:29,389
may be interacting with Windows will

00:11:27,499 --> 00:11:31,369
give the active windows poll process a

00:11:29,389 --> 00:11:33,559
higher priority and therefore larger

00:11:31,369 --> 00:11:35,869
time slices more often to keep things

00:11:33,559 --> 00:11:38,599
responsive to the user that's using the

00:11:35,869 --> 00:11:40,519
application but giving a too short same

00:11:38,599 --> 00:11:42,439
time slice to the only thread that needs

00:11:40,519 --> 00:11:43,699
to a lot of work and in causing

00:11:42,439 --> 00:11:44,720
excessive switching to otherwise

00:11:43,699 --> 00:11:46,789
inactive threads

00:11:44,720 --> 00:11:48,470
means that time is wasted and overall

00:11:46,789 --> 00:11:56,419
throughput goes down which is bad for

00:11:48,470 --> 00:11:58,339
service so when a thread is either

00:11:56,419 --> 00:12:01,689
preempted or cooperatively gives up

00:11:58,339 --> 00:12:03,889
control what needs to be altered

00:12:01,689 --> 00:12:05,809
software is generally written as it is

00:12:03,889 --> 00:12:08,509
as if it is the only thing on the

00:12:05,809 --> 00:12:10,489
machine and you will run forever to

00:12:08,509 --> 00:12:12,109
maintain sly the operating system has to

00:12:10,489 --> 00:12:14,149
save the state of the thread before a

00:12:12,109 --> 00:12:17,539
pre-emptive and restore it when it runs

00:12:14,149 --> 00:12:19,639
again ideally a thread will never know

00:12:17,539 --> 00:12:22,549
it has been preempted and will still run

00:12:19,639 --> 00:12:24,259
correctly to do this the operating

00:12:22,549 --> 00:12:26,600
system must save the current working set

00:12:24,259 --> 00:12:28,100
of the thread to memory the registers

00:12:26,600 --> 00:12:29,859
which can be thought of as high

00:12:28,100 --> 00:12:32,209
performance bits of memory on the CPU

00:12:29,859 --> 00:12:34,579
represent the current CPU level state

00:12:32,209 --> 00:12:36,589
the virtual memory representing the rest

00:12:34,579 --> 00:12:38,359
of the state in RAM and the program

00:12:36,589 --> 00:12:40,339
counter representing one instruction

00:12:38,359 --> 00:12:45,049
inside the binary that the throat was

00:12:40,339 --> 00:12:47,539
executed executing many of you probably

00:12:45,049 --> 00:12:49,249
not multiplayer it's we're in the same

00:12:47,539 --> 00:12:50,959
process you create a new thread to do

00:12:49,249 --> 00:12:53,659
some tasks without stopping the current

00:12:50,959 --> 00:12:56,809
through every process which responds to

00:12:53,659 --> 00:12:59,689
a instance of a run binary has one or

00:12:56,809 --> 00:13:02,299
more threads each thread is a chain of

00:12:59,689 --> 00:13:04,279
instructions with its own stack CPU

00:13:02,299 --> 00:13:05,509
registers and alike but shares its

00:13:04,279 --> 00:13:08,029
virtual memory pool with the other

00:13:05,509 --> 00:13:11,209
threads in the process the process

00:13:08,029 --> 00:13:12,829
however holds the state about what user

00:13:11,209 --> 00:13:15,439
is running it what binary is running

00:13:12,829 --> 00:13:16,700
what binary is running and the memory

00:13:15,439 --> 00:13:20,410
holds as halters

00:13:16,700 --> 00:13:20,410
it's between threads and processors

00:13:20,800 --> 00:13:25,130
pre-emptive concurrency creates new

00:13:22,880 --> 00:13:27,200
problems each thread may be putting up

00:13:25,130 --> 00:13:30,440
to dat anytime the thread doesn't know

00:13:27,200 --> 00:13:32,210
that what problems can is cause the

00:13:30,440 --> 00:13:35,870
largest is race conditions in

00:13:32,210 --> 00:13:38,990
multi-threaded code let's imagine this

00:13:35,870 --> 00:13:41,030
code being a random thread it reads a

00:13:38,990 --> 00:13:42,820
balloon from memory flips it and then

00:13:41,030 --> 00:13:46,880
saves it back and then reads it again

00:13:42,820 --> 00:13:48,950
simple if it is the only thing running

00:13:46,880 --> 00:13:54,290
with no preemption we can expect this

00:13:48,950 --> 00:13:55,940
output but what if in the same process

00:13:54,290 --> 00:13:58,760
we have two instances of this code in

00:13:55,940 --> 00:14:00,350
two different threads thread one might

00:13:58,760 --> 00:14:02,150
get up to the comment having read a

00:14:00,350 --> 00:14:04,910
false written a true and then being

00:14:02,150 --> 00:14:07,100
suspended threaten to may then start and

00:14:04,910 --> 00:14:09,200
run to completion having read the true

00:14:07,100 --> 00:14:11,120
flipped about to false and saved it back

00:14:09,200 --> 00:14:14,450
thread 1 then racemes

00:14:11,120 --> 00:14:17,300
and what does it read before exiting it

00:14:14,450 --> 00:14:22,340
reads false as thread 2 wrote this is an

00:14:17,300 --> 00:14:24,800
example of a race condition so it's 1995

00:14:22,340 --> 00:14:26,660
I've still got one CPU but we're running

00:14:24,800 --> 00:14:29,480
multiple programs on it that might not

00:14:26,660 --> 00:14:31,130
play nicely that's ok virtual memory and

00:14:29,480 --> 00:14:32,720
pre-emptive multitasking means that all

00:14:31,130 --> 00:14:36,050
works fine unless someone writes some

00:14:32,720 --> 00:14:43,910
buggy moulting multi-threaded code let's

00:14:36,050 --> 00:14:45,170
skip forward to 2001 we just XP it was

00:14:43,910 --> 00:14:46,940
one of the first consumer operating

00:14:45,170 --> 00:14:51,940
systems where we could tap start taking

00:14:46,940 --> 00:14:51,940
advantage of parallelism and pinball

00:14:53,380 --> 00:14:57,770
simultaneous multi-threading known as

00:14:55,580 --> 00:14:59,420
are marketed as hyper threading by Intel

00:14:57,770 --> 00:15:03,140
is a way of providing parallelism

00:14:59,420 --> 00:15:05,000
without having true to true cause it

00:15:03,140 --> 00:15:07,640
works by duplicating the instruction

00:15:05,000 --> 00:15:09,020
queues creating two logical processes

00:15:07,640 --> 00:15:12,080
that the operating system can address

00:15:09,020 --> 00:15:14,330
the news these two logical processors

00:15:12,080 --> 00:15:16,070
feed into one physical processor more

00:15:14,330 --> 00:15:17,930
efficiently filling in gaps where one

00:15:16,070 --> 00:15:20,810
logical processor may be waiting from

00:15:17,930 --> 00:15:22,370
Donovan cache or Ram by processing the

00:15:20,810 --> 00:15:24,260
instructions of the other or by

00:15:22,370 --> 00:15:26,270
combining instructions from both that

00:15:24,260 --> 00:15:29,530
the physical processor may be able to

00:15:26,270 --> 00:15:29,530
run in a single instruction

00:15:30,200 --> 00:15:34,800
later in Windows XP s life multi-core

00:15:33,030 --> 00:15:37,740
processors became very common on on

00:15:34,800 --> 00:15:39,780
consumer computers this added a new

00:15:37,740 --> 00:15:43,710
layer of complexity as true parallelism

00:15:39,780 --> 00:15:45,630
was now possible and one of the major

00:15:43,710 --> 00:15:49,010
features of parallelism is causing your

00:15:45,630 --> 00:15:51,990
threaded code to become even more broken

00:15:49,010 --> 00:15:55,320
now any line of this code the memory at

00:15:51,990 --> 00:15:56,970
0 X 0 can't be changed even if you have

00:15:55,320 --> 00:15:58,830
the whole time slice and your thread is

00:15:56,970 --> 00:16:01,230
not preempted another thread can modify

00:15:58,830 --> 00:16:02,700
the memory you are looking at this

00:16:01,230 --> 00:16:04,440
increases the likelihood of race

00:16:02,700 --> 00:16:06,240
conditions as some dangerous code may

00:16:04,440 --> 00:16:08,700
have always feared in the fraction of a

00:16:06,240 --> 00:16:13,350
time slice and never presented itself as

00:16:08,700 --> 00:16:15,060
an issue until now the proper way to

00:16:13,350 --> 00:16:17,010
implement this would be to wrap the

00:16:15,060 --> 00:16:18,480
critical section the parts that required

00:16:17,010 --> 00:16:20,840
the data they operate on not be modified

00:16:18,480 --> 00:16:23,580
in a walk of some sort

00:16:20,840 --> 00:16:26,150
now mutexes are a different name for

00:16:23,580 --> 00:16:28,950
lock named as a mutual exclusion

00:16:26,150 --> 00:16:32,130
semaphores are a type of mutex incoming

00:16:28,950 --> 00:16:35,040
two times binary and counting binary

00:16:32,130 --> 00:16:36,780
semaphore are locked or unlocked which

00:16:35,040 --> 00:16:38,520
is useful protect for protecting

00:16:36,780 --> 00:16:40,200
resources that can't be mutated or

00:16:38,520 --> 00:16:43,860
accessed by two things at the same time

00:16:40,200 --> 00:16:45,660
such as memory or socket counting

00:16:43,860 --> 00:16:47,160
semaphores or when multiple things can

00:16:45,660 --> 00:16:49,380
access it but only up to a certain

00:16:47,160 --> 00:16:50,760
number you may have a thread pool we

00:16:49,380 --> 00:16:52,530
have a certain number of threads an

00:16:50,760 --> 00:16:54,960
accounting semaphore controlling when a

00:16:52,530 --> 00:16:56,430
task may be sent to it tasks must

00:16:54,960 --> 00:16:58,470
weighed and killed until the counting

00:16:56,430 --> 00:17:03,180
semaphore is not at its limit to try and

00:16:58,470 --> 00:17:05,370
acquire a lock one of the major problems

00:17:03,180 --> 00:17:08,610
with locks is that they can be a source

00:17:05,370 --> 00:17:11,459
of errors themselves and fall prey to a

00:17:08,610 --> 00:17:13,110
race condition just like the examples of

00:17:11,459 --> 00:17:15,600
reading bullying from memory before an

00:17:13,110 --> 00:17:17,220
Avery ridden lock can read a false try

00:17:15,600 --> 00:17:18,630
and set a true and not have done it in

00:17:17,220 --> 00:17:22,050
time for never thread to read a false

00:17:18,630 --> 00:17:23,790
and set it to true as well giving two or

00:17:22,050 --> 00:17:26,579
more threats what is meant to be an

00:17:23,790 --> 00:17:27,000
exclusive lock the lock needs to be

00:17:26,579 --> 00:17:29,130
atomic

00:17:27,000 --> 00:17:33,050
that is the read/write operation happens

00:17:29,130 --> 00:17:33,050
instantaneously to all other threads

00:17:36,220 --> 00:17:41,090
that is looking before you leave may

00:17:38,690 --> 00:17:42,739
actually cause problems as looking and

00:17:41,090 --> 00:17:45,889
then deciding whether to do something is

00:17:42,739 --> 00:17:47,389
more than one instruction now with

00:17:45,889 --> 00:17:49,039
modern CPUs a ship with atomic

00:17:47,389 --> 00:17:51,739
instructions to assist with creating

00:17:49,039 --> 00:17:53,989
better locks one such instruction

00:17:51,739 --> 00:17:57,379
commonly become being called a test and

00:17:53,989 --> 00:17:59,710
set when a thread wants a lock it runs a

00:17:57,379 --> 00:18:02,659
loop produces a test and set instruction

00:17:59,710 --> 00:18:04,669
which tests for false and atomically

00:18:02,659 --> 00:18:08,239
sets it to true if the test condition is

00:18:04,669 --> 00:18:10,249
true avoids looping and train again this

00:18:08,239 --> 00:18:11,629
can cause problems too though as if you

00:18:10,249 --> 00:18:13,549
have 10 threads waiting to acquire a

00:18:11,629 --> 00:18:15,799
single lock nine of them will be

00:18:13,549 --> 00:18:17,330
spinning in a loop trying to do that

00:18:15,799 --> 00:18:19,639
test and set which is only one

00:18:17,330 --> 00:18:21,859
instruction so it's atomic but they'll

00:18:19,639 --> 00:18:25,609
just be wasting CPU time as one thread

00:18:21,859 --> 00:18:27,230
will hold the lock it's no fixed Q Eva

00:18:25,609 --> 00:18:30,739
there's no queueing interest is whatever

00:18:27,230 --> 00:18:32,480
thread grabs the lock when it's vacant

00:18:30,739 --> 00:18:34,220
will get it so one thread could be

00:18:32,480 --> 00:18:35,809
waiting for a very long time and one

00:18:34,220 --> 00:18:37,639
thread that's not being waiting for a

00:18:35,809 --> 00:18:40,070
very long time could get the lock rather

00:18:37,639 --> 00:18:42,019
than the one that's been waiting there

00:18:40,070 --> 00:18:44,179
are more complex locks that are fairer

00:18:42,019 --> 00:18:48,379
that build on top of these primitives

00:18:44,179 --> 00:18:50,749
though code that probably uses locks

00:18:48,379 --> 00:18:52,129
doesn't share global state or a voice

00:18:50,749 --> 00:18:54,649
doesn't fall prey to multi-threading

00:18:52,129 --> 00:18:56,570
issues is called thread safe code isn't

00:18:54,649 --> 00:18:58,519
thread safe by default so it's important

00:18:56,570 --> 00:19:02,029
to verify that it is before using it in

00:18:58,519 --> 00:19:04,039
a concurrent environment due to the

00:19:02,029 --> 00:19:06,529
advent of symmetric multiprocessing on

00:19:04,039 --> 00:19:08,359
consume Hardware applications again more

00:19:06,529 --> 00:19:10,009
and more thread safe and are being

00:19:08,359 --> 00:19:12,619
recent take advantage of the extra calls

00:19:10,009 --> 00:19:18,919
that we have at our disposal let's move

00:19:12,619 --> 00:19:20,179
forward see your 2007 the future over

00:19:18,919 --> 00:19:22,249
the next decade as it becomes

00:19:20,179 --> 00:19:25,489
increasingly hard to make a CPU faster

00:19:22,249 --> 00:19:27,169
we end up with more CPUs on a die on the

00:19:25,489 --> 00:19:30,529
server which may have two processor

00:19:27,169 --> 00:19:32,090
sockets 32 core configurations each call

00:19:30,529 --> 00:19:35,809
with multi-threading can mean your

00:19:32,090 --> 00:19:37,850
system sees 64 logical processors this

00:19:35,809 --> 00:19:40,179
introduces brand-new problems such as

00:19:37,850 --> 00:19:43,220
cache coherency and worst case misses

00:19:40,179 --> 00:19:45,320
many CPU share some level of cache

00:19:43,220 --> 00:19:47,450
between physical cores so on a dual core

00:19:45,320 --> 00:19:49,159
being moved from CPU 1 to CPU to may not

00:19:47,450 --> 00:19:51,440
be such a big issue

00:19:49,159 --> 00:19:53,119
but if you're on a 64 logical course

00:19:51,440 --> 00:19:55,220
system and you get moved to an entirely

00:19:53,119 --> 00:19:57,169
different dye or a voids between cores

00:19:55,220 --> 00:19:58,429
that share no caches you have now lost

00:19:57,169 --> 00:20:00,710
all the benefits that those cases

00:19:58,429 --> 00:20:03,320
provided as well as saving potentially

00:20:00,710 --> 00:20:04,940
outdated captures behind if you were to

00:20:03,320 --> 00:20:06,710
switch back to that core later if that

00:20:04,940 --> 00:20:08,899
case wasn't flushed then your

00:20:06,710 --> 00:20:12,649
application might just use it and it

00:20:08,899 --> 00:20:14,659
might lead to incorrect behavior Windows

00:20:12,649 --> 00:20:16,940
8 killed off the CPU tick instead

00:20:14,659 --> 00:20:18,830
scheduling and dynamically this is good

00:20:16,940 --> 00:20:21,349
for power saving as it prevents the CP

00:20:18,830 --> 00:20:23,389
being woken up every 15.6 milliseconds

00:20:21,349 --> 00:20:26,419
to sometimes process maybe nothing but

00:20:23,389 --> 00:20:28,999
some time is sense ramifications for

00:20:26,419 --> 00:20:30,739
time slices because 15.6 milliseconds is

00:20:28,999 --> 00:20:33,080
no longer the small Stute time slice can

00:20:30,739 --> 00:20:34,639
be and it makes larger time slices more

00:20:33,080 --> 00:20:37,549
efficient as the operating system is not

00:20:34,639 --> 00:20:39,019
interrupting them needlessly on linux

00:20:37,549 --> 00:20:40,609
the introduction of Chiklis kernels

00:20:39,019 --> 00:20:42,859
meant there was no longer a difference

00:20:40,609 --> 00:20:45,499
between a server and desktop kernel this

00:20:42,859 --> 00:20:47,989
change happen I think bun to 12 by 4 or

00:20:45,499 --> 00:20:49,489
just after that so now desktop and

00:20:47,989 --> 00:20:52,909
server there's no difference in the

00:20:49,489 --> 00:20:54,499
kernel the CPU is not the only thing

00:20:52,909 --> 00:20:56,929
that can have concurrent access troubles

00:20:54,499 --> 00:20:58,789
lots of tasks don't fit on one CPUs

00:20:56,929 --> 00:21:00,259
execute instructions and perform betters

00:20:58,789 --> 00:21:02,749
on the better on the kind of processes

00:21:00,259 --> 00:21:04,729
that graphics processing units have this

00:21:02,749 --> 00:21:06,759
includes 3d rendering video encoding and

00:21:04,729 --> 00:21:09,409
decoding machine learning that's what

00:21:06,759 --> 00:21:11,059
however GPUs generally don't have memory

00:21:09,409 --> 00:21:12,859
management units on them and some

00:21:11,059 --> 00:21:16,099
applications could corrupt graphics or

00:21:12,859 --> 00:21:18,470
data offer programs Windows Vista and up

00:21:16,099 --> 00:21:20,599
has a display driver model that provides

00:21:18,470 --> 00:21:23,210
both memory segmentation for GPU using

00:21:20,599 --> 00:21:25,279
applications as well as GPU time slicing

00:21:23,210 --> 00:21:28,820
disallowing any one application from

00:21:25,279 --> 00:21:31,519
monopolizing it so we've talked about

00:21:28,820 --> 00:21:34,570
CPUs and operating systems what does

00:21:31,519 --> 00:21:37,249
this all mean when we apply it to Python

00:21:34,570 --> 00:21:39,649
it's really easy to write multi-threaded

00:21:37,249 --> 00:21:41,210
Python code the problem is that because

00:21:39,649 --> 00:21:41,899
of concurrency issues inside the

00:21:41,210 --> 00:21:44,210
interpreter

00:21:41,899 --> 00:21:46,489
Python doesn't actually run Python code

00:21:44,210 --> 00:21:48,979
in multiple threads the global

00:21:46,489 --> 00:21:50,809
interpreter lock or Jil means that only

00:21:48,979 --> 00:21:52,669
one thread in the Python process is

00:21:50,809 --> 00:21:55,849
actually executing Python at any one

00:21:52,669 --> 00:21:57,849
time this has the benefit of thanking

00:21:55,849 --> 00:22:00,849
all of concurrency problems not happen

00:21:57,849 --> 00:22:03,080
by making - effectively non-concurrent

00:22:00,849 --> 00:22:05,029
this doesn't shield you from CX

00:22:03,080 --> 00:22:06,980
engines however brittle which released

00:22:05,029 --> 00:22:08,570
the global interpreter lock so if you

00:22:06,980 --> 00:22:10,309
pass a plastic object into a sixth

00:22:08,570 --> 00:22:12,200
engine it can potentially read and

00:22:10,309 --> 00:22:15,289
access it in a non thread safe way and

00:22:12,200 --> 00:22:18,970
cause avoids the impossible bugs the C

00:22:15,289 --> 00:22:18,970
extension itself may not be thread safe

00:22:22,809 --> 00:22:27,230
another option is to avoid threads as

00:22:25,220 --> 00:22:29,529
much as possible and you said adopt

00:22:27,230 --> 00:22:31,970
cooperative multitasking practices

00:22:29,529 --> 00:22:33,830
Python asynchronous i/o frameworks such

00:22:31,970 --> 00:22:36,230
as icing hire tornado and twisted

00:22:33,830 --> 00:22:38,000
implement this s/t frameworks in other

00:22:36,230 --> 00:22:39,190
languages like Ruby's event machine and

00:22:38,000 --> 00:22:41,419
nodejs

00:22:39,190 --> 00:22:43,850
but since we're only in a single thread

00:22:41,419 --> 00:22:46,880
things that block need not be used

00:22:43,850 --> 00:22:49,039
this means no blanks or calls to sockets

00:22:46,880 --> 00:22:50,690
or files and we have to somehow support

00:22:49,039 --> 00:22:53,059
every connection we might make to the

00:22:50,690 --> 00:22:54,260
external world without putting it we

00:22:53,059 --> 00:22:55,789
have to support being able to maintain

00:22:54,260 --> 00:22:59,120
external connections without putting it

00:22:55,789 --> 00:23:01,250
in a thread the problem of how to handle

00:22:59,120 --> 00:23:03,769
many connections in one thread is a big

00:23:01,250 --> 00:23:05,960
one but not insurmountable every modern

00:23:03,769 --> 00:23:07,399
operating system ships of some method of

00:23:05,960 --> 00:23:10,519
implementing non-blocking and

00:23:07,399 --> 00:23:12,139
synchronous i/o every windows a program

00:23:10,519 --> 00:23:14,960
is event driven at the core so I owe

00:23:12,139 --> 00:23:17,870
completion ports has a callback designer

00:23:14,960 --> 00:23:19,789
fits very well in it on Linux and UNIX

00:23:17,870 --> 00:23:22,309
based operating systems we have select a

00:23:19,789 --> 00:23:25,039
pole and kqu to pick from depending on

00:23:22,309 --> 00:23:26,750
which kernel use these kernel api is by

00:23:25,039 --> 00:23:30,019
calling them with lists of sockets and

00:23:26,750 --> 00:23:33,679
it tells you which ones you can send or

00:23:30,019 --> 00:23:36,529
receive on and if you can't send or

00:23:33,679 --> 00:23:39,889
receive on them you just buffer its fits

00:23:36,529 --> 00:23:42,350
well into an event-driven system these

00:23:39,889 --> 00:23:44,360
techniques work and it does scale it's

00:23:42,350 --> 00:23:45,889
how a twisted or async I application can

00:23:44,360 --> 00:23:48,110
support thousands of connections on a

00:23:45,889 --> 00:23:49,720
single core and how nginx can drive

00:23:48,110 --> 00:23:52,340
massive amounts of traffic efficiently

00:23:49,720 --> 00:23:53,779
plus you can support new processors and

00:23:52,340 --> 00:23:55,820
communicate with them asynchronously as

00:23:53,779 --> 00:23:57,769
well allowing you to execute long

00:23:55,820 --> 00:24:00,139
running our requirements asks that don't

00:23:57,769 --> 00:24:02,210
otherwise fit the event-driven design of

00:24:00,139 --> 00:24:05,929
communicating with them in a way that

00:24:02,210 --> 00:24:07,929
does of course we're still at the mercy

00:24:05,929 --> 00:24:10,309
of the operating system thread scheduler

00:24:07,929 --> 00:24:11,750
even if we're not paying the costs of

00:24:10,309 --> 00:24:13,460
thread switching in our application

00:24:11,750 --> 00:24:16,120
itself we have to play nice with

00:24:13,460 --> 00:24:16,120
everyone else

00:24:19,180 --> 00:24:23,990
reducing thread contention is important

00:24:21,770 --> 00:24:26,140
as if there's less threads competing for

00:24:23,990 --> 00:24:28,640
run time your time slice can be bigger

00:24:26,140 --> 00:24:30,650
if you still do have a lot of threads

00:24:28,640 --> 00:24:31,580
but multiple calls you can use an

00:24:30,650 --> 00:24:33,320
operating system called

00:24:31,580 --> 00:24:35,840
operating system feature called affinity

00:24:33,320 --> 00:24:38,360
to force a process to stay on a

00:24:35,840 --> 00:24:40,220
particular core if you can keep your

00:24:38,360 --> 00:24:42,500
important worker thread on its own CPU

00:24:40,220 --> 00:24:44,240
and so it's priority high enough you're

00:24:42,500 --> 00:24:46,010
sure to get long uninterrupted time

00:24:44,240 --> 00:24:47,750
slices and will increase the performance

00:24:46,010 --> 00:24:50,450
of your single threaded event-driven

00:24:47,750 --> 00:24:54,380
application or even your application

00:24:50,450 --> 00:24:55,640
that uses threads if you do need to use

00:24:54,380 --> 00:24:57,200
threads and let's face it some

00:24:55,640 --> 00:24:59,600
particular api's don't come

00:24:57,200 --> 00:25:02,210
asynchronously you can reduce the memory

00:24:59,600 --> 00:25:04,430
overhead by altering the stack every

00:25:02,210 --> 00:25:06,530
thread need needs its own working stack

00:25:04,430 --> 00:25:08,960
and sometimes that could be set far too

00:25:06,530 --> 00:25:10,490
high if you have a hundred threads on

00:25:08,960 --> 00:25:13,190
your system and each had a megabyte of

00:25:10,490 --> 00:25:16,070
stank that's 100 megabytes of overhead

00:25:13,190 --> 00:25:17,510
right there you can configure how big

00:25:16,070 --> 00:25:20,890
the stack size is for your particular

00:25:17,510 --> 00:25:23,300
application when you spawn the thread

00:25:20,890 --> 00:25:25,330
usually if you start a thread to do some

00:25:23,300 --> 00:25:27,800
processing you will want some data back

00:25:25,330 --> 00:25:29,090
but communication between threads can be

00:25:27,800 --> 00:25:31,100
difficult if you don't have something

00:25:29,090 --> 00:25:33,440
like the jail to protect you as you have

00:25:31,100 --> 00:25:35,450
to manage your own synchronization if

00:25:33,440 --> 00:25:37,550
you put this task in a normal process

00:25:35,450 --> 00:25:39,790
and communicate over some sort of

00:25:37,550 --> 00:25:43,460
bi-directional bus such as a UNIX socket

00:25:39,790 --> 00:25:46,520
pipes or TCP then there is no directly

00:25:43,460 --> 00:25:47,750
shared state involved this does now make

00:25:46,520 --> 00:25:49,550
your application effectively a

00:25:47,750 --> 00:25:52,040
distribute system with all the problems

00:25:49,550 --> 00:25:54,050
that has the task managers exist to take

00:25:52,040 --> 00:25:57,140
some of the issues out of it and there's

00:25:54,050 --> 00:25:59,180
ways to get around it additionally if

00:25:57,140 --> 00:26:00,680
you communicate over some pipe with

00:25:59,180 --> 00:26:02,990
different portions of your application

00:26:00,680 --> 00:26:06,080
so using easy to turn those pipes into

00:26:02,990 --> 00:26:08,630
say a TCP and move it off the machine if

00:26:06,080 --> 00:26:15,220
it gets too big we all know where that

00:26:08,630 --> 00:26:15,220
leads thank you

00:26:20,520 --> 00:26:27,240
hi I've still got five minutes okay

00:26:24,830 --> 00:26:30,240
we've time yeah I'll take I'll take a

00:26:27,240 --> 00:26:32,250
question or two thank you so much amber

00:26:30,240 --> 00:26:34,800
there's time for one question or maybe

00:26:32,250 --> 00:26:36,240
two if they're very short so please try

00:26:34,800 --> 00:26:39,120
and make them short and make them

00:26:36,240 --> 00:26:42,929
questions as they say anyone please do

00:26:39,120 --> 00:26:49,890
not ask about the gel also don't ask

00:26:42,929 --> 00:26:52,140
about the Jill no no no takers I do I do

00:26:49,890 --> 00:26:55,620
have one it's the story of our

00:26:52,140 --> 00:26:58,710
concurrency lately in Python 3 and also

00:26:55,620 --> 00:27:02,610
back ported to Python 2 is async i/o

00:26:58,710 --> 00:27:05,309
what is your take on that as a practical

00:27:02,610 --> 00:27:08,280
solution and the future evolution of it

00:27:05,309 --> 00:27:10,470
well so just to know is the Python 2

00:27:08,280 --> 00:27:13,320
back port of async is deprecated instant

00:27:10,470 --> 00:27:16,130
user so you should just use Python 3

00:27:13,320 --> 00:27:19,590
basically our Python 3 is great

00:27:16,130 --> 00:27:21,990
it's very well acing the method of doing

00:27:19,590 --> 00:27:24,179
what async has done has been proven to

00:27:21,990 --> 00:27:26,850
be popular in Python in the past we've

00:27:24,179 --> 00:27:28,500
tornado and twisted the future of a

00:27:26,850 --> 00:27:31,230
cinco and all of that is basically

00:27:28,500 --> 00:27:33,630
getting getting and normalized in the

00:27:31,230 --> 00:27:36,630
community that you ship libraries that

00:27:33,630 --> 00:27:39,360
are asynchronous compatible because

00:27:36,630 --> 00:27:41,130
right now if you people install requests

00:27:39,360 --> 00:27:43,140
and use requests in your async i/o

00:27:41,130 --> 00:27:44,429
application it just doesn't work you end

00:27:43,140 --> 00:27:46,920
up walking and then you're just throwing

00:27:44,429 --> 00:27:48,540
the event driven system away so I think

00:27:46,920 --> 00:27:50,790
the future is people adopting it seeing

00:27:48,540 --> 00:27:52,530
the benefits of it it does have its

00:27:50,790 --> 00:27:54,390
benefits it does does have its downsides

00:27:52,530 --> 00:27:57,600
if you're doing a lot of CPU sort of

00:27:54,390 --> 00:27:59,520
sort of stuff then multi processing or

00:27:57,600 --> 00:28:01,350
multi-threading multi processing if it's

00:27:59,520 --> 00:28:03,900
all in Python is a much better idea than

00:28:01,350 --> 00:28:05,580
using async i/o but a lot of us write

00:28:03,900 --> 00:28:08,420
web applications that maybe have lots

00:28:05,580 --> 00:28:11,280
and lots of users and supporting those

00:28:08,420 --> 00:28:13,740
in a classical system like just rain

00:28:11,280 --> 00:28:15,809
Jango with unicorn you end up with a lot

00:28:13,740 --> 00:28:18,090
more servers and all more threads and

00:28:15,809 --> 00:28:20,880
you maybe want to while if you're just

00:28:18,090 --> 00:28:23,130
talking to a database which is a easily

00:28:20,880 --> 00:28:24,809
asynchronous operation then a single

00:28:23,130 --> 00:28:28,020
async aerial application can serve

00:28:24,809 --> 00:28:30,660
thousands of users a minute it's

00:28:28,020 --> 00:28:32,880
basically the the futures all depends on

00:28:30,660 --> 00:28:34,110
people using it if people will adopt it

00:28:32,880 --> 00:28:34,350
and pick it up then it's going to be a

00:28:34,110 --> 00:28:36,720
very

00:28:34,350 --> 00:28:38,100
right feet future if no one picks it up

00:28:36,720 --> 00:28:41,760
and we all just keep doing what we're

00:28:38,100 --> 00:28:44,070
doing then your and it'll you know

00:28:41,760 --> 00:28:46,980
not not advanced so you should probably

00:28:44,070 --> 00:28:48,480
look into it if you haven't or twisted

00:28:46,980 --> 00:28:50,610
twisted also works if you stuck on

00:28:48,480 --> 00:28:52,320
Python to christen a cinco have

00:28:50,610 --> 00:28:56,460
compatibility layers between each other

00:28:52,320 --> 00:28:58,350
as do tornado so you don't have to be

00:28:56,460 --> 00:29:00,600
sort of a hold on to any one of them you

00:28:58,350 --> 00:29:03,570
can sort of pick and choose working on

00:29:00,600 --> 00:29:06,900
that a bit more Python three seven will

00:29:03,570 --> 00:29:08,669
have a lot more features in a in that

00:29:06,900 --> 00:29:10,169
department allowing you to sort of pick

00:29:08,669 --> 00:29:12,570
and choose your asynchronous framework

00:29:10,169 --> 00:29:15,570
and have them all I cooperate together

00:29:12,570 --> 00:29:17,280
in the same process without without you

00:29:15,570 --> 00:29:18,750
know having to put twisty and one thread

00:29:17,280 --> 00:29:20,010
and a singer and one thread and working

00:29:18,750 --> 00:29:21,780
out how to communicate between them

00:29:20,010 --> 00:29:27,650
they'll all just run on the AC guy

00:29:21,780 --> 00:29:27,650

YouTube URL: https://www.youtube.com/watch?v=gJ6loj3nB4s


