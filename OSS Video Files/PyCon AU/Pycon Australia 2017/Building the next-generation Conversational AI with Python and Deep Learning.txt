Title: Building the next-generation Conversational AI with Python and Deep Learning
Publication date: 2017-08-04
Playlist: Pycon Australia 2017
Description: 
	David Low Jia Wei

http://2017.pycon-au.org/schedule/presentation/57/

#pyconau

This talk was given at PyCon Australia 2017 which was held from 3-8 August, 2017 in Melbourne, Victoria.

PyCon Australia is the national conference for users of the Python Programming Language. In August 2017, we're returning to Melbourne, bringing together students, enthusiasts, and professionals with a love of Python from around Australia, and from all over the World. 

August 3-8 2017, Melbourne, Victoria

Python, PyCon, PyConAU
Captions: 
	00:00:00,620 --> 00:00:05,670
so our next talk for this session and

00:00:04,350 --> 00:00:08,580
the last talk for this session before

00:00:05,670 --> 00:00:09,889
morning tea is by David Lowe and is on

00:00:08,580 --> 00:00:12,809
building the next generation

00:00:09,889 --> 00:00:15,210
conversational AI with Python and deep

00:00:12,809 --> 00:00:17,430
learning David has come from Singapore

00:00:15,210 --> 00:00:20,720
where he is the founder and chief

00:00:17,430 --> 00:00:24,330
scientist of a startup called pan ji

00:00:20,720 --> 00:00:28,650
David's background is in a range of data

00:00:24,330 --> 00:00:30,359
science and AI technologies he

00:00:28,650 --> 00:00:31,980
represented Singapore and the National

00:00:30,359 --> 00:00:35,399
University of Singapore in the data

00:00:31,980 --> 00:00:37,200
science games last year clinched top

00:00:35,399 --> 00:00:40,170
spot amongst the Asian American teams

00:00:37,200 --> 00:00:43,260
there he's been a guest lecturer at

00:00:40,170 --> 00:00:45,210
universities he has worked with in

00:00:43,260 --> 00:00:50,219
research projects with universities like

00:00:45,210 --> 00:00:52,469
Carnegie Mellon and the and MIT for fun

00:00:50,219 --> 00:00:56,160
he competes on Kegel and is ranked in

00:00:52,469 --> 00:00:57,840
the top 0.2 percent he's also an avid

00:00:56,160 --> 00:01:00,329
Python developer which is good because

00:00:57,840 --> 00:01:02,160
we are at a Python conference and so

00:01:00,329 --> 00:01:04,799
he's here today to talk about AI chat

00:01:02,160 --> 00:01:09,890
bot technologies and how that fits into

00:01:04,799 --> 00:01:09,890
deep natural language processing David a

00:01:18,560 --> 00:01:25,650
very good morning I'm David from

00:01:21,479 --> 00:01:28,229
Singapore so it's my first time to in

00:01:25,650 --> 00:01:33,619
fact to Australia and my first hike on a

00:01:28,229 --> 00:01:37,560
oh so great - great to see you guys okay

00:01:33,619 --> 00:01:40,140
so for those who read my abstract for

00:01:37,560 --> 00:01:42,750
the tour I actually make some changes to

00:01:40,140 --> 00:01:46,380
the content to cater for the timetable

00:01:42,750 --> 00:01:46,920
change but I thought the toast only got

00:01:46,380 --> 00:01:48,720
15 minutes

00:01:46,920 --> 00:01:51,180
I realize it's two different minutes so

00:01:48,720 --> 00:01:55,619
I guess we could have a longer day

00:01:51,180 --> 00:01:59,729
sessions yeah okay so in this fast-paced

00:01:55,619 --> 00:02:02,040
world customer very often they require

00:01:59,729 --> 00:02:05,790
the demand efficiencies when they're

00:02:02,040 --> 00:02:08,129
trying to talk to the company so so very

00:02:05,790 --> 00:02:10,560
often we see like customer complaining

00:02:08,129 --> 00:02:12,810
on the social media that they they have

00:02:10,560 --> 00:02:13,830
been waiting on the phone for 3045

00:02:12,810 --> 00:02:15,600
minutes

00:02:13,830 --> 00:02:19,140
trying to get to talk to the customer

00:02:15,600 --> 00:02:21,450
service so here come chatbots

00:02:19,140 --> 00:02:25,680
shabbat is an automated conversation

00:02:21,450 --> 00:02:30,800
agents that helps company to communicate

00:02:25,680 --> 00:02:33,390
to their customers via voice or text and

00:02:30,800 --> 00:02:36,150
the main purpose is to streamline the

00:02:33,390 --> 00:02:38,400
interactions between the people and the

00:02:36,150 --> 00:02:42,990
chibok around the clock so you work 24/7

00:02:38,400 --> 00:02:45,150
without any break so shahboz are

00:02:42,990 --> 00:02:49,410
beneficial to both parties the customer

00:02:45,150 --> 00:02:51,900
and a company so because it's cheaper to

00:02:49,410 --> 00:02:55,020
develop a chatbots compared to trainer

00:02:51,900 --> 00:02:57,120
humans and is more scalable so it wants

00:02:55,020 --> 00:02:58,680
these trained you just can leave it

00:02:57,120 --> 00:03:02,250
there and through machine learning you

00:02:58,680 --> 00:03:04,140
get better and better when when is when

00:03:02,250 --> 00:03:09,530
he has talked to more customer gather

00:03:04,140 --> 00:03:13,290
more conversation history okay so from

00:03:09,530 --> 00:03:16,080
Apple Siri to Amazon Alexa so we have

00:03:13,290 --> 00:03:18,900
seen this Shabbat everywhere however

00:03:16,080 --> 00:03:22,830
there are plenty of Sawadee Don Chao

00:03:18,900 --> 00:03:24,480
bots in the market so that which utilize

00:03:22,830 --> 00:03:27,660
more stressful approach like pattern

00:03:24,480 --> 00:03:29,550
matching or rule-based approach so today

00:03:27,660 --> 00:03:31,920
I will share some something about

00:03:29,550 --> 00:03:37,100
building the so called next generations

00:03:31,920 --> 00:03:37,100
conversation AI using Python I'm Denali

00:03:39,440 --> 00:03:45,720
yeah so it's the overview of my top

00:03:42,510 --> 00:03:51,090
today suggest I share about the current

00:03:45,720 --> 00:03:53,340
state of the conversational AI and we

00:03:51,090 --> 00:03:57,410
talk about initiative from Facebook in

00:03:53,340 --> 00:04:01,980
fact from their group Facebook

00:03:57,410 --> 00:04:04,230
artificial intelligence that which is

00:04:01,980 --> 00:04:08,640
about the dialogue research platform

00:04:04,230 --> 00:04:14,269
called poly then I will show a demo of a

00:04:08,640 --> 00:04:16,890
question answering systems followed by a

00:04:14,269 --> 00:04:20,940
something that caught in the news

00:04:16,890 --> 00:04:23,400
recently about Facebook research and

00:04:20,940 --> 00:04:26,460
lastly will share about what we learned

00:04:23,400 --> 00:04:27,710
as I mean yes panda in Singapore after

00:04:26,460 --> 00:04:30,319
we done

00:04:27,710 --> 00:04:36,020
launched to chat BOTS with two big

00:04:30,319 --> 00:04:38,539
trends and to press clients yeah so okay

00:04:36,020 --> 00:04:41,360
well Siri and excite and the lights can

00:04:38,539 --> 00:04:43,789
follow simple spoken or typed commands

00:04:41,360 --> 00:04:46,430
and answer basic questions obviously

00:04:43,789 --> 00:04:48,979
they can't hold conversations like a

00:04:46,430 --> 00:04:52,759
human and have no real understanding of

00:04:48,979 --> 00:04:56,210
the words they use and this is from you

00:04:52,759 --> 00:05:02,870
is the senior editor from MIT Technology

00:04:56,210 --> 00:05:04,490
Review Leslie yeah it shows the current

00:05:02,870 --> 00:05:06,800
limitations of the technologies when you

00:05:04,490 --> 00:05:12,410
apply to chat BOTS most of Shaba in the

00:05:06,800 --> 00:05:13,940
markets okay so sadly most of the chat

00:05:12,410 --> 00:05:17,690
BOTS available on the market are

00:05:13,940 --> 00:05:20,139
actually a glorified IVR in case you

00:05:17,690 --> 00:05:23,110
have no idea idea is stands for

00:05:20,139 --> 00:05:26,030
interactive voice response system so

00:05:23,110 --> 00:05:30,229
this had a system that may try to call

00:05:26,030 --> 00:05:32,449
the bank then you press one to ask about

00:05:30,229 --> 00:05:35,090
credit card press two about banking's

00:05:32,449 --> 00:05:36,949
so in this case the shabbat doesn't

00:05:35,090 --> 00:05:42,490
really understand natural language so

00:05:36,949 --> 00:05:42,490
and is programmed to ask you a certain

00:05:43,570 --> 00:05:48,289
depends on the user action Zoe please

00:05:45,740 --> 00:05:49,969
want you to press on the button sir to

00:05:48,289 --> 00:05:51,830
book a test drive but you just could

00:05:49,969 --> 00:05:55,370
understand like show me your latest

00:05:51,830 --> 00:05:57,500
model then you prom you to give her

00:05:55,370 --> 00:06:04,280
stuck commands again then lead you to

00:05:57,500 --> 00:06:06,590
book a test drive the second example is

00:06:04,280 --> 00:06:10,159
yeah no matter why your time we just

00:06:06,590 --> 00:06:14,150
keep prompting you to fix story bots or

00:06:10,159 --> 00:06:16,130
guided conversations so these are the

00:06:14,150 --> 00:06:19,280
bots that could have the match natural

00:06:16,130 --> 00:06:24,310
language so you just keep pushing our

00:06:19,280 --> 00:06:32,650
buttons as you to react to the buttons

00:06:24,310 --> 00:06:35,659
so moving forward Facebook has and

00:06:32,650 --> 00:06:39,020
release this dialogue research software

00:06:35,659 --> 00:06:41,420
platforms and the logo is a pirate

00:06:39,020 --> 00:06:45,920
parrots name is called

00:06:41,420 --> 00:06:48,650
poly and it's developed in patterns so

00:06:45,920 --> 00:06:51,470
the okay so the purpose is to provide an

00:06:48,650 --> 00:06:54,230
unified framework for training and

00:06:51,470 --> 00:06:56,180
testing of dialogue models so that to

00:06:54,230 --> 00:06:58,040
any enabled' check-box to converse

00:06:56,180 --> 00:07:00,680
battle compared to the shabbat you have

00:06:58,040 --> 00:07:03,620
seen like just now so the green the

00:07:00,680 --> 00:07:06,230
grand vision is to enable assist more

00:07:03,620 --> 00:07:08,960
systemic developments and evaluations of

00:07:06,230 --> 00:07:12,530
dialogue agents help to help push the

00:07:08,960 --> 00:07:14,000
state of the art type the

00:07:12,530 --> 00:07:16,520
state-of-the-art technology in dialogue

00:07:14,000 --> 00:07:17,000
further and benefits the field as a

00:07:16,520 --> 00:07:22,040
whole

00:07:17,000 --> 00:07:24,350
so wow it's not what are called tech

00:07:22,040 --> 00:07:27,640
technology breakthrough is definitely a

00:07:24,350 --> 00:07:33,170
great initiative to standardize the

00:07:27,640 --> 00:07:35,570
dialogue research so here he had a few

00:07:33,170 --> 00:07:37,430
of the main features so you know he has

00:07:35,570 --> 00:07:41,480
these integrations of Amazon Mechanical

00:07:37,430 --> 00:07:44,690
Turk and its support multitask training

00:07:41,480 --> 00:07:49,490
I wish will be elaborating more about

00:07:44,690 --> 00:07:52,790
Marita's training and it has a built in

00:07:49,490 --> 00:07:58,700
data set for about 20 tasks which I will

00:07:52,790 --> 00:08:01,430
be sharing more theta okay and you can

00:07:58,700 --> 00:08:08,200
find more information on PA are out of

00:08:01,430 --> 00:08:09,610
AI so officer website ok so this is the

00:08:08,200 --> 00:08:13,070
[Music]

00:08:09,610 --> 00:08:16,250
live chat interface they built in the

00:08:13,070 --> 00:08:20,620
poly platforms so over here you can see

00:08:16,250 --> 00:08:24,710
this this user interface allowed the

00:08:20,620 --> 00:08:28,190
researcher to provide a short passage of

00:08:24,710 --> 00:08:30,830
content then you ask the humans to give

00:08:28,190 --> 00:08:34,670
provided questions given this context

00:08:30,830 --> 00:08:37,729
and then you ask again the same the same

00:08:34,670 --> 00:08:40,010
agents the humans to give answers so

00:08:37,729 --> 00:08:43,220
through this way they are referred to

00:08:40,010 --> 00:08:44,540
gather data in fact right no matter what

00:08:43,220 --> 00:08:48,290
you're working on like machine learning

00:08:44,540 --> 00:08:50,480
deep learning the most important thing I

00:08:48,290 --> 00:08:53,600
would say is the data so without data

00:08:50,480 --> 00:08:56,810
you can do any machine any model

00:08:53,600 --> 00:08:59,300
and we need high quality data because as

00:08:56,810 --> 00:09:01,459
the saying goes rubbish in rubbish out

00:08:59,300 --> 00:09:06,880
you can't expect a machine any model to

00:09:01,459 --> 00:09:10,310
generate insights from noisy noisy data

00:09:06,880 --> 00:09:12,170
so an important part of pal a is the

00:09:10,310 --> 00:09:15,550
seamless integrations with the

00:09:12,170 --> 00:09:19,370
mechanical tax for data collections

00:09:15,550 --> 00:09:22,579
training and evaluations so this

00:09:19,370 --> 00:09:25,790
interface show the data collection part

00:09:22,579 --> 00:09:28,130
in fact they also have this evaluation

00:09:25,790 --> 00:09:30,649
part where they ask the humans to rate

00:09:28,130 --> 00:09:33,350
the answers given by the model so in

00:09:30,649 --> 00:09:35,029
this case they you they can use that

00:09:33,350 --> 00:09:39,259
feedback to further improve that model

00:09:35,029 --> 00:09:42,860
so the human talkers in this case are

00:09:39,259 --> 00:09:47,750
also view as agents in police free mode

00:09:42,860 --> 00:09:51,889
so right person to percents dialogues

00:09:47,750 --> 00:09:53,839
persons to watts dialogue or even multi

00:09:51,889 --> 00:09:59,930
people and bots in a group chat context

00:09:53,839 --> 00:10:01,750
it can be realized in this framework so

00:09:59,930 --> 00:10:06,019
all this row can be switched without

00:10:01,750 --> 00:10:08,440
code changes in the code changes to the

00:10:06,019 --> 00:10:08,440
agents

00:10:13,140 --> 00:10:19,290
okay so the convention conventional

00:10:17,040 --> 00:10:21,959
machine learning approach right usually

00:10:19,290 --> 00:10:23,850
we UPE a particular metric to optimize

00:10:21,959 --> 00:10:25,860
let's say one should predict do a

00:10:23,850 --> 00:10:29,269
regression predict a finger or you say

00:10:25,860 --> 00:10:31,320
root-mean-square oh I see or to do

00:10:29,269 --> 00:10:34,440
classifications problem there maybe you

00:10:31,320 --> 00:10:36,000
pick a you see so conventional machine

00:10:34,440 --> 00:10:40,610
learning approach we try to optimize for

00:10:36,000 --> 00:10:43,079
a specific a particular matrix and

00:10:40,610 --> 00:10:46,589
usually what we do is between a either a

00:10:43,079 --> 00:10:49,470
single model or we train and send both

00:10:46,589 --> 00:10:53,940
models of multiple simple or single

00:10:49,470 --> 00:10:56,550
models then we fine-tune the that model

00:10:53,940 --> 00:10:59,670
or those model and simple model and took

00:10:56,550 --> 00:11:02,010
it to parameters to try to achieve the

00:10:59,670 --> 00:11:04,980
highest score in terms of that matrix we

00:11:02,010 --> 00:11:08,279
identify just now so for multi-touch

00:11:04,980 --> 00:11:11,430
learning okay multitask learning is also

00:11:08,279 --> 00:11:13,829
known as dry learning learning to learn

00:11:11,430 --> 00:11:17,940
interfaces and it's not a new concept

00:11:13,829 --> 00:11:21,060
has been known for quite a while okay so

00:11:17,940 --> 00:11:23,910
what differentiate multitask from

00:11:21,060 --> 00:11:25,649
conventional approaches optimize for

00:11:23,910 --> 00:11:27,029
more than one loss functions that you

00:11:25,649 --> 00:11:31,490
can consider as a multi-touch learning

00:11:27,029 --> 00:11:35,390
and why why we need multitask learning

00:11:31,490 --> 00:11:37,949
okay so it helps by improving the

00:11:35,390 --> 00:11:40,740
generalizations and by leveraging on the

00:11:37,949 --> 00:11:45,660
domain specific information contained in

00:11:40,740 --> 00:11:49,800
the training signals of related tasks so

00:11:45,660 --> 00:11:53,610
yeah so why we need generalizations so

00:11:49,800 --> 00:11:55,880
because it prevents overheating so you

00:11:53,610 --> 00:11:58,170
do see of overfitting of the model

00:11:55,880 --> 00:12:00,449
against the specific data set we are

00:11:58,170 --> 00:12:02,399
working on and encourage the model to

00:12:00,449 --> 00:12:04,610
perform something called task transfer

00:12:02,399 --> 00:12:09,480
so we learn across different tasks and

00:12:04,610 --> 00:12:11,430
gain more insight compared to just focus

00:12:09,480 --> 00:12:13,910
on one task and learning on the same

00:12:11,430 --> 00:12:13,910
data sets

00:12:18,280 --> 00:12:28,190
okay so okay yeah the 20-day assets

00:12:22,070 --> 00:12:30,920
included in the poly platforms so we

00:12:28,190 --> 00:12:34,130
have QA is question answering datasets

00:12:30,920 --> 00:12:37,160
this is from Stanford and for this one

00:12:34,130 --> 00:12:40,340
is simulated data from Facebook would be

00:12:37,160 --> 00:12:43,010
a Barbie task yeah we have some other

00:12:40,340 --> 00:12:45,980
tasks like go or enter dialogue some

00:12:43,010 --> 00:12:50,420
other data sets then we have a sentence

00:12:45,980 --> 00:12:53,150
completions data sets and just use just

00:12:50,420 --> 00:12:55,640
a dialogue chitchat data sets which you

00:12:53,150 --> 00:12:58,910
have something from the open to open

00:12:55,640 --> 00:13:03,290
forums we have movie sub ready ready

00:12:58,910 --> 00:13:04,970
data set under the movies even like open

00:13:03,290 --> 00:13:07,970
subtitles data sets so you have the

00:13:04,970 --> 00:13:10,310
subtitles from the other movies and

00:13:07,970 --> 00:13:13,010
lastly we have the vision QA which

00:13:10,310 --> 00:13:19,220
basically have data set related to

00:13:13,010 --> 00:13:23,800
images or media yeah so what we can do

00:13:19,220 --> 00:13:27,140
with all these data sets okay so okay so

00:13:23,800 --> 00:13:30,880
this data set are being organized into

00:13:27,140 --> 00:13:34,910
five categories each respond to the task

00:13:30,880 --> 00:13:37,730
so question answering is the simplest

00:13:34,910 --> 00:13:39,830
form of dialogue is a so every time I

00:13:37,730 --> 00:13:41,570
asked one questions and what kept back

00:13:39,830 --> 00:13:44,450
with one answers then I follow if

00:13:41,570 --> 00:13:46,640
another questions this is a simplest

00:13:44,450 --> 00:13:48,500
forms and we have the sentence

00:13:46,640 --> 00:13:51,410
completion which also known as the

00:13:48,500 --> 00:13:52,850
Clause test basically trying to give it

00:13:51,410 --> 00:13:55,910
a center and try to fill in about the

00:13:52,850 --> 00:14:00,230
missing words then we have the

00:13:55,910 --> 00:14:03,050
goal-oriented dialogue which okay so

00:14:00,230 --> 00:14:06,560
what this means is usually maybe for

00:14:03,050 --> 00:14:09,530
example I have a movie booking BOTS so

00:14:06,560 --> 00:14:14,260
the goal is to have the customers bullet

00:14:09,530 --> 00:14:16,940
in the ends then we have chit chat use

00:14:14,260 --> 00:14:20,930
dialogue without a specific goal so some

00:14:16,940 --> 00:14:22,520
like more of our discussions then we

00:14:20,930 --> 00:14:24,740
have a Vishu dialogue which we try to

00:14:22,520 --> 00:14:26,270
answers or ask questions answers

00:14:24,740 --> 00:14:29,950
questions based on the image or the

00:14:26,270 --> 00:14:29,950
media de provide

00:14:33,210 --> 00:14:39,850
okay so yeah so we have work on

00:14:37,330 --> 00:14:43,480
something on the question answering

00:14:39,850 --> 00:14:48,300
so let me brings up the demo first let

00:14:43,480 --> 00:14:48,300
me introduce the data sets working on

00:15:33,400 --> 00:15:40,060
okay school is actually open source the

00:15:37,800 --> 00:15:45,850
question-answering datasets from

00:15:40,060 --> 00:15:47,800
Stanford okay so this is the website you

00:15:45,850 --> 00:15:49,990
can download a test data set here and

00:15:47,800 --> 00:15:53,589
there's a needle walk that you can

00:15:49,990 --> 00:15:56,500
submit your the mesquite submit your

00:15:53,589 --> 00:15:59,560
model and you can see how well your

00:15:56,500 --> 00:16:02,740
model performs against other model from

00:15:59,560 --> 00:16:06,400
other research institutes so let's just

00:16:02,740 --> 00:16:11,070
look at the data so yeah so okay so

00:16:06,400 --> 00:16:15,580
right now the ever 100,000 articles and

00:16:11,070 --> 00:16:20,080
maybe you can just goes to one of it so

00:16:15,580 --> 00:16:22,060
this obviously short passage extracted

00:16:20,080 --> 00:16:27,339
from Wikipedia in this case is about

00:16:22,060 --> 00:16:30,010
Nikola Tesla so and this is the training

00:16:27,339 --> 00:16:31,690
the label data done by human so for

00:16:30,010 --> 00:16:36,060
example these questions in what year was

00:16:31,690 --> 00:16:41,140
Nikola Tesla blondes and the answer is

00:16:36,060 --> 00:16:43,750
1856 okay so the 3d humans ask questions

00:16:41,140 --> 00:16:46,750
and the humans have to labor the answers

00:16:43,750 --> 00:16:49,930
from the passage in this case if you

00:16:46,750 --> 00:16:52,720
record a mechanical you I so you get to

00:16:49,930 --> 00:16:55,690
crap on the passage to identify the

00:16:52,720 --> 00:16:57,880
answers from the passage of all the

00:16:55,690 --> 00:17:00,940
paragraph so we have other questions

00:16:57,880 --> 00:17:04,959
this one is related to the year and this

00:17:00,940 --> 00:17:09,309
is about the NCT and the yoga and like

00:17:04,959 --> 00:17:16,929
home country to graphical occasions and

00:17:09,309 --> 00:17:20,770
some short phrases and looking at is

00:17:16,929 --> 00:17:23,589
that trainee data so after we train the

00:17:20,770 --> 00:17:27,880
model on this hundred thousands data

00:17:23,589 --> 00:17:29,530
sets then we have a system that can

00:17:27,880 --> 00:17:32,320
perform crashing sorry

00:17:29,530 --> 00:17:36,640
so because this is my first time to

00:17:32,320 --> 00:17:39,190
happen so I go to the Wikipedia and grab

00:17:36,640 --> 00:17:43,450
a few paragraph about Mel burns and

00:17:39,190 --> 00:17:45,570
paste it into my systems so the the

00:17:43,450 --> 00:17:47,350
model is trained only the other

00:17:45,570 --> 00:17:48,880
Wikipedia set

00:17:47,350 --> 00:17:52,360
in fact it doesn't include the Melbourne

00:17:48,880 --> 00:17:56,770
page so I just pay pasty mislead aliens

00:17:52,360 --> 00:17:59,919
as a path set so let me try to have some

00:17:56,770 --> 00:18:02,590
questions so I remember it can only

00:17:59,919 --> 00:18:06,100
answers question related to this context

00:18:02,590 --> 00:18:10,870
this few paragraph so let me maybe I

00:18:06,100 --> 00:18:18,940
asked about the populations yeah so what

00:18:10,870 --> 00:18:28,539
is the populations how open and also

00:18:18,940 --> 00:18:31,450
should be 4.6 million okay so we can get

00:18:28,539 --> 00:18:34,059
extracting numbers well so maybe as

00:18:31,450 --> 00:18:42,960
something else so okay we asked about

00:18:34,059 --> 00:18:42,960
this million so what the people leaving

00:18:56,549 --> 00:19:02,789
okay so okay so that's if you can see

00:18:59,849 --> 00:19:05,099
there's no what's living in the

00:19:02,789 --> 00:19:08,159
paragraph so as we understand it happy

00:19:05,099 --> 00:19:10,979
turns is because he has some sort of

00:19:08,159 --> 00:19:13,349
cementing understandings and later

00:19:10,979 --> 00:19:16,409
explained maybe they're just give you a

00:19:13,349 --> 00:19:21,029
high level view okay so maybe ask

00:19:16,409 --> 00:19:23,249
another questions about okay so female

00:19:21,029 --> 00:19:25,499
it was suppressed me Melbourne was the

00:19:23,249 --> 00:19:32,989
host city for some Olympic Games

00:19:25,499 --> 00:19:38,249
maybe I tried to fire when was Olympic

00:19:32,989 --> 00:19:39,749
host in the city without specific named

00:19:38,249 --> 00:19:50,219
nubbins see whether you can figure it

00:19:39,749 --> 00:19:53,070
out okay 1956 okay so maybe this time I

00:19:50,219 --> 00:19:56,639
tried to identify someone a person so

00:19:53,070 --> 00:19:59,519
when we pick these questions Sir Richard

00:19:56,639 --> 00:20:03,919
Polk which name give the name Melbourne

00:19:59,519 --> 00:20:10,249
to Melbourne so who gave the name

00:20:03,919 --> 00:20:10,249
Maryland to City

00:20:14,350 --> 00:20:21,850
so it is able to associate who in this

00:20:18,519 --> 00:20:24,490
case you are asking for a name or a

00:20:21,850 --> 00:20:28,289
percent entity so the extract answers

00:20:24,490 --> 00:20:28,289
from here yeah

00:20:28,720 --> 00:20:34,750
okay so beside short answers you can

00:20:31,480 --> 00:20:38,259
also extract long answers maybe ask

00:20:34,750 --> 00:20:40,509
something like okay so maybe you are the

00:20:38,259 --> 00:20:41,919
oldest cultural institution you know can

00:20:40,509 --> 00:20:45,940
be found Melbourne so it's supposed to

00:20:41,919 --> 00:21:05,559
retrieve this whole dispute station

00:20:45,940 --> 00:21:12,039
specs okay the Melbourne Cricket Ground

00:21:05,559 --> 00:21:20,100
the show gallery is a try or any way the

00:21:12,039 --> 00:21:20,100
obvious one to ascend question yeah okay

00:21:20,279 --> 00:21:28,600
okay I have no idea where they can so

00:21:22,679 --> 00:21:37,090
what is interesting about Melbourne you

00:21:28,600 --> 00:21:38,769
surprise me if you can answer okay maybe

00:21:37,090 --> 00:21:41,910
you not find interesting yeah but would

00:21:38,769 --> 00:21:44,290
be interesting for the boat

00:21:41,910 --> 00:21:52,080
because it the boss like humans over

00:21:44,290 --> 00:21:54,070
that most populous city yeah okay so

00:21:52,080 --> 00:21:56,170
later we can play around with the demo

00:21:54,070 --> 00:22:00,630
further I've been doing the carry so

00:21:56,170 --> 00:22:00,630
let's go back to the slides

00:22:07,570 --> 00:22:13,479
okay yeah so basically what is okay so

00:22:11,320 --> 00:22:16,840
what we done in the back is basically we

00:22:13,479 --> 00:22:19,419
built a an 2n trainable model that

00:22:16,840 --> 00:22:22,690
allows the collaborations between the

00:22:19,419 --> 00:22:25,090
different layers and the network that we

00:22:22,690 --> 00:22:27,580
truly document to have internal

00:22:25,090 --> 00:22:30,399
representations of the documents

00:22:27,580 --> 00:22:32,590
conditions or the questions input that

00:22:30,399 --> 00:22:35,200
is trying to answer so basically we have

00:22:32,590 --> 00:22:38,409
this fractal level embeddings we string

00:22:35,200 --> 00:22:40,419
on the character level coppiced and we

00:22:38,409 --> 00:22:43,720
have a what embedding twist rain on the

00:22:40,419 --> 00:22:46,629
low-level copies then we have a contacts

00:22:43,720 --> 00:22:55,299
layer that to build into the reputations

00:22:46,629 --> 00:22:58,179
of the whole thing so okay so yeah okay

00:22:55,299 --> 00:22:59,919
so maybe in the in the past week you

00:22:58,179 --> 00:23:02,979
police seen some some news on your

00:22:59,919 --> 00:23:06,220
Facebook wall about Facebook there's a

00:23:02,979 --> 00:23:08,519
facebook robots this supposed to be very

00:23:06,220 --> 00:23:11,729
dangerous and it's something like Skynet

00:23:08,519 --> 00:23:13,779
convert the its own language and

00:23:11,729 --> 00:23:19,090
Facebook was so penny and they shut down

00:23:13,779 --> 00:23:22,649
the program or the model okay okay relax

00:23:19,090 --> 00:23:26,320
in fact they haven't invented Skynet yet

00:23:22,649 --> 00:23:30,609
okay so yeah they are not panic yeah so

00:23:26,320 --> 00:23:33,249
what happened is that okay Facebook is

00:23:30,609 --> 00:23:36,070
developing AI agents to perform

00:23:33,249 --> 00:23:39,309
negotiations while they are trained in

00:23:36,070 --> 00:23:42,820
plain English the researchers didn't

00:23:39,309 --> 00:23:46,200
create we work mechanism for the bots to

00:23:42,820 --> 00:23:48,759
stick to the way that humans speak

00:23:46,200 --> 00:23:51,429
natural language so they invented a

00:23:48,759 --> 00:23:53,820
language themself because is more

00:23:51,429 --> 00:23:56,710
efficient which the robot robot things

00:23:53,820 --> 00:23:59,649
so yeah BCD they become creative and

00:23:56,710 --> 00:24:04,090
invent their own efficient way of

00:23:59,649 --> 00:24:06,820
negotiate negotiating a deal which seems

00:24:04,090 --> 00:24:09,629
nonsensical to humans so we have a bot

00:24:06,820 --> 00:24:12,429
at least and Bob here and they have

00:24:09,629 --> 00:24:15,309
three books and some head and the boss

00:24:12,429 --> 00:24:17,980
so Bob say I can't everything else

00:24:15,309 --> 00:24:20,930
poor half 0 to me to me to me to me to

00:24:17,980 --> 00:24:27,620
me seems like Alice one wonderful

00:24:20,930 --> 00:24:30,380
very desperately yeah so okay so the

00:24:27,620 --> 00:24:31,910
agents at the model got shut down not

00:24:30,380 --> 00:24:34,490
because they become dangerous it's

00:24:31,910 --> 00:24:38,960
become because the the research

00:24:34,490 --> 00:24:41,060
this is researchers okay so strong okay

00:24:38,960 --> 00:24:44,060
the the bagua Shanda because they are

00:24:41,060 --> 00:24:46,520
not yet supposed to talk about human so

00:24:44,060 --> 00:24:48,350
in this case human can understand and

00:24:46,520 --> 00:24:53,780
obviously we can't negotiate with the

00:24:48,350 --> 00:25:02,180
bot if they speak it like this so yeah

00:24:53,780 --> 00:25:06,440
it is shut it down yeah I think the all

00:25:02,180 --> 00:25:08,420
those reporter they hire because before

00:25:06,440 --> 00:25:11,420
this there was this argument between

00:25:08,420 --> 00:25:13,330
Ilan Mars and Mars occiput so yeah they

00:25:11,420 --> 00:25:19,550
just had right on the highway and try to

00:25:13,330 --> 00:25:24,140
spin something out okay so back to okay

00:25:19,550 --> 00:25:26,300
so my company panned I see we we just

00:25:24,140 --> 00:25:29,000
celebrated our first anniversary last

00:25:26,300 --> 00:25:33,950
month and we have launched to chat BOTS

00:25:29,000 --> 00:25:37,790
with two clients okay so this is what we

00:25:33,950 --> 00:25:40,760
learned a short few short lessons so the

00:25:37,790 --> 00:25:44,450
first one is a user acquisition it's

00:25:40,760 --> 00:25:46,370
simple but it's not using retention so

00:25:44,450 --> 00:25:47,930
for user acquisition acquisitions for

00:25:46,370 --> 00:25:50,690
consumer I just put in more marketing

00:25:47,930 --> 00:25:52,670
dollars for enterprises easy you just

00:25:50,690 --> 00:25:55,850
get someone higher up to force people to

00:25:52,670 --> 00:25:57,440
sign up to the chat BOTS and but for

00:25:55,850 --> 00:25:59,900
user retention right to actually make

00:25:57,440 --> 00:26:02,630
them use the chibok you need to engage

00:25:59,900 --> 00:26:05,870
them continuously by adding in more

00:26:02,630 --> 00:26:08,260
contents more or putting in like

00:26:05,870 --> 00:26:12,320
gamification try to make the whole

00:26:08,260 --> 00:26:15,770
conversational reacts more funds then

00:26:12,320 --> 00:26:18,110
user expectations so because when you

00:26:15,770 --> 00:26:20,990
when the users or general public they

00:26:18,110 --> 00:26:22,460
have of machine learning AI they would

00:26:20,990 --> 00:26:25,670
think that you know everything is

00:26:22,460 --> 00:26:28,040
connected to internet is supposed to

00:26:25,670 --> 00:26:30,170
reform Expedia and connect to all it our

00:26:28,040 --> 00:26:33,270
basis and this is the impression they

00:26:30,170 --> 00:26:34,830
got for Hollywood movies but in fact

00:26:33,270 --> 00:26:37,380
yeah so we need to set the right

00:26:34,830 --> 00:26:39,990
expectations i okay this Shabbat is a

00:26:37,380 --> 00:26:42,030
customer-service Shabbat it's supposed

00:26:39,990 --> 00:26:44,760
to only answers a question related to

00:26:42,030 --> 00:26:48,270
the product inquiry or to check on their

00:26:44,760 --> 00:26:52,110
policy in case of insurance and the

00:26:48,270 --> 00:26:54,150
third one is content co-creation so it's

00:26:52,110 --> 00:26:55,680
important that we work closely with our

00:26:54,150 --> 00:26:58,010
current to create the content or the

00:26:55,680 --> 00:27:00,360
knowledge base of the Shabbat because

00:26:58,010 --> 00:27:02,400
the content and the knowledge base will

00:27:00,360 --> 00:27:08,700
determine how smart or how knowledgeable

00:27:02,400 --> 00:27:10,680
your Shabbat will be okay yeah we are

00:27:08,700 --> 00:27:14,580
hiring software genus and community

00:27:10,680 --> 00:27:16,380
majors yeah so if you've got many meals

00:27:14,580 --> 00:27:19,620
you'd like to find out more about the

00:27:16,380 --> 00:27:22,940
positions and yeah so I'm open to

00:27:19,620 --> 00:27:22,940
questions for the audience

00:27:23,420 --> 00:27:30,000
thank you David do we have any questions

00:27:26,690 --> 00:27:35,130
well we have referred to the QA system

00:27:30,000 --> 00:27:36,990
or if you're intelligent agents have

00:27:35,130 --> 00:27:40,350
questions you're welcome to ask them as

00:27:36,990 --> 00:27:44,430
well I mean if they don't say just to me

00:27:40,350 --> 00:27:46,710
to me to me to me to me to me um so one

00:27:44,430 --> 00:27:49,890
of the questions I have is how do you

00:27:46,710 --> 00:27:51,840
handle new contradictory information so

00:27:49,890 --> 00:27:54,540
suppose you had trained your chat bot on

00:27:51,840 --> 00:27:56,520
like your company's policies and then

00:27:54,540 --> 00:28:00,060
you introduced a new policy so you've

00:27:56,520 --> 00:28:01,590
got that how can chat BOTS like that

00:28:00,060 --> 00:28:04,140
understand that it needs to like

00:28:01,590 --> 00:28:05,850
invalidate its old information and like

00:28:04,140 --> 00:28:07,740
how does it just keep the useful old

00:28:05,850 --> 00:28:11,960
information but update only the new

00:28:07,740 --> 00:28:14,730
revised information okay so currently we

00:28:11,960 --> 00:28:16,790
still involve human insight so in this

00:28:14,730 --> 00:28:19,860
case the human need to carry off the

00:28:16,790 --> 00:28:22,020
updated informations from from the model

00:28:19,860 --> 00:28:28,950
and we just retrain the whole model on

00:28:22,020 --> 00:28:31,430
the new informations hi I'm just a quick

00:28:28,950 --> 00:28:35,400
question about out of call learning so

00:28:31,430 --> 00:28:37,050
what advances are there for allowing the

00:28:35,400 --> 00:28:39,090
chat bot to go out and find new

00:28:37,050 --> 00:28:40,680
information so you've got the question

00:28:39,090 --> 00:28:44,040
answering system there we give it a

00:28:40,680 --> 00:28:46,990
context how can we train chat BOTS to go

00:28:44,040 --> 00:28:53,890
out and find new information

00:28:46,990 --> 00:28:55,480
okay so okay so four new the training

00:28:53,890 --> 00:28:57,970
process will still be the same just that

00:28:55,480 --> 00:29:02,410
maybe all the time you're adding in more

00:28:57,970 --> 00:29:07,720
and more data if you the developer came

00:29:02,410 --> 00:29:10,270
across so she was all questions about is

00:29:07,720 --> 00:29:13,690
it like how do we integrate new data

00:29:10,270 --> 00:29:18,010
sources or sorry so let's say we don't

00:29:13,690 --> 00:29:19,840
give the chat bot data but we give it si

00:29:18,010 --> 00:29:21,970
access to Google or something like that

00:29:19,840 --> 00:29:24,250
so it gets a question that it hasn't on

00:29:21,970 --> 00:29:26,170
a topic it hasn't seen before so it has

00:29:24,250 --> 00:29:29,020
to then go and identify where new

00:29:26,170 --> 00:29:30,250
information is and then part and then

00:29:29,020 --> 00:29:31,390
from that point on it's pretty

00:29:30,250 --> 00:29:34,570
straightforward because it's the same

00:29:31,390 --> 00:29:36,340
process but but that that sort of idea

00:29:34,570 --> 00:29:38,440
there of going out and finding new

00:29:36,340 --> 00:29:38,880
information is there anything on that

00:29:38,440 --> 00:29:41,500
front

00:29:38,880 --> 00:29:42,940
okay so for our case right we are

00:29:41,500 --> 00:29:47,230
working with Enterprise client and

00:29:42,940 --> 00:29:49,690
usually the data we have is mostly in

00:29:47,230 --> 00:29:52,000
host data so but I think for your case

00:29:49,690 --> 00:29:53,920
like maybe a public-facing chibok you

00:29:52,000 --> 00:29:56,440
like to have to check out that learned

00:29:53,920 --> 00:30:00,610
on itself so you get access to all those

00:29:56,440 --> 00:30:04,320
new pages in Wikipedia and and just put

00:30:00,610 --> 00:30:06,690
put it into the training process and

00:30:04,320 --> 00:30:11,590
hopefully learn more about the new stuff

00:30:06,690 --> 00:30:19,450
it's possible yeah do we have any other

00:30:11,590 --> 00:30:22,150
questions thanks for you talk just a

00:30:19,450 --> 00:30:24,130
quick question about the chat bot if it

00:30:22,150 --> 00:30:26,680
gets asked the question that it cannot

00:30:24,130 --> 00:30:30,070
possibly answer how can it tell that

00:30:26,680 --> 00:30:32,740
it's answer is not right okay so when

00:30:30,070 --> 00:30:35,640
the chibok in the intern in a working

00:30:32,740 --> 00:30:37,390
right they for issue answers they the

00:30:35,640 --> 00:30:39,760
thing is to the world they have a

00:30:37,390 --> 00:30:41,530
certain confidence level so we have this

00:30:39,760 --> 00:30:42,670
threshold it seemed like the machine

00:30:41,530 --> 00:30:45,640
learning model we have a probability

00:30:42,670 --> 00:30:49,270
probability so for us are we fully set

00:30:45,640 --> 00:30:51,490
like you only give out this answer if

00:30:49,270 --> 00:30:55,140
you are mighty possessor if not just

00:30:51,490 --> 00:30:55,140
sorry I could understand

00:30:56,039 --> 00:31:03,940
one last question hi so I have two

00:31:02,679 --> 00:31:09,730
questions one for you and one for the

00:31:03,940 --> 00:31:11,080
jackpot okay so for you for your for

00:31:09,730 --> 00:31:15,039
your current customers how long does it

00:31:11,080 --> 00:31:16,809
take to train the train and if say would

00:31:15,039 --> 00:31:18,549
it be feasible for them to add new data

00:31:16,809 --> 00:31:21,880
every day and run overnight a training

00:31:18,549 --> 00:31:26,490
session or is that does it take too long

00:31:21,880 --> 00:31:26,490
currently in terms of processing okay so

00:31:28,080 --> 00:31:34,510
the turnaround time is one week again

00:31:31,870 --> 00:31:36,970
depends on that it does details how

00:31:34,510 --> 00:31:40,210
BIG's the day I said so usually less

00:31:36,970 --> 00:31:43,720
than what we able to do a batch updates

00:31:40,210 --> 00:31:47,320
on the model okay so you could do like a

00:31:43,720 --> 00:31:49,059
weekly data data dump and have answers

00:31:47,320 --> 00:31:52,630
the next week I mean we need to validate

00:31:49,059 --> 00:31:56,020
the performance and yeah before we go

00:31:52,630 --> 00:31:59,220
out and for the chat bot what makes

00:31:56,020 --> 00:31:59,220
Melbourne um nice place to live

00:32:03,940 --> 00:32:18,710
what oops

00:32:16,040 --> 00:32:20,300
okay Oh which is because it's huge yeah

00:32:18,710 --> 00:32:23,360
so you can it's a nice place to live

00:32:20,300 --> 00:32:27,890
because yeah nine thousand nine hundred

00:32:23,360 --> 00:32:29,990
give me the square sir so having broken

00:32:27,890 --> 00:32:32,960
the check but I think we might leave it

00:32:29,990 --> 00:32:42,800
there can everyone please give a big

00:32:32,960 --> 00:32:46,900
round of applause to David and on behalf

00:32:42,800 --> 00:32:46,900

YouTube URL: https://www.youtube.com/watch?v=Xj036sOwvgM


