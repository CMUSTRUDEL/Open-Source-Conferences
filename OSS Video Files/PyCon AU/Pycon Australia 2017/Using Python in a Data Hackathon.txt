Title: Using Python in a Data Hackathon
Publication date: 2017-08-05
Playlist: Pycon Australia 2017
Description: 
	Tennessee Leeuwenburg

http://2017.pycon-au.org/schedule/presentation/3/

#pyconau

This talk was given at PyCon Australia 2017 which was held from 3-8 August, 2017 in Melbourne, Victoria.

PyCon Australia is the national conference for users of the Python Programming Language. In August 2017, we're returning to Melbourne, bringing together students, enthusiasts, and professionals with a love of Python from around Australia, and from all over the World. 

August 3-8 2017, Melbourne, Victoria

Python, PyCon, PyConAU
Captions: 
	00:00:00,030 --> 00:00:05,339
okay welcome everyone my name is Robert

00:00:04,140 --> 00:00:08,970
Leighton I'll be chairing this session

00:00:05,339 --> 00:00:10,530
so really like that role it means I've

00:00:08,970 --> 00:00:11,519
get to be the center of attention for a

00:00:10,530 --> 00:00:15,719
little while but I don't actually have

00:00:11,519 --> 00:00:17,940
to do any work so we've got a pretty

00:00:15,719 --> 00:00:19,650
strict schedule so with the idea of

00:00:17,940 --> 00:00:21,350
kikyo keeping things in tune with the

00:00:19,650 --> 00:00:24,869
other talks that people can move around

00:00:21,350 --> 00:00:26,400
but so means after the talk we'll have a

00:00:24,869 --> 00:00:28,470
10-minute break so if you want to go to

00:00:26,400 --> 00:00:29,609
one of the other mini constand feel free

00:00:28,470 --> 00:00:33,930
to do that and they'll probably be

00:00:29,609 --> 00:00:36,360
people coming in as well as we sort of

00:00:33,930 --> 00:00:37,739
spoke about before the break it's

00:00:36,360 --> 00:00:39,540
probably a bit late now but next time

00:00:37,739 --> 00:00:41,190
you move try to take the seats out the

00:00:39,540 --> 00:00:42,629
front because people do move around and

00:00:41,190 --> 00:00:45,629
stuff like that

00:00:42,629 --> 00:00:48,690
putting a spare space up here all right

00:00:45,629 --> 00:00:52,050
so that further adue first up we got

00:00:48,690 --> 00:00:53,579
Tennessee so Tennessee talking before he

00:00:52,050 --> 00:00:56,340
started program before the incident was

00:00:53,579 --> 00:00:57,390
around or the web which means he's had

00:00:56,340 --> 00:01:02,190
to learn how to program without

00:00:57,390 --> 00:01:06,210
stackoverflow painful so I'll hand over

00:01:02,190 --> 00:01:08,670
the hip and welcome in Tennessee okay

00:01:06,210 --> 00:01:12,119
thanks very much Robert yeah so this

00:01:08,670 --> 00:01:14,939
talk is amazingly deep or insightful or

00:01:12,119 --> 00:01:17,130
a huge training session it's more about

00:01:14,939 --> 00:01:19,140
this particular idea of a data hackathon

00:01:17,130 --> 00:01:22,590
and there's no real time to be deep or

00:01:19,140 --> 00:01:25,770
insightful in a data hackathon hands up

00:01:22,590 --> 00:01:28,619
who's done one of these before okay so

00:01:25,770 --> 00:01:32,100
how many of you finished something on

00:01:28,619 --> 00:01:34,439
time right that's a lot less hands okay

00:01:32,100 --> 00:01:37,250
so that tells me this talk is not wasted

00:01:34,439 --> 00:01:39,630
so this talk is about that problem that

00:01:37,250 --> 00:01:42,180
essentially what you might have in a

00:01:39,630 --> 00:01:44,820
typical data hackathon is like like two

00:01:42,180 --> 00:01:46,649
days or like maybe a week you know

00:01:44,820 --> 00:01:49,079
depending on exactly what the format is

00:01:46,649 --> 00:01:51,840
so you're down on a time scale where if

00:01:49,079 --> 00:01:53,759
you lose an hour to something you didn't

00:01:51,840 --> 00:01:56,640
need to lose it to that that's

00:01:53,759 --> 00:01:58,020
significant if you lose six hours to

00:01:56,640 --> 00:02:01,200
something you didn't need to lose it to

00:01:58,020 --> 00:02:05,009
that that's also at the very least

00:02:01,200 --> 00:02:07,920
highly disappointing so I wind in 1:1

00:02:05,009 --> 00:02:09,330
recently and took a few sort of notes

00:02:07,920 --> 00:02:11,190
from that experience about what worked

00:02:09,330 --> 00:02:13,170
and what didn't work so anyone who's

00:02:11,190 --> 00:02:13,500
considering participating in something

00:02:13,170 --> 00:02:15,870
of this

00:02:13,500 --> 00:02:17,430
you might have have some notes for what

00:02:15,870 --> 00:02:19,980
to go on about so if everyone else what

00:02:17,430 --> 00:02:21,720
do you do in a data hackathon so if you

00:02:19,980 --> 00:02:23,700
if you've been you've probably seen

00:02:21,720 --> 00:02:25,560
plenty online so I don't need to over

00:02:23,700 --> 00:02:28,320
explain this but you generally need to

00:02:25,560 --> 00:02:32,310
predict something visualizer explain

00:02:28,320 --> 00:02:34,890
something pitch an idea make a demo or

00:02:32,310 --> 00:02:36,000
make a video of a demo that you pretend

00:02:34,890 --> 00:02:38,280
works

00:02:36,000 --> 00:02:41,430
that's roughly that's roughly the spread

00:02:38,280 --> 00:02:42,840
and different people are different

00:02:41,430 --> 00:02:44,430
interested in different parts of it so

00:02:42,840 --> 00:02:46,350
one of the things about a data hackathon

00:02:44,430 --> 00:02:48,420
is it a lot of the time it's not just

00:02:46,350 --> 00:02:51,300
technical people like govhack ran last

00:02:48,420 --> 00:02:53,370
week and that sort of similar and you

00:02:51,300 --> 00:02:55,860
know maybe one person in four or five

00:02:53,370 --> 00:02:58,110
was really a strong developer and

00:02:55,860 --> 00:02:59,340
everyone else was brought something else

00:02:58,110 --> 00:03:00,930
than something quite different to the

00:02:59,340 --> 00:03:03,450
table and that was based around the idea

00:03:00,930 --> 00:03:05,280
of making a video or a website or

00:03:03,450 --> 00:03:07,140
application that demonstrated sort of an

00:03:05,280 --> 00:03:09,030
interesting concept and and I know

00:03:07,140 --> 00:03:12,060
coming from the developer side that that

00:03:09,030 --> 00:03:13,350
extra ability to like give a reason to

00:03:12,060 --> 00:03:15,750
what you're doing is actually very

00:03:13,350 --> 00:03:18,600
valuable because I'm terrible at that I

00:03:15,750 --> 00:03:20,370
just know how to make stuff work so what

00:03:18,600 --> 00:03:22,290
things are in this in this talk there's

00:03:20,370 --> 00:03:24,209
managing time in the data form you

00:03:22,290 --> 00:03:26,370
basically have no time so it becomes

00:03:24,209 --> 00:03:28,350
quite important to not get knocked down

00:03:26,370 --> 00:03:30,150
as many things at the start that are

00:03:28,350 --> 00:03:32,010
going to cause you to stumble divide

00:03:30,150 --> 00:03:33,420
things up well in a team step three

00:03:32,010 --> 00:03:34,610
we'll return to this later if there's

00:03:33,420 --> 00:03:37,709
time

00:03:34,610 --> 00:03:40,380
so basically set up your environment and

00:03:37,709 --> 00:03:42,900
then a little run-through on how to do a

00:03:40,380 --> 00:03:45,870
few few basic things you might need to

00:03:42,900 --> 00:03:50,519
do anyone who's been to my talks before

00:03:45,870 --> 00:03:52,950
knows I'm not very much in favor of the

00:03:50,519 --> 00:03:55,230
just stand here and talk for a half an

00:03:52,950 --> 00:03:58,620
hour so I encourage people to interrupt

00:03:55,230 --> 00:04:00,030
or have a conversation etc etc half the

00:03:58,620 --> 00:04:02,070
people in the room will know more than I

00:04:00,030 --> 00:04:04,140
do about any particular slide that I'm

00:04:02,070 --> 00:04:06,180
talking about so we might as well treat

00:04:04,140 --> 00:04:08,790
each other as a roomful of peers as

00:04:06,180 --> 00:04:10,530
anything else so just sing out and if I

00:04:08,790 --> 00:04:13,799
get stuck I'll turn to you for the

00:04:10,530 --> 00:04:16,680
answer okay so what kind of data is in a

00:04:13,799 --> 00:04:19,859
data fund there's usually CSV files

00:04:16,680 --> 00:04:21,479
containing some kind of record set it

00:04:19,859 --> 00:04:22,830
may be something that sort of got dumped

00:04:21,479 --> 00:04:24,930
out of a database somewhere but

00:04:22,830 --> 00:04:27,300
traditionally they won't go here's a

00:04:24,930 --> 00:04:29,099
Postgres database file they'll go

00:04:27,300 --> 00:04:32,550
they'll extract it out into something

00:04:29,099 --> 00:04:34,500
that's a little little more of a simpler

00:04:32,550 --> 00:04:37,229
data format could be time series data

00:04:34,500 --> 00:04:38,879
might have image images in directories

00:04:37,229 --> 00:04:41,970
usually where you know something about

00:04:38,879 --> 00:04:44,789
those images array based image like data

00:04:41,970 --> 00:04:46,650
where the actual sort of pixel values

00:04:44,789 --> 00:04:48,960
have some kind of semantic meanings like

00:04:46,650 --> 00:04:50,639
a measurement or something like that but

00:04:48,960 --> 00:04:51,960
basically you can just largely treat

00:04:50,639 --> 00:04:54,330
them as images for the purposes of

00:04:51,960 --> 00:04:57,030
working with the data a bunch of

00:04:54,330 --> 00:04:58,530
documents with or without metadata or

00:04:57,030 --> 00:05:00,360
something that's a mix of these things

00:04:58,530 --> 00:05:02,069
where there's some kind of record format

00:05:00,360 --> 00:05:03,360
where like there's an image and as well

00:05:02,069 --> 00:05:05,039
as that there's some information about

00:05:03,360 --> 00:05:07,949
the image like the time and the location

00:05:05,039 --> 00:05:09,960
and things along those lines so a lot of

00:05:07,949 --> 00:05:12,629
a lot of the data fun stuffs were about

00:05:09,960 --> 00:05:14,280
working with the data so I was at

00:05:12,629 --> 00:05:16,830
govhack again last week and I reckon

00:05:14,280 --> 00:05:20,370
like a good half of the time was just

00:05:16,830 --> 00:05:21,900
spent working with the data so almost

00:05:20,370 --> 00:05:23,759
all of these include like the machine

00:05:21,900 --> 00:05:25,620
learning like it just works you know you

00:05:23,759 --> 00:05:27,539
actually don't need to reinvent machine

00:05:25,620 --> 00:05:29,190
learning in your hackathon what you need

00:05:27,539 --> 00:05:30,990
to do is get your data into the right

00:05:29,190 --> 00:05:32,279
format so that you can just feed it to

00:05:30,990 --> 00:05:35,039
the tools in a straightforward fashion

00:05:32,279 --> 00:05:36,630
in the data hackathon and then learn how

00:05:35,039 --> 00:05:38,639
to quickly throw those things on a

00:05:36,630 --> 00:05:41,759
website in some kind of way you can

00:05:38,639 --> 00:05:43,740
visualize it so one of the things that's

00:05:41,759 --> 00:05:46,409
not that this quite useful as having

00:05:43,740 --> 00:05:48,569
worked with similar data before so if

00:05:46,409 --> 00:05:50,759
you know that your your data hackathon

00:05:48,569 --> 00:05:53,400
is patient data or something yeah aha

00:05:50,759 --> 00:05:55,889
that's a kind of time series type deal

00:05:53,400 --> 00:05:57,599
or it might be well it depends what it

00:05:55,889 --> 00:05:59,759
is like if it's prescription data or

00:05:57,599 --> 00:06:02,370
transactions it might be time series if

00:05:59,759 --> 00:06:05,370
it's where people are sick it might be

00:06:02,370 --> 00:06:07,710
geospatial etc etc so this is just like

00:06:05,370 --> 00:06:09,629
a basic set of where you can get like

00:06:07,710 --> 00:06:11,819
well-structured datasets for trying

00:06:09,629 --> 00:06:13,710
something out in advance now it's not

00:06:11,819 --> 00:06:15,569
necessary for you to work through all of

00:06:13,710 --> 00:06:17,550
these problems or even the one in hand

00:06:15,569 --> 00:06:19,710
before the data hackathon but it will

00:06:17,550 --> 00:06:22,139
mean that you've got a predefined way of

00:06:19,710 --> 00:06:23,400
going about the work in advance so if

00:06:22,139 --> 00:06:28,919
you can do that it's probably pretty

00:06:23,400 --> 00:06:30,690
helpful environment setup super hard no

00:06:28,919 --> 00:06:33,690
it's not really you just clone this

00:06:30,690 --> 00:06:35,460
thing and and it'll work now environment

00:06:33,690 --> 00:06:37,050
setup is super hard if you're all on

00:06:35,460 --> 00:06:38,639
different laptops and you haven't talked

00:06:37,050 --> 00:06:40,320
about it beforehand with different

00:06:38,639 --> 00:06:42,479
operating systems and different versions

00:06:40,320 --> 00:06:44,009
of libraries then it really really is

00:06:42,479 --> 00:06:45,960
super hard because all of a sudden

00:06:44,009 --> 00:06:47,729
you'll find you cannot transfer or share

00:06:45,960 --> 00:06:49,589
work between people and you will

00:06:47,729 --> 00:06:50,940
suddenly lose six hours to trying to

00:06:49,589 --> 00:06:52,740
track down why this version of that

00:06:50,940 --> 00:06:54,180
thing doesn't work on Windows or on

00:06:52,740 --> 00:06:57,599
Linux or wherever it may be

00:06:54,180 --> 00:07:00,449
so going through it's like conceptually

00:06:57,599 --> 00:07:02,099
trivial but you absolutely can lose half

00:07:00,449 --> 00:07:03,630
of your time to just trying to make the

00:07:02,099 --> 00:07:04,969
thing work or you'll just lose a

00:07:03,630 --> 00:07:07,169
dissapoint of teammate because

00:07:04,969 --> 00:07:08,639
two-thirds of the team has a functioning

00:07:07,169 --> 00:07:10,110
environment and one-third of them just

00:07:08,639 --> 00:07:13,710
one-third if you just gets bored and

00:07:10,110 --> 00:07:16,319
goes away so this is a very simple

00:07:13,710 --> 00:07:18,210
repository there are no examples or

00:07:16,319 --> 00:07:19,680
anything it is just shell scripts to

00:07:18,210 --> 00:07:22,199
setup an anaconda Python environment

00:07:19,680 --> 00:07:24,210
with the latest version of the most

00:07:22,199 --> 00:07:25,889
relevant libraries for this kind of

00:07:24,210 --> 00:07:29,669
activity and then there's a bunch of

00:07:25,889 --> 00:07:31,469
add-on scripts and I had I tried to do

00:07:29,669 --> 00:07:32,789
this a few times like at work and for

00:07:31,469 --> 00:07:34,469
data Thon's this that and the other and

00:07:32,789 --> 00:07:36,360
I'm like well I need something that'll

00:07:34,469 --> 00:07:38,069
like spin up an environment and show you

00:07:36,360 --> 00:07:39,779
how to structure your directories and

00:07:38,069 --> 00:07:41,009
make you know data and input data and

00:07:39,779 --> 00:07:43,169
all of these sort of complicated things

00:07:41,009 --> 00:07:44,580
and it just even that was too

00:07:43,169 --> 00:07:46,830
complicated for working with other

00:07:44,580 --> 00:07:49,740
people like they had different ideas I'd

00:07:46,830 --> 00:07:51,779
find them you know you know six hours

00:07:49,740 --> 00:07:53,849
into like building their own environment

00:07:51,779 --> 00:07:55,380
out of shell scripts and it like it was

00:07:53,849 --> 00:07:57,539
just too complicated so there's nothing

00:07:55,380 --> 00:07:59,039
in here other than just installing the

00:07:57,539 --> 00:08:00,479
common set of base packages so that

00:07:59,039 --> 00:08:02,729
everyone's got the basic tools to work

00:08:00,479 --> 00:08:04,949
with and from there on in you're

00:08:02,729 --> 00:08:08,699
basically in shell scripts bash and

00:08:04,949 --> 00:08:11,310
Jupiter notebooks so step one of the

00:08:08,699 --> 00:08:14,520
data that athan is data ingestion it's I

00:08:11,310 --> 00:08:16,949
hate it it's boring it's unavoidable so

00:08:14,520 --> 00:08:18,930
yeah your chief strategy is to find

00:08:16,949 --> 00:08:23,219
someone who does not know this fact and

00:08:18,930 --> 00:08:25,560
that and make them do it if you have to

00:08:23,219 --> 00:08:28,860
do it I'm very you know then this is for

00:08:25,560 --> 00:08:31,500
you so here we go so so the fall asleep

00:08:28,860 --> 00:08:33,899
part of the data thon is so databases

00:08:31,500 --> 00:08:36,930
step on just use each sequel like don't

00:08:33,899 --> 00:08:39,810
use Postgres don't use whatever other

00:08:36,930 --> 00:08:43,740
things you've got don't just use CSV

00:08:39,810 --> 00:08:45,329
files don't use Google BigTable

00:08:43,740 --> 00:08:47,610
just you see qualitÃ© now the reason I

00:08:45,329 --> 00:08:49,980
say that as one is is it's like it comes

00:08:47,610 --> 00:08:52,350
with Python so you don't have to do

00:08:49,980 --> 00:08:53,760
anything about it the files are

00:08:52,350 --> 00:08:56,370
transportable on USB

00:08:53,760 --> 00:08:58,110
via Wi-Fi so there is no there are no

00:08:56,370 --> 00:09:00,150
user permissions there's no complicated

00:08:58,110 --> 00:09:02,970
anything you just go bang here here's

00:09:00,150 --> 00:09:05,640
your data shove the USB key in and for

00:09:02,970 --> 00:09:07,650
the purposes of data processing it is as

00:09:05,640 --> 00:09:09,630
fast as the other technology choices

00:09:07,650 --> 00:09:11,510
that are available I mean there's you

00:09:09,630 --> 00:09:13,920
know there's no security and there's no

00:09:11,510 --> 00:09:15,000
transaction locking the wall that maybe

00:09:13,920 --> 00:09:16,320
there is I don't know but I don't think

00:09:15,000 --> 00:09:19,560
there's transaction locking and there's

00:09:16,320 --> 00:09:21,450
definitely not scaling out but for when

00:09:19,560 --> 00:09:24,240
your environment is the laptops you've

00:09:21,450 --> 00:09:26,340
got around it's perfect if you're using

00:09:24,240 --> 00:09:27,930
some kind of cloud thing so a lot of

00:09:26,340 --> 00:09:29,340
people go I know in Tennessee you

00:09:27,930 --> 00:09:30,630
shouldn't set people up on their laptops

00:09:29,340 --> 00:09:32,520
you should get them all under the cloud

00:09:30,630 --> 00:09:35,550
well that's that's great until the Wi-Fi

00:09:32,520 --> 00:09:38,340
dropped out and and then it becomes like

00:09:35,550 --> 00:09:40,080
very challenging and also it's more

00:09:38,340 --> 00:09:41,850
difficult than you'd expect and more

00:09:40,080 --> 00:09:43,980
expensive than you'd expect to get like

00:09:41,850 --> 00:09:45,210
for people working on the same

00:09:43,980 --> 00:09:47,850
environment you either have to go

00:09:45,210 --> 00:09:49,470
through some like recipe of SSH key

00:09:47,850 --> 00:09:51,240
sharing and dealing with the fact that

00:09:49,470 --> 00:09:54,120
only some of you know how to actually do

00:09:51,240 --> 00:09:56,340
SSH key sharing like it's just I

00:09:54,120 --> 00:09:57,870
actually don't find it practically worth

00:09:56,340 --> 00:10:00,150
it in the time available and you

00:09:57,870 --> 00:10:02,190
certainly makes it harder like go out

00:10:00,150 --> 00:10:04,080
from the venue to a coffee shop or go

00:10:02,190 --> 00:10:06,570
back home and keep working the upside so

00:10:04,080 --> 00:10:08,970
that the cloud instances can persist so

00:10:06,570 --> 00:10:10,860
if you've got a long-running job on one

00:10:08,970 --> 00:10:13,170
then yeah great you can like turn your

00:10:10,860 --> 00:10:15,420
computer off and that the magic cloud

00:10:13,170 --> 00:10:16,830
machine will keep going but like it's

00:10:15,420 --> 00:10:18,600
more it's more it's a it's more

00:10:16,830 --> 00:10:21,830
sophisticated if you can take that on

00:10:18,600 --> 00:10:24,450
good for you but by and large it's not

00:10:21,830 --> 00:10:25,920
it's it's still worth having everyone on

00:10:24,450 --> 00:10:28,830
a common base starting point

00:10:25,920 --> 00:10:30,270
I find don't use other relational

00:10:28,830 --> 00:10:32,490
databases I think they'll just slow you

00:10:30,270 --> 00:10:36,210
down unless you know those things back

00:10:32,490 --> 00:10:39,720
to front don't you if you need to cache

00:10:36,210 --> 00:10:41,780
bits of table like data so most of the

00:10:39,720 --> 00:10:45,000
machine learning tools want basically

00:10:41,780 --> 00:10:47,160
you know column like like squares of

00:10:45,000 --> 00:10:49,800
data you know in one shape or form an

00:10:47,160 --> 00:10:51,720
old process that row wise and so you

00:10:49,800 --> 00:10:53,670
will often go I need to add a column I

00:10:51,720 --> 00:10:56,040
need to remove a column etc etc and then

00:10:53,670 --> 00:10:57,690
you might go I need to save that out to

00:10:56,040 --> 00:11:00,180
share with someone else and go hey I've

00:10:57,690 --> 00:11:01,740
pre-process the data and join the tables

00:11:00,180 --> 00:11:03,480
just how I want it and now I've got this

00:11:01,740 --> 00:11:06,240
big blog of data that I want to feed to

00:11:03,480 --> 00:11:07,620
my model I'll save it out to CSV it is

00:11:06,240 --> 00:11:10,320
much faster to you

00:11:07,620 --> 00:11:12,930
is something called Apache feather

00:11:10,320 --> 00:11:14,730
format and it's basically it's

00:11:12,930 --> 00:11:16,290
effectively like a binary thing that

00:11:14,730 --> 00:11:22,130
just plugs into pandas that you can read

00:11:16,290 --> 00:11:25,440
and write from we tried CSV hdf5 netcdf

00:11:22,130 --> 00:11:27,360
and this this feather format thing and

00:11:25,440 --> 00:11:30,150
the feather format thing was faster by

00:11:27,360 --> 00:11:32,400
like a factor of like 2 we also tried

00:11:30,150 --> 00:11:34,890
dusk so some people go are great I can

00:11:32,400 --> 00:11:36,420
do this sounds like that this sounds

00:11:34,890 --> 00:11:38,430
unrelated but we did it at the same time

00:11:36,420 --> 00:11:40,290
so it's related to me

00:11:38,430 --> 00:11:42,120
we tried dusk which was like a

00:11:40,290 --> 00:11:45,300
distributed thing which will like use

00:11:42,120 --> 00:11:47,430
multiple nodes and so forth what I found

00:11:45,300 --> 00:11:49,800
is that that was actually also slower on

00:11:47,430 --> 00:11:52,350
a single machine than just going through

00:11:49,800 --> 00:11:54,360
the process so and it seemed to have

00:11:52,350 --> 00:11:56,040
like bad internal caching because I

00:11:54,360 --> 00:11:57,990
think it assumed because it was

00:11:56,040 --> 00:11:59,910
distributed it might as well reload off

00:11:57,990 --> 00:12:03,360
disk because that's what it's for so if

00:11:59,910 --> 00:12:05,520
you have like six machines sure but if

00:12:03,360 --> 00:12:08,550
you actually have just like one disk in

00:12:05,520 --> 00:12:09,089
one memory you don't you will lose time

00:12:08,550 --> 00:12:11,850
to dusk

00:12:09,089 --> 00:12:14,160
sorry random thing don't use a fancy

00:12:11,850 --> 00:12:16,470
object database for relational work the

00:12:14,160 --> 00:12:18,209
reason I mainly say that is that a lot

00:12:16,470 --> 00:12:21,360
of the tools are going to be expecting

00:12:18,209 --> 00:12:23,310
just row by row data so if you do this

00:12:21,360 --> 00:12:25,920
you're gonna end up turning it back into

00:12:23,310 --> 00:12:29,700
a more simple structure a lot of the

00:12:25,920 --> 00:12:33,120
time anyway and once it's in sequel Lite

00:12:29,700 --> 00:12:35,160
or whatever database you've chosen you'd

00:12:33,120 --> 00:12:36,900
stick indexes in because you will

00:12:35,160 --> 00:12:38,940
probably find a lot of the work will be

00:12:36,900 --> 00:12:41,070
like the feature engineering I want to

00:12:38,940 --> 00:12:42,900
know more about this I figured out

00:12:41,070 --> 00:12:44,820
something that my model can't see or

00:12:42,900 --> 00:12:46,890
that I need to add to the data so you'll

00:12:44,820 --> 00:12:49,290
go back a lot of the time and the

00:12:46,890 --> 00:12:52,670
indexes will make a big difference to

00:12:49,290 --> 00:12:54,870
being able to go back efficiently

00:12:52,670 --> 00:12:57,450
ok so predicting things so we've dealt

00:12:54,870 --> 00:12:59,700
with the boring bit so I haven't gone

00:12:57,450 --> 00:13:01,170
through like data cleansing and all of

00:12:59,700 --> 00:13:04,380
that I feel like there's a lot of advice

00:13:01,170 --> 00:13:05,700
about that in the world already so I

00:13:04,380 --> 00:13:07,350
sort of feel like there's not a lot of

00:13:05,700 --> 00:13:10,080
point in like reintroducing all of those

00:13:07,350 --> 00:13:11,700
techniques here but you you may want to

00:13:10,080 --> 00:13:14,100
do that this isn't a sort of a stet

00:13:11,700 --> 00:13:15,990
repeatable stepwise process so set up

00:13:14,100 --> 00:13:18,060
things like a Jupiter and I used like

00:13:15,990 --> 00:13:20,490
Jupiter notebooks and I call it like one

00:13:18,060 --> 00:13:21,089
load the data to do the thing three do

00:13:20,490 --> 00:13:22,709
like

00:13:21,089 --> 00:13:24,660
we just use the numbers so it turns up

00:13:22,709 --> 00:13:28,589
in order so that you can repeat these

00:13:24,660 --> 00:13:31,050
things things if needed okay so then

00:13:28,589 --> 00:13:34,559
you're into working with the data is the

00:13:31,050 --> 00:13:36,269
most interesting bit so the this now we

00:13:34,559 --> 00:13:38,100
start to sort of fork out into more

00:13:36,269 --> 00:13:39,509
topics than we can reasonably cover in

00:13:38,100 --> 00:13:41,790
half an hour

00:13:39,509 --> 00:13:44,329
but if you go back to those lit like

00:13:41,790 --> 00:13:47,129
lists of data sets most of those will

00:13:44,329 --> 00:13:48,809
also come with like the internet we'll

00:13:47,129 --> 00:13:53,430
have tutorials for working with that

00:13:48,809 --> 00:13:56,730
kind of data by and large if the this XG

00:13:53,430 --> 00:13:59,339
boost thing if your data is like rows of

00:13:56,730 --> 00:14:03,029
a data base that's that's just the one

00:13:59,339 --> 00:14:04,470
to use there's there's a number of posts

00:14:03,029 --> 00:14:07,319
out there called XT boosts the

00:14:04,470 --> 00:14:09,990
winningest algorithm on Kaggle and it's

00:14:07,319 --> 00:14:12,600
it's up the top for a reason it's very

00:14:09,990 --> 00:14:14,399
robust to a broad variety of different

00:14:12,600 --> 00:14:17,610
problems and produces really very good

00:14:14,399 --> 00:14:20,850
results if you're going to go down the

00:14:17,610 --> 00:14:23,850
neural network path unless you like deep

00:14:20,850 --> 00:14:25,829
in neural network land what you need to

00:14:23,850 --> 00:14:27,839
know is that there are reference

00:14:25,829 --> 00:14:30,209
architectures for neural network models

00:14:27,839 --> 00:14:32,519
and that they have been they've been

00:14:30,209 --> 00:14:34,740
like thrashed out for imaging processing

00:14:32,519 --> 00:14:36,600
effectiveness already and there's two

00:14:34,740 --> 00:14:38,639
ways to use them there's one is is you

00:14:36,600 --> 00:14:40,740
can just spin them up like Karros will

00:14:38,639 --> 00:14:42,240
come with like you can just load that

00:14:40,740 --> 00:14:44,879
model you know you don't even need to

00:14:42,240 --> 00:14:46,439
specify everything you just pre process

00:14:44,879 --> 00:14:48,990
your data to the standard reference

00:14:46,439 --> 00:14:50,459
input image size at the data processing

00:14:48,990 --> 00:14:53,999
stage and you just feed it into this

00:14:50,459 --> 00:14:55,679
image size the models expecting and and

00:14:53,999 --> 00:14:56,100
away you go so you can use something

00:14:55,679 --> 00:14:58,079
called

00:14:56,100 --> 00:15:00,899
you can take this reference architecture

00:14:58,079 --> 00:15:02,939
train from scratch you can take a pre

00:15:00,899 --> 00:15:06,110
trained model is the other the other way

00:15:02,939 --> 00:15:09,540
you can sort of leap forward on that one

00:15:06,110 --> 00:15:12,120
text I've said there's this LS TM thing

00:15:09,540 --> 00:15:14,279
which is a long short-term memory

00:15:12,120 --> 00:15:17,040
architecture there's actually a lot more

00:15:14,279 --> 00:15:18,509
to text machine learning than that but

00:15:17,040 --> 00:15:21,959
this is like if you wanted to produce

00:15:18,509 --> 00:15:23,610
like like a simple stupid chat bot that

00:15:21,959 --> 00:15:26,519
looked like it kind of worked

00:15:23,610 --> 00:15:28,410
that's how if you want to produce like a

00:15:26,519 --> 00:15:30,089
chat bot that can like respond to

00:15:28,410 --> 00:15:31,709
queries and actually understand what's

00:15:30,089 --> 00:15:34,410
going on then you're into this whole

00:15:31,709 --> 00:15:36,360
other sort of universe of

00:15:34,410 --> 00:15:38,760
trying to work out how to do that but if

00:15:36,360 --> 00:15:40,890
you just want to like generate text that

00:15:38,760 --> 00:15:43,860
looks like like if you needed to take

00:15:40,890 --> 00:15:46,620
you know 35 Wikipedia pages and produce

00:15:43,860 --> 00:15:47,970
something that looked boilerplate you

00:15:46,620 --> 00:15:49,680
liked it vaguely knew what it was doing

00:15:47,970 --> 00:15:50,970
that would be that the mechanism for

00:15:49,680 --> 00:15:52,680
doing so and you can also apply to

00:15:50,970 --> 00:15:55,710
things like code which is kind of cool

00:15:52,680 --> 00:15:57,360
okay so most of the effort however

00:15:55,710 --> 00:15:59,460
should be in the feature engineering so

00:15:57,360 --> 00:16:01,620
if you know what's coming

00:15:59,460 --> 00:16:03,090
find your standard data set learn to use

00:16:01,620 --> 00:16:04,710
whichever one of these techniques you

00:16:03,090 --> 00:16:06,090
need to use to predict to solve a

00:16:04,710 --> 00:16:09,000
similar problem just for your own

00:16:06,090 --> 00:16:10,500
benefit and then spend your time in the

00:16:09,000 --> 00:16:13,080
hackathon learning about the data at

00:16:10,500 --> 00:16:15,980
hand in the future engineering so the

00:16:13,080 --> 00:16:19,620
key feature is limited time a few other

00:16:15,980 --> 00:16:21,660
hints and tips make sure you've got a

00:16:19,620 --> 00:16:23,520
github account setup and that everyone

00:16:21,660 --> 00:16:26,160
knows how to pull and push from a github

00:16:23,520 --> 00:16:28,680
account or like whatever just make sure

00:16:26,160 --> 00:16:31,260
you've got easy sharing of code setup

00:16:28,680 --> 00:16:33,780
you will probably want to share data as

00:16:31,260 --> 00:16:36,600
well particularly in Australia without

00:16:33,780 --> 00:16:38,790
awesome upload speeds it's actually just

00:16:36,600 --> 00:16:40,830
it's usually quicker to do the USB thing

00:16:38,790 --> 00:16:42,440
and actually our awesome upload speeds

00:16:40,830 --> 00:16:45,420
are also a problem with the cloud-based

00:16:42,440 --> 00:16:47,730
solutions so if you've got like I don't

00:16:45,420 --> 00:16:50,040
know six hundred Meg of whatever it is

00:16:47,730 --> 00:16:51,900
to upload to the cloud that actually

00:16:50,040 --> 00:16:54,120
takes you a fair whack of time

00:16:51,900 --> 00:16:56,970
unfortunately particularly over an

00:16:54,120 --> 00:16:59,040
overloaded Wi-Fi connection bring some

00:16:56,970 --> 00:17:00,810
USB keys but you know practice good USB

00:16:59,040 --> 00:17:04,350
key hygiene if you don't know where it's

00:17:00,810 --> 00:17:07,170
come from don't plug it in do use Python

00:17:04,350 --> 00:17:10,050
and sequel it's awesome don't try to do

00:17:07,170 --> 00:17:11,610
everything in memory with pandas it can

00:17:10,050 --> 00:17:15,030
be done it turns out it's much slower

00:17:11,610 --> 00:17:17,910
because sequel has amazing indexing so

00:17:15,030 --> 00:17:20,400
it's great for taking your tables that

00:17:17,910 --> 00:17:22,050
you've loaded into a database and join

00:17:20,400 --> 00:17:24,990
together and then working with it in

00:17:22,050 --> 00:17:29,670
memory fantastic it's not amazingly good

00:17:24,990 --> 00:17:31,770
for reprocessing data again and again

00:17:29,670 --> 00:17:35,190
do you use Jupiter notebooks they're

00:17:31,770 --> 00:17:37,740
amazing okay so this is a like a little

00:17:35,190 --> 00:17:40,890
bit of results in application so this is

00:17:37,740 --> 00:17:45,240
this is where we came there were we came

00:17:40,890 --> 00:17:47,760
position number 27 there was a basic

00:17:45,240 --> 00:17:49,680
business rule of like so

00:17:47,760 --> 00:17:51,360
I'm not even gonna go into what the

00:17:49,680 --> 00:17:53,850
domain was but there was there was like

00:17:51,360 --> 00:17:56,760
a one line if statement that would get

00:17:53,850 --> 00:17:58,320
you 94% accuracy on your prediction and

00:17:56,760 --> 00:18:00,390
everything else was about how much of

00:17:58,320 --> 00:18:01,740
that residual between 94 percent and a

00:18:00,390 --> 00:18:06,480
hundred percent accuracy and you could

00:18:01,740 --> 00:18:08,970
get so we got 96 percent so and the best

00:18:06,480 --> 00:18:11,520
the the number one which isn't depicted

00:18:08,970 --> 00:18:13,800
got 97 percent so they got about a 20

00:18:11,520 --> 00:18:17,460
percent bump ahead of us on predicting

00:18:13,800 --> 00:18:19,260
the residuals but you know for a week it

00:18:17,460 --> 00:18:20,520
for a weekend of mashing around with it

00:18:19,260 --> 00:18:22,920
where we had all of those timing

00:18:20,520 --> 00:18:25,220
problems I just outlined I felt we felt

00:18:22,920 --> 00:18:27,870
like we had achieved a credible outcome

00:18:25,220 --> 00:18:28,770
one of the nice things about XG boost is

00:18:27,870 --> 00:18:32,100
that it lets you visualize something

00:18:28,770 --> 00:18:34,020
called feature importance I tried to

00:18:32,100 --> 00:18:35,820
understand what that actually meant in a

00:18:34,020 --> 00:18:39,600
mathematical sense I couldn't I just

00:18:35,820 --> 00:18:42,180
went away with this graph so broadly

00:18:39,600 --> 00:18:44,730
speaking the you know something

00:18:42,180 --> 00:18:48,350
something ensemble of trees waiting this

00:18:44,730 --> 00:18:51,120
number okay so that you can label these

00:18:48,350 --> 00:18:53,130
I've lost all of my data and notebooks

00:18:51,120 --> 00:18:55,050
from from this so you have to look at

00:18:53,130 --> 00:18:57,810
these earth things but you can label

00:18:55,050 --> 00:18:59,670
this so that f/8 is probably like that

00:18:57,810 --> 00:19:01,710
magic rule effectively like that magic

00:18:59,670 --> 00:19:03,330
rule I told you about but all of these

00:19:01,710 --> 00:19:04,560
other ones are the other features in the

00:19:03,330 --> 00:19:06,060
data so if you're doing feature

00:19:04,560 --> 00:19:08,640
engineering even if you want to use a

00:19:06,060 --> 00:19:10,590
more complicated rule or algorithm you

00:19:08,640 --> 00:19:12,750
can start with the XG boost so long as

00:19:10,590 --> 00:19:15,030
it's suitable for the problem come up

00:19:12,750 --> 00:19:16,590
with hey I think it would be amazing if

00:19:15,030 --> 00:19:19,170
I like worked out if it was a full moon

00:19:16,590 --> 00:19:21,390
and divided it by PI I think that that's

00:19:19,170 --> 00:19:23,400
like the best feature ever add it to

00:19:21,390 --> 00:19:25,650
your list and then you can visualize

00:19:23,400 --> 00:19:27,870
what XG boost thinks the significance of

00:19:25,650 --> 00:19:30,990
your engineered feature is and XG boost

00:19:27,870 --> 00:19:33,870
is like fast so you can actually have a

00:19:30,990 --> 00:19:36,210
pretty like short loop turnaround time

00:19:33,870 --> 00:19:37,980
on learning about whether your your

00:19:36,210 --> 00:19:40,650
conceptualization of the data and the

00:19:37,980 --> 00:19:43,380
features is correct so it's also a real

00:19:40,650 --> 00:19:45,750
accelerator for your own experimentation

00:19:43,380 --> 00:19:47,490
in the process so that's if you can do

00:19:45,750 --> 00:19:52,940
it that way it's a it's really brilliant

00:19:47,490 --> 00:19:58,560
so our final solution was tolerably

00:19:52,940 --> 00:20:01,470
skillful and yeah the main things that

00:19:58,560 --> 00:20:04,379
that got us up were debug

00:20:01,470 --> 00:20:07,049
our code so that we were using the XT

00:20:04,379 --> 00:20:09,389
boost model appropriately

00:20:07,049 --> 00:20:10,740
yeah we like failed pretty hard on the

00:20:09,389 --> 00:20:12,929
weekend but it was a one-week

00:20:10,740 --> 00:20:14,070
competition and we like went out and

00:20:12,929 --> 00:20:15,779
we're like we're gonna knock this thing

00:20:14,070 --> 00:20:17,639
over we're gonna take as long as it

00:20:15,779 --> 00:20:19,559
takes and like an hour in and I'm like

00:20:17,639 --> 00:20:20,970
oh I think this line should like have a

00:20:19,559 --> 00:20:22,950
different if statement and then we got

00:20:20,970 --> 00:20:25,679
96% and didn't get any further for the

00:20:22,950 --> 00:20:27,509
rest of the day but so the biggest wind

00:20:25,679 --> 00:20:29,370
was like just properly understand the

00:20:27,509 --> 00:20:31,620
methodology of the tool you use so that

00:20:29,370 --> 00:20:33,809
you don't make stupid mistakes the tools

00:20:31,620 --> 00:20:35,039
work really well so if you have clean

00:20:33,809 --> 00:20:37,350
data that you've done your data

00:20:35,039 --> 00:20:40,110
processing on a solid reference

00:20:37,350 --> 00:20:42,690
architecture and the right features you

00:20:40,110 --> 00:20:44,820
will get a solid result it's not like a

00:20:42,690 --> 00:20:46,169
risky thing where you're like going to

00:20:44,820 --> 00:20:47,669
be be lost you just get those

00:20:46,169 --> 00:20:49,320
foundations in place and you will be

00:20:47,669 --> 00:20:51,720
alright and then you can spend the rest

00:20:49,320 --> 00:20:55,919
of the time working out how to get that

00:20:51,720 --> 00:20:57,600
last little bit of the way okay so yeah

00:20:55,919 --> 00:20:59,850
the difference between number 27 and

00:20:57,600 --> 00:21:01,139
number one was averaging multiple

00:20:59,850 --> 00:21:02,909
techniques interestingly in this

00:21:01,139 --> 00:21:05,309
competition if you took the number one

00:21:02,909 --> 00:21:07,289
result predictions and the number two

00:21:05,309 --> 00:21:08,669
result predictions and averaged them you

00:21:07,289 --> 00:21:12,840
got better than the number one result

00:21:08,669 --> 00:21:15,509
predictions so ensemble antenna Khalidi

00:21:12,840 --> 00:21:16,710
answer to getting those last few percent

00:21:15,509 --> 00:21:18,330
in terms of whether you should bother

00:21:16,710 --> 00:21:20,929
doing it or not but you should do it

00:21:18,330 --> 00:21:23,429
after your feature engineering probably

00:21:20,929 --> 00:21:26,309
yeah

00:21:23,429 --> 00:21:27,330
just try every strategy yeah people

00:21:26,309 --> 00:21:28,919
going well why don't we do like a

00:21:27,330 --> 00:21:30,720
weighted average of all of these

00:21:28,919 --> 00:21:33,330
ensembles and like is there some value

00:21:30,720 --> 00:21:35,460
in like doing a more fine-grained sort

00:21:33,330 --> 00:21:37,379
of approach the averaging of all of the

00:21:35,460 --> 00:21:39,690
different input models and the JUnit

00:21:37,379 --> 00:21:41,970
general answer on the internet says like

00:21:39,690 --> 00:21:43,500
well theoretically it seems like there

00:21:41,970 --> 00:21:45,480
should be but you try that and tell me

00:21:43,500 --> 00:21:48,120
if it comes out better and the tends not

00:21:45,480 --> 00:21:49,860
to so the the the weight of opinion

00:21:48,120 --> 00:21:51,809
seems to be don't bother putting brains

00:21:49,860 --> 00:21:57,299
into averaging your ensembles just do a

00:21:51,809 --> 00:21:59,190
simple average done on time on time and

00:21:57,299 --> 00:22:00,570
on budget okay so I'm sorry if I just

00:21:59,190 --> 00:22:02,879
sort of abruptly ended the the

00:22:00,570 --> 00:22:04,650
presentation with I need I need a better

00:22:02,879 --> 00:22:08,760
closing in

00:22:04,650 --> 00:22:10,980
I ran out of cats I'm sorry okay so I

00:22:08,760 --> 00:22:17,430
think time for questions yeah awesome so

00:22:10,980 --> 00:22:20,430
semi one have any questions I do so so

00:22:17,430 --> 00:22:22,710
on the averaging so one of the

00:22:20,430 --> 00:22:24,270
techniques is to just take the outputs

00:22:22,710 --> 00:22:25,260
of those check that into a machine

00:22:24,270 --> 00:22:27,210
learning out with them and then you get

00:22:25,260 --> 00:22:30,090
this whole pipeline but I imagine that

00:22:27,210 --> 00:22:32,550
sort of is over-engineered for a weekend

00:22:30,090 --> 00:22:34,410
or do you just sort of average them and

00:22:32,550 --> 00:22:37,140
that's best strategy I think there's a

00:22:34,410 --> 00:22:40,260
couple of questions there one so

00:22:37,140 --> 00:22:42,360
basically it appears like a bait like

00:22:40,260 --> 00:22:45,480
just a simple mean average is actually

00:22:42,360 --> 00:22:47,100
generally better than feeding it into a

00:22:45,480 --> 00:22:49,050
more complex model the only difference

00:22:47,100 --> 00:22:51,540
would be is if those models were like

00:22:49,050 --> 00:22:53,220
quite different and like one of them had

00:22:51,540 --> 00:22:55,170
a different set of features to the other

00:22:53,220 --> 00:22:57,360
one in which case you really might want

00:22:55,170 --> 00:22:58,770
to like if this one knows about some

00:22:57,360 --> 00:23:01,740
things and this one knows about other

00:22:58,770 --> 00:23:03,510
things like this one might be some kind

00:23:01,740 --> 00:23:05,520
of like spatial have some spatial

00:23:03,510 --> 00:23:07,200
processing in it and this other one

00:23:05,520 --> 00:23:09,090
doesn't because it doesn't fit into the

00:23:07,200 --> 00:23:11,040
tool then you might go they've got like

00:23:09,090 --> 00:23:12,390
different knowledge and then you might

00:23:11,040 --> 00:23:14,250
want to feed them in because in

00:23:12,390 --> 00:23:16,170
different circumstances one might it

00:23:14,250 --> 00:23:17,580
depends where the conditionals are so if

00:23:16,170 --> 00:23:20,400
there's a condition where this one will

00:23:17,580 --> 00:23:22,290
do better then you probably want you'll

00:23:20,400 --> 00:23:24,480
want the pipeline approach if you think

00:23:22,290 --> 00:23:26,760
they should perform roughly the same

00:23:24,480 --> 00:23:30,240
regardless of situation then you

00:23:26,760 --> 00:23:32,820
probably want a simple average can you

00:23:30,240 --> 00:23:34,860
share with some of the tools you use to

00:23:32,820 --> 00:23:37,650
visual aids your data sets that may be

00:23:34,860 --> 00:23:39,210
geospatial or just to try to plot it get

00:23:37,650 --> 00:23:42,450
a better insight when you first got it

00:23:39,210 --> 00:23:46,290
yes so there's there's a few things one

00:23:42,450 --> 00:23:48,600
is this just like a big you know feature

00:23:46,290 --> 00:23:50,550
by feature scatter plot of each one

00:23:48,600 --> 00:23:52,350
showing the the relationships between

00:23:50,550 --> 00:23:55,260
each of the features so like a big big

00:23:52,350 --> 00:23:59,160
matrix of the significance of all of the

00:23:55,260 --> 00:24:01,530
feature inputs that's quite useful just

00:23:59,160 --> 00:24:03,330
doing a simple it depends how many

00:24:01,530 --> 00:24:04,890
features you're working with I guess if

00:24:03,330 --> 00:24:06,870
you've only got like four or five

00:24:04,890 --> 00:24:09,240
features or something like that you can

00:24:06,870 --> 00:24:11,400
just like scatter plot each one you know

00:24:09,240 --> 00:24:13,710
like just get it just get it visualized

00:24:11,400 --> 00:24:15,540
however you can in terms of which

00:24:13,710 --> 00:24:16,480
visualization tools to use this quite a

00:24:15,540 --> 00:24:19,540
lot of

00:24:16,480 --> 00:24:22,090
ones now Seaborn is good matplotlib I

00:24:19,540 --> 00:24:23,530
finders it's okay but you have to spend

00:24:22,090 --> 00:24:26,440
a fair bit of time engineering your

00:24:23,530 --> 00:24:28,990
plots you probably like just label your

00:24:26,440 --> 00:24:30,820
axes and just get it on the page rather

00:24:28,990 --> 00:24:31,929
than worry too much about the details of

00:24:30,820 --> 00:24:35,650
it because most of this stuff you'll

00:24:31,929 --> 00:24:38,020
throw away later showing getting it on a

00:24:35,650 --> 00:24:39,309
map can reveal spatial relationships

00:24:38,020 --> 00:24:40,630
like that's one of the things where all

00:24:39,309 --> 00:24:42,910
of the tools I just showed you tend to

00:24:40,630 --> 00:24:44,470
fall down is on complicated spatial

00:24:42,910 --> 00:24:46,980
relationships so one of the things you

00:24:44,470 --> 00:24:49,299
might want to do is get like a

00:24:46,980 --> 00:24:51,160
geospatial database or that I think

00:24:49,299 --> 00:24:52,780
there's a spatial light I've been used

00:24:51,160 --> 00:24:54,669
it personally but it's geospatial

00:24:52,780 --> 00:24:56,890
plug-in onto sequel light and then you

00:24:54,669 --> 00:24:58,990
can calculate things like distances from

00:24:56,890 --> 00:25:01,390
other things and then feed that back

00:24:58,990 --> 00:25:05,679
into the records for use by the by the

00:25:01,390 --> 00:25:07,360
other models so I don't I'm less strong

00:25:05,679 --> 00:25:10,630
on the visualization side so maybe

00:25:07,360 --> 00:25:13,270
someone else has has more guidance on

00:25:10,630 --> 00:25:14,559
the visualization side I think we have a

00:25:13,270 --> 00:25:17,890
talk on that coming up later this

00:25:14,559 --> 00:25:30,600
afternoon so that might work yes I do

00:25:17,890 --> 00:25:30,600
have any any other questions yeah I

00:25:35,730 --> 00:25:40,000
haven't used it in fact if I get you to

00:25:38,169 --> 00:25:42,190
repeat the questions yes the question

00:25:40,000 --> 00:25:44,740
was paid that looks awesome

00:25:42,190 --> 00:25:46,600
so what tea pot is is basically it's

00:25:44,740 --> 00:25:48,160
just a big black box sausage factory

00:25:46,600 --> 00:25:50,320
that knows about a whole lot of

00:25:48,160 --> 00:25:52,090
different techniques and you just feed

00:25:50,320 --> 00:25:53,470
it the data and just like just in your

00:25:52,090 --> 00:25:55,299
error function and just tell it to go

00:25:53,470 --> 00:25:56,919
not and it'll pop out and it says use

00:25:55,299 --> 00:25:58,900
this particular model and here's what

00:25:56,919 --> 00:26:00,250
the score was so you know that you might

00:25:58,900 --> 00:26:02,320
think of it as like a grid search

00:26:00,250 --> 00:26:04,720
approach where it's not just the meta

00:26:02,320 --> 00:26:06,429
parameters it's actually the algorithm

00:26:04,720 --> 00:26:08,590
and the strategy that's actually being

00:26:06,429 --> 00:26:10,210
being searched through and which sounds

00:26:08,590 --> 00:26:12,340
very appealing when I looked at it it

00:26:10,210 --> 00:26:14,470
had a real like a year ago it had a

00:26:12,340 --> 00:26:17,559
relatively limited number of models it

00:26:14,470 --> 00:26:19,419
actually knew about and in terms of

00:26:17,559 --> 00:26:21,910
using it over a weekend

00:26:19,419 --> 00:26:23,320
you probably want if it fits you

00:26:21,910 --> 00:26:25,510
probably want to be iterating on your

00:26:23,320 --> 00:26:26,679
feature to your feature engineering more

00:26:25,510 --> 00:26:28,960
than you want to be searching through

00:26:26,679 --> 00:26:30,880
model space so it might be the kind of

00:26:28,960 --> 00:26:33,520
thing where if you've got a real

00:26:30,880 --> 00:26:35,380
strong team on this then yeah it might

00:26:33,520 --> 00:26:37,060
actually be really good to go well we've

00:26:35,380 --> 00:26:39,550
got a basic set of features now let's

00:26:37,060 --> 00:26:41,920
find out which you go find the best

00:26:39,550 --> 00:26:43,570
model you go engineer features and then

00:26:41,920 --> 00:26:45,520
throw the features over the fence to the

00:26:43,570 --> 00:26:46,930
person doing the model engineering so if

00:26:45,520 --> 00:26:49,540
you've got a strong enough team it could

00:26:46,930 --> 00:26:51,610
be useful but if it's just like three of

00:26:49,540 --> 00:26:52,930
you and you're not not as deep on some

00:26:51,610 --> 00:26:56,080
of these things I would go with the

00:26:52,930 --> 00:26:58,270
simple approach and feature engineer yet

00:26:56,080 --> 00:27:02,260
my question is do you have any general

00:26:58,270 --> 00:27:03,840
tips for a future engineering general

00:27:02,260 --> 00:27:05,950
tip for feature engineering I guess

00:27:03,840 --> 00:27:07,990
concentrate on things that the models

00:27:05,950 --> 00:27:10,540
don't know about so they don't magically

00:27:07,990 --> 00:27:13,000
know about spatial relations like large

00:27:10,540 --> 00:27:14,950
scale fake spatial relationships very

00:27:13,000 --> 00:27:16,810
much so there's nothing in a deep

00:27:14,950 --> 00:27:19,780
learning model that calculates distances

00:27:16,810 --> 00:27:21,520
for example I mean if it's if you're

00:27:19,780 --> 00:27:22,960
using like a convolutional approach or

00:27:21,520 --> 00:27:25,540
an image segmentation approach it can

00:27:22,960 --> 00:27:27,850
like find areas of interest and and so

00:27:25,540 --> 00:27:30,070
forth but it doesn't like take that back

00:27:27,850 --> 00:27:32,620
as an input to distances to other things

00:27:30,070 --> 00:27:34,480
that are too noticed etc so things where

00:27:32,620 --> 00:27:35,980
you can like work out where the model

00:27:34,480 --> 00:27:38,800
where that particular approach is going

00:27:35,980 --> 00:27:40,420
to be weak is really good like NXG boost

00:27:38,800 --> 00:27:43,600
would be the same it would have no clue

00:27:40,420 --> 00:27:45,340
unless you entered it into like which

00:27:43,600 --> 00:27:48,090
latitudes and longitudes are close to

00:27:45,340 --> 00:27:50,650
which other latitudes and longitudes and

00:27:48,090 --> 00:27:52,780
bringing in extra data is always a nice

00:27:50,650 --> 00:27:54,180
Chiti way of feature engineering so if

00:27:52,780 --> 00:27:56,650
you've got like latitudes and longitudes

00:27:54,180 --> 00:27:58,980
in your data set you could just find

00:27:56,650 --> 00:28:02,170
other stuff like if people are getting

00:27:58,980 --> 00:28:03,820
sick maybe they live in cold climates or

00:28:02,170 --> 00:28:05,410
maybe they live you know so if you can

00:28:03,820 --> 00:28:06,760
like reason about the world and pull in

00:28:05,410 --> 00:28:10,690
some more facts that can be of

00:28:06,760 --> 00:28:12,970
assistance all right so I think that

00:28:10,690 --> 00:28:16,650
brings us to time so and so could

00:28:12,970 --> 00:28:16,650
everyone join me in thanking Tennessee

00:28:20,740 --> 00:28:24,120

YouTube URL: https://www.youtube.com/watch?v=Ck1Ns6D3rZc


