Title: "Your Escape Plan From Numpy + Cython" - Cheng-Lin Yang (PyConline AU 2020)
Publication date: 2020-09-08
Playlist: PyConline AU 2020
Description: 
	Cheng-Lin Yang

https://2020.pycon.org.au/program/Y3SXGF

If you've been a data scientist or researcher long enough, you must have encountered a situation where your NumPy code ran quickly on small datasets in a testing environment but performed poorly on real-world datasets (100x larger or more). In this talk, I will introduce three Pythonic solutions to improve NumPy performance drastically without modifying too many codes.

At the beginning of the talk, a math equation: logsumexp, which is widely used in machine learning, will be illustrated. I will show how it is implemented with pure NumPy and use it as a benchmark so we can compare it to three proposed solutions at the end of the talk.

Then, three solutions: CuPy, Numba, and Pythran will be presented in separate sections. In each section, I will give a brief introduction to the solution and show how to apply this solution to our benchmark code.

At the end of the talk, I will compare these solutions from different aspects:

    * How much performance is boosted after each solution is applied
    * Ease to apply on your existing code (including the ease of debugging)
    * Limitations of each solution
    * Which solution should be applied first in given scenarios

Last but not the least, I will show a relatively new but interesting solution: Transonic to the audience so they can give it a try on their side project.

Produced by NDV: https://youtube.com/channel/UCQ7dFBzZGlBvtU2hCecsBBg?sub_confirmation=1

Python, PyCon, PyConAU, PyConline

Sat Sep  5 16:00:00 2020 at Obvious
Captions: 
	00:00:04,400 --> 00:00:07,120
hello

00:00:05,200 --> 00:00:09,280
thank you for having me at pycon

00:00:07,120 --> 00:00:11,280
australia 2020

00:00:09,280 --> 00:00:12,400
it's truly my honor to present the

00:00:11,280 --> 00:00:14,920
following topic

00:00:12,400 --> 00:00:16,640
your escape plan from nongpai and

00:00:14,920 --> 00:00:19,279
samsung

00:00:16,640 --> 00:00:20,480
here is some of my information my name

00:00:19,279 --> 00:00:22,760
is chun ling yang

00:00:20,480 --> 00:00:24,320
and you can find me on github

00:00:22,760 --> 00:00:27,119
c-l-y-a-n-g

00:00:24,320 --> 00:00:29,359
i'm a taiwanese and live in taipei now

00:00:27,119 --> 00:00:30,320
currently working for a cyber security

00:00:29,359 --> 00:00:33,280
company called

00:00:30,320 --> 00:00:34,719
scicraft japan and i'm also a member of

00:00:33,280 --> 00:00:37,040
the machine learning team

00:00:34,719 --> 00:00:39,520
so basically all my daily life is

00:00:37,040 --> 00:00:40,000
dealing with millions of logs generated

00:00:39,520 --> 00:00:42,840
by

00:00:40,000 --> 00:00:44,640
a lot of endpoints in different

00:00:42,840 --> 00:00:47,360
countries

00:00:44,640 --> 00:00:48,879
okay before we start here's one very

00:00:47,360 --> 00:00:51,120
quick question for you

00:00:48,879 --> 00:00:53,680
let's say you have a very large numpy

00:00:51,120 --> 00:00:56,399
array which contains a lot of non

00:00:53,680 --> 00:00:59,520
floating points and you want to each

00:00:56,399 --> 00:01:01,520
element to multiply itself eight times

00:00:59,520 --> 00:01:02,879
which of the following code do you think

00:01:01,520 --> 00:01:06,479
run faster

00:01:02,879 --> 00:01:09,600
is it a the power function of numpy

00:01:06,479 --> 00:01:12,640
or b x times times eight

00:01:09,600 --> 00:01:15,600
or c the most naive one x times

00:01:12,640 --> 00:01:19,360
x and then repeat four times i'll give

00:01:15,600 --> 00:01:19,360
you three seconds to think about it

00:01:21,680 --> 00:01:26,000
the answer might surprise you is c the

00:01:24,799 --> 00:01:28,960
most naive one you

00:01:26,000 --> 00:01:29,759
just use x times x and then repeat four

00:01:28,960 --> 00:01:32,720
times

00:01:29,759 --> 00:01:34,159
in order to perfect here is the result

00:01:32,720 --> 00:01:36,880
of my benchmark

00:01:34,159 --> 00:01:37,520
as you can see the power function of num

00:01:36,880 --> 00:01:41,520
pi

00:01:37,520 --> 00:01:44,720
and x times times a they both took about

00:01:41,520 --> 00:01:47,600
two seconds and the for the

00:01:44,720 --> 00:01:48,640
most negative one x times x repeat four

00:01:47,600 --> 00:01:51,520
times

00:01:48,640 --> 00:01:52,479
and then you can see it only take 0.4

00:01:51,520 --> 00:01:54,640
seconds

00:01:52,479 --> 00:01:55,840
so it's about five times faster than

00:01:54,640 --> 00:01:59,119
previous two

00:01:55,840 --> 00:02:01,280
but there's a cage so if unless you are

00:01:59,119 --> 00:02:04,640
doing the scientific computing

00:02:01,280 --> 00:02:07,040
which require very very high accuracy

00:02:04,640 --> 00:02:09,520
otherwise the result of the last one

00:02:07,040 --> 00:02:12,640
will be a very small difference than

00:02:09,520 --> 00:02:15,760
the previous two the difference

00:02:12,640 --> 00:02:18,879
is like 10 to number of power negative

00:02:15,760 --> 00:02:19,200
20. so i believe in most cases you will

00:02:18,879 --> 00:02:22,480
just

00:02:19,200 --> 00:02:26,720
choose the final last solution

00:02:22,480 --> 00:02:26,720
x times x and then repeat four times

00:02:26,959 --> 00:02:32,720
okay let's move on why not samsung

00:02:30,160 --> 00:02:33,840
if you ever have the non-pine core

00:02:32,720 --> 00:02:35,840
performance issue

00:02:33,840 --> 00:02:36,959
and ask your friends colleagues or

00:02:35,840 --> 00:02:39,519
teachers how to

00:02:36,959 --> 00:02:40,560
improve it most likely the answer you

00:02:39,519 --> 00:02:43,440
will get is need

00:02:40,560 --> 00:02:44,800
like why don't you try on saison so in

00:02:43,440 --> 00:02:47,599
this slide i will give

00:02:44,800 --> 00:02:48,000
some points and counts regarding to it

00:02:47,599 --> 00:02:51,120
first

00:02:48,000 --> 00:02:52,640
let's take a look at advantage if you

00:02:51,120 --> 00:02:55,200
are using samsung

00:02:52,640 --> 00:02:56,239
and of course you can utilize a lot of

00:02:55,200 --> 00:03:00,000
third-party c

00:02:56,239 --> 00:03:02,480
libraries and normally c code is

00:03:00,000 --> 00:03:03,280
runs much much faster than the python

00:03:02,480 --> 00:03:05,920
code

00:03:03,280 --> 00:03:08,239
and also price samsung allows you to

00:03:05,920 --> 00:03:11,519
release the global interpreter lock

00:03:08,239 --> 00:03:13,280
or code gil which means that your

00:03:11,519 --> 00:03:16,080
multi-threaded program

00:03:13,280 --> 00:03:17,599
can be run much much faster than its

00:03:16,080 --> 00:03:19,680
existing one

00:03:17,599 --> 00:03:21,760
and also you can still have the wrong

00:03:19,680 --> 00:03:24,000
time check for the common problem

00:03:21,760 --> 00:03:24,879
like the boundary check or some error

00:03:24,000 --> 00:03:27,840
handling

00:03:24,879 --> 00:03:29,040
and which will handle by the upper layer

00:03:27,840 --> 00:03:32,319
python

00:03:29,040 --> 00:03:33,599
and the last the on syntax is very

00:03:32,319 --> 00:03:35,599
similar to python

00:03:33,599 --> 00:03:37,280
meaning that you can learn it in a very

00:03:35,599 --> 00:03:40,480
short amount of time

00:03:37,280 --> 00:03:42,400
but also it has some disadvantage

00:03:40,480 --> 00:03:45,040
the first thing i can think is that you

00:03:42,400 --> 00:03:47,680
have to handle the memory by yourself

00:03:45,040 --> 00:03:48,959
so for example if you are using malloc

00:03:47,680 --> 00:03:52,000
in your samsung code

00:03:48,959 --> 00:03:55,040
and then you have to use this memory

00:03:52,000 --> 00:03:57,439
by yourself and then freely after all

00:03:55,040 --> 00:03:58,480
and you have to do it all by your own

00:03:57,439 --> 00:04:01,439
otherwise

00:03:58,480 --> 00:04:03,280
it might cause some very same serious

00:04:01,439 --> 00:04:06,000
memory leak

00:04:03,280 --> 00:04:07,840
and also to get the ultimate performance

00:04:06,000 --> 00:04:10,400
with saison

00:04:07,840 --> 00:04:11,200
to write a c core and the low-level

00:04:10,400 --> 00:04:14,799
intrinsic

00:04:11,200 --> 00:04:17,040
cannot be avoided so no matter what

00:04:14,799 --> 00:04:18,320
if you want to get the best performance

00:04:17,040 --> 00:04:22,079
you have to write a c

00:04:18,320 --> 00:04:25,120
code and trust me it's really painful

00:04:22,079 --> 00:04:27,360
it's just something like it and why do i

00:04:25,120 --> 00:04:29,840
know it because the code you see is raw

00:04:27,360 --> 00:04:29,840
by myself

00:04:29,919 --> 00:04:33,360
great let's have a look to today's

00:04:32,240 --> 00:04:36,000
example

00:04:33,360 --> 00:04:37,600
this example will use as a benchmark for

00:04:36,000 --> 00:04:40,639
the rest of the toe

00:04:37,600 --> 00:04:41,199
so let's have a look if you are not new

00:04:40,639 --> 00:04:43,360
to

00:04:41,199 --> 00:04:44,639
a machine learning you must know what

00:04:43,360 --> 00:04:47,360
soft max function

00:04:44,639 --> 00:04:48,639
is the formula is just like the one on

00:04:47,360 --> 00:04:50,960
the screen

00:04:48,639 --> 00:04:53,040
and don't worry i'm not going to explain

00:04:50,960 --> 00:04:55,600
it in a mathematical way

00:04:53,040 --> 00:04:56,080
all you have to know is that it's a

00:04:55,600 --> 00:04:59,199
number

00:04:56,080 --> 00:05:02,160
divided by the sum of a lot of numbers

00:04:59,199 --> 00:05:04,639
and that's enough and you might think

00:05:02,160 --> 00:05:07,440
the formula itself looks very easy and

00:05:04,639 --> 00:05:08,479
it shouldn't be very hard to implement

00:05:07,440 --> 00:05:11,039
in python

00:05:08,479 --> 00:05:12,080
and yes you are correct but if you try

00:05:11,039 --> 00:05:14,400
to implement

00:05:12,080 --> 00:05:17,919
with the formula on the stream you will

00:05:14,400 --> 00:05:19,840
easily encounter the numerical problem

00:05:17,919 --> 00:05:21,520
in computer science we call it a

00:05:19,840 --> 00:05:24,560
underflow or overflow

00:05:21,520 --> 00:05:26,400
issue and on the next slide i will give

00:05:24,560 --> 00:05:29,440
you a underflow

00:05:26,400 --> 00:05:30,639
example so to avoid this kind of

00:05:29,440 --> 00:05:33,360
situation

00:05:30,639 --> 00:05:36,160
a trick called the log sum exponential

00:05:33,360 --> 00:05:39,919
will be used

00:05:36,160 --> 00:05:42,240
now here's the example of underflow

00:05:39,919 --> 00:05:43,440
let's say the sum of this part of the

00:05:42,240 --> 00:05:46,080
denominator

00:05:43,440 --> 00:05:46,880
is one three four two one seven seven

00:05:46,080 --> 00:05:50,479
two a

00:05:46,880 --> 00:05:53,360
and the last part is its reciprocal

00:05:50,479 --> 00:05:54,880
and what will happen if we are trying to

00:05:53,360 --> 00:05:58,000
add them together

00:05:54,880 --> 00:06:02,479
here's the benchmark as you can see

00:05:58,000 --> 00:06:05,440
i set variable a to 1342172a

00:06:02,479 --> 00:06:06,800
and then trying to pass it with its

00:06:05,440 --> 00:06:09,840
reciprocal

00:06:06,800 --> 00:06:12,800
and here's the result as you can see

00:06:09,840 --> 00:06:14,240
it's exactly same as a it's quite

00:06:12,800 --> 00:06:17,759
shocking right

00:06:14,240 --> 00:06:19,840
this effect is called underflow

00:06:17,759 --> 00:06:22,400
you might think this is not a very big

00:06:19,840 --> 00:06:24,560
deal but if you are doing a scientific

00:06:22,400 --> 00:06:27,280
calculation like markov chain

00:06:24,560 --> 00:06:28,560
the input data is a list of very small

00:06:27,280 --> 00:06:31,600
probability

00:06:28,560 --> 00:06:35,280
and just like my example on the slide

00:06:31,600 --> 00:06:36,800
after specific position the probability

00:06:35,280 --> 00:06:39,759
will not be counted

00:06:36,800 --> 00:06:42,800
which will cause very large error in

00:06:39,759 --> 00:06:45,919
your final result

00:06:42,800 --> 00:06:47,759
so as i mentioned in the previous page

00:06:45,919 --> 00:06:48,960
this problem can be solved by a simple

00:06:47,759 --> 00:06:51,840
trick called log sum

00:06:48,960 --> 00:06:52,639
exponential and the formula is just like

00:06:51,840 --> 00:06:55,599
the one i

00:06:52,639 --> 00:06:56,720
should show on the slide and the result

00:06:55,599 --> 00:06:59,520
of this formula

00:06:56,720 --> 00:07:01,199
will mathematically equivalent to the

00:06:59,520 --> 00:07:02,880
surface function

00:07:01,199 --> 00:07:04,240
and don't worry again because i'm not

00:07:02,880 --> 00:07:06,880
going to prove it

00:07:04,240 --> 00:07:07,440
in the toe but the answer can be easily

00:07:06,880 --> 00:07:10,479
find

00:07:07,440 --> 00:07:13,520
on the internet so in order to

00:07:10,479 --> 00:07:15,360
prove it it really works here is another

00:07:13,520 --> 00:07:17,520
example code

00:07:15,360 --> 00:07:19,919
as you can see the final result over

00:07:17,520 --> 00:07:22,560
here you can see the very

00:07:19,919 --> 00:07:23,919
little difference uh between this one

00:07:22,560 --> 00:07:27,680
and the previous one

00:07:23,919 --> 00:07:30,960
so the small the smaller value is not

00:07:27,680 --> 00:07:31,599
cutted or avoided which will result in a

00:07:30,960 --> 00:07:34,720
more

00:07:31,599 --> 00:07:37,280
more accurate result to your final

00:07:34,720 --> 00:07:37,280
answers

00:07:37,599 --> 00:07:41,280
some of you might ask scipy already has

00:07:40,479 --> 00:07:43,919
this function

00:07:41,280 --> 00:07:45,280
why would you rebuild your own wheel the

00:07:43,919 --> 00:07:47,680
answer to that is

00:07:45,280 --> 00:07:49,280
scifi's function is built for general

00:07:47,680 --> 00:07:51,440
purpose usage

00:07:49,280 --> 00:07:52,319
meaning it will perform a lot of checks

00:07:51,440 --> 00:07:55,599
to make sure

00:07:52,319 --> 00:07:58,240
input and output data is well handled

00:07:55,599 --> 00:07:59,840
but in a real-world scenario you know

00:07:58,240 --> 00:08:02,400
what your data is

00:07:59,840 --> 00:08:03,840
so you can rewrite the function based on

00:08:02,400 --> 00:08:07,120
your data

00:08:03,840 --> 00:08:10,400
not only you can remove a lot of checks

00:08:07,120 --> 00:08:11,120
but also it gives you an opportunity to

00:08:10,400 --> 00:08:14,080
apply

00:08:11,120 --> 00:08:16,400
third-party boosting solution to improve

00:08:14,080 --> 00:08:19,440
your code performance

00:08:16,400 --> 00:08:22,240
today's case i will assume there's the

00:08:19,440 --> 00:08:25,039
input data will be only one dimensional

00:08:22,240 --> 00:08:26,639
array and then i will try to apply three

00:08:25,039 --> 00:08:31,039
different solution

00:08:26,639 --> 00:08:34,080
to the example i just mentioned before

00:08:31,039 --> 00:08:37,200
okay let's moving on how do we implement

00:08:34,080 --> 00:08:38,320
log sum exponential in numpy as i

00:08:37,200 --> 00:08:40,479
mentioned before

00:08:38,320 --> 00:08:41,919
all my input data will just be one

00:08:40,479 --> 00:08:44,959
dimensional array

00:08:41,919 --> 00:08:46,240
so logs on exponential coping implement

00:08:44,959 --> 00:08:48,800
as follows

00:08:46,240 --> 00:08:50,800
as you can see it only took three lines

00:08:48,800 --> 00:08:53,600
of codes to finish

00:08:50,800 --> 00:08:55,680
it's quite easy right here i'm going to

00:08:53,600 --> 00:08:58,000
leave five seconds to you to view the

00:08:55,680 --> 00:08:58,000
code

00:09:01,760 --> 00:09:06,480
time is up so after finish our own

00:09:05,040 --> 00:09:08,800
version in numpy

00:09:06,480 --> 00:09:10,959
i wrote a very simple benchmark code to

00:09:08,800 --> 00:09:14,080
compare our own version versus

00:09:10,959 --> 00:09:15,279
scipy's original function the result is

00:09:14,080 --> 00:09:18,320
on the right

00:09:15,279 --> 00:09:19,680
as you can see our version is about 0.5

00:09:18,320 --> 00:09:22,560
seconds faster

00:09:19,680 --> 00:09:23,360
than the original scipy's function you

00:09:22,560 --> 00:09:27,040
might think

00:09:23,360 --> 00:09:29,440
it's only 0.5 second it's not a lot

00:09:27,040 --> 00:09:31,200
but if you need to code this function a

00:09:29,440 --> 00:09:33,279
million times a day

00:09:31,200 --> 00:09:34,240
it will save you about half million

00:09:33,279 --> 00:09:37,600
seconds

00:09:34,240 --> 00:09:39,839
that's quite a lot right

00:09:37,600 --> 00:09:41,600
starting from here i'm going to

00:09:39,839 --> 00:09:42,320
introduce three different types of

00:09:41,600 --> 00:09:44,080
solution

00:09:42,320 --> 00:09:46,640
that might improve your non-price

00:09:44,080 --> 00:09:48,399
performance the first solution will be

00:09:46,640 --> 00:09:50,800
coupon

00:09:48,399 --> 00:09:53,200
coupon is an open source project

00:09:50,800 --> 00:09:55,920
developed by japanese company

00:09:53,200 --> 00:09:56,640
it provides numpy compatible nd array on

00:09:55,920 --> 00:09:59,839
cuda

00:09:56,640 --> 00:10:02,800
so you can utilize all your gpu powers

00:09:59,839 --> 00:10:04,000
and also it is compatible with existing

00:10:02,800 --> 00:10:05,680
kuda kernel

00:10:04,000 --> 00:10:07,279
meaning that you don't have to waste

00:10:05,680 --> 00:10:09,200
your existing file

00:10:07,279 --> 00:10:10,480
you just need to import it and then

00:10:09,200 --> 00:10:13,920
cooldown will run

00:10:10,480 --> 00:10:15,440
it for you it also provides many numpy

00:10:13,920 --> 00:10:17,680
equivalent functions

00:10:15,440 --> 00:10:19,760
so you so you don't have to change your

00:10:17,680 --> 00:10:23,279
code a lot and minimize the core

00:10:19,760 --> 00:10:26,720
refactoring effect but still

00:10:23,279 --> 00:10:29,440
please remember coupon and numpai

00:10:26,720 --> 00:10:31,760
uh has some difference please check on

00:10:29,440 --> 00:10:32,800
koopa's website to find a detailed

00:10:31,760 --> 00:10:36,000
difference

00:10:32,800 --> 00:10:36,720
between cooper and nongpai and one last

00:10:36,000 --> 00:10:39,360
thing

00:10:36,720 --> 00:10:40,640
moving the data between cpu and gpu is

00:10:39,360 --> 00:10:43,360
very expensive

00:10:40,640 --> 00:10:43,760
please use it wisely otherwise it might

00:10:43,360 --> 00:10:46,240
not

00:10:43,760 --> 00:10:47,120
improve your performance but drag your

00:10:46,240 --> 00:10:50,399
performance

00:10:47,120 --> 00:10:53,680
a lot so how do we

00:10:50,399 --> 00:10:56,079
implement logs and exponential in coupon

00:10:53,680 --> 00:10:58,320
it's quite easy all you have to do is

00:10:56,079 --> 00:11:01,440
import copy a cp

00:10:58,320 --> 00:11:02,519
and then use a function uh underline

00:11:01,440 --> 00:11:06,240
over here

00:11:02,519 --> 00:11:08,959
cp.array to convert the existing numpy

00:11:06,240 --> 00:11:09,920
array to coupon array and then

00:11:08,959 --> 00:11:13,120
couponwood

00:11:09,920 --> 00:11:14,240
does the metric for you and here is the

00:11:13,120 --> 00:11:17,839
final result

00:11:14,240 --> 00:11:20,000
as you can see our cool pi version

00:11:17,839 --> 00:11:22,000
the running time of our q5 version is

00:11:20,000 --> 00:11:25,920
just 1.6 second

00:11:22,000 --> 00:11:26,720
so it's from like 6.5 second to 1.6

00:11:25,920 --> 00:11:29,920
second

00:11:26,720 --> 00:11:32,079
it's pretty amazing right

00:11:29,920 --> 00:11:33,040
now let's move on to the next solution

00:11:32,079 --> 00:11:35,360
number

00:11:33,040 --> 00:11:36,240
number is a very popular open source

00:11:35,360 --> 00:11:38,480
project

00:11:36,240 --> 00:11:39,519
that can boost your numpy and python

00:11:38,480 --> 00:11:41,600
performance

00:11:39,519 --> 00:11:42,640
it is also backed by many large

00:11:41,600 --> 00:11:45,839
companies and

00:11:42,640 --> 00:11:48,399
organizations the approach number used

00:11:45,839 --> 00:11:51,279
is called just-in-time technology

00:11:48,399 --> 00:11:52,880
basically you just translate a subset of

00:11:51,279 --> 00:11:55,360
python and numpy code

00:11:52,880 --> 00:11:56,560
into low-level machine code and runs

00:11:55,360 --> 00:12:00,240
faster

00:11:56,560 --> 00:12:03,040
it also utilizes both cpu and gpu power

00:12:00,240 --> 00:12:04,000
one of the best in number has is that it

00:12:03,040 --> 00:12:07,600
supports open

00:12:04,000 --> 00:12:09,360
mp which means that you can improve your

00:12:07,600 --> 00:12:12,639
multi-threaded

00:12:09,360 --> 00:12:14,800
program much much faster the highlight

00:12:12,639 --> 00:12:17,440
of number is that you provide near

00:12:14,800 --> 00:12:19,519
zero code modification all you have to

00:12:17,440 --> 00:12:22,160
do is put a decorator

00:12:19,519 --> 00:12:22,800
at jit before the function you want to

00:12:22,160 --> 00:12:25,440
do

00:12:22,800 --> 00:12:27,040
you want to speed up and number will

00:12:25,440 --> 00:12:30,320
take care of it

00:12:27,040 --> 00:12:30,959
and currently number only works best

00:12:30,320 --> 00:12:34,240
with the

00:12:30,959 --> 00:12:36,800
functions not classes so if you want to

00:12:34,240 --> 00:12:37,440
accelerate your classes please do not

00:12:36,800 --> 00:12:39,839
use

00:12:37,440 --> 00:12:42,000
number otherwise you will you might have

00:12:39,839 --> 00:12:44,800
a lot of issue with that

00:12:42,000 --> 00:12:45,920
and number also has a very large user

00:12:44,800 --> 00:12:48,639
community

00:12:45,920 --> 00:12:50,839
which means that if you have any problem

00:12:48,639 --> 00:12:52,560
uh you can find the answer on the stack

00:12:50,839 --> 00:12:54,560
overflow

00:12:52,560 --> 00:12:56,240
when talking about number there are two

00:12:54,560 --> 00:12:59,120
modes you need to know

00:12:56,240 --> 00:12:59,600
the first one is no python no so in this

00:12:59,120 --> 00:13:02,560
mode

00:12:59,600 --> 00:13:03,600
number allows you to get rid of python

00:13:02,560 --> 00:13:06,240
gil

00:13:03,600 --> 00:13:07,920
so you can get the most of the

00:13:06,240 --> 00:13:10,880
performance from it

00:13:07,920 --> 00:13:12,480
but not every function is supported in

00:13:10,880 --> 00:13:14,560
no python mode so you

00:13:12,480 --> 00:13:16,240
sometimes you have to switch back to the

00:13:14,560 --> 00:13:18,480
option mode

00:13:16,240 --> 00:13:20,000
in order to know which function is

00:13:18,480 --> 00:13:22,000
support in which mode

00:13:20,000 --> 00:13:23,200
you have to look up the document in

00:13:22,000 --> 00:13:25,440
numbers website

00:13:23,200 --> 00:13:27,360
luckily the document itself is very

00:13:25,440 --> 00:13:30,079
thorough so you should

00:13:27,360 --> 00:13:30,480
you shouldn't have any problem to find

00:13:30,079 --> 00:13:33,680
out

00:13:30,480 --> 00:13:36,880
which one works in which mode

00:13:33,680 --> 00:13:38,480
finally if you want to use openmp you

00:13:36,880 --> 00:13:41,360
must use it with the no

00:13:38,480 --> 00:13:43,199
jit mode so basically you only can use

00:13:41,360 --> 00:13:46,000
it in the normal python mode

00:13:43,199 --> 00:13:47,360
and with that here is the sample code of

00:13:46,000 --> 00:13:50,560
the

00:13:47,360 --> 00:13:53,760
mp code as you can see all i have to do

00:13:50,560 --> 00:13:56,560
is just change the p range

00:13:53,760 --> 00:13:58,079
to p range and then roomba will

00:13:56,560 --> 00:14:00,800
recognize this

00:13:58,079 --> 00:14:01,360
and then trying to parallelize my code

00:14:00,800 --> 00:14:03,440
so

00:14:01,360 --> 00:14:05,279
there's just one character change and

00:14:03,440 --> 00:14:08,560
then i can get the most

00:14:05,279 --> 00:14:11,279
performance out of number

00:14:08,560 --> 00:14:13,360
now let's see how to implement log sun

00:14:11,279 --> 00:14:16,399
exponential by number

00:14:13,360 --> 00:14:18,880
here's the example i wrote

00:14:16,399 --> 00:14:20,320
as you can remember when you're looking

00:14:18,880 --> 00:14:22,639
at the code

00:14:20,320 --> 00:14:24,800
it's basically almost the same as the

00:14:22,639 --> 00:14:27,120
one i implement in numpy

00:14:24,800 --> 00:14:27,839
yes that's the correct that's correct

00:14:27,120 --> 00:14:30,480
they are

00:14:27,839 --> 00:14:31,519
exactly the same the only difference

00:14:30,480 --> 00:14:33,600
between this one

00:14:31,519 --> 00:14:35,760
and the previous one is that there are

00:14:33,600 --> 00:14:38,639
two different decorators i put

00:14:35,760 --> 00:14:39,680
so the first one is at jit and the

00:14:38,639 --> 00:14:43,760
second one is at

00:14:39,680 --> 00:14:46,880
njit and and everything else is

00:14:43,760 --> 00:14:48,639
almost the same and here's the result as

00:14:46,880 --> 00:14:50,480
you can see

00:14:48,639 --> 00:14:53,040
when using the null python mode with

00:14:50,480 --> 00:14:54,079
number the performance i get is about

00:14:53,040 --> 00:14:56,720
six seconds

00:14:54,079 --> 00:14:59,600
but when switching back to the jit mode

00:14:56,720 --> 00:15:02,800
it's about 6.7 seconds

00:14:59,600 --> 00:15:04,000
i think it's about 0.2 second slower

00:15:02,800 --> 00:15:06,959
than the original

00:15:04,000 --> 00:15:07,839
scipy functions so here's the very big

00:15:06,959 --> 00:15:11,040
difference

00:15:07,839 --> 00:15:12,160
if your function cannot accelerate by

00:15:11,040 --> 00:15:14,399
number

00:15:12,160 --> 00:15:15,279
sometimes it will give you the worst

00:15:14,399 --> 00:15:18,720
result

00:15:15,279 --> 00:15:20,160
so be careful with that now let's move

00:15:18,720 --> 00:15:23,680
on to the last solution

00:15:20,160 --> 00:15:26,399
python python is a relatively new

00:15:23,680 --> 00:15:27,519
open source project written by a french

00:15:26,399 --> 00:15:30,480
developer

00:15:27,519 --> 00:15:32,240
it is under very active development as

00:15:30,480 --> 00:15:35,279
it has a very fast

00:15:32,240 --> 00:15:38,480
growing community unlike number

00:15:35,279 --> 00:15:39,199
which use just-in-time technology python

00:15:38,480 --> 00:15:41,839
use

00:15:39,199 --> 00:15:43,759
ahead of time compiling approach

00:15:41,839 --> 00:15:46,959
basically it means that you will

00:15:43,759 --> 00:15:47,920
you will translate a part of your python

00:15:46,959 --> 00:15:51,920
and numpy code

00:15:47,920 --> 00:15:54,639
into c plus plus and then utilize modern

00:15:51,920 --> 00:15:55,279
compiler to compile and optimize your

00:15:54,639 --> 00:15:58,880
code

00:15:55,279 --> 00:15:59,440
into very efficient low-level machine

00:15:58,880 --> 00:16:02,560
code

00:15:59,440 --> 00:16:05,839
and runs faster it also supports

00:16:02,560 --> 00:16:08,880
a subset of python and non-pi functions

00:16:05,839 --> 00:16:12,480
and works on python 2.7

00:16:08,880 --> 00:16:15,120
and python 3.6 true 3.8

00:16:12,480 --> 00:16:17,519
just like number all you have to do is

00:16:15,120 --> 00:16:19,519
put a very spatial decorator before the

00:16:17,519 --> 00:16:22,720
function you want to boost

00:16:19,519 --> 00:16:23,440
and python will take the rest work for

00:16:22,720 --> 00:16:26,480
you

00:16:23,440 --> 00:16:27,519
and you also support openmp so you can

00:16:26,480 --> 00:16:31,199
utilize

00:16:27,519 --> 00:16:34,240
the full power of multi-threaded in your

00:16:31,199 --> 00:16:37,680
code so how do we

00:16:34,240 --> 00:16:39,839
implement on exponential in python

00:16:37,680 --> 00:16:41,839
to use python normally you need two

00:16:39,839 --> 00:16:44,560
steps first

00:16:41,839 --> 00:16:46,720
you just write the python code as usual

00:16:44,560 --> 00:16:48,720
so here is my sample code

00:16:46,720 --> 00:16:50,639
the only thing you have to do is put a

00:16:48,720 --> 00:16:53,839
very special decorator

00:16:50,639 --> 00:16:56,480
like over here it's the hashtag pathran

00:16:53,839 --> 00:16:57,279
export and then your function name and

00:16:56,480 --> 00:17:00,480
then

00:16:57,279 --> 00:17:03,199
the data type of of the input

00:17:00,480 --> 00:17:05,199
input data and that's pretty much

00:17:03,199 --> 00:17:07,439
everything you have to do

00:17:05,199 --> 00:17:09,199
and then the rest is just like the one

00:17:07,439 --> 00:17:11,520
in numpy

00:17:09,199 --> 00:17:14,000
after you finish editing the file all

00:17:11,520 --> 00:17:16,559
you have to do is compile you can use

00:17:14,000 --> 00:17:20,400
this very very long command

00:17:16,559 --> 00:17:23,439
over here or you can take a

00:17:20,400 --> 00:17:27,280
a easier one you just use python

00:17:23,439 --> 00:17:30,320
and then which part over here python

00:17:27,280 --> 00:17:31,280
and then your file name and you will use

00:17:30,320 --> 00:17:35,039
all the d4

00:17:31,280 --> 00:17:37,600
argument to compile your code

00:17:35,039 --> 00:17:39,919
so once you finish your code and compile

00:17:37,600 --> 00:17:44,000
your code without any compelling error

00:17:39,919 --> 00:17:46,799
raw then second step is that import it

00:17:44,000 --> 00:17:48,720
the compiled module to the file so you

00:17:46,799 --> 00:17:51,280
just create another file

00:17:48,720 --> 00:17:53,840
and then import just compile the module

00:17:51,280 --> 00:17:56,160
over here so here is the example

00:17:53,840 --> 00:17:57,120
and then all you have to do is just call

00:17:56,160 --> 00:18:00,160
the function

00:17:57,120 --> 00:18:03,840
like you used to do in the python

00:18:00,160 --> 00:18:07,280
so here is the code and the code will

00:18:03,840 --> 00:18:08,960
successful uh is executed here is the

00:18:07,280 --> 00:18:11,520
result of the password

00:18:08,960 --> 00:18:12,640
as you can see the result is much much

00:18:11,520 --> 00:18:16,160
faster than the

00:18:12,640 --> 00:18:19,360
non-price no python mode so

00:18:16,160 --> 00:18:20,360
sorry it's numbers no python it it only

00:18:19,360 --> 00:18:23,039
took

00:18:20,360 --> 00:18:25,679
5.45 seconds to finish

00:18:23,039 --> 00:18:26,320
it's about one and a half seconds faster

00:18:25,679 --> 00:18:29,760
than

00:18:26,320 --> 00:18:33,919
numbers no python mode so if you want to

00:18:29,760 --> 00:18:36,400
get the full power of your gp cpu

00:18:33,919 --> 00:18:37,679
please consider to use python to get the

00:18:36,400 --> 00:18:41,120
ultimate

00:18:37,679 --> 00:18:43,360
performance so that's it i just

00:18:41,120 --> 00:18:45,840
introduced three different approaches to

00:18:43,360 --> 00:18:48,160
improve your python and non-price code

00:18:45,840 --> 00:18:48,880
performance so right now you might want

00:18:48,160 --> 00:18:52,640
to ask

00:18:48,880 --> 00:18:55,679
which is better before we compare

00:18:52,640 --> 00:18:56,000
i have to tell you all the benchmark i

00:18:55,679 --> 00:18:58,400
run

00:18:56,000 --> 00:19:01,360
in the previous slide is on a bare metal

00:18:58,400 --> 00:19:05,200
machine with the following specification

00:19:01,360 --> 00:19:09,520
the cpu i use is an intel xion cpu

00:19:05,200 --> 00:19:12,960
and it comes with 256 gigabyte of ram

00:19:09,520 --> 00:19:16,880
it also has a geforce gtx 1080

00:19:12,960 --> 00:19:20,799
ti gpu the python version i use

00:19:16,880 --> 00:19:23,440
is 3.6.9 on ubuntu

00:19:20,799 --> 00:19:24,160
and all the other libraries and version

00:19:23,440 --> 00:19:27,440
information

00:19:24,160 --> 00:19:30,400
you can find on this slide

00:19:27,440 --> 00:19:31,120
in this slide i just put all previous

00:19:30,400 --> 00:19:33,679
benchmark

00:19:31,120 --> 00:19:36,720
results into same bar chart so you can

00:19:33,679 --> 00:19:39,679
compare the result by yourself

00:19:36,720 --> 00:19:40,160
the answer itself is quite clear if you

00:19:39,679 --> 00:19:43,760
have

00:19:40,160 --> 00:19:45,440
single or multiple gpu coupon will be

00:19:43,760 --> 00:19:47,679
your best choice

00:19:45,440 --> 00:19:49,200
because when you see the original

00:19:47,679 --> 00:19:52,240
function in scipy

00:19:49,200 --> 00:19:56,080
took about 6.7 to finish coupe i

00:19:52,240 --> 00:19:56,559
only need 1.6 seconds so that's about 5

00:19:56,080 --> 00:20:00,559
times

00:19:56,559 --> 00:20:03,120
faster it's just a no-brainer

00:20:00,559 --> 00:20:03,760
however if you don't have any gpu don't

00:20:03,120 --> 00:20:06,960
worry

00:20:03,760 --> 00:20:09,200
you still have the other option so as i

00:20:06,960 --> 00:20:11,360
mentioned before original sci price

00:20:09,200 --> 00:20:14,000
function took 6.7

00:20:11,360 --> 00:20:15,679
in this scenario i would suggest you to

00:20:14,000 --> 00:20:19,039
try number first

00:20:15,679 --> 00:20:22,640
because number supports more non-pi

00:20:19,039 --> 00:20:24,640
solution length python so

00:20:22,640 --> 00:20:25,760
after you give it a number a try you

00:20:24,640 --> 00:20:29,039
will find that

00:20:25,760 --> 00:20:31,200
in no jit mode number can successfully

00:20:29,039 --> 00:20:34,240
compile and ask you

00:20:31,200 --> 00:20:37,440
and it gives you about 0.7

00:20:34,240 --> 00:20:38,799
seconds faster and from now on you can

00:20:37,440 --> 00:20:42,159
give the python

00:20:38,799 --> 00:20:44,640
another try so if if the same function

00:20:42,159 --> 00:20:47,679
also support it entirely

00:20:44,640 --> 00:20:48,480
then it can give you extra performance

00:20:47,679 --> 00:20:51,520
boost

00:20:48,480 --> 00:20:53,120
in my case price range can works on in

00:20:51,520 --> 00:20:56,960
my benchmark code

00:20:53,120 --> 00:20:58,559
so the total execution time of python is

00:20:56,960 --> 00:21:01,120
5.4 second

00:20:58,559 --> 00:21:02,320
so by comparing to the original sci

00:21:01,120 --> 00:21:05,840
price version

00:21:02,320 --> 00:21:08,720
it's about 20 or 25 percent

00:21:05,840 --> 00:21:09,600
faster than original solution let's not

00:21:08,720 --> 00:21:12,720
bear for just

00:21:09,600 --> 00:21:13,440
change a few lines of code and get extra

00:21:12,720 --> 00:21:17,840
00:21:13,440 --> 00:21:17,840
of performance i can call you a day

00:21:18,480 --> 00:21:22,640
at the end i would like to show you my

00:21:20,799 --> 00:21:26,400
own decision tree

00:21:22,640 --> 00:21:29,200
to kupai number and python

00:21:26,400 --> 00:21:30,480
here is my decision tree so the first

00:21:29,200 --> 00:21:34,400
question starting with

00:21:30,480 --> 00:21:36,400
do you have gpu if you do have gpu then

00:21:34,400 --> 00:21:39,039
the following up question would be

00:21:36,400 --> 00:21:39,919
do you need to use cuda kernel or do you

00:21:39,039 --> 00:21:42,799
need to

00:21:39,919 --> 00:21:44,320
implement your own kuda kernel if the

00:21:42,799 --> 00:21:47,039
answer is still yes

00:21:44,320 --> 00:21:48,240
then i will uh recommend you to use

00:21:47,039 --> 00:21:50,799
coupon

00:21:48,240 --> 00:21:52,159
if the answer is no then the following

00:21:50,799 --> 00:21:55,280
question will be

00:21:52,159 --> 00:21:55,919
do you also have the cpu computation

00:21:55,280 --> 00:22:00,080
task

00:21:55,919 --> 00:22:02,960
with your gpu if the answer is yes

00:22:00,080 --> 00:22:03,600
then number will be a better choice

00:22:02,960 --> 00:22:06,720
otherwise

00:22:03,600 --> 00:22:09,520
please stay with school pi

00:22:06,720 --> 00:22:10,640
if you don't have any gpu you still have

00:22:09,520 --> 00:22:12,799
options right

00:22:10,640 --> 00:22:14,240
so the but the question itself will be

00:22:12,799 --> 00:22:17,360
very very easy

00:22:14,240 --> 00:22:20,000
do you like to deal with compiler

00:22:17,360 --> 00:22:22,000
so if the answer is no then i would

00:22:20,000 --> 00:22:24,720
suggest you to use number

00:22:22,000 --> 00:22:26,880
so it will only give you a very minimal

00:22:24,720 --> 00:22:29,280
compiling errors

00:22:26,880 --> 00:22:30,799
and if you are a gig and you you like to

00:22:29,280 --> 00:22:33,200
deal with the compiler

00:22:30,799 --> 00:22:34,480
compiling flag and all the compiling

00:22:33,200 --> 00:22:38,000
error logs

00:22:34,480 --> 00:22:41,440
and then of course python can give you

00:22:38,000 --> 00:22:42,159
the most of the and also if you choose

00:22:41,440 --> 00:22:45,840
python

00:22:42,159 --> 00:22:48,559
as the uh as the uh example i demo

00:22:45,840 --> 00:22:49,200
in the previous page and also in my real

00:22:48,559 --> 00:22:52,320
work

00:22:49,200 --> 00:22:55,679
python can almost always give me the

00:22:52,320 --> 00:22:57,760
most cpu power out of it so

00:22:55,679 --> 00:23:01,120
i would suggest you if you want to

00:22:57,760 --> 00:23:04,720
achieve the best performance with cpu

00:23:01,120 --> 00:23:07,280
python will be your best choice

00:23:04,720 --> 00:23:09,919
finally at the end of this talk i would

00:23:07,280 --> 00:23:13,280
like to provide three takeaways to you

00:23:09,919 --> 00:23:14,000
first if you have gpu please try coupon

00:23:13,280 --> 00:23:16,880
first

00:23:14,000 --> 00:23:17,280
it's really easy to use coupon just use

00:23:16,880 --> 00:23:20,320
you

00:23:17,280 --> 00:23:22,799
import coupons cp and then call

00:23:20,320 --> 00:23:25,600
non-price function with coupon but

00:23:22,799 --> 00:23:27,520
there's one thing you have to remember

00:23:25,600 --> 00:23:29,760
please remember to convert non-price

00:23:27,520 --> 00:23:32,559
array to cool price array

00:23:29,760 --> 00:23:33,120
so coupon can help you to move the data

00:23:32,559 --> 00:23:36,559
from

00:23:33,120 --> 00:23:39,600
physical memory to graphic cost memory

00:23:36,559 --> 00:23:41,679
second if you only have gpu that's

00:23:39,600 --> 00:23:44,159
totally fine because you still have

00:23:41,679 --> 00:23:46,320
option in this case i would suggest you

00:23:44,159 --> 00:23:48,400
to use number first

00:23:46,320 --> 00:23:50,480
because number supports more numpy

00:23:48,400 --> 00:23:53,760
functions than python

00:23:50,480 --> 00:23:54,559
and i would strongly recommend you to

00:23:53,760 --> 00:23:57,679
use

00:23:54,559 --> 00:24:00,559
number and it's no python mode

00:23:57,679 --> 00:24:01,200
if your code runs smoothly in with

00:24:00,559 --> 00:24:04,320
number

00:24:01,200 --> 00:24:05,120
and no python mode then i would suggest

00:24:04,320 --> 00:24:08,240
you to

00:24:05,120 --> 00:24:09,679
try python and python to get more

00:24:08,240 --> 00:24:13,600
performance

00:24:09,679 --> 00:24:16,720
in my company's case we can get the most

00:24:13,600 --> 00:24:19,279
cpu power with python every time so

00:24:16,720 --> 00:24:20,320
it's very worse to give you a try

00:24:19,279 --> 00:24:22,720
finally

00:24:20,320 --> 00:24:23,600
each solution support different type

00:24:22,720 --> 00:24:27,039
numbers of

00:24:23,600 --> 00:24:28,320
non-price function luckily each solution

00:24:27,039 --> 00:24:30,799
has a very well

00:24:28,320 --> 00:24:32,159
written and maintained website so you

00:24:30,799 --> 00:24:35,120
can easily find the

00:24:32,159 --> 00:24:36,640
supports uh function list on each

00:24:35,120 --> 00:24:39,120
solution's website

00:24:36,640 --> 00:24:41,679
so just give it a look and also it's

00:24:39,120 --> 00:24:42,640
fairly easy to find out which function

00:24:41,679 --> 00:24:44,960
doesn't work

00:24:42,640 --> 00:24:46,000
because normally your program will just

00:24:44,960 --> 00:24:47,760
die if the

00:24:46,000 --> 00:24:49,440
function is not supported by the

00:24:47,760 --> 00:24:53,520
proposed uh

00:24:49,440 --> 00:24:57,120
solution and also if a doesn't work

00:24:53,520 --> 00:24:59,200
uh be my word so if for example if

00:24:57,120 --> 00:25:00,960
if python doesn't work you can always

00:24:59,200 --> 00:25:04,960
give a number a try

00:25:00,960 --> 00:25:06,000
and in the reality especially during my

00:25:04,960 --> 00:25:09,919
work

00:25:06,000 --> 00:25:12,960
i always try to use a mixture of

00:25:09,919 --> 00:25:16,400
these three proposed method so

00:25:12,960 --> 00:25:20,159
sometimes i will use number with python

00:25:16,400 --> 00:25:20,880
or coupon with python so it's all up to

00:25:20,159 --> 00:25:24,000
you

00:25:20,880 --> 00:25:27,440
i would suggest you to give a mixture

00:25:24,000 --> 00:25:30,480
solution a try so that's pretty much

00:25:27,440 --> 00:25:42,720
all my talk thank you and i hope you

00:25:30,480 --> 00:25:42,720

YouTube URL: https://www.youtube.com/watch?v=Xkq12Zz8fro


