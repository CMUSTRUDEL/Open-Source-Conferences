Title: Benchmarking stuff made ridiculously easy (with lots of pictures) - Mr. Tennessee J Leeuwenburg
Publication date: 2011-08-22
Playlist: PyCon Australia 2011
Description: 
	(Mic issues for first ~1:30)

Tennessee has been working on a module for integrating cpu time management with unit testing
using an easy-to-use decorator. With all the options turned on, this will produce a
a performance history, tracked by revision, integrated with the software used to produce
the benchmarking graphs as used onÂ http://speed.pypy.org/. You too can have this kind of
shinyness for (almost) free!.
Captions: 
	00:00:01,490 --> 00:00:06,359
yeah thanks very much this talks kind of

00:00:04,350 --> 00:00:08,550
a mash-up between like what is

00:00:06,359 --> 00:00:09,750
benchmarking what do what should you be

00:00:08,550 --> 00:00:11,670
doing with the benchmarking what could

00:00:09,750 --> 00:00:13,440
you be doing with benchmarking and then

00:00:11,670 --> 00:00:15,389
it's kind of sliding through to some

00:00:13,440 --> 00:00:17,789
code that I wrote to to get this done at

00:00:15,389 --> 00:00:20,119
work so I thought I'd take a look at the

00:00:17,789 --> 00:00:23,490
history of benchmarking and it's either

00:00:20,119 --> 00:00:25,920
cobblers making shoes or possibly land

00:00:23,490 --> 00:00:27,510
surveyors attempting to gain a uniform

00:00:25,920 --> 00:00:29,760
information about the height of things

00:00:27,510 --> 00:00:30,929
above sea level so straight away you can

00:00:29,760 --> 00:00:33,450
see it's about something that you want

00:00:30,929 --> 00:00:36,690
to have happen the same way every time

00:00:33,450 --> 00:00:38,070
guaranteed bar none because you want to

00:00:36,690 --> 00:00:39,719
be able to sell someone a pair of shoes

00:00:38,070 --> 00:00:41,010
you don't want that you know they're too

00:00:39,719 --> 00:00:42,870
big or too small you need to come up

00:00:41,010 --> 00:00:46,320
with a way to make that or a repeatable

00:00:42,870 --> 00:00:48,930
process and any software application is

00:00:46,320 --> 00:00:50,910
that its core of a repeatable process so

00:00:48,930 --> 00:00:52,440
benchmarking is important to you if you

00:00:50,910 --> 00:00:57,000
want to make sure that the process is

00:00:52,440 --> 00:00:58,829
consistent and repeatable generally you

00:00:57,000 --> 00:01:01,250
do that by some kind of check against a

00:00:58,829 --> 00:01:02,940
standard hopefully an objective standard

00:01:01,250 --> 00:01:04,619
fundamentally it's evaluating

00:01:02,940 --> 00:01:06,960
performance through measurement so in

00:01:04,619 --> 00:01:08,909
this particular chart from the fictional

00:01:06,960 --> 00:01:10,830
marketing department we've got a

00:01:08,909 --> 00:01:13,680
struggle or measure or however they are

00:01:10,830 --> 00:01:15,540
this is how we are and what we can see

00:01:13,680 --> 00:01:18,270
over time is that we used to be terrible

00:01:15,540 --> 00:01:20,340
and now we managed to come come up close

00:01:18,270 --> 00:01:22,979
to the to the competition so this has

00:01:20,340 --> 00:01:25,080
really two functions one is it allowed

00:01:22,979 --> 00:01:27,570
me to see that you're behind the curve

00:01:25,080 --> 00:01:29,159
according to some particular measure the

00:01:27,570 --> 00:01:31,200
other ones that allow you to justify

00:01:29,159 --> 00:01:34,350
your pain arises by that the examinee of

00:01:31,200 --> 00:01:36,240
your past performance so let's take a

00:01:34,350 --> 00:01:38,549
look at a concrete concrete example this

00:01:36,240 --> 00:01:41,130
doesn't use any of the code armor but

00:01:38,549 --> 00:01:42,659
are very big on benchmarking in fact

00:01:41,130 --> 00:01:45,090
some major selling point that they have

00:01:42,659 --> 00:01:46,560
and David hooked in with someone who's

00:01:45,090 --> 00:01:49,229
building a system for visualizing

00:01:46,560 --> 00:01:51,930
performance called Coastie that goes to

00:01:49,229 --> 00:01:53,790
mention speed then go to focus no memory

00:01:51,930 --> 00:01:56,450
performance or anything else that makes

00:01:53,790 --> 00:02:03,299
sense peel business

00:01:56,450 --> 00:02:04,830
we've lost the mic never mind okay so an

00:02:03,299 --> 00:02:07,320
example of that like if your phone

00:02:04,830 --> 00:02:09,060
manufacturer you may have certain uptime

00:02:07,320 --> 00:02:12,450
guarantees may be more important to you

00:02:09,060 --> 00:02:14,130
than speed or some other metric so let's

00:02:12,450 --> 00:02:16,800
take a look straight away at the

00:02:14,130 --> 00:02:18,840
capacity of this of the imagery to tell

00:02:16,800 --> 00:02:20,970
the story about what's going on here so

00:02:18,840 --> 00:02:23,130
the yellow line is normalized C Python

00:02:20,970 --> 00:02:24,870
performance and straight away you can

00:02:23,130 --> 00:02:26,790
see that all of the blue things apart

00:02:24,870 --> 00:02:28,950
from the one in the middle under the

00:02:26,790 --> 00:02:30,420
yellow thing and it doesn't take a whole

00:02:28,950 --> 00:02:32,700
lot of rocket science to realize that

00:02:30,420 --> 00:02:34,170
that's actually a substantial

00:02:32,700 --> 00:02:35,610
performance enhancement over the

00:02:34,170 --> 00:02:37,260
particular thing that you meant you're

00:02:35,610 --> 00:02:40,019
measuring so you don't need to explain

00:02:37,260 --> 00:02:42,150
to someone in some complicated fashion

00:02:40,019 --> 00:02:43,680
that they could potentially move to pi

00:02:42,150 --> 00:02:45,870
PI of that if they're facing a speed

00:02:43,680 --> 00:02:49,500
restriction it really still tells the

00:02:45,870 --> 00:02:52,110
whole story you can use benchmarking in

00:02:49,500 --> 00:02:54,150
a few ways you could use it to push

00:02:52,110 --> 00:02:56,160
around the time that your developers are

00:02:54,150 --> 00:02:58,260
spending and the pressures that exist on

00:02:56,160 --> 00:02:59,880
them and one of the ways to do that is

00:02:58,260 --> 00:03:02,010
by introducing something into their

00:02:59,880 --> 00:03:03,690
feedback loop if you show them again and

00:03:02,010 --> 00:03:05,459
again and again that's something that

00:03:03,690 --> 00:03:07,530
they're doing is slower than it needs to

00:03:05,459 --> 00:03:09,720
be slower than in the past they're not

00:03:07,530 --> 00:03:11,070
really making it a priority you can

00:03:09,720 --> 00:03:13,560
bring it up and put pressure into the

00:03:11,070 --> 00:03:15,450
system and why pressure i don't mean

00:03:13,560 --> 00:03:18,359
making them work an extra four hours a

00:03:15,450 --> 00:03:20,549
day and eating pizzas or eating pizzas

00:03:18,359 --> 00:03:21,900
at work instead of having a life I just

00:03:20,549 --> 00:03:23,400
mean that you put it front and center in

00:03:21,900 --> 00:03:26,600
front of them and you say this thing is

00:03:23,400 --> 00:03:30,180
important so to improve performance

00:03:26,600 --> 00:03:33,150
measure it but this makes the selection

00:03:30,180 --> 00:03:35,940
of your measurement fairly important so

00:03:33,150 --> 00:03:37,260
here's an example of why you can take a

00:03:35,940 --> 00:03:38,820
look straight away at PI PI's

00:03:37,260 --> 00:03:40,500
performance over time now it might be

00:03:38,820 --> 00:03:42,600
drawing a bit of a longbow to say that

00:03:40,500 --> 00:03:44,910
this graph is responsible for pie pie

00:03:42,600 --> 00:03:46,470
pie speed enhancements over time but it

00:03:44,910 --> 00:03:49,350
shows the consistent application of

00:03:46,470 --> 00:03:51,329
effort and arguably you can see that it

00:03:49,350 --> 00:03:55,230
shows to some extent a diminishing

00:03:51,329 --> 00:03:57,690
return as they approximate towards what

00:03:55,230 --> 00:03:59,850
what might be around about the limits of

00:03:57,690 --> 00:04:01,440
what they can easily achieve but again

00:03:59,850 --> 00:04:03,150
it sell it sells another kind of

00:04:01,440 --> 00:04:06,030
important message that these people

00:04:03,150 --> 00:04:08,040
don't just care about speed now they've

00:04:06,030 --> 00:04:10,020
always cared about speed and they always

00:04:08,040 --> 00:04:12,390
will care about speed so if that's a

00:04:10,020 --> 00:04:14,730
one factor to you it sells that message

00:04:12,390 --> 00:04:16,770
quite effectively as well a word of

00:04:14,730 --> 00:04:19,709
warning you can prove anything with

00:04:16,770 --> 00:04:22,500
statistics there's just lies damn lies

00:04:19,709 --> 00:04:24,630
and statistics as they say so you really

00:04:22,500 --> 00:04:26,730
got to have a handle on selecting a

00:04:24,630 --> 00:04:29,390
number when you're making your initial

00:04:26,730 --> 00:04:32,160
graph it can be really quite important

00:04:29,390 --> 00:04:33,750
so what do you compare against compare

00:04:32,160 --> 00:04:35,670
comparison over time is one of the most

00:04:33,750 --> 00:04:38,010
straightforward kinds of comparison you

00:04:35,670 --> 00:04:40,020
can do but you do have a lot of other

00:04:38,010 --> 00:04:41,430
options for us configuration is relevant

00:04:40,020 --> 00:04:42,990
because we deploy to different places

00:04:41,430 --> 00:04:44,940
which have different amounts of

00:04:42,990 --> 00:04:47,160
geography involved so our data sets are

00:04:44,940 --> 00:04:48,660
very different in particular deployments

00:04:47,160 --> 00:04:50,790
so that might be something that's

00:04:48,660 --> 00:04:52,620
relevant relevant to your application or

00:04:50,790 --> 00:04:54,690
you can benchmark by Hardware I don't

00:04:52,620 --> 00:04:57,300
know if anyone's ever been pulled off

00:04:54,690 --> 00:04:59,520
their development development process to

00:04:57,300 --> 00:05:00,930
go okay you take this machine that we've

00:04:59,520 --> 00:05:02,400
just bought and tell us if it's any good

00:05:00,930 --> 00:05:05,040
for a week but it's not a whole lot of

00:05:02,400 --> 00:05:06,990
fun if you've got a direct competitor as

00:05:05,040 --> 00:05:09,170
you might with open source have access

00:05:06,990 --> 00:05:11,220
to their source code you can do

00:05:09,170 --> 00:05:12,570
comparison plots you can take a look at

00:05:11,220 --> 00:05:14,880
how you're doing compared to how they're

00:05:12,570 --> 00:05:16,680
doing and you can share quite a lot of

00:05:14,880 --> 00:05:18,900
information about what the crunch crunch

00:05:16,680 --> 00:05:20,520
parts are in each of your applications

00:05:18,900 --> 00:05:22,710
and some applications may even have

00:05:20,520 --> 00:05:24,690
standard trials and tests obvious ones

00:05:22,710 --> 00:05:29,100
being like acid three tests for HTML

00:05:24,690 --> 00:05:31,860
compliance you can use benchmarking to

00:05:29,100 --> 00:05:34,440
notice problems so instead of a bit

00:05:31,860 --> 00:05:37,290
speed being at something that you might

00:05:34,440 --> 00:05:38,730
have to go and run a specific report for

00:05:37,290 --> 00:05:42,090
you can just background it into your

00:05:38,730 --> 00:05:44,910
build bot and every time it spikes over

00:05:42,090 --> 00:05:46,320
six you get an email so you can push you

00:05:44,910 --> 00:05:47,670
can push it down so that you can just

00:05:46,320 --> 00:05:49,260
worry about it at the light at the

00:05:47,670 --> 00:05:51,240
latest possible minute rather than

00:05:49,260 --> 00:05:54,169
having to be having to be proactive

00:05:51,240 --> 00:05:56,640
about it you can push it out of your RAM

00:05:54,169 --> 00:05:57,960
so what's the benchmarking of software

00:05:56,640 --> 00:05:59,910
specifically you could ask what's

00:05:57,960 --> 00:06:01,410
measurable about software what should be

00:05:59,910 --> 00:06:02,940
the basis for comparison and what

00:06:01,410 --> 00:06:05,040
standards exist and this will change

00:06:02,940 --> 00:06:07,410
depending on your industry but most

00:06:05,040 --> 00:06:10,260
benchmarking is about speed because

00:06:07,410 --> 00:06:12,330
let's face it if it works the only thing

00:06:10,260 --> 00:06:13,950
you really care about is how fast it is

00:06:12,330 --> 00:06:15,570
if you've got something that's sitting

00:06:13,950 --> 00:06:19,560
there on your phone on your laptop and

00:06:15,570 --> 00:06:21,750
it works like that that is such a key to

00:06:19,560 --> 00:06:23,280
you know user acceptance of what it is

00:06:21,750 --> 00:06:23,790
that you're doing people will put up or

00:06:23,280 --> 00:06:26,060
put up

00:06:23,790 --> 00:06:28,140
a lot if it's fast we've got this

00:06:26,060 --> 00:06:30,590
application at work that was written by

00:06:28,140 --> 00:06:33,660
a non programmer in their off hours

00:06:30,590 --> 00:06:35,880
that's never been properly transitioned

00:06:33,660 --> 00:06:38,450
to our IT department is completely

00:06:35,880 --> 00:06:40,770
unsupported but it is the favorite

00:06:38,450 --> 00:06:43,350
application of our forecasters it's not

00:06:40,770 --> 00:06:45,300
the best it's not the most powerful but

00:06:43,350 --> 00:06:47,220
they just love it the most and it's

00:06:45,300 --> 00:06:49,830
because it works just exactly like that

00:06:47,220 --> 00:06:51,360
it's just snappy to use and everyone

00:06:49,830 --> 00:06:55,140
understands it it's easy to sell to

00:06:51,360 --> 00:06:57,570
people there are other aspects so you

00:06:55,140 --> 00:06:59,970
two can benchmark your Python code so

00:06:57,570 --> 00:07:02,160
there's this thing I wrote I'd like to

00:06:59,970 --> 00:07:05,100
share it benchmark adopt I will collect

00:07:02,160 --> 00:07:06,840
all of this information for you and it's

00:07:05,100 --> 00:07:08,520
designed to just work I think that the

00:07:06,840 --> 00:07:10,500
best gift you can give anyone when

00:07:08,520 --> 00:07:12,990
programming is to take something and

00:07:10,500 --> 00:07:16,140
make it really really easy for someone

00:07:12,990 --> 00:07:17,670
else to do so benchmark atop pie is a

00:07:16,140 --> 00:07:19,920
tool which measures and reports on

00:07:17,670 --> 00:07:21,960
execution speed it's a pretty thin

00:07:19,920 --> 00:07:23,850
wrapper around see profile it's not like

00:07:21,960 --> 00:07:27,030
a work of genius it's just a work of

00:07:23,850 --> 00:07:29,460
convenience it has integration for code

00:07:27,030 --> 00:07:33,810
speed and your manager will love it your

00:07:29,460 --> 00:07:36,360
mileage may vary so it's available for a

00:07:33,810 --> 00:07:38,460
very straightforward installation you

00:07:36,360 --> 00:07:40,410
can grab the source very easy to follow

00:07:38,460 --> 00:07:42,540
tutorials so one of the things that I've

00:07:40,410 --> 00:07:43,560
got is about for tutorials and I'm going

00:07:42,540 --> 00:07:45,510
to try and get through the slides

00:07:43,560 --> 00:07:46,770
reasonably quickly and we can take a

00:07:45,510 --> 00:07:49,110
little bit of a look at some of the

00:07:46,770 --> 00:07:52,680
demos that spec that's packaged with it

00:07:49,110 --> 00:07:56,400
and take a bit of a look at it I think

00:07:52,680 --> 00:07:58,590
it's fairly easy to use I either it's a

00:07:56,400 --> 00:07:59,900
good way to go or the most gratuitous

00:07:58,590 --> 00:08:04,080
use of a decorator and a presentation

00:07:59,900 --> 00:08:05,730
could be either and the fundamental

00:08:04,080 --> 00:08:07,860
model is is what I call test-driven

00:08:05,730 --> 00:08:10,500
benchmarking so one of the things that

00:08:07,860 --> 00:08:12,510
sometimes you might be concerned about

00:08:10,500 --> 00:08:14,160
is whether you need to have some careful

00:08:12,510 --> 00:08:16,110
control around the setup and

00:08:14,160 --> 00:08:19,110
installation of a benchmarking

00:08:16,110 --> 00:08:21,960
environment so you might you might need

00:08:19,110 --> 00:08:24,960
to do something like oh wait I'm heavily

00:08:21,960 --> 00:08:26,250
networked and what network involved one

00:08:24,960 --> 00:08:28,410
of the things you need to do then is

00:08:26,250 --> 00:08:32,099
like simulate network lag things like

00:08:28,410 --> 00:08:33,750
that all of those are good too to get

00:08:32,099 --> 00:08:35,370
right and will contribute towards your

00:08:33,750 --> 00:08:36,690
numbers and your information being far

00:08:35,370 --> 00:08:39,330
more correct

00:08:36,690 --> 00:08:42,900
but they may get in the way of the kind

00:08:39,330 --> 00:08:44,280
of 00 hurdle model of starting so what

00:08:42,900 --> 00:08:45,900
I've done isn't anything particularly

00:08:44,280 --> 00:08:47,670
genius it's just particularly convenient

00:08:45,900 --> 00:08:49,350
because you can just take your existing

00:08:47,670 --> 00:08:57,330
test suite and just go give me the

00:08:49,350 --> 00:09:00,090
numbers I'm trying to avoid this okay so

00:08:57,330 --> 00:09:03,510
how do you use it well you import it as

00:09:00,090 --> 00:09:04,800
a module then you import a sub module

00:09:03,510 --> 00:09:06,750
which is responsible for the actual

00:09:04,800 --> 00:09:08,550
collection of the information and then

00:09:06,750 --> 00:09:09,990
you import the decorator and then you

00:09:08,550 --> 00:09:11,820
just wrap your function around it so

00:09:09,990 --> 00:09:14,190
you've got some function that does

00:09:11,820 --> 00:09:15,960
something pointless inexpensive and then

00:09:14,190 --> 00:09:18,900
all you have to do is call it so you

00:09:15,960 --> 00:09:21,540
don't need to drop in a specialized

00:09:18,900 --> 00:09:23,040
execution piece of code to call this

00:09:21,540 --> 00:09:25,710
function over the top of it you don't

00:09:23,040 --> 00:09:28,500
need to write something that sits

00:09:25,710 --> 00:09:31,260
alongside pi dot test to like carefully

00:09:28,500 --> 00:09:33,000
do see profile run calls into these into

00:09:31,260 --> 00:09:35,190
these functions and end up duplicating

00:09:33,000 --> 00:09:37,440
half of your half of your API into the

00:09:35,190 --> 00:09:40,260
program you can just drop one of these

00:09:37,440 --> 00:09:42,000
in you can drop it into the absolute

00:09:40,260 --> 00:09:43,560
middle of a piece of your application

00:09:42,000 --> 00:09:45,330
just around any function that you decide

00:09:43,560 --> 00:09:46,890
hey I'm interested I don't know what

00:09:45,330 --> 00:09:48,420
this calls doing I think I might just

00:09:46,890 --> 00:09:50,400
drop a decorator in and see what comes

00:09:48,420 --> 00:09:52,170
out the other end or you could wrap it

00:09:50,400 --> 00:09:54,060
around every test function or you could

00:09:52,170 --> 00:09:56,360
wrap it around the slow test function or

00:09:54,060 --> 00:09:59,250
a failing test function and it will

00:09:56,360 --> 00:10:01,740
interpret that get in the way of the

00:09:59,250 --> 00:10:05,450
standard call to that function run it

00:10:01,740 --> 00:10:07,680
you know configurable number of times i

00:10:05,450 --> 00:10:09,510
accidentally defaulted it to a hundred

00:10:07,680 --> 00:10:11,730
it turns out that really slows down my

00:10:09,510 --> 00:10:13,380
test suite so you might want to pick a

00:10:11,730 --> 00:10:15,510
number like for you don't want to pick

00:10:13,380 --> 00:10:17,910
one it's just a thing to watch out for

00:10:15,510 --> 00:10:19,950
because there's so much invocation time

00:10:17,910 --> 00:10:21,780
the first time something runs often

00:10:19,950 --> 00:10:23,760
you've got to import a new module that

00:10:21,780 --> 00:10:26,430
takes more time but subsequent runs very

00:10:23,760 --> 00:10:29,070
fast so you generally want to take an

00:10:26,430 --> 00:10:31,440
average or you might as well just stick

00:10:29,070 --> 00:10:35,730
with the sum of some number of calls

00:10:31,440 --> 00:10:37,620
over time this then basically dumps you

00:10:35,730 --> 00:10:39,900
out of historical archive to disk so

00:10:37,620 --> 00:10:42,000
it's fairly loosely coupled so step one

00:10:39,900 --> 00:10:44,310
is build an archive of this stuff out on

00:10:42,000 --> 00:10:46,589
disk so one of the things I didn't want

00:10:44,310 --> 00:10:47,730
to do was end up coupling too many

00:10:46,589 --> 00:10:50,010
things together in this particular

00:10:47,730 --> 00:10:52,020
application and I think that's not

00:10:50,010 --> 00:10:54,120
bad rule of thumb for anyone doing like

00:10:52,020 --> 00:10:55,770
anything at work open source projects

00:10:54,120 --> 00:10:57,780
however it is you like to write code if

00:10:55,770 --> 00:10:59,880
you can come up with a natural

00:10:57,780 --> 00:11:01,470
separation point in this case the

00:10:59,880 --> 00:11:03,570
collection of statistics and the doing

00:11:01,470 --> 00:11:06,210
of something with them dump that dump

00:11:03,570 --> 00:11:08,580
that interface down onto disk as a

00:11:06,210 --> 00:11:10,140
historical archive you can you can do a

00:11:08,580 --> 00:11:11,670
lot of interesting things like that and

00:11:10,140 --> 00:11:13,470
of course these p stats objects that

00:11:11,670 --> 00:11:15,000
come out the other end there they're

00:11:13,470 --> 00:11:18,900
quite a rich data structure you can do

00:11:15,000 --> 00:11:22,050
quite a lot with them so you've got to

00:11:18,900 --> 00:11:24,150
choose what to pay attention to the the

00:11:22,050 --> 00:11:27,330
easiest choices are like whatever you

00:11:24,150 --> 00:11:29,250
want or everything but as you as you

00:11:27,330 --> 00:11:30,600
kind of get a bit more sophisticated and

00:11:29,250 --> 00:11:32,700
you realize wait there's actually a

00:11:30,600 --> 00:11:34,260
whole lot of everything and I don't

00:11:32,700 --> 00:11:36,300
really know what to pay attention to you

00:11:34,260 --> 00:11:38,370
might need to consider what it is that's

00:11:36,300 --> 00:11:40,290
going to give you your your best results

00:11:38,370 --> 00:11:42,660
there's no just magic answer watching

00:11:40,290 --> 00:11:44,190
the most expensive functions is not a

00:11:42,660 --> 00:11:46,140
bad idea but it often turns out that

00:11:44,190 --> 00:11:48,390
your most expensive expensive functions

00:11:46,140 --> 00:11:50,550
are already your most highly optimized

00:11:48,390 --> 00:11:52,290
ones you can't get around the fact that

00:11:50,550 --> 00:11:53,910
you've got a hundred giga byte array

00:11:52,290 --> 00:11:55,680
that you need to process you can't get

00:11:53,910 --> 00:11:57,750
around the fact that you've already

00:11:55,680 --> 00:11:59,670
pushed this call out to sea and that's

00:11:57,750 --> 00:12:01,680
as fast as the city that's as fast as

00:11:59,670 --> 00:12:03,210
disk reading rights go often those

00:12:01,680 --> 00:12:05,490
things will dominate your most expensive

00:12:03,210 --> 00:12:07,260
functions anyway so you need to do a bit

00:12:05,490 --> 00:12:09,540
of have a bit of insight into what it is

00:12:07,260 --> 00:12:10,950
your programs doing and start start kind

00:12:09,540 --> 00:12:12,630
of hand rolling this thing and that's

00:12:10,950 --> 00:12:15,060
sort of where some of the magic comes in

00:12:12,630 --> 00:12:18,240
about selecting a good set of set of

00:12:15,060 --> 00:12:20,340
things to be watching but again and this

00:12:18,240 --> 00:12:22,320
is where that's separated everything

00:12:20,340 --> 00:12:24,030
gets stored out to the disk and then you

00:12:22,320 --> 00:12:25,320
can go back and watch something else

00:12:24,030 --> 00:12:27,300
over history if you want to watch

00:12:25,320 --> 00:12:29,130
something else over history yet to watch

00:12:27,300 --> 00:12:31,140
the most common user operations that's a

00:12:29,130 --> 00:12:33,060
really good way to go when in doubt get

00:12:31,140 --> 00:12:34,920
user focused pay attention to what your

00:12:33,060 --> 00:12:37,380
customers want give them what they want

00:12:34,920 --> 00:12:40,020
and go okay well I'll take these system

00:12:37,380 --> 00:12:42,270
tests these represent the slowest or the

00:12:40,020 --> 00:12:44,580
most frequently executed user operations

00:12:42,270 --> 00:12:46,350
or the most business critical operations

00:12:44,580 --> 00:12:47,940
or just the things that people love

00:12:46,350 --> 00:12:50,160
which may actually not even be about

00:12:47,940 --> 00:12:51,990
your core functionality but they might

00:12:50,160 --> 00:12:53,790
just love the fact that you've got an

00:12:51,990 --> 00:12:55,410
integrated Twitter client and if that's

00:12:53,790 --> 00:12:58,170
slow that might hold them back so you

00:12:55,410 --> 00:13:01,500
can do a bit of audience perspective in

00:12:58,170 --> 00:13:03,180
your test suite in your benchmark watch

00:13:01,500 --> 00:13:05,700
watch list

00:13:03,180 --> 00:13:07,860
hand hand select a mixture of kind of

00:13:05,700 --> 00:13:09,390
like inner loop and outer loop things so

00:13:07,860 --> 00:13:11,820
you might want to take a look at you

00:13:09,390 --> 00:13:14,190
know how long does my whole test suite

00:13:11,820 --> 00:13:16,410
take how long does it take to do some

00:13:14,190 --> 00:13:18,360
complicated thing and then just like

00:13:16,410 --> 00:13:19,890
take a look at some contributory factors

00:13:18,360 --> 00:13:21,410
to that that might be relatively small

00:13:19,890 --> 00:13:24,680
but you might want to highly optimized

00:13:21,410 --> 00:13:28,650
critical path functions if you have a

00:13:24,680 --> 00:13:30,420
GUI application watching how fast QT

00:13:28,650 --> 00:13:32,190
lays out its dialogues like you know

00:13:30,420 --> 00:13:34,710
that happens in its own thread it may

00:13:32,190 --> 00:13:36,300
not be what's actually slowing that

00:13:34,710 --> 00:13:38,460
person down whose job it is to do

00:13:36,300 --> 00:13:39,930
something all day it might be the 10

00:13:38,460 --> 00:13:42,630
minute background task that you've got

00:13:39,930 --> 00:13:44,190
to go submit to your database so paying

00:13:42,630 --> 00:13:46,680
attention to what the critical path is

00:13:44,190 --> 00:13:49,050
in terms of the user interaction these

00:13:46,680 --> 00:13:51,810
are some numbers from from work so this

00:13:49,050 --> 00:13:54,870
is quite interesting this isn't a hybrid

00:13:51,810 --> 00:13:57,600
Python SI system and these are our most

00:13:54,870 --> 00:13:59,190
expensive functions and none of them are

00:13:57,600 --> 00:14:01,440
the Python functions they're all

00:13:59,190 --> 00:14:02,850
actually the sea functions so straight

00:14:01,440 --> 00:14:04,560
away it's quite interesting because

00:14:02,850 --> 00:14:06,420
actually I don't really need to

00:14:04,560 --> 00:14:08,070
benchmark my Python it turns out what I

00:14:06,420 --> 00:14:11,910
probably need to do is go upgrade some

00:14:08,070 --> 00:14:13,830
old cruft ec libraries almost all of the

00:14:11,910 --> 00:14:20,150
time is in one place you often hear

00:14:13,830 --> 00:14:23,700
about the 8020 rule this is the 99 and

00:14:20,150 --> 00:14:25,830
98 hundredths two to two hundredths

00:14:23,700 --> 00:14:28,140
rules okay that means that there are

00:14:25,830 --> 00:14:31,680
just 12 functions taking ninety percent

00:14:28,140 --> 00:14:34,010
of the time out of 6700 functions so

00:14:31,680 --> 00:14:36,510
straight away you just go I know exactly

00:14:34,010 --> 00:14:40,710
where to look for what's low in this

00:14:36,510 --> 00:14:42,780
particular application version control

00:14:40,710 --> 00:14:44,010
is integrated but primitive obviously

00:14:42,780 --> 00:14:47,870
you want to tie these things back to

00:14:44,010 --> 00:14:51,150
commits when you can and it's on the way

00:14:47,870 --> 00:14:53,070
visualization is done through this code

00:14:51,150 --> 00:14:55,290
speed interface but you can do it

00:14:53,070 --> 00:14:56,940
through excel as a comma separated value

00:14:55,290 --> 00:14:58,290
exporter so you can email these things

00:14:56,940 --> 00:15:01,380
to your manager who can open them in

00:14:58,290 --> 00:15:03,120
Excel so there's a demo on there so I

00:15:01,380 --> 00:15:05,070
thought I'd grab a few few real world

00:15:03,120 --> 00:15:07,230
examples these are Python implemented

00:15:05,070 --> 00:15:09,330
sort functions and a Fibonacci Fibonacci

00:15:07,230 --> 00:15:12,150
calculator that calculates the Fibonacci

00:15:09,330 --> 00:15:13,920
of 26 so straight away you get to see

00:15:12,150 --> 00:15:16,440
your first-year University course

00:15:13,920 --> 00:15:17,100
smiling back at you with bubble sort

00:15:16,440 --> 00:15:20,070
insertion

00:15:17,100 --> 00:15:21,720
sort merge quick and where would Python

00:15:20,070 --> 00:15:26,460
be without a Tim sort that doesn't even

00:15:21,720 --> 00:15:28,740
register on my graph I'm going to

00:15:26,460 --> 00:15:32,280
probably hurry through to some extent

00:15:28,740 --> 00:15:34,620
the controlling the environment I would

00:15:32,280 --> 00:15:37,110
just just caution you don't always know

00:15:34,620 --> 00:15:39,060
the call-in paths to a function even if

00:15:37,110 --> 00:15:40,770
you think you do so write a particular

00:15:39,060 --> 00:15:43,500
top-level test that calls it in a

00:15:40,770 --> 00:15:45,750
particular way and and you'll avoid a

00:15:43,500 --> 00:15:47,360
few issues try a few things like

00:15:45,750 --> 00:15:52,590
different different kinds of data

00:15:47,360 --> 00:15:54,060
realistic data the this again take a

00:15:52,590 --> 00:15:58,440
look at total time versus cumulative

00:15:54,060 --> 00:16:00,630
time total time is actually the time

00:15:58,440 --> 00:16:02,880
that you can make less by making

00:16:00,630 --> 00:16:04,500
algorithms more efficient cumulative

00:16:02,880 --> 00:16:06,510
time is the sort of thing where you go I

00:16:04,500 --> 00:16:10,830
might be wrapping my my contributing

00:16:06,510 --> 00:16:12,810
functions up in some bad way and future

00:16:10,830 --> 00:16:14,820
directions I need a user base larger

00:16:12,810 --> 00:16:17,160
than one I need to integrate properly

00:16:14,820 --> 00:16:19,440
with version control I think I can make

00:16:17,160 --> 00:16:21,210
the interface even simpler and there's

00:16:19,440 --> 00:16:24,320
just you know this is really just my

00:16:21,210 --> 00:16:26,700
to-do list may not be that interesting

00:16:24,320 --> 00:16:28,200
acknowledgments I'd like to thank its

00:16:26,700 --> 00:16:30,570
coalfield who got the code speed

00:16:28,200 --> 00:16:32,700
integration over the line Mikkel Taurus

00:16:30,570 --> 00:16:34,680
who developed code speed and the Bureau

00:16:32,700 --> 00:16:37,950
of Meteorology for allowing this work to

00:16:34,680 --> 00:16:39,210
progress is open source no I've got only

00:16:37,950 --> 00:16:43,980
one minute left but i'm just going to

00:16:39,210 --> 00:16:47,340
bounce back sorry 05 awesome maya my

00:16:43,980 --> 00:16:48,900
android is fast I'm just going to bounce

00:16:47,340 --> 00:16:50,460
back because having gone through the

00:16:48,900 --> 00:16:53,490
slides I really don't think I made

00:16:50,460 --> 00:16:55,680
enough of what's going on here now this

00:16:53,490 --> 00:16:57,780
thing here is a web application called

00:16:55,680 --> 00:17:00,870
code speed that just sits there and it

00:16:57,780 --> 00:17:03,660
draws these graphs it draws over time

00:17:00,870 --> 00:17:06,660
graphs and it draws these normalized

00:17:03,660 --> 00:17:10,010
relative to some baseline graph and it

00:17:06,660 --> 00:17:12,560
currently runs pi PI it gives you

00:17:10,010 --> 00:17:14,970
comparison overtime against C Python

00:17:12,560 --> 00:17:17,040
there's a move on to maybe do the same

00:17:14,970 --> 00:17:19,980
thing for C Python so that you can get

00:17:17,040 --> 00:17:21,810
per function graphs these things are all

00:17:19,980 --> 00:17:24,180
available over time per function as well

00:17:21,810 --> 00:17:26,370
it's quite a powerful application you

00:17:24,180 --> 00:17:29,820
could readily use the code I've written

00:17:26,370 --> 00:17:31,020
to just drop it drop a configuration

00:17:29,820 --> 00:17:32,610
into your pie test and

00:17:31,020 --> 00:17:36,030
basically auto submit what you've

00:17:32,610 --> 00:17:39,000
already got now I think you'd probably

00:17:36,030 --> 00:17:41,430
get it up inside of an hour maybe two

00:17:39,000 --> 00:17:43,860
hours there's a fab installer for code

00:17:41,430 --> 00:17:45,930
speed as part of this as part of the

00:17:43,860 --> 00:17:48,750
code base you just go fab install code

00:17:45,930 --> 00:17:51,450
speed sets up an example for you you do

00:17:48,750 --> 00:17:53,220
a minimal configuration of your unit

00:17:51,450 --> 00:17:55,920
tests and minimal configuration of the

00:17:53,220 --> 00:17:57,630
submission to code speed and you'll have

00:17:55,920 --> 00:18:01,110
a website running up with a graph inside

00:17:57,630 --> 00:18:02,910
an hour or easy so look thanks everyone

00:18:01,110 --> 00:18:09,930
for their time I hope I wasn't too

00:18:02,910 --> 00:18:18,990
disorganized okay we got time for a

00:18:09,930 --> 00:18:21,270
couple questions you said it wrapped

00:18:18,990 --> 00:18:23,540
around the sea profile module does it

00:18:21,270 --> 00:18:29,520
have any support for the run snake run

00:18:23,540 --> 00:18:31,320
visualizer no it should it was it came

00:18:29,520 --> 00:18:33,960
together very quickly so i kept it

00:18:31,320 --> 00:18:35,460
fairly minimal i quite like to put some

00:18:33,960 --> 00:18:43,200
more features into this thing over the

00:18:35,460 --> 00:18:46,200
next sort of six months or so so curious

00:18:43,200 --> 00:18:48,000
about how this might fit into a larger

00:18:46,200 --> 00:18:51,060
bill bottle of continuous integration

00:18:48,000 --> 00:18:53,190
kind of environment have you given some

00:18:51,060 --> 00:18:55,260
thought to where the boundary points in

00:18:53,190 --> 00:18:57,390
that might be yeah you could pick it up

00:18:55,260 --> 00:18:59,370
pretty much as is say you had jenkins

00:18:57,390 --> 00:19:02,130
you could do a non complete you could

00:18:59,370 --> 00:19:04,710
easily do an execution of your unit

00:19:02,130 --> 00:19:06,600
tests with this stuff turned on and a

00:19:04,710 --> 00:19:08,400
specified version tag that came out of

00:19:06,600 --> 00:19:10,980
your build bought it would drop it into

00:19:08,400 --> 00:19:13,260
into that historical disk archive with a

00:19:10,980 --> 00:19:16,050
version number and then when when that's

00:19:13,260 --> 00:19:17,310
enabled this the code speed submission

00:19:16,050 --> 00:19:18,930
will sniff the version number out of the

00:19:17,310 --> 00:19:21,450
file name and you will get a version

00:19:18,930 --> 00:19:24,150
history of your of your speed over time

00:19:21,450 --> 00:19:26,610
it will slow down your test suite so you

00:19:24,150 --> 00:19:29,040
might want to do it on every fifteenth

00:19:26,610 --> 00:19:32,070
commit or nightly instead of every time

00:19:29,040 --> 00:19:38,610
and yeah it's pretty easy to integrate

00:19:32,070 --> 00:19:41,580
yeah actually I do have a question for

00:19:38,610 --> 00:19:43,530
you which I was thinking look you two

00:19:41,580 --> 00:19:44,820
aspects that one you've lost over and

00:19:43,530 --> 00:19:45,299
the other you had on the slide but I

00:19:44,820 --> 00:19:46,309
think

00:19:45,299 --> 00:19:49,070
you actually mentioned explicitly

00:19:46,309 --> 00:19:52,559
intrigued to see how you're handling it

00:19:49,070 --> 00:19:54,539
the first one is if you're running on a

00:19:52,559 --> 00:19:55,950
box where something else is running you

00:19:54,539 --> 00:19:57,539
know if you are to share machine and

00:19:55,950 --> 00:19:58,860
someone else kickstarts their massive

00:19:57,539 --> 00:20:00,480
lightly processing when you start your

00:19:58,860 --> 00:20:02,639
benchmark and your benchmarking data is

00:20:00,480 --> 00:20:05,460
really quite tainted yeah is there any

00:20:02,639 --> 00:20:07,559
protection or coverage against knowing

00:20:05,460 --> 00:20:09,960
that has happened or reporting that in

00:20:07,559 --> 00:20:12,509
the data no I had a go at looking to see

00:20:09,960 --> 00:20:14,580
what could potentially be done and

00:20:12,509 --> 00:20:17,460
there's not an enormous amount you could

00:20:14,580 --> 00:20:19,859
maybe virtualize it might be something

00:20:17,460 --> 00:20:21,840
you could do but all of the advice from

00:20:19,859 --> 00:20:24,029
the from those who have gone before is

00:20:21,840 --> 00:20:26,759
to not run it on a machine that's doing

00:20:24,029 --> 00:20:28,799
anything else at the time I wish they

00:20:26,759 --> 00:20:30,359
were a better answer though okay the

00:20:28,799 --> 00:20:33,509
second one sort of the other part of it

00:20:30,359 --> 00:20:35,220
is on the first time you run anybody of

00:20:33,509 --> 00:20:36,749
courage like if you've entered I've got

00:20:35,220 --> 00:20:37,980
a selection of people I files the first

00:20:36,749 --> 00:20:39,509
time you run it it compiles and

00:20:37,980 --> 00:20:42,090
generates all the pyc files and that the

00:20:39,509 --> 00:20:43,830
first profile run can universally be

00:20:42,090 --> 00:20:45,869
thrown away unless you are only ever

00:20:43,830 --> 00:20:49,799
doing one run and testing that as part

00:20:45,869 --> 00:20:52,739
of the the profiling process is there

00:20:49,799 --> 00:20:55,109
any particular reason that you can or

00:20:52,739 --> 00:20:59,940
should include that first run in your

00:20:55,109 --> 00:21:01,619
averages well the answer is probably the

00:20:59,940 --> 00:21:03,299
default mode for this application should

00:21:01,619 --> 00:21:04,950
be to throw away the first run but

00:21:03,299 --> 00:21:07,679
that's not how it is it includes the

00:21:04,950 --> 00:21:09,809
first run arguments for why you wouldn't

00:21:07,679 --> 00:21:12,090
obvious is that often in operations

00:21:09,809 --> 00:21:13,619
that's a sunk cost it's gone it's just

00:21:12,090 --> 00:21:15,239
happened when the application started

00:21:13,619 --> 00:21:17,730
ninety percent of the modules got import

00:21:15,239 --> 00:21:20,369
imported things already the argument for

00:21:17,730 --> 00:21:22,830
why you might include it is if you have

00:21:20,369 --> 00:21:24,330
dynamic reloading of your Python for any

00:21:22,830 --> 00:21:26,249
particular reason you might want to

00:21:24,330 --> 00:21:28,379
maybe you'll serve a startup time

00:21:26,249 --> 00:21:30,779
actually is the thing you're testing and

00:21:28,379 --> 00:21:32,549
so you actually want to know about the

00:21:30,779 --> 00:21:34,470
startup time so it's about controlling

00:21:32,549 --> 00:21:37,320
without paying attention to the right

00:21:34,470 --> 00:21:40,529
things is there a other any hooks or

00:21:37,320 --> 00:21:42,600
plans to add hooks to flush all the pyc

00:21:40,529 --> 00:21:44,669
files so that actually can be something

00:21:42,600 --> 00:21:46,619
that you profile specifically as assume

00:21:44,669 --> 00:21:47,970
legislates profile yeah assuring that

00:21:46,619 --> 00:21:49,499
we're starting with a clip it's a good

00:21:47,970 --> 00:21:55,529
idea it wouldn't take very long to

00:21:49,499 --> 00:21:58,359
implement yeah okay

00:21:55,529 --> 00:22:00,340
yes sir um one thing I was thinking

00:21:58,359 --> 00:22:02,739
about and you did mention this earlier

00:22:00,340 --> 00:22:04,269
was that if you've got a large

00:22:02,739 --> 00:22:05,590
application you really have to pick and

00:22:04,269 --> 00:22:07,809
choose what it is you really want to

00:22:05,590 --> 00:22:10,149
profile so is there an easy way to keep

00:22:07,809 --> 00:22:12,879
track of what it was that you picked and

00:22:10,149 --> 00:22:14,799
chosen yeah so when when you set up the

00:22:12,879 --> 00:22:17,409
code speed submission thing you just

00:22:14,799 --> 00:22:19,779
list functions and so I would encourage

00:22:17,409 --> 00:22:21,789
people to stick with a list of functions

00:22:19,779 --> 00:22:23,830
over time because the meaning of how

00:22:21,789 --> 00:22:26,440
long those things take won't be apparent

00:22:23,830 --> 00:22:28,179
the first time you do it you'll need to

00:22:26,440 --> 00:22:30,099
run that thing for three months before

00:22:28,179 --> 00:22:32,440
you finally figure out the relationship

00:22:30,099 --> 00:22:34,269
between what you're watching and what's

00:22:32,440 --> 00:22:36,639
going on on the desk and what everyone's

00:22:34,269 --> 00:22:38,799
reactions are so that the users might

00:22:36,639 --> 00:22:40,419
react to something having a consistency

00:22:38,799 --> 00:22:42,339
over time in your reporting to the

00:22:40,419 --> 00:22:44,019
organization into your manager is an

00:22:42,339 --> 00:22:47,289
important part of them understanding

00:22:44,019 --> 00:22:48,969
what you're telling them so if you're

00:22:47,289 --> 00:22:51,129
seriously going to do it a good amount

00:22:48,969 --> 00:22:52,629
of initial consideration and then

00:22:51,129 --> 00:22:55,839
consistency of what you're reporting

00:22:52,629 --> 00:22:57,429
over time is really important but this

00:22:55,839 --> 00:22:59,859
does have the capacity because it stores

00:22:57,429 --> 00:23:02,440
the historical archive to essentially

00:22:59,859 --> 00:23:05,679
rerun history and and resubmit over a

00:23:02,440 --> 00:23:07,269
different set of functions actually I

00:23:05,679 --> 00:23:08,919
even think you should probably have

00:23:07,269 --> 00:23:10,029
multiple perspectives that you're

00:23:08,919 --> 00:23:11,589
watching you should have like your

00:23:10,029 --> 00:23:13,059
managers perspective and your users

00:23:11,589 --> 00:23:15,519
perspective and you could actually

00:23:13,059 --> 00:23:17,109
record have multiple code speeds for

00:23:15,519 --> 00:23:19,529
multiple audiences you know if you

00:23:17,109 --> 00:23:21,940
really want to go the whole nine yard I

00:23:19,529 --> 00:23:23,109
guess the next it's almost the opposite

00:23:21,940 --> 00:23:26,049
question what you're asking before his

00:23:23,109 --> 00:23:27,940
ways of running tests done under load

00:23:26,049 --> 00:23:29,139
under load scenario so as I said it's

00:23:27,940 --> 00:23:30,249
the easiest ways to get a computer

00:23:29,139 --> 00:23:32,229
that's not doing anything else in test

00:23:30,249 --> 00:23:34,089
what it is but the question is you know

00:23:32,229 --> 00:23:35,349
if it's only you haven't actually got as

00:23:34,089 --> 00:23:37,089
much memory to run some of these things

00:23:35,349 --> 00:23:39,669
whether there's a speed difference and

00:23:37,089 --> 00:23:41,950
things like that yeah I mean that a lot

00:23:39,669 --> 00:23:43,359
of that will come into it will not so

00:23:41,950 --> 00:23:44,919
much be a part of the benchmarking

00:23:43,359 --> 00:23:48,159
application as it will be a part of your

00:23:44,919 --> 00:23:49,479
test invocation environment and there

00:23:48,159 --> 00:23:51,429
are things that there is definitely

00:23:49,479 --> 00:23:53,589
network simulators for example that you

00:23:51,429 --> 00:23:57,009
might want to either plug in as a mock

00:23:53,589 --> 00:23:59,739
in some of your tests anyway because you

00:23:57,009 --> 00:24:01,690
want to be testing them anyway and yeah

00:23:59,739 --> 00:24:03,519
you there's just so many levels of

00:24:01,690 --> 00:24:05,409
sophistication the idea behind this is

00:24:03,519 --> 00:24:07,870
that you can take your existing code

00:24:05,409 --> 00:24:11,050
base and for the cost

00:24:07,870 --> 00:24:13,330
30 lines of code get graphs inside of an

00:24:11,050 --> 00:24:14,500
hour and then that extra sophistication

00:24:13,330 --> 00:24:18,480
would probably come in to test

00:24:14,500 --> 00:24:18,480
configuration rather than this code base

00:24:18,720 --> 00:24:23,260
one of the problems in Python web

00:24:21,670 --> 00:24:25,510
applications is that people do

00:24:23,260 --> 00:24:27,760
benchmarks but the applications aren't

00:24:25,510 --> 00:24:29,200
real data and so when you move into

00:24:27,760 --> 00:24:31,480
production it's a totally different

00:24:29,200 --> 00:24:32,830
picture because yeah you just think it's

00:24:31,480 --> 00:24:34,330
a behavior defined that sort of sub

00:24:32,830 --> 00:24:36,280
problem in what you're doing and that

00:24:34,330 --> 00:24:38,080
you'll do benchmarks and unit testing

00:24:36,280 --> 00:24:40,500
with in reality when you're actually in

00:24:38,080 --> 00:24:43,270
the real lap it's a total different well

00:24:40,500 --> 00:24:45,760
just for historical reasons we don't get

00:24:43,270 --> 00:24:47,530
bitten by that particular thing but I

00:24:45,760 --> 00:24:49,360
think it's generally important to

00:24:47,530 --> 00:24:50,980
realize that unit testing isn't just the

00:24:49,360 --> 00:24:53,080
answer to everything and you actually

00:24:50,980 --> 00:24:54,940
need some system tests and smoke tests

00:24:53,080 --> 00:24:57,010
to go along with it and the system tests

00:24:54,940 --> 00:24:59,740
should actually be realistic as should

00:24:57,010 --> 00:25:01,120
the smoke tests and then those things

00:24:59,740 --> 00:25:02,140
will give you performance numbers that

00:25:01,120 --> 00:25:04,900
are closer to your production

00:25:02,140 --> 00:25:06,160
environment yeah if you've never tested

00:25:04,900 --> 00:25:07,780
how your code works in a production

00:25:06,160 --> 00:25:10,750
environment and you deploy it to

00:25:07,780 --> 00:25:12,160
production I think that's bad so I just

00:25:10,750 --> 00:25:20,170
think it's important to have stages of

00:25:12,160 --> 00:25:24,090
testing any more questions all right

00:25:20,170 --> 00:25:24,090

YouTube URL: https://www.youtube.com/watch?v=N2_DvRBokS0


