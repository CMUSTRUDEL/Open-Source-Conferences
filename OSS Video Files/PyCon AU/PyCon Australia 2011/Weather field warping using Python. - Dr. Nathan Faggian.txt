Title: Weather field warping using Python. - Dr. Nathan Faggian
Publication date: 2011-08-22
Playlist: PyCon Australia 2011
Description: 
	Python is a great language for prototyping computer vision algorithms, the availability of libraries such as Numpy and Scipy make for rapid development similar to that of Matlab, R and IDL. At the Bureau of Meteorology (BoM) we are solving the interesting problem of weather field warping. Warping (aka non-linear image registration) is used, for example, to determine what the predicted temperature will be hourly if we only have predictions every three hours
Captions: 
	00:00:02,389 --> 00:00:07,049
Thanks it's sort of appropriate that i'm

00:00:05,339 --> 00:00:10,349
talking about warping because my slides

00:00:07,049 --> 00:00:13,019
are warped a little bit so I hope it

00:00:10,349 --> 00:00:18,060
doesn't affect anybody but I noticed

00:00:13,019 --> 00:00:21,240
today that I didn't have a very detailed

00:00:18,060 --> 00:00:24,150
description of my background or where

00:00:21,240 --> 00:00:26,550
I'm from so I thought I'd stick in

00:00:24,150 --> 00:00:28,019
something about the author and just just

00:00:26,550 --> 00:00:30,750
communicate to you guys that my

00:00:28,019 --> 00:00:33,780
backgrounds basically computer science

00:00:30,750 --> 00:00:36,620
i'm not a meteorologist any of the views

00:00:33,780 --> 00:00:40,050
that i'm pushing out there on my own and

00:00:36,620 --> 00:00:44,789
you know i've been involved with python

00:00:40,050 --> 00:00:47,370
probably from from my postdoc days and

00:00:44,789 --> 00:00:50,399
medical imaging up until recently when I

00:00:47,370 --> 00:00:52,320
became a Python developer at bomb but

00:00:50,399 --> 00:00:55,309
before that I was very much into

00:00:52,320 --> 00:00:58,590
computer vision face recognition and

00:00:55,309 --> 00:01:00,030
modeling of human faces and that's me

00:00:58,590 --> 00:01:06,689
when I had a mohawk a couple of years

00:01:00,030 --> 00:01:09,200
ago so back to the weather I guess this

00:01:06,689 --> 00:01:14,760
is a talk about manipulating

00:01:09,200 --> 00:01:18,180
Weatherfield data and the context of

00:01:14,760 --> 00:01:20,610
this talk will will be really around how

00:01:18,180 --> 00:01:27,720
we're trying to make things easier for a

00:01:20,610 --> 00:01:29,250
forecaster at the bureau generally there

00:01:27,720 --> 00:01:32,250
are a few really complex problems that

00:01:29,250 --> 00:01:35,130
are trying to be addressed so you know

00:01:32,250 --> 00:01:36,840
that I tried to categorize these and you

00:01:35,130 --> 00:01:38,640
know basically the first one that

00:01:36,840 --> 00:01:40,680
everybody knows about is numerical

00:01:38,640 --> 00:01:43,229
weather prediction and that's been

00:01:40,680 --> 00:01:45,270
developed for very very very many years

00:01:43,229 --> 00:01:47,130
now and it's just getting more complex

00:01:45,270 --> 00:01:49,530
so we're getting to a position where

00:01:47,130 --> 00:01:52,890
we're trying to describe physical

00:01:49,530 --> 00:01:55,020
properties scales that we previously

00:01:52,890 --> 00:01:57,509
couldn't even try to model before

00:01:55,020 --> 00:02:00,030
because we've got bigger supercomputers

00:01:57,509 --> 00:02:02,909
and we've got more complex

00:02:00,030 --> 00:02:04,560
understandings of the physics then we

00:02:02,909 --> 00:02:06,780
also have the additional problem of

00:02:04,560 --> 00:02:09,060
actually trying to make decisions based

00:02:06,780 --> 00:02:10,679
on this data so aggregating all of this

00:02:09,060 --> 00:02:13,110
numerical weather prediction data that's

00:02:10,679 --> 00:02:13,950
what the forecaster does forecasters the

00:02:13,110 --> 00:02:16,290
human computer

00:02:13,950 --> 00:02:19,530
that makes the decisions about forecasts

00:02:16,290 --> 00:02:21,330
and issuing warnings and things and then

00:02:19,530 --> 00:02:23,220
you've got this additional problem again

00:02:21,330 --> 00:02:25,140
a forecast system so enabling

00:02:23,220 --> 00:02:27,900
forecasters to actually do that and

00:02:25,140 --> 00:02:29,819
that's sort of the Calgary that I'm

00:02:27,900 --> 00:02:32,160
falling into generally i'm working in

00:02:29,819 --> 00:02:35,160
forecast systems and we're responsible

00:02:32,160 --> 00:02:36,750
for you know generating manipulating and

00:02:35,160 --> 00:02:44,180
visualizing the guidance that goes to

00:02:36,750 --> 00:02:47,250
forecasters so just to try and motivate

00:02:44,180 --> 00:02:50,069
the problem i'm going to be looking at a

00:02:47,250 --> 00:02:52,500
case study which was cyclone yasi that

00:02:50,069 --> 00:02:56,519
was a tropical cyclone that hit northern

00:02:52,500 --> 00:02:58,560
Australia and februari this year and it

00:02:56,519 --> 00:03:00,090
was a very big cyclone and so I thought

00:02:58,560 --> 00:03:03,750
it'd be very interesting to talk about a

00:03:00,090 --> 00:03:05,610
very big cyclone in my talk the details

00:03:03,750 --> 00:03:07,290
are pretty impressive it had had

00:03:05,610 --> 00:03:11,760
something like a sustained wind speed of

00:03:07,290 --> 00:03:16,140
200 kilometers an hour and wind gusts of

00:03:11,760 --> 00:03:21,989
almost I guess 300 285 corners now so it

00:03:16,140 --> 00:03:25,170
was a it was a real beast so I talked

00:03:21,989 --> 00:03:27,840
about whether field warping and enabling

00:03:25,170 --> 00:03:31,260
forecasters and trying to help them make

00:03:27,840 --> 00:03:34,019
decisions and really what this talk is

00:03:31,260 --> 00:03:37,170
about is about improving this concept of

00:03:34,019 --> 00:03:39,930
whether field interpolation Weatherfield

00:03:37,170 --> 00:03:41,940
interpolation is about estimating the

00:03:39,930 --> 00:03:45,450
unknown data points between the known

00:03:41,940 --> 00:03:48,239
data points and so to motivate this with

00:03:45,450 --> 00:03:51,420
a real example I've just picked out some

00:03:48,239 --> 00:03:54,329
surface level pressure fields of Cyclone

00:03:51,420 --> 00:03:56,010
Yasi that are 20 hours apart and I'm

00:03:54,329 --> 00:03:58,260
pretending that we don't have

00:03:56,010 --> 00:04:01,019
information between those 20 hours in

00:03:58,260 --> 00:04:02,819
reality we do we have we have data and

00:04:01,019 --> 00:04:04,680
we have heaps of it about the cyclones

00:04:02,819 --> 00:04:08,400
when they're happening but this is just

00:04:04,680 --> 00:04:10,349
the demonstration so on the Left we've

00:04:08,400 --> 00:04:13,290
got the cyclone as its approaching the

00:04:10,349 --> 00:04:15,299
land and I've called that T equals zero

00:04:13,290 --> 00:04:18,419
and on the right we've got the cyclone

00:04:15,299 --> 00:04:20,820
out in the ocean and that's t- 26 28

00:04:18,419 --> 00:04:22,950
hours away and the goal of whether field

00:04:20,820 --> 00:04:25,200
interpolation is to say what is the

00:04:22,950 --> 00:04:26,940
cyclone in between these two points what

00:04:25,200 --> 00:04:27,780
does it actually look like if we don't

00:04:26,940 --> 00:04:35,700
have any information

00:04:27,780 --> 00:04:37,350
about it so there's actually a few ways

00:04:35,700 --> 00:04:39,900
that you can solve this problem you know

00:04:37,350 --> 00:04:41,730
the cyclone field is just a scalar field

00:04:39,900 --> 00:04:43,440
you've got two measurements of scalar

00:04:41,730 --> 00:04:45,830
fields you can interpolate between them

00:04:43,440 --> 00:04:48,000
you can perform a weighted average so

00:04:45,830 --> 00:04:49,500
what's the advantage of doing a weighted

00:04:48,000 --> 00:04:51,690
average well it's very straightforward

00:04:49,500 --> 00:04:53,940
it's easy to understand and it's

00:04:51,690 --> 00:04:56,190
extremely quick what's the disadvantage

00:04:53,940 --> 00:04:58,889
of doing away leverage it introduces

00:04:56,190 --> 00:05:00,900
effects that aren't realistic you might

00:04:58,889 --> 00:05:04,890
get a cyclone appearing in two spots of

00:05:00,900 --> 00:05:07,470
the image for example what I'm talking

00:05:04,890 --> 00:05:10,080
about in this talk is using warping so

00:05:07,470 --> 00:05:12,390
this is this idea of transforming the

00:05:10,080 --> 00:05:15,240
two data points to a similar midpoint

00:05:12,390 --> 00:05:16,680
and then doing the average and the

00:05:15,240 --> 00:05:19,890
benefit of that is you get something

00:05:16,680 --> 00:05:22,470
that actually looks realistic the the

00:05:19,890 --> 00:05:25,110
actual problem with that is well it's

00:05:22,470 --> 00:05:27,360
pretty complicated to do so implementing

00:05:25,110 --> 00:05:33,090
it in python is basically what i'm

00:05:27,360 --> 00:05:36,150
talking about today this is just a video

00:05:33,090 --> 00:05:39,000
to demonstrate you know really what

00:05:36,150 --> 00:05:41,010
we're getting at so on the right you've

00:05:39,000 --> 00:05:43,979
got this averaged or weighted average

00:05:41,010 --> 00:05:45,870
example and it shows you that if we're

00:05:43,979 --> 00:05:48,000
trying to estimate these interpolated

00:05:45,870 --> 00:05:49,500
time points really the stuff that we get

00:05:48,000 --> 00:05:51,870
in the middle isn't very realistic it

00:05:49,500 --> 00:05:54,780
looks like we've got to cyclones you get

00:05:51,870 --> 00:05:57,539
this dumbbell sort of appearance whereas

00:05:54,780 --> 00:05:59,870
if you use a morphing approach which is

00:05:57,539 --> 00:06:01,530
on the left you can see that the

00:05:59,870 --> 00:06:04,440
characteristics of the cyclone are

00:06:01,530 --> 00:06:06,539
maintained you can even see the

00:06:04,440 --> 00:06:09,180
intensification of the low as it

00:06:06,539 --> 00:06:12,360
approaches the land so generally it's

00:06:09,180 --> 00:06:18,120
the better a better approach which is

00:06:12,360 --> 00:06:21,300
good because I developed it to bring

00:06:18,120 --> 00:06:23,910
this time a little bit more you know we

00:06:21,300 --> 00:06:26,460
really do have sample points in the

00:06:23,910 --> 00:06:28,650
middle so we do know what the cyclone

00:06:26,460 --> 00:06:30,150
looked like at time point t equals 10 so

00:06:28,650 --> 00:06:32,250
let's actually have a look at the error

00:06:30,150 --> 00:06:35,190
that we get when we use a weighted

00:06:32,250 --> 00:06:39,840
average vs. and affected weighted

00:06:35,190 --> 00:06:41,610
average I guess in poly so really all I

00:06:39,840 --> 00:06:44,599
want to demonstrate is that if you look

00:06:41,610 --> 00:06:48,419
the midpoint here like the middle graph

00:06:44,599 --> 00:06:50,460
basically what we're looking at is our

00:06:48,419 --> 00:06:52,860
estimate of where the cyclone is at time

00:06:50,460 --> 00:06:54,780
point equals 10 if you look at the plot

00:06:52,860 --> 00:06:56,310
directly underneath it what we're

00:06:54,780 --> 00:06:59,129
looking at there is the difference

00:06:56,310 --> 00:07:01,889
between our estimate and what the actual

00:06:59,129 --> 00:07:04,379
cyclone was so the observed cyclone and

00:07:01,889 --> 00:07:08,069
you can see that the error field looks

00:07:04,379 --> 00:07:09,659
more or less flat you know there might

00:07:08,069 --> 00:07:12,180
be a slight peak where we've got the

00:07:09,659 --> 00:07:13,650
center just a little bit off but if you

00:07:12,180 --> 00:07:15,210
compare that to the weighted average

00:07:13,650 --> 00:07:17,610
approach you can see this sort of

00:07:15,210 --> 00:07:20,009
dumbbell in the error field and that's

00:07:17,610 --> 00:07:22,020
basically saying that we've got the two

00:07:20,009 --> 00:07:26,479
centers actually present in the data and

00:07:22,020 --> 00:07:26,479
so the air is actually quite high so

00:07:31,639 --> 00:07:37,919
this is my one slide explanation of

00:07:35,159 --> 00:07:41,099
image registration it is not adequate as

00:07:37,919 --> 00:07:42,659
an explanation of image registration but

00:07:41,099 --> 00:07:44,900
basically what I want to get across to

00:07:42,659 --> 00:07:48,389
you guys is that image registration

00:07:44,900 --> 00:07:50,729
warping and morphing in my mind they all

00:07:48,389 --> 00:07:54,060
basically mean the same thing when I

00:07:50,729 --> 00:07:55,770
wrote my PhD thesis I think I got burnt

00:07:54,060 --> 00:07:57,569
pretty heavily for saying warping and

00:07:55,770 --> 00:08:02,430
and more thing with the same thing but I

00:07:57,569 --> 00:08:04,889
just don't care anymore they are and the

00:08:02,430 --> 00:08:08,669
crux of the problem really here is to

00:08:04,889 --> 00:08:11,219
estimate defamation parameters that map

00:08:08,669 --> 00:08:13,259
one field to another field and those

00:08:11,219 --> 00:08:17,490
defamation parameters come from a model

00:08:13,259 --> 00:08:19,770
so you might say I want a shifting model

00:08:17,490 --> 00:08:22,589
that says give me the amount of shifting

00:08:19,770 --> 00:08:25,080
from A to B and parameterize that as the

00:08:22,589 --> 00:08:26,819
displacement in X and Y or you might say

00:08:25,080 --> 00:08:30,839
give me the amount of rotation

00:08:26,819 --> 00:08:32,699
translation scale skew and that forms

00:08:30,839 --> 00:08:34,669
like a six parameter model which is an

00:08:32,699 --> 00:08:37,169
affine model that you try to estimate

00:08:34,669 --> 00:08:42,149
you can take it even further and you can

00:08:37,169 --> 00:08:43,860
have nonlinear models but basically what

00:08:42,149 --> 00:08:45,570
it really really boils down to is

00:08:43,860 --> 00:08:48,120
parameter search so it's a nonlinear

00:08:45,570 --> 00:08:51,029
optimization problem you're trying to

00:08:48,120 --> 00:08:53,430
find the parameters that maximize the

00:08:51,029 --> 00:08:54,570
similarity between you two images

00:08:53,430 --> 00:08:57,779
and that's what I'm trying to

00:08:54,570 --> 00:08:58,920
demonstrate here further on into the

00:08:57,779 --> 00:09:00,570
talk I'll provide some reading material

00:08:58,920 --> 00:09:02,670
if you guys are really interested in

00:09:00,570 --> 00:09:04,230
image registration I suggest that you

00:09:02,670 --> 00:09:07,920
follow up that reading material have a

00:09:04,230 --> 00:09:10,589
read but for now one of the key things

00:09:07,920 --> 00:09:13,529
that I really want to talk about is the

00:09:10,589 --> 00:09:17,279
core components of image registration in

00:09:13,529 --> 00:09:19,410
my mind at least boil down to 33 key

00:09:17,279 --> 00:09:21,240
ideas and that's one idea that you've

00:09:19,410 --> 00:09:24,920
got a similarity metric so you've got a

00:09:21,240 --> 00:09:27,570
way to measure how close two images are

00:09:24,920 --> 00:09:29,520
and that can actually be quite quite

00:09:27,570 --> 00:09:31,110
naive that can be very simple it could

00:09:29,520 --> 00:09:34,080
be like the sum of absolute differences

00:09:31,110 --> 00:09:37,730
for example and then you've got a

00:09:34,080 --> 00:09:40,770
sampler and a sampler basically turns

00:09:37,730 --> 00:09:43,980
what isn't a continuous thing into a

00:09:40,770 --> 00:09:46,560
continuous thing so you know an image

00:09:43,980 --> 00:09:49,850
isn't a continuous function basically if

00:09:46,560 --> 00:09:53,339
we want to sample an image at Point 2.5

00:09:49,850 --> 00:09:55,890
x 2.5 then we have to interpolate the

00:09:53,339 --> 00:09:57,660
points around it and say that that pixel

00:09:55,890 --> 00:09:59,130
value is actually the sum or the way

00:09:57,660 --> 00:10:02,220
some of its neighbors and that's what a

00:09:59,130 --> 00:10:04,320
sampler basically is and then we've got

00:10:02,220 --> 00:10:06,029
the idea of defamation models so like I

00:10:04,320 --> 00:10:09,390
was saying before you could have a

00:10:06,029 --> 00:10:11,970
translation model a shift sorry which I

00:10:09,390 --> 00:10:14,250
call the shift model or an affine model

00:10:11,970 --> 00:10:16,440
or you know spline or something like

00:10:14,250 --> 00:10:21,150
that to to give you some idea of how the

00:10:16,440 --> 00:10:22,950
field is moving so i guess the good

00:10:21,150 --> 00:10:26,520
thing for everybody is that I just

00:10:22,950 --> 00:10:27,690
implemented this in Python and you don't

00:10:26,520 --> 00:10:32,880
really have to worry about the details

00:10:27,690 --> 00:10:35,459
unless you really want to basically what

00:10:32,880 --> 00:10:37,110
what I've gone and done is I I started

00:10:35,459 --> 00:10:38,790
an open source project and I called a

00:10:37,110 --> 00:10:42,029
Python register it's probably not the

00:10:38,790 --> 00:10:44,640
best name for a Python package and it

00:10:42,029 --> 00:10:45,930
may change name in the future but it's

00:10:44,640 --> 00:10:48,150
already got a little bit of an

00:10:45,930 --> 00:10:50,700
contribution from from people that are

00:10:48,150 --> 00:10:55,860
involved with a popular psychic called

00:10:50,700 --> 00:10:57,690
psychic image and to sort of break it

00:10:55,860 --> 00:11:00,060
down into the things that we actually

00:10:57,690 --> 00:11:03,750
have implemented right now I put this

00:11:00,060 --> 00:11:05,490
table up there which which basically

00:11:03,750 --> 00:11:07,110
shows the metrics that we have

00:11:05,490 --> 00:11:08,430
implemented so we've got the

00:11:07,110 --> 00:11:11,399
really simple metric implemented which

00:11:08,430 --> 00:11:13,620
is absolute differences we've got a few

00:11:11,399 --> 00:11:15,209
models and I'm just talking about the

00:11:13,620 --> 00:11:17,760
green ones for now I'll get to the red

00:11:15,209 --> 00:11:20,899
and and aaron joins in a sec so we've

00:11:17,760 --> 00:11:23,339
got a basic shifting model an affine

00:11:20,899 --> 00:11:25,709
transformation model and then we've got

00:11:23,339 --> 00:11:27,300
samplers and all of these samplers

00:11:25,709 --> 00:11:30,930
except for the spline sampler are

00:11:27,300 --> 00:11:32,459
implemented using C types so we've got a

00:11:30,930 --> 00:11:34,440
nearest-neighbor sampler a cubic

00:11:32,459 --> 00:11:36,959
convolution sampler and we've also got

00:11:34,440 --> 00:11:38,579
the spline sampler which is basically

00:11:36,959 --> 00:11:42,300
just pulling map coordinates out of

00:11:38,579 --> 00:11:46,290
sight pires in the image library now to

00:11:42,300 --> 00:11:47,850
explain the red cells basically I have a

00:11:46,290 --> 00:11:49,829
few wants like I don't want to use

00:11:47,850 --> 00:11:54,120
simple similarity metric I want to use

00:11:49,829 --> 00:11:55,950
more complex ones so basically if you go

00:11:54,120 --> 00:11:59,130
to the github link you can see that

00:11:55,950 --> 00:12:00,420
we're posting tasks for the project and

00:11:59,130 --> 00:12:03,810
these are sort of things that we want to

00:12:00,420 --> 00:12:06,300
have implemented so we've got some ideas

00:12:03,810 --> 00:12:07,980
about making more complex similarity

00:12:06,300 --> 00:12:11,100
metrics and wrapping them into the whole

00:12:07,980 --> 00:12:12,329
optimization process and examples of

00:12:11,100 --> 00:12:15,089
those could be normalized cross

00:12:12,329 --> 00:12:16,350
correlation or computing the mutual

00:12:15,089 --> 00:12:22,079
information of the images to give you

00:12:16,350 --> 00:12:24,510
similarity the orange cells are things

00:12:22,079 --> 00:12:26,850
that I've had a crack at so I've tried

00:12:24,510 --> 00:12:30,720
to implement a polynomial defamation

00:12:26,850 --> 00:12:32,810
model it sort of works we also have a

00:12:30,720 --> 00:12:36,000
splined information model which is

00:12:32,810 --> 00:12:38,220
supposed to be a good way of

00:12:36,000 --> 00:12:41,130
approximating the non rigid motion that

00:12:38,220 --> 00:12:46,050
you could have if one image was like

00:12:41,130 --> 00:12:48,000
wobbling for example or a fluid the two

00:12:46,050 --> 00:12:50,449
papers that are really driving all of

00:12:48,000 --> 00:12:52,860
the development of put underneath I

00:12:50,449 --> 00:12:54,899
can't emphasize enough that these are

00:12:52,860 --> 00:12:56,699
probably like the seminal image

00:12:54,899 --> 00:12:59,040
registration papers so if you're

00:12:56,699 --> 00:13:01,260
interested in understanding image

00:12:59,040 --> 00:13:03,600
registration what I strongly recommend

00:13:01,260 --> 00:13:07,890
is that you go and have a read of the

00:13:03,600 --> 00:13:09,570
baker and Matthews paper and just just

00:13:07,890 --> 00:13:13,230
have a flick through it it's actually a

00:13:09,570 --> 00:13:16,620
five-part series it was just a little

00:13:13,230 --> 00:13:18,480
bit scary at first but I think just if

00:13:16,620 --> 00:13:20,399
you read the first paper you'll get an

00:13:18,480 --> 00:13:21,000
impression of how difficult the process

00:13:20,399 --> 00:13:25,290
actually can

00:13:21,000 --> 00:13:27,090
be and really I don't believe aside from

00:13:25,290 --> 00:13:30,900
implementing like a nonlinear optimizer

00:13:27,090 --> 00:13:38,310
it's actually that difficult and please

00:13:30,900 --> 00:13:41,100
follow it on github so I wanted to have

00:13:38,310 --> 00:13:43,590
a few examples of how simple or hard it

00:13:41,100 --> 00:13:46,170
would actually be to to sort of glue my

00:13:43,590 --> 00:13:47,910
package together and and actually

00:13:46,170 --> 00:13:49,470
implement some image registration so

00:13:47,910 --> 00:13:51,990
hopefully in a second I'm going to try

00:13:49,470 --> 00:13:54,110
and demo this but because my screen is a

00:13:51,990 --> 00:13:59,190
bit warped it might not look that great

00:13:54,110 --> 00:14:01,550
but the key idea here is that you you

00:13:59,190 --> 00:14:05,850
import this python registered package

00:14:01,550 --> 00:14:09,120
you import a metric import a sampler and

00:14:05,850 --> 00:14:11,250
you import a model like a defamation

00:14:09,120 --> 00:14:13,790
model and then you just glue them

00:14:11,250 --> 00:14:16,200
together so we've got this top-level

00:14:13,790 --> 00:14:21,330
register script which is sort of like a

00:14:16,200 --> 00:14:22,980
our glue for a register at all so in

00:14:21,330 --> 00:14:26,550
this case I just wanted to point out

00:14:22,980 --> 00:14:28,380
that it's very simple and this is an

00:14:26,550 --> 00:14:33,030
example of performing an affine

00:14:28,380 --> 00:14:35,310
registration between two images so in in

00:14:33,030 --> 00:14:37,500
this case it would be just a standard

00:14:35,310 --> 00:14:41,100
you know image processing image that

00:14:37,500 --> 00:14:44,370
we've rotated by 20 degrees and we form

00:14:41,100 --> 00:14:46,050
an athlean regístrate ER we coerce the

00:14:44,370 --> 00:14:48,620
image data into what I call register

00:14:46,050 --> 00:14:51,390
data because I want to have a concept of

00:14:48,620 --> 00:14:54,990
both images and features and intimate in

00:14:51,390 --> 00:14:57,240
images and for that sort of concept to

00:14:54,990 --> 00:15:00,000
work we've basically got a container for

00:14:57,240 --> 00:15:01,830
the image the other thing that is really

00:15:00,000 --> 00:15:04,470
important about having register data is

00:15:01,830 --> 00:15:07,380
that it's very easy in image

00:15:04,470 --> 00:15:09,360
registration just to consider the image

00:15:07,380 --> 00:15:12,089
and the coordinates in the image as the

00:15:09,360 --> 00:15:15,330
pixels but that's really wrong you have

00:15:12,089 --> 00:15:17,700
to actually have coordinate spaces so in

00:15:15,330 --> 00:15:20,280
the future part of the work that we're

00:15:17,700 --> 00:15:22,920
going to really be tackling is really

00:15:20,280 --> 00:15:25,440
addressing the coordinates and doing

00:15:22,920 --> 00:15:26,970
that properly in Python and integrating

00:15:25,440 --> 00:15:29,610
that with the whole registration process

00:15:26,970 --> 00:15:31,620
it's it's basically a big no-no to do

00:15:29,610 --> 00:15:33,950
image registration assuming pixel

00:15:31,620 --> 00:15:37,650
coordinates are the coordinate system

00:15:33,950 --> 00:15:41,730
and then the final step is basically

00:15:37,650 --> 00:15:44,250
calling the top-level register method

00:15:41,730 --> 00:15:46,140
and and running it and there's a few

00:15:44,250 --> 00:15:48,240
methods on it so you can print out a

00:15:46,140 --> 00:15:50,550
verbose description of what's happening

00:15:48,240 --> 00:15:54,980
at every iteration or you can print out

00:15:50,550 --> 00:16:01,050
a graphic by having a plot call back I

00:15:54,980 --> 00:16:07,160
might escape out of this my screen is

00:16:01,050 --> 00:16:07,160
super huge let's just see what happens

00:16:11,420 --> 00:16:16,340
okay so i went to the complex

00:16:14,080 --> 00:16:19,310
demonstration first which was a bit

00:16:16,340 --> 00:16:20,840
silly but basically what i wanted to

00:16:19,310 --> 00:16:24,050
demonstrate here is that we've got the

00:16:20,840 --> 00:16:26,180
python logo that's the image we've got a

00:16:24,050 --> 00:16:28,010
deformed python logo that's called the

00:16:26,180 --> 00:16:30,680
template what we're trying to estimate

00:16:28,010 --> 00:16:33,500
the deformations between the image and

00:16:30,680 --> 00:16:36,410
the template and that's visualized in

00:16:33,500 --> 00:16:40,580
the center here as agreed that's sort of

00:16:36,410 --> 00:16:42,470
changing shape and the way or the driver

00:16:40,580 --> 00:16:44,930
for that change of shape is a cubic

00:16:42,470 --> 00:16:46,820
spline model so it's really it's a

00:16:44,930 --> 00:16:48,650
really complex model it might have like

00:16:46,820 --> 00:16:49,850
100 parameters for example and we're

00:16:48,650 --> 00:16:51,440
just trying to find those parameters

00:16:49,850 --> 00:16:56,750
that minimize the difference between the

00:16:51,440 --> 00:16:58,820
image and template so this is a sari on

00:16:56,750 --> 00:17:01,730
the bottom right hand corner as a

00:16:58,820 --> 00:17:04,220
demonstration of the era so that the

00:17:01,730 --> 00:17:05,360
nonlinear image registration component

00:17:04,220 --> 00:17:07,010
of this package really isn't finished

00:17:05,360 --> 00:17:08,810
yet but this is just a demonstration

00:17:07,010 --> 00:17:10,820
that we're sort of getting somewhere

00:17:08,810 --> 00:17:12,800
with it and we can do very simple things

00:17:10,820 --> 00:17:15,950
at the moment in the future we want to

00:17:12,800 --> 00:17:19,730
be able to sort of estimate large-scale

00:17:15,950 --> 00:17:21,760
definitions of pull up am a simpler

00:17:19,730 --> 00:17:21,760
example

00:17:28,990 --> 00:17:39,190
what is the rotated Python logo so it'll

00:17:37,090 --> 00:17:40,929
eventually get there but basically this

00:17:39,190 --> 00:17:42,520
just shows a very simple a fine

00:17:40,929 --> 00:17:44,110
relationship between the image in the

00:17:42,520 --> 00:17:47,290
template and the air flying relationship

00:17:44,110 --> 00:17:49,780
is an in-plane rotation so an affine

00:17:47,290 --> 00:17:51,100
transformation has six parameters we're

00:17:49,780 --> 00:17:52,450
just doing a search for the six

00:17:51,100 --> 00:17:55,360
parameters that minimize the difference

00:17:52,450 --> 00:17:56,559
between these two images and you can see

00:17:55,360 --> 00:18:02,320
in the middle that the coordinates are

00:17:56,559 --> 00:18:10,179
just sort of rotated okay let's go back

00:18:02,320 --> 00:18:12,240
to keynote which play again a but

00:18:10,179 --> 00:18:14,410
non-linear example which i showed before

00:18:12,240 --> 00:18:17,110
the main difference here is that you

00:18:14,410 --> 00:18:19,390
just glue in a different defamation

00:18:17,110 --> 00:18:23,230
model everything else is basically the

00:18:19,390 --> 00:18:25,450
same nonlinear image registration is not

00:18:23,230 --> 00:18:29,290
as robust as the linear image

00:18:25,450 --> 00:18:31,510
registration bye-bye nonlinear in linear

00:18:29,290 --> 00:18:33,820
I mean the defamation model so if you

00:18:31,510 --> 00:18:36,160
have a cubic spline model with a hundred

00:18:33,820 --> 00:18:38,380
parameters it's much harder to optimize

00:18:36,160 --> 00:18:43,990
that than it is to optimize an affine

00:18:38,380 --> 00:18:45,370
model which has six parameters so this

00:18:43,990 --> 00:18:48,400
is sort of the future of a perceived

00:18:45,370 --> 00:18:51,820
future of the projects we have lots of

00:18:48,400 --> 00:18:53,559
wants there's already been a fair bit of

00:18:51,820 --> 00:18:55,840
work on feature-based registration which

00:18:53,559 --> 00:18:57,280
is very very fast there's a direct

00:18:55,840 --> 00:18:58,690
linear solution if you've got

00:18:57,280 --> 00:19:01,900
corresponding features between two

00:18:58,690 --> 00:19:04,830
images that's largely been implemented

00:19:01,900 --> 00:19:08,070
but not really tightly integrated yet

00:19:04,830 --> 00:19:12,040
there's some work from contributor rhian

00:19:08,070 --> 00:19:14,260
than in dual who's been working on

00:19:12,040 --> 00:19:15,850
automatic feature detection so the idea

00:19:14,260 --> 00:19:17,830
there would be if you have a

00:19:15,850 --> 00:19:20,110
feature-based registration algorithm and

00:19:17,830 --> 00:19:22,120
you have an automatic feature detector

00:19:20,110 --> 00:19:24,370
and matcha you don't have to have

00:19:22,120 --> 00:19:26,020
anybody controlling it you just run

00:19:24,370 --> 00:19:32,470
these things that's particularly good

00:19:26,020 --> 00:19:33,850
for video stabilization for example this

00:19:32,470 --> 00:19:35,410
is sort of repeating myself a bit we've

00:19:33,850 --> 00:19:36,790
got similarity matrix and defamation

00:19:35,410 --> 00:19:40,690
models that we want to throw into the

00:19:36,790 --> 00:19:42,070
package my idea of version 1 point 0

00:19:40,690 --> 00:19:42,759
would be something that's integrated

00:19:42,070 --> 00:19:45,609
with

00:19:42,759 --> 00:19:47,549
a psych it known as I Kadima JH which is

00:19:45,609 --> 00:19:50,079
basically like an image processing

00:19:47,549 --> 00:19:55,509
package which is going to be some tacked

00:19:50,079 --> 00:19:57,789
onto the side of scifi you know i do i

00:19:55,509 --> 00:20:00,249
do know a little bit about testing and i

00:19:57,789 --> 00:20:01,599
do want to have complete Co coverage of

00:20:00,249 --> 00:20:03,849
this package to give people confidence

00:20:01,599 --> 00:20:06,099
if they're going to go and manipulate

00:20:03,849 --> 00:20:12,549
things inside it try to improve it sped

00:20:06,099 --> 00:20:14,859
it up for example once again if you're

00:20:12,549 --> 00:20:18,190
interested in image registration please

00:20:14,859 --> 00:20:20,829
read these two papers the final paper is

00:20:18,190 --> 00:20:23,159
is all about really interesting

00:20:20,829 --> 00:20:25,179
defamation models so the cubic spline

00:20:23,159 --> 00:20:28,359
defamation model and how you would fit

00:20:25,179 --> 00:20:31,499
that that's basically the nonlinear

00:20:28,359 --> 00:20:31,499
registration example I showed

00:20:37,450 --> 00:20:43,169
I can yeah I can make it available yep

00:20:47,279 --> 00:20:55,480
sure and please follow my project have a

00:20:52,570 --> 00:20:57,100
look if you want to see how I don't know

00:20:55,480 --> 00:20:58,690
maybe a crazy person tries to implement

00:20:57,100 --> 00:21:02,529
these algorithms check out my code and

00:20:58,690 --> 00:21:04,899
read through it I should I should

00:21:02,529 --> 00:21:07,750
actually say that it's not all my code I

00:21:04,899 --> 00:21:10,630
actually do have two contributors who

00:21:07,750 --> 00:21:12,760
are making lots of developments in

00:21:10,630 --> 00:21:15,700
addition to myself and that would be a

00:21:12,760 --> 00:21:17,799
rien founder duel and stephan van der

00:21:15,700 --> 00:21:18,880
walt and they're they're mostly very

00:21:17,799 --> 00:21:23,529
interested in the feature based

00:21:18,880 --> 00:21:25,480
registration right now I should thank my

00:21:23,529 --> 00:21:31,059
colleagues at beyond that's that's

00:21:25,480 --> 00:21:32,350
basically the end so you know a lot of a

00:21:31,059 --> 00:21:33,850
lot of this works actually really

00:21:32,350 --> 00:21:35,769
difficult to get off the ground at the

00:21:33,850 --> 00:21:37,480
bureau because it's not very simple to

00:21:35,769 --> 00:21:40,210
get an open source project going it

00:21:37,480 --> 00:21:43,630
takes quite a lot of meetings and quite

00:21:40,210 --> 00:21:45,309
a lot of emails so i should think

00:21:43,630 --> 00:21:48,039
tennessee for being involved in

00:21:45,309 --> 00:21:52,470
organizing a lot of a lot of that stuff

00:21:48,039 --> 00:21:55,450
I should thank Brianna and Damian and

00:21:52,470 --> 00:21:57,179
Gary and John for being actively

00:21:55,450 --> 00:21:59,080
involved in some of this work as well

00:21:57,179 --> 00:22:00,880
basically telling me not to put

00:21:59,080 --> 00:22:10,240
equations in my presentation was a good

00:22:00,880 --> 00:22:11,320
idea so if there's any questions come

00:22:10,240 --> 00:22:13,210
from

00:22:11,320 --> 00:22:15,280
how much of this stuff is actually in

00:22:13,210 --> 00:22:18,310
use now at the bureau you're using it at

00:22:15,280 --> 00:22:20,650
all or is it a you know would like to

00:22:18,310 --> 00:22:24,220
use it yeah this this started as a

00:22:20,650 --> 00:22:26,440
part-time project that I had going and

00:22:24,220 --> 00:22:30,340
we we do plan to use image registration

00:22:26,440 --> 00:22:32,650
pretty heavily in the future it's pretty

00:22:30,340 --> 00:22:37,570
much the next big chunk of my work at

00:22:32,650 --> 00:22:39,430
the bureau hi thanks for the doc is

00:22:37,570 --> 00:22:43,720
there any data available from the Bureau

00:22:39,430 --> 00:22:46,000
which is available for public use well

00:22:43,720 --> 00:22:49,360
that's a good question I'm not sure I

00:22:46,000 --> 00:22:51,160
can't answer that right now that you

00:22:49,360 --> 00:22:54,040
know in terms of maybe numerical weather

00:22:51,160 --> 00:22:56,560
prediction output you can see like the

00:22:54,040 --> 00:22:58,720
access models and the output from the

00:22:56,560 --> 00:23:01,810
Bureau website I'm not sure if you can

00:22:58,720 --> 00:23:07,330
get to the Royal fields but but I could

00:23:01,810 --> 00:23:10,300
find out a double-barrel question from

00:23:07,330 --> 00:23:12,520
what I understand the original data that

00:23:10,300 --> 00:23:16,570
you're working with is not really this

00:23:12,520 --> 00:23:19,210
nice smooth field that your illustration

00:23:16,570 --> 00:23:22,030
shows yeah it's really data that was

00:23:19,210 --> 00:23:24,160
collected at individual places and

00:23:22,030 --> 00:23:26,260
individual times and then assimilated

00:23:24,160 --> 00:23:27,910
through an assimilation model so is

00:23:26,260 --> 00:23:31,990
there any way that you can actually go

00:23:27,910 --> 00:23:34,030
back into that data and register it from

00:23:31,990 --> 00:23:35,380
one from one assimilation period to

00:23:34,030 --> 00:23:39,300
another or is that it much harder

00:23:35,380 --> 00:23:41,590
problem so there's a much harder problem

00:23:39,300 --> 00:23:43,210
basically I'm looking at the output of

00:23:41,590 --> 00:23:45,760
the numerical weather prediction model

00:23:43,210 --> 00:23:47,920
and what you're saying is that numerical

00:23:45,760 --> 00:23:49,720
weather prediction is basically an

00:23:47,920 --> 00:23:51,040
aggregation of observations and things

00:23:49,720 --> 00:23:54,910
and they go through a really complex

00:23:51,040 --> 00:23:56,320
process and to generate some fields the

00:23:54,910 --> 00:23:58,630
answer is now having considered any of

00:23:56,320 --> 00:24:00,490
that really yes I did have a second

00:23:58,630 --> 00:24:05,950
question and there might be easy to

00:24:00,490 --> 00:24:08,200
answer it is it useful to have more

00:24:05,950 --> 00:24:12,040
general nonlinear solvers at the back

00:24:08,200 --> 00:24:14,050
end or is this such a unique problem

00:24:12,040 --> 00:24:16,690
that it has to have its own type of the

00:24:14,050 --> 00:24:19,720
nonlinear solution it's a good that's a

00:24:16,690 --> 00:24:23,000
good question basically when I started

00:24:19,720 --> 00:24:26,000
working on this I picked up the syfy

00:24:23,000 --> 00:24:28,640
you know nonlinear solvers and I try to

00:24:26,000 --> 00:24:30,830
use them and it's possible to use those

00:24:28,640 --> 00:24:32,930
general solvers for this problem it's

00:24:30,830 --> 00:24:35,710
not a unique problem it's a nonlinear

00:24:32,930 --> 00:24:39,200
least squares problem that's been solved

00:24:35,710 --> 00:24:40,790
but to really understand what's going on

00:24:39,200 --> 00:24:43,520
at every iteration I wanted to be able

00:24:40,790 --> 00:24:45,170
to like put shortcuts in and print out

00:24:43,520 --> 00:24:46,730
things and stuff like that and I just

00:24:45,170 --> 00:24:49,070
found that too difficult using the

00:24:46,730 --> 00:24:51,410
existing sci-fi stuff so I went and

00:24:49,070 --> 00:24:53,540
implemented it myself maybe that's

00:24:51,410 --> 00:24:55,520
reinventing the wheel but I completely

00:24:53,540 --> 00:24:57,560
understand absolutely everything that's

00:24:55,520 --> 00:25:02,690
going on and that's something I was

00:24:57,560 --> 00:25:04,970
really looking for in this case I really

00:25:02,690 --> 00:25:06,950
interesting talk really enjoyed it are

00:25:04,970 --> 00:25:10,370
there any alternative libraries for

00:25:06,950 --> 00:25:11,990
doing image registration such as you

00:25:10,370 --> 00:25:13,700
know something in c or something like

00:25:11,990 --> 00:25:16,010
that or you the main event at this point

00:25:13,700 --> 00:25:17,870
that that's that's a loaded question I

00:25:16,010 --> 00:25:23,180
know that work for sure is definitely

00:25:17,870 --> 00:25:25,670
answer is yes so there's existing you

00:25:23,180 --> 00:25:27,440
know that there are very good existing

00:25:25,670 --> 00:25:30,020
see libraries for image registration

00:25:27,440 --> 00:25:31,340
that exist particularly the ones that

00:25:30,020 --> 00:25:36,320
come to mind are the insight

00:25:31,340 --> 00:25:38,330
registration tool kit I rtk itk they

00:25:36,320 --> 00:25:42,460
come from the medical imaging sort of

00:25:38,330 --> 00:25:45,800
domain so they do have python bindings

00:25:42,460 --> 00:25:47,900
but I'm sort of approaching this problem

00:25:45,800 --> 00:25:49,880
in with the mindset that I'm going to

00:25:47,900 --> 00:25:52,240
manipulate the algorithms that I'm using

00:25:49,880 --> 00:25:54,290
so i might not necessarily want to use

00:25:52,240 --> 00:25:57,200
exactly the same image registration

00:25:54,290 --> 00:25:59,180
algorithms that are available and that's

00:25:57,200 --> 00:26:02,030
why i've implemented python register and

00:25:59,180 --> 00:26:04,730
in the process i've implemented some

00:26:02,030 --> 00:26:06,380
algorithms that are i think much easier

00:26:04,730 --> 00:26:09,110
to understand than to drill down to the

00:26:06,380 --> 00:26:11,720
bottom of using like a complex c.c

00:26:09,110 --> 00:26:14,420
binding for example one thing I should

00:26:11,720 --> 00:26:16,640
know is that all of this stuff really

00:26:14,420 --> 00:26:19,010
except for the sampler is just numpy

00:26:16,640 --> 00:26:22,750
inside pie so it's extremely easy for

00:26:19,010 --> 00:26:22,750
someone to pick up read and understand

00:26:25,460 --> 00:26:32,850
um yeah thanks to the talk I just I

00:26:29,610 --> 00:26:34,559
guess a quick question oh but if I could

00:26:32,850 --> 00:26:37,559
perhaps get you just to say a little bit

00:26:34,559 --> 00:26:43,410
about how you know when a solution is

00:26:37,559 --> 00:26:45,539
actually good okay um so I mean you you

00:26:43,410 --> 00:26:48,179
have a solver that was going to have

00:26:45,539 --> 00:26:50,549
some sense of goodness of fit but aside

00:26:48,179 --> 00:26:52,140
from that presumably that's different

00:26:50,549 --> 00:26:54,630
for the different models so it's hard to

00:26:52,140 --> 00:26:57,120
compare the one family of model to

00:26:54,630 --> 00:27:00,450
another yeah to go to the details

00:26:57,120 --> 00:27:03,929
basically when you're turning the wheel

00:27:00,450 --> 00:27:05,580
on the nonlinear optimization you know

00:27:03,929 --> 00:27:07,919
what one very simple way that you know

00:27:05,580 --> 00:27:10,140
that you've converged is that the change

00:27:07,919 --> 00:27:13,260
in the parameter set gets smaller and

00:27:10,140 --> 00:27:15,900
smaller so you can threshold that and

00:27:13,260 --> 00:27:18,929
say once your delta on the parameter set

00:27:15,900 --> 00:27:21,690
gets below a particular threshold maybe

00:27:18,929 --> 00:27:23,760
like 12 the negative for something 10 to

00:27:21,690 --> 00:27:25,380
the negative 4 sorry that's when you

00:27:23,760 --> 00:27:29,789
stop iterating that's when you stop

00:27:25,380 --> 00:27:32,909
turning the wheel it's a measure of

00:27:29,789 --> 00:27:34,110
convergence I guess so okay the

00:27:32,909 --> 00:27:40,580
questions are getting more difficult bit

00:27:34,110 --> 00:27:44,370
like another another thing that we do is

00:27:40,580 --> 00:27:47,039
well that I do in in the solver is I'm

00:27:44,370 --> 00:27:49,860
using basically a modified gradient

00:27:47,039 --> 00:27:52,080
descent algorithm and I'm keeping track

00:27:49,860 --> 00:27:54,150
of the bad iterations and so the bad

00:27:52,080 --> 00:27:56,010
iterations are when you take a step in

00:27:54,150 --> 00:27:58,380
the error doesn't decrease it increases

00:27:56,010 --> 00:28:01,140
and the idea there is that you can

00:27:58,380 --> 00:28:03,330
backtrack so if you have a step and your

00:28:01,140 --> 00:28:05,039
error actually increases what you want

00:28:03,330 --> 00:28:06,659
to do is say I don't want to take that

00:28:05,039 --> 00:28:10,140
step I want to take a bigger step and

00:28:06,659 --> 00:28:12,030
hope that the error decreases and so the

00:28:10,140 --> 00:28:13,710
idea there is that you keep this count

00:28:12,030 --> 00:28:15,059
of the number of bad iterations so the

00:28:13,710 --> 00:28:17,460
number of times that your air is

00:28:15,059 --> 00:28:19,440
actually increased and then you stop

00:28:17,460 --> 00:28:22,530
iterating when your arrow just keeps on

00:28:19,440 --> 00:28:25,530
increasing that's basically what I do

00:28:22,530 --> 00:28:27,740
right now yeah there are many many

00:28:25,530 --> 00:28:32,400
nonlinear solvers that you could try it

00:28:27,740 --> 00:28:34,500
hey so the idea is to take the source

00:28:32,400 --> 00:28:35,830
image and deform it to the target image

00:28:34,500 --> 00:28:37,570
and

00:28:35,830 --> 00:28:42,039
I guess implicit in that you come up

00:28:37,570 --> 00:28:43,840
with a path as well yeah so I guess if

00:28:42,039 --> 00:28:46,179
you wanted to think of it like you want

00:28:43,840 --> 00:28:48,429
to go halfway or three quarters or yeah

00:28:46,179 --> 00:28:52,320
so so when I when I've been talking

00:28:48,429 --> 00:28:54,970
about weighted averaging with advection

00:28:52,320 --> 00:28:57,580
basically what i do in that case is i

00:28:54,970 --> 00:29:00,220
say the form from point A to point B

00:28:57,580 --> 00:29:03,370
okay and give me the defamation field

00:29:00,220 --> 00:29:04,960
that goes from point A to point B now

00:29:03,370 --> 00:29:07,630
just have the magnitude of that

00:29:04,960 --> 00:29:10,029
deformation field and that says this is

00:29:07,630 --> 00:29:13,149
the defamation to the midpoint and then

00:29:10,029 --> 00:29:16,539
I transformed point or the image data at

00:29:13,149 --> 00:29:19,269
point a to the midpoint and I use the

00:29:16,539 --> 00:29:21,130
inverse to transform the image data at

00:29:19,269 --> 00:29:22,630
point B it's in the midpoint and then

00:29:21,130 --> 00:29:24,039
you compute the average and that's why

00:29:22,630 --> 00:29:26,080
the result actually looks pretty good

00:29:24,039 --> 00:29:28,990
because when you do this advection

00:29:26,080 --> 00:29:30,580
basically you can introduce artifacts so

00:29:28,990 --> 00:29:33,070
you can pull in pixels from the

00:29:30,580 --> 00:29:34,480
boundaries and things like that but if

00:29:33,070 --> 00:29:36,880
you do the averaging you can wash out

00:29:34,480 --> 00:29:41,440
those artifacts and that's basically why

00:29:36,880 --> 00:29:44,980
the method works pretty well okay we'll

00:29:41,440 --> 00:29:47,139
just do one last question thanks and do

00:29:44,980 --> 00:29:50,080
you always get the global minima world

00:29:47,139 --> 00:29:53,559
just Atkins of optimization people but

00:29:50,080 --> 00:29:54,940
in the car so I didn't do a PhD in

00:29:53,559 --> 00:29:57,519
optimization theory or anything like

00:29:54,940 --> 00:29:59,740
that but basically you know we just have

00:29:57,519 --> 00:30:03,309
an estimate it's not guaranteed to be

00:29:59,740 --> 00:30:06,419
the global minimum it's a minimum that

00:30:03,309 --> 00:30:06,419
that's a longer to say on our

00:30:10,630 --> 00:30:15,790
so make them thank you for an excellent

00:30:13,300 --> 00:30:19,050
talk kids and if everyone complete show

00:30:15,790 --> 00:30:19,050

YouTube URL: https://www.youtube.com/watch?v=LRQJvXtpU90


