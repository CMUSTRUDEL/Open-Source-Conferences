Title: Science MiniConf: Monte Carlo Business Case Analysis with pandas by Arthur Street
Publication date: 2014-08-11
Playlist: PyCon Australia 2014 Science & Data miniconf
Description: 
	Pandas is increasingly becoming a standard tool in scientific computing.  Could it also have a role in the CFO's office?
 
CFOs regularly need to analyse the impact of different projects or business cases, and they almost universally do this using spreadsheets.  Spreadsheets have many advantages - they have a low barrier to entry and are easy for most people to understand.  However as they get more complicated, disadvantages start to appear; in particular, they can be inflexible and highly error-prone.
 
In this talk I will explain how business case analysis can be done using python and pandas.  The python version has several advantages over spreadsheets: it is more flexible as the business structure changes; formulas only need to be changed in a single place, reducing the chance of error; and report-ready plots are quick to produce.  I'll go through a way of structuring the problem for some simple business logic, and ways to visualise the results.
 
The example I’ll discuss is made more interesting and useful by being “Monte Carlo” analysis. Traditional business case analysis takes single point estimates of sales, costs and prices, and calculates a single profit forecast. Everybody knows the profit will not turn out to be exactly equal to the forecast.  But it is not clear what the range of profits might be, or how likely a loss is.  "Monte Carlo" analysis solves this problem by allowing ranges or distributions on the assumptions; the forecast is then a range of outcomes.
 
In short, I’ll demonstrate how you can use pandas to analyse high-impact business decisions, and dodge many of the problems of using spreadsheets.

PyCon Australia is the national conference for users of the Python Programming Language. In August 2014, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

August 1-5, Brisbane, Queensland, Australia
Captions: 
	00:00:05,519 --> 00:00:10,719
inviting me to give this talk and I'm

00:00:07,569 --> 00:00:13,150
honored to be up first today I thought

00:00:10,719 --> 00:00:15,519
what I'd talk about is an application

00:00:13,150 --> 00:00:17,890
you may not have thought of for the

00:00:15,519 --> 00:00:22,029
tools that you use in science and data

00:00:17,890 --> 00:00:25,930
analysis and that is in business case

00:00:22,029 --> 00:00:27,759
analysis so that's um I guess what I'll

00:00:25,930 --> 00:00:29,469
try and achieve today in this talk will

00:00:27,759 --> 00:00:31,509
basically twofold one is telling what

00:00:29,469 --> 00:00:33,130
business case analysis means and in

00:00:31,509 --> 00:00:37,630
particular Monte Carlo business case

00:00:33,130 --> 00:00:39,490
analysis and secondly try and give you

00:00:37,630 --> 00:00:45,070
the idea that using pandas to do it is

00:00:39,490 --> 00:00:46,600
not completely crazy so what is business

00:00:45,070 --> 00:00:52,090
case analysis well basically I'm talking

00:00:46,600 --> 00:00:53,829
about any big investment decision that a

00:00:52,090 --> 00:00:56,290
company needs to make they usually do

00:00:53,829 --> 00:00:57,520
some sort of analysis to to decide

00:00:56,290 --> 00:01:01,870
whether it's going to be a profitable

00:00:57,520 --> 00:01:04,570
venture or not and usually that takes

00:01:01,870 --> 00:01:07,210
the form of a spreadsheet and it

00:01:04,570 --> 00:01:09,789
basically involves taking a lot of

00:01:07,210 --> 00:01:12,280
inputs such as costs and revenues and

00:01:09,789 --> 00:01:14,859
volumes market share all that sort of

00:01:12,280 --> 00:01:19,420
stuff turn it into a measure of profit

00:01:14,859 --> 00:01:21,490
and this is one representation a

00:01:19,420 --> 00:01:24,069
suggestive one of what that might look

00:01:21,490 --> 00:01:25,799
like and the idea here is obviously the

00:01:24,069 --> 00:01:27,939
way I've drawn it is giving it

00:01:25,799 --> 00:01:30,159
emphasizing the fact that you only get a

00:01:27,939 --> 00:01:32,319
single figure out of it in the typical

00:01:30,159 --> 00:01:34,479
way that it's done so you make a bunch

00:01:32,319 --> 00:01:37,509
of forecasts about your costs and your

00:01:34,479 --> 00:01:39,490
volumes and your revenues and you get

00:01:37,509 --> 00:01:42,340
one single profit number of course that

00:01:39,490 --> 00:01:43,840
doesn't tell you whether you know what's

00:01:42,340 --> 00:01:45,399
the chance of losing money in this or

00:01:43,840 --> 00:01:50,289
what's what's the chance of making too

00:01:45,399 --> 00:01:51,819
many dollars so for that a lot of

00:01:50,289 --> 00:01:54,520
companies are turning to Monte Carlo

00:01:51,819 --> 00:01:56,259
business case analysis where you would

00:01:54,520 --> 00:01:58,270
get a histogram or some sort of

00:01:56,259 --> 00:01:59,920
distribution of course that's very

00:01:58,270 --> 00:02:02,740
natural for scientists to think in terms

00:01:59,920 --> 00:02:06,549
of distributions and error bars and so

00:02:02,740 --> 00:02:08,580
on it has its challenges of course

00:02:06,549 --> 00:02:11,080
because you have to assess what the

00:02:08,580 --> 00:02:12,280
uncertainties are in in the inputs you

00:02:11,080 --> 00:02:13,810
know what's the possible range of

00:02:12,280 --> 00:02:15,400
volumes and put some sort of actual

00:02:13,810 --> 00:02:17,470
probabilities on that and that's quite

00:02:15,400 --> 00:02:19,660
an art to do that well

00:02:17,470 --> 00:02:22,210
to counter the various cognitive and

00:02:19,660 --> 00:02:25,570
motivational biases biases that people

00:02:22,210 --> 00:02:28,810
have when doing that so there are

00:02:25,570 --> 00:02:31,060
definitely challenges to doing it but

00:02:28,810 --> 00:02:32,890
but you know the advantages you can now

00:02:31,060 --> 00:02:34,630
start to talk about what are the chances

00:02:32,890 --> 00:02:37,600
of losing money or other sorts of

00:02:34,630 --> 00:02:39,100
questions and I've done this I used to

00:02:37,600 --> 00:02:41,410
work at pricewaterhousecoopers as a

00:02:39,100 --> 00:02:42,520
consultant where we used to do this sort

00:02:41,410 --> 00:02:45,100
of work and we'd always use spreadsheets

00:02:42,520 --> 00:02:46,660
to do it and spreadsheets have some

00:02:45,100 --> 00:02:49,120
fantastic advantages in that they're

00:02:46,660 --> 00:02:52,390
very easy to use you can get going very

00:02:49,120 --> 00:02:54,370
quickly they're very visual so that's

00:02:52,390 --> 00:02:57,870
traditionally where it's done and most

00:02:54,370 --> 00:02:59,890
like chief financial officer areas will

00:02:57,870 --> 00:03:03,910
use spreadsheets a lot for that and

00:02:59,890 --> 00:03:05,260
they're very comfortable with it one of

00:03:03,910 --> 00:03:07,000
the outputs you can get and there are

00:03:05,260 --> 00:03:09,190
there are atoms you can get to excel

00:03:07,000 --> 00:03:11,920
that will do this for you is this is

00:03:09,190 --> 00:03:13,270
called a tornado diagram which is

00:03:11,920 --> 00:03:14,860
another output in addition to that

00:03:13,270 --> 00:03:16,930
histogram I just showed you of profit

00:03:14,860 --> 00:03:19,570
this this will actually show you which

00:03:16,930 --> 00:03:24,340
are the inputs that the uncertainty in

00:03:19,570 --> 00:03:25,840
really matters so if you were to explain

00:03:24,340 --> 00:03:27,670
what that top bar means for example if

00:03:25,840 --> 00:03:29,739
you were to hold all the other inputs at

00:03:27,670 --> 00:03:32,980
their expected values and just very the

00:03:29,739 --> 00:03:34,810
volume from its lowest value to its

00:03:32,980 --> 00:03:36,820
highest value and to be precise and then

00:03:34,810 --> 00:03:39,040
say over an eighty percent confidence

00:03:36,820 --> 00:03:41,680
interval or some confidence interval

00:03:39,040 --> 00:03:43,959
that you define what would be the change

00:03:41,680 --> 00:03:45,600
in the profit if you do that so in this

00:03:43,959 --> 00:03:48,370
example it's pointing out to you that

00:03:45,600 --> 00:03:50,140
volume and price and to some degree the

00:03:48,370 --> 00:03:52,540
third one there they're the ones that

00:03:50,140 --> 00:03:54,730
will really determine whether you're

00:03:52,540 --> 00:03:56,680
profitable or not and things like your

00:03:54,730 --> 00:03:58,150
fixed costs and and to some degree of

00:03:56,680 --> 00:03:59,920
variable costs you don't need to spend

00:03:58,150 --> 00:04:01,209
quite as much time thinking about what

00:03:59,920 --> 00:04:03,070
those uncertainties are because they

00:04:01,209 --> 00:04:07,120
won't have such a big impact on your

00:04:03,070 --> 00:04:10,000
profit so getting back to my comment

00:04:07,120 --> 00:04:11,799
about spreadsheets why would I even

00:04:10,000 --> 00:04:14,890
talked about doing it in something other

00:04:11,799 --> 00:04:16,359
than a spreadsheet there there are many

00:04:14,890 --> 00:04:20,560
problems with spreadsheets which I'm

00:04:16,359 --> 00:04:23,850
sure you're familiar with namely that to

00:04:20,560 --> 00:04:25,960
just give you a few examples when you

00:04:23,850 --> 00:04:27,250
you know you've basically got to put

00:04:25,960 --> 00:04:28,930
your formulas in every single cells

00:04:27,250 --> 00:04:33,310
you're repeating the same formula many

00:04:28,930 --> 00:04:35,199
times when you want to add another row

00:04:33,310 --> 00:04:37,180
or column to a table that you know

00:04:35,199 --> 00:04:40,840
you've often got to just double check

00:04:37,180 --> 00:04:42,490
that you that you you know the summation

00:04:40,840 --> 00:04:44,620
formulas and so on are still picking up

00:04:42,490 --> 00:04:46,419
the right Rangers if you want to add

00:04:44,620 --> 00:04:50,590
another dimension you know that's pretty

00:04:46,419 --> 00:04:52,180
tricky if you want to add another whole

00:04:50,590 --> 00:04:54,039
sort of table it can take a bit of

00:04:52,180 --> 00:04:55,810
surgery on your spreadsheet to fix that

00:04:54,039 --> 00:04:58,120
they quite hard to test if you're not

00:04:55,810 --> 00:05:00,759
experienced the in developing the

00:04:58,120 --> 00:05:02,169
logical flow can get pretty tangled so

00:05:00,759 --> 00:05:04,360
so there are there some things that

00:05:02,169 --> 00:05:06,669
you're probably already recognizing if

00:05:04,360 --> 00:05:08,050
you use a programming language for

00:05:06,669 --> 00:05:10,870
example Python you you're going to get

00:05:08,050 --> 00:05:13,720
around a lot of those problems and make

00:05:10,870 --> 00:05:15,099
your work less error-prone so that they

00:05:13,720 --> 00:05:16,449
might sound a little bit abstract what

00:05:15,099 --> 00:05:18,000
I've just gone through but just to point

00:05:16,449 --> 00:05:20,560
out that they do have real-world

00:05:18,000 --> 00:05:22,860
consequences I've just pulled out to

00:05:20,560 --> 00:05:26,770
headlines from the last couple of years

00:05:22,860 --> 00:05:31,660
which have at their root spreadsheet

00:05:26,770 --> 00:05:33,580
problems and the first one is some

00:05:31,660 --> 00:05:35,530
analysis done by two economists Reinhart

00:05:33,580 --> 00:05:39,130
and Rogoff you may have heard of they

00:05:35,530 --> 00:05:41,050
wrote a paper called growth in a time of

00:05:39,130 --> 00:05:42,669
debt I wrote a number of papers but that

00:05:41,050 --> 00:05:45,639
one in particular and in that one they

00:05:42,669 --> 00:05:47,620
found that when countries took on too

00:05:45,639 --> 00:05:51,610
much public debt above say ninety

00:05:47,620 --> 00:05:53,680
percent of annual GDP there was a bit of

00:05:51,610 --> 00:05:55,539
a an inflection point and their growth

00:05:53,680 --> 00:05:57,669
rates slowed down so this was an

00:05:55,539 --> 00:06:00,430
argument to not take on too much debt

00:05:57,669 --> 00:06:02,349
and that's been adopted by a lot of

00:06:00,430 --> 00:06:04,090
countries too or as a sort of

00:06:02,349 --> 00:06:05,830
intellectual underpinning for the

00:06:04,090 --> 00:06:08,680
policies of some countries towards

00:06:05,830 --> 00:06:11,050
austerity now turns out that actually

00:06:08,680 --> 00:06:12,759
when they made that out of public there

00:06:11,050 --> 00:06:16,000
were some problems in their analysis

00:06:12,759 --> 00:06:19,169
which people have gone through and one

00:06:16,000 --> 00:06:23,380
of them was an Excel spreadsheet error

00:06:19,169 --> 00:06:25,360
where they were summing over a table a

00:06:23,380 --> 00:06:26,949
list of countries and they just left off

00:06:25,360 --> 00:06:29,039
the bottom few countries because the

00:06:26,949 --> 00:06:30,880
range didn't go far enough down and

00:06:29,039 --> 00:06:32,580
unfortunately Australia was one of those

00:06:30,880 --> 00:06:34,870
countries

00:06:32,580 --> 00:06:38,280
in fact a lot of other countries near

00:06:34,870 --> 00:06:40,570
the start of the alphabet so those are

00:06:38,280 --> 00:06:41,740
so when you enter turn that when you fix

00:06:40,570 --> 00:06:44,290
that problem and one or two other

00:06:41,740 --> 00:06:48,370
problems as well then this inflection

00:06:44,290 --> 00:06:50,080
point disappeared so that's that's one

00:06:48,370 --> 00:06:53,110
big one and then another was in the last

00:06:50,080 --> 00:06:58,060
few years again I tried a at JP Morgan

00:06:53,110 --> 00:06:59,800
in in credit default swaps took a very

00:06:58,060 --> 00:07:02,620
large position which led to a very large

00:06:59,800 --> 00:07:05,620
loss and a fine as well by the US

00:07:02,620 --> 00:07:07,060
regulators and it turned out that one of

00:07:05,620 --> 00:07:09,040
the reasons they were again many

00:07:07,060 --> 00:07:11,830
contributing factors but one one reason

00:07:09,040 --> 00:07:15,280
was their spreadsheet which calculated

00:07:11,830 --> 00:07:17,560
the risk of the position had a formula

00:07:15,280 --> 00:07:18,940
wrong in it in which it was using a sum

00:07:17,560 --> 00:07:21,370
instead of an average or maybe an

00:07:18,940 --> 00:07:23,500
average instead of a sum and as a result

00:07:21,370 --> 00:07:25,390
the risk was apparently half of what it

00:07:23,500 --> 00:07:27,790
would have been if they'd use the other

00:07:25,390 --> 00:07:31,930
formula so I was able to take more risk

00:07:27,790 --> 00:07:33,220
than then the company realized so

00:07:31,930 --> 00:07:36,340
they're just two examples and that they

00:07:33,220 --> 00:07:40,180
lost billions of dollars in that in that

00:07:36,340 --> 00:07:42,210
position so just to give you the sense

00:07:40,180 --> 00:07:44,650
that these are real real issues and

00:07:42,210 --> 00:07:46,270
there's in fact quite a fun website you

00:07:44,650 --> 00:07:48,220
can go to if you like that sort of thing

00:07:46,270 --> 00:07:50,590
European spreadsheet risks interest

00:07:48,220 --> 00:07:52,030
group where they actually have a page

00:07:50,590 --> 00:07:58,090
called horror stories where they go

00:07:52,030 --> 00:08:03,220
through lots of these things that's come

00:07:58,090 --> 00:08:05,110
in straight away has it okay okay so

00:08:03,220 --> 00:08:08,740
that's that's why spreadsheet you should

00:08:05,110 --> 00:08:10,540
just have a bit of you know pause for

00:08:08,740 --> 00:08:11,470
thought before you want you to doing one

00:08:10,540 --> 00:08:21,340
of these sorts of things in a

00:08:11,470 --> 00:08:23,350
spreadsheet now you can use any

00:08:21,340 --> 00:08:25,750
programming language I guess instead of

00:08:23,350 --> 00:08:28,479
a spreadsheet and a lot of people are

00:08:25,750 --> 00:08:30,010
using or some people using our to do

00:08:28,479 --> 00:08:33,370
this there's a book that came out last

00:08:30,010 --> 00:08:39,460
year by Robert Brown called business

00:08:33,370 --> 00:08:41,320
case analysis in our and and so

00:08:39,460 --> 00:08:43,510
certainly pandas isn't the only option

00:08:41,320 --> 00:08:45,700
but I like pandas in fact some of this

00:08:43,510 --> 00:08:46,390
work that I developed for a client I did

00:08:45,700 --> 00:08:49,150
in our first

00:08:46,390 --> 00:08:50,890
because they they like our but I'm

00:08:49,150 --> 00:08:54,310
trying to convince them to use the

00:08:50,890 --> 00:08:57,460
pandas version or the Python version so

00:08:54,310 --> 00:09:00,040
as it says up here one reason why i like

00:08:57,460 --> 00:09:01,240
to use pandas for it as opposed to say

00:09:00,040 --> 00:09:04,300
just raw python or some other

00:09:01,240 --> 00:09:05,470
programming language is if you think

00:09:04,300 --> 00:09:07,150
about the way you structure your data

00:09:05,470 --> 00:09:10,540
especially in a spreadsheet you'd have

00:09:07,150 --> 00:09:12,700
tables and in a spreadsheet you'll add

00:09:10,540 --> 00:09:14,290
if you want to manipulate that data you

00:09:12,700 --> 00:09:16,420
pretty much have to use the position of

00:09:14,290 --> 00:09:19,600
the data in the table as the as the

00:09:16,420 --> 00:09:21,370
index in pandas you can index by name so

00:09:19,600 --> 00:09:24,880
if you've got a cost table in a price

00:09:21,370 --> 00:09:27,040
table then it doesn't matter if if your

00:09:24,880 --> 00:09:28,870
cost of apples is first is the first

00:09:27,040 --> 00:09:30,430
line and your price of Apple's is the

00:09:28,870 --> 00:09:32,680
second if your reference off apples then

00:09:30,430 --> 00:09:34,450
you're going to pick it up so that just

00:09:32,680 --> 00:09:37,320
adds an extra level of robustness that

00:09:34,450 --> 00:09:37,320
you wouldn't have in a spreadsheet

00:09:38,490 --> 00:09:43,330
secondly it can handle missing data so

00:09:40,990 --> 00:09:45,880
suppose in one of your tables you had

00:09:43,330 --> 00:09:47,680
bananas and it wasn't in the other one

00:09:45,880 --> 00:09:51,880
well a spreadsheets going to have

00:09:47,680 --> 00:09:53,410
trouble with that but in in pandas you

00:09:51,880 --> 00:09:54,880
can determine what the behavior is and

00:09:53,410 --> 00:09:57,340
sometimes the behavior will be that you

00:09:54,880 --> 00:09:58,780
should that's fine like say you don't

00:09:57,340 --> 00:10:01,930
grow any bananas and it doesn't matter

00:09:58,780 --> 00:10:03,520
that you don't have a cost and you can

00:10:01,930 --> 00:10:06,010
determine that behavior or in some cases

00:10:03,520 --> 00:10:07,240
the fact that you are missing a car so

00:10:06,010 --> 00:10:08,710
you were going bananas and you don't

00:10:07,240 --> 00:10:10,510
have the cost well that's a problem so

00:10:08,710 --> 00:10:13,960
you can set up that sort of behavior in

00:10:10,510 --> 00:10:15,970
your analysis and the third reason why I

00:10:13,960 --> 00:10:18,730
think it's a great tool is that you can

00:10:15,970 --> 00:10:21,250
broadcast dimensions what I mean by that

00:10:18,730 --> 00:10:22,750
is say you now realize that actually a

00:10:21,250 --> 00:10:26,500
cost depended on what farm you're

00:10:22,750 --> 00:10:28,180
growing these trees on so you want to

00:10:26,500 --> 00:10:30,700
restructure your data like that and say

00:10:28,180 --> 00:10:32,650
okay in farm a the cost is fifteen cents

00:10:30,700 --> 00:10:34,810
per kilogram of apples been in farm be

00:10:32,650 --> 00:10:37,840
it's twelve cents but the prices don't

00:10:34,810 --> 00:10:39,790
depend on the farm well in Python pandas

00:10:37,840 --> 00:10:41,920
when you combine these this data

00:10:39,790 --> 00:10:44,290
together it will naturally just put the

00:10:41,920 --> 00:10:46,900
cost of the pears and broadcast it out

00:10:44,290 --> 00:10:49,340
so that each farm it's the same

00:10:46,900 --> 00:10:57,800
so that gives you a lot more flexibility

00:10:49,340 --> 00:10:59,990
than you'd get in a spreadsheet that's

00:10:57,800 --> 00:11:01,910
the reason why I like Penn is now to

00:10:59,990 --> 00:11:03,740
just dive into you know it could be I

00:11:01,910 --> 00:11:05,090
guess if you don't familiar with pandas

00:11:03,740 --> 00:11:06,410
you might think what could be a bit

00:11:05,090 --> 00:11:09,770
scary to do it though because it

00:11:06,410 --> 00:11:12,410
spreadsheets so simple right so this bit

00:11:09,770 --> 00:11:14,750
i'm trying to now give you the idea that

00:11:12,410 --> 00:11:16,340
it's not that hard reading the data is

00:11:14,750 --> 00:11:17,600
very simple oh well there's four steps

00:11:16,340 --> 00:11:19,340
perhaps going back a step there's four

00:11:17,600 --> 00:11:20,950
steps that you might think of in doing

00:11:19,340 --> 00:11:23,810
the analysis one is reading in the data

00:11:20,950 --> 00:11:26,690
the second is then simulating by which

00:11:23,810 --> 00:11:28,730
i'm in drawing some random distribution

00:11:26,690 --> 00:11:31,310
so if you've got the distribution of

00:11:28,730 --> 00:11:34,520
inputs you want to simulate it draw out

00:11:31,310 --> 00:11:36,650
some numbers some random variables from

00:11:34,520 --> 00:11:37,970
there and then actually do some

00:11:36,650 --> 00:11:41,660
calculations so i don't calculate your

00:11:37,970 --> 00:11:43,160
profit and then report it you don't

00:11:41,660 --> 00:11:45,830
strictly have to simulate i guess if you

00:11:43,160 --> 00:11:47,390
wanted to be pretty hardcore about it

00:11:45,830 --> 00:11:50,480
you could actually walk work with the

00:11:47,390 --> 00:11:52,310
raw mathematical you know formulation of

00:11:50,480 --> 00:11:53,540
the distributions but that can get

00:11:52,310 --> 00:11:56,150
pretty complicated if you're doing

00:11:53,540 --> 00:11:57,830
complex calculations on it but you could

00:11:56,150 --> 00:12:01,610
do that say in Mathematica or something

00:11:57,830 --> 00:12:04,070
a few if you wanted to go that route so

00:12:01,610 --> 00:12:06,050
reading data is very simple this

00:12:04,070 --> 00:12:08,090
basically this read csb you just read it

00:12:06,050 --> 00:12:09,950
from a comma separated values file or

00:12:08,090 --> 00:12:11,270
you can even read it from excel so

00:12:09,950 --> 00:12:14,390
that's pretty straightforward that'll

00:12:11,270 --> 00:12:17,870
give you a table called a data table a

00:12:14,390 --> 00:12:19,640
data frame rather called costs and I'm

00:12:17,870 --> 00:12:22,670
going to do a quick demonstration in in

00:12:19,640 --> 00:12:24,830
an ID Python notebook after this this

00:12:22,670 --> 00:12:28,070
slide just to give you some idea of how

00:12:24,830 --> 00:12:30,800
how it works in practice hands dirty a

00:12:28,070 --> 00:12:32,810
bit simulating is a little bit trickier

00:12:30,800 --> 00:12:34,160
and and that I'll go through in more

00:12:32,810 --> 00:12:35,270
detail in this demonstration but I'm

00:12:34,160 --> 00:12:38,800
just trying to give you the idea it's

00:12:35,270 --> 00:12:38,800
only a couple of lines to do that to

00:12:39,460 --> 00:12:44,750
calculations particularly easy you just

00:12:41,570 --> 00:12:46,160
say you've got a data frame with a

00:12:44,750 --> 00:12:48,230
ballgame and a price in it and you want

00:12:46,160 --> 00:12:50,899
to calculate the revenue by multiplying

00:12:48,230 --> 00:12:53,660
them it's literally as easy as that

00:12:50,899 --> 00:12:56,240
and then finally reporting is as easy as

00:12:53,660 --> 00:12:59,420
well if you want to create a histogram

00:12:56,240 --> 00:13:03,800
there's the histor dump all your results

00:12:59,420 --> 00:13:07,579
back to excel that's easy too okay so

00:13:03,800 --> 00:13:10,879
over to a quick demonstration I when I

00:13:07,579 --> 00:13:12,920
finish this I'll come back and just have

00:13:10,879 --> 00:13:13,939
a couple of slides left to just go

00:13:12,920 --> 00:13:19,089
through the good things or bad things

00:13:13,939 --> 00:13:19,089
and the next steps about using pandas

00:13:24,160 --> 00:13:30,129
okay good enough

00:13:36,670 --> 00:13:41,710
so a quick quick demo of some of the

00:13:39,130 --> 00:13:43,390
commands that you'd use to do this first

00:13:41,710 --> 00:13:45,130
of all you just need to set it up which

00:13:43,390 --> 00:13:48,070
you may have seen before it's based on

00:13:45,130 --> 00:13:52,510
numpy as an umpire some adverse saying

00:13:48,070 --> 00:13:56,560
and ah the model I'll just demonstrate

00:13:52,510 --> 00:13:58,090
here is a pretty easy one it's just what

00:13:56,560 --> 00:13:59,590
I described before some you've got some

00:13:58,090 --> 00:14:01,480
costs you've got some revenues those

00:13:59,590 --> 00:14:04,390
revenues a price times volume and the

00:14:01,480 --> 00:14:06,520
volumes just to add an extra level to at

00:14:04,390 --> 00:14:08,320
are calculated as the number of trees on

00:14:06,520 --> 00:14:09,940
the farm times the average amount of

00:14:08,320 --> 00:14:11,200
fruit that you get off the tree and so

00:14:09,940 --> 00:14:16,420
that amount of fruit that you get off

00:14:11,200 --> 00:14:18,760
the tree that will simulate in this so

00:14:16,420 --> 00:14:20,680
to read in the data exactly like we

00:14:18,760 --> 00:14:22,420
described I described earlier I've just

00:14:20,680 --> 00:14:26,050
added one extra argument there so that

00:14:22,420 --> 00:14:30,280
any extra spaces in the file get Tom get

00:14:26,050 --> 00:14:31,480
don't get put into the data and you've

00:14:30,280 --> 00:14:33,940
probably seen this sort of thing in

00:14:31,480 --> 00:14:36,240
pandas comes up quite nicely in the

00:14:33,940 --> 00:14:38,860
ipython notebook as a data table there

00:14:36,240 --> 00:14:42,310
so the csv file is literally that same

00:14:38,860 --> 00:14:45,190
structure then we could read in the

00:14:42,310 --> 00:14:46,540
amount of fruit per tree and here here

00:14:45,190 --> 00:14:48,760
I've just specified the mean and the

00:14:46,540 --> 00:14:51,100
standard deviation of each and as you

00:14:48,760 --> 00:14:53,440
can see of a few little things are put

00:14:51,100 --> 00:14:55,300
in here in the top one the number of

00:14:53,440 --> 00:14:57,040
trees is / farm and in the bottom one

00:14:55,300 --> 00:14:59,380
the amount of food that the trees grow

00:14:57,040 --> 00:15:02,170
is is not dependent on the farm so we're

00:14:59,380 --> 00:15:04,480
going to see broadcasting happening I've

00:15:02,170 --> 00:15:06,100
also got Red Delicious in the second one

00:15:04,480 --> 00:15:12,010
but not in the first one so you'll see

00:15:06,100 --> 00:15:13,690
how the missing data works as well and

00:15:12,010 --> 00:15:16,030
here it is I guess all that is about to

00:15:13,690 --> 00:15:18,910
happen in this merge command so I've got

00:15:16,030 --> 00:15:21,640
the pandas merge up there that's just

00:15:18,910 --> 00:15:23,140
put those two put those two tables

00:15:21,640 --> 00:15:25,240
together and you can see it's broadcast

00:15:23,140 --> 00:15:27,640
out in the first two lines farm a and

00:15:25,240 --> 00:15:29,320
farm be both the Apple the granny smith

00:15:27,640 --> 00:15:33,940
apples have both got means and standard

00:15:29,320 --> 00:15:36,400
deviations of 230 and Red Delicious is

00:15:33,940 --> 00:15:38,350
missing because inherent if you just do

00:15:36,400 --> 00:15:40,390
merge without any describing how you do

00:15:38,350 --> 00:15:41,830
it it only keeps the keys from the first

00:15:40,390 --> 00:15:43,840
table so the fact there were no Red

00:15:41,830 --> 00:15:44,259
Delicious in the num trees table means

00:15:43,840 --> 00:15:47,589
you don't

00:15:44,259 --> 00:15:49,979
in the output but if you want them you

00:15:47,589 --> 00:15:52,569
can just supply a parameter like this

00:15:49,979 --> 00:15:53,919
the outta here and it will then keep

00:15:52,569 --> 00:15:56,529
both of them and you'll see there's a

00:15:53,919 --> 00:15:58,199
not a number down the bottom there which

00:15:56,529 --> 00:16:00,220
you could then deal with how you want to

00:15:58,199 --> 00:16:04,449
and I'll give you an example of that in

00:16:00,220 --> 00:16:06,009
a bit so that's actually two of the

00:16:04,449 --> 00:16:10,139
steps I guess reading while reading and

00:16:06,009 --> 00:16:14,979
then merging the data into one one table

00:16:10,139 --> 00:16:18,279
I'll just run quickly through the the

00:16:14,979 --> 00:16:20,619
way that you then do the simulation all

00:16:18,279 --> 00:16:21,729
the way I've done it you may have a

00:16:20,619 --> 00:16:25,179
better way in which case I'd be

00:16:21,729 --> 00:16:27,999
interested to hear so we've got this

00:16:25,179 --> 00:16:31,059
table fruit and we want to replace those

00:16:27,999 --> 00:16:33,429
last two columns with an actual sampling

00:16:31,059 --> 00:16:35,589
and then actually have more rows one per

00:16:33,429 --> 00:16:37,419
iteration okay and the way we're going

00:16:35,589 --> 00:16:39,729
to do that I'll just take a bit of a

00:16:37,419 --> 00:16:41,079
detour and talk about group by because

00:16:39,729 --> 00:16:45,160
we're going to do it using this group by

00:16:41,079 --> 00:16:47,139
command group by will let you aggregate

00:16:45,160 --> 00:16:49,029
some of this data and then do some

00:16:47,139 --> 00:16:51,009
statistics on it so for example if you

00:16:49,029 --> 00:16:52,899
wanted to count how many different rows

00:16:51,009 --> 00:16:54,819
there were for each farm you could use

00:16:52,899 --> 00:16:57,429
this command group by farm and then

00:16:54,819 --> 00:16:59,410
count and you can see it tells you there

00:16:57,429 --> 00:17:03,639
are three rows for farm a and through

00:16:59,410 --> 00:17:04,899
two rows for VAR b for each column you

00:17:03,639 --> 00:17:07,329
don't have to group by just one thing

00:17:04,899 --> 00:17:08,889
you grew by two so here we're now seeing

00:17:07,329 --> 00:17:10,959
there were two varieties of apple at

00:17:08,889 --> 00:17:15,850
parme and one variety of peer and two

00:17:10,959 --> 00:17:17,199
varieties of apple at farm be and you

00:17:15,850 --> 00:17:19,240
don't have to just do simple things like

00:17:17,199 --> 00:17:22,419
count you can actually define your own

00:17:19,240 --> 00:17:24,399
functions as well so for example if you

00:17:22,419 --> 00:17:28,809
use the supplier will apply this test

00:17:24,399 --> 00:17:30,549
function to to each row and write it out

00:17:28,809 --> 00:17:32,909
and my test function is indeed just

00:17:30,549 --> 00:17:35,230
account so we get the same result but

00:17:32,909 --> 00:17:38,440
now we've got the tools we need to do

00:17:35,230 --> 00:17:40,330
this simulation if instead of just

00:17:38,440 --> 00:17:44,590
counting suppose I actually put out a

00:17:40,330 --> 00:17:46,690
random uni unit normal here then you'll

00:17:44,590 --> 00:17:48,039
see we now get and I'm counting as well

00:17:46,690 --> 00:17:50,679
just to keep the continuity with the

00:17:48,039 --> 00:17:53,260
previous line so you can see we now have

00:17:50,679 --> 00:17:55,800
account and a random variable coming in

00:17:53,260 --> 00:17:58,540
at each position

00:17:55,800 --> 00:18:00,190
that gives you a couple of rows we

00:17:58,540 --> 00:18:01,510
actually wanted a couple of sorry a

00:18:00,190 --> 00:18:04,900
couple of columns we actually wanted a

00:18:01,510 --> 00:18:06,820
couple of rows for each one so now if we

00:18:04,900 --> 00:18:10,480
use a function like this where we're

00:18:06,820 --> 00:18:13,150
returning a data frame with three random

00:18:10,480 --> 00:18:14,410
normals in it it'll produce this output

00:18:13,150 --> 00:18:16,680
and you can see now we're getting pretty

00:18:14,410 --> 00:18:21,220
close to what we want where we have a

00:18:16,680 --> 00:18:22,990
where we've drawn three random variables

00:18:21,220 --> 00:18:25,660
from this distribution for each for each

00:18:22,990 --> 00:18:26,980
row the last step we need is simply to

00:18:25,660 --> 00:18:29,160
use the mean and the standard deviation

00:18:26,980 --> 00:18:33,070
we actually had in the original data

00:18:29,160 --> 00:18:35,290
which we can do with this this test

00:18:33,070 --> 00:18:36,670
function comes in with a group and you

00:18:35,290 --> 00:18:38,440
just you can actually just pull the mean

00:18:36,670 --> 00:18:41,230
and the standard deviation from that and

00:18:38,440 --> 00:18:44,290
so we're away basically with that and

00:18:41,230 --> 00:18:49,300
there's our there's our data table with

00:18:44,290 --> 00:18:51,250
the with the simulations in it you'll

00:18:49,300 --> 00:18:53,470
find in pandas there's often a lot of

00:18:51,250 --> 00:18:55,510
data manipulation you need to do just to

00:18:53,470 --> 00:18:58,420
get the exact form that you want so for

00:18:55,510 --> 00:19:01,090
example this doesn't have a column name

00:18:58,420 --> 00:19:03,990
for the iteration so if you want to add

00:19:01,090 --> 00:19:08,890
that in one way you can do it is just

00:19:03,990 --> 00:19:10,690
this rename command here I've also done

00:19:08,890 --> 00:19:13,390
reset index so you can go back and forth

00:19:10,690 --> 00:19:14,980
between having your indices grouped in

00:19:13,390 --> 00:19:17,500
the nice way you see in the previous

00:19:14,980 --> 00:19:20,110
cell to having them just list it out

00:19:17,500 --> 00:19:21,280
every time and pretty much different

00:19:20,110 --> 00:19:24,040
tasks it's better to have them in

00:19:21,280 --> 00:19:27,420
different formats I'll found but you can

00:19:24,040 --> 00:19:30,490
see now we've got an iteration column

00:19:27,420 --> 00:19:32,050
and just to give you a that was only

00:19:30,490 --> 00:19:35,590
with three iterations just say you

00:19:32,050 --> 00:19:37,570
wanted to use a thousand you know it's

00:19:35,590 --> 00:19:40,290
just as easy now because it's all just a

00:19:37,570 --> 00:19:42,940
parameter and then in this example

00:19:40,290 --> 00:19:45,040
rather than list out all thousand

00:19:42,940 --> 00:19:48,040
iterations for each farm I'm just giving

00:19:45,040 --> 00:19:50,710
you a describe you can see I've run

00:19:48,040 --> 00:19:52,660
describe up there and it's just giving

00:19:50,710 --> 00:19:54,310
you the mean and standard deviation of

00:19:52,660 --> 00:19:55,960
some other parameters about that simular

00:19:54,310 --> 00:19:57,910
and you can see that the means and

00:19:55,960 --> 00:20:02,440
standard deviations add up about the way

00:19:57,910 --> 00:20:05,110
you want okay so that's that's sort of

00:20:02,440 --> 00:20:07,690
the simulation part of it the

00:20:05,110 --> 00:20:09,700
calculation part then is as easy as I

00:20:07,690 --> 00:20:11,710
said with any luck so what have we go

00:20:09,700 --> 00:20:14,410
we've now got this sim fruit poetry

00:20:11,710 --> 00:20:15,970
table where we've simulated and the head

00:20:14,410 --> 00:20:19,810
part of that command just shows you the

00:20:15,970 --> 00:20:21,640
first few minds we now put the number of

00:20:19,810 --> 00:20:23,350
trees back into that table which came

00:20:21,640 --> 00:20:26,110
out of there somewhere along the way and

00:20:23,350 --> 00:20:29,980
now we do this calculation where we

00:20:26,110 --> 00:20:33,190
simply add in a volume row that interval

00:20:29,980 --> 00:20:35,110
volume column sorry you can see there so

00:20:33,190 --> 00:20:37,030
that volume column and here is just the

00:20:35,110 --> 00:20:42,280
product of the number of trees in the

00:20:37,030 --> 00:20:43,780
fruit poetry so from there I'll just

00:20:42,280 --> 00:20:45,220
skip over a few lines because basically

00:20:43,780 --> 00:20:47,260
I'm just reading in some costs and

00:20:45,220 --> 00:20:51,040
prices and so on and we're going to

00:20:47,260 --> 00:20:52,960
merge them all in and then we get to a

00:20:51,040 --> 00:20:55,710
line like that way you've actually got a

00:20:52,960 --> 00:21:00,040
revenue coming in for each of these and

00:20:55,710 --> 00:21:02,260
then a real world thing here now comes

00:21:00,040 --> 00:21:04,180
in which is that's all very nice but

00:21:02,260 --> 00:21:06,130
actually some of your costs might not be

00:21:04,180 --> 00:21:08,500
down at that very granular level of

00:21:06,130 --> 00:21:10,030
varieties you know every variety of

00:21:08,500 --> 00:21:12,430
fruit so for example fixed costs might

00:21:10,030 --> 00:21:16,300
just be a you plan to run parme you've

00:21:12,430 --> 00:21:19,420
got some fixed costs and so there's an

00:21:16,300 --> 00:21:20,590
example of the fixed costs there and the

00:21:19,420 --> 00:21:21,880
way that you would deal with that is

00:21:20,590 --> 00:21:24,010
you've just got to use this group by

00:21:21,880 --> 00:21:26,140
function again to get all your data the

00:21:24,010 --> 00:21:28,030
simulations back up to that level so if

00:21:26,140 --> 00:21:30,100
we grouped by farm and iteration will

00:21:28,030 --> 00:21:34,270
now have a data table we can apply the

00:21:30,100 --> 00:21:39,820
fixed cost too and we can do that again

00:21:34,270 --> 00:21:41,110
with merge and the screens not quite

00:21:39,820 --> 00:21:44,380
wide enough you can see we've now got

00:21:41,110 --> 00:21:48,880
this fixed cost guy over here and it

00:21:44,380 --> 00:21:50,430
just applies to just applies to farms it

00:21:48,880 --> 00:21:53,590
doesn't apply down at the level of the

00:21:50,430 --> 00:21:55,030
variety of fruit and because it didn't

00:21:53,590 --> 00:21:57,690
because it didn't have a fixed cost for

00:21:55,030 --> 00:21:59,279
farm be we've got Nan's coming in here

00:21:57,690 --> 00:22:00,779
and just to show you how you can deal

00:21:59,279 --> 00:22:04,230
with that quite simply you just use this

00:22:00,779 --> 00:22:06,389
Phil na command and that word dumb that

00:22:04,230 --> 00:22:08,610
would replace it with you zero and you

00:22:06,389 --> 00:22:10,980
can have much more sophisticated Phil na

00:22:08,610 --> 00:22:15,269
s than that where you feel forward or

00:22:10,980 --> 00:22:16,590
use a function so then we're in a

00:22:15,269 --> 00:22:19,230
position we can now calculate the profit

00:22:16,590 --> 00:22:21,029
and even some it over the farms and

00:22:19,230 --> 00:22:22,919
here's you here's what you might finish

00:22:21,029 --> 00:22:24,529
with at the top here where for each

00:22:22,919 --> 00:22:26,549
iteration you've calculated the profit

00:22:24,529 --> 00:22:27,960
I've gone through that in quite a bit of

00:22:26,549 --> 00:22:33,029
detail but I guess the idea is just to

00:22:27,960 --> 00:22:34,409
show it's not too scary the logic is you

00:22:33,029 --> 00:22:35,909
know you can contain all your formulas

00:22:34,409 --> 00:22:38,039
in just one place you don't have to push

00:22:35,909 --> 00:22:41,879
them across many cells in in a

00:22:38,039 --> 00:22:45,360
spreadsheet so I like that and just to

00:22:41,879 --> 00:22:47,070
put it all in one place that's it's just

00:22:45,360 --> 00:22:52,799
a bit more than a screen full I guess of

00:22:47,070 --> 00:22:55,860
code there to actually do that let me

00:22:52,799 --> 00:22:59,070
run it so I've done it for 10,000

00:22:55,860 --> 00:23:01,580
iterations here and then you can see you

00:22:59,070 --> 00:23:03,509
get you can print out some histograms

00:23:01,580 --> 00:23:06,059
you probably need to spend a little bit

00:23:03,509 --> 00:23:08,399
of work on prettying them up but the

00:23:06,059 --> 00:23:12,059
basic basic output is there and you can

00:23:08,399 --> 00:23:17,909
also calculate things like what's the

00:23:12,059 --> 00:23:19,440
chance of a loss based on that one one

00:23:17,909 --> 00:23:20,549
cool thing about pandas that i haven't

00:23:19,440 --> 00:23:21,600
mentioned that i'll just take the

00:23:20,549 --> 00:23:24,240
opportunity because there's a little bit

00:23:21,600 --> 00:23:29,490
of time is this boolean indexing feature

00:23:24,240 --> 00:23:31,889
here so here it's only going to be

00:23:29,490 --> 00:23:33,629
summing up this someone the apply two

00:23:31,889 --> 00:23:36,590
rows where the profit is less than or

00:23:33,629 --> 00:23:39,929
equal to 0 so that then sums up how many

00:23:36,590 --> 00:23:42,000
times profit was less than zero and by

00:23:39,929 --> 00:23:44,399
dividing by enya then getting a fraction

00:23:42,000 --> 00:23:47,659
of the times so you get say seven or

00:23:44,399 --> 00:23:47,659
eight percent chance of loss there

00:23:51,140 --> 00:23:56,130
in all of that you know these are the

00:23:54,000 --> 00:23:57,929
key pandas functions that I've used in

00:23:56,130 --> 00:24:00,840
all of that if you're interested just as

00:23:57,929 --> 00:24:03,510
a summary pretty much you know reading

00:24:00,840 --> 00:24:07,350
in the file with bread CSV and merging

00:24:03,510 --> 00:24:09,029
group I and apply and fill na and hissed

00:24:07,350 --> 00:24:11,940
and then these features are broadcasting

00:24:09,029 --> 00:24:14,549
and boolean indexing and then some a

00:24:11,940 --> 00:24:16,470
little bit of data manipulation or the

00:24:14,549 --> 00:24:20,809
structure manipulation things like

00:24:16,470 --> 00:24:20,809
dropping resetting index and renaming

00:24:34,029 --> 00:24:41,029
alright so then just to finish up the

00:24:36,799 --> 00:24:42,830
good things again are that it's easy to

00:24:41,029 --> 00:24:45,590
add new farms and crops when you do it

00:24:42,830 --> 00:24:49,279
this way you just put them into the data

00:24:45,590 --> 00:24:51,230
files and it sort of all works if you

00:24:49,279 --> 00:24:52,669
wanted to add whole new dimensions so in

00:24:51,230 --> 00:24:55,970
practice you'd want to have you know

00:24:52,669 --> 00:24:57,500
profit per year that's pretty easy to do

00:24:55,970 --> 00:25:00,770
because it's just another another

00:24:57,500 --> 00:25:02,929
dimension it's also easy to add tests I

00:25:00,770 --> 00:25:05,570
haven't gone through that in this

00:25:02,929 --> 00:25:08,840
example but I've got a repository on

00:25:05,570 --> 00:25:11,240
bitbucket where I've got this example

00:25:08,840 --> 00:25:12,770
and some more examples and then actually

00:25:11,240 --> 00:25:16,909
have some tests there so you can see

00:25:12,770 --> 00:25:18,140
that that's quite doable and and as a

00:25:16,909 --> 00:25:21,679
result of all those things it's less

00:25:18,140 --> 00:25:23,299
error-prone than using a spreadsheet the

00:25:21,679 --> 00:25:25,460
bad things about doing it this way I

00:25:23,299 --> 00:25:28,309
guess says you might expect spreadsheets

00:25:25,460 --> 00:25:30,830
are really easy I don't see using pandas

00:25:28,309 --> 00:25:33,110
it's not going to take over anytime soon

00:25:30,830 --> 00:25:35,120
using spreadsheets to do this but I

00:25:33,110 --> 00:25:39,200
think in some key situations where

00:25:35,120 --> 00:25:43,159
there's a lot of money at stake I think

00:25:39,200 --> 00:25:44,840
it's it's not a bad approach and I even

00:25:43,159 --> 00:25:46,340
if companies themselves don't sort of

00:25:44,840 --> 00:25:48,020
take this on I think there's probably a

00:25:46,340 --> 00:25:50,500
role for consultants specialist

00:25:48,020 --> 00:25:55,870
consultants to have these skills and and

00:25:50,500 --> 00:25:59,630
do that sort of analysis pandas itself

00:25:55,870 --> 00:26:02,539
is a great tool and it's fantastic that

00:25:59,630 --> 00:26:04,700
it's available it does have a few things

00:26:02,539 --> 00:26:07,399
that I found a bit non-intuitive like um

00:26:04,700 --> 00:26:09,020
using right sometimes it's been

00:26:07,399 --> 00:26:10,520
inconsistent to my mind of whether you

00:26:09,020 --> 00:26:12,620
put the robe or the column name first

00:26:10,520 --> 00:26:15,890
insert the arguments and in fact the

00:26:12,620 --> 00:26:17,630
fact that it uses this hierarchical

00:26:15,890 --> 00:26:20,809
indexing so that everything is a two

00:26:17,630 --> 00:26:22,370
dimensional structure isn't my natural

00:26:20,809 --> 00:26:24,049
way of thinking I tend to think more i

00:26:22,370 --> 00:26:26,650
guess like the underlying numpy has the

00:26:24,049 --> 00:26:29,200
multidimensional arrays

00:26:26,650 --> 00:26:30,790
so sometimes just getting the right

00:26:29,200 --> 00:26:32,620
commands to do what you want can take a

00:26:30,790 --> 00:26:36,070
bit of work but when you get there it

00:26:32,620 --> 00:26:38,440
looks fairly obvious a kiss and then

00:26:36,070 --> 00:26:40,180
finally next steps I mentioned the bit

00:26:38,440 --> 00:26:42,040
bucket repository where I've put a few

00:26:40,180 --> 00:26:43,960
routines to help make this a little bit

00:26:42,040 --> 00:26:46,150
easier in practice and based on some of

00:26:43,960 --> 00:26:48,790
the things that I've found when trying

00:26:46,150 --> 00:26:52,330
to do this for example when you're

00:26:48,790 --> 00:26:53,590
drawing from well when you you're not

00:26:52,330 --> 00:26:54,760
always going to want to use normal

00:26:53,590 --> 00:26:56,350
distributions in fact I wouldn't

00:26:54,760 --> 00:27:00,130
recommend it even for the example I gave

00:26:56,350 --> 00:27:01,690
here of the fruit fruit on the trees

00:27:00,130 --> 00:27:02,980
because you're going to have disasters

00:27:01,690 --> 00:27:06,250
and other sorts of things you don't want

00:27:02,980 --> 00:27:08,230
your numbers going below zero so I've

00:27:06,250 --> 00:27:10,540
got a routine in there which based on

00:27:08,230 --> 00:27:12,850
the parameters that you specify in your

00:27:10,540 --> 00:27:15,790
input file it'll work out what sort of

00:27:12,850 --> 00:27:18,430
distribution you wanted another

00:27:15,790 --> 00:27:20,200
important one is it's you don't want to

00:27:18,430 --> 00:27:22,780
rush into Monte Carlo analysis before

00:27:20,200 --> 00:27:24,910
you've done the base case situation as

00:27:22,780 --> 00:27:26,830
much as I maligned just doing a single

00:27:24,910 --> 00:27:29,200
case you know it's still a good place to

00:27:26,830 --> 00:27:31,060
start because if you rush to quickly

00:27:29,200 --> 00:27:33,580
into complicating it you kind of often

00:27:31,060 --> 00:27:35,800
find it quite hard to work out if there

00:27:33,580 --> 00:27:37,750
are problems as well so there's some

00:27:35,800 --> 00:27:39,610
code there so that if you pass in an N

00:27:37,750 --> 00:27:42,730
equals zero instead of N equals ten

00:27:39,610 --> 00:27:46,390
thousand it it will return using the

00:27:42,730 --> 00:27:48,670
same logic and all the same calculations

00:27:46,390 --> 00:27:50,710
that you've done it will return the base

00:27:48,670 --> 00:27:52,300
case rather than a simulation so that

00:27:50,710 --> 00:27:54,130
you you can see whether you your base

00:27:52,300 --> 00:27:55,630
case makes sense and similarly

00:27:54,130 --> 00:27:58,630
sensitivity analysis that tornado

00:27:55,630 --> 00:28:00,460
diagram I showed at the start where you

00:27:58,630 --> 00:28:03,880
just very one thing at a time there's

00:28:00,460 --> 00:28:05,470
some code to do that as well some

00:28:03,880 --> 00:28:08,050
specialized input-output stuff to make

00:28:05,470 --> 00:28:12,960
things like years easier to input and

00:28:08,050 --> 00:28:15,850
this talk itself is there too so I guess

00:28:12,960 --> 00:28:18,130
the key message I'd like to get across

00:28:15,850 --> 00:28:19,600
really is that it's this is might be an

00:28:18,130 --> 00:28:20,770
interesting use for Python and panders

00:28:19,600 --> 00:28:24,550
that you haven't thought of before and

00:28:20,770 --> 00:28:27,790
hopefully it will improve investment

00:28:24,550 --> 00:28:31,470
making in businesses and beware of

00:28:27,790 --> 00:28:31,470
spreadsheets thanks very much

00:28:34,880 --> 00:28:40,650
thank you very much so um um we don't

00:28:39,300 --> 00:28:42,780
have any time for questions but um

00:28:40,650 --> 00:28:44,940
please speak to Arthur afterwards so

00:28:42,780 --> 00:28:47,370
thank you very much Arthur so Arthur run

00:28:44,940 --> 00:28:50,220
to consultancy business developing web

00:28:47,370 --> 00:28:53,090
apps with a math and analysis flavor and

00:28:50,220 --> 00:28:53,090
he also run

00:28:58,480 --> 00:29:00,540

YouTube URL: https://www.youtube.com/watch?v=KcMaO2f7ww4


