Title: Science MiniConf: PyMODIS: processing 14 years of NASA's remotely sensed MODIS imagery by Ben Davies
Publication date: 2014-08-17
Playlist: PyCon Australia 2014 Science & Data miniconf
Description: 
	PyCon Australia is the national conference for users of the Python Programming Language. In August 2014, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

August 1-5, Brisbane, Queensland, Australia
Captions: 
	00:00:05,830 --> 00:00:14,470
oh hi everyone thanks for coming along

00:00:11,350 --> 00:00:16,689
to Poland today I'm just gonna discuss a

00:00:14,470 --> 00:00:18,760
project that I've been working on on and

00:00:16,689 --> 00:00:21,369
off it's a collaborative GIS project

00:00:18,760 --> 00:00:22,630
between myself and a group out of the

00:00:21,369 --> 00:00:29,890
ANU called the Finnish school of

00:00:22,630 --> 00:00:31,239
environment and society so yeah it's

00:00:29,890 --> 00:00:33,250
probably mentioned before actually a

00:00:31,239 --> 00:00:35,350
scientific specialist program and

00:00:33,250 --> 00:00:36,370
working out of the NCI I didn't see I

00:00:35,350 --> 00:00:37,750
actually stands for national

00:00:36,370 --> 00:00:39,129
computational infrastructure it was

00:00:37,750 --> 00:00:40,989
formerly known as the a new

00:00:39,129 --> 00:00:43,929
supercomputer facility or some people

00:00:40,989 --> 00:00:45,850
might notice a pack we're actually the

00:00:43,929 --> 00:00:47,260
host of reijin which is currently the

00:00:45,850 --> 00:00:49,660
largest supercomputer in the southern

00:00:47,260 --> 00:00:51,640
hemisphere he's a shot of the Machine

00:00:49,660 --> 00:00:55,660
room it's actually instantly useful as a

00:00:51,640 --> 00:00:57,219
film said to so apparently if you see

00:00:55,660 --> 00:00:59,170
something called the code coming on TV

00:00:57,219 --> 00:01:01,239
that's you'll see you there

00:00:59,170 --> 00:01:03,519
we actually provide petabytes storage

00:01:01,239 --> 00:01:06,070
facilities and there's also a cloud for

00:01:03,519 --> 00:01:09,060
services there too and we typically host

00:01:06,070 --> 00:01:10,930
for the day a new research csro

00:01:09,060 --> 00:01:15,550
Geoscience Australia and Bureau of

00:01:10,930 --> 00:01:17,830
Meteorology certain by day job I'm

00:01:15,550 --> 00:01:20,080
developing a lot of GIS and software and

00:01:17,830 --> 00:01:21,490
I actually support a number of science

00:01:20,080 --> 00:01:23,740
people there and this is sort of a rough

00:01:21,490 --> 00:01:26,290
example here of bridging the gap between

00:01:23,740 --> 00:01:27,400
scientists and technology so we actually

00:01:26,290 --> 00:01:29,200
do it's a classification that we're

00:01:27,400 --> 00:01:31,030
doing and we have to the drape that over

00:01:29,200 --> 00:01:32,770
a digital elevation model there so

00:01:31,030 --> 00:01:34,210
that's actually Southeast Australia I

00:01:32,770 --> 00:01:37,450
don't know how well it's coming up and

00:01:34,210 --> 00:01:40,470
I've the screen lie predominant use of

00:01:37,450 --> 00:01:42,850
Python is for things like basically

00:01:40,470 --> 00:01:44,680
geospatial processing this terrain

00:01:42,850 --> 00:01:47,460
analysis fits into that as well

00:01:44,680 --> 00:01:49,960
prototyping it's data analysis and

00:01:47,460 --> 00:01:52,890
obviously we're data exploration and

00:01:49,960 --> 00:01:55,930
actually use it quite a bit for testing

00:01:52,890 --> 00:01:57,310
so since 2007 are actually collaborated

00:01:55,930 --> 00:01:58,780
with a group out of the finish school at

00:01:57,310 --> 00:02:01,210
the ANU so this is their building

00:01:58,780 --> 00:02:03,310
they're actually concentrating on a

00:02:01,210 --> 00:02:05,920
plethora the environmental problems like

00:02:03,310 --> 00:02:09,879
through the water crisis climate change

00:02:05,920 --> 00:02:11,080
fires droughts and biodiversity loss is

00:02:09,879 --> 00:02:13,660
the sort of thing I'm helping them to

00:02:11,080 --> 00:02:15,430
focus on as well so the particular

00:02:13,660 --> 00:02:16,930
research for this particular research

00:02:15,430 --> 00:02:18,860
interest of this group are things like

00:02:16,930 --> 00:02:20,750
modeling floor and floor

00:02:18,860 --> 00:02:24,320
flora and fauna response to climate

00:02:20,750 --> 00:02:26,000
change in atmospheric co2 and they

00:02:24,320 --> 00:02:27,350
typically change a work if like

00:02:26,000 --> 00:02:28,880
large-scale actually up to the

00:02:27,350 --> 00:02:30,800
continental scale is they're trying to

00:02:28,880 --> 00:02:33,170
treat an ecosystem is a continuous whole

00:02:30,800 --> 00:02:35,150
so I mean just sort of like you're

00:02:33,170 --> 00:02:38,210
working with like all of Australia in a

00:02:35,150 --> 00:02:39,830
data set at once and mostly they're

00:02:38,210 --> 00:02:42,650
geographers they've got no formal

00:02:39,830 --> 00:02:44,540
software training and they typically

00:02:42,650 --> 00:02:48,440
just using things like Windows desktop

00:02:44,540 --> 00:02:49,820
GIS like arcmap that could do a bit of

00:02:48,440 --> 00:02:51,680
our coding every now and then and this

00:02:49,820 --> 00:02:54,610
sort of stuff on Windows boxes and they

00:02:51,680 --> 00:02:54,610
don't have any admin rights

00:02:56,380 --> 00:03:01,760
so back in early 2012 they actually

00:02:59,600 --> 00:03:03,530
contacted me and said I hope we need

00:03:01,760 --> 00:03:04,970
some updated vegetation data and

00:03:03,530 --> 00:03:07,400
previously one of their senior

00:03:04,970 --> 00:03:09,140
researchers said she'd done all the work

00:03:07,400 --> 00:03:12,440
to actually produce a number of layers

00:03:09,140 --> 00:03:13,310
and it turns out this research had

00:03:12,440 --> 00:03:17,000
already retired

00:03:13,310 --> 00:03:18,950
come on NJ so they sort of left with

00:03:17,000 --> 00:03:21,050
this okay what do we do no one else

00:03:18,950 --> 00:03:24,350
could actually repeat this work it took

00:03:21,050 --> 00:03:26,170
ages to produce and they basically gave

00:03:24,350 --> 00:03:28,640
me a time frame of a couple months

00:03:26,170 --> 00:03:30,260
apparently some of these our research

00:03:28,640 --> 00:03:32,540
partners needed to start a fairly soon

00:03:30,260 --> 00:03:34,160
and I heard I don't know if it's true

00:03:32,540 --> 00:03:38,239
but it was partly gonna make it into my

00:03:34,160 --> 00:03:39,890
life ECC reports so this sort of

00:03:38,239 --> 00:03:41,510
interesting their idea of was they

00:03:39,890 --> 00:03:45,110
wanted to extract functional leaf type

00:03:41,510 --> 00:03:48,290
data from digital vegetation information

00:03:45,110 --> 00:03:50,930
and there was if NASA has got this

00:03:48,290 --> 00:03:52,610
terrorist satellite with these series of

00:03:50,930 --> 00:03:54,500
instruments called modus instruments and

00:03:52,610 --> 00:03:57,709
which is that since the moderate

00:03:54,500 --> 00:03:59,750
resolution imaging spectroradiometer and

00:03:57,709 --> 00:04:01,310
this actually is a satellite it just

00:03:59,750 --> 00:04:04,370
goes in images the earth sort of every

00:04:01,310 --> 00:04:08,330
one to two days and they were interested

00:04:04,370 --> 00:04:09,890
to take a subset of that imagery or

00:04:08,330 --> 00:04:11,570
something about thirty-six instruments

00:04:09,890 --> 00:04:13,310
instruments on it on board and I wanted

00:04:11,570 --> 00:04:15,350
to actually to see is one of the results

00:04:13,310 --> 00:04:16,370
from one of those they actually wanna

00:04:15,350 --> 00:04:17,810
sort of take some of this base

00:04:16,370 --> 00:04:19,280
vegetation data

00:04:17,810 --> 00:04:22,160
break that down into three different

00:04:19,280 --> 00:04:25,160
vegetation classes they call the tutor

00:04:22,160 --> 00:04:26,240
gore music and scholar Phil so this

00:04:25,160 --> 00:04:28,970
encompasses everything from things like

00:04:26,240 --> 00:04:32,030
grasslands shrublands and have open

00:04:28,970 --> 00:04:33,650
forests close forests and rainforests

00:04:32,030 --> 00:04:35,960
and the goal is to sort of get this like

00:04:33,650 --> 00:04:38,840
these rough vegetation classes for all

00:04:35,960 --> 00:04:42,700
of Australia over the time series that

00:04:38,840 --> 00:04:45,169
this modus satellites been input taking

00:04:42,700 --> 00:04:47,270
informational readings so with that way

00:04:45,169 --> 00:04:49,190
they can basically get an idea of

00:04:47,270 --> 00:04:50,960
vegetation changes across Australia for

00:04:49,190 --> 00:04:54,500
the past probably by now it took about

00:04:50,960 --> 00:04:56,300
14 years of data so this will obviously

00:04:54,500 --> 00:04:57,740
help result things like if you've got a

00:04:56,300 --> 00:04:59,480
bushfire that might actually just

00:04:57,740 --> 00:05:01,340
completely blitz an area and then you'll

00:04:59,480 --> 00:05:02,690
note that say the vegetation there will

00:05:01,340 --> 00:05:05,240
be completely changed and you can

00:05:02,690 --> 00:05:07,400
actually sort of track recovery and or

00:05:05,240 --> 00:05:09,080
if the actual types the types of

00:05:07,400 --> 00:05:11,000
vegetation like completely change

00:05:09,080 --> 00:05:12,200
there's probably example the best

00:05:11,000 --> 00:05:14,360
example I can think of that is if

00:05:12,200 --> 00:05:17,600
anyone's familiar with the bush fires in

00:05:14,360 --> 00:05:18,830
Canberra in about 2003 and Mount Stromlo

00:05:17,600 --> 00:05:21,080
is there that was actually a pine forest

00:05:18,830 --> 00:05:23,390
it Hill and that actually got completely

00:05:21,080 --> 00:05:25,550
blitzed in the fires and it actually

00:05:23,390 --> 00:05:27,740
became more of a sort of grassland and

00:05:25,550 --> 00:05:30,370
sort of open shrubby woodland and it's

00:05:27,740 --> 00:05:32,450
now actually slowly starting to recover

00:05:30,370 --> 00:05:33,950
and the federal group they're looking at

00:05:32,450 --> 00:05:38,780
mainly using this thing called the modus

00:05:33,950 --> 00:05:40,280
13q one product or NDVI NDVI stands to

00:05:38,780 --> 00:05:42,890
normalized difference vegetation index

00:05:40,280 --> 00:05:45,100
and this is roughly speaking it's a like

00:05:42,890 --> 00:05:47,510
a measurement of live green vegetation

00:05:45,100 --> 00:05:49,340
so if you've got yellow values

00:05:47,510 --> 00:05:51,979
represents in a dry vegetation or

00:05:49,340 --> 00:05:53,960
possibly even bare soil and high values

00:05:51,979 --> 00:05:55,490
as you get supplier of the scale it's

00:05:53,960 --> 00:05:58,610
sort of the more green your vegetation

00:05:55,490 --> 00:06:00,020
you should top out at rainforest and you

00:05:58,610 --> 00:06:01,490
end up with multiple acquisitions per

00:06:00,020 --> 00:06:03,140
year so you can actually get this like

00:06:01,490 --> 00:06:04,820
there's a time series of all this

00:06:03,140 --> 00:06:06,550
information so you can actually start to

00:06:04,820 --> 00:06:08,780
you can actually start me to change

00:06:06,550 --> 00:06:13,039
unfortunately we had a copy of this data

00:06:08,780 --> 00:06:14,900
hosted at NCI and here's a rough example

00:06:13,039 --> 00:06:18,050
that I ripped from a NASA site you can

00:06:14,900 --> 00:06:19,840
basically see here you've got this brown

00:06:18,050 --> 00:06:22,400
it's representing like below average

00:06:19,840 --> 00:06:24,770
moisture sieve actually it's probably in

00:06:22,400 --> 00:06:27,110
the middle of a drought so you can

00:06:24,770 --> 00:06:29,660
actually see up in the sort of sort of a

00:06:27,110 --> 00:06:30,710
crew shusuke National Park and Victorian

00:06:29,660 --> 00:06:33,560
Highlands you sort of getting some

00:06:30,710 --> 00:06:35,930
fairly dry areas but then if you skip

00:06:33,560 --> 00:06:37,280
forward two years or so you've it's

00:06:35,930 --> 00:06:39,110
actually picked up and it's obviously

00:06:37,280 --> 00:06:40,550
it's being a lot more rainfall perhaps

00:06:39,110 --> 00:06:43,760
than normal and it's actually grained up

00:06:40,550 --> 00:06:44,279
again so just go into a bit of the

00:06:43,760 --> 00:06:46,919
actual take

00:06:44,279 --> 00:06:48,839
detail of some of the data you end up

00:06:46,919 --> 00:06:50,999
with the number of cities like raster or

00:06:48,839 --> 00:06:53,309
bitmap images of this data and it comes

00:06:50,999 --> 00:06:57,089
in at sort of a nine second or 250 meter

00:06:53,309 --> 00:06:59,069
cell each data sits about nineteen

00:06:57,089 --> 00:06:59,939
thousand by fourteen thousand cells so

00:06:59,069 --> 00:07:03,119
you end up with about two hundred

00:06:59,939 --> 00:07:05,279
eighty-five thousand cells per image and

00:07:03,119 --> 00:07:07,279
that's all 16-bit integer data and you

00:07:05,279 --> 00:07:10,709
end up with about half a gigabyte a year

00:07:07,279 --> 00:07:12,749
sorry half a gigabyte per image that

00:07:10,709 --> 00:07:16,289
boil and there's twenty three Rastas per

00:07:12,749 --> 00:07:17,819
year so you end up you're basically in

00:07:16,289 --> 00:07:20,759
down with about 12 gigabytes a year of

00:07:17,819 --> 00:07:21,989
data and this starts in early 2000 and

00:07:20,759 --> 00:07:23,399
continues to a couple of months before

00:07:21,989 --> 00:07:25,679
the present day because it's actually a

00:07:23,399 --> 00:07:27,599
sort of processing lag with the CSIRO

00:07:25,679 --> 00:07:31,409
actually a sort of do some sort of the

00:07:27,599 --> 00:07:32,939
processing steps to it and obviously new

00:07:31,409 --> 00:07:36,179
acquisitions are adding about two layers

00:07:32,939 --> 00:07:38,069
or a gigabyte per month basically it's

00:07:36,179 --> 00:07:39,869
not huge in high-performance computing

00:07:38,069 --> 00:07:41,579
terms but it's sort of it's problematic

00:07:39,869 --> 00:07:44,969
it's like scientists the data of a

00:07:41,579 --> 00:07:46,949
technical background and obviously you

00:07:44,969 --> 00:07:48,539
considered you can break this NDVI layer

00:07:46,949 --> 00:07:50,729
down into a number of these functional

00:07:48,539 --> 00:07:52,679
leaf types was talking about earlier and

00:07:50,729 --> 00:07:54,569
my particular roles I was given a Word

00:07:52,679 --> 00:07:57,089
document which said oh here's a couple

00:07:54,569 --> 00:07:59,369
of algorithms listed a couple of

00:07:57,089 --> 00:08:01,469
processing steps there's a bit more

00:07:59,369 --> 00:08:04,349
detail including a couple of academic

00:08:01,469 --> 00:08:10,799
papers that were handed over and so I

00:08:04,349 --> 00:08:13,169
started digging through that and also

00:08:10,799 --> 00:08:14,669
joined out yeah there was the existing

00:08:13,169 --> 00:08:15,779
work that this other side stood done so

00:08:14,669 --> 00:08:17,269
I started to pick through that and find

00:08:15,779 --> 00:08:19,679
out what was going on with that so

00:08:17,269 --> 00:08:21,509
there's basically these data archives

00:08:19,679 --> 00:08:23,069
that I found that was full of it was

00:08:21,509 --> 00:08:24,509
just this basically looked like somebody

00:08:23,069 --> 00:08:26,489
got in their hard drive dumped it into

00:08:24,509 --> 00:08:28,259
the archive and left it there so there

00:08:26,489 --> 00:08:31,919
was a lot of intermediate files I could

00:08:28,259 --> 00:08:34,610
just it was just junk a lot of stuff was

00:08:31,919 --> 00:08:36,839
I know it was completely undocumented I

00:08:34,610 --> 00:08:37,769
found a couple of Word documents they

00:08:36,839 --> 00:08:40,439
didn't actually include any

00:08:37,769 --> 00:08:41,819
documentation whatsoever so it's kind of

00:08:40,439 --> 00:08:44,339
like ham what's actually happening here

00:08:41,819 --> 00:08:46,529
I found a couple of data sets but

00:08:44,339 --> 00:08:47,850
they're in this weird addressee raster

00:08:46,529 --> 00:08:49,709
format which I've never heard of before

00:08:47,850 --> 00:08:51,180
and it didn't actually contain any

00:08:49,709 --> 00:08:52,500
metadata so I couldn't actually track

00:08:51,180 --> 00:08:55,889
back on history they need this stuff

00:08:52,500 --> 00:08:57,450
either so this is sort of funny had a

00:08:55,889 --> 00:08:59,190
few more details it turns out

00:08:57,450 --> 00:09:00,720
people this is the previous research

00:08:59,190 --> 00:09:03,180
would use this tool called addressee and

00:09:00,720 --> 00:09:05,970
that was this Windows desktop type thing

00:09:03,180 --> 00:09:09,750
it was some GIS product that have been

00:09:05,970 --> 00:09:12,630
started back in about 1987 I think it

00:09:09,750 --> 00:09:15,210
made its own additional custom raster

00:09:12,630 --> 00:09:17,040
format fortunately the g2 libraries

00:09:15,210 --> 00:09:20,010
handled that so I'm actually able to

00:09:17,040 --> 00:09:22,040
read some of the data and I actually

00:09:20,010 --> 00:09:26,490
sort of found out more about how thee so

00:09:22,040 --> 00:09:28,260
it's someone cool that it turns out that

00:09:26,490 --> 00:09:31,020
the tool can actually brought a bit of

00:09:28,260 --> 00:09:33,690
cut this has this like features from

00:09:31,020 --> 00:09:34,770
Brian this thing called macro code and

00:09:33,690 --> 00:09:35,910
that actually made a bit more sense

00:09:34,770 --> 00:09:37,950
because I found one of these strange

00:09:35,910 --> 00:09:40,260
Word documents contained it was about 20

00:09:37,950 --> 00:09:41,520
pages and it was just lines after lines

00:09:40,260 --> 00:09:44,520
of what looked like some of it matched

00:09:41,520 --> 00:09:47,070
the keyboard it was sort of earful of

00:09:44,520 --> 00:09:51,150
all these asterisks in odd magic numbers

00:09:47,070 --> 00:09:52,560
it was quite obscure and actually we're

00:09:51,150 --> 00:09:54,350
trying to find some public documentation

00:09:52,560 --> 00:09:56,280
on the internet it was none of it

00:09:54,350 --> 00:09:57,600
basically because it's a proprietary

00:09:56,280 --> 00:09:59,160
piece of software no one wanted to

00:09:57,600 --> 00:10:01,410
actually just release that documentation

00:09:59,160 --> 00:10:03,420
so I had to get someone to like probably

00:10:01,410 --> 00:10:04,470
illegally send you some PDF how you do

00:10:03,420 --> 00:10:10,170
so I could understand what this thing

00:10:04,470 --> 00:10:14,700
was it turns out that you've lost a

00:10:10,170 --> 00:10:15,930
slide oh here we go yeah this is

00:10:14,700 --> 00:10:19,590
actually an example of one of the lines

00:10:15,930 --> 00:10:21,120
of code you've got because it is like

00:10:19,590 --> 00:10:23,970
these magic numbers they actually turn

00:10:21,120 --> 00:10:25,590
out to be function arguments so you've

00:10:23,970 --> 00:10:27,900
got things like this one here might

00:10:25,590 --> 00:10:32,130
actually mean subtract if it's a two

00:10:27,900 --> 00:10:34,830
might mean add so you sort of you force

00:10:32,130 --> 00:10:36,690
to use magic numbers as of like a look

00:10:34,830 --> 00:10:38,100
half and so you gotta go in her eyes

00:10:36,690 --> 00:10:40,260
round in this documentation to find out

00:10:38,100 --> 00:10:42,600
what's there so I just figured that's

00:10:40,260 --> 00:10:44,340
just incredibly easy for like a yeah one

00:10:42,600 --> 00:10:45,420
number typo can go I noticed you've done

00:10:44,340 --> 00:10:47,610
the complete officer to what you're

00:10:45,420 --> 00:10:48,720
trying to do I thought was a fairly

00:10:47,610 --> 00:10:51,390
shonky language here because you're

00:10:48,720 --> 00:10:53,520
enforcing risky programming practice and

00:10:51,390 --> 00:10:55,140
bad practice too

00:10:53,520 --> 00:10:57,900
and it turns out these asterisks are

00:10:55,140 --> 00:11:00,000
actually spaces or you probably want

00:10:57,900 --> 00:11:01,770
that actually to be a caller is this you

00:11:00,000 --> 00:11:06,570
really want to use a normal thing that

00:11:01,770 --> 00:11:08,190
you'd separate concepts with so so

00:11:06,570 --> 00:11:09,840
that's a year reminded me of this quote

00:11:08,190 --> 00:11:21,930
that I found summer and

00:11:09,840 --> 00:11:23,040
which is essentially a consistency yes I

00:11:21,930 --> 00:11:25,530
started digging through this word

00:11:23,040 --> 00:11:27,840
document seriously I found like the

00:11:25,530 --> 00:11:30,270
first thing had there are 20 pages of

00:11:27,840 --> 00:11:33,240
this sort of stuff it was just masses of

00:11:30,270 --> 00:11:34,590
repeated code the only thing the only

00:11:33,240 --> 00:11:36,480
real differences was I could to actually

00:11:34,590 --> 00:11:39,540
see a couple of these names sort of

00:11:36,480 --> 00:11:42,710
change to like temp to temp 3 up to sit

00:11:39,540 --> 00:11:44,700
like 1024 something then it would repeat

00:11:42,710 --> 00:11:46,680
so I was thinking of what the hell's

00:11:44,700 --> 00:11:49,890
going on here why don't we just like

00:11:46,680 --> 00:11:51,390
what into you some loops it turns out

00:11:49,890 --> 00:11:54,420
the language didn't actually contain

00:11:51,390 --> 00:11:57,360
loops you were supposed to write to some

00:11:54,420 --> 00:11:58,830
VB or C++ code and then call the macros

00:11:57,360 --> 00:12:00,060
do that so instead of this marking with

00:11:58,830 --> 00:12:03,690
one language you've got to go and learn

00:12:00,060 --> 00:12:04,980
to program in VB or something else and

00:12:03,690 --> 00:12:06,210
your work for it have to be written in

00:12:04,980 --> 00:12:07,860
some other language so you immediately

00:12:06,210 --> 00:12:11,670
it's just putting a deal on this so I

00:12:07,860 --> 00:12:13,350
just that Arnaud code is the 20 page

00:12:11,670 --> 00:12:15,510
sort of this kind of thing here that

00:12:13,350 --> 00:12:19,110
covered essentially the first error

00:12:15,510 --> 00:12:21,180
Corrections staff of the like of this

00:12:19,110 --> 00:12:23,040
process so that was probably about 5% of

00:12:21,180 --> 00:12:24,570
the work and I've had a bunch of weird

00:12:23,040 --> 00:12:27,450
documents I just you didn't want to look

00:12:24,570 --> 00:12:34,020
at her so it's kind of a clear case of

00:12:27,450 --> 00:12:36,390
tools and forcing bad practice yeah if

00:12:34,020 --> 00:12:40,350
you smother ya discover another like

00:12:36,390 --> 00:12:41,670
other fun things the probably that year

00:12:40,350 --> 00:12:43,650
the main thing is basically there's some

00:12:41,670 --> 00:12:45,270
horrible memory management turned out

00:12:43,650 --> 00:12:48,060
every line of code that would write a

00:12:45,270 --> 00:12:50,280
result to a file so that previous error

00:12:48,060 --> 00:12:52,080
set of error Corrections that select 11

00:12:50,280 --> 00:12:56,400
steps that actually wrote 11 output

00:12:52,080 --> 00:12:58,530
files so I don't know how to I'm

00:12:56,400 --> 00:13:00,270
reaching me that wasn't a desktop and it

00:12:58,530 --> 00:13:02,220
turns out I think the researcher because

00:13:00,270 --> 00:13:05,820
she couldn't fit like all these half a

00:13:02,220 --> 00:13:07,440
gigabyte ran wires into RAM once she

00:13:05,820 --> 00:13:09,270
does get to sort of slice Australia off

00:13:07,440 --> 00:13:10,830
and then kind of like run these through

00:13:09,270 --> 00:13:12,690
in segments so she's having to do all

00:13:10,830 --> 00:13:15,930
this manual work and then stitch it all

00:13:12,690 --> 00:13:17,970
back together at the end so sort of up

00:13:15,930 --> 00:13:20,490
to getting this some getting this on my

00:13:17,970 --> 00:13:22,050
brain really hurts just from seeing how

00:13:20,490 --> 00:13:22,529
she did this and I'm also impressed that

00:13:22,050 --> 00:13:25,709
someone was a

00:13:22,529 --> 00:13:28,379
like just do such boring work over and

00:13:25,709 --> 00:13:29,430
over and it's sort of you it's just

00:13:28,379 --> 00:13:30,480
seeing there's this real technical

00:13:29,430 --> 00:13:32,310
barrier there you've got this like

00:13:30,480 --> 00:13:34,769
massive clutch to get around using this

00:13:32,310 --> 00:13:37,709
horrible tool and but that's all the

00:13:34,769 --> 00:13:39,269
scientists had and so I sort of felt

00:13:37,709 --> 00:13:40,620
like she was trying to like shift this

00:13:39,269 --> 00:13:44,490
one ton of do it with a little plastic

00:13:40,620 --> 00:13:46,230
cup it also got worse because you've

00:13:44,490 --> 00:13:49,230
obviously got that new data is coming in

00:13:46,230 --> 00:13:50,939
regularly so it turned out the

00:13:49,230 --> 00:13:52,470
researcher didn't like having to sort of

00:13:50,939 --> 00:13:54,589
like try and do two or three layers at

00:13:52,470 --> 00:13:56,939
once so she ended up ending this sort of

00:13:54,589 --> 00:13:59,850
let like two or three years of the data

00:13:56,939 --> 00:14:01,709
or accumulate sort of then go and like

00:13:59,850 --> 00:14:03,600
mock up some more of this code and then

00:14:01,709 --> 00:14:04,829
actually go forth and like grind through

00:14:03,600 --> 00:14:06,959
and grind through and in sort of

00:14:04,829 --> 00:14:08,129
basically just manually stick these

00:14:06,959 --> 00:14:10,230
other layers on the end of what she'd

00:14:08,129 --> 00:14:11,550
already had and so I've got this

00:14:10,230 --> 00:14:13,800
explanation now for why it took a really

00:14:11,550 --> 00:14:17,129
long time to get this massive turnaround

00:14:13,800 --> 00:14:20,209
of data and it also explains why yeah it

00:14:17,129 --> 00:14:24,720
started it's just really used to produce

00:14:20,209 --> 00:14:26,009
it also gets it even worse the she was

00:14:24,720 --> 00:14:28,170
actually doing research in the meantime

00:14:26,009 --> 00:14:32,370
and it was like just sort of refining

00:14:28,170 --> 00:14:33,689
some of the methods and obviously you

00:14:32,370 --> 00:14:35,040
these can lead to sort of better results

00:14:33,689 --> 00:14:36,720
but you can't just apply the different

00:14:35,040 --> 00:14:38,399
method to your processing halfway

00:14:36,720 --> 00:14:39,870
through because it's a 1/2 of your data

00:14:38,399 --> 00:14:41,220
done with one method in the other half

00:14:39,870 --> 00:14:42,600
would be done with something else and

00:14:41,220 --> 00:14:43,949
that may have actually happened I'm not

00:14:42,600 --> 00:14:46,259
sure

00:14:43,949 --> 00:14:48,300
so it basically meant in 2011 she had to

00:14:46,259 --> 00:14:50,329
go back and redo the entire thing with

00:14:48,300 --> 00:14:52,230
this new method so she's basically just

00:14:50,329 --> 00:14:54,600
duplicated all the way over again

00:14:52,230 --> 00:14:56,850
duplicated probably simply cold you've

00:14:54,600 --> 00:14:58,019
got two versions of data and it's

00:14:56,850 --> 00:15:01,800
probably like two oceans of code

00:14:58,019 --> 00:15:03,120
floating around somewhere you've got

00:15:01,800 --> 00:15:06,929
this other problem you can actually test

00:15:03,120 --> 00:15:08,660
that macro code it's like how many bugs

00:15:06,929 --> 00:15:11,429
are gonna be floating around in that

00:15:08,660 --> 00:15:12,720
then I was actually also realizing if

00:15:11,429 --> 00:15:14,579
you sort of stuff up some of the earlier

00:15:12,720 --> 00:15:16,800
steps the actual those results because

00:15:14,579 --> 00:15:18,209
they're involved in the like calculation

00:15:16,800 --> 00:15:19,379
of derivative layers you're going to end

00:15:18,209 --> 00:15:21,480
up with those sort of like bugs

00:15:19,379 --> 00:15:24,149
promulgating through all the way to your

00:15:21,480 --> 00:15:25,829
end product you've also got all these

00:15:24,149 --> 00:15:27,240
manual steps like constantly probably

00:15:25,829 --> 00:15:28,350
pointing and clicking through things and

00:15:27,240 --> 00:15:30,509
trying to get that workflow down

00:15:28,350 --> 00:15:31,740
manually so there's yeah who knows what

00:15:30,509 --> 00:15:34,319
type it's going to be an introduced fear

00:15:31,740 --> 00:15:37,089
and you can't actually test that either

00:15:34,319 --> 00:15:38,649
and also I had no idea of what actual

00:15:37,089 --> 00:15:39,999
testing methods we used at the end to

00:15:38,649 --> 00:15:41,439
actually sort of validate these data

00:15:39,999 --> 00:15:44,290
products and whether or not they are

00:15:41,439 --> 00:15:45,610
okay and as a sin of sin in other areas

00:15:44,290 --> 00:15:46,869
of science people just sort of looked at

00:15:45,610 --> 00:15:48,790
the data that they gave me and it says

00:15:46,869 --> 00:15:50,470
okay yet that looks all right so we'll

00:15:48,790 --> 00:15:52,059
keep going with it

00:15:50,470 --> 00:15:56,290
so really raised their question how

00:15:52,059 --> 00:15:58,300
confident are we in that data pretty

00:15:56,290 --> 00:15:59,889
much boiled down to it was a total

00:15:58,300 --> 00:16:01,600
write-off I decided I couldn't you there

00:15:59,889 --> 00:16:03,519
was no software I could use and I didn't

00:16:01,600 --> 00:16:06,579
want to trust that data so I basically

00:16:03,519 --> 00:16:09,399
started over it completely from scratch

00:16:06,579 --> 00:16:10,959
so basically given the amount of data I

00:16:09,399 --> 00:16:13,629
thought this is probably more of a C++

00:16:10,959 --> 00:16:15,309
problem I previously used Python for a

00:16:13,629 --> 00:16:17,889
bit of terrain analysis work and the

00:16:15,309 --> 00:16:20,649
particular algorithms using you turned

00:16:17,889 --> 00:16:23,529
out to be quite slow so I just sort of

00:16:20,649 --> 00:16:27,670
started off with GDL use G test for unit

00:16:23,529 --> 00:16:29,319
testing and I pretty much just had two

00:16:27,670 --> 00:16:31,449
sources of report I miss documents that

00:16:29,319 --> 00:16:33,220
was the word document saying here's some

00:16:31,449 --> 00:16:34,839
algorithms and a couple of academic

00:16:33,220 --> 00:16:36,749
papers which perhaps expanded on a few

00:16:34,839 --> 00:16:38,949
of the things in bit more detail but

00:16:36,749 --> 00:16:40,569
this was all sort of missing finer

00:16:38,949 --> 00:16:42,490
details that I didn't sort of understand

00:16:40,569 --> 00:16:44,379
so just to work in this exploratory of

00:16:42,490 --> 00:16:46,329
rapid application development approach

00:16:44,379 --> 00:16:46,990
and kind of like find some details as

00:16:46,329 --> 00:16:50,139
what's going on

00:16:46,990 --> 00:16:52,749
I immediately sort of was encountering

00:16:50,139 --> 00:16:55,059
problems because there's like certain

00:16:52,749 --> 00:16:57,279
uncertainties with this stuff it was

00:16:55,059 --> 00:16:58,809
like having to sort of decide on data so

00:16:57,279 --> 00:17:00,040
I just up front and some of the brief

00:16:58,809 --> 00:17:01,769
people it was working we didn't actually

00:17:00,040 --> 00:17:04,120
know some of the finer details

00:17:01,769 --> 00:17:05,559
so it's also MIT messing with memory

00:17:04,120 --> 00:17:08,919
management in a way all the fun with see

00:17:05,559 --> 00:17:10,600
like templates and also testing involved

00:17:08,919 --> 00:17:11,860
having sort of like compile your tests

00:17:10,600 --> 00:17:14,620
and sort of go through this much slower

00:17:11,860 --> 00:17:15,939
cycle so after implementing like one

00:17:14,620 --> 00:17:17,549
step I kind of decided this is going to

00:17:15,939 --> 00:17:20,289
take a bit too long so I went back to

00:17:17,549 --> 00:17:23,439
reconsidering pipe and we're still so

00:17:20,289 --> 00:17:25,329
good for by easy people like myself I

00:17:23,439 --> 00:17:26,529
actually did a bit of evaluation up

00:17:25,329 --> 00:17:28,600
front and said it was testing some

00:17:26,529 --> 00:17:30,130
numerical pipe in operations and that

00:17:28,600 --> 00:17:31,720
actually gave me some confidence that

00:17:30,130 --> 00:17:33,159
yeah I can actually do this in Python

00:17:31,720 --> 00:17:34,510
with GDL

00:17:33,159 --> 00:17:37,330
and I think yeah I can always write

00:17:34,510 --> 00:17:39,130
rewrite bottlenecks if needed actually

00:17:37,330 --> 00:17:40,270
turns out that yep I think was one of

00:17:39,130 --> 00:17:42,100
these really good languages for

00:17:40,270 --> 00:17:43,600
exploratory development some of the

00:17:42,100 --> 00:17:45,150
problems just vanish through things like

00:17:43,600 --> 00:17:46,380
dynamic typing

00:17:45,150 --> 00:17:47,730
like I said of ignore some of the

00:17:46,380 --> 00:17:51,120
problems and just sort of concentrate on

00:17:47,730 --> 00:17:52,860
getting actual algorithms correct even

00:17:51,120 --> 00:17:54,480
just use the basic unit test module and

00:17:52,860 --> 00:17:56,370
O's test that was like a much faster

00:17:54,480 --> 00:17:57,120
like turnaround of tests and things like

00:17:56,370 --> 00:17:59,400
that

00:17:57,120 --> 00:18:00,810
and just hoping things like the simple

00:17:59,400 --> 00:18:02,160
language and like simplifying another

00:18:00,810 --> 00:18:03,690
thing is going to produce that cognitive

00:18:02,160 --> 00:18:05,820
load so I could actually concentrate

00:18:03,690 --> 00:18:07,410
more on like what is the problem I'm

00:18:05,820 --> 00:18:08,880
trying to solve not what's this stupid

00:18:07,410 --> 00:18:12,360
memory problem was saying fault I'm

00:18:08,880 --> 00:18:14,610
getting with C++ probably actually

00:18:12,360 --> 00:18:17,430
funding unit testing came in quite handy

00:18:14,610 --> 00:18:19,200
tubes that was actually enabled me to

00:18:17,430 --> 00:18:21,060
sort of like find gaps where the

00:18:19,200 --> 00:18:22,800
published models didn't actually address

00:18:21,060 --> 00:18:24,960
all your possible inputs like sort of

00:18:22,800 --> 00:18:26,520
like how do you handle different types

00:18:24,960 --> 00:18:29,150
of no data values if you're trying to do

00:18:26,520 --> 00:18:31,230
a moving window over say like nine

00:18:29,150 --> 00:18:33,930
segments of the time series you've got

00:18:31,230 --> 00:18:35,370
sort of mixed no data in with that so

00:18:33,930 --> 00:18:37,110
really over this done work so to be able

00:18:35,370 --> 00:18:39,480
to use the unit tests to sort of like

00:18:37,110 --> 00:18:41,040
refine these algorithms down and sort of

00:18:39,480 --> 00:18:44,430
like handle load data better and adding

00:18:41,040 --> 00:18:45,870
sort of more filtering and some of these

00:18:44,430 --> 00:18:49,440
things possibly didn't even make it into

00:18:45,870 --> 00:18:51,270
addressee yeah so by the time in 2012

00:18:49,440 --> 00:18:53,460
came around had an extraordinarily rough

00:18:51,270 --> 00:18:55,290
version one going it had a sort of

00:18:53,460 --> 00:18:57,120
fairly rudimentary workflow sitting over

00:18:55,290 --> 00:18:59,250
the top I was actually able to sort of

00:18:57,120 --> 00:19:01,260
process through twelve years of data

00:18:59,250 --> 00:19:03,510
it took about sort of two days at work

00:19:01,260 --> 00:19:06,000
instead of like sitting off like two

00:19:03,510 --> 00:19:07,770
jobs on the supercomputer and I said

00:19:06,000 --> 00:19:09,390
there's a number of just constraints

00:19:07,770 --> 00:19:11,760
that I had from the code and just the

00:19:09,390 --> 00:19:12,330
environment I was working in but in the

00:19:11,760 --> 00:19:13,560
end

00:19:12,330 --> 00:19:15,840
yeah the performance if it actually

00:19:13,560 --> 00:19:17,640
wasn't too bad and it was probably it's

00:19:15,840 --> 00:19:19,740
better than I expected and that was even

00:19:17,640 --> 00:19:22,350
from an profiled code like I didn't

00:19:19,740 --> 00:19:23,190
actually get a chance to go through and

00:19:22,350 --> 00:19:25,710
sort of find if it was really

00:19:23,190 --> 00:19:27,780
inefficient areas and so always him yet

00:19:25,710 --> 00:19:28,590
but just even these feel like a half

00:19:27,780 --> 00:19:31,880
complete product

00:19:28,590 --> 00:19:33,690
reduce the manual load incredibly so and

00:19:31,880 --> 00:19:40,410
obviously there was no way I was going

00:19:33,690 --> 00:19:42,570
to get that far with C++ so here was a

00:19:40,410 --> 00:19:43,980
yeah I decided once that I had some data

00:19:42,570 --> 00:19:46,530
regulations just do a rudimentary

00:19:43,980 --> 00:19:48,330
comparison of the some of the plots and

00:19:46,530 --> 00:19:49,590
I don't know how visible it is here but

00:19:48,330 --> 00:19:51,360
actually you can see the red part here

00:19:49,590 --> 00:19:52,710
is the original data and that's actually

00:19:51,360 --> 00:19:55,840
instead of actually being a smooth

00:19:52,710 --> 00:19:57,620
distribution is some kind of like you

00:19:55,840 --> 00:19:58,549
some of the people at the front could

00:19:57,620 --> 00:19:59,840
probably see it's kind of jagged

00:19:58,549 --> 00:20:01,640
something's obviously gone wrong with

00:19:59,840 --> 00:20:03,230
that and it was it's kind of gave me

00:20:01,640 --> 00:20:03,980
some evidence that there was something

00:20:03,230 --> 00:20:08,419
you'd gone wrong with the original

00:20:03,980 --> 00:20:10,610
production so for a while it's actually

00:20:08,419 --> 00:20:12,140
pulled off on to other projects but it

00:20:10,610 --> 00:20:14,090
wasn't it was basically late last year I

00:20:12,140 --> 00:20:15,740
got back onto it and I actually was able

00:20:14,090 --> 00:20:17,630
to find those bugs in my own code which

00:20:15,740 --> 00:20:19,370
obviously not surprising I was able to

00:20:17,630 --> 00:20:21,559
fix that and a couple of other sort of a

00:20:19,370 --> 00:20:23,120
lot of classification problems actually

00:20:21,559 --> 00:20:26,360
got a chance to refactor the whole thing

00:20:23,120 --> 00:20:29,179
and get rid of the grotty code that

00:20:26,360 --> 00:20:31,070
appeared last time there's probably a

00:20:29,179 --> 00:20:33,080
number of temporal just sort of clearing

00:20:31,070 --> 00:20:35,179
out temporal or handling of temporal

00:20:33,080 --> 00:20:37,159
differences got stuck in as well so I

00:20:35,179 --> 00:20:39,169
was able to like handle things like

00:20:37,159 --> 00:20:40,460
tidal zones where obviously like if

00:20:39,169 --> 00:20:42,559
you've got a satellite flying over

00:20:40,460 --> 00:20:44,690
different times of water away sort of at

00:20:42,559 --> 00:20:45,950
different points and you can that was

00:20:44,690 --> 00:20:49,580
probably just ignored in the previous

00:20:45,950 --> 00:20:51,490
version yes oh and also examining like

00:20:49,580 --> 00:20:53,090
completely rewrite it workflow so

00:20:51,490 --> 00:20:54,470
basically was able to add in

00:20:53,090 --> 00:20:56,990
multi-processing and get some like

00:20:54,470 --> 00:20:58,789
parallel processing happening and it

00:20:56,990 --> 00:21:02,360
also got rid of pretty much all the

00:20:58,789 --> 00:21:04,039
manual tasks unfortunately yeah I tried

00:21:02,360 --> 00:21:08,169
to run this thing before Python but then

00:21:04,039 --> 00:21:10,159
something fell over so rather ironic

00:21:08,169 --> 00:21:12,950
it's sort of you working towards the

00:21:10,159 --> 00:21:14,179
summary I've assumed was like just

00:21:12,950 --> 00:21:15,590
having dealt with the project over this

00:21:14,179 --> 00:21:17,450
sort of period of time could have got a

00:21:15,590 --> 00:21:19,070
bit blase about it but it was sort of

00:21:17,450 --> 00:21:20,480
easy to just go and how do I write a

00:21:19,070 --> 00:21:22,429
talk on this thing it just seems like I

00:21:20,480 --> 00:21:23,899
just saved someone about 20 years of

00:21:22,429 --> 00:21:27,470
their life of stuff remember this

00:21:23,899 --> 00:21:28,940
interesting product but you actually

00:21:27,470 --> 00:21:30,080
sort of have to it's sort of thinking

00:21:28,940 --> 00:21:31,520
about a bit more detail realised

00:21:30,080 --> 00:21:36,799
actually improve some of the scientific

00:21:31,520 --> 00:21:38,179
method and using Python and sort of like

00:21:36,799 --> 00:21:41,360
we're really sort of done making it a

00:21:38,179 --> 00:21:43,370
more rigorous sort of fell rework

00:21:41,360 --> 00:21:45,649
so obviously first of all just by fixing

00:21:43,370 --> 00:21:47,299
out the horrible original workflow it

00:21:45,649 --> 00:21:48,770
removed a number of manual steps and

00:21:47,299 --> 00:21:50,510
sources of errors so actually starting

00:21:48,770 --> 00:21:53,690
to like improve through rigorousness

00:21:50,510 --> 00:21:55,309
they're obviously using like one set of

00:21:53,690 --> 00:21:56,919
tested code to generate the data means

00:21:55,309 --> 00:21:58,880
there was just like one set of

00:21:56,919 --> 00:22:00,919
translations being applied at a time

00:21:58,880 --> 00:22:02,470
rather than students at 20 pages of code

00:22:00,919 --> 00:22:04,549
before where you potentially go to see

00:22:02,470 --> 00:22:05,740
different models for each step being

00:22:04,549 --> 00:22:09,220
accidentally

00:22:05,740 --> 00:22:11,090
apply because someone's done some typos

00:22:09,220 --> 00:22:13,460
obviously the previous work for it

00:22:11,090 --> 00:22:15,920
wasn't documented so that wasn't really

00:22:13,460 --> 00:22:17,510
like an open science thing that work was

00:22:15,920 --> 00:22:18,800
kind of like stuck in the researchers

00:22:17,510 --> 00:22:20,840
head and you couldn't actually sort of

00:22:18,800 --> 00:22:22,340
get it out and give it to someone else

00:22:20,840 --> 00:22:24,650
whereas I can at least give someone of

00:22:22,340 --> 00:22:29,150
this poem Otis code and say there's a

00:22:24,650 --> 00:22:30,230
method we've used this is also we've

00:22:29,150 --> 00:22:33,050
actually just made a number of

00:22:30,230 --> 00:22:35,870
flexibility gains the same DVLA data or

00:22:33,050 --> 00:22:37,490
sporadically changed or updated when I

00:22:35,870 --> 00:22:40,910
think some of the underlying processing

00:22:37,490 --> 00:22:42,290
methods actually get fixed up so in our

00:22:40,910 --> 00:22:43,460
case we just be able to like set off

00:22:42,290 --> 00:22:46,000
some supercomputing jobs

00:22:43,460 --> 00:22:47,990
rerun the thing and regenerate that data

00:22:46,000 --> 00:22:50,360
and we don't have to go through the

00:22:47,990 --> 00:22:52,630
process of managing 40 pages of code

00:22:50,360 --> 00:22:54,850
together and obviously there's other

00:22:52,630 --> 00:22:56,750
CSIRO's with this group called ODS cover

00:22:54,850 --> 00:22:58,910
and they're actually about to and

00:22:56,750 --> 00:23:00,890
changed their underlying data format so

00:22:58,910 --> 00:23:02,210
but we're using GDL so we've got

00:23:00,890 --> 00:23:04,100
essentially a trivial fix because we've

00:23:02,210 --> 00:23:07,880
got we can just handle the data type

00:23:04,100 --> 00:23:10,190
signal Stickley probably sort of just

00:23:07,880 --> 00:23:11,600
showing a few concluding points really

00:23:10,190 --> 00:23:13,310
this project for me was like a real

00:23:11,600 --> 00:23:15,700
eye-opener so like how difficult

00:23:13,310 --> 00:23:18,020
technology is just for some scientists

00:23:15,700 --> 00:23:19,700
it's really like some of them have

00:23:18,020 --> 00:23:21,170
really got such limited options they

00:23:19,700 --> 00:23:23,090
just have to get their work done with

00:23:21,170 --> 00:23:23,480
manual labor or they've got nothing to

00:23:23,090 --> 00:23:25,610
work with

00:23:23,480 --> 00:23:27,790
and this isn't really the first instance

00:23:25,610 --> 00:23:30,980
of this sort of thing I've seen either

00:23:27,790 --> 00:23:32,600
also know that yeah I'm seeing like an

00:23:30,980 --> 00:23:34,880
increasing level of technical challenge

00:23:32,600 --> 00:23:36,320
I mean to the geospatial field as well

00:23:34,880 --> 00:23:41,690
like you're getting larger amounts of

00:23:36,320 --> 00:23:42,650
data you've got sort of things like the

00:23:41,690 --> 00:23:44,510
one second

00:23:42,650 --> 00:23:45,740
DM of Australia is coming up I've

00:23:44,510 --> 00:23:47,990
actually been working on that recently

00:23:45,740 --> 00:23:49,910
and that's like a 70 80 gigabyte single

00:23:47,990 --> 00:23:54,110
layer and this researcher and it had

00:23:49,910 --> 00:23:55,220
about 100 gig to deal with it obviously

00:23:54,110 --> 00:23:56,420
this sort of these sort of scaling

00:23:55,220 --> 00:23:58,190
challenges are putting it out of reach

00:23:56,420 --> 00:24:02,150
or sort of working with sort of data out

00:23:58,190 --> 00:24:03,590
of the reach of many scientists probably

00:24:02,150 --> 00:24:05,630
another general observation things like

00:24:03,590 --> 00:24:07,790
automated or unit testing it's really

00:24:05,630 --> 00:24:10,790
not a tool that's understood or used by

00:24:07,790 --> 00:24:12,260
scientists I guess I mentioned earlier

00:24:10,790 --> 00:24:14,150
to listen to like look at data and say

00:24:12,260 --> 00:24:15,770
okay is that yeah that seems to be

00:24:14,150 --> 00:24:18,440
possible or encountered instances of

00:24:15,770 --> 00:24:21,590
that I don't really consider that I say

00:24:18,440 --> 00:24:23,360
testing approach so and it's not really

00:24:21,590 --> 00:24:24,680
suited if you've got a complex work or

00:24:23,360 --> 00:24:27,050
perhaps like subtle things you're trying

00:24:24,680 --> 00:24:28,490
to investigate I know what also wonder

00:24:27,050 --> 00:24:30,020
if some side isn't even got those

00:24:28,490 --> 00:24:31,280
technical skills who look at gigabytes

00:24:30,020 --> 00:24:36,710
of data anyway and actually try and

00:24:31,280 --> 00:24:38,150
verify that one will say sort of finding

00:24:36,710 --> 00:24:39,980
that year by introducing the testing I

00:24:38,150 --> 00:24:42,530
was actually able to like you very like

00:24:39,980 --> 00:24:44,300
a much greater sort of confidence in

00:24:42,530 --> 00:24:46,700
that those results are actually matching

00:24:44,300 --> 00:24:47,660
the models that I was given I'd still

00:24:46,700 --> 00:24:49,850
like to actually go ahead and take

00:24:47,660 --> 00:24:51,620
another step which is like some of this

00:24:49,850 --> 00:24:54,890
data up against other independent

00:24:51,620 --> 00:24:56,900
datasets obviously yeah I'd say there's

00:24:54,890 --> 00:24:58,520
a massive need for sort of professional

00:24:56,900 --> 00:25:00,560
software development in a sort of like

00:24:58,520 --> 00:25:02,120
in various scientific fields there's all

00:25:00,560 --> 00:25:03,650
be public like a lot of scope even

00:25:02,120 --> 00:25:07,040
actually the size of the data and

00:25:03,650 --> 00:25:08,480
technical challenges out there obviously

00:25:07,040 --> 00:25:09,950
having developers what helps to free

00:25:08,480 --> 00:25:12,320
researchers are from having to do a lot

00:25:09,950 --> 00:25:14,300
of this sort of technical stuff and then

00:25:12,320 --> 00:25:17,150
you actually sort of more using funding

00:25:14,300 --> 00:25:18,410
more efficiently to so instead of having

00:25:17,150 --> 00:25:19,970
someone like mucking around with twenty

00:25:18,410 --> 00:25:21,350
pages or their ad receipt oh they can

00:25:19,970 --> 00:25:22,910
just go and concentrate on the methods

00:25:21,350 --> 00:25:27,080
and someone else can spend a lot less

00:25:22,910 --> 00:25:28,310
time writing it in Python otherwise yeah

00:25:27,080 --> 00:25:29,690
I think something like this software

00:25:28,310 --> 00:25:31,040
carpentry movement that's probably a

00:25:29,690 --> 00:25:33,080
good step in the right direction to try

00:25:31,040 --> 00:25:36,680
like you people basic skills to avoid

00:25:33,080 --> 00:25:38,210
doing silly things and it's like see

00:25:36,680 --> 00:25:39,500
this is important with geospatial data

00:25:38,210 --> 00:25:40,070
it's actually sort of used in the real

00:25:39,500 --> 00:25:42,760
world

00:25:40,070 --> 00:25:45,350
and you also could you used to say like

00:25:42,760 --> 00:25:47,210
influence policy decisions that like say

00:25:45,350 --> 00:25:48,350
like federal and state levels so that

00:25:47,210 --> 00:25:50,170
you kind of what there's an incentive

00:25:48,350 --> 00:25:53,270
actually to make sure that that's right

00:25:50,170 --> 00:25:54,920
and I'd sort of yeah based on this I

00:25:53,270 --> 00:25:56,390
would say I personally found Pythian was

00:25:54,920 --> 00:25:59,750
like a really useful general platform

00:25:56,390 --> 00:26:01,190
for actually just getting some of this

00:25:59,750 --> 00:26:03,560
work done it's actually far better than

00:26:01,190 --> 00:26:05,090
other tools and it's obviously like just

00:26:03,560 --> 00:26:06,650
this is probably the first major project

00:26:05,090 --> 00:26:08,210
that was using parts and on and it was

00:26:06,650 --> 00:26:10,730
actually changed my opinion of what it

00:26:08,210 --> 00:26:12,290
was capable of yeah so much that I'm

00:26:10,730 --> 00:26:15,260
actually using it for a project with GA

00:26:12,290 --> 00:26:22,270
which hopefully be the subject of a talk

00:26:15,260 --> 00:26:22,270
next hi corn Q&A time

00:26:27,350 --> 00:26:29,410

YouTube URL: https://www.youtube.com/watch?v=OKzJOpbfjGk


