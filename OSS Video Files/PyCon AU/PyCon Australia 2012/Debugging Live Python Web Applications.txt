Title: Debugging Live Python Web Applications
Publication date: 2012-08-23
Playlist: PyCon Australia 2012
Description: 
	Graham Dumpleton
Monitoring tools will record the result of what happened to your web application or system when a problem arises, but for some classes of problem are of limited help in working out what happened, except through inference or by way of
Captions: 
	00:00:00,000 --> 00:00:06,420
presenter is the author of mod wsgi

00:00:03,650 --> 00:00:08,040
which is instrumental in developers

00:00:06,420 --> 00:00:10,650
being able to deploy Python to the

00:00:08,040 --> 00:00:12,690
Apache web server he's also a member of

00:00:10,650 --> 00:00:15,269
both the apache software foundation and

00:00:12,690 --> 00:00:19,140
the hyphen software foundation so he

00:00:15,269 --> 00:00:21,420
keeps very busy and he's regular day job

00:00:19,140 --> 00:00:23,220
is with as a developer with New Relic so

00:00:21,420 --> 00:00:27,019
if you could all please give a warm

00:00:23,220 --> 00:00:27,019
welcome to Graham dumpin

00:00:30,279 --> 00:00:36,020
thank you this talks actually being

00:00:33,440 --> 00:00:37,399
prepared I'm giving presentation now but

00:00:36,020 --> 00:00:38,960
it's actually we got some assistance

00:00:37,399 --> 00:00:40,790
repairing it from a guy called bomb

00:00:38,960 --> 00:00:42,800
Jeffers is working with me at New Relic

00:00:40,790 --> 00:00:44,809
he started recently she's actually going

00:00:42,800 --> 00:00:49,129
to give this talk at django con in the

00:00:44,809 --> 00:00:51,800
US as well in a few weeks now if you did

00:00:49,129 --> 00:00:55,879
want to follow a longer the word on the

00:00:51,800 --> 00:00:57,379
side yard to SlideShare but because of

00:00:55,879 --> 00:01:00,500
the network issue it stopped about there

00:00:57,379 --> 00:01:02,720
when I tried so don't go 35-cent I will

00:01:00,500 --> 00:01:04,159
try again to upload it later so you can

00:01:02,720 --> 00:01:08,570
look at the actual charts a bit more

00:01:04,159 --> 00:01:10,460
detail so you've written what you

00:01:08,570 --> 00:01:11,720
believe is the most amazing website in

00:01:10,460 --> 00:01:13,939
the world and you deployed it to

00:01:11,720 --> 00:01:15,830
production real customers are using it

00:01:13,939 --> 00:01:17,780
it's making you money for you but

00:01:15,830 --> 00:01:19,760
something is going wrong with it you

00:01:17,780 --> 00:01:21,920
don't quite know what and because it is

00:01:19,760 --> 00:01:23,840
something because it is a real live

00:01:21,920 --> 00:01:25,280
production website you can't necessarily

00:01:23,840 --> 00:01:26,780
go in and just start playing with it

00:01:25,280 --> 00:01:30,140
what are you going to do how you're

00:01:26,780 --> 00:01:31,430
going to debug the problems for some

00:01:30,140 --> 00:01:33,170
types of problems where you get a nice

00:01:31,430 --> 00:01:35,179
partial exception trace back the cause

00:01:33,170 --> 00:01:36,649
may be obvious but caught the cause of

00:01:35,179 --> 00:01:38,719
other things such as data corruption

00:01:36,649 --> 00:01:40,820
memory leaks Fred locking and issues

00:01:38,719 --> 00:01:42,649
issues and general performance problems

00:01:40,820 --> 00:01:44,509
be more elusive trying to duplicate

00:01:42,649 --> 00:01:46,789
issues in a development system can

00:01:44,509 --> 00:01:48,200
sometimes work but more often not your

00:01:46,789 --> 00:01:50,060
things that problems are only going to

00:01:48,200 --> 00:01:54,140
show up once you deploy your code to

00:01:50,060 --> 00:01:55,520
production as developers we would love

00:01:54,140 --> 00:01:57,229
to be able to just dive in and start

00:01:55,520 --> 00:01:59,389
poking around the live web application

00:01:57,229 --> 00:02:01,100
but operations stuff aren't going to

00:01:59,389 --> 00:02:02,569
like that one bit they get very nervous

00:02:01,100 --> 00:02:05,179
when you say I want to do this or that

00:02:02,569 --> 00:02:06,679
if we're going to try and do things with

00:02:05,179 --> 00:02:08,119
a live web application it has to be

00:02:06,679 --> 00:02:10,610
things that aren't going to make things

00:02:08,119 --> 00:02:12,530
worse the results of the things we do

00:02:10,610 --> 00:02:14,660
need to be predictable with the effect

00:02:12,530 --> 00:02:16,670
of doing them able to be validated in

00:02:14,660 --> 00:02:20,690
advance so you can test out what you're

00:02:16,670 --> 00:02:22,640
going to do whatever we do it's all

00:02:20,690 --> 00:02:24,170
about managing risk we don't want to

00:02:22,640 --> 00:02:26,480
loose cannon there's going to cause more

00:02:24,170 --> 00:02:28,310
damage than good there is no reason no

00:02:26,480 --> 00:02:30,410
why we can't do things which do have

00:02:28,310 --> 00:02:32,209
some level of risk we just need to be

00:02:30,410 --> 00:02:34,640
controlled in what we do and make sure

00:02:32,209 --> 00:02:36,350
we understand the consequences if making

00:02:34,640 --> 00:02:38,900
changes script the actions you're going

00:02:36,350 --> 00:02:40,760
to take test them beforehand and develop

00:02:38,900 --> 00:02:41,990
contingency plans to cope with when

00:02:40,760 --> 00:02:46,220
things do go pee

00:02:41,990 --> 00:02:48,200
it the most benign thing you can do is

00:02:46,220 --> 00:02:49,850
passive monitoring that is where you set

00:02:48,200 --> 00:02:52,340
up in advance mechanisms to collect data

00:02:49,850 --> 00:02:53,690
on a continual basis in the event of a

00:02:52,340 --> 00:02:55,520
problem you at least and have some

00:02:53,690 --> 00:02:57,950
forensic information to try and analyze

00:02:55,520 --> 00:02:59,990
what went wrong monitoring can take many

00:02:57,950 --> 00:03:02,120
forms this can include collecting log

00:02:59,990 --> 00:03:06,440
files details of application exceptions

00:03:02,120 --> 00:03:08,300
or quite specific performance data in

00:03:06,440 --> 00:03:10,010
the case of log files they can come from

00:03:08,300 --> 00:03:11,630
many sources including the operating

00:03:10,010 --> 00:03:13,700
system your web server your web

00:03:11,630 --> 00:03:15,800
application back-end application

00:03:13,700 --> 00:03:18,020
services and databases these can be

00:03:15,800 --> 00:03:19,490
spread all over the place to make sense

00:03:18,020 --> 00:03:21,410
of and make it easier to find and

00:03:19,490 --> 00:03:23,450
correlate information various free and

00:03:21,410 --> 00:03:25,250
commercial products exist to help these

00:03:23,450 --> 00:03:29,270
tools and simple terms are search

00:03:25,250 --> 00:03:30,860
engines for log information log file

00:03:29,270 --> 00:03:33,020
analysis can only work though if the

00:03:30,860 --> 00:03:35,240
application actually log something about

00:03:33,020 --> 00:03:36,860
an event if a web application in web

00:03:35,240 --> 00:03:39,560
applications in particular exceptions

00:03:36,860 --> 00:03:42,710
often translated to a generic HTTP 500

00:03:39,560 --> 00:03:44,960
error and no details are locked in this

00:03:42,710 --> 00:03:46,580
situation extra step step needs to be

00:03:44,960 --> 00:03:49,160
taken to configure the framework to

00:03:46,580 --> 00:03:51,170
record details of exceptions or to add

00:03:49,160 --> 00:03:52,700
in additional tools which can intercept

00:03:51,170 --> 00:03:56,080
exceptions and report them back to a

00:03:52,700 --> 00:03:58,250
service of storage and later analysis

00:03:56,080 --> 00:03:59,840
when we move up to server monitoring

00:03:58,250 --> 00:04:01,640
there a range of open source choices

00:03:59,840 --> 00:04:03,170
what these monitor can be quite

00:04:01,640 --> 00:04:04,940
extensive but they can also be quite

00:04:03,170 --> 00:04:06,800
hard to set up and manage depending on

00:04:04,940 --> 00:04:08,570
the product for many users the

00:04:06,800 --> 00:04:10,580
simplicity that pre-configured solution

00:04:08,570 --> 00:04:11,960
can be just as beneficial if not easier

00:04:10,580 --> 00:04:14,630
to deal with in a highly configurable

00:04:11,960 --> 00:04:17,090
and highly complex solution so your

00:04:14,630 --> 00:04:18,770
mileage may vary depending on the

00:04:17,090 --> 00:04:21,820
product you choose so shop around and

00:04:18,770 --> 00:04:24,440
see which which one works best for you

00:04:21,820 --> 00:04:25,820
once a dive deeper into what is going

00:04:24,440 --> 00:04:27,350
inside of your path from web vocation

00:04:25,820 --> 00:04:28,670
and that's where I was obviously going

00:04:27,350 --> 00:04:31,370
to say that New Relic is your friend ins

00:04:28,670 --> 00:04:33,200
friend in addition to providing server

00:04:31,370 --> 00:04:35,210
monitoring New Relic provides real user

00:04:33,200 --> 00:04:37,310
monitoring and application performance

00:04:35,210 --> 00:04:38,900
monitoring for your web application that

00:04:37,310 --> 00:04:41,060
gives a deeper level of introspection

00:04:38,900 --> 00:04:42,890
into where time is being spent within

00:04:41,060 --> 00:04:44,510
your application code as well as

00:04:42,890 --> 00:04:49,310
including time spent calling out to

00:04:44,510 --> 00:04:50,720
external databases and web servers so

00:04:49,310 --> 00:04:52,460
you can easily bring together a set of

00:04:50,720 --> 00:04:54,500
monitoring tool the question and is what

00:04:52,460 --> 00:04:54,750
value are they in debugging an issue as

00:04:54,500 --> 00:04:56,520
a

00:04:54,750 --> 00:04:58,860
to telling you that there is a problem

00:04:56,520 --> 00:05:00,270
in the first place the big-ticket item

00:04:58,860 --> 00:05:02,040
with websites as performance a

00:05:00,270 --> 00:05:04,170
high-level view which looks across

00:05:02,040 --> 00:05:05,610
end-user time application time and that

00:05:04,170 --> 00:05:07,080
of back-end services allows you to

00:05:05,610 --> 00:05:10,770
quickly drill down to where the problem

00:05:07,080 --> 00:05:12,330
may lie and user monitoring can help you

00:05:10,770 --> 00:05:14,010
realize that the actual issues with the

00:05:12,330 --> 00:05:15,690
page content you're generating rather

00:05:14,010 --> 00:05:18,120
than the mechanisms of generating it

00:05:15,690 --> 00:05:20,730
from there you can use various web page

00:05:18,120 --> 00:05:22,620
performance and analysis tools but keep

00:05:20,730 --> 00:05:23,940
in mind though that these operate not

00:05:22,620 --> 00:05:26,370
from the perspective of you actually

00:05:23,940 --> 00:05:29,100
uses but where the onload service is

00:05:26,370 --> 00:05:33,690
located or if using a browser based one

00:05:29,100 --> 00:05:35,190
where you're where you are located in

00:05:33,690 --> 00:05:37,260
the future advances like the browser

00:05:35,190 --> 00:05:38,700
resource timing specification coming out

00:05:37,260 --> 00:05:40,950
of the World Wide Web Consortium could

00:05:38,700 --> 00:05:42,480
make such analysis rep analysis more

00:05:40,950 --> 00:05:44,520
representative what real users are

00:05:42,480 --> 00:05:45,960
seeing as it then would be technically

00:05:44,520 --> 00:05:47,880
possible to report such information

00:05:45,960 --> 00:05:49,710
direct from user browsers giving you a

00:05:47,880 --> 00:05:51,210
much larger data set to work with

00:05:49,710 --> 00:05:54,620
because you actually you are literally

00:05:51,210 --> 00:05:56,760
pulling it out of the users browsers

00:05:54,620 --> 00:05:58,590
what now for where the problem is in

00:05:56,760 --> 00:05:59,970
your application if using your Elliott

00:05:58,590 --> 00:06:01,290
you can start to drill down and look at

00:05:59,970 --> 00:06:03,060
performance of individual request

00:06:01,290 --> 00:06:05,010
handlers seeing therefore report and

00:06:03,060 --> 00:06:07,290
response times you can also get a more

00:06:05,010 --> 00:06:11,130
detailed view of individual sample slow

00:06:07,290 --> 00:06:12,780
transactions the performance breakdown

00:06:11,130 --> 00:06:14,190
in a slow transaction summary gives you

00:06:12,780 --> 00:06:15,750
a high level overview of where time is

00:06:14,190 --> 00:06:17,850
being spent for that specific slow

00:06:15,750 --> 00:06:19,979
transaction the summary that doesn't

00:06:17,850 --> 00:06:21,810
necessarily provide you of any context

00:06:19,979 --> 00:06:25,800
of where in your code time consuming

00:06:21,810 --> 00:06:27,240
operation was made some level of context

00:06:25,800 --> 00:06:29,280
can be obtained by drilling down and

00:06:27,240 --> 00:06:30,750
looking at the details of so transaction

00:06:29,280 --> 00:06:32,400
traces but it is limited to those

00:06:30,750 --> 00:06:35,610
functions which have been deemed of

00:06:32,400 --> 00:06:37,140
interest by us in producing the agent it

00:06:35,610 --> 00:06:38,760
needs to be limited in this way to

00:06:37,140 --> 00:06:40,229
ensure that the overhead of monitoring

00:06:38,760 --> 00:06:42,419
does not impact the performance of your

00:06:40,229 --> 00:06:44,280
application if we were to do full

00:06:42,419 --> 00:06:45,750
profiling it's just going to be too much

00:06:44,280 --> 00:06:47,100
of an overhead and it's going to kill

00:06:45,750 --> 00:06:50,760
your whole web application and that's

00:06:47,100 --> 00:06:52,290
why we need to be selective so because

00:06:50,760 --> 00:06:54,690
instrumentation is targeted only two

00:06:52,290 --> 00:06:56,340
areas such as time spent in middleware

00:06:54,690 --> 00:06:58,020
view handlers template rendering and

00:06:56,340 --> 00:06:59,940
temporal oxen in Django for example

00:06:58,020 --> 00:07:01,140
eventually you get situation where you

00:06:59,940 --> 00:07:03,090
get blocks of time where you lack

00:07:01,140 --> 00:07:04,890
sufficient detail this is where

00:07:03,090 --> 00:07:07,560
monitoring tools can need a bit more

00:07:04,890 --> 00:07:08,160
help for you indicating what else is of

00:07:07,560 --> 00:07:11,430
interest in you

00:07:08,160 --> 00:07:13,350
specific application you have a few

00:07:11,430 --> 00:07:15,570
choices how you can do this in your le

00:07:13,350 --> 00:07:17,430
the first is to make changes to your

00:07:15,570 --> 00:07:19,080
actual code base so you can apply

00:07:17,430 --> 00:07:20,700
function decorators to existing

00:07:19,080 --> 00:07:22,560
functions where you can use context

00:07:20,700 --> 00:07:25,110
manager objects to time within blocks of

00:07:22,560 --> 00:07:27,000
code within a function such changes are

00:07:25,110 --> 00:07:29,700
obviously intrusive though which could

00:07:27,000 --> 00:07:32,880
be an issue plus it also doesn't help

00:07:29,700 --> 00:07:34,710
when you want it times spent time how

00:07:32,880 --> 00:07:37,850
long it takes in third-party code which

00:07:34,710 --> 00:07:40,170
you can't easily go in and modify a

00:07:37,850 --> 00:07:41,250
second approach is to nominate functions

00:07:40,170 --> 00:07:43,680
of interest by way of a configuration

00:07:41,250 --> 00:07:45,510
file this avoids you needing to change

00:07:43,680 --> 00:07:49,230
codes then can we use with that

00:07:45,510 --> 00:07:51,060
third-party code but the array ascent

00:07:49,230 --> 00:07:54,510
very simplistically usually Ainge's two

00:07:51,060 --> 00:07:56,610
very simple function tracing a final

00:07:54,510 --> 00:07:58,140
option is monkey patching here you can

00:07:56,610 --> 00:08:00,150
specify a function to be called when a

00:07:58,140 --> 00:08:01,500
specific module is imported that

00:08:00,150 --> 00:08:03,720
function would then go in and monkey

00:08:01,500 --> 00:08:05,400
patch the code and this gives you a lot

00:08:03,720 --> 00:08:07,350
more flexibility of what then you can

00:08:05,400 --> 00:08:08,850
actually do whichever of these

00:08:07,350 --> 00:08:10,470
approaches have taken the problem here

00:08:08,850 --> 00:08:12,480
is that to get the added visibility you

00:08:10,470 --> 00:08:14,490
need to make a change of some sort to

00:08:12,480 --> 00:08:16,290
your code and redeploy it and restart

00:08:14,490 --> 00:08:18,450
your application before you'll see the

00:08:16,290 --> 00:08:20,010
additional instrumented functions so the

00:08:18,450 --> 00:08:22,020
problem is it does not provide you the

00:08:20,010 --> 00:08:23,760
here-and-now way of doling down into a

00:08:22,020 --> 00:08:26,580
problem at the time that is occurring

00:08:23,760 --> 00:08:28,740
because you may go and change your code

00:08:26,580 --> 00:08:30,660
restart it to captions information and

00:08:28,740 --> 00:08:32,729
then it's no longer occurring as a

00:08:30,660 --> 00:08:33,990
problem because it's being dependent on

00:08:32,729 --> 00:08:37,469
the history that has occurred up to that

00:08:33,990 --> 00:08:39,210
point in your application a partial

00:08:37,469 --> 00:08:41,729
solution is what they call Fred sampling

00:08:39,210 --> 00:08:44,219
and this is where you would go in and

00:08:41,729 --> 00:08:47,010
start up a profiling session that takes

00:08:44,219 --> 00:08:48,750
a periodic snapshot of where what each

00:08:47,010 --> 00:08:51,720
fred is doing at a specific point in

00:08:48,750 --> 00:08:53,610
time and from that producer call tree

00:08:51,720 --> 00:08:56,000
showing what percentage of time code at

00:08:53,610 --> 00:08:57,870
a specific point was executing

00:08:56,000 --> 00:08:59,220
unfortunately right now New Relic at

00:08:57,870 --> 00:09:00,720
least don't we don't do that for Python

00:08:59,220 --> 00:09:03,960
although it is something we've been

00:09:00,720 --> 00:09:05,820
looking at but there are separate Fred

00:09:03,960 --> 00:09:07,950
sampling tools that do exist Dropbox

00:09:05,820 --> 00:09:09,630
recently announced plop along with a

00:09:07,950 --> 00:09:11,520
pretty visualization tool to try and

00:09:09,630 --> 00:09:13,530
throw start making sense of that data

00:09:11,520 --> 00:09:15,660
you're getting another is stat prof

00:09:13,530 --> 00:09:17,610
which advertises itself as being able to

00:09:15,660 --> 00:09:19,650
trace down to line level which I believe

00:09:17,610 --> 00:09:21,000
to plot pops early perhaps get into the

00:09:19,650 --> 00:09:22,320
function level

00:09:21,000 --> 00:09:25,260
you know the premise behind these

00:09:22,320 --> 00:09:27,150
sampling approaches is that the overhead

00:09:25,260 --> 00:09:29,340
is lower than traditional full profile

00:09:27,150 --> 00:09:32,040
such as provided by the PI from profile

00:09:29,340 --> 00:09:34,170
modules so whereas for i'm pricin

00:09:32,040 --> 00:09:35,940
profiling can't be used in production

00:09:34,170 --> 00:09:40,680
application then something like Fred

00:09:35,940 --> 00:09:42,030
sampling could ultimately Fred sampling

00:09:40,680 --> 00:09:44,310
is still an estimate though it's not as

00:09:42,030 --> 00:09:46,080
accurate as full profile in a middle

00:09:44,310 --> 00:09:48,390
ground though is not to run profiling

00:09:46,080 --> 00:09:51,120
all the time but collect samples there

00:09:48,390 --> 00:09:52,980
as well so that is don't profile the

00:09:51,120 --> 00:09:55,440
whole program which is what people

00:09:52,980 --> 00:09:56,970
traditionally do target specific

00:09:55,440 --> 00:09:59,240
functions and only collect a full

00:09:56,970 --> 00:10:01,740
profile sample for a call every so often

00:09:59,240 --> 00:10:03,540
we could for instance have the criteria

00:10:01,740 --> 00:10:05,700
be that we collect samples at minimum of

00:10:03,540 --> 00:10:08,460
one second apart and write out the

00:10:05,700 --> 00:10:12,030
aggregated results after 30 successive

00:10:08,460 --> 00:10:14,580
calls and that way we're imposing a much

00:10:12,030 --> 00:10:15,840
lower overhead on the on the on your

00:10:14,580 --> 00:10:17,280
production web application because

00:10:15,840 --> 00:10:18,390
you're just not doing it very often but

00:10:17,280 --> 00:10:21,210
it still gives you a representative

00:10:18,390 --> 00:10:23,930
sample of better than a Fred sampling of

00:10:21,210 --> 00:10:26,190
what's going on what you need to look at

00:10:23,930 --> 00:10:28,050
so this can be achieved using the C

00:10:26,190 --> 00:10:30,810
profile module a decorator and a bit of

00:10:28,050 --> 00:10:32,640
context manager magic we just need to

00:10:30,810 --> 00:10:34,230
add in a gating mechanism to control how

00:10:32,640 --> 00:10:35,580
often it is done and we can achieve that

00:10:34,230 --> 00:10:40,050
full profile and for a function of

00:10:35,580 --> 00:10:41,820
interest and because I said it's because

00:10:40,050 --> 00:10:43,230
it's done in frankly enough then the

00:10:41,820 --> 00:10:45,120
overhead imposed on that on production

00:10:43,230 --> 00:10:48,050
web app is not going to be as bad as for

00:10:45,120 --> 00:10:50,280
full profile of the whole application

00:10:48,050 --> 00:10:51,900
now New Relic is by no means the only

00:10:50,280 --> 00:10:53,910
way of instrumenting web applications to

00:10:51,900 --> 00:10:55,710
collect metrics although it is arguably

00:10:53,910 --> 00:10:57,450
gives you a lot of value out of the box

00:10:55,710 --> 00:10:59,970
with immediately actual data because we

00:10:57,450 --> 00:11:01,620
go in there and targets a Django as a

00:10:59,970 --> 00:11:04,770
framework and we go in at all this extra

00:11:01,620 --> 00:11:06,150
stuff in but whatever the solution it is

00:11:04,770 --> 00:11:07,260
whether you use some of the other ones

00:11:06,150 --> 00:11:08,070
I've listed here which again you're

00:11:07,260 --> 00:11:10,320
gonna have to do everything yourself

00:11:08,070 --> 00:11:12,750
manually to actually collect all the

00:11:10,320 --> 00:11:14,400
data you still need to manually modify

00:11:12,750 --> 00:11:16,220
your code to add that an extra

00:11:14,400 --> 00:11:18,270
instrumentation you want to further

00:11:16,220 --> 00:11:20,010
explore a problem when you've got an

00:11:18,270 --> 00:11:21,180
issue here occurring in production so

00:11:20,010 --> 00:11:23,670
you still need to go and redeploy your

00:11:21,180 --> 00:11:25,800
web app so getting more in depth useful

00:11:23,670 --> 00:11:26,940
data can therefore be a long process and

00:11:25,800 --> 00:11:30,450
this is the problem we've got to solve

00:11:26,940 --> 00:11:32,339
you sort of monitoring can go so far but

00:11:30,450 --> 00:11:33,760
to get that more out of the monitoring

00:11:32,339 --> 00:11:37,720
at that point in time it's

00:11:33,760 --> 00:11:39,760
what do we do so what is it lacking is

00:11:37,720 --> 00:11:41,020
ability to prod you live web application

00:11:39,760 --> 00:11:42,400
to get it to start yielding that

00:11:41,020 --> 00:11:44,440
additional data while the problem is

00:11:42,400 --> 00:11:46,450
occurring some tools give you this

00:11:44,440 --> 00:11:48,460
interactivity but they're only suitable

00:11:46,450 --> 00:11:49,930
for development environments as they

00:11:48,460 --> 00:11:52,630
display the data back in the brows of

00:11:49,930 --> 00:11:54,730
the request is made from century putos

00:11:52,630 --> 00:11:56,620
provides separate analysis of trace

00:11:54,730 --> 00:11:58,090
backs and state variables after the fact

00:11:56,620 --> 00:11:59,590
but we still don't have a way of

00:11:58,090 --> 00:12:04,990
changing the way the application is

00:11:59,590 --> 00:12:07,120
running application back doors to affect

00:12:04,990 --> 00:12:09,030
change and not new the logging module in

00:12:07,120 --> 00:12:10,960
Python even supply such a backdoor

00:12:09,030 --> 00:12:13,020
enable this and it will listen on a

00:12:10,960 --> 00:12:15,700
socket for connections and allow to pass

00:12:13,020 --> 00:12:17,920
the application and new configuration

00:12:15,700 --> 00:12:19,840
for the logging subsystem changes

00:12:17,920 --> 00:12:22,570
dangerous do exist with such mechanism

00:12:19,840 --> 00:12:24,580
so the logging module actually runs eval

00:12:22,570 --> 00:12:27,100
on parts of the configuration file

00:12:24,580 --> 00:12:29,290
meaning that you can actually inject

00:12:27,100 --> 00:12:32,050
arbitrary code into your application and

00:12:29,290 --> 00:12:33,700
I actually only found this out a couple

00:12:32,050 --> 00:12:36,010
of weeks ago when I was digging around

00:12:33,700 --> 00:12:39,400
the logging module sending emails of the

00:12:36,010 --> 00:12:42,040
Python security list okay they didn't

00:12:39,400 --> 00:12:44,830
feel as that bad of an issue so

00:12:42,040 --> 00:12:45,910
essentially got a bug put on the bug

00:12:44,830 --> 00:12:47,800
tracker and they've got to change the

00:12:45,910 --> 00:12:49,090
daka to warn you about at least but it

00:12:47,800 --> 00:12:53,860
was a bit scary and I saw that one the

00:12:49,090 --> 00:12:55,450
first time a bit unexpected but if you

00:12:53,860 --> 00:12:57,550
are concerned about arbitrary execution

00:12:55,450 --> 00:12:59,680
of of code well you could actually

00:12:57,550 --> 00:13:01,630
instead elect to expose a full embedded

00:12:59,680 --> 00:13:03,850
Python interpreter prompt and and

00:13:01,630 --> 00:13:05,740
various things like a vent 'let heat pie

00:13:03,850 --> 00:13:07,990
and twisted manhole do have that ability

00:13:05,740 --> 00:13:09,670
you can go a step further again you can

00:13:07,990 --> 00:13:12,160
have the rather scary contact a parasite

00:13:09,670 --> 00:13:14,980
which uses gdb to perform code injection

00:13:12,160 --> 00:13:18,190
into an arbitrary unmodified Python

00:13:14,980 --> 00:13:20,950
process I really as long as you don't

00:13:18,190 --> 00:13:24,010
have it fully stripped optimized I've

00:13:20,950 --> 00:13:25,150
pretty sure all works but we want

00:13:24,010 --> 00:13:28,150
something that allows real-time

00:13:25,150 --> 00:13:29,800
interaction but also want that access to

00:13:28,150 --> 00:13:34,090
be more controlled than a full-on

00:13:29,800 --> 00:13:35,560
interpreter or debugger so providing

00:13:34,090 --> 00:13:37,120
this means for interactive access to a

00:13:35,560 --> 00:13:39,730
running process is something I've toyed

00:13:37,120 --> 00:13:42,120
with for many years and then trying to

00:13:39,730 --> 00:13:45,100
help people debug mod wsgi particularly

00:13:42,120 --> 00:13:46,100
so following on from Pike on the US this

00:13:45,100 --> 00:13:48,829
year

00:13:46,100 --> 00:13:51,019
Adam Lowry gave a talk on Finkel soccer

00:13:48,829 --> 00:13:54,529
console where he again talked about back

00:13:51,019 --> 00:13:55,880
doors and using it to get stack traces

00:13:54,529 --> 00:13:58,130
out for the different PI from France I

00:13:55,880 --> 00:13:59,990
finally go sit down and actually create

00:13:58,130 --> 00:14:01,370
something which is bundles up all the

00:13:59,990 --> 00:14:03,560
ideas I've been playing with over the

00:14:01,370 --> 00:14:07,190
years so I create this package called I

00:14:03,560 --> 00:14:09,170
spied I was originally intended just

00:14:07,190 --> 00:14:10,759
looking at it with whiskey applications

00:14:09,170 --> 00:14:12,350
but it sort of turns into a thing which

00:14:10,759 --> 00:14:15,139
suitable for other applications of all

00:14:12,350 --> 00:14:16,880
so that's why says wsj shell on on

00:14:15,139 --> 00:14:19,850
github but it's actually called a spot

00:14:16,880 --> 00:14:22,310
inside so depending on your application

00:14:19,850 --> 00:14:23,899
architecture just the process here when

00:14:22,310 --> 00:14:26,060
we embed ice bite into it would listen

00:14:23,899 --> 00:14:28,279
on over an international UNIX domain

00:14:26,060 --> 00:14:30,529
socket to hide the details you go to

00:14:28,279 --> 00:14:32,240
know I spy client program is used to

00:14:30,529 --> 00:14:34,610
make the connection to the actual

00:14:32,240 --> 00:14:37,190
process the command interface is driven

00:14:34,610 --> 00:14:38,630
using the command module from Python and

00:14:37,190 --> 00:14:39,800
once you can connect it you can list all

00:14:38,630 --> 00:14:41,720
the plugins which you have configured

00:14:39,800 --> 00:14:43,490
the system to make available because a

00:14:41,720 --> 00:14:44,839
rather than sort of like jumping

00:14:43,490 --> 00:14:46,579
straight into interpreters what they'll

00:14:44,839 --> 00:14:48,050
be all done the whole point of this was

00:14:46,579 --> 00:14:50,149
let's try and make this controlled

00:14:48,050 --> 00:14:52,610
interface so this have it based on on

00:14:50,149 --> 00:14:56,360
plugins and so on and and control it

00:14:52,610 --> 00:14:57,920
that way so we can change the context of

00:14:56,360 --> 00:14:59,449
specific plug-in you can then issue the

00:14:57,920 --> 00:15:01,759
specific commands which that plug-in

00:14:59,449 --> 00:15:03,620
makes available because it isn't that

00:15:01,759 --> 00:15:04,910
full interpreter you can control what

00:15:03,620 --> 00:15:06,709
the plugins you have enabled and

00:15:04,910 --> 00:15:08,360
therefore those commands this way you

00:15:06,709 --> 00:15:10,730
restrict what can be done ensure that

00:15:08,360 --> 00:15:12,139
you can't do too much damage by virtual

00:15:10,730 --> 00:15:15,500
just not putting the things in there

00:15:12,139 --> 00:15:17,720
that can if you are addicted that power

00:15:15,500 --> 00:15:19,189
though then no problem you can go into

00:15:17,720 --> 00:15:20,810
the configuration file and for the

00:15:19,189 --> 00:15:22,610
Python plug-in you can say I want to

00:15:20,810 --> 00:15:24,410
enable embedded interpreter support and

00:15:22,610 --> 00:15:26,269
once you do that you can go in there and

00:15:24,410 --> 00:15:29,990
still run up a consult and do do as much

00:15:26,269 --> 00:15:31,130
damage as you want if you're comfortable

00:15:29,990 --> 00:15:32,420
with monkey patching a live web

00:15:31,130 --> 00:15:34,009
application there a range of other

00:15:32,420 --> 00:15:35,870
things one could do one could introduce

00:15:34,009 --> 00:15:37,519
the wrappers it catches details of

00:15:35,870 --> 00:15:39,199
exceptions and enables you to perform

00:15:37,519 --> 00:15:41,029
post-mortem debugging within the live

00:15:39,199 --> 00:15:42,980
process this is similar tools like the

00:15:41,029 --> 00:15:46,130
flask debugger but done using PDB

00:15:42,980 --> 00:15:47,689
directly in the life process finally

00:15:46,130 --> 00:15:49,519
monkey patching can also help with our

00:15:47,689 --> 00:15:51,230
original problem of how does one change

00:15:49,519 --> 00:15:53,420
what is being monitored by a live web

00:15:51,230 --> 00:15:55,399
application without a restart when an

00:15:53,420 --> 00:15:56,959
interactive console with an interactive

00:15:55,399 --> 00:15:58,030
console like this it becomes feasible to

00:15:56,959 --> 00:15:59,800
have commands that little

00:15:58,030 --> 00:16:01,480
to monkey patch the live system to add

00:15:59,800 --> 00:16:03,460
those additional function traces that

00:16:01,480 --> 00:16:06,010
we're trying to do for configuration or

00:16:03,460 --> 00:16:07,960
otherwise before that would only exist

00:16:06,010 --> 00:16:09,400
until the process exited but it doesn't

00:16:07,960 --> 00:16:12,040
leave to provide you some cup some

00:16:09,400 --> 00:16:13,390
coverage of the problem until you can

00:16:12,040 --> 00:16:17,050
make that permanent change in your code

00:16:13,390 --> 00:16:19,450
and redeployed a further problem area

00:16:17,050 --> 00:16:21,010
we're monitoring well we're monitoring

00:16:19,450 --> 00:16:22,480
can be useful is answering the perennial

00:16:21,010 --> 00:16:24,370
question of how many process and Fred

00:16:22,480 --> 00:16:26,800
should i configure my my whiskey servant

00:16:24,370 --> 00:16:28,420
use capacity can be viewed relative to

00:16:26,800 --> 00:16:29,470
normal traffic loads but could also be

00:16:28,420 --> 00:16:31,360
used to gauge whether you have

00:16:29,470 --> 00:16:32,740
sufficient capacity in a farm of servers

00:16:31,360 --> 00:16:36,880
when you need to perform a role in

00:16:32,740 --> 00:16:38,200
restart during a deployed if you've done

00:16:36,880 --> 00:16:39,550
your homework and have the available

00:16:38,200 --> 00:16:40,960
capacity than although you will see it

00:16:39,550 --> 00:16:42,700
jumping how much of your capacity is

00:16:40,960 --> 00:16:45,070
used when some service has taken offline

00:16:42,700 --> 00:16:47,440
the effect on application response times

00:16:45,070 --> 00:16:49,120
will not be affected get it wrong though

00:16:47,440 --> 00:16:51,070
and you could start to see a backlog

00:16:49,120 --> 00:16:53,230
with an increase in request queuing time

00:16:51,070 --> 00:16:55,030
overall response times growing and

00:16:53,230 --> 00:16:58,150
customer satisfaction basically going

00:16:55,030 --> 00:17:00,010
down the drain further cause of back

00:16:58,150 --> 00:17:02,230
logging due to increased capacity is

00:17:00,010 --> 00:17:03,760
when requests block and the effective

00:17:02,230 --> 00:17:06,400
number of available Fred's drops

00:17:03,760 --> 00:17:08,350
monitoring systems will often only

00:17:06,400 --> 00:17:10,870
report on a web transaction once it's

00:17:08,350 --> 00:17:13,300
complete if a request never completes

00:17:10,870 --> 00:17:14,920
you will not get any metrics about it

00:17:13,300 --> 00:17:17,950
nor a slow transaction tray so you're

00:17:14,920 --> 00:17:19,240
not going to know about it so this is

00:17:17,950 --> 00:17:21,580
again is where an interactive console

00:17:19,240 --> 00:17:23,470
can help in particularly you could run a

00:17:21,580 --> 00:17:26,380
command to dump out the details of all

00:17:23,470 --> 00:17:28,360
active whiskey requests including the

00:17:26,380 --> 00:17:29,770
environment details and a Python stack

00:17:28,360 --> 00:17:31,750
trace of where the code was in that

00:17:29,770 --> 00:17:33,940
point so all you need to now do is go

00:17:31,750 --> 00:17:35,260
find those transactions which have been

00:17:33,940 --> 00:17:37,270
running and longer than the expected

00:17:35,260 --> 00:17:39,160
amount of time and you can see where

00:17:37,270 --> 00:17:43,090
where it is what it was doing and why

00:17:39,160 --> 00:17:44,530
therefore it may have blocked so being

00:17:43,090 --> 00:17:46,990
interacted consult though we can only

00:17:44,530 --> 00:17:48,790
talk to one process at a time what do we

00:17:46,990 --> 00:17:50,560
do about multi-process web applications

00:17:48,790 --> 00:17:51,970
obviously if interacting with an

00:17:50,560 --> 00:17:53,530
embedded interpret or a debugging

00:17:51,970 --> 00:17:56,080
session there's not really much we can

00:17:53,530 --> 00:17:58,600
do but if we only wish to dump out the

00:17:56,080 --> 00:18:01,060
details of what a process is doing or

00:17:58,600 --> 00:18:02,770
perform monkey patching what we want

00:18:01,060 --> 00:18:04,510
here is an ability in the client program

00:18:02,770 --> 00:18:05,890
to automatically apply a set of commands

00:18:04,510 --> 00:18:08,380
across a whole bunch of service in one

00:18:05,890 --> 00:18:10,520
go and that's giving ourselves a script

00:18:08,380 --> 00:18:12,630
ability

00:18:10,520 --> 00:18:14,250
because the console are in the interface

00:18:12,630 --> 00:18:16,410
and the command module in particular is

00:18:14,250 --> 00:18:18,000
being used rather than trying to wrap up

00:18:16,410 --> 00:18:19,530
things in some high-level message

00:18:18,000 --> 00:18:21,480
oriented service abstraction with this

00:18:19,530 --> 00:18:23,490
whole thing writing new plugins is

00:18:21,480 --> 00:18:25,500
relatively easily all that is necessary

00:18:23,490 --> 00:18:27,210
to provide a method for each command

00:18:25,500 --> 00:18:28,680
that writes the response to the output

00:18:27,210 --> 00:18:30,990
stream object set up for that instance

00:18:28,680 --> 00:18:32,940
of the shelf and for more complicated

00:18:30,990 --> 00:18:34,140
plugins which require for our input such

00:18:32,940 --> 00:18:37,080
as an embed interpreter as the input

00:18:34,140 --> 00:18:40,800
streams also they're available so it

00:18:37,080 --> 00:18:42,360
jump in there and extended so so the

00:18:40,800 --> 00:18:44,270
whole point there we vice by when it go

00:18:42,360 --> 00:18:46,410
is not just to be another interpreter

00:18:44,270 --> 00:18:47,730
way of getting into it it was this whole

00:18:46,410 --> 00:18:49,620
thing of a general infrastructure for

00:18:47,730 --> 00:18:51,930
managing a console and interaction with

00:18:49,620 --> 00:18:53,400
a process so the goal and hopefully is

00:18:51,930 --> 00:18:54,360
that the wider community here all sort

00:18:53,400 --> 00:18:56,340
of gate oh this is a really good idea

00:18:54,360 --> 00:18:59,190
and we'll start to have all these

00:18:56,340 --> 00:19:00,660
plugins get made which will be available

00:18:59,190 --> 00:19:02,160
from pipeline just download them install

00:19:00,660 --> 00:19:05,130
and listed in the config file say that

00:19:02,160 --> 00:19:07,260
you want them and where you go so one

00:19:05,130 --> 00:19:09,180
could see lots of useful plugins being

00:19:07,260 --> 00:19:10,890
developed a good in process memory

00:19:09,180 --> 00:19:12,870
analysis tool for tracking memory growth

00:19:10,890 --> 00:19:14,070
would be example here which would be

00:19:12,870 --> 00:19:16,530
particularly interesting and valuable

00:19:14,070 --> 00:19:18,330
and where again monitoring systems

00:19:16,530 --> 00:19:20,160
although they can show you how much

00:19:18,330 --> 00:19:21,870
memory your application is using there

00:19:20,160 --> 00:19:25,050
anything necessarily report on it once a

00:19:21,870 --> 00:19:26,430
minute for example so you can't see the

00:19:25,050 --> 00:19:28,410
little transit things that are going on

00:19:26,430 --> 00:19:30,750
between and nor can you get the in-depth

00:19:28,410 --> 00:19:32,010
detail on things like how many objects

00:19:30,750 --> 00:19:34,530
have been created and all those sorts of

00:19:32,010 --> 00:19:36,210
things so monitoring systems yeah give a

00:19:34,530 --> 00:19:37,560
good note of you but that's one thing I

00:19:36,210 --> 00:19:39,870
don't know who could answer answer on

00:19:37,560 --> 00:19:43,410
you there is here there is heat pi which

00:19:39,870 --> 00:19:45,780
is roughly complicated in my view and

00:19:43,410 --> 00:19:48,720
attends a tendency to crash process I've

00:19:45,780 --> 00:19:51,300
found so hopefully ice bar will be nice

00:19:48,720 --> 00:19:52,620
nice mechanism for people come up with a

00:19:51,300 --> 00:19:55,920
nice plug-in for memory developing to be

00:19:52,620 --> 00:19:57,960
really good so in conclusion what am I

00:19:55,920 --> 00:19:59,700
trying to say that is the production

00:19:57,960 --> 00:20:01,950
systems need not be treated as this

00:19:59,700 --> 00:20:04,170
special sanctum that only anointed

00:20:01,950 --> 00:20:05,970
operations people can touch use

00:20:04,170 --> 00:20:08,340
monitoring systems so you know what

00:20:05,970 --> 00:20:10,230
problems that arise but be prepared and

00:20:08,340 --> 00:20:12,930
also put in place mechanisms to help you

00:20:10,230 --> 00:20:14,460
debug the issues that do arise do it in

00:20:12,930 --> 00:20:16,320
a way that is controllable and

00:20:14,460 --> 00:20:19,230
scriptable so that the results are

00:20:16,320 --> 00:20:21,030
predictable during debugging then

00:20:19,230 --> 00:20:23,250
becomes a normal procedure in the same

00:20:21,030 --> 00:20:23,770
way the deploy sir and your your ops

00:20:23,250 --> 00:20:25,600
people

00:20:23,770 --> 00:20:29,590
not going to get freaked out when I say

00:20:25,600 --> 00:20:31,000
I want to do this so also you would hope

00:20:29,590 --> 00:20:32,410
that you would see new relic is part of

00:20:31,000 --> 00:20:35,110
your tool set when you're doing all of

00:20:32,410 --> 00:20:37,060
this but whatever you do they use some

00:20:35,110 --> 00:20:38,890
level of monitoring if you have no

00:20:37,060 --> 00:20:40,270
monitoring and all then you're not only

00:20:38,890 --> 00:20:42,310
will you not know immediately when there

00:20:40,270 --> 00:20:44,500
is a problem but you're not even know

00:20:42,310 --> 00:20:47,230
where to start looking to debug it so

00:20:44,500 --> 00:20:49,510
become a data nerd deploy new relic and

00:20:47,230 --> 00:20:59,530
if you're interested in I spied and come

00:20:49,510 --> 00:21:01,450
and have a chat to me after we have a

00:20:59,530 --> 00:21:03,070
few minutes for questions so if you do

00:21:01,450 --> 00:21:04,810
have questions please wait for the mic

00:21:03,070 --> 00:21:07,630
to come around just stick your hand up

00:21:04,810 --> 00:21:10,110
and Mark or run the mic down to you any

00:21:07,630 --> 00:21:10,110
questions

00:21:16,519 --> 00:21:21,200
hi Justin I was interested if you had

00:21:19,519 --> 00:21:23,629
could think of any stories off the top

00:21:21,200 --> 00:21:27,679
of your head of when you used I spied I

00:21:23,629 --> 00:21:29,479
spy deal i spied tonight I okay to just

00:21:27,679 --> 00:21:30,679
I guess you've discovered particular

00:21:29,479 --> 00:21:32,570
sort of memory leaks or performance

00:21:30,679 --> 00:21:35,330
issues where you completely didn't

00:21:32,570 --> 00:21:37,759
expect it and I aspire something I put

00:21:35,330 --> 00:21:39,409
together Manny that when people ask me

00:21:37,759 --> 00:21:40,789
about mod w show problems I can be

00:21:39,409 --> 00:21:42,200
prepared and say hey look go put this

00:21:40,789 --> 00:21:44,029
thing in and now I can tell them what to

00:21:42,200 --> 00:21:45,349
do fortunately said I did of not

00:21:44,029 --> 00:21:48,109
actually how do you wanna come up and

00:21:45,349 --> 00:21:49,700
need it but what i have done is the

00:21:48,109 --> 00:21:51,619
whole concept of that embedded console

00:21:49,700 --> 00:21:53,119
is something that I've taken in and for

00:21:51,619 --> 00:21:56,200
our new relic hyphenation I've actually

00:21:53,119 --> 00:21:58,249
got a variant of in our Asian itself and

00:21:56,200 --> 00:22:00,859
one of the things we've been looking at

00:21:58,249 --> 00:22:02,359
is how to support a sink applications

00:22:00,859 --> 00:22:04,279
rather than just blocking Wiz gaps in

00:22:02,359 --> 00:22:05,749
our Python agent and yet one of the

00:22:04,279 --> 00:22:06,979
customers I was trying to trial some of

00:22:05,749 --> 00:22:10,669
the stuff we were playing around with

00:22:06,979 --> 00:22:12,559
their they would find that this twisted

00:22:10,669 --> 00:22:15,289
mutation I was all working and then it

00:22:12,559 --> 00:22:16,309
suddenly will stop and we had no idea so

00:22:15,289 --> 00:22:17,779
this is an example where with the

00:22:16,309 --> 00:22:20,119
interactive console is good i can say

00:22:17,779 --> 00:22:21,320
I'll deploy this new version of the

00:22:20,119 --> 00:22:24,109
Asian I've got which we're about to

00:22:21,320 --> 00:22:25,700
release soon configured is to be enabled

00:22:24,109 --> 00:22:27,440
and when he had the problem I could tell

00:22:25,700 --> 00:22:29,719
him to go in there going there and we'd

00:22:27,440 --> 00:22:31,459
pre set up all these commands which

00:22:29,719 --> 00:22:34,279
would allow us to dump out information

00:22:31,459 --> 00:22:37,039
about what our own agent was doing so we

00:22:34,279 --> 00:22:39,859
could see that oh it was at this point

00:22:37,039 --> 00:22:42,019
in time it was had this one active web

00:22:39,859 --> 00:22:45,889
transaction at which it was monitoring

00:22:42,019 --> 00:22:47,779
and it gotten it somehow lost sort of

00:22:45,889 --> 00:22:49,729
got stuck at that point it got like

00:22:47,779 --> 00:22:52,129
kristin is really weird because in a

00:22:49,729 --> 00:22:53,690
whiskey app everything said separate

00:22:52,129 --> 00:22:55,700
freds and therefore we can track each

00:22:53,690 --> 00:22:57,889
web transaction individually but in a

00:22:55,700 --> 00:22:59,809
sync app you've only got one Fred so we

00:22:57,889 --> 00:23:02,059
have this web transaction record which

00:22:59,809 --> 00:23:04,879
we sort of keep having to pop off the

00:23:02,059 --> 00:23:07,179
top and toes of the current one so it

00:23:04,879 --> 00:23:09,499
would end up getting left there and

00:23:07,179 --> 00:23:11,389
meanwhile the transaction finished and

00:23:09,499 --> 00:23:13,969
because it was the current one the whole

00:23:11,389 --> 00:23:15,019
system got confused and our new ones

00:23:13,969 --> 00:23:17,119
come along and it wouldn't do anything

00:23:15,019 --> 00:23:18,619
so that was an example where else able

00:23:17,119 --> 00:23:21,079
to use this interactive console to at

00:23:18,619 --> 00:23:22,879
least confirm what I fought was

00:23:21,079 --> 00:23:24,379
happening in their app and from that

00:23:22,879 --> 00:23:25,190
other then I'll do a bit more digging in

00:23:24,379 --> 00:23:27,410
the code and work

00:23:25,190 --> 00:23:28,610
what was probably happening in that

00:23:27,410 --> 00:23:29,960
particular case I still have actually

00:23:28,610 --> 00:23:32,210
fixed it I've told them to I'll disable

00:23:29,960 --> 00:23:33,800
this bit of instrumentation and at least

00:23:32,210 --> 00:23:36,440
they're getting overall response times

00:23:33,800 --> 00:23:38,540
but they're not getting deep information

00:23:36,440 --> 00:23:39,590
on twisted deferred moment within the

00:23:38,540 --> 00:23:42,320
context of where that was a bit

00:23:39,590 --> 00:23:45,200
unfortunate but B that's it that's an

00:23:42,320 --> 00:23:48,710
example how long has ice buddy been

00:23:45,200 --> 00:23:50,090
around long I wrote it I basically got

00:23:48,710 --> 00:23:52,040
all the bits together and shoves it in

00:23:50,090 --> 00:23:54,500
the Reaper back in Lock easter long

00:23:52,040 --> 00:23:57,320
weekend but I haven't publicized it this

00:23:54,500 --> 00:23:59,210
is the first major outing just to say it

00:23:57,320 --> 00:24:02,030
it's not it's not finished like some

00:23:59,210 --> 00:24:03,380
things in there like this idea of being

00:24:02,030 --> 00:24:04,790
able to apply a script of commands

00:24:03,380 --> 00:24:06,470
across mobile so it isn't implemented

00:24:04,790 --> 00:24:08,720
yet it's the idea it's what I want to

00:24:06,470 --> 00:24:09,710
achieve and it needs some cleanup but

00:24:08,720 --> 00:24:11,230
this is where I'm putting it out there

00:24:09,710 --> 00:24:13,280
and hopefully you'll get the interest to

00:24:11,230 --> 00:24:15,200
people might want to start contributing

00:24:13,280 --> 00:24:16,580
on it because the demand I'm really busy

00:24:15,200 --> 00:24:18,440
and I haven't had time to get back to it

00:24:16,580 --> 00:24:28,850
well think it looks bloody interesting

00:24:18,440 --> 00:24:31,880
yes think anybody else no grandma you

00:24:28,850 --> 00:24:35,020
hang around for the hackathon afterwards

00:24:31,880 --> 00:24:38,420
no I fortunately I have to go back up

00:24:35,020 --> 00:24:40,010
leaving Monday last time ok go just

00:24:38,420 --> 00:24:46,460
wondering because it would be good to

00:24:40,010 --> 00:24:53,050
work on so I've got a couple of things

00:24:46,460 --> 00:24:56,180
to give you full thanks thanks Graham

00:24:53,050 --> 00:25:00,430
some coffee in a coffee mode very much

00:24:56,180 --> 00:25:00,430

YouTube URL: https://www.youtube.com/watch?v=FG2ai9XFzSo


