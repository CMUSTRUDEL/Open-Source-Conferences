Title: Techniques for improving Python performance
Publication date: 2012-08-23
Playlist: PyCon Australia 2012
Description: 
	Andrew Rowe
Andrew Rowe will detail and demonstrate a number of proven techniques for improving the performance of large Python programs.

Using multiprocessing.
Using custom extensions.
Refactoring code.
using comprehensions.
Dictionaries v. L
Captions: 
	00:00:00,000 --> 00:00:05,310
I'm sad Rove strain biostatistics if I

00:00:03,810 --> 00:00:07,710
press the button and go oh yeah

00:00:05,310 --> 00:00:09,599
so the ABS is a federal government

00:00:07,710 --> 00:00:11,490
agency for collecting statistics to

00:00:09,599 --> 00:00:13,380
improve decision-making so we're

00:00:11,490 --> 00:00:16,460
responsible sensors CPI unemployment

00:00:13,380 --> 00:00:18,930
bounce of poems and plenty of other ones

00:00:16,460 --> 00:00:20,189
we've got plenty of statistics and we

00:00:18,930 --> 00:00:21,930
like to give them to any when it comes

00:00:20,189 --> 00:00:25,199
along and sell them to people who want a

00:00:21,930 --> 00:00:26,340
lot more details so we can buy that in

00:00:25,199 --> 00:00:27,630
this presentation I'll show you

00:00:26,340 --> 00:00:30,599
techniques they used to reduce this time

00:00:27,630 --> 00:00:33,059
from a standard deviation run from 19

00:00:30,599 --> 00:00:35,899
hours to almost 1 hour so what's the

00:00:33,059 --> 00:00:37,890
deduplication I think the next page

00:00:35,899 --> 00:00:39,690
stranger statistics must check the

00:00:37,890 --> 00:00:41,940
census to ensure that people only

00:00:39,690 --> 00:00:44,700
counted once and this process is called

00:00:41,940 --> 00:00:46,320
deduplication we have large numbers and

00:00:44,700 --> 00:00:49,020
we use we have very high accuracy

00:00:46,320 --> 00:00:50,700
standards for XE rare but not too high

00:00:49,020 --> 00:00:53,100
standards for twelve intensively and

00:00:50,700 --> 00:00:54,719
presentations so we use a system from

00:00:53,100 --> 00:00:58,170
the a new called feble to process the

00:00:54,719 --> 00:00:59,820
data so let's have a look so febrile

00:00:58,170 --> 00:01:03,000
it's a friendly example biomedical

00:00:59,820 --> 00:01:04,619
record linkage is written in Python and

00:01:03,000 --> 00:01:06,570
designed to handle hundreds of moons of

00:01:04,619 --> 00:01:08,700
comparisons using dozens of premises it

00:01:06,570 --> 00:01:09,930
was developed at there and you by Peter

00:01:08,700 --> 00:01:12,990
Christian work in churches at the

00:01:09,930 --> 00:01:16,320
supercomputing Center so he took that

00:01:12,990 --> 00:01:19,200
over and initially when we were running

00:01:16,320 --> 00:01:20,340
it it took an awful long time so we had

00:01:19,200 --> 00:01:22,740
a standard job of about two hundred

00:01:20,340 --> 00:01:26,009
thousand records and it would take 19

00:01:22,740 --> 00:01:31,500
hours to run and this was on you know

00:01:26,009 --> 00:01:33,479
our Z on Windows Server 2010 with 196

00:01:31,500 --> 00:01:36,329
gigabytes of memory so it should have

00:01:33,479 --> 00:01:38,340
gone fast but it was pretty slicer so we

00:01:36,329 --> 00:01:39,840
had 20,000 then we had another job which

00:01:38,340 --> 00:01:42,540
was to do all the census to check the

00:01:39,840 --> 00:01:47,700
duplication and it would take seven days

00:01:42,540 --> 00:01:48,869
and then it just crash so that was a bit

00:01:47,700 --> 00:01:51,119
wasn't too good and the thing with

00:01:48,869 --> 00:01:54,390
census is that we have to get everything

00:01:51,119 --> 00:01:56,700
done within a certain time frame by

00:01:54,390 --> 00:01:58,560
legislation if we don't finish then all

00:01:56,700 --> 00:02:02,640
the data that can be used to identify

00:01:58,560 --> 00:02:03,149
people is removed so so we've got one

00:02:02,640 --> 00:02:04,680
more month

00:02:03,149 --> 00:02:06,270
two more months I think until December

00:02:04,680 --> 00:02:07,860
then all the forms and all the data

00:02:06,270 --> 00:02:10,890
which could identify someone from the

00:02:07,860 --> 00:02:12,900
census is popped and destroyed and all

00:02:10,890 --> 00:02:13,770
the drives are wipes and all the

00:02:12,900 --> 00:02:17,190
databases are clean

00:02:13,770 --> 00:02:19,410
so all we have left is the summation you

00:02:17,190 --> 00:02:21,510
know the the general stuff you can't

00:02:19,410 --> 00:02:23,610
identify anyone after that date so we

00:02:21,510 --> 00:02:25,740
have a time period so taking seven days

00:02:23,610 --> 00:02:29,460
to run and they're not doing anything is

00:02:25,740 --> 00:02:32,190
good so it's a student able pebble to

00:02:29,460 --> 00:02:35,640
make go faster and these are some of the

00:02:32,190 --> 00:02:40,670
lessons I learnt including that performs

00:02:35,640 --> 00:02:43,500
a pebble so lesson number one costly

00:02:40,670 --> 00:02:46,230
pebble shouldn't use multiple cores with

00:02:43,500 --> 00:02:47,610
MPI which is a multiprocessor isn't

00:02:46,230 --> 00:02:49,050
library but no wonder the IDS never got

00:02:47,610 --> 00:02:52,080
into work that was the number one thing

00:02:49,050 --> 00:02:54,240
to try and get that work we had Windows

00:02:52,080 --> 00:02:55,890
virtual servers with 8z on calls and a

00:02:54,240 --> 00:02:57,150
hundred ninety gigabytes of memory so

00:02:55,890 --> 00:03:00,030
there's potential there you know you

00:02:57,150 --> 00:03:03,630
have one core it takes eight hours eight

00:03:00,030 --> 00:03:04,200
cause obviously takes one hour so that's

00:03:03,630 --> 00:03:06,450
ideal

00:03:04,200 --> 00:03:12,480
that was the potentially as making much

00:03:06,450 --> 00:03:14,700
go faster to go much faster okay so

00:03:12,480 --> 00:03:16,590
after a bit of fiddling around with the

00:03:14,700 --> 00:03:18,750
multiple quarters the results I got so

00:03:16,590 --> 00:03:21,209
we started off here with one core then

00:03:18,750 --> 00:03:23,340
we once we've employed an MPI to cause

00:03:21,209 --> 00:03:25,350
you can see down it's practically half

00:03:23,340 --> 00:03:28,740
the speed three cores

00:03:25,350 --> 00:03:31,740
not too better for cause it's not quite

00:03:28,740 --> 00:03:33,720
down here where it should be and as you

00:03:31,740 --> 00:03:36,630
get more and more cause the improvement

00:03:33,720 --> 00:03:39,540
sort of lessons off a lot and then you

00:03:36,630 --> 00:03:41,880
can see this big bar graph up here soon

00:03:39,540 --> 00:03:43,770
as you go across two machines which you

00:03:41,880 --> 00:03:45,170
can do with MPI you can set that machine

00:03:43,770 --> 00:03:47,580
so they all behave like one

00:03:45,170 --> 00:03:49,290
yeah you go up there so there's

00:03:47,580 --> 00:03:50,700
obviously something happening here yeah

00:03:49,290 --> 00:03:52,410
what was happening there was it was just

00:03:50,700 --> 00:03:53,790
taking a long time to communicate and

00:03:52,410 --> 00:03:56,790
synchronize all the data between

00:03:53,790 --> 00:03:59,700
machines so I gave up that idea I was

00:03:56,790 --> 00:04:00,840
had visions of you know a huge grid come

00:03:59,700 --> 00:04:02,100
seing everything in the bureau and I'd

00:04:00,840 --> 00:04:05,630
take over all the resources and

00:04:02,100 --> 00:04:05,630
everything be done immediately good

00:04:06,170 --> 00:04:12,630
megalomania is often sort of frustrated

00:04:09,270 --> 00:04:16,320
okay so next one okay I'll go

00:04:12,630 --> 00:04:17,880
demonstration of single core and then

00:04:16,320 --> 00:04:21,140
mobile core now let's go to the demo and

00:04:17,880 --> 00:04:21,140
see that crashes

00:04:21,350 --> 00:04:31,230
all right so I'm gonna read up to you

00:04:29,970 --> 00:04:35,450
three four four six eight hundred

00:04:31,230 --> 00:04:35,450
million with one quart

00:04:36,919 --> 00:04:39,870
okay so that took two seconds that's

00:04:39,090 --> 00:04:41,400
that's pretty good

00:04:39,870 --> 00:04:44,990
maybe we'll just make it a bit longer so

00:04:41,400 --> 00:04:44,990
it's pretty obvious what's going on here

00:04:47,630 --> 00:04:59,220
so it's taking longer obviously come on

00:04:50,669 --> 00:05:01,710
come on maybes taking too long you think

00:04:59,220 --> 00:05:02,729
it'd take ten times long okay so does so

00:05:01,710 --> 00:05:04,440
it's sixteen seconds

00:05:02,729 --> 00:05:06,389
now we put an extra parameter at the end

00:05:04,440 --> 00:05:09,240
here just how many cords are going to

00:05:06,389 --> 00:05:10,710
run apparently my PC says it's got four

00:05:09,240 --> 00:05:11,910
cords we left you'd say two causes

00:05:10,710 --> 00:05:14,520
hyper-threading so I'll just write with

00:05:11,910 --> 00:05:24,030
two cause and that should go twice as

00:05:14,520 --> 00:05:26,700
fast come on come on there you go see if

00:05:24,030 --> 00:05:28,530
you can run your program on more than

00:05:26,700 --> 00:05:31,320
one process you could potentially have a

00:05:28,530 --> 00:05:32,669
number of times it takes so what this

00:05:31,320 --> 00:05:40,039
does is if you want to have a look at

00:05:32,669 --> 00:05:40,039
the code okay go

00:05:42,850 --> 00:05:51,830
so what we're doing here is we're just

00:05:47,980 --> 00:05:52,880
counting the number of CPUs working

00:05:51,830 --> 00:05:55,370
hammer you're doing they're creating a

00:05:52,880 --> 00:05:56,690
key for each CPU and we're going down to

00:05:55,370 --> 00:05:58,490
using the multi processing module which

00:05:56,690 --> 00:06:00,080
is a standard part of Python every

00:05:58,490 --> 00:06:01,700
version of Python I believe has got it

00:06:00,080 --> 00:06:04,790
so you don't need to install anything

00:06:01,700 --> 00:06:06,770
else which is great and you just say I

00:06:04,790 --> 00:06:08,390
want to run this function and all these

00:06:06,770 --> 00:06:11,480
other process and I start it and then

00:06:08,390 --> 00:06:13,790
you just wait for it to job to finish in

00:06:11,480 --> 00:06:16,190
that the join bit means wait for the

00:06:13,790 --> 00:06:17,750
finish I don't know why it says join not

00:06:16,190 --> 00:06:20,480
wait for everything to finish there you

00:06:17,750 --> 00:06:24,250
go and once you do that you could just

00:06:20,480 --> 00:06:26,750
up in your function to do the adding up

00:06:24,250 --> 00:06:28,940
you just have to a method of ways of it

00:06:26,750 --> 00:06:30,770
each process knows which bit of it it's

00:06:28,940 --> 00:06:34,270
adding up and then it puts the result

00:06:30,770 --> 00:06:36,620
into the queue and returns it so that

00:06:34,270 --> 00:06:39,440
that's the hard part of multiprocessing

00:06:36,620 --> 00:06:41,270
is deciding how to divide up your job so

00:06:39,440 --> 00:06:44,090
things can operate independently and

00:06:41,270 --> 00:06:45,320
then understanding how to coordinate and

00:06:44,090 --> 00:06:47,630
bring them all back together again so

00:06:45,320 --> 00:06:52,040
we'll go back to demo to the

00:06:47,630 --> 00:06:53,720
presentation so here I've got screened

00:06:52,040 --> 00:06:56,570
up of working on one of our servers with

00:06:53,720 --> 00:07:00,350
8 cores and beforehand

00:06:56,570 --> 00:07:02,320
it took 12 seconds and afterwards one

00:07:00,350 --> 00:07:04,820
second so that's a pretty good speed up

00:07:02,320 --> 00:07:07,910
see if you could apply that to all the

00:07:04,820 --> 00:07:11,000
job you can go from 19 hours 19 divided

00:07:07,910 --> 00:07:12,440
by 8 is about 2 so then you can get 2

00:07:11,000 --> 00:07:14,270
hours so that's that's pretty good so

00:07:12,440 --> 00:07:18,650
that's the sort of thing we're having

00:07:14,270 --> 00:07:20,900
for do that ok so we put in the MPI and

00:07:18,650 --> 00:07:23,180
oh and that's what happened we went from

00:07:20,900 --> 00:07:26,300
19 hours down to one and a half hours

00:07:23,180 --> 00:07:27,290
that meant that strategists can use they

00:07:26,300 --> 00:07:29,990
said oh great

00:07:27,290 --> 00:07:32,450
your job now instead of tacky 90s takes

00:07:29,990 --> 00:07:34,340
one else let's put more data into it and

00:07:32,450 --> 00:07:36,110
change all the options so we can get

00:07:34,340 --> 00:07:38,120
more detail and put it back up to 19

00:07:36,110 --> 00:07:41,920
hours in that's that's what uses a like

00:07:38,120 --> 00:07:44,480
I believe ok so there we did that and

00:07:41,920 --> 00:07:46,670
that meant that not only they could

00:07:44,480 --> 00:07:47,960
start they could do their jobs within

00:07:46,670 --> 00:07:49,160
one day but they could actually do

00:07:47,960 --> 00:07:51,230
multiple jobs so they could make

00:07:49,160 --> 00:07:53,570
mistakes and enhance it and change the

00:07:51,230 --> 00:07:55,220
parameters it was a really great fun

00:07:53,570 --> 00:07:59,270
they love me

00:07:55,220 --> 00:08:00,650
and I got an award you've got 50 bucks

00:07:59,270 --> 00:08:05,480
oh there you go that's what happens in

00:08:00,650 --> 00:08:08,150
public service it's almost the same

00:08:05,480 --> 00:08:09,320
award as for going to a meeting once for

00:08:08,150 --> 00:08:10,640
something else been organized and ever

00:08:09,320 --> 00:08:15,820
attending again and getting the award

00:08:10,640 --> 00:08:19,430
for that I was pretty pleased okay so

00:08:15,820 --> 00:08:21,380
once we did this we were then reduced

00:08:19,430 --> 00:08:23,150
the time and we allowed the whole census

00:08:21,380 --> 00:08:24,650
to be duplicated so that's 20 million

00:08:23,150 --> 00:08:27,320
records compared against 20 million

00:08:24,650 --> 00:08:29,240
other records and you got perhaps 400

00:08:27,320 --> 00:08:31,880
billion comparisons or 400 million

00:08:29,240 --> 00:08:34,280
comparisons and that was all we could do

00:08:31,880 --> 00:08:35,599
that within about three or four days so

00:08:34,280 --> 00:08:38,240
that was pretty good and it completed

00:08:35,599 --> 00:08:41,479
okay Sydney it's the moss okay I did

00:08:38,240 --> 00:08:42,979
this one okay so now the things that we

00:08:41,479 --> 00:08:46,100
did within which we noticed that we were

00:08:42,979 --> 00:08:48,140
running Python 3.4 because now I needed

00:08:46,100 --> 00:08:49,730
the bother to upgrade and then I looked

00:08:48,140 --> 00:08:52,850
at it I said okay if you upgrade from

00:08:49,730 --> 00:08:55,460
patented for 2.7 without changing any of

00:08:52,850 --> 00:08:58,730
your code it'll go 30 to 40 percent

00:08:55,460 --> 00:09:00,500
faster so did that immediately our thing

00:08:58,730 --> 00:09:03,890
was that through the code there was all

00:09:00,500 --> 00:09:07,040
these is false to do debugging take all

00:09:03,890 --> 00:09:07,910
em out goes another 20% faster so

00:09:07,040 --> 00:09:09,380
there's a lot of things that people

00:09:07,910 --> 00:09:11,960
don't notice it you know things like

00:09:09,380 --> 00:09:13,880
that and that thing is this another

00:09:11,960 --> 00:09:15,170
thing is when we're reading files we

00:09:13,880 --> 00:09:17,150
just read them and using the standard

00:09:15,170 --> 00:09:19,040
Python course but if you change them

00:09:17,150 --> 00:09:21,260
around so you can memory map the files

00:09:19,040 --> 00:09:23,870
into the virtual memory you'll get

00:09:21,260 --> 00:09:25,610
another 20% so just by a couple of

00:09:23,870 --> 00:09:27,230
simple change of that haven't changed

00:09:25,610 --> 00:09:30,380
any of the logic of your program running

00:09:27,230 --> 00:09:34,670
new packages what's that 30 plus 20

00:09:30,380 --> 00:09:36,320
bucks 20 is something a lot I don't

00:09:34,670 --> 00:09:37,970
think so you can add up percentages

00:09:36,320 --> 00:09:38,690
that's a sort of statistically invalid

00:09:37,970 --> 00:09:42,940
thing to do that

00:09:38,690 --> 00:09:42,940
never all right

00:09:47,260 --> 00:09:52,820
well it's sort of like debugging then

00:09:50,779 --> 00:09:55,040
when the bloke wrote the code he said

00:09:52,820 --> 00:09:57,380
you know if I compare these results to

00:09:55,040 --> 00:09:59,690
those results do they come out expected

00:09:57,380 --> 00:10:01,070
print it out so we just went in there

00:09:59,690 --> 00:10:04,040
where they had all the print statements

00:10:01,070 --> 00:10:05,089
no it just took him out because he had

00:10:04,040 --> 00:10:06,860
all these print statements even

00:10:05,089 --> 00:10:08,420
debugging mode if debugging mode if

00:10:06,860 --> 00:10:10,160
debugging mode if debugging mode print

00:10:08,420 --> 00:10:11,839
statement so just get rid of them all

00:10:10,160 --> 00:10:14,140
and that saves a lot of time especially

00:10:11,839 --> 00:10:17,050
you have a loop like if you're looping

00:10:14,140 --> 00:10:20,120
400 trillion times if something takes

00:10:17,050 --> 00:10:22,190
0.0001 seconds multiply that by 400

00:10:20,120 --> 00:10:23,420
trillion that's a lot so when you're

00:10:22,190 --> 00:10:24,920
doing little done but it doesn't matter

00:10:23,420 --> 00:10:26,240
to make much difference what are you

00:10:24,920 --> 00:10:28,339
doing big numbers you go down take

00:10:26,240 --> 00:10:31,760
things like that it really makes a big

00:10:28,339 --> 00:10:33,350
difference okay and these are specific

00:10:31,760 --> 00:10:35,839
techniques that can be used with any

00:10:33,350 --> 00:10:37,460
Python standard installation don't need

00:10:35,839 --> 00:10:40,010
any other packages don't need um PI or

00:10:37,460 --> 00:10:41,089
anything else like that and the like I

00:10:40,010 --> 00:10:42,800
was saying the for large numbers

00:10:41,089 --> 00:10:43,880
comparisons cause small delays and

00:10:42,800 --> 00:10:45,320
efficiencies that can build up into

00:10:43,880 --> 00:10:46,220
large blockages so when you're talking

00:10:45,320 --> 00:10:48,670
really big numbers

00:10:46,220 --> 00:10:52,520
little tiny numbers are significant that

00:10:48,670 --> 00:10:54,500
makes any sense okay so the first one is

00:10:52,520 --> 00:10:55,670
you use X range instead of range now

00:10:54,500 --> 00:10:57,530
this might be something has been settle

00:10:55,670 --> 00:10:59,030
over the place but it's easier when

00:10:57,530 --> 00:11:00,589
you're writing out a for loop just to

00:10:59,030 --> 00:11:03,200
say range and treat it like it's a C for

00:11:00,589 --> 00:11:06,500
loop or a while loop but it doesn't

00:11:03,200 --> 00:11:07,760
quite work like that so range has to

00:11:06,500 --> 00:11:10,400
generate a list of the numbers before

00:11:07,760 --> 00:11:13,220
humor ation starts so it's not like a

00:11:10,400 --> 00:11:14,240
for loop in C where you just increment

00:11:13,220 --> 00:11:15,440
and just check so you've only got one

00:11:14,240 --> 00:11:18,700
little value that you only got it in

00:11:15,440 --> 00:11:21,260
four bytes 16 bytes were you in a range

00:11:18,700 --> 00:11:22,940
it'll create the whole range in memory

00:11:21,260 --> 00:11:25,070
and then put it in the for loop and

00:11:22,940 --> 00:11:26,390
either write across it which doesn't

00:11:25,070 --> 00:11:27,920
seem to note you don't notice that if

00:11:26,390 --> 00:11:30,140
you're doing like a thousand ten

00:11:27,920 --> 00:11:33,470
thousand hundred thousand what happens

00:11:30,140 --> 00:11:35,870
if you're doing 100 million you got a

00:11:33,470 --> 00:11:38,209
hundred million into objects in your

00:11:35,870 --> 00:11:39,860
range and that could take up a lot of

00:11:38,209 --> 00:11:41,870
memory even 192 gigabytes it's

00:11:39,860 --> 00:11:44,990
significant it can take time to produce

00:11:41,870 --> 00:11:45,980
if your number is really gigantic it can

00:11:44,990 --> 00:11:50,320
take up all the memory in the thing

00:11:45,980 --> 00:11:50,320
crashes ok so I've got an example here

00:11:51,610 --> 00:11:55,980
this is my code here can you see that

00:11:54,890 --> 00:11:59,550
well enough

00:11:55,980 --> 00:12:02,279
no yes oh good okay least one person

00:11:59,550 --> 00:12:05,880
cancer that's all right okay so what

00:12:02,279 --> 00:12:13,230
we're doing simply here is we're making

00:12:05,880 --> 00:12:14,670
a range up there oh yeah okay so here

00:12:13,230 --> 00:12:16,230
I'm just telling working out how long it

00:12:14,670 --> 00:12:18,180
takes to create a range before you do

00:12:16,230 --> 00:12:19,980
any processing then cutting and right

00:12:18,180 --> 00:12:20,430
now I'm using x-rays an X range is

00:12:19,980 --> 00:12:22,620
different

00:12:20,430 --> 00:12:24,449
I think it's an iterator I carry with

00:12:22,620 --> 00:12:27,120
the details of it it's almost like a

00:12:24,449 --> 00:12:29,670
while you know while one's less than 100

00:12:27,120 --> 00:12:39,870
one plus plus you know exit plus plus

00:12:29,670 --> 00:12:42,810
okay so let's run that what's that Hemi

00:12:39,870 --> 00:12:45,930
are zero severe I think that's 1 billion

00:12:42,810 --> 00:12:47,940
100 million ok so it took for two and a

00:12:45,930 --> 00:12:50,040
half almost three seconds to create the

00:12:47,940 --> 00:12:51,660
range before we actually did anything so

00:12:50,040 --> 00:12:53,880
there to you you're you're not achieving

00:12:51,660 --> 00:12:55,399
anything for using a ray you're slowing

00:12:53,880 --> 00:12:59,570
down before you can do any processing

00:12:55,399 --> 00:13:02,190
now it's so there you go 16 seconds to I

00:12:59,570 --> 00:13:04,290
don't know what I did but did something

00:13:02,190 --> 00:13:08,160
I don't know

00:13:04,290 --> 00:13:11,690
yeah ok there we go and now it's range

00:13:08,160 --> 00:13:13,140
if your fingers clash should go faster

00:13:11,690 --> 00:13:14,240
yah-tchi

00:13:13,140 --> 00:13:19,890
yeah well that's pretty good anyway

00:13:14,240 --> 00:13:23,160
that's one second but yeah I could see

00:13:19,890 --> 00:13:29,430
that we go into the performance monitor

00:13:23,160 --> 00:13:32,190
here you can see here that's where it

00:13:29,430 --> 00:13:35,040
quite of the range so you've used up

00:13:32,190 --> 00:13:38,160
almost all your memory creating a range

00:13:35,040 --> 00:13:42,870
just to do a little loop so you better

00:13:38,160 --> 00:13:45,810
watch out for things like that okay next

00:13:42,870 --> 00:13:48,360
one Pikul parameters now in our

00:13:45,810 --> 00:13:50,730
application has to restore state so it

00:13:48,360 --> 00:13:54,740
kids keeps things in pickles it also

00:13:50,730 --> 00:13:56,639
uses pickle to do it's it's MPI

00:13:54,740 --> 00:13:59,430
synchronization so we have large data

00:13:56,639 --> 00:14:02,130
structures in lists and arrays and

00:13:59,430 --> 00:14:05,010
dictionaries and what the the pickle

00:14:02,130 --> 00:14:06,750
thing does it pickles them up sends them

00:14:05,010 --> 00:14:08,480
to the other hosts where their own

00:14:06,750 --> 00:14:10,399
pickled

00:14:08,480 --> 00:14:13,250
that's how we sort of think send things

00:14:10,399 --> 00:14:14,690
around using MPI pickle them up and then

00:14:13,250 --> 00:14:18,769
you say it copy this maybe try the other

00:14:14,690 --> 00:14:20,329
posters over then they'll unpick like so

00:14:18,769 --> 00:14:22,940
you probably familiar so pickle makes a

00:14:20,329 --> 00:14:24,139
by extreme representation of any pretty

00:14:22,940 --> 00:14:26,269
much any Python object which is

00:14:24,139 --> 00:14:27,800
serializable and it puts it into a

00:14:26,269 --> 00:14:30,709
structure then you can unpeople it and

00:14:27,800 --> 00:14:32,810
bring it back out now the default plan

00:14:30,709 --> 00:14:35,810
is for asking storage which is not ideal

00:14:32,810 --> 00:14:37,040
for speed it's also big but you know

00:14:35,810 --> 00:14:38,510
it's a default parameter so if people

00:14:37,040 --> 00:14:40,940
who's not thinking about it I'll just go

00:14:38,510 --> 00:14:42,440
pickle it'll work and I go her a mix

00:14:40,940 --> 00:14:44,600
part and project and they won't think

00:14:42,440 --> 00:14:46,699
about it anymore which is what I do is

00:14:44,600 --> 00:14:49,730
start but people has a protocol

00:14:46,699 --> 00:14:51,050
parameter it's also a sea Python library

00:14:49,730 --> 00:14:52,790
which is often mentioned but if you've

00:14:51,050 --> 00:14:53,839
got bit of a card working just keep guy

00:14:52,790 --> 00:14:55,910
he won't think about it

00:14:53,839 --> 00:15:01,779
because it's work so what do you care

00:14:55,910 --> 00:15:05,440
there's now I've got an example we go

00:15:01,779 --> 00:15:12,019
oops not that one this is probably work

00:15:05,440 --> 00:15:16,130
so let's just run that okay so what do

00:15:12,019 --> 00:15:18,949
you got I've got two million items and

00:15:16,130 --> 00:15:20,510
making a pickle a time believes

00:15:18,949 --> 00:15:24,980
beforehand I should only take about 30

00:15:20,510 --> 00:15:26,390
seconds to run each example you know but

00:15:24,980 --> 00:15:30,140
you know presentations everything slows

00:15:26,390 --> 00:15:31,430
down the internet goes away and when

00:15:30,140 --> 00:15:33,170
you're up here you know time time

00:15:31,430 --> 00:15:37,779
accelerates have you ever noticed that

00:15:33,170 --> 00:15:40,279
if you're doing a presentation come on

00:15:37,779 --> 00:15:43,390
our board is completed to play World of

00:15:40,279 --> 00:15:43,390
Tanks so it should be fast

00:15:49,959 --> 00:15:55,160
okay

00:15:51,220 --> 00:15:57,229
well well that's ready okay so what he

00:15:55,160 --> 00:16:00,189
asked what do we set the protocol to so

00:15:57,229 --> 00:16:03,100
we'll have a look at this source code oh

00:16:00,189 --> 00:16:06,709
my god team is I have to speed up okay

00:16:03,100 --> 00:16:12,289
ten whatever okay so you go down here

00:16:06,709 --> 00:16:16,479
you look at your pickle I've got C

00:16:12,289 --> 00:16:18,829
pickle just pickle and this one you got

00:16:16,479 --> 00:16:20,449
particle equals pickle highest protocol

00:16:18,829 --> 00:16:22,329
see if you do that a little minute you

00:16:20,449 --> 00:16:24,229
pick up the fastest most efficient one

00:16:22,329 --> 00:16:25,850
so that's what you do but you gotta

00:16:24,229 --> 00:16:27,379
remember when young people in I don't

00:16:25,850 --> 00:16:31,729
know if it works it out or not Korean

00:16:27,379 --> 00:16:32,989
but then we go back to our example you

00:16:31,729 --> 00:16:35,199
know whatever got chewed off splotches

00:16:32,989 --> 00:16:38,809
just to confuse me so there we go see

00:16:35,199 --> 00:16:41,059
ordinary pickle 50 seconds see pickle

00:16:38,809 --> 00:16:43,339
seven seconds pickle ladders protocol

00:16:41,059 --> 00:16:46,970
one second you'll reduce the time you

00:16:43,339 --> 00:16:49,039
have taken to store your data to 150th

00:16:46,970 --> 00:16:51,379
of the time just by changing your

00:16:49,039 --> 00:16:52,579
protocol a parameter and including a

00:16:51,379 --> 00:16:53,779
different standard light which works

00:16:52,579 --> 00:16:57,439
exactly the same as the other standard

00:16:53,779 --> 00:17:04,539
library oops

00:16:57,439 --> 00:17:04,539
I wouldn't notice the wrong one

00:17:06,370 --> 00:17:13,990
it's this one here we go next one shelf

00:17:09,730 --> 00:17:16,449
parameters now shelf is like a lot a

00:17:13,990 --> 00:17:19,150
dictionary which lives on disk it uses

00:17:16,449 --> 00:17:20,740
pickle as its protocol for storing

00:17:19,150 --> 00:17:23,559
things at this so if we put a protocol

00:17:20,740 --> 00:17:24,850
parameter onto a shelf we can also we

00:17:23,559 --> 00:17:36,100
can speed things up so I'll just give a

00:17:24,850 --> 00:17:40,120
demo of that she'd also take about 20

00:17:36,100 --> 00:17:42,070
seconds now we use shelves to store

00:17:40,120 --> 00:17:44,200
results of each run so we can compare

00:17:42,070 --> 00:17:47,620
them now before wasn't doing any

00:17:44,200 --> 00:17:51,640
particular protocol so we will still we

00:17:47,620 --> 00:17:55,330
had shelves of for 10 gigabytes which

00:17:51,640 --> 00:17:59,380
take a long time to run so there we go

00:17:55,330 --> 00:18:01,720
21 6 the normal and if things work out

00:17:59,380 --> 00:18:03,730
it's about 5 6 so there you go just by

00:18:01,720 --> 00:18:04,690
changing protocol you can make that part

00:18:03,730 --> 00:18:07,679
of your application

00:18:04,690 --> 00:18:10,090
you know completing quarter of a time

00:18:07,679 --> 00:18:12,340
and you give right now to 100 gigabyte

00:18:10,090 --> 00:18:14,950
or a 10 gigabyte file which takes 20

00:18:12,340 --> 00:18:18,909
minutes or an hour the court of a time

00:18:14,950 --> 00:18:20,440
you know it really adds up ok it's the

00:18:18,909 --> 00:18:22,630
next one you can do its file having

00:18:20,440 --> 00:18:27,820
techniques now we now process we have

00:18:22,630 --> 00:18:29,620
data files millions of lines long and it

00:18:27,820 --> 00:18:32,520
was just using Python red line right

00:18:29,620 --> 00:18:35,919
line ruling line so what we do just by

00:18:32,520 --> 00:18:39,100
changing the few parameters you can

00:18:35,919 --> 00:18:47,490
speed things up so let's have a look at

00:18:39,100 --> 00:18:47,490
the code for a second alright okay

00:18:48,349 --> 00:18:55,649
so just naively where we are we could

00:18:53,700 --> 00:18:57,509
just do a bit of code like this so we

00:18:55,649 --> 00:18:59,359
just read a line load of line then right

00:18:57,509 --> 00:19:01,379
now obviously they're better ways to

00:18:59,359 --> 00:19:03,899
write but you might be doing some

00:19:01,379 --> 00:19:07,289
processing in the middle then we've got

00:19:03,899 --> 00:19:10,080
that one now you can also do perhaps you

00:19:07,289 --> 00:19:11,669
can read a line right to a bit of memory

00:19:10,080 --> 00:19:15,479
and then write it all out in a big blob

00:19:11,669 --> 00:19:19,309
or you could read it all in in a big

00:19:15,479 --> 00:19:21,869
blob and write out in the big blob or

00:19:19,309 --> 00:19:24,329
finally you can read it all in in a big

00:19:21,869 --> 00:19:25,999
blob as a memory map fast this is an

00:19:24,329 --> 00:19:29,190
example of memory mapped file in here

00:19:25,999 --> 00:19:32,549
just do that and that will make that the

00:19:29,190 --> 00:19:34,950
file appear like it's a a big string and

00:19:32,549 --> 00:19:36,690
they can do python slicing and all sorts

00:19:34,950 --> 00:19:39,479
of string operations on it and it sort

00:19:36,690 --> 00:19:40,859
of maps it in the virtual memory so it's

00:19:39,479 --> 00:19:43,109
dramatic how quickly have much

00:19:40,859 --> 00:19:52,289
difference it makes so we go look at a

00:19:43,109 --> 00:19:55,649
demo whoopsie so here I've got about

00:19:52,289 --> 00:20:03,869
four 10 megabyte files I'm adding

00:19:55,649 --> 00:20:09,149
together yeah maybe should have made

00:20:03,869 --> 00:20:10,559
these demos a little bit quicker yeah

00:20:09,149 --> 00:20:12,239
it's not it's not so exciting watching

00:20:10,559 --> 00:20:13,109
nothing happen but the course just gets

00:20:12,239 --> 00:20:14,309
speed up you have to remove the

00:20:13,109 --> 00:20:15,690
debugging otherwise you could say

00:20:14,309 --> 00:20:18,479
reading line one reading line - Greg

00:20:15,690 --> 00:20:20,190
what do I want for life are you ever

00:20:18,479 --> 00:20:22,889
tempted to do that don't do that because

00:20:20,190 --> 00:20:25,559
it's that's wrong even though it's

00:20:22,889 --> 00:20:27,179
comforting ok so we go so we do the

00:20:25,559 --> 00:20:31,019
first sort of naive Lea one line by line

00:20:27,179 --> 00:20:34,139
and you get 26 seconds and 7 megabits

00:20:31,019 --> 00:20:37,619
megabytes a second now should be getting

00:20:34,139 --> 00:20:41,329
faster so the little cursor should go

00:20:37,619 --> 00:20:43,559
away soon here we go we didn't you know

00:20:41,329 --> 00:20:45,389
running out reading lines brought out by

00:20:43,559 --> 00:20:45,919
blocks that's a bit faster that's pretty

00:20:45,389 --> 00:20:48,419
good

00:20:45,919 --> 00:20:49,739
cuz that when we finished doing it okay

00:20:48,419 --> 00:20:52,649
reading a block right out by block

00:20:49,739 --> 00:20:53,969
that's that's a lot better we were in

00:20:52,649 --> 00:20:58,409
your block and loaded up with a memory

00:20:53,969 --> 00:21:00,210
map module there you go that's 1/6 of

00:20:58,409 --> 00:21:03,499
the time isn't it No

00:21:00,210 --> 00:21:10,169
all right no 26 divided by 4 that's

00:21:03,499 --> 00:21:12,539
pretty good okay okay next one okay I

00:21:10,169 --> 00:21:15,059
showed you that one okay here your local

00:21:12,539 --> 00:21:19,110
glue is global this is a silly python

00:21:15,059 --> 00:21:20,879
trick that you often see but you don't

00:21:19,110 --> 00:21:22,559
realize the effect of it so what you can

00:21:20,879 --> 00:21:24,419
do the way that Python looks up things

00:21:22,559 --> 00:21:26,220
it looks at in first if it's in a local

00:21:24,419 --> 00:21:28,200
list of functions it looks in a global

00:21:26,220 --> 00:21:31,919
list and every time you call it it does

00:21:28,200 --> 00:21:33,210
that so what you can do is if you've got

00:21:31,919 --> 00:21:34,980
a function which is one of the built-in

00:21:33,210 --> 00:21:36,990
functions like a max you can make it

00:21:34,980 --> 00:21:39,269
into a local maximum is a local minimum

00:21:36,990 --> 00:21:41,159
and that way instead of looking it up in

00:21:39,269 --> 00:21:42,480
the global list it looks something the

00:21:41,159 --> 00:21:53,340
local list it's faster so let's have a

00:21:42,480 --> 00:21:57,509
look at the demo that okay so we're

00:21:53,340 --> 00:22:00,869
gonna do this 1 million times so you go

00:21:57,509 --> 00:22:02,190
that's the global one that's the local

00:22:00,869 --> 00:22:04,470
one night you see there's a difference

00:22:02,190 --> 00:22:06,869
this little tiny difference if you're

00:22:04,470 --> 00:22:09,450
doing that 400 fillion times that really

00:22:06,869 --> 00:22:14,929
adds up see that's just silly Python

00:22:09,450 --> 00:22:17,190
tree okay okay so that's a good one and

00:22:14,929 --> 00:22:19,769
now this first addiction this is an

00:22:17,190 --> 00:22:22,200
interesting one where if you don't

00:22:19,769 --> 00:22:24,360
choose the right collection size you can

00:22:22,200 --> 00:22:25,590
you can things work perfectly when

00:22:24,360 --> 00:22:27,389
you've got little mouse data but if you

00:22:25,590 --> 00:22:29,759
get big amounts of data it can quickly

00:22:27,389 --> 00:22:31,499
go bad so when you're trying to if you

00:22:29,759 --> 00:22:33,389
wanna you have borrow a list of numbers

00:22:31,499 --> 00:22:34,710
and you want say is this number I've

00:22:33,389 --> 00:22:35,759
already seen it is this number already

00:22:34,710 --> 00:22:37,320
seen that have approached this number

00:22:35,759 --> 00:22:38,580
you might put it in the list because

00:22:37,320 --> 00:22:41,519
that makes sense you put lists even

00:22:38,580 --> 00:22:47,090
numbers in the list so what what happens

00:22:41,519 --> 00:22:47,090
if you do that okay

00:22:47,779 --> 00:22:52,259
okay so here we go first all you've got

00:22:50,850 --> 00:22:54,269
a hundred items you list and the first

00:22:52,259 --> 00:22:58,110
number is a list and the second number

00:22:54,269 --> 00:23:02,190
is addiction is a dictionary got 200

00:22:58,110 --> 00:23:05,100
items 304 and 1000s point to come down

00:23:02,190 --> 00:23:08,039
ten thousand is one point nine hundred

00:23:05,100 --> 00:23:10,019
thousand two hundred thousand so you're

00:23:08,039 --> 00:23:12,330
sort of going it's going up in

00:23:10,019 --> 00:23:13,560
accordance with the size of the list or

00:23:12,330 --> 00:23:16,170
the dictionary they

00:23:13,560 --> 00:23:19,680
every time we search a dictionary this

00:23:16,170 --> 00:23:20,970
time is zero so if you can just look in

00:23:19,680 --> 00:23:22,890
your code to see whether you use a list

00:23:20,970 --> 00:23:24,930
just take it out and use the dictionary

00:23:22,890 --> 00:23:26,850
because they're pretty much operate and

00:23:24,930 --> 00:23:28,230
match the same way and dictionary takes

00:23:26,850 --> 00:23:30,960
up a little bit more Mary but it doesn't

00:23:28,230 --> 00:23:33,090
make much difference so I wrote a little

00:23:30,960 --> 00:23:34,650
bit of code not even I test without with

00:23:33,090 --> 00:23:36,600
a faster way it works perfectly fine

00:23:34,650 --> 00:23:38,430
didn't notice it but then we can put

00:23:36,600 --> 00:23:41,220
into production and we're doing four

00:23:38,430 --> 00:23:44,040
hundred thousand 1 million and he said

00:23:41,220 --> 00:23:45,620
oh the server crashed got this point in

00:23:44,040 --> 00:23:47,760
it crash it just stopped nothing working

00:23:45,620 --> 00:23:50,190
of course it wasn't crash it was just

00:23:47,760 --> 00:23:53,040
sitting there going through a ten Ling

00:23:50,190 --> 00:23:54,900
and line list looking for one number and

00:23:53,040 --> 00:23:58,110
we just looked at that and I go bang

00:23:54,900 --> 00:23:59,040
ahead changed around we went from ten

00:23:58,110 --> 00:24:05,190
minutes sitting there doing nothing to

00:23:59,040 --> 00:24:07,800
zero okay what's the next one okay this

00:24:05,190 --> 00:24:09,090
is a little bit more complicated so see

00:24:07,800 --> 00:24:11,340
libraries and there's another

00:24:09,090 --> 00:24:14,220
presentation yesterday where you can use

00:24:11,340 --> 00:24:16,320
the C types package to look up any to

00:24:14,220 --> 00:24:17,940
see live but it's already existing well

00:24:16,320 --> 00:24:23,070
you also can do is you can write your

00:24:17,940 --> 00:24:24,510
own C library to do things okay so let's

00:24:23,070 --> 00:24:33,710
have a look at a bit of bit of simple

00:24:24,510 --> 00:24:33,710
code here findings

00:24:34,610 --> 00:24:40,490
okay so this is a example card so we've

00:24:38,929 --> 00:24:43,750
got a silly operation where it doesn't

00:24:40,490 --> 00:24:46,429
adds up all the ASCII values of a string

00:24:43,750 --> 00:24:49,520
so I wrote another one called multiplied

00:24:46,429 --> 00:24:52,220
deal which has that similar function but

00:24:49,520 --> 00:24:55,809
in C so we have a look at that and the

00:24:52,220 --> 00:24:59,900
cutters here go see something with a C

00:24:55,809 --> 00:25:01,700
extension oh there it is okay so then we

00:24:59,900 --> 00:25:04,549
just do like this it says all you need

00:25:01,700 --> 00:25:05,150
to write in Visual Studio it's it's

00:25:04,549 --> 00:25:06,530
trivial

00:25:05,150 --> 00:25:10,600
they were just doing exactly the same

00:25:06,530 --> 00:25:10,600
thing in C so what's going to happen

00:25:15,820 --> 00:25:18,820
stop

00:25:25,299 --> 00:25:31,400
okay so we're gonna look add up I think

00:25:29,240 --> 00:25:32,480
it's a very big string add up all the

00:25:31,400 --> 00:25:34,910
ASCII values I'm gonna do that twenty

00:25:32,480 --> 00:25:39,950
thousand times hey it's another one of

00:25:34,910 --> 00:25:42,580
my programs okay see here you need

00:25:39,950 --> 00:25:46,390
to twenty thousand took twelve seconds

00:25:42,580 --> 00:25:49,299
but the DLL look point zero one second

00:25:46,390 --> 00:25:51,320
so it's a hundred times faster and

00:25:49,299 --> 00:25:53,809
writing a deal like that could have

00:25:51,320 --> 00:25:55,100
taken you maybe half an hour and the

00:25:53,809 --> 00:25:58,220
biggest amount of time would be waiting

00:25:55,100 --> 00:25:59,630
for Visual Studio to load and the second

00:25:58,220 --> 00:26:05,510
biggest time was to try and find out

00:25:59,630 --> 00:26:07,820
where I put the DLL so with a simple

00:26:05,510 --> 00:26:10,250
little bit of logic changing from one

00:26:07,820 --> 00:26:11,540
language to another making the DLL 100

00:26:10,250 --> 00:26:13,309
times faster so we had one particular

00:26:11,540 --> 00:26:16,669
function it in this thing which would

00:26:13,309 --> 00:26:19,160
calc take two names and compare them and

00:26:16,669 --> 00:26:22,400
give you a number about how close those

00:26:19,160 --> 00:26:26,179
two names were together and I changed

00:26:22,400 --> 00:26:27,410
that to a DLL and that took 30% off time

00:26:26,179 --> 00:26:29,809
the things and that was being called

00:26:27,410 --> 00:26:32,090
every time we did a record it was being

00:26:29,809 --> 00:26:33,890
cold millions and millions of times so

00:26:32,090 --> 00:26:35,809
you could look at you you're profiling

00:26:33,890 --> 00:26:38,299
look at to see where things are going a

00:26:35,809 --> 00:26:40,490
little bit going there and you can

00:26:38,299 --> 00:26:43,280
really with a little bit of work you can

00:26:40,490 --> 00:26:46,640
make things a hundred times better now

00:26:43,280 --> 00:26:51,890
that's pretty good we all know si don't

00:26:46,640 --> 00:26:55,900
we because part is written C and we all

00:26:51,890 --> 00:26:55,900
build Python from the source don't we

00:26:58,330 --> 00:27:05,660
okay so there we go and I think that's

00:27:02,690 --> 00:27:07,580
the main things that I've done you just

00:27:05,660 --> 00:27:09,770
do some simple things changing protocols

00:27:07,580 --> 00:27:12,410
changing parameters changing language

00:27:09,770 --> 00:27:18,549
use you get things going a lot faster

00:27:12,410 --> 00:27:18,549
with little effort okay

00:27:22,630 --> 00:27:29,990
so we have a few minutes for questions

00:27:25,100 --> 00:27:31,940
anyone's thanks that was a great talk I

00:27:29,990 --> 00:27:33,170
just want to quickly add with the list

00:27:31,940 --> 00:27:35,840
versus dictionary thing that you could

00:27:33,170 --> 00:27:37,430
also use a set and that's the same the

00:27:35,840 --> 00:27:44,870
same performance as a dictionary at

00:27:37,430 --> 00:27:46,550
slightly different semantics so I have a

00:27:44,870 --> 00:27:47,809
question about the farm going through

00:27:46,550 --> 00:27:49,130
that large well you've got the only got

00:27:47,809 --> 00:27:50,929
small files oh so I have a situation

00:27:49,130 --> 00:27:52,850
overall like a two year right file yeah

00:27:50,929 --> 00:27:55,070
and so like you've got examples there

00:27:52,850 --> 00:27:56,510
where you're doing it like not a very

00:27:55,070 --> 00:27:57,970
pythonic way and like kind of there's

00:27:56,510 --> 00:28:00,830
another way to do which is you just go

00:27:57,970 --> 00:28:03,050
basically you just go open the file and

00:28:00,830 --> 00:28:04,670
just go full line in file and you just

00:28:03,050 --> 00:28:05,840
go through it that way and I don't know

00:28:04,670 --> 00:28:07,460
what performance difference it is for

00:28:05,840 --> 00:28:08,870
the demo file or not but I'll just

00:28:07,460 --> 00:28:11,150
measure to see if you've tried that

00:28:08,870 --> 00:28:13,760
just out of interest let's have a look

00:28:11,150 --> 00:28:15,440
okay he's a code there's a number of

00:28:13,760 --> 00:28:19,940
ways you can you can read files in

00:28:15,440 --> 00:28:23,990
Python if we go up the top here the very

00:28:19,940 --> 00:28:25,700
simplest way is to do like this we've

00:28:23,990 --> 00:28:26,750
open and right they didn't tell you that

00:28:25,700 --> 00:28:28,670
because that was quicker than the other

00:28:26,750 --> 00:28:32,690
way I did it so that would ruin my whole

00:28:28,670 --> 00:28:35,690
theory but the reason you coffin can't

00:28:32,690 --> 00:28:38,480
do this is if you've got a 10 gigabyte

00:28:35,690 --> 00:28:40,460
file and you've got 2 gigabytes of

00:28:38,480 --> 00:28:41,929
memory you can't because it tries to

00:28:40,460 --> 00:28:45,770
read all in memory as far as I'm aware

00:28:41,929 --> 00:28:49,540
so you can't do that so we were

00:28:45,770 --> 00:28:52,580
operating you giant files and each

00:28:49,540 --> 00:28:53,750
processing core has to read the files so

00:28:52,580 --> 00:28:57,559
that's the other thing would be careful

00:28:53,750 --> 00:29:00,290
the MPI every process shares it's

00:28:57,559 --> 00:29:01,910
exactly the same memory she be writing

00:29:00,290 --> 00:29:03,770
the processor takes one gigabyte you run

00:29:01,910 --> 00:29:05,870
on one call and he said I'll let's make

00:29:03,770 --> 00:29:08,480
it fast with maker than 10 cores what

00:29:05,870 --> 00:29:10,160
happens he's now you've got 10 gigabytes

00:29:08,480 --> 00:29:12,290
because we've got one gigabyte per call

00:29:10,160 --> 00:29:14,809
so might work finding your two gigabyte

00:29:12,290 --> 00:29:16,760
server putting the MPI and then it goes

00:29:14,809 --> 00:29:18,800
oh why is it going slow it should go 10

00:29:16,760 --> 00:29:21,440
times faster that's cuz it's just all

00:29:18,800 --> 00:29:23,030
the memories are taken up and Python

00:29:21,440 --> 00:29:26,620
just tends to crash when it runs out of

00:29:23,030 --> 00:29:28,090
memory it's not special pricing

00:29:26,620 --> 00:29:30,670
okay now I'm going to make another

00:29:28,090 --> 00:29:32,770
example which might show you a little

00:29:30,670 --> 00:29:34,920
bit a little bit more complex where is

00:29:32,770 --> 00:29:34,920
it

00:29:38,110 --> 00:29:43,900
I've got a couple of them when is it a

00:29:40,520 --> 00:29:43,900
captain what's cold now

00:29:48,160 --> 00:30:02,470
oops okay so we got and went up here so

00:30:00,860 --> 00:30:08,930
this is the multiprocessing

00:30:02,470 --> 00:30:11,660
version of counting loans in a file now

00:30:08,930 --> 00:30:15,140
you can't just go read right when you're

00:30:11,660 --> 00:30:16,250
carrying lines of file solve some bit

00:30:15,140 --> 00:30:18,680
strange some people like to know how

00:30:16,250 --> 00:30:20,240
many lines in the file cuz so all they

00:30:18,680 --> 00:30:21,440
might say I want to know how many lines

00:30:20,240 --> 00:30:23,000
are follow the dough how long it takes

00:30:21,440 --> 00:30:24,470
so I'll spin them out counting all the

00:30:23,000 --> 00:30:27,110
lines in the file so then I can know how

00:30:24,470 --> 00:30:29,059
long it's going to take when I'm first

00:30:27,110 --> 00:30:30,320
with you but that's alright so we had a

00:30:29,059 --> 00:30:32,000
bit of code in here which checks the

00:30:30,320 --> 00:30:33,290
lines of cars because they correspond to

00:30:32,000 --> 00:30:34,700
records so you want to know what's the

00:30:33,290 --> 00:30:37,309
maximum record number that's the line

00:30:34,700 --> 00:30:40,490
fault so here you go multi one

00:30:37,309 --> 00:30:42,440
yes I know this is afraid of program

00:30:40,490 --> 00:30:46,429
because I get our açaí so tells me that

00:30:42,440 --> 00:30:48,260
we're still yelling okay so here we go

00:30:46,429 --> 00:30:51,710
what we want to do is we count the

00:30:48,260 --> 00:30:54,110
number of CPUs here and then we create

00:30:51,710 --> 00:30:57,880
queues for each process and we may put

00:30:54,110 --> 00:31:00,140
them all make a queue put in the queue

00:30:57,880 --> 00:31:03,710
dictionary we've got a list that's a

00:31:00,140 --> 00:31:06,800
list and then we call the function using

00:31:03,710 --> 00:31:10,220
the multiplexing process function so

00:31:06,800 --> 00:31:13,790
while it does we come into this function

00:31:10,220 --> 00:31:16,820
up here and then it opens up the file

00:31:13,790 --> 00:31:19,760
memory map file works how the file size

00:31:16,820 --> 00:31:23,690
is then it decides which part of the

00:31:19,760 --> 00:31:27,410
file it will count the lines in and then

00:31:23,690 --> 00:31:29,809
you just wobble through there and read

00:31:27,410 --> 00:31:31,460
each line tell you the other process

00:31:29,809 --> 00:31:36,490
where you are and you add up and you

00:31:31,460 --> 00:31:38,750
read them up in and we have an arrest

00:31:36,490 --> 00:31:39,410
and I think that's the end of my time

00:31:38,750 --> 00:31:44,000
isn't it

00:31:39,410 --> 00:31:46,970
ok so we have a pike on mug and I a

00:31:44,000 --> 00:31:51,190
blend of African swallow for you so

00:31:46,970 --> 00:31:51,190

YouTube URL: https://www.youtube.com/watch?v=pBF3dKrVhxQ


