Title: Big data with python
Publication date: 2012-08-23
Playlist: PyCon Australia 2012
Description: 
	Alex Sharp
Dealing with big data isn't a particularly new problem. There are all sorts of new solutions, each with their own niche, their own hype. It's important to remember that python is not "too slow" for big data, and that with projects such as
Captions: 
	00:00:01,310 --> 00:00:09,780
Hey look hey everyone so and I said

00:00:07,859 --> 00:00:11,610
before I'm Alec sharp I'm from Ryan vm

00:00:09,780 --> 00:00:16,020
just quick show of hands who's heard of

00:00:11,610 --> 00:00:19,140
us okay um so we're a sponsor of the

00:00:16,020 --> 00:00:20,789
event amongst other things everyone here

00:00:19,140 --> 00:00:23,100
gets I think a hundred bucks with a free

00:00:20,789 --> 00:00:25,590
credit just for being here we also

00:00:23,100 --> 00:00:29,160
sponsored code Wars and a few other

00:00:25,590 --> 00:00:31,199
things but long story short around vm is

00:00:29,160 --> 00:00:33,329
an engineering organization we're cool

00:00:31,199 --> 00:00:35,969
because we turn supercomputing tech and

00:00:33,329 --> 00:00:37,829
we actually turn it into a cloud so we

00:00:35,969 --> 00:00:39,270
had to play around with terabytes worth

00:00:37,829 --> 00:00:43,469
the switching and petabytes with the

00:00:39,270 --> 00:00:45,750
storage and we yeah it's a really cool

00:00:43,469 --> 00:00:49,680
job although you could say I'm slightly

00:00:45,750 --> 00:00:52,140
biased giving them a founder but anyways

00:00:49,680 --> 00:00:55,860
so this is the talks called big data and

00:00:52,140 --> 00:00:57,930
Python now just to preempt a few

00:00:55,860 --> 00:01:00,449
questions you'll notice that there isn't

00:00:57,930 --> 00:01:02,850
actually any Python code in this talk

00:01:00,449 --> 00:01:05,850
that's because there was initially

00:01:02,850 --> 00:01:07,290
Python code however when I was going

00:01:05,850 --> 00:01:09,570
through a while I was doing it I want to

00:01:07,290 --> 00:01:11,159
start off and you just like so am I

00:01:09,570 --> 00:01:13,710
going to go through and do it standard

00:01:11,159 --> 00:01:15,479
sort of talk with disco and MapReduce

00:01:13,710 --> 00:01:17,759
and I said well I'm going to move bit

00:01:15,479 --> 00:01:20,280
back a bit further back and I'm going to

00:01:17,759 --> 00:01:22,110
show something that's hopefully a little

00:01:20,280 --> 00:01:25,380
more interesting to you guys so first

00:01:22,110 --> 00:01:27,420
off what is big data it's been hyped it

00:01:25,380 --> 00:01:30,540
means it can mean almost whatever you

00:01:27,420 --> 00:01:33,060
feel like so things like page rank which

00:01:30,540 --> 00:01:36,090
is by the way damn cool who is read the

00:01:33,060 --> 00:01:38,670
paper pagerank paper yeah it's

00:01:36,090 --> 00:01:42,110
essentially how do you how do you win it

00:01:38,670 --> 00:01:44,820
searching by finding the eigen values of

00:01:42,110 --> 00:01:46,409
squillion basically in matrix it's

00:01:44,820 --> 00:01:48,270
really kind of cool to work out how it

00:01:46,409 --> 00:01:50,130
goes from cure mats to something

00:01:48,270 --> 00:01:52,320
something very real in much the same way

00:01:50,130 --> 00:01:55,140
I say nuclear Sims you can't say that

00:01:52,320 --> 00:01:59,490
LOL is class start is not a big data job

00:01:55,140 --> 00:02:01,700
like it's pretty huge however the bit

00:01:59,490 --> 00:02:04,860
that I'm going to start off with is

00:02:01,700 --> 00:02:07,560
essentially i'm going over a few papers

00:02:04,860 --> 00:02:10,229
that were published I'm not naming names

00:02:07,560 --> 00:02:12,550
here however if you're interested come

00:02:10,229 --> 00:02:15,910
talk to me after i'll show them to

00:02:12,550 --> 00:02:19,030
the main job well just go back a little

00:02:15,910 --> 00:02:21,850
bit data analysis at scale is where you

00:02:19,030 --> 00:02:23,800
see lots of big data jobs things like

00:02:21,850 --> 00:02:25,510
facebook facebook really cares who you

00:02:23,800 --> 00:02:27,490
are Facebook really cares who your real

00:02:25,510 --> 00:02:30,120
friends are no your facebook friends cuz

00:02:27,490 --> 00:02:33,880
even they know they're not real friends

00:02:30,120 --> 00:02:35,080
similarly for example Google like you

00:02:33,880 --> 00:02:37,180
might be known under a whole bunch of

00:02:35,080 --> 00:02:39,160
pseudonyms but working out who is the

00:02:37,180 --> 00:02:41,470
same persons very interesting piece of

00:02:39,160 --> 00:02:43,300
information however a bit that I'm going

00:02:41,470 --> 00:02:46,030
to go through and show is a really cool

00:02:43,300 --> 00:02:48,010
one and it's I you a telemarketer now

00:02:46,030 --> 00:02:50,920
you might go through and say well wait

00:02:48,010 --> 00:02:52,410
what but this is a very important piece

00:02:50,920 --> 00:02:55,840
of information because telemarketers

00:02:52,410 --> 00:02:58,570
well they're horrible I'm not not not

00:02:55,840 --> 00:03:00,700
put too fine a point on it but for the

00:02:58,570 --> 00:03:02,230
big telcos they go through and they they

00:03:00,700 --> 00:03:04,240
cause lots of abuse complaints and all

00:03:02,230 --> 00:03:07,840
the rest so finding them is a big

00:03:04,240 --> 00:03:11,410
challenge so big data data analysis at

00:03:07,840 --> 00:03:13,840
scale you're a giant telco you're trying

00:03:11,410 --> 00:03:15,670
to answer a very simple question in a

00:03:13,840 --> 00:03:17,800
very restricted domain very very

00:03:15,670 --> 00:03:20,020
restricted domain you know your data is

00:03:17,800 --> 00:03:22,390
looking like coming in and you're trying

00:03:20,020 --> 00:03:23,920
to do it what you're trying to do it

00:03:22,390 --> 00:03:26,350
well enough they are not going to go

00:03:23,920 --> 00:03:28,780
bankrupt trying to do it which is in

00:03:26,350 --> 00:03:30,910
some ways rather hard so in this case

00:03:28,780 --> 00:03:33,070
are you telling market on and the thing

00:03:30,910 --> 00:03:35,200
I'm going to be explaining is well to to

00:03:33,070 --> 00:03:36,880
really interesting algorithms for one

00:03:35,200 --> 00:03:39,370
County how many people you've called and

00:03:36,880 --> 00:03:43,090
to how many people you've called and I

00:03:39,370 --> 00:03:45,010
do this without using a counter so think

00:03:43,090 --> 00:03:47,860
about that for a second and yes it's

00:03:45,010 --> 00:03:50,440
tender domain um in this case it big

00:03:47,860 --> 00:03:51,910
telcos doing this so I need across all

00:03:50,440 --> 00:03:55,810
that school ians of users they're doing

00:03:51,910 --> 00:03:57,100
on embedded hardware and yeah so and at

00:03:55,810 --> 00:03:59,530
the end of the day this needs to be done

00:03:57,100 --> 00:04:01,300
cheaply because otherwise it can it's

00:03:59,530 --> 00:04:02,709
just cheaper to just not use the

00:04:01,300 --> 00:04:07,930
information at all and just deal with

00:04:02,709 --> 00:04:09,640
the day abuse first things first a very

00:04:07,930 --> 00:04:12,459
important thing about big data is you

00:04:09,640 --> 00:04:14,140
need to know your distributions so I'm

00:04:12,459 --> 00:04:17,140
kind of sorry but they there will be

00:04:14,140 --> 00:04:18,850
some maths in here there's really no way

00:04:17,140 --> 00:04:21,880
to get around it because a very mad

00:04:18,850 --> 00:04:25,919
heavy subject so this is a pre

00:04:21,880 --> 00:04:29,349
distribution it i use is just a general

00:04:25,919 --> 00:04:32,560
so there are the distribution to look

00:04:29,349 --> 00:04:35,039
like this we're like for example if

00:04:32,560 --> 00:04:40,000
you're looking at a number of be like

00:04:35,039 --> 00:04:42,099
number of our people okay I really

00:04:40,000 --> 00:04:43,539
should bro laser pointer but number of

00:04:42,099 --> 00:04:45,789
people that someone is calling and

00:04:43,539 --> 00:04:47,530
percent are so you'll find there are

00:04:45,789 --> 00:04:50,889
some people who call absolutely everyone

00:04:47,530 --> 00:04:52,689
and most people call no one this is very

00:04:50,889 --> 00:04:56,289
common you see this all the time you see

00:04:52,689 --> 00:04:58,240
it and say in big networks there's all

00:04:56,289 --> 00:05:00,550
of the so everyone song to Google been

00:04:58,240 --> 00:05:03,879
on song to my website common common sort

00:05:00,550 --> 00:05:04,990
of problem but knowing the distributions

00:05:03,879 --> 00:05:06,969
then means that you can make all sorts

00:05:04,990 --> 00:05:08,620
of assumptions that will really help you

00:05:06,969 --> 00:05:10,599
are not show I'll show it later on with

00:05:08,620 --> 00:05:13,419
a really cool paper by actually will

00:05:10,599 --> 00:05:17,259
name this one google at the end this is

00:05:13,419 --> 00:05:18,729
the other one normal distribution um you

00:05:17,259 --> 00:05:21,879
have to be very careful here because

00:05:18,729 --> 00:05:23,319
okay so here who here knows that if you

00:05:21,879 --> 00:05:25,270
average a whole bunch of numbers they

00:05:23,319 --> 00:05:28,090
eventually become normal who is done

00:05:25,270 --> 00:05:30,759
like basic stats okay you need to be

00:05:28,090 --> 00:05:32,440
very careful with what numbers you're

00:05:30,759 --> 00:05:34,750
averaging because otherwise you end up

00:05:32,440 --> 00:05:36,310
with some very interesting results that

00:05:34,750 --> 00:05:38,669
being said normal distributions are

00:05:36,310 --> 00:05:41,680
awesome and they are your friend and

00:05:38,669 --> 00:05:46,330
certainly my friend many ways it's okay

00:05:41,680 --> 00:05:47,589
so first thing now okay first off who

00:05:46,330 --> 00:05:52,990
noticed that this thing doesn't actually

00:05:47,589 --> 00:05:55,629
have a counter okay wait okay there is

00:05:52,990 --> 00:05:57,969
no like 10 its standard example use

00:05:55,629 --> 00:05:59,740
memcached or whatever you pull in a

00:05:57,969 --> 00:06:01,060
value you increment the value and you

00:05:59,740 --> 00:06:02,949
write it back out that that's the way

00:06:01,060 --> 00:06:05,529
you do a count up right like that's the

00:06:02,949 --> 00:06:07,810
canonical standard way of doing this the

00:06:05,529 --> 00:06:09,939
problem is if you're going through and

00:06:07,810 --> 00:06:11,560
doing this like if i read this counter

00:06:09,939 --> 00:06:13,810
and then someone else reads this counter

00:06:11,560 --> 00:06:15,250
then you can end up with us both try and

00:06:13,810 --> 00:06:17,469
ride at the same time you have raised

00:06:15,250 --> 00:06:19,810
conditions and if you try to solve the

00:06:17,469 --> 00:06:22,000
race conditions then you end up with

00:06:19,810 --> 00:06:24,430
other concurrency issues you have

00:06:22,000 --> 00:06:26,889
problems scaling it out and it's just

00:06:24,430 --> 00:06:29,319
generally really hard on your actual

00:06:26,889 --> 00:06:31,599
data stores you have all sorts of really

00:06:29,319 --> 00:06:34,849
nasty problems so you have things like

00:06:31,599 --> 00:06:37,759
this so um

00:06:34,849 --> 00:06:39,319
you three take and all the time in Big

00:06:37,759 --> 00:06:41,599
Data by the way you read someone's paper

00:06:39,319 --> 00:06:43,189
and in about four lines i'll go throw

00:06:41,599 --> 00:06:45,379
now sure really easy steps you take a

00:06:43,189 --> 00:06:48,169
look and you're just like i have no idea

00:06:45,379 --> 00:06:50,149
what that guy just did this is this is

00:06:48,169 --> 00:06:52,159
one of those who start off is that to

00:06:50,149 --> 00:06:54,199
some random number count the number of

00:06:52,159 --> 00:06:57,830
leading zeros and keep a track of the

00:06:54,199 --> 00:06:59,809
maximum and you just like how on earth

00:06:57,830 --> 00:07:01,939
does that count the number of things

00:06:59,809 --> 00:07:05,689
like so who's thinking that right now

00:07:01,939 --> 00:07:08,689
how on earth does this work okay it's

00:07:05,689 --> 00:07:11,029
cool so because you're counting number

00:07:08,689 --> 00:07:13,879
of leading zeros so these are all random

00:07:11,029 --> 00:07:16,429
numbers so the chance that the bit right

00:07:13,879 --> 00:07:20,719
at the end is zero is fifty-fifty so

00:07:16,429 --> 00:07:22,819
55th like 50 cent 05 step one same so

00:07:20,719 --> 00:07:26,449
you have a fifty percent chance if you

00:07:22,819 --> 00:07:30,439
just look at one that you'll receive one

00:07:26,449 --> 00:07:31,909
from your from your count similarly the

00:07:30,439 --> 00:07:35,689
probability of there being two leading

00:07:31,909 --> 00:07:39,589
zeros is a cordon three is an a4 is a

00:07:35,689 --> 00:07:41,599
sixteenth and so on and so forth so like

00:07:39,589 --> 00:07:43,279
let me just give you an example if I've

00:07:41,599 --> 00:07:45,169
actually run this algorithm say a

00:07:43,279 --> 00:07:48,319
million times what is the probability

00:07:45,169 --> 00:07:50,479
that i have only ever encountered say

00:07:48,319 --> 00:07:56,930
only one leading zero and the answer is

00:07:50,479 --> 00:07:59,779
it's very very small so yeah it did it's

00:07:56,930 --> 00:08:04,099
a stat tack there you'll see a lot of

00:07:59,779 --> 00:08:05,419
these but in this case you're using the

00:08:04,099 --> 00:08:09,800
fact that all of these things have

00:08:05,419 --> 00:08:12,139
different probabilities to give you the

00:08:09,800 --> 00:08:16,009
data that you need to find very very

00:08:12,139 --> 00:08:18,559
approximately where it goes yeah um oh

00:08:16,009 --> 00:08:19,519
yes yes so you deal with the you do with

00:08:18,559 --> 00:08:22,819
the in a binder in the binary

00:08:19,519 --> 00:08:25,459
representation and use to to the two

00:08:22,819 --> 00:08:28,219
that says the is the estimate now

00:08:25,459 --> 00:08:30,740
generally like to see okay it'll give

00:08:28,219 --> 00:08:32,930
you a actually rather horrible estimate

00:08:30,740 --> 00:08:35,060
if you don't want so you go through and

00:08:32,930 --> 00:08:36,439
you get a whole bunch of them and you

00:08:35,060 --> 00:08:37,899
have rich them because that's what you

00:08:36,439 --> 00:08:40,579
do if you want to make it more out um

00:08:37,899 --> 00:08:43,029
more accurate yeah okay hands up if you

00:08:40,579 --> 00:08:46,230
think averaging is the right thing to do

00:08:43,029 --> 00:08:48,240
good a good good answer

00:08:46,230 --> 00:08:50,790
don't average this you will end up with

00:08:48,240 --> 00:08:53,220
absolutely weird and wonderful answers

00:08:50,790 --> 00:08:55,410
what you need to do if you look at the

00:08:53,220 --> 00:08:57,600
paper you need to take a bias corrected

00:08:55,410 --> 00:09:00,480
harmonic mean which is by the way

00:08:57,600 --> 00:09:02,850
absolutely horrible they have this

00:09:00,480 --> 00:09:04,560
massive formula and all the rest however

00:09:02,850 --> 00:09:08,040
you just take the median which is good

00:09:04,560 --> 00:09:12,120
enough and and bio you see that a lot um

00:09:08,040 --> 00:09:14,370
oh just round thing if you want to troll

00:09:12,120 --> 00:09:18,930
data scientists get into a mean versus

00:09:14,370 --> 00:09:20,520
median to bed just yeah however so

00:09:18,930 --> 00:09:23,430
median is just standard and that's

00:09:20,520 --> 00:09:25,980
simply because when you do this I you

00:09:23,430 --> 00:09:27,540
end up with some some of your estimates

00:09:25,980 --> 00:09:29,340
and up to high some of them end up too

00:09:27,540 --> 00:09:32,490
low and because it's exponentially

00:09:29,340 --> 00:09:36,140
increasing the mean gets waited too far

00:09:32,490 --> 00:09:38,430
based on the very high higher elements

00:09:36,140 --> 00:09:41,370
so it doesn't properly respect him

00:09:38,430 --> 00:09:45,120
harmonic means are a bit better for this

00:09:41,370 --> 00:09:47,820
and the problem is is that as you'll see

00:09:45,120 --> 00:09:49,680
with stats we would say most Lee's Big

00:09:47,820 --> 00:09:51,330
Data things it's usually cheaper to get

00:09:49,680 --> 00:09:53,190
things that are wrong and then make them

00:09:51,330 --> 00:09:54,870
right then you actually get the right

00:09:53,190 --> 00:09:57,420
things in the first place so in this

00:09:54,870 --> 00:09:58,890
case this is a very cheap counter I you

00:09:57,420 --> 00:10:00,870
just need to keep track of a maximum

00:09:58,890 --> 00:10:03,150
which is one of the cheapest operations

00:10:00,870 --> 00:10:05,370
possible you can run on the background

00:10:03,150 --> 00:10:06,870
it's really nice but then you all the

00:10:05,370 --> 00:10:08,580
extra work on the other side actually

00:10:06,870 --> 00:10:10,950
turn the turn turn account is in a

00:10:08,580 --> 00:10:13,170
meaningful data if the really cool thing

00:10:10,950 --> 00:10:17,670
is called FML so method of maximum

00:10:13,170 --> 00:10:19,320
likelihood so harmonic means and all the

00:10:17,670 --> 00:10:22,920
rest okay that those are fairly standard

00:10:19,320 --> 00:10:25,380
things FML is a really cool stats method

00:10:22,920 --> 00:10:28,530
what's essentially so these counters

00:10:25,380 --> 00:10:30,330
have these values well out of all of the

00:10:28,530 --> 00:10:32,250
possible things that I that could have

00:10:30,330 --> 00:10:34,470
happened in the real world what is the

00:10:32,250 --> 00:10:35,820
most likely thing in the real world that

00:10:34,470 --> 00:10:39,260
would cause the counters to have the

00:10:35,820 --> 00:10:41,880
values that they have it's very nice is

00:10:39,260 --> 00:10:45,180
well it's not that horrible but it's

00:10:41,880 --> 00:10:48,360
still horrible to make but if you want

00:10:45,180 --> 00:10:51,270
it for the absolute minimum on sort of

00:10:48,360 --> 00:10:54,600
cost that's what you want same thing I

00:10:51,270 --> 00:10:57,480
mean Inc people have you called okay who

00:10:54,600 --> 00:10:59,370
you know is what a hash function is ok

00:10:57,480 --> 00:11:02,279
for the

00:10:59,370 --> 00:11:03,870
and a half people who haven't a hash

00:11:02,279 --> 00:11:05,940
function like for example hash of the

00:11:03,870 --> 00:11:08,610
person is you take this person and you

00:11:05,940 --> 00:11:10,589
turn them into a random number now just

00:11:08,610 --> 00:11:13,050
a quick question what we're using in the

00:11:10,589 --> 00:11:15,990
last slide we were using random numbers

00:11:13,050 --> 00:11:19,200
yeah yeah because like the first step

00:11:15,990 --> 00:11:20,430
was take a tag around a number so now

00:11:19,200 --> 00:11:23,730
you're saying well how does this work

00:11:20,430 --> 00:11:25,529
with uniques the answer is of course if

00:11:23,730 --> 00:11:29,310
you take a quick look at the previous

00:11:25,529 --> 00:11:31,170
algorithm you will you'll arm you'll

00:11:29,310 --> 00:11:33,089
know that if you run it with the same

00:11:31,170 --> 00:11:35,190
random number twice it can't possibly

00:11:33,089 --> 00:11:37,980
change and the reason that's actually

00:11:35,190 --> 00:11:40,200
fairly simple if I have a number it

00:11:37,980 --> 00:11:42,360
can't suddenly get more leading zeros

00:11:40,200 --> 00:11:45,000
into it be simply because you show it to

00:11:42,360 --> 00:11:47,010
me twice is it well it has that many

00:11:45,000 --> 00:11:51,270
leading zeros that just doesn't happen

00:11:47,010 --> 00:11:56,250
maths don't work that way so because of

00:11:51,270 --> 00:11:58,730
that when you run this using the hash it

00:11:56,250 --> 00:12:01,740
only counts the number of unique people

00:11:58,730 --> 00:12:05,100
which i think is rather quite I I think

00:12:01,740 --> 00:12:06,630
that's cool like a little thing some you

00:12:05,100 --> 00:12:09,480
see lots of things was just like that

00:12:06,630 --> 00:12:11,730
guy has got it figured out like whoever

00:12:09,480 --> 00:12:13,860
came came up with that I'm going to buy

00:12:11,730 --> 00:12:16,980
that guy a beer and a cake because he

00:12:13,860 --> 00:12:19,500
just solved one of my problems um yeah

00:12:16,980 --> 00:12:20,910
so it's unique people and goes the

00:12:19,500 --> 00:12:23,580
problem is then so how do we saw the

00:12:20,910 --> 00:12:26,459
data so this is how many people have you

00:12:23,580 --> 00:12:29,339
called so that is like well there's

00:12:26,459 --> 00:12:32,100
perrito log-normal I'm reasonably sure

00:12:29,339 --> 00:12:34,589
that it's actually something else called

00:12:32,100 --> 00:12:37,279
the simp distribution you should

00:12:34,589 --> 00:12:40,050
wikipedia that it's pretty damn cool

00:12:37,279 --> 00:12:41,910
however they look roughly the same and

00:12:40,050 --> 00:12:42,930
the thing is is that most account is

00:12:41,910 --> 00:12:45,089
going to be an easier because most

00:12:42,930 --> 00:12:48,300
people don't call anyone a sad but true

00:12:45,089 --> 00:12:50,730
fact so if we just saw the same number

00:12:48,300 --> 00:12:51,810
of bits for all of them then all of the

00:12:50,730 --> 00:12:55,140
counting is going to be massively

00:12:51,810 --> 00:12:57,120
oversized yes so well what can we do for

00:12:55,140 --> 00:12:58,620
this like you're not going to store

00:12:57,120 --> 00:13:00,050
stuff and pressed in memory because it's

00:12:58,620 --> 00:13:02,130
really not going to help you that much

00:13:00,050 --> 00:13:05,610
what do you do the answer is of course

00:13:02,130 --> 00:13:08,610
you call Google they like seriously the

00:13:05,610 --> 00:13:11,320
Google guys they know so much but yeah

00:13:08,610 --> 00:13:14,140
now it was only completely different

00:13:11,320 --> 00:13:15,400
unary encoding and you're just like what

00:13:14,140 --> 00:13:17,200
on earth does that have to do with

00:13:15,400 --> 00:13:22,780
anything else I can I hear that from

00:13:17,200 --> 00:13:25,570
someone oh okay no sir it does make

00:13:22,780 --> 00:13:28,150
sense try to give it give another slide

00:13:25,570 --> 00:13:32,320
so you narrow encoding is essentially

00:13:28,150 --> 00:13:34,660
arm like so say I'm representing one

00:13:32,320 --> 00:13:35,860
it's like i'm using site if use a

00:13:34,660 --> 00:13:38,560
slightly different representation one

00:13:35,860 --> 00:13:40,870
and say it's what it's what binary would

00:13:38,560 --> 00:13:42,760
be if it had no zero that's one way of

00:13:40,870 --> 00:13:44,440
thinking about it you have one and you

00:13:42,760 --> 00:13:50,110
have to represent all numbers just using

00:13:44,440 --> 00:13:54,210
one so it's like 11 11 11 and so on yeah

00:13:50,110 --> 00:13:59,470
so how do you store these counters okay

00:13:54,210 --> 00:14:02,230
that H is a hash function and use a

00:13:59,470 --> 00:14:03,790
giant bit array so yeah the answer to

00:14:02,230 --> 00:14:06,010
the previous question is that yes you

00:14:03,790 --> 00:14:09,700
can compress it you can press it by

00:14:06,010 --> 00:14:12,160
sharing the bits i kid you not you share

00:14:09,700 --> 00:14:15,180
the bits between the counters and then

00:14:12,160 --> 00:14:18,190
you deal with the slight false positive

00:14:15,180 --> 00:14:19,810
like it makes accounts slightly less

00:14:18,190 --> 00:14:22,960
accurate but on the other end these were

00:14:19,810 --> 00:14:24,880
my random estimate counts anyway so

00:14:22,960 --> 00:14:26,320
making it slightly less accurate really

00:14:24,880 --> 00:14:28,600
doesn't matter if it means that we can

00:14:26,320 --> 00:14:30,490
store more counters so overall you can

00:14:28,600 --> 00:14:33,100
make it more accurate and useless gives

00:14:30,490 --> 00:14:35,440
us space I know I I thought that was

00:14:33,100 --> 00:14:38,710
pretty damn awesome but then I'm a bit

00:14:35,440 --> 00:14:42,310
of a nerd in case you haven't noticed so

00:14:38,710 --> 00:14:45,130
okay so you have this hash function and

00:14:42,310 --> 00:14:48,250
it's essentially given the name of the

00:14:45,130 --> 00:14:50,710
counter and a bit position workout we're

00:14:48,250 --> 00:14:53,590
in the bitter a it should be so for

00:14:50,710 --> 00:14:57,520
counter Joe and bit position one you

00:14:53,590 --> 00:14:58,720
should be in bit position 10 so you go

00:14:57,520 --> 00:15:00,160
through and you look at the tenth bed

00:14:58,720 --> 00:15:04,090
your work out if it's sad or what have

00:15:00,160 --> 00:15:06,430
you now usually say on set you go

00:15:04,090 --> 00:15:08,140
through and you say well so let's say K

00:15:06,430 --> 00:15:12,310
is a count of value and it's a we say K

00:15:08,140 --> 00:15:14,740
is 5i 0 through and I say well what for

00:15:12,310 --> 00:15:16,870
for counter Joe what should that where

00:15:14,740 --> 00:15:19,990
should the first bit be first bit should

00:15:16,870 --> 00:15:21,760
be into a bit to set it to where should

00:15:19,990 --> 00:15:23,779
this wave and then you just keep going

00:15:21,760 --> 00:15:25,459
until you go up to

00:15:23,779 --> 00:15:27,259
everything was bit five I think I said

00:15:25,459 --> 00:15:29,689
because five was the value of the

00:15:27,259 --> 00:15:32,660
counter and you and the number of

00:15:29,689 --> 00:15:39,019
counters by um sorry I just had to do

00:15:32,660 --> 00:15:41,930
that so because you do that that the

00:15:39,019 --> 00:15:43,910
downside is that if you're setting bits

00:15:41,930 --> 00:15:46,459
that are the same bits and somebody

00:15:43,910 --> 00:15:48,499
else's counter then you the other

00:15:46,459 --> 00:15:50,660
counter might miss count and might be

00:15:48,499 --> 00:15:53,480
considered larger than it really should

00:15:50,660 --> 00:15:57,829
be but on the other hand because you're

00:15:53,480 --> 00:15:58,939
sharing bits because most of your

00:15:57,829 --> 00:16:01,279
accountants are going to be very low

00:15:58,939 --> 00:16:02,839
values you can then use many fewer bits

00:16:01,279 --> 00:16:05,990
so that's essentially where they're

00:16:02,839 --> 00:16:08,720
coming from so similarly on on read you

00:16:05,990 --> 00:16:11,420
simply keep counting until you until you

00:16:08,720 --> 00:16:13,759
find a zero so where's my first bits and

00:16:11,420 --> 00:16:15,499
bit too that's a one then next one

00:16:13,759 --> 00:16:17,839
should be a bit for that's a one or the

00:16:15,499 --> 00:16:20,569
next one's a zero well okay that that's

00:16:17,839 --> 00:16:22,189
it my account is only two and then you

00:16:20,569 --> 00:16:24,620
do the stuff that I mentioned earlier

00:16:22,189 --> 00:16:28,519
aren't actually turn into turn to a real

00:16:24,620 --> 00:16:31,160
number on it's at this stage when I tell

00:16:28,519 --> 00:16:34,009
you once again that is usually easier to

00:16:31,160 --> 00:16:36,319
get lots of data and then turn like lots

00:16:34,009 --> 00:16:38,180
of noisy data and then make sense of it

00:16:36,319 --> 00:16:40,790
at the end rather than trying to collect

00:16:38,180 --> 00:16:42,980
really clean data so for example with

00:16:40,790 --> 00:16:45,980
the earlier algorithms those are very

00:16:42,980 --> 00:16:47,689
cheap to run they're very cheap to store

00:16:45,980 --> 00:16:48,829
you only need a couple of bits like for

00:16:47,689 --> 00:16:50,569
example let's say they are running a

00:16:48,829 --> 00:16:52,939
counter let's see need to count up to 4

00:16:50,569 --> 00:16:55,430
billion one you need to increment a

00:16:52,939 --> 00:17:00,199
counter 4 billion times which takes some

00:16:55,430 --> 00:17:02,990
time to you need to store 32 bits 32

00:17:00,199 --> 00:17:07,640
bits is a lot more than what it's like

00:17:02,990 --> 00:17:11,030
five or six which is log of 32 but yeah

00:17:07,640 --> 00:17:13,399
so it's essentially you stole s data you

00:17:11,030 --> 00:17:14,539
need fewer like you had fewer operations

00:17:13,399 --> 00:17:18,740
and the operations you're trying to do

00:17:14,539 --> 00:17:24,500
it cheaper many ways so that part was

00:17:18,740 --> 00:17:27,980
just analytics so that was actually I

00:17:24,500 --> 00:17:30,140
don't name them but yeah large telco UK

00:17:27,980 --> 00:17:31,549
telco they had problems with a whole

00:17:30,140 --> 00:17:35,940
bunch of telemarketers come in with a

00:17:31,549 --> 00:17:37,049
sip trunk they need to develop some

00:17:35,940 --> 00:17:39,029
rhythms to go through and efficiently

00:17:37,049 --> 00:17:42,480
find them on their massively distribute

00:17:39,029 --> 00:17:44,549
infrastructure and so they did and I

00:17:42,480 --> 00:17:48,059
kind of modified a little bit to make it

00:17:44,549 --> 00:17:49,950
an easier example mostly because those

00:17:48,059 --> 00:17:51,539
methods aren't exactly the methods that

00:17:49,950 --> 00:17:53,250
you would use in a real real life

00:17:51,539 --> 00:17:54,480
scenario but they're easy enough for me

00:17:53,250 --> 00:17:56,730
to go through and show and their damn

00:17:54,480 --> 00:17:58,169
cool add that and the damn cool is also

00:17:56,730 --> 00:18:00,600
a very good reason why I'm why I'm

00:17:58,169 --> 00:18:01,919
showing them to you bo it hands up who

00:18:00,600 --> 00:18:08,789
thinks that those algorithms are damn

00:18:01,919 --> 00:18:10,860
cool oh yeah okay so ever okay everyone

00:18:08,789 --> 00:18:12,960
knows MapReduce if you want to MapReduce

00:18:10,860 --> 00:18:15,240
tutorial Google Map Reduce or a thousand

00:18:12,960 --> 00:18:18,960
one of those what people tend to forget

00:18:15,240 --> 00:18:21,210
is that there's more to Big Data than

00:18:18,960 --> 00:18:23,009
MapReduce so let's just say you're

00:18:21,210 --> 00:18:25,200
trying to sum all these things standard

00:18:23,009 --> 00:18:27,299
way is you go through and yet like first

00:18:25,200 --> 00:18:29,970
number at second number at third number

00:18:27,299 --> 00:18:32,669
whatever that takes some time it takes

00:18:29,970 --> 00:18:34,679
Oh n time and that's the problem when

00:18:32,669 --> 00:18:38,009
you're a big data set well your data

00:18:34,679 --> 00:18:39,690
sets from huge so because it's that

00:18:38,009 --> 00:18:44,389
large it then takes forever to go

00:18:39,690 --> 00:18:48,149
through one run these operations on so

00:18:44,389 --> 00:18:51,200
you can do things like this this is an

00:18:48,149 --> 00:18:54,629
addition tree but it's an example of

00:18:51,200 --> 00:18:57,929
more widely used technique more widely

00:18:54,629 --> 00:19:01,110
used technique is quite nicely known as

00:18:57,929 --> 00:19:02,820
property hacks they're called property

00:19:01,110 --> 00:19:04,950
hacks because you use the properties of

00:19:02,820 --> 00:19:07,169
your data set and the things you're

00:19:04,950 --> 00:19:09,870
trying to do in order to act in order to

00:19:07,169 --> 00:19:13,230
break it into little pieces that you can

00:19:09,870 --> 00:19:15,389
then reintegrate using other functions

00:19:13,230 --> 00:19:18,570
in some more efficient way then you

00:19:15,389 --> 00:19:20,509
would just generally think to do one

00:19:18,570 --> 00:19:23,879
example of this is actually shown in

00:19:20,509 --> 00:19:25,289
Google's page rank paper and also in the

00:19:23,879 --> 00:19:26,940
Stanford big data book which I'm not

00:19:25,289 --> 00:19:29,279
sure if it's in the in the paper but

00:19:26,940 --> 00:19:30,990
it's definitely the book where they go

00:19:29,279 --> 00:19:33,539
through and they take this absolutely

00:19:30,990 --> 00:19:35,370
massive matrix and they go through and

00:19:33,539 --> 00:19:37,019
they cut it into slices and they

00:19:35,370 --> 00:19:40,679
distribute it now napped in your case

00:19:37,019 --> 00:19:42,059
they use MapReduce but the the end

00:19:40,679 --> 00:19:43,910
result is the same they use multiple

00:19:42,059 --> 00:19:47,870
rounds of MapReduce and they

00:19:43,910 --> 00:19:51,290
beautiful yeah abused the the properties

00:19:47,870 --> 00:19:53,780
of its not even matrix multiplication

00:19:51,290 --> 00:19:56,150
level it was the various things that

00:19:53,780 --> 00:19:57,350
I'll trying to do to the matrices that

00:19:56,150 --> 00:19:59,600
they could go through and integrate it

00:19:57,350 --> 00:20:02,560
and end up with the right result so in

00:19:59,600 --> 00:20:04,570
this case this like a tree like this

00:20:02,560 --> 00:20:08,780
means you can go through and say add

00:20:04,570 --> 00:20:11,450
large numbers of numbers in log n time

00:20:08,780 --> 00:20:15,200
so you guys can probably pretty pretty

00:20:11,450 --> 00:20:19,730
easily see that but the more general

00:20:15,200 --> 00:20:21,770
case is the by far the cooler case B I

00:20:19,730 --> 00:20:24,230
just wanted to let you guys know that

00:20:21,770 --> 00:20:26,600
there is more to district imputing than

00:20:24,230 --> 00:20:28,430
MapReduce because it gets massively you

00:20:26,600 --> 00:20:32,690
like every everybody uses it and it gets

00:20:28,430 --> 00:20:35,000
a bit hyped finally okay why Python wild

00:20:32,690 --> 00:20:38,680
use Python for this Python is damn

00:20:35,000 --> 00:20:41,030
awesome next Python is damn awesome

00:20:38,680 --> 00:20:43,220
syphon if you haven't used it siphons

00:20:41,030 --> 00:20:45,460
damn awesome mostly because you use

00:20:43,220 --> 00:20:48,320
Python code or restricted Python code

00:20:45,460 --> 00:20:50,990
compartment to see our pie is damn

00:20:48,320 --> 00:20:53,510
awesome for doing data analytics numpy

00:20:50,990 --> 00:20:59,270
and sci-fi are just damn awesome old

00:20:53,510 --> 00:21:02,210
port lets you connect as an erlang node

00:20:59,270 --> 00:21:04,820
and that is really awesome because lots

00:21:02,210 --> 00:21:06,260
of the larger like for example insides

00:21:04,820 --> 00:21:08,690
of telcos and all those sorts of things

00:21:06,260 --> 00:21:10,250
those are all early so going through and

00:21:08,690 --> 00:21:13,820
being able to connect to the end of it

00:21:10,250 --> 00:21:17,210
is very useful similarly zeromq lots of

00:21:13,820 --> 00:21:19,490
say hft staff is all zeromq and finna

00:21:17,210 --> 00:21:22,400
band on the inside so being able to just

00:21:19,490 --> 00:21:25,880
attach to to that and use that is very

00:21:22,400 --> 00:21:29,300
useful python is by far the nicest glue

00:21:25,880 --> 00:21:30,590
language around and it's it's more than

00:21:29,300 --> 00:21:32,330
a glue language it's a really awesome

00:21:30,590 --> 00:21:34,940
language so that's why you should use

00:21:32,330 --> 00:21:36,460
Python for big data work because in case

00:21:34,940 --> 00:21:38,990
you haven't noticed the actual

00:21:36,460 --> 00:21:42,980
algorithms earlier on they're very

00:21:38,990 --> 00:21:46,460
they're very simple and being able to

00:21:42,980 --> 00:21:49,160
very easily arm iterating what have you

00:21:46,460 --> 00:21:50,540
is well one of the great selling points

00:21:49,160 --> 00:21:53,660
of Python as well as it's awesome

00:21:50,540 --> 00:21:56,870
libraries so interesting stuff won't go

00:21:53,660 --> 00:21:57,520
into this some of the the earlier things

00:21:56,870 --> 00:21:59,710
are

00:21:57,520 --> 00:22:01,690
called hyper log log counters the

00:21:59,710 --> 00:22:03,730
general class is called log log counters

00:22:01,690 --> 00:22:06,160
the hybrid stuff is kind of weird but

00:22:03,730 --> 00:22:09,970
very cool the Stanford big data book is

00:22:06,160 --> 00:22:10,960
awesome I just as books go if you're

00:22:09,970 --> 00:22:13,480
interested in this sort of stuff you

00:22:10,960 --> 00:22:15,490
should definitely read that book the

00:22:13,480 --> 00:22:26,380
rest of it is just other cool stuff that

00:22:15,490 --> 00:22:34,120
people generally don't know Thanks thank

00:22:26,380 --> 00:22:35,440
you previously any questions if you know

00:22:34,120 --> 00:22:37,300
what's interesting going to some of

00:22:35,440 --> 00:22:39,160
these while I'm talking anyone

00:22:37,300 --> 00:22:42,610
interested in a rough overview of what

00:22:39,160 --> 00:22:45,310
these are okay to left hashing is damn

00:22:42,610 --> 00:22:48,370
awesome I say that a lot that's because

00:22:45,310 --> 00:22:50,920
lots of stuff is awesome um so to left

00:22:48,370 --> 00:22:53,830
hashing basically means that if you take

00:22:50,920 --> 00:22:56,380
a large set of things you pick two items

00:22:53,830 --> 00:23:01,600
at random and you put your thing in the

00:22:56,380 --> 00:23:05,860
least loaded one you are fetal log log

00:23:01,600 --> 00:23:10,900
in optimal in terms of your load

00:23:05,860 --> 00:23:12,280
balancing that okay I'm not like that is

00:23:10,900 --> 00:23:14,440
an absolutely massive achievement

00:23:12,280 --> 00:23:17,140
because typically it would require all

00:23:14,440 --> 00:23:18,700
sorts of complex things and horrible

00:23:17,140 --> 00:23:21,790
horrible hacks to get even close to that

00:23:18,700 --> 00:23:25,840
and like logo again is close enough to

00:23:21,790 --> 00:23:30,030
01 that you just don't care and just

00:23:25,840 --> 00:23:33,640
choosing to and moving the left well one

00:23:30,030 --> 00:23:35,710
actually yeah bit of homework why do you

00:23:33,640 --> 00:23:38,260
choose the left one there there is a

00:23:35,710 --> 00:23:39,880
thesis on that it like it is a thesis

00:23:38,260 --> 00:23:42,040
but it's easy enough to read it it has

00:23:39,880 --> 00:23:46,540
an overview of all the things talk to me

00:23:42,040 --> 00:23:48,970
if you want it but it yeah it's really

00:23:46,540 --> 00:23:50,980
cool how for some reason she's always

00:23:48,970 --> 00:23:53,200
choosing the left one on in the case of

00:23:50,980 --> 00:23:55,990
a tie gives you a more optimal result

00:23:53,200 --> 00:23:58,690
and yes that stuff's cool Stanford big

00:23:55,990 --> 00:24:01,690
data book is damn cool it just has lots

00:23:58,690 --> 00:24:03,520
and lots of stuff in it hyperlocal

00:24:01,690 --> 00:24:04,840
counters are kind of the things that I

00:24:03,520 --> 00:24:10,490
showed you in the beginning but not

00:24:04,840 --> 00:24:12,050
quite it's an adaptation bloom filters

00:24:10,490 --> 00:24:15,320
blue filters belong in the more general

00:24:12,050 --> 00:24:19,910
set of mq so approximate membership

00:24:15,320 --> 00:24:22,970
query so um if i have a thing I ok who

00:24:19,910 --> 00:24:28,070
is used sets in Python before sets or

00:24:22,970 --> 00:24:33,290
done X&Y bloom filters are a damn

00:24:28,070 --> 00:24:36,140
efficient way to work out is X in why so

00:24:33,290 --> 00:24:39,020
they can store like any particular

00:24:36,140 --> 00:24:42,290
element no matter what it is in string

00:24:39,020 --> 00:24:45,140
whatever they can do that in I think the

00:24:42,290 --> 00:24:47,780
theoretical max is one point four four

00:24:45,140 --> 00:24:49,910
bits no matter what it is however

00:24:47,780 --> 00:24:53,000
generally it's more like four bits which

00:24:49,910 --> 00:24:55,400
is still damn awesome the only downside

00:24:53,000 --> 00:24:58,190
is that it has it has false positives

00:24:55,400 --> 00:24:59,570
but no false negatives that is to say it

00:24:58,190 --> 00:25:01,910
will occasionally tell you that things

00:24:59,570 --> 00:25:03,080
are in there that aren't in there but it

00:25:01,910 --> 00:25:06,080
will never tell you that something is

00:25:03,080 --> 00:25:08,440
not in there when it in fact is so

00:25:06,080 --> 00:25:13,370
things are cool they have been

00:25:08,440 --> 00:25:15,770
superseded this is a good thing about

00:25:13,370 --> 00:25:17,630
big data by good and bad is that stuff

00:25:15,770 --> 00:25:19,309
is happening continuously all around the

00:25:17,630 --> 00:25:20,900
world so bloom filters everyone loves

00:25:19,309 --> 00:25:24,290
bloom filters there's a squillion types

00:25:20,900 --> 00:25:26,600
and they run everything there in oh if

00:25:24,290 --> 00:25:28,040
you google them you'll find them you'll

00:25:26,600 --> 00:25:31,450
find applications in all sorts of things

00:25:28,040 --> 00:25:34,280
they were superseded well superseded in

00:25:31,450 --> 00:25:36,170
2011 for the applications where the

00:25:34,280 --> 00:25:38,809
bloom filter is larger than ran by

00:25:36,170 --> 00:25:41,360
quotient filters that that only came out

00:25:38,809 --> 00:25:44,120
in like twenty eleven there are two

00:25:41,360 --> 00:25:46,429
papers mentioning and at the moment so

00:25:44,120 --> 00:25:48,470
there are things like there is no python

00:25:46,429 --> 00:25:50,390
implementation for it you can't even

00:25:48,470 --> 00:25:52,490
like for if you do a simple google

00:25:50,390 --> 00:25:54,679
search you won't even find example code

00:25:52,490 --> 00:25:57,290
on it that's how new this stuff is but

00:25:54,679 --> 00:26:01,270
it's really quite cool it's I think 30

00:25:57,290 --> 00:26:04,010
or 40 times faster than bloom filters so

00:26:01,270 --> 00:26:05,809
stuff in the Big Data soil space is

00:26:04,010 --> 00:26:08,420
going through it's moving really fast

00:26:05,809 --> 00:26:10,730
you you take a look at it and it looks

00:26:08,420 --> 00:26:12,830
kind of scary but if you if you take the

00:26:10,730 --> 00:26:15,230
time and you have a look at it most of

00:26:12,830 --> 00:26:17,690
the stuff isn't that bad like if you

00:26:15,230 --> 00:26:20,510
look at home the hyper log log count as

00:26:17,690 --> 00:26:23,600
paper is kind of nasty I mailmen on end

00:26:20,510 --> 00:26:26,410
up publishing something that's a bit

00:26:23,600 --> 00:26:29,330
easy to understand on but the actual

00:26:26,410 --> 00:26:31,010
like you like you guys would get me you

00:26:29,330 --> 00:26:32,510
take one look at it you know like how

00:26:31,010 --> 00:26:34,880
does this work but then when you have a

00:26:32,510 --> 00:26:38,539
couple minutes to have a think about

00:26:34,880 --> 00:26:40,100
it's like oh yeah it's the you need to

00:26:38,539 --> 00:26:41,929
make sure that you're not scared off by

00:26:40,100 --> 00:26:43,610
the initial by the initial step because

00:26:41,929 --> 00:26:46,270
even if it has unfamiliar notation or

00:26:43,610 --> 00:26:49,880
whatever most this stuff isn't that hard

00:26:46,270 --> 00:26:52,010
anyways I'd those questions sorry soon

00:26:49,880 --> 00:26:53,240
night I really love this stuff sir so

00:26:52,010 --> 00:26:58,250
we'll have time for maybe just one

00:26:53,240 --> 00:27:00,140
question if there are any and yeah thank

00:26:58,250 --> 00:27:01,789
you for the talk oh you mentioned I if

00:27:00,140 --> 00:27:03,110
you do it many many times and eventually

00:27:01,789 --> 00:27:05,570
you were getting to be more accurate

00:27:03,110 --> 00:27:07,000
yeah you didn't actually mention in

00:27:05,570 --> 00:27:10,700
practice how do you make it accurate

00:27:07,000 --> 00:27:12,350
okay um accurate he's an interesting

00:27:10,700 --> 00:27:14,450
term accurate depends on what you're

00:27:12,350 --> 00:27:16,370
trying to use it for like let me just

00:27:14,450 --> 00:27:19,669
give you an example on to do do do do do

00:27:16,370 --> 00:27:21,470
do do do do do do wait and hear if

00:27:19,669 --> 00:27:24,799
you're trying to work out if someone is

00:27:21,470 --> 00:27:27,110
sitting over here or if they're sitting

00:27:24,799 --> 00:27:28,760
over here you don't need to be very

00:27:27,110 --> 00:27:30,380
accurate at all that's that's very easy

00:27:28,760 --> 00:27:31,850
for you if you're trying to

00:27:30,380 --> 00:27:33,530
differentiate two people are really

00:27:31,850 --> 00:27:36,980
close together they need to want more

00:27:33,530 --> 00:27:37,909
accuracy however may I think the two

00:27:36,980 --> 00:27:40,159
major ones a method of maximum

00:27:37,909 --> 00:27:43,490
likelihood and it's minimization of

00:27:40,159 --> 00:27:45,950
entropy is the other one pick up a stats

00:27:43,490 --> 00:27:49,190
textbook it's it's usually taught fairly

00:27:45,950 --> 00:27:51,049
easily it's not that complicated but

00:27:49,190 --> 00:27:53,929
usually use those sorts of methods on

00:27:51,049 --> 00:27:55,580
large numbers of proximate counters so

00:27:53,929 --> 00:27:57,169
you eventually do we have some kind of

00:27:55,580 --> 00:27:59,030
error margin you just iterate until you

00:27:57,169 --> 00:28:00,830
satisfy your requirements so you say

00:27:59,030 --> 00:28:04,610
that's hecka enough I can stop here is

00:28:00,830 --> 00:28:06,080
the high work um it depends on what

00:28:04,610 --> 00:28:09,200
you're doing also I should make another

00:28:06,080 --> 00:28:12,140
shout out who he knows bears da y yes

00:28:09,200 --> 00:28:13,940
okay the guys who don't phase is very

00:28:12,140 --> 00:28:16,070
useful and you should just google it

00:28:13,940 --> 00:28:18,470
it's I know it gets a bit of hype as

00:28:16,070 --> 00:28:20,360
being hard to understand if you find a

00:28:18,470 --> 00:28:22,370
source that ease into pure maths

00:28:20,360 --> 00:28:24,549
textbook but I don't don't learn this

00:28:22,370 --> 00:28:27,230
from pure math textbook you'll be fine

00:28:24,549 --> 00:28:29,570
beer so in terms of how you know how I

00:28:27,230 --> 00:28:31,190
curates accurate enough it usually just

00:28:29,570 --> 00:28:34,429
depends on what your bounce are you try

00:28:31,190 --> 00:28:34,820
it out that you can do lots of modeling

00:28:34,429 --> 00:28:37,669
as

00:28:34,820 --> 00:28:38,809
more lots of Stan's stuff there's also a

00:28:37,669 --> 00:28:40,279
whole bunch of interesting things you

00:28:38,809 --> 00:28:42,350
can do like for example if you know what

00:28:40,279 --> 00:28:44,750
your internal distributions were you can

00:28:42,350 --> 00:28:46,700
you can feed that information into your

00:28:44,750 --> 00:28:48,679
model to make your model more accurate

00:28:46,700 --> 00:28:51,080
certain you'll need fuel counters so you

00:28:48,679 --> 00:28:52,549
do cool stuff like that yeah thank you

00:28:51,080 --> 00:28:54,769
very much air out of time but a bunch of

00:28:52,549 --> 00:28:56,960
sent you with them some coffee beans and

00:28:54,769 --> 00:28:59,679
a mug could from park on Australian

00:28:56,960 --> 00:28:59,679

YouTube URL: https://www.youtube.com/watch?v=sN3pRNh-_6Y


