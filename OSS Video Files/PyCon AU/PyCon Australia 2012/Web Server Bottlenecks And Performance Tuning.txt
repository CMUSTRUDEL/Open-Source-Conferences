Title: Web Server Bottlenecks And Performance Tuning
Publication date: 2012-08-23
Playlist: PyCon Australia 2012
Description: 
	Graham Dumpleton
A benchmark of a hello world application is often what developers use to make the all important decision of what web hosting infrastructure they use. Worse is that in many cases this is the only sort of performance testing or monitor
Captions: 
	00:00:02,959 --> 00:00:09,630
good morning everyone if we can settle

00:00:06,089 --> 00:00:12,540
in before we get started with this next

00:00:09,630 --> 00:00:14,700
talk just to give you a heads up I'm

00:00:12,540 --> 00:00:15,870
still waiting on confirmed details of

00:00:14,700 --> 00:00:19,920
the talk but there has been a slight

00:00:15,870 --> 00:00:21,660
change coming up later on next door one

00:00:19,920 --> 00:00:25,320
of the talks has changed there will be a

00:00:21,660 --> 00:00:27,930
new Gengo talk the web schedule is being

00:00:25,320 --> 00:00:29,519
updated as we speak and I'll have some

00:00:27,930 --> 00:00:30,539
confirmed details hopefully by the end

00:00:29,519 --> 00:00:34,829
of this session so I'll let you know

00:00:30,539 --> 00:00:36,980
what's happening there so on to the

00:00:34,829 --> 00:00:39,300
first talk in this session for the day

00:00:36,980 --> 00:00:41,460
web server and bottlenecks and

00:00:39,300 --> 00:00:47,370
performance with Graham Dumbarton who

00:00:41,460 --> 00:00:50,879
has been the author of modern WSGI a

00:00:47,370 --> 00:00:52,739
pretty instrumental piece of code for

00:00:50,879 --> 00:00:55,739
Python and he's also a member of the

00:00:52,739 --> 00:00:58,170
Apache Software Foundation and the

00:00:55,739 --> 00:00:59,309
Python Software Foundation so very

00:00:58,170 --> 00:01:01,199
active in the community and we're

00:00:59,309 --> 00:01:04,219
pleased to have him to give us this talk

00:01:01,199 --> 00:01:04,219
this morning thank you

00:01:06,180 --> 00:01:12,030
this is actually a philan talk someone

00:01:08,820 --> 00:01:14,189
else's talk couldn't happen for some

00:01:12,030 --> 00:01:15,540
reason I don't know why I guess most

00:01:14,189 --> 00:01:18,060
people might have realized that because

00:01:15,540 --> 00:01:21,060
I I have done this talk before at PyCon

00:01:18,060 --> 00:01:23,189
in the u.s. Saipan Sydney and also user

00:01:21,060 --> 00:01:24,360
group in San Francisco so it's possible

00:01:23,189 --> 00:01:25,830
you've seen the vidiians to be able to

00:01:24,360 --> 00:01:28,640
send the video that's why we've got some

00:01:25,830 --> 00:01:31,369
more crowd today but there's a minute

00:01:28,640 --> 00:01:34,680
the slides are already up on SlideShare

00:01:31,369 --> 00:01:36,420
and my slides from yesterday's are now

00:01:34,680 --> 00:01:39,360
up on SlideShare I finally managed to

00:01:36,420 --> 00:01:42,479
get them up by doing it from my room and

00:01:39,360 --> 00:01:43,770
if you if you feel like if you want to

00:01:42,479 --> 00:01:45,750
check up with how I do on this talk you

00:01:43,770 --> 00:01:48,920
know go back and watch the PyCon video

00:01:45,750 --> 00:01:48,920
from when I do it last time too

00:01:49,009 --> 00:01:53,009
so before we talk about website

00:01:51,060 --> 00:01:54,899
performance tuning it's important to

00:01:53,009 --> 00:01:56,729
step back and look at the bigger picture

00:01:54,899 --> 00:01:58,229
although newbies especially have

00:01:56,729 --> 00:02:00,990
obsession with trying to find that

00:01:58,229 --> 00:02:02,100
fastest web server they can reality is

00:02:00,990 --> 00:02:03,210
that things are a little bit more

00:02:02,100 --> 00:02:05,549
complicated than that

00:02:03,210 --> 00:02:08,250
systems of the many moving parts the

00:02:05,549 --> 00:02:10,330
actual per request latency introduced by

00:02:08,250 --> 00:02:11,890
a web server is very small

00:02:10,330 --> 00:02:15,670
relation to the time spent in other

00:02:11,890 --> 00:02:17,560
parts of the system as far as the user

00:02:15,670 --> 00:02:19,390
is concerned the main delays they will

00:02:17,560 --> 00:02:21,820
notice are those resulting from how long

00:02:19,390 --> 00:02:23,350
it takes their web browser to render the

00:02:21,820 --> 00:02:25,480
page returned by the web application

00:02:23,350 --> 00:02:27,340
this will be followed up by network

00:02:25,480 --> 00:02:29,560
delays when talking to the web app and

00:02:27,340 --> 00:02:32,250
when grabbing down static assets from

00:02:29,560 --> 00:02:34,900
media servers or content data networks

00:02:32,250 --> 00:02:37,000
the time spent in the web application is

00:02:34,900 --> 00:02:38,980
therefore a small percentage of the time

00:02:37,000 --> 00:02:41,680
is perceived by the user for when during

00:02:38,980 --> 00:02:43,420
rendering and web pages being served any

00:02:41,680 --> 00:02:45,010
time delay is introduced by the web

00:02:43,420 --> 00:02:49,330
server will be much smaller percentage

00:02:45,010 --> 00:02:51,520
again Steve sunders summarizes this

00:02:49,330 --> 00:02:52,900
disparity between front end time and web

00:02:51,520 --> 00:02:55,330
application time and what he calls the

00:02:52,900 --> 00:02:57,459
performance golden rule this is that

00:02:55,330 --> 00:02:59,650
eighty to ninety percent of end-user

00:02:57,459 --> 00:03:01,870
response time is spent in the front end

00:02:59,650 --> 00:03:03,910
if you're after an easy win for

00:03:01,870 --> 00:03:05,740
improving end-user satisfaction with

00:03:03,910 --> 00:03:07,950
your website the front end is actually

00:03:05,740 --> 00:03:10,480
where you should start

00:03:07,950 --> 00:03:12,700
so although the bigger media gains maybe

00:03:10,480 --> 00:03:14,590
one in the front end the web application

00:03:12,700 --> 00:03:16,570
still represents lots of opportunity to

00:03:14,590 --> 00:03:18,480
further reduce response times from means

00:03:16,570 --> 00:03:20,110
other than fiddling with the web server

00:03:18,480 --> 00:03:22,630
improvements can be had in the

00:03:20,110 --> 00:03:24,430
application code but also in databases

00:03:22,630 --> 00:03:28,330
or back-end services used by your web

00:03:24,430 --> 00:03:30,700
application so is running benchmarks on

00:03:28,330 --> 00:03:32,410
web servers complete waste of time the

00:03:30,700 --> 00:03:34,150
answer is yes and no the sort of

00:03:32,410 --> 00:03:36,250
benchmarks that are usually published on

00:03:34,150 --> 00:03:38,260
websites to compare web services usually

00:03:36,250 --> 00:03:39,850
serve little value they're generally

00:03:38,260 --> 00:03:42,160
only served to give the newbies a false

00:03:39,850 --> 00:03:43,989
sense of security over any decision they

00:03:42,160 --> 00:03:46,360
make as to which web server they choose

00:03:43,989 --> 00:03:48,430
to use versus that people forever

00:03:46,360 --> 00:03:51,630
reference these benchmarks as a gospel

00:03:48,430 --> 00:03:54,190
truth when they can be far from it

00:03:51,630 --> 00:03:56,260
the main reason that typical web server

00:03:54,190 --> 00:03:59,620
benchmark is useless is a test Sonia

00:03:56,260 --> 00:04:01,450
single narrow idealized use case web

00:03:59,620 --> 00:04:03,130
servers are implemented using different

00:04:01,450 --> 00:04:05,440
architectures and using different code

00:04:03,130 --> 00:04:07,390
you're better off choosing a web server

00:04:05,440 --> 00:04:09,580
that you believe has the features you

00:04:07,390 --> 00:04:12,510
require and then use benchmarks to help

00:04:09,580 --> 00:04:15,610
explore the behavior of that system

00:04:12,510 --> 00:04:17,519
often documented benchmarks you find a

00:04:15,610 --> 00:04:19,680
nothing more than a hello world program

00:04:17,519 --> 00:04:21,419
the testing consists of running it at a

00:04:19,680 --> 00:04:23,130
maximum request Freeport with some

00:04:21,419 --> 00:04:25,650
arbitrary number of concurrent users

00:04:23,130 --> 00:04:28,229
this does not narrow up narrow what real

00:04:25,650 --> 00:04:30,630
traffic a public-facing web server would

00:04:28,229 --> 00:04:32,940
receive it certainly doesn't show what

00:04:30,630 --> 00:04:37,410
causes a server to fail as load

00:04:32,940 --> 00:04:39,630
increases just that it will what should

00:04:37,410 --> 00:04:41,789
you test then there are many different

00:04:39,630 --> 00:04:43,259
use cases one could test and how any one

00:04:41,789 --> 00:04:45,569
performs can be dictated by the

00:04:43,259 --> 00:04:47,699
architecture of the system how the code

00:04:45,569 --> 00:04:50,069
was written and how the system is

00:04:47,699 --> 00:04:51,539
configured when the test is run the more

00:04:50,069 --> 00:04:53,460
interesting tests of those would

00:04:51,539 --> 00:04:55,740
deliberately go out to trigger specific

00:04:53,460 --> 00:04:57,630
problems this is because it is the

00:04:55,740 --> 00:04:59,310
corner cases that are usually going to

00:04:57,630 --> 00:05:03,810
cause an issue rather than the typical

00:04:59,310 --> 00:05:05,159
use case what sort of factors can come

00:05:03,810 --> 00:05:07,139
into play and affect performance

00:05:05,159 --> 00:05:08,819
these are varied and can arise from the

00:05:07,139 --> 00:05:10,530
hardware or virtualized system being

00:05:08,819 --> 00:05:12,449
used they can derive from the

00:05:10,530 --> 00:05:14,729
configuration you use for the specific

00:05:12,449 --> 00:05:16,530
web server but also can be influenced by

00:05:14,729 --> 00:05:18,659
how the Python language interpreter

00:05:16,530 --> 00:05:20,370
works to make it hard these can all

00:05:18,659 --> 00:05:23,820
interplay with each other in unexpected

00:05:20,370 --> 00:05:25,440
ways some things can be out of your

00:05:23,820 --> 00:05:27,419
control altogether such as the type of

00:05:25,440 --> 00:05:29,130
web browser and what type of network the

00:05:27,419 --> 00:05:31,860
traffic between you and the user has to

00:05:29,130 --> 00:05:33,599
traverse very few public banking must

00:05:31,860 --> 00:05:37,710
try to account for these issues in a

00:05:33,599 --> 00:05:39,330
realistic way requirements as dictated

00:05:37,710 --> 00:05:41,580
by your own web application or how you

00:05:39,330 --> 00:05:44,130
decide to architect you also your your

00:05:41,580 --> 00:05:45,539
overall system can also contribute such

00:05:44,130 --> 00:05:49,620
as whether you try and use the same

00:05:45,539 --> 00:05:50,880
server to serve up static assets to

00:05:49,620 --> 00:05:52,409
illustrate how some of these different

00:05:50,880 --> 00:05:54,060
factors can come into play I will go

00:05:52,409 --> 00:05:56,280
through a few specific use cases to

00:05:54,060 --> 00:05:57,870
present issues in practice and where

00:05:56,280 --> 00:06:00,900
possible relate them to these factors

00:05:57,870 --> 00:06:03,240
these include memory usage usage usage

00:06:00,900 --> 00:06:04,949
of processes versus Fred's impacts of

00:06:03,240 --> 00:06:08,389
long-running quests and restarting a

00:06:04,949 --> 00:06:10,560
server process and startup costs a

00:06:08,389 --> 00:06:12,300
simple place to get started is memory

00:06:10,560 --> 00:06:15,090
usage this is always a hot topic

00:06:12,300 --> 00:06:16,590
invented contention with benchmarks it

00:06:15,090 --> 00:06:19,229
isn't hard to find people claiming that

00:06:16,590 --> 00:06:20,699
Apache is a big bloated memory hog this

00:06:19,229 --> 00:06:22,560
benchmark in particular is

00:06:20,699 --> 00:06:24,810
representative of poorly chosen Apache

00:06:22,560 --> 00:06:26,789
configuration of course it will use more

00:06:24,810 --> 00:06:27,199
memory if you configure it to have 1,000

00:06:26,789 --> 00:06:30,110
Fred

00:06:27,199 --> 00:06:32,090
if servers are tested aren't set up in a

00:06:30,110 --> 00:06:34,479
comparable way you can hardly expect it

00:06:32,090 --> 00:06:37,009
to be a fair comparison

00:06:34,479 --> 00:06:38,810
actually this estimating the overall

00:06:37,009 --> 00:06:41,060
amount of memory used is not a difficult

00:06:38,810 --> 00:06:42,740
exercise it's after all a simple formula

00:06:41,060 --> 00:06:45,020
taking an acceleration and number of

00:06:42,740 --> 00:06:47,599
processes the base memory used by the

00:06:45,020 --> 00:06:50,150
web server memory for each additional

00:06:47,599 --> 00:06:51,800
Fred and the application itself things

00:06:50,150 --> 00:06:54,169
get more complicated when one considers

00:06:51,800 --> 00:06:56,120
per request transient memory but

00:06:54,169 --> 00:06:57,460
ignoring that one can easily visualize

00:06:56,120 --> 00:07:00,409
what you're dealing with

00:06:57,460 --> 00:07:02,330
in short adding more processors is going

00:07:00,409 --> 00:07:03,620
to see memory usage grow quicker than

00:07:02,330 --> 00:07:05,689
adding more friends to existing

00:07:03,620 --> 00:07:07,669
processes although some of that per

00:07:05,689 --> 00:07:10,069
process based memory usage is the web

00:07:07,669 --> 00:07:11,930
server the majority of it will be in the

00:07:10,069 --> 00:07:14,449
end of your fat Python web application

00:07:11,930 --> 00:07:16,729
to blame a web server for using too much

00:07:14,449 --> 00:07:18,529
memory is plain silly when your web

00:07:16,729 --> 00:07:20,150
application could be using up to fifty

00:07:18,529 --> 00:07:22,370
to a hundred times as much memory the

00:07:20,150 --> 00:07:26,020
issue is really about what configuration

00:07:22,370 --> 00:07:28,400
you choose to set the web server up with

00:07:26,020 --> 00:07:30,139
what usually happens is that people will

00:07:28,400 --> 00:07:32,089
blind to use whatever the defaults are

00:07:30,139 --> 00:07:33,469
for a server for fat python web

00:07:32,089 --> 00:07:36,080
applications would use a lot of memory

00:07:33,469 --> 00:07:38,930
this can be disastrous Apache with its

00:07:36,080 --> 00:07:40,399
pre four NPM can for example dynamically

00:07:38,930 --> 00:07:43,159
create up to one hundred and fifty

00:07:40,399 --> 00:07:45,589
processes that is potentially 150 copies

00:07:43,159 --> 00:07:47,149
of your fat - web application in memory

00:07:45,589 --> 00:07:50,509
so for course it's going to use low

00:07:47,149 --> 00:07:52,699
memory those servers which generally

00:07:50,509 --> 00:07:54,259
seen is faring best as far as memory

00:07:52,699 --> 00:07:56,749
usage are those has default

00:07:54,259 --> 00:07:59,240
configurations use only a single process

00:07:56,749 --> 00:08:01,159
and a single fred guess what if you were

00:07:59,240 --> 00:08:02,930
to configure Apache that way then the

00:08:01,159 --> 00:08:03,589
amount of memory it uses will not be

00:08:02,930 --> 00:08:05,779
much different

00:08:03,589 --> 00:08:07,939
so granted though we were perhaps you up

00:08:05,779 --> 00:08:09,649
it does helped it also strip unheeded

00:08:07,939 --> 00:08:13,339
models out of Apache that you don't use

00:08:09,649 --> 00:08:14,990
to really get the best from it so don't

00:08:13,339 --> 00:08:16,819
start things off by using whatever the

00:08:14,990 --> 00:08:19,129
default processes Fred's configurations

00:08:16,819 --> 00:08:21,379
are especially if looking at memory

00:08:19,129 --> 00:08:22,219
usage do so and you can easily get the

00:08:21,379 --> 00:08:24,740
wrong impression

00:08:22,219 --> 00:08:26,180
also don't pick arbitrary values when

00:08:24,740 --> 00:08:29,629
you have no idea whether it's reasonable

00:08:26,180 --> 00:08:31,189
a disk scaler configuration of 101 files

00:08:29,629 --> 00:08:32,810
and Fred's is used by that benchmark

00:08:31,189 --> 00:08:34,490
will not even fit on this chart it's

00:08:32,810 --> 00:08:36,500
sort of like over there in the next room

00:08:34,490 --> 00:08:38,760
somewhere

00:08:36,500 --> 00:08:40,710
how many presents and Fred should you

00:08:38,760 --> 00:08:42,660
use then the total number of Fred's

00:08:40,710 --> 00:08:44,400
across all processes is dictated by the

00:08:42,660 --> 00:08:46,830
number of overlapping concurrent

00:08:44,400 --> 00:08:49,520
requests how much overlap there is

00:08:46,830 --> 00:08:51,840
depends on response times and fruit foot

00:08:49,520 --> 00:08:53,330
processes are preferred over Fred's but

00:08:51,840 --> 00:08:56,400
constrained by memory you have available

00:08:53,330 --> 00:08:58,260
the optimal number can also be dictated

00:08:56,400 --> 00:09:00,450
by how many processes are available on

00:08:58,260 --> 00:09:03,180
the system unicorn for example

00:09:00,450 --> 00:09:06,360
recommends you use two to four times

00:09:03,180 --> 00:09:09,510
some number of processes as you have CPU

00:09:06,360 --> 00:09:11,100
cores available one can get a feel for

00:09:09,510 --> 00:09:14,280
how many Fred you'll need by looking

00:09:11,100 --> 00:09:15,870
Fred utilization that is how much do the

00:09:14,280 --> 00:09:18,600
requests take up of the potential

00:09:15,870 --> 00:09:20,070
capacity in this example by adding up

00:09:18,600 --> 00:09:22,080
the green areas representing the

00:09:20,070 --> 00:09:24,810
requests coming in over time we have a

00:09:22,080 --> 00:09:26,910
fred utilization of about two this means

00:09:24,810 --> 00:09:29,520
that if all requests were serialized we

00:09:26,910 --> 00:09:31,050
would need only two friends requests

00:09:29,520 --> 00:09:33,720
don't arrive in such an orderly fashion

00:09:31,050 --> 00:09:37,470
though so we do need more friends to

00:09:33,720 --> 00:09:39,420
ensure that they aren't delayed because

00:09:37,470 --> 00:09:41,370
response times are generally quite short

00:09:39,420 --> 00:09:43,830
it's actually surprising how few fred

00:09:41,370 --> 00:09:45,930
you can get away with if the number of

00:09:43,830 --> 00:09:48,390
Fred's is too low and response times of

00:09:45,930 --> 00:09:50,790
fruit foot grows though then the Fred

00:09:48,390 --> 00:09:52,740
utilization will increase eventually

00:09:50,790 --> 00:09:54,090
what happens then is that requests will

00:09:52,740 --> 00:09:56,370
start to back up as they wait for

00:09:54,090 --> 00:09:58,350
available friends and Rick queuing time

00:09:56,370 --> 00:10:00,330
will increase this will add to the

00:09:58,350 --> 00:10:04,080
delays that end user sees in their total

00:10:00,330 --> 00:10:05,490
page load time if we add processes

00:10:04,080 --> 00:10:07,950
rather than Fred's we can delay the

00:10:05,490 --> 00:10:09,900
onset of such problems the reason the

00:10:07,950 --> 00:10:11,880
processes work better is that the Python

00:10:09,900 --> 00:10:14,280
global interpreter lock effectively

00:10:11,880 --> 00:10:16,770
serializes execution with indistinct

00:10:14,280 --> 00:10:19,080
Fred's of a single process adding more

00:10:16,770 --> 00:10:21,150
processes so obviously means more memory

00:10:19,080 --> 00:10:23,520
this has got nothing to do with which

00:10:21,150 --> 00:10:25,230
server now and a choice you made which

00:10:23,520 --> 00:10:28,950
is going to be bound by how much memory

00:10:25,230 --> 00:10:30,450
you have available if you're a memory

00:10:28,950 --> 00:10:32,310
constrained finding the right balance

00:10:30,450 --> 00:10:34,080
and what you can get away with an order

00:10:32,310 --> 00:10:36,090
to storages memory usage is a tricky

00:10:34,080 --> 00:10:37,590
problem it is all made harder when you

00:10:36,090 --> 00:10:38,750
have no idea what is going on inside of

00:10:37,590 --> 00:10:40,850
your web application

00:10:38,750 --> 00:10:42,769
if the web application has a heavy bias

00:10:40,850 --> 00:10:44,750
towards cpu-bound activity within the

00:10:42,769 --> 00:10:46,399
process then you are forced towards the

00:10:44,750 --> 00:10:49,100
direction of needing more processes

00:10:46,399 --> 00:10:50,959
because of the issues with the Gil if

00:10:49,100 --> 00:10:53,089
your web application is making lots of

00:10:50,959 --> 00:10:55,009
call-outs to back-end services and so

00:10:53,089 --> 00:10:57,019
Friends of blocking waiting on oh I I

00:10:55,009 --> 00:10:59,029
owe more of the time than not you can

00:10:57,019 --> 00:11:00,709
get away or using more friends because

00:10:59,029 --> 00:11:02,839
the threads aren't competing as much of

00:11:00,709 --> 00:11:05,389
each other for use of the CPU of in the

00:11:02,839 --> 00:11:06,889
same process if you have no idea what

00:11:05,389 --> 00:11:08,569
your web application is doing this

00:11:06,889 --> 00:11:11,060
judgment is going to be hit and miss

00:11:08,569 --> 00:11:15,379
affair as far as tuning the processes

00:11:11,060 --> 00:11:17,089
threads balance to make such judgment

00:11:15,379 --> 00:11:19,699
even harder you also have a long-running

00:11:17,089 --> 00:11:21,500
requests to contend with these can arise

00:11:19,699 --> 00:11:24,170
due to issues in your own code or

00:11:21,500 --> 00:11:25,850
back-end services but also due to how

00:11:24,170 --> 00:11:28,579
much data you are moving around and how

00:11:25,850 --> 00:11:30,500
slow the HTTP clients are the basic

00:11:28,579 --> 00:11:32,959
problem here is a long-running request

00:11:30,500 --> 00:11:34,459
because it ties up a thread will reduce

00:11:32,959 --> 00:11:38,180
the maximum fruitful you could achieve

00:11:34,459 --> 00:11:40,579
during that a period of time the

00:11:38,180 --> 00:11:42,139
unpredictability of request times means

00:11:40,579 --> 00:11:44,029
you need to always ensure you have a

00:11:42,139 --> 00:11:46,189
good amount of extra capacity in a

00:11:44,029 --> 00:11:48,529
number of processes Fred's allocated

00:11:46,189 --> 00:11:50,180
don't provide sufficient Headroom and

00:11:48,529 --> 00:11:52,879
when a number of long-running quest

00:11:50,180 --> 00:11:55,250
requests coincide you'll suddenly find

00:11:52,879 --> 00:11:57,230
fred availability drops requests can

00:11:55,250 --> 00:11:58,910
start back logging and the overall

00:11:57,230 --> 00:12:03,050
response times are seen by your user

00:11:58,910 --> 00:12:04,939
will increase where your application

00:12:03,050 --> 00:12:07,699
code or back-end service is slow you up

00:12:04,939 --> 00:12:09,350
you also need to work out why sometimes

00:12:07,699 --> 00:12:09,980
issues can come from places you least

00:12:09,350 --> 00:12:12,470
expect them

00:12:09,980 --> 00:12:15,199
for example especially with Django watch

00:12:12,470 --> 00:12:17,329
out for how long Postgres SQL database

00:12:15,199 --> 00:12:19,220
connections take one thing you can

00:12:17,329 --> 00:12:21,230
consider in this case is a local

00:12:19,220 --> 00:12:25,579
external connection pull off such as PG

00:12:21,230 --> 00:12:28,790
banter if you're using Apache mod of SGI

00:12:25,579 --> 00:12:30,139
or guna corn stick engine eccentric c

00:12:28,790 --> 00:12:32,029
request through to your whiskey server

00:12:30,139 --> 00:12:33,709
this will make your whiskey server

00:12:32,029 --> 00:12:36,740
perform better as you'll be isolated

00:12:33,709 --> 00:12:38,269
from slow HTTP clients the threads in

00:12:36,740 --> 00:12:40,250
the background back-end will be tied up

00:12:38,269 --> 00:12:42,559
for less time meaning lower thread

00:12:40,250 --> 00:12:44,300
utilization thus allowing you to handle

00:12:42,559 --> 00:12:47,269
a higher throughput with less resources

00:12:44,300 --> 00:12:48,829
you can also upload tasks such as static

00:12:47,269 --> 00:12:51,590
file serving to engine X which is going

00:12:48,829 --> 00:12:53,880
to do a better job of it anyway

00:12:51,590 --> 00:12:55,310
when introducing a front-end do be

00:12:53,880 --> 00:12:57,540
careful though of the funneling effect

00:12:55,310 --> 00:12:59,220
especially if the number of concurrent

00:12:57,540 --> 00:13:01,380
requests that come handle reducers at

00:12:59,220 --> 00:13:04,020
each step if your web application

00:13:01,380 --> 00:13:06,060
backlogs users may give up but request

00:13:04,020 --> 00:13:08,460
is still skewed queued up and have to be

00:13:06,060 --> 00:13:10,020
handled your web application wastes time

00:13:08,460 --> 00:13:12,210
and may have trouble catching up with

00:13:10,020 --> 00:13:14,790
the backlog it is perhaps better to set

00:13:12,210 --> 00:13:16,350
up service a request timeout with a 503

00:13:14,790 --> 00:13:20,280
before getting to your web application

00:13:16,350 --> 00:13:21,840
if you can worst case scenario here is

00:13:20,280 --> 00:13:23,460
complete overload where the servant

00:13:21,840 --> 00:13:25,410
never really recovers for an extended

00:13:23,460 --> 00:13:27,720
period or until you could shut down the

00:13:25,410 --> 00:13:29,580
server request timeouts within the web

00:13:27,720 --> 00:13:31,530
application where supporter can help a

00:13:29,580 --> 00:13:33,630
bit but only to throw out long-running

00:13:31,530 --> 00:13:35,100
requests I've already mentioned you

00:13:33,630 --> 00:13:36,630
really need to stop those requests

00:13:35,100 --> 00:13:38,240
getting to the web application if there

00:13:36,630 --> 00:13:40,620
is no longer a point handling them

00:13:38,240 --> 00:13:44,370
options here various solutions available

00:13:40,620 --> 00:13:45,510
to avoid it aren't always great you

00:13:44,370 --> 00:13:46,890
might actually think that doing a

00:13:45,510 --> 00:13:49,020
restart will solve a problem with

00:13:46,890 --> 00:13:51,270
backlog requests you have to be careful

00:13:49,020 --> 00:13:53,670
here as well though for some service the

00:13:51,270 --> 00:13:55,530
listener socket can be preserved so any

00:13:53,670 --> 00:13:58,350
backlog there isn't actually clear

00:13:55,530 --> 00:14:00,030
further when performing a restart new

00:13:58,350 --> 00:14:02,610
processes have to be created and

00:14:00,030 --> 00:14:04,530
application loaded again this can take

00:14:02,610 --> 00:14:06,840
time and cause more requests to backlog

00:14:04,530 --> 00:14:09,690
so choose carefully when you restart

00:14:06,840 --> 00:14:11,400
- totally reset a system is better to

00:14:09,690 --> 00:14:15,330
actually do a full shutdown and clear

00:14:11,400 --> 00:14:17,190
out the whole backlog for fat pipe from

00:14:15,330 --> 00:14:19,080
web applications of a large data costs

00:14:17,190 --> 00:14:21,360
so the configurations which allow for

00:14:19,080 --> 00:14:23,790
auto scaling can also compound problems

00:14:21,360 --> 00:14:25,710
when under load you get a further

00:14:23,790 --> 00:14:28,230
throughput spike the server can decide

00:14:25,710 --> 00:14:30,240
to let start more processes this slows

00:14:28,230 --> 00:14:32,160
the system down temporarily causing

00:14:30,240 --> 00:14:34,350
backlog and if it takes a long time to

00:14:32,160 --> 00:14:36,990
start processes the server could decide

00:14:34,350 --> 00:14:39,330
to start even more processes increasing

00:14:36,990 --> 00:14:42,960
system load again blowing our memory and

00:14:39,330 --> 00:14:44,730
overloading a whole system to avoid

00:14:42,960 --> 00:14:46,440
unexpected surprises you're better off

00:14:44,730 --> 00:14:49,980
starting up the maximum number of

00:14:46,440 --> 00:14:51,810
processes you expect or require but to

00:14:49,980 --> 00:14:55,110
require or can fit in available memory

00:14:51,810 --> 00:14:57,050
with your web application loaded ensure

00:14:55,110 --> 00:14:59,930
you preload your web application

00:14:57,050 --> 00:15:01,970
start and not lazily when first request

00:14:59,930 --> 00:15:03,880
arrives do everything possible to keep

00:15:01,970 --> 00:15:06,709
the processes in memory at all time

00:15:03,880 --> 00:15:08,660
avoid restarts especially don't use

00:15:06,709 --> 00:15:12,440
options to restart when some maximum

00:15:08,660 --> 00:15:13,640
request count is reached because the

00:15:12,440 --> 00:15:15,110
suggestion is that you should pre

00:15:13,640 --> 00:15:17,420
configure the server to its maximum

00:15:15,110 --> 00:15:18,950
capacity the outset it does limit the

00:15:17,420 --> 00:15:20,750
vertical scaling you can do at least

00:15:18,950 --> 00:15:22,910
within the content confines of the same

00:15:20,750 --> 00:15:25,190
hardware next step therefore is

00:15:22,910 --> 00:15:27,170
horizontal scaling keep in mind the same

00:15:25,190 --> 00:15:28,850
issue about pre loading you don't want

00:15:27,170 --> 00:15:31,010
to bring on new hosts and direct traffic

00:15:28,850 --> 00:15:32,240
to them only for the first requests sent

00:15:31,010 --> 00:15:35,839
to it to be delayed while the

00:15:32,240 --> 00:15:37,940
application loads no matter how you set

00:15:35,839 --> 00:15:39,500
your system if problems do arise the

00:15:37,940 --> 00:15:41,450
only way you're going to start to be

00:15:39,500 --> 00:15:42,829
able to understand what went wrong when

00:15:41,450 --> 00:15:43,370
it does all crash and heap is through

00:15:42,829 --> 00:15:45,470
monitoring

00:15:43,370 --> 00:15:48,230
if you treat your system as a black box

00:15:45,470 --> 00:15:50,000
how we know what is going on inside one

00:15:48,230 --> 00:15:51,529
thing is for sure all those benchmarks

00:15:50,000 --> 00:15:53,690
you may have run to find out what the

00:15:51,529 --> 00:15:57,529
fastest webserver was I'm not going to

00:15:53,690 --> 00:15:59,300
help you one bit at that point 7

00:15:57,529 --> 00:16:00,769
monitoring tools although useful only

00:15:59,300 --> 00:16:02,839
show the effect of the problem on the

00:16:00,769 --> 00:16:05,180
overall system they don't necessarily

00:16:02,839 --> 00:16:08,089
provide you the inside of what is going

00:16:05,180 --> 00:16:09,860
on inside of your web application they

00:16:08,089 --> 00:16:12,320
still largely treat your web application

00:16:09,860 --> 00:16:15,290
and web server like a black box a deeper

00:16:12,320 --> 00:16:16,399
level of introspection is required so

00:16:15,290 --> 00:16:17,690
when we talk about finding out what's

00:16:16,399 --> 00:16:19,190
happening inside of your private web

00:16:17,690 --> 00:16:21,500
application the options have sort of

00:16:19,190 --> 00:16:24,050
been a bit limited tools such as dan go

00:16:21,500 --> 00:16:25,550
to debug tool bar or the / - profiler

00:16:24,050 --> 00:16:27,620
are only suited to a development

00:16:25,550 --> 00:16:29,089
environment century can be used in

00:16:27,620 --> 00:16:30,589
production to capture errors but

00:16:29,089 --> 00:16:33,800
performance problems aren't going to

00:16:30,589 --> 00:16:35,209
generate nice exceptions for you your

00:16:33,800 --> 00:16:36,980
poem option here obviously is in your

00:16:35,209 --> 00:16:38,779
relic at this point it provides the

00:16:36,980 --> 00:16:39,980
ability to monitor the front-end your

00:16:38,779 --> 00:16:41,540
web application and the underlying

00:16:39,980 --> 00:16:43,100
server it gives you that deep

00:16:41,540 --> 00:16:45,890
introspection required to know what is

00:16:43,100 --> 00:16:47,630
going on for me is the author of mod

00:16:45,890 --> 00:16:49,310
WSGI having norelli it means that I've

00:16:47,630 --> 00:16:50,329
actually been able to use the reporting

00:16:49,310 --> 00:16:52,640
it provides to delft

00:16:50,329 --> 00:16:54,560
quite deep into the behavior if mod wsg

00:16:52,640 --> 00:16:56,510
are in different situations and the

00:16:54,560 --> 00:16:57,529
results have been quite revealing one of

00:16:56,510 --> 00:16:59,000
the areas that is helped in

00:16:57,529 --> 00:17:00,680
understanding us is funneling effects

00:16:59,000 --> 00:17:03,019
with when using daemon modes that I have

00:17:00,680 --> 00:17:04,010
talked about I'll admit there is room

00:17:03,019 --> 00:17:05,870
for improvement there

00:17:04,010 --> 00:17:06,890
not wsj it's it's not quite getting it

00:17:05,870 --> 00:17:08,449
right and it's causing a few problems

00:17:06,890 --> 00:17:10,940
that no it's an area which hopefully

00:17:08,449 --> 00:17:15,079
I'll fix up in mod WSGI for if I can get

00:17:10,940 --> 00:17:16,880
the time so so many things are pick a

00:17:15,079 --> 00:17:18,740
web server an architecture which seems

00:17:16,880 --> 00:17:20,810
to meet your requirements then use

00:17:18,740 --> 00:17:23,060
benchmarks to evaluate behavior

00:17:20,810 --> 00:17:24,920
don't use benchmarks simply to try and

00:17:23,060 --> 00:17:27,380
compare different systems don't trust

00:17:24,920 --> 00:17:29,300
server defaults configure and tune your

00:17:27,380 --> 00:17:31,880
whole stack based on the results you get

00:17:29,300 --> 00:17:33,500
from live production monitoring using

00:17:31,880 --> 00:17:37,100
your le for deep introspection of what

00:17:33,500 --> 00:17:38,540
is going on all parts of your system so

00:17:37,100 --> 00:17:40,310
if you are doing piping web application

00:17:38,540 --> 00:17:42,530
development do therefore consider giving

00:17:40,310 --> 00:17:44,090
Niroula control if you're not sure New

00:17:42,530 --> 00:17:45,530
Relic does provide a free trial period

00:17:44,090 --> 00:17:48,110
where you can try and all the features

00:17:45,530 --> 00:17:49,790
it has when even when the trial ends

00:17:48,110 --> 00:17:51,200
there's a free life subscription level

00:17:49,790 --> 00:17:53,060
which is available and still provides

00:17:51,200 --> 00:17:54,590
lots of useful information so give it a

00:17:53,060 --> 00:17:56,000
try the worst thing that can happen is

00:17:54,590 --> 00:18:03,490
you actually find out how bad your web

00:17:56,000 --> 00:18:03,490
application is performing cool thanks

00:18:05,320 --> 00:18:16,300
have we got any questions for Graham and

00:18:12,670 --> 00:18:19,200
always rely on Russell russek's Plains

00:18:16,300 --> 00:18:21,820
me one day why he always rushes up to

00:18:19,200 --> 00:18:23,470
make the first question if it's a diesel

00:18:21,820 --> 00:18:26,440
my thing story it is on my blog come

00:18:23,470 --> 00:18:28,630
saying if you want to find out here okay

00:18:26,440 --> 00:18:30,220
so what I completely agree what you're

00:18:28,630 --> 00:18:31,840
saying here I will also just throw in a

00:18:30,220 --> 00:18:33,610
free plug on your behalf and you really

00:18:31,840 --> 00:18:34,870
awesome and it's just safe I asked so

00:18:33,610 --> 00:18:38,410
many times the last two weeks is how

00:18:34,870 --> 00:18:39,700
funny what you said saying here's a

00:18:38,410 --> 00:18:41,500
unique you need to know how your book

00:18:39,700 --> 00:18:42,400
your application performs and the best

00:18:41,500 --> 00:18:46,450
way to do that is to get live

00:18:42,400 --> 00:18:47,770
performance benchmarks however that does

00:18:46,450 --> 00:18:49,570
leave you a little bit open - oh crap

00:18:47,770 --> 00:18:52,150
moments where hey I'm gonna move move

00:18:49,570 --> 00:18:54,310
I'm going to deploy my news site and you

00:18:52,150 --> 00:18:55,900
don't have live data yet because you

00:18:54,310 --> 00:18:58,390
haven't got actual users you don't know

00:18:55,900 --> 00:19:00,100
how big necessarily your Python

00:18:58,390 --> 00:19:03,100
application is going to be when it gets

00:19:00,100 --> 00:19:05,950
deployed any suggestions or tips on how

00:19:03,100 --> 00:19:07,300
you could set up in such a way that you

00:19:05,950 --> 00:19:09,430
can at least get a reasonable first

00:19:07,300 --> 00:19:10,840
estimate so you don't deploy to servers

00:19:09,430 --> 00:19:13,480
when you actually do tend to supply the

00:19:10,840 --> 00:19:15,160
load that you're expecting to get well

00:19:13,480 --> 00:19:17,140
the normal way people would handle that

00:19:15,160 --> 00:19:19,810
office is try and do benchmarking in a

00:19:17,140 --> 00:19:21,490
staging system there's obviously no

00:19:19,810 --> 00:19:23,620
reason where you can't put your looking

00:19:21,490 --> 00:19:25,180
there to try and gauge how that's going

00:19:23,620 --> 00:19:28,270
to work but it's the same problem your

00:19:25,180 --> 00:19:29,530
variability be users and the different

00:19:28,270 --> 00:19:31,000
connections they come over and the

00:19:29,530 --> 00:19:33,730
different browsers that using doesn't

00:19:31,000 --> 00:19:36,880
make that really hard so yeah there's

00:19:33,730 --> 00:19:40,050
still no simple answer for that except

00:19:36,880 --> 00:19:40,050
the techniques which exist already

00:19:41,670 --> 00:19:50,050
thanks Russ anybody else I actually have

00:19:47,050 --> 00:19:54,580
a question it's advantage of having the

00:19:50,050 --> 00:19:57,340
microphone you said in one of the slides

00:19:54,580 --> 00:20:00,520
about putting nginx in front of a

00:19:57,340 --> 00:20:05,260
unicorn or something like that for slow

00:20:00,520 --> 00:20:08,110
clients is does Apache and mod whiskey

00:20:05,260 --> 00:20:10,300
get you a similar thing because the you

00:20:08,110 --> 00:20:11,950
know your Python is kind of running

00:20:10,300 --> 00:20:14,529
through mod whiskey or is

00:20:11,950 --> 00:20:17,529
advantageous still to have something

00:20:14,529 --> 00:20:19,929
like nginx in front of Apache and mod

00:20:17,529 --> 00:20:21,519
whiskey it's still it it's still good to

00:20:19,929 --> 00:20:24,639
have engineers in front and the reason

00:20:21,519 --> 00:20:26,380
for this is that nginx is async

00:20:24,639 --> 00:20:27,639
so you don't have this problem of if

00:20:26,380 --> 00:20:29,169
you've got a large number of concurrent

00:20:27,639 --> 00:20:31,480
requests of having to have every one

00:20:29,169 --> 00:20:33,549
thread per request so the memory

00:20:31,480 --> 00:20:35,440
footprint is really low and what engine

00:20:33,549 --> 00:20:36,909
X does is that when it gets a request in

00:20:35,440 --> 00:20:39,490
and its proxying through to a back-end

00:20:36,909 --> 00:20:40,990
such as green tea corn or Apache is it

00:20:39,490 --> 00:20:42,909
won't actually bother proxying

00:20:40,990 --> 00:20:45,490
until it's read all the request headers

00:20:42,909 --> 00:20:47,380
and also depending on your configuration

00:20:45,490 --> 00:20:49,480
and I think the default is one megabyte

00:20:47,380 --> 00:20:51,789
if if the request content is less than

00:20:49,480 --> 00:20:54,190
one megabyte it will wait till it reads

00:20:51,789 --> 00:20:56,049
all that in as well before it even sends

00:20:54,190 --> 00:20:57,940
it through the back end so it's

00:20:56,049 --> 00:20:59,620
effectively got then the whole request

00:20:57,940 --> 00:21:02,470
available so when you do send it through

00:20:59,620 --> 00:21:03,760
to Apache it can immediately act on it

00:21:02,470 --> 00:21:05,889
because it's got everything it needs to

00:21:03,760 --> 00:21:07,330
and this is where the advantage comes

00:21:05,889 --> 00:21:10,120
whereas if a patchy handle it

00:21:07,330 --> 00:21:12,820
immediately and you've got a slow client

00:21:10,120 --> 00:21:15,179
and that data dribbles in very slowly in

00:21:12,820 --> 00:21:18,159
comparative leaps to what could be fast

00:21:15,179 --> 00:21:19,840
then you're tying up that fred and that

00:21:18,159 --> 00:21:21,490
means you you're limiting the resources

00:21:19,840 --> 00:21:23,830
got to handle an unrealized I'm a

00:21:21,490 --> 00:21:25,360
concurrent requests so that's why what

00:21:23,830 --> 00:21:28,419
so that's where the benefit comes from

00:21:25,360 --> 00:21:30,669
is that waiting for all that request

00:21:28,419 --> 00:21:32,649
content to come in they know then on the

00:21:30,669 --> 00:21:34,899
way back when you send your response

00:21:32,649 --> 00:21:37,690
back because you've got that buffering

00:21:34,899 --> 00:21:40,389
within the socket between Apache and

00:21:37,690 --> 00:21:43,059
nginx it can essentially push out quite

00:21:40,389 --> 00:21:44,740
a lot immediately an engine extent is

00:21:43,059 --> 00:21:46,960
the one that this sort of again gives a

00:21:44,740 --> 00:21:50,769
bit more buffering and contribute the

00:21:46,960 --> 00:21:52,990
response so Apache only gets the request

00:21:50,769 --> 00:21:54,159
when it can act on it so can get it then

00:21:52,990 --> 00:21:56,049
just immediately handed off the

00:21:54,159 --> 00:21:58,120
application run it and it can offload

00:21:56,049 --> 00:21:59,740
that response very quickly so that is

00:21:58,120 --> 00:22:04,570
the benefit from having engineers in

00:21:59,740 --> 00:22:05,380
front oh that's great I'll just I can

00:22:04,570 --> 00:22:07,389
allege to that one as well

00:22:05,380 --> 00:22:09,070
completely great the other reason that's

00:22:07,389 --> 00:22:10,870
worth it and this is I'm in a Django

00:22:09,070 --> 00:22:13,330
context we've I've learned the hard way

00:22:10,870 --> 00:22:15,399
but it's also true of other web servers

00:22:13,330 --> 00:22:17,500
nginx is really really good at serving

00:22:15,399 --> 00:22:19,120
flat for serving serving static files so

00:22:17,500 --> 00:22:20,169
you can have your Apache thing that's

00:22:19,120 --> 00:22:21,700
actually doing the heavy lift

00:22:20,169 --> 00:22:23,350
with the database and it has a big

00:22:21,700 --> 00:22:25,600
memory footprint for every post Pro

00:22:23,350 --> 00:22:26,950
processes there and then you've got the

00:22:25,600 --> 00:22:28,090
files just being served really really

00:22:26,950 --> 00:22:30,309
quickly out of nginx so the only

00:22:28,090 --> 00:22:31,359
requests that are taking up your apache

00:22:30,309 --> 00:22:33,100
are the ones that actually need to use

00:22:31,359 --> 00:22:35,049
apache and everything else is just going

00:22:33,100 --> 00:22:37,239
straight out so yeah and one of the

00:22:35,049 --> 00:22:40,389
other things in engine X which not been

00:22:37,239 --> 00:22:42,489
any they would know about there's a you

00:22:40,389 --> 00:22:46,480
can actually send back a header from

00:22:42,489 --> 00:22:50,019
Apache which is an X accelerate XSL

00:22:46,480 --> 00:22:51,730
redirect or something what it allows you

00:22:50,019 --> 00:22:54,460
to do is essentially if you're

00:22:51,730 --> 00:22:56,950
generating a very large response or or

00:22:54,460 --> 00:23:02,200
you're having to gate access to a file

00:22:56,950 --> 00:23:04,629
via Django's authorization mechanism so

00:23:02,200 --> 00:23:05,980
it's not a static file which is just

00:23:04,629 --> 00:23:07,690
publicly accessible so you can't have

00:23:05,980 --> 00:23:08,859
engineers immediately serve it up you

00:23:07,690 --> 00:23:10,989
need to go through all the indication

00:23:08,859 --> 00:23:12,609
everything if that file exists from the

00:23:10,989 --> 00:23:14,710
file system rather than actually have

00:23:12,609 --> 00:23:16,210
the Django app send the file back you

00:23:14,710 --> 00:23:18,580
can just send back this except X

00:23:16,210 --> 00:23:20,440
accelerate accel redirect header to

00:23:18,580 --> 00:23:24,159
engineers and as long as you set up

00:23:20,440 --> 00:23:25,899
engineers in a way that that file system

00:23:24,159 --> 00:23:28,210
error is essentially is a private area

00:23:25,899 --> 00:23:30,429
which only internal requests and

00:23:28,210 --> 00:23:32,859
engineers can server since you say ok

00:23:30,429 --> 00:23:34,570
I'll let you in I need to serve this big

00:23:32,859 --> 00:23:37,059
large response but here it is over here

00:23:34,570 --> 00:23:39,100
and get nginx serves that up as well so

00:23:37,059 --> 00:23:41,080
you can actually do things like that as

00:23:39,100 --> 00:23:46,559
well which is very beneficial that's

00:23:41,080 --> 00:23:46,559
that's really cool well ok

00:23:47,220 --> 00:23:50,789
now thanks for mentioning that I

00:23:49,090 --> 00:23:54,159
actually use that feature of my own

00:23:50,789 --> 00:23:56,230
hosting services where i authenticated

00:23:54,159 --> 00:23:58,600
in the django layer then offload the

00:23:56,230 --> 00:24:02,259
Ashville sending the file once it's

00:23:58,600 --> 00:24:05,289
poetic event in the genetics I said I

00:24:02,259 --> 00:24:07,539
should ask suppose the typical

00:24:05,289 --> 00:24:12,450
configuration I use is straight nginx

00:24:07,539 --> 00:24:14,830
proxy back to G unicorn we talked to the

00:24:12,450 --> 00:24:18,119
pros and cons of that approach versus

00:24:14,830 --> 00:24:18,119
having a party in the middle as well

00:24:18,539 --> 00:24:24,549
Apache in the middle of nginx patchy

00:24:21,279 --> 00:24:25,779
unicorn why you mean don't relax in

00:24:24,549 --> 00:24:28,509
front a punch in the middle and then

00:24:25,779 --> 00:24:29,889
Django the backend no he just stick in

00:24:28,509 --> 00:24:31,179
your corner straight in front of behind

00:24:29,889 --> 00:24:33,639
straight behind engineer there's no

00:24:31,179 --> 00:24:35,769
movie no point having Apache involved if

00:24:33,639 --> 00:24:41,350
you're using guna con at that point okay

00:24:35,769 --> 00:24:43,419
but but I mean you can't run might as my

00:24:41,350 --> 00:24:44,860
WSGI away which effectively has been the

00:24:43,419 --> 00:24:47,409
same things G unicorn does as I

00:24:44,860 --> 00:24:53,049
understand it you'd have us chained by

00:24:47,409 --> 00:24:54,820
the Apache WSGI my jaw oh yes Joe in

00:24:53,049 --> 00:24:56,740
other words why would I want to use

00:24:54,820 --> 00:24:59,619
apply to you or jewnicorn instead of the

00:24:56,740 --> 00:25:01,720
other okay the thing with Apache does

00:24:59,619 --> 00:25:05,440
provide a lot of built-in modules from a

00:25:01,720 --> 00:25:08,289
lot of weird things windows indication

00:25:05,440 --> 00:25:10,179
all sorts of things like that so it's

00:25:08,289 --> 00:25:13,779
like it's like the batteries included

00:25:10,179 --> 00:25:15,399
mentality of Python so a lot of people

00:25:13,779 --> 00:25:16,840
use it for that reason it does have all

00:25:15,399 --> 00:25:18,249
this existing functionality which if you

00:25:16,840 --> 00:25:19,509
just think GU nakorn behind

00:25:18,249 --> 00:25:22,059
nginx you're not going to have all those

00:25:19,509 --> 00:25:23,860
extra features the other preferences

00:25:22,059 --> 00:25:25,090
people have for using Apache is that

00:25:23,860 --> 00:25:27,039
they've got system administrators to

00:25:25,090 --> 00:25:28,539
understand it so it can be allowed to do

00:25:27,039 --> 00:25:30,279
with comfort of understanding the

00:25:28,539 --> 00:25:32,139
particular environment you're using so

00:25:30,279 --> 00:25:33,669
there's this various reasons and and

00:25:32,139 --> 00:25:35,289
these days the performance or the

00:25:33,669 --> 00:25:36,460
different solutions when you really get

00:25:35,289 --> 00:25:37,869
down to it if you configure them

00:25:36,460 --> 00:25:39,869
properly is not really much difference

00:25:37,869 --> 00:25:42,429
at the server level because most of the

00:25:39,869 --> 00:25:43,629
bottleneck is in your app your databases

00:25:42,429 --> 00:25:46,090
your problems in front end time and

00:25:43,629 --> 00:25:48,879
things like this so whenever someone

00:25:46,090 --> 00:25:51,990
asks me people ask well what should I

00:25:48,879 --> 00:25:54,720
use you'll never find me saying

00:25:51,990 --> 00:25:56,910
use mod WSGI and Apache my answer is

00:25:54,720 --> 00:25:59,580
always going to be go find the one which

00:25:56,910 --> 00:26:01,410
suits your mindset of how you think and

00:25:59,580 --> 00:26:03,690
what you're think you're capable of

00:26:01,410 --> 00:26:06,090
managing because that's more important

00:26:03,690 --> 00:26:07,770
you know how to manage it because a lot

00:26:06,090 --> 00:26:10,080
of people are scared off by Apache and

00:26:07,770 --> 00:26:11,850
Finance so so complicated and it's very

00:26:10,080 --> 00:26:13,980
easy for them stuff set configuration up

00:26:11,850 --> 00:26:15,420
and make a big mess whereas the defaults

00:26:13,980 --> 00:26:19,530
and unicorn are actually probably more

00:26:15,420 --> 00:26:21,150
friendly and for PyCon next year I

00:26:19,530 --> 00:26:21,780
actually intend to try and put it in

00:26:21,150 --> 00:26:24,450
Talk

00:26:21,780 --> 00:26:26,580
why Apache sucks for hosting Python

00:26:24,450 --> 00:26:29,880
Python web applications because the

00:26:26,580 --> 00:26:31,520
default Apache configuration is more

00:26:29,880 --> 00:26:35,040
suited for static file handing and PHP

00:26:31,520 --> 00:26:38,160
it's not a good default setup for Python

00:26:35,040 --> 00:26:40,230
and when people just grab a solution and

00:26:38,160 --> 00:26:41,700
whack it in you're not necessarily going

00:26:40,230 --> 00:26:43,679
to get the best experience from it

00:26:41,700 --> 00:26:47,730
especially if you use embedded node in

00:26:43,679 --> 00:26:49,080
pre fork NPM so no safe situation which

00:26:47,730 --> 00:26:50,820
people aren't prepared to go in and try

00:26:49,080 --> 00:26:53,000
and work out how to set up patchy profit

00:26:50,820 --> 00:26:55,559
unicorn is a better solution

00:26:53,000 --> 00:26:58,080
I've got an better native solution if

00:26:55,559 --> 00:27:00,360
you like I mean a naive solution I

00:26:58,080 --> 00:27:02,429
wouldn't say no I've it's just better

00:27:00,360 --> 00:27:03,420
for those people who don't have that

00:27:02,429 --> 00:27:04,950
it's what people are going to get on in

00:27:03,420 --> 00:27:09,890
program people who don't want to do

00:27:04,950 --> 00:27:09,890
system admin that that's means anything

00:27:10,700 --> 00:27:15,330
just just on a point of the fact that

00:27:14,190 --> 00:27:17,630
Apache can be difficult to configure

00:27:15,330 --> 00:27:20,610
correctly for these different use cases

00:27:17,630 --> 00:27:22,530
it's other any resources that where you

00:27:20,610 --> 00:27:24,900
can go to get a boiler place or good

00:27:22,530 --> 00:27:26,850
example beginning configuration

00:27:24,900 --> 00:27:29,610
templates you could start from because

00:27:26,850 --> 00:27:30,960
yeah it's time from this the default

00:27:29,610 --> 00:27:32,100
Apache configuration and then trying to

00:27:30,960 --> 00:27:33,570
weed out everything you don't need and

00:27:32,100 --> 00:27:36,030
get it correct is pretty daunting a

00:27:33,570 --> 00:27:37,830
difficult I mean if if baseline

00:27:36,030 --> 00:27:40,230
configuration files were provided that

00:27:37,830 --> 00:27:42,000
made it much easier I think people would

00:27:40,230 --> 00:27:42,510
be less resistant to try to do that

00:27:42,000 --> 00:27:45,809
themselves

00:27:42,510 --> 00:27:48,390
my first guidance is do please always

00:27:45,809 --> 00:27:50,429
use what the Apache configuration is

00:27:48,390 --> 00:27:52,230
that shipped I haven't see people who

00:27:50,429 --> 00:27:54,809
recommend throwing it all the way

00:27:52,230 --> 00:27:57,179
completely and then providing in putting

00:27:54,809 --> 00:27:58,350
in just a minimal required the problem

00:27:57,179 --> 00:28:01,010
is there's a whole lot of default in

00:27:58,350 --> 00:28:03,650
there which make your system secure

00:28:01,010 --> 00:28:05,900
and by throwing it all out it actually

00:28:03,650 --> 00:28:08,270
falls back to actually making some

00:28:05,900 --> 00:28:11,150
things a bit insecure so for example if

00:28:08,270 --> 00:28:13,040
you throw it all the configuration the

00:28:11,150 --> 00:28:15,200
patent to default in patchy is that is

00:28:13,040 --> 00:28:16,990
if a patchy can map a URL to your file

00:28:15,200 --> 00:28:19,669
system it will then serve up anything

00:28:16,990 --> 00:28:21,980
whereas the default supplied Apache

00:28:19,669 --> 00:28:23,419
configuration files will say well no

00:28:21,980 --> 00:28:25,280
we're going to say everything from slash

00:28:23,419 --> 00:28:29,210
you're not allowed in there and then it

00:28:25,280 --> 00:28:34,010
will expose certain bits so Oh a juicy

00:28:29,210 --> 00:28:36,110
Apache one if you're gonna just because

00:28:34,010 --> 00:28:38,059
mod W shows to Moses embedded mode and

00:28:36,110 --> 00:28:40,280
demand better motors where it runs in

00:28:38,059 --> 00:28:41,720
the Apache worker processes if you're

00:28:40,280 --> 00:28:44,780
going to use embedded mode always use

00:28:41,720 --> 00:28:45,950
work or MPN don't use pre fork npm if

00:28:44,780 --> 00:28:48,590
you don't know what you're doing like

00:28:45,950 --> 00:28:49,640
pre fork npm behind engineers with my

00:28:48,590 --> 00:28:51,559
dear which is actually going to give you

00:28:49,640 --> 00:28:54,970
the best performance but you do need to

00:28:51,559 --> 00:28:57,650
be very careful how you set it up so

00:28:54,970 --> 00:29:00,380
that's my first warning on that one now

00:28:57,650 --> 00:29:01,850
in terms of the talk i intend giving a

00:29:00,380 --> 00:29:03,860
park on one of the things i hope to come

00:29:01,850 --> 00:29:05,720
out of that is and i'll play with it a

00:29:03,860 --> 00:29:09,320
bit already I've got some scripts which

00:29:05,720 --> 00:29:11,660
will take Apache NPM settings and draw

00:29:09,320 --> 00:29:13,520
some nice charts all I was doing in

00:29:11,660 --> 00:29:15,679
spreadsheet actually from once I

00:29:13,520 --> 00:29:17,030
generated the data and George you were a

00:29:15,679 --> 00:29:20,090
nice little chart about how that

00:29:17,030 --> 00:29:22,460
configuration behaves as requests

00:29:20,090 --> 00:29:23,750
concurrent requests comes in and it

00:29:22,460 --> 00:29:25,760
quickly shows when you've picked a

00:29:23,750 --> 00:29:27,530
really bad config because there's some

00:29:25,760 --> 00:29:29,059
certain rules you should follow in in

00:29:27,530 --> 00:29:32,059
patchy and PM settings and if you don't

00:29:29,059 --> 00:29:34,850
do it right you can have Apache thinking

00:29:32,059 --> 00:29:36,380
are you don't have enough processes to

00:29:34,850 --> 00:29:38,780
handle the number of concurrent requests

00:29:36,380 --> 00:29:40,070
can I'll create more worker processes

00:29:38,780 --> 00:29:42,410
for you if you're using embedded mode

00:29:40,070 --> 00:29:43,730
and then on the next iteration because

00:29:42,410 --> 00:29:45,530
you've stuffed up the config it'll say

00:29:43,730 --> 00:29:47,000
actually now I think you've got more

00:29:45,530 --> 00:29:48,980
than you need and I'll delete it it'll

00:29:47,000 --> 00:29:51,200
destroy a straightaway so you're not

00:29:48,980 --> 00:29:52,429
getting this flashing of processes so

00:29:51,200 --> 00:29:53,960
there's a lot of tricks like that yes

00:29:52,429 --> 00:29:55,600
which is good and they're sort of sort

00:29:53,960 --> 00:29:58,070
of things hopefully I'm going to

00:29:55,600 --> 00:30:00,590
document for this talk doing parkour

00:29:58,070 --> 00:30:03,380
next year and hopefully have a website

00:30:00,590 --> 00:30:05,990
set up where you can go in here plug in

00:30:03,380 --> 00:30:07,640
your MPM settings for apache

00:30:05,990 --> 00:30:08,990
Figg at least 50 working using embedded

00:30:07,640 --> 00:30:10,880
mode and I'll draw you this nice little

00:30:08,990 --> 00:30:13,460
chart with an explanation of what it

00:30:10,880 --> 00:30:16,610
means and try and point out what you're

00:30:13,460 --> 00:30:19,940
doing this this is wrong and so on so I

00:30:16,610 --> 00:30:21,980
that's something I hope to do yeah well

00:30:19,940 --> 00:30:24,050
I always want to do these sorts because

00:30:21,980 --> 00:30:26,059
another way comes at the time but I

00:30:24,050 --> 00:30:27,920
figure I've got this thing on my head in

00:30:26,059 --> 00:30:31,100
already that for next year's pipeline

00:30:27,920 --> 00:30:32,570
and I well had grand ideas to make this

00:30:31,100 --> 00:30:34,160
talk last year as well which I didn't

00:30:32,570 --> 00:30:35,990
get too out of it I forget I think this

00:30:34,160 --> 00:30:40,070
talking to try and start and work on

00:30:35,990 --> 00:30:41,480
this okay I know we had a couple another

00:30:40,070 --> 00:30:43,940
question but I think we've run out of

00:30:41,480 --> 00:30:48,010
time so we're gonna have to move on yeah

00:30:43,940 --> 00:30:48,010

YouTube URL: https://www.youtube.com/watch?v=eOkxLCCbU9w


