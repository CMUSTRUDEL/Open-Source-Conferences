Title: "Lessons learned building Python microservices" - Richard Jones (PyCon AU 2019)
Publication date: 2019-08-03
Playlist: PyCon Australia 2019
Description: 
	Richard Jones

I will talk about challenges and wins that have come from introducing Python into a multilingual microservices kubernetes architecture with lots of legacy.

https://2019.pycon-au.org/talks/lessons-learned-building-python-microservices

PyCon AU, the national Python Language conference, is on again this August in Sydney, at the International Convention Centre, Sydney, August 2 - 6 2019.

Video licence: CC BY-NC-SA 4.0 - https://creativecommons.org/licenses/by-nc-sa/4.0/

Python, PyCon, PyConAU

Sat Aug  3 10:30:00 2019 at C3.3
Captions: 
	00:00:00,060 --> 00:00:06,000
good morning everybody and welcome to

00:00:02,010 --> 00:00:08,340
room C three one three we now have up

00:00:06,000 --> 00:00:09,510
Richard Jones to talk us to us about

00:00:08,340 --> 00:00:18,960
market services

00:00:09,510 --> 00:00:20,460
Thank You Justin and I'm gonna have a

00:00:18,960 --> 00:00:23,039
bit of an experiment here I'm gonna try

00:00:20,460 --> 00:00:24,840
doing this without my glasses so if I

00:00:23,039 --> 00:00:29,960
start rambling it's because I'm old and

00:00:24,840 --> 00:00:33,540
I can't read alrighty so I've been a

00:00:29,960 --> 00:00:36,210
Python developer for over two decades

00:00:33,540 --> 00:00:39,989
now and recently I've been getting into

00:00:36,210 --> 00:00:40,950
micro services in kind of a big way at

00:00:39,989 --> 00:00:43,410
the very first

00:00:40,950 --> 00:00:46,020
PyCon a you I think is the first one I

00:00:43,410 --> 00:00:48,989
actually gave a talk about doing micro

00:00:46,020 --> 00:00:50,850
services using micro frameworks and that

00:00:48,989 --> 00:00:52,559
was fascinating at the time but it's

00:00:50,850 --> 00:00:55,680
only in the last couple of years that

00:00:52,559 --> 00:00:58,980
have been getting into like dozens of

00:00:55,680 --> 00:01:01,320
micro services to support a business so

00:00:58,980 --> 00:01:05,010
this talk is pretty much the things that

00:01:01,320 --> 00:01:07,650
we've learned as a team over that over

00:01:05,010 --> 00:01:10,260
that two years that journey so I work

00:01:07,650 --> 00:01:13,890
for Rhys and we have an IT system that

00:01:10,260 --> 00:01:15,210
is itself decades old and it's grown to

00:01:13,890 --> 00:01:18,210
support a business that's been around

00:01:15,210 --> 00:01:20,400
for almost a hundred years and we have

00:01:18,210 --> 00:01:21,750
some pretty unique business processes so

00:01:20,400 --> 00:01:23,130
it's it's kind of in there's some

00:01:21,750 --> 00:01:24,840
interesting stuff in that we'll work on

00:01:23,130 --> 00:01:26,909
and it's a bigger IT department you

00:01:24,840 --> 00:01:31,650
probably think for a plumbing supply

00:01:26,909 --> 00:01:35,280
company but what even our micro services

00:01:31,650 --> 00:01:37,710
I hear you ask so you know how you're

00:01:35,280 --> 00:01:39,869
huge organically growing codebase

00:01:37,710 --> 00:01:40,439
resembles something akin to a bowl of

00:01:39,869 --> 00:01:42,750
spaghetti

00:01:40,439 --> 00:01:44,340
the term spaghetti code is probably

00:01:42,750 --> 00:01:47,250
something you're familiar with well

00:01:44,340 --> 00:01:49,790
micro services I kind of like a bowl of

00:01:47,250 --> 00:01:52,799
spaghetti with meatballs there's

00:01:49,790 --> 00:01:54,950
slightly less mess little blobs of water

00:01:52,799 --> 00:01:58,649
and it's very tasty

00:01:54,950 --> 00:01:59,640
you know that's micro services so these

00:01:58,649 --> 00:02:01,950
are the things that I'm going to be

00:01:59,640 --> 00:02:04,259
talking about today roughly speaking a

00:02:01,950 --> 00:02:06,420
bunch of different subjects things that

00:02:04,259 --> 00:02:10,800
we've run into and things that we've

00:02:06,420 --> 00:02:13,110
learnt along the way so just to give you

00:02:10,800 --> 00:02:13,680
some sort of context the architecture

00:02:13,110 --> 00:02:18,890
that we've been

00:02:13,680 --> 00:02:21,930
today we have a kubernetes cluster

00:02:18,890 --> 00:02:25,200
managing dozens of micro services in

00:02:21,930 --> 00:02:28,140
Java and Python with angular front ends

00:02:25,200 --> 00:02:31,980
using the BFF pattern can I get a hands

00:02:28,140 --> 00:02:34,530
up who's heard of the BFF pattern I'm

00:02:31,980 --> 00:02:36,569
gonna come back to that though we do

00:02:34,530 --> 00:02:39,379
also have a monolithic genero

00:02:36,569 --> 00:02:44,489
application who's heard of Gennaro

00:02:39,379 --> 00:02:48,569
Frankie good on you my coworker in the

00:02:44,489 --> 00:02:50,370
audience and we have a single info mix

00:02:48,569 --> 00:02:51,989
database underlying it all now this

00:02:50,370 --> 00:02:54,780
one's probably a bit more more popular

00:02:51,989 --> 00:02:57,780
who's heard of Infinix yes

00:02:54,780 --> 00:03:01,069
five-six excellent I hadn't heard of

00:02:57,780 --> 00:03:04,260
either of them before I started at Ries

00:03:01,069 --> 00:03:07,200
interactions between our services in

00:03:04,260 --> 00:03:09,480
that cluster are verified through

00:03:07,200 --> 00:03:12,150
contracts which I'll come back to so the

00:03:09,480 --> 00:03:14,250
services are loosely domain based so

00:03:12,150 --> 00:03:17,159
there's one for users and one for

00:03:14,250 --> 00:03:20,099
customers and and so on and they're all

00:03:17,159 --> 00:03:24,239
loosely coupled supported by these

00:03:20,099 --> 00:03:25,799
contracts we have users internally at

00:03:24,239 --> 00:03:27,810
our branches there's about eight hundred

00:03:25,799 --> 00:03:31,169
branches in Australia or in New Zealand

00:03:27,810 --> 00:03:33,449
and they use a suite of angular and

00:03:31,169 --> 00:03:35,760
genero applications on their counter

00:03:33,449 --> 00:03:38,959
computers we also have the general

00:03:35,760 --> 00:03:41,430
public accessing our public websites I

00:03:38,959 --> 00:03:44,459
think we've done a pretty darn good job

00:03:41,430 --> 00:03:46,650
of successfully operating this bilingual

00:03:44,459 --> 00:03:48,389
environment because we've ensured those

00:03:46,650 --> 00:03:49,949
services are loosely coupled and

00:03:48,389 --> 00:03:54,269
interactions are supported by those

00:03:49,949 --> 00:03:57,780
contracts an individual Python service

00:03:54,269 --> 00:03:59,370
looks like this roughly speaking it's a

00:03:57,780 --> 00:04:02,400
docker container and it has django

00:03:59,370 --> 00:04:04,439
running in it under mod whiskey and it

00:04:02,400 --> 00:04:09,870
uses Django rest framework that's the

00:04:04,439 --> 00:04:12,180
DRF there it's a very long we run over

00:04:09,870 --> 00:04:16,079
infer mix that's the database and we

00:04:12,180 --> 00:04:19,099
have we use PI ODBC to interface to that

00:04:16,079 --> 00:04:22,279
and we have a django intermix DB

00:04:19,099 --> 00:04:25,290
interface for django which we maintain

00:04:22,279 --> 00:04:27,630
to to run specifics for the

00:04:25,290 --> 00:04:30,720
Phenix database calls to all of our

00:04:27,630 --> 00:04:35,010
other services are encapsulated in API

00:04:30,720 --> 00:04:38,190
libraries we don't embed calls to our

00:04:35,010 --> 00:04:41,610
other services in our services using

00:04:38,190 --> 00:04:44,070
requests directly we encapsulate them so

00:04:41,610 --> 00:04:46,650
that we can have consistent and robust

00:04:44,070 --> 00:04:48,330
handling of inputs and errors as

00:04:46,650 --> 00:04:50,850
appropriate and we're not just copy and

00:04:48,330 --> 00:04:53,540
pasting a particular version of a call

00:04:50,850 --> 00:04:57,000
to another service across our codebase

00:04:53,540 --> 00:04:59,190
those libraries sit over a common HTTP

00:04:57,000 --> 00:05:01,320
layer that we maintain based on requests

00:04:59,190 --> 00:05:03,980
which has additional common features

00:05:01,320 --> 00:05:06,930
like request tracking IDs and

00:05:03,980 --> 00:05:08,190
authentication it also has some other

00:05:06,930 --> 00:05:12,510
bells and whistles that I'll be coming

00:05:08,190 --> 00:05:15,390
back to in some micro service

00:05:12,510 --> 00:05:16,950
architectures front ends the user

00:05:15,390 --> 00:05:20,370
interfaces are not allowed to talk

00:05:16,950 --> 00:05:22,410
directly to services or the database but

00:05:20,370 --> 00:05:24,630
must instead talk through posh proxy

00:05:22,410 --> 00:05:27,900
services and these are called backends

00:05:24,630 --> 00:05:29,760
for front ends the merit of this is

00:05:27,900 --> 00:05:32,400
debatable and I'm happy to talk about

00:05:29,760 --> 00:05:33,750
that after the talk but this is the

00:05:32,400 --> 00:05:37,020
pattern that we've implemented across

00:05:33,750 --> 00:05:39,300
the board so the applet the architecture

00:05:37,020 --> 00:05:42,210
of a Python front-end app is similar to

00:05:39,300 --> 00:05:43,730
our back-end app to a service it has the

00:05:42,210 --> 00:05:47,040
docker container with the Django

00:05:43,730 --> 00:05:49,590
operating as the BFF but aside mod

00:05:47,040 --> 00:05:52,680
whiskey we have the angular code which

00:05:49,590 --> 00:05:55,500
is served up by Apache as well we still

00:05:52,680 --> 00:05:58,050
run those calls to the services through

00:05:55,500 --> 00:06:02,820
the API libraries but you'll note

00:05:58,050 --> 00:06:04,170
there's no connection to the database so

00:06:02,820 --> 00:06:07,820
one of the big wings that we found in

00:06:04,170 --> 00:06:10,860
our teams is the use of get sub modules

00:06:07,820 --> 00:06:12,990
so when we're using those libraries to

00:06:10,860 --> 00:06:15,240
connect to those services that in our

00:06:12,990 --> 00:06:16,950
organization we've found it super

00:06:15,240 --> 00:06:19,650
convenient to be able to work on the

00:06:16,950 --> 00:06:21,090
service that we're working on and the

00:06:19,650 --> 00:06:24,510
API library connecting to the other

00:06:21,090 --> 00:06:26,460
service at the same time using git sub

00:06:24,510 --> 00:06:28,680
modules you can pull in a library

00:06:26,460 --> 00:06:31,230
repository into a service repository

00:06:28,680 --> 00:06:34,320
pinned to a specific commit of the

00:06:31,230 --> 00:06:36,960
library repository and then you can work

00:06:34,320 --> 00:06:38,999
on that code at the same time making

00:06:36,960 --> 00:06:41,869
changes to both code bases

00:06:38,999 --> 00:06:44,669
pycharm has excellent support for this

00:06:41,869 --> 00:06:47,519
allowing us to perform effectively a

00:06:44,669 --> 00:06:48,899
single commit and push resulting in all

00:06:47,519 --> 00:06:51,089
of those repositories that have been

00:06:48,899 --> 00:06:53,999
affected being committed and pushed at

00:06:51,089 --> 00:06:56,849
the same time this prevents the need for

00:06:53,999 --> 00:06:58,679
making a release of the library getting

00:06:56,849 --> 00:07:00,329
it slightly wrong making another release

00:06:58,679 --> 00:07:03,529
of a library pulling it into the service

00:07:00,329 --> 00:07:05,610
updating the service and so on

00:07:03,529 --> 00:07:12,419
significantly speeds up at that

00:07:05,610 --> 00:07:14,999
development cycle consistency of

00:07:12,419 --> 00:07:16,949
environment and practices basically

00:07:14,999 --> 00:07:20,519
means folks are able to help out other

00:07:16,949 --> 00:07:22,249
teams or even migrate between teams with

00:07:20,519 --> 00:07:24,599
minimal impact to their productivity

00:07:22,249 --> 00:07:27,389
this means things like code style

00:07:24,599 --> 00:07:30,360
development tooling testing methods and

00:07:27,389 --> 00:07:33,569
project structures we had an almost

00:07:30,360 --> 00:07:35,789
clean slate to work with at Ries we were

00:07:33,569 --> 00:07:39,779
training up existing genero developers

00:07:35,789 --> 00:07:41,489
to work with Python so when I joined we

00:07:39,779 --> 00:07:48,269
were developing all of these practices

00:07:41,489 --> 00:07:50,389
from the ground up so some of the common

00:07:48,269 --> 00:07:52,829
tooling that we said we've settled on

00:07:50,389 --> 00:07:55,289
include things like cookie cutter which

00:07:52,829 --> 00:07:57,569
ensures that all of our services start

00:07:55,289 --> 00:08:00,089
off looking similar and I'm quite

00:07:57,569 --> 00:08:01,649
serious we in the team just the team

00:08:00,089 --> 00:08:03,419
that I work in we've got a couple of

00:08:01,649 --> 00:08:06,300
dozen services that we look after that's

00:08:03,419 --> 00:08:08,249
a couple of dozen service code bases and

00:08:06,300 --> 00:08:12,809
they're all stamped out to look exactly

00:08:08,249 --> 00:08:15,829
the same in structure so for example

00:08:12,809 --> 00:08:19,799
they all store the Django project

00:08:15,829 --> 00:08:22,319
information like the settings file in a

00:08:19,799 --> 00:08:24,629
module called main that's across the

00:08:22,319 --> 00:08:26,669
board everybody knows exactly where the

00:08:24,629 --> 00:08:29,999
settings file is regardless of which

00:08:26,669 --> 00:08:31,409
service they're looking at we use tox so

00:08:29,999 --> 00:08:33,360
that developers don't have to worry

00:08:31,409 --> 00:08:35,089
about managing all of those virtual

00:08:33,360 --> 00:08:37,949
environments for all of those services

00:08:35,089 --> 00:08:42,149
we use PI tests because it's just best

00:08:37,949 --> 00:08:44,250
in in class for a long time now we use

00:08:42,149 --> 00:08:46,829
flake eight and I thought so there's no

00:08:44,250 --> 00:08:50,189
really weird surprises about any of the

00:08:46,829 --> 00:08:52,470
formatting of the code more recently

00:08:50,189 --> 00:08:55,350
we've turned on black in

00:08:52,470 --> 00:08:58,320
and our projects to just format the code

00:08:55,350 --> 00:09:00,390
for us we're also using I sought again

00:08:58,320 --> 00:09:04,160
just to automatically format the code

00:09:00,390 --> 00:09:06,660
for us that was inspired by our by our

00:09:04,160 --> 00:09:09,750
experience using prettier which is a

00:09:06,660 --> 00:09:11,700
tool for front-end development so it

00:09:09,750 --> 00:09:16,980
automatically formats typescript and

00:09:11,700 --> 00:09:19,350
HTML and their CSS a big win of doing

00:09:16,980 --> 00:09:22,140
this of having this common approach to

00:09:19,350 --> 00:09:23,970
all of these services means that if we

00:09:22,140 --> 00:09:26,520
come along and we have some tech that

00:09:23,970 --> 00:09:28,260
involves look we've got a really we just

00:09:26,520 --> 00:09:29,730
got to bump up the time out through our

00:09:28,260 --> 00:09:32,100
database connection across all of our

00:09:29,730 --> 00:09:33,960
services we can just cut a script that

00:09:32,100 --> 00:09:36,150
makes that change across all those

00:09:33,960 --> 00:09:40,050
repositories and pushes up that change

00:09:36,150 --> 00:09:43,910
as and we don't have to do any work so

00:09:40,050 --> 00:09:46,350
that's a huge win for us funny story

00:09:43,910 --> 00:09:47,180
after I'd written that slide a couple of

00:09:46,350 --> 00:09:49,860
days later

00:09:47,180 --> 00:09:51,720
hawky posted this to Twitter which

00:09:49,860 --> 00:09:54,810
pretty much lists exactly the same tool

00:09:51,720 --> 00:10:00,090
set that I just listed so I think that's

00:09:54,810 --> 00:10:02,400
probably a bit of a win just a little

00:10:00,090 --> 00:10:04,740
word about testing we've had a bit of to

00:10:02,400 --> 00:10:07,950
and fro in our teams about how to

00:10:04,740 --> 00:10:10,650
approach testing melanie Crutchfield

00:10:07,950 --> 00:10:13,560
yesterday described very wonderfully in

00:10:10,650 --> 00:10:15,630
her talk about how you can find a dozen

00:10:13,560 --> 00:10:18,420
different definitions of what a unit

00:10:15,630 --> 00:10:22,050
test is let alone even the other types

00:10:18,420 --> 00:10:24,360
of tests you might encounter in our team

00:10:22,050 --> 00:10:26,160
we've had that conversation we've had we

00:10:24,360 --> 00:10:31,320
still have on ongoing conversations

00:10:26,160 --> 00:10:34,620
about what end-to-end means we aim

00:10:31,320 --> 00:10:36,870
though for our unit tests to be as high

00:10:34,620 --> 00:10:39,450
as possible in our code as they can be

00:10:36,870 --> 00:10:42,720
while still achieving our coverage goal

00:10:39,450 --> 00:10:45,660
with 100% coverage with caveats around

00:10:42,720 --> 00:10:47,400
things that are difficult to test that

00:10:45,660 --> 00:10:50,580
means that changes to our underlying

00:10:47,400 --> 00:10:52,620
implementation or refactoring generally

00:10:50,580 --> 00:10:54,870
won't break those tests and indeed we

00:10:52,620 --> 00:10:57,660
can use those tests to ensure that we

00:10:54,870 --> 00:11:01,160
have confidence when we do refactoring

00:10:57,660 --> 00:11:01,160
and we haven't broken anything

00:11:03,700 --> 00:11:09,460
pycharm was introduced for consistency

00:11:06,670 --> 00:11:11,200
of editor across our newbie teams it

00:11:09,460 --> 00:11:13,330
allows everyone to help out other people

00:11:11,200 --> 00:11:14,560
do we doing work on their computer or

00:11:13,330 --> 00:11:17,200
helping them out with things they're

00:11:14,560 --> 00:11:19,060
getting stuck within the editor it's

00:11:17,200 --> 00:11:22,120
especially useful in when we're doing

00:11:19,060 --> 00:11:24,400
pair programming our developers

00:11:22,120 --> 00:11:26,370
routinely use the introspection tools

00:11:24,400 --> 00:11:29,890
that pycharm provides to poke around

00:11:26,370 --> 00:11:31,270
implementations other editors are an

00:11:29,890 --> 00:11:33,220
option for the more experienced

00:11:31,270 --> 00:11:35,200
developers of course but the vim folks

00:11:33,220 --> 00:11:41,380
are quite jealous of multi cursor

00:11:35,200 --> 00:11:43,540
editing so we did have a few teams that

00:11:41,380 --> 00:11:45,340
were migrating to Python so we learned I

00:11:43,540 --> 00:11:47,860
mean state is learned it in stages team

00:11:45,340 --> 00:11:50,830
by team and it's a really big win I

00:11:47,860 --> 00:11:53,560
can't overstate this having those folks

00:11:50,830 --> 00:11:57,010
who are genero developers which is a

00:11:53,560 --> 00:12:00,520
very niche language and you know it's

00:11:57,010 --> 00:12:02,080
future is debatable being trained up in

00:12:00,520 --> 00:12:06,610
a language that certainly does have a

00:12:02,080 --> 00:12:09,310
future that's a huge win but we did

00:12:06,610 --> 00:12:11,140
updating stages so one team could kind

00:12:09,310 --> 00:12:15,100
of forge the new path and help inform

00:12:11,140 --> 00:12:16,630
the practices in other teams in practice

00:12:15,100 --> 00:12:19,380
what happened was things were a bit too

00:12:16,630 --> 00:12:21,460
new and some things worked like

00:12:19,380 --> 00:12:24,370
encapsulating our calls to services in

00:12:21,460 --> 00:12:27,160
libraries to share common code using

00:12:24,370 --> 00:12:29,980
those contracts and some things didn't

00:12:27,160 --> 00:12:32,320
one team in particular found talks very

00:12:29,980 --> 00:12:35,620
difficult to use and they ended up

00:12:32,320 --> 00:12:39,070
replacing it with a complicated bash

00:12:35,620 --> 00:12:42,850
script and docker compose that's

00:12:39,070 --> 00:12:45,070
introduced its own knock-on issues the

00:12:42,850 --> 00:12:46,990
takeaway here really is that if you're

00:12:45,070 --> 00:12:48,130
going to do this you need to have

00:12:46,990 --> 00:12:49,600
wrecked

00:12:48,130 --> 00:12:53,560
you need to force yourself to have

00:12:49,600 --> 00:12:55,900
regular consistent meetings events

00:12:53,560 --> 00:12:57,580
whatever where you touch base with those

00:12:55,900 --> 00:13:03,430
teams and find out where their pain

00:12:57,580 --> 00:13:05,230
points are and catch them early so we

00:13:03,430 --> 00:13:07,360
run services and consumers of those

00:13:05,230 --> 00:13:10,180
services in four different programming

00:13:07,360 --> 00:13:13,270
languages in quite different stacks of

00:13:10,180 --> 00:13:16,860
software so how do we make them work

00:13:13,270 --> 00:13:20,190
together I've touched on the use of

00:13:16,860 --> 00:13:24,380
contracts we use pact to declare and

00:13:20,190 --> 00:13:26,730
enforce contracts between our services

00:13:24,380 --> 00:13:29,690
this allows us to avoid the need for

00:13:26,730 --> 00:13:33,570
expensive and brittle integration tests

00:13:29,690 --> 00:13:36,030
integration being front-end all the way

00:13:33,570 --> 00:13:40,680
through to a database where the database

00:13:36,030 --> 00:13:42,840
is in some known State we can verify

00:13:40,680 --> 00:13:45,060
that a consumers use of a service is

00:13:42,840 --> 00:13:47,630
valid and that a change to a service

00:13:45,060 --> 00:13:50,160
won't break registered interactions

00:13:47,630 --> 00:13:52,650
finally we can use those contracts

00:13:50,160 --> 00:13:54,870
though that the corpus of pacts those

00:13:52,650 --> 00:13:57,420
contracts to answer questions about how

00:13:54,870 --> 00:13:59,970
our api's are actually being used for

00:13:57,420 --> 00:14:02,580
example to deprecate a field in a

00:13:59,970 --> 00:14:05,000
response payload we know whether or not

00:14:02,580 --> 00:14:07,410
we have any consumers using that field

00:14:05,000 --> 00:14:09,150
if you'd like to know more about pact

00:14:07,410 --> 00:14:11,430
then you can either chat to me after

00:14:09,150 --> 00:14:14,190
this talk or you can watch my colleague

00:14:11,430 --> 00:14:18,150
Silvia yaps talk from last year's play

00:14:14,190 --> 00:14:21,390
con a year along the way we've developed

00:14:18,150 --> 00:14:25,590
a version of pact called pact man

00:14:21,390 --> 00:14:31,230
which is a play on words the other

00:14:25,590 --> 00:14:33,090
options were worse we've we've released

00:14:31,230 --> 00:14:34,860
it as open-source it's a pure Python

00:14:33,090 --> 00:14:36,960
implementation of pact mocking and

00:14:34,860 --> 00:14:39,450
verification and includes some really

00:14:36,960 --> 00:14:41,940
solid PI test support so if you're going

00:14:39,450 --> 00:14:47,730
to get into pact in Python this is the

00:14:41,940 --> 00:14:50,370
go-to tool another aspect of

00:14:47,730 --> 00:14:52,110
interoperability you've got contracts up

00:14:50,370 --> 00:14:53,700
here talking about services talking to

00:14:52,110 --> 00:14:55,710
services another level of

00:14:53,700 --> 00:14:57,170
interoperability is all the way down at

00:14:55,710 --> 00:15:01,980
the HTTP layer

00:14:57,170 --> 00:15:03,600
so generally HTTP talks to HTV priyad

00:15:01,980 --> 00:15:05,850
pretty well because it's been around for

00:15:03,600 --> 00:15:08,280
quite some time but we found one big

00:15:05,850 --> 00:15:12,060
sticking point what you're seeing here

00:15:08,280 --> 00:15:15,120
is a thing called HTTP keep alive and it

00:15:12,060 --> 00:15:17,310
removes the the need for closing and

00:15:15,120 --> 00:15:19,500
reopening of connections from consumers

00:15:17,310 --> 00:15:21,510
to services when the consumer knows it's

00:15:19,500 --> 00:15:25,110
going to make multiple requests to the

00:15:21,510 --> 00:15:27,990
same server and that's very common in a

00:15:25,110 --> 00:15:30,210
micro service framework the time taken

00:15:27,990 --> 00:15:30,720
to manage that connection can often

00:15:30,210 --> 00:15:33,060
equal

00:15:30,720 --> 00:15:37,860
or even exceed the time to service

00:15:33,060 --> 00:15:39,899
requests so the problem we ran into was

00:15:37,860 --> 00:15:42,389
we were using you whiskey which is very

00:15:39,899 --> 00:15:46,079
popular but unfortunately it doesn't

00:15:42,389 --> 00:15:49,560
implement keep alive a client believes

00:15:46,079 --> 00:15:52,019
that HTTP keep alive is active but when

00:15:49,560 --> 00:15:54,240
it sends through a follow-up request us

00:15:52,019 --> 00:15:55,399
G has closed the connection and we get

00:15:54,240 --> 00:15:58,680
an error

00:15:55,399 --> 00:16:01,589
normally folks run whiskey applications

00:15:58,680 --> 00:16:04,920
behind another server like Apache or

00:16:01,589 --> 00:16:08,129
nginx is very popular and so this isn't

00:16:04,920 --> 00:16:10,620
a problem because nginx will just smooth

00:16:08,129 --> 00:16:12,449
out that little bump it'll see that the

00:16:10,620 --> 00:16:13,949
connection has been closed and all open

00:16:12,449 --> 00:16:19,050
a new connection and the connection

00:16:13,949 --> 00:16:21,180
works we however are running a micro

00:16:19,050 --> 00:16:22,949
service architecture where services talk

00:16:21,180 --> 00:16:25,470
directly to other services in a closed

00:16:22,949 --> 00:16:29,129
environment we don't need nginx we can

00:16:25,470 --> 00:16:32,939
just poke em straight at each other or

00:16:29,129 --> 00:16:34,470
we thought we could so we ended up going

00:16:32,939 --> 00:16:36,569
through a rather painful process of

00:16:34,470 --> 00:16:39,389
replacing you is gearing up in our

00:16:36,569 --> 00:16:41,730
implementations with mod whiskey which

00:16:39,389 --> 00:16:44,579
I've already mentioned is the current

00:16:41,730 --> 00:16:50,389
whiskey implementation we use and that

00:16:44,579 --> 00:16:53,279
definitely does implement keep alive so

00:16:50,389 --> 00:16:55,920
there are so many different ways that

00:16:53,279 --> 00:16:58,199
computers can fail even just temporarily

00:16:55,920 --> 00:17:01,350
and we need to build a little resilience

00:16:58,199 --> 00:17:03,240
into our services to cope with that in a

00:17:01,350 --> 00:17:05,730
micro service architecture you're more

00:17:03,240 --> 00:17:08,189
susceptible to brief random intermittent

00:17:05,730 --> 00:17:10,650
inexplicable errors somewhere in the OSI

00:17:08,189 --> 00:17:13,230
stack lots that can go wrong

00:17:10,650 --> 00:17:17,240
these propagate into our code base as

00:17:13,230 --> 00:17:21,929
TCP errors or client disconnected or

00:17:17,240 --> 00:17:23,880
HTTP 502 proxy failures or the driver

00:17:21,929 --> 00:17:27,539
did not return an error which is the

00:17:23,880 --> 00:17:29,880
worst case so we've implemented a few

00:17:27,539 --> 00:17:32,460
things to work with this one of the

00:17:29,880 --> 00:17:35,970
things we've done is turn on retrying of

00:17:32,460 --> 00:17:38,850
certain types of HTTP errors so our

00:17:35,970 --> 00:17:41,360
underlying HTTP library implements

00:17:38,850 --> 00:17:44,060
retries a certain number of retries of

00:17:41,360 --> 00:17:50,240
HTTP 502 errors

00:17:44,060 --> 00:17:52,850
to TCP level errors for get requests we

00:17:50,240 --> 00:17:56,240
also see errors sometimes when we try to

00:17:52,850 --> 00:17:59,600
connect to the database for a number of

00:17:56,240 --> 00:18:03,470
reasons so we added we've added retries

00:17:59,600 --> 00:18:07,010
in our django database layer to retry

00:18:03,470 --> 00:18:09,260
those database connection attempts with

00:18:07,010 --> 00:18:11,120
those two things in place which were

00:18:09,260 --> 00:18:14,270
reasonably simple to implement

00:18:11,120 --> 00:18:19,940
we found our rate of reported service

00:18:14,270 --> 00:18:23,020
errors dropped dramatically one little

00:18:19,940 --> 00:18:25,820
tweak to the database one though is that

00:18:23,020 --> 00:18:28,370
the intermix database that we connect to

00:18:25,820 --> 00:18:30,170
can actually take some time to connect

00:18:28,370 --> 00:18:31,880
in the order of seconds in the worst

00:18:30,170 --> 00:18:35,090
case but you know hundreds of

00:18:31,880 --> 00:18:37,250
milliseconds sometimes we want pretty

00:18:35,090 --> 00:18:41,750
rapid responses generally speaking to

00:18:37,250 --> 00:18:43,820
our our our service requests so for that

00:18:41,750 --> 00:18:47,300
reason we hold on to the connection to

00:18:43,820 --> 00:18:49,400
the database for a pretty long time the

00:18:47,300 --> 00:18:51,500
network can have other ideas though or

00:18:49,400 --> 00:18:53,900
the database might be restarted

00:18:51,500 --> 00:18:55,850
overnight resulting in spurious errors

00:18:53,900 --> 00:18:58,670
from our services when they next try to

00:18:55,850 --> 00:19:00,920
use that connection so we've implemented

00:18:58,670 --> 00:19:05,780
a validation step in our database

00:19:00,920 --> 00:19:09,260
connection so that we perform a select

00:19:05,780 --> 00:19:12,170
one from Jewel effectively a database no

00:19:09,260 --> 00:19:15,470
op it goes to the database make sure

00:19:12,170 --> 00:19:16,940
that connection is still alive and

00:19:15,470 --> 00:19:19,010
that's actually a win from our

00:19:16,940 --> 00:19:21,560
environment where we've learned about

00:19:19,010 --> 00:19:24,320
that from our Java teams this is a

00:19:21,560 --> 00:19:29,300
feature that's built into the JDBC

00:19:24,320 --> 00:19:32,420
client that they use in their code so on

00:19:29,300 --> 00:19:34,070
the type subject of resilience we

00:19:32,420 --> 00:19:37,310
monitor the health of our systems on a

00:19:34,070 --> 00:19:39,800
per team graph on a dashboard we

00:19:37,310 --> 00:19:42,140
actually have a physical screen per team

00:19:39,800 --> 00:19:44,720
hanging from the ceiling that we can

00:19:42,140 --> 00:19:46,850
display these dashboards on these

00:19:44,720 --> 00:19:50,660
display information about error and

00:19:46,850 --> 00:19:53,390
retry rates over the day the very top

00:19:50,660 --> 00:19:57,650
graph of their service anomalies that

00:19:53,390 --> 00:20:01,010
graphs for all of our services how many

00:19:57,650 --> 00:20:02,960
unexpected HTTP Co status codes we saw

00:20:01,010 --> 00:20:06,890
unexpected being anything that's not a

00:20:02,960 --> 00:20:08,720
200 or 300 or 400 some of the 400s if we

00:20:06,890 --> 00:20:11,210
see a 500 you'll get an you'll get a

00:20:08,720 --> 00:20:13,790
spike there so that shows us that we

00:20:11,210 --> 00:20:17,330
receive we saw one of those today well

00:20:13,790 --> 00:20:19,160
when I took this photo if we see a

00:20:17,330 --> 00:20:20,630
bigger number there then we know that

00:20:19,160 --> 00:20:22,730
we've got a problem and we have had

00:20:20,630 --> 00:20:25,340
instances where we've seen a spike of

00:20:22,730 --> 00:20:27,320
you know fifty or a hundred in in that

00:20:25,340 --> 00:20:28,820
anomaly graph and we've gone off to that

00:20:27,320 --> 00:20:30,440
where people and they've said oh we

00:20:28,820 --> 00:20:35,060
didn't oh yeah look something what's

00:20:30,440 --> 00:20:37,580
happening we also show things like

00:20:35,060 --> 00:20:40,490
research response times for high load

00:20:37,580 --> 00:20:43,700
services services and other information

00:20:40,490 --> 00:20:46,970
like build statuses century alert

00:20:43,700 --> 00:20:49,070
accounts and so on all of our services

00:20:46,970 --> 00:20:50,780
send all of their exceptions all of our

00:20:49,070 --> 00:20:53,240
front ends for that matter send all of

00:20:50,780 --> 00:20:55,580
their exceptions to sentry they're not

00:20:53,240 --> 00:20:57,470
lost and you wouldn't believe the number

00:20:55,580 --> 00:21:01,940
of exceptions happen in a JavaScript

00:20:57,470 --> 00:21:03,680
front-end we also use elk

00:21:01,940 --> 00:21:05,990
that's elasticsearch in camana and

00:21:03,680 --> 00:21:08,450
prometheus to callate log events and

00:21:05,990 --> 00:21:10,610
performance data and there's a custom

00:21:08,450 --> 00:21:12,920
tool sitting behind this to pull in data

00:21:10,610 --> 00:21:14,690
from other places like sentry our build

00:21:12,920 --> 00:21:16,910
system our git repository our pact

00:21:14,690 --> 00:21:18,920
broker and our kubernetes cluster and

00:21:16,910 --> 00:21:21,440
that just shoves it all into a Postgres

00:21:18,920 --> 00:21:23,750
database that Griffin ax can pull in so

00:21:21,440 --> 00:21:25,040
you can see up here the build statuses

00:21:23,750 --> 00:21:29,540
and so forth but over the other side

00:21:25,040 --> 00:21:30,950
their outstanding pull requests all

00:21:29,540 --> 00:21:33,200
logging is sent to a central

00:21:30,950 --> 00:21:35,060
elasticsearch aggregator and is done

00:21:33,200 --> 00:21:38,950
using JSON so that we can perform

00:21:35,060 --> 00:21:41,750
intelligent queries on our logged events

00:21:38,950 --> 00:21:44,810
this is again looking for anomalies in

00:21:41,750 --> 00:21:50,000
in services any log status that we don't

00:21:44,810 --> 00:21:51,950
expect to see so one big gotcha

00:21:50,000 --> 00:21:54,740
in the pythonic world is if that you

00:21:51,950 --> 00:21:57,620
deviate from the community default and

00:21:54,740 --> 00:21:59,570
tech stack norm your life becomes

00:21:57,620 --> 00:22:01,700
difficult just because you're out in the

00:21:59,570 --> 00:22:05,060
wilds that very few people have been

00:22:01,700 --> 00:22:08,360
before again coming back to who's heard

00:22:05,060 --> 00:22:10,580
of intermix the parking world really

00:22:08,360 --> 00:22:11,420
likes Django over a fully controlled

00:22:10,580 --> 00:22:16,550
post-grad

00:22:11,420 --> 00:22:18,530
database for example just dealing with

00:22:16,550 --> 00:22:22,010
the connections to the Infinix database

00:22:18,530 --> 00:22:23,990
has been interesting in itself we've had

00:22:22,010 --> 00:22:26,660
to create that django database adapter

00:22:23,990 --> 00:22:28,730
the actual initial work was done for us

00:22:26,660 --> 00:22:30,680
by common code but we've been since

00:22:28,730 --> 00:22:33,740
taken it over and we run that open

00:22:30,680 --> 00:22:36,200
source project now ourselves we found so

00:22:33,740 --> 00:22:40,790
many weird issues in ODBC connections

00:22:36,200 --> 00:22:47,120
and so on so this is the django intermix

00:22:40,790 --> 00:22:53,000
DB project so we run that single shared

00:22:47,120 --> 00:22:55,400
legacy obscure database but django it's

00:22:53,000 --> 00:22:57,590
got its own thoughts about databases it

00:22:55,400 --> 00:22:59,840
wants to store its own data things about

00:22:57,590 --> 00:23:02,210
users and sessions and there's a couple

00:22:59,840 --> 00:23:04,160
of other things in there as well we

00:23:02,210 --> 00:23:07,850
can't do that in the legacy database

00:23:04,160 --> 00:23:10,120
because we have dozens of Django's that

00:23:07,850 --> 00:23:13,670
would mean we'd need a second database

00:23:10,120 --> 00:23:16,940
two databases in Django is basically a

00:23:13,670 --> 00:23:18,440
bad idea it causes all sorts of

00:23:16,940 --> 00:23:20,510
difficulties the configuration is a bit

00:23:18,440 --> 00:23:22,670
messy but as soon as you start thinking

00:23:20,510 --> 00:23:26,770
about doing anything around transactions

00:23:22,670 --> 00:23:26,770
in your unit tests you are screwed

00:23:27,100 --> 00:23:31,940
fortunately for our services the Django

00:23:29,810 --> 00:23:33,710
database users and permissions and

00:23:31,940 --> 00:23:35,780
sessions and all that other stuff is

00:23:33,710 --> 00:23:37,850
actually unnecessary so we just don't

00:23:35,780 --> 00:23:39,500
initialize it it means we get this

00:23:37,850 --> 00:23:40,760
warning every time we start up Django

00:23:39,500 --> 00:23:46,400
saying hey you've got unapplied

00:23:40,760 --> 00:23:48,410
migrations it's like yeah whatever so

00:23:46,400 --> 00:23:51,650
there's a catch there though the Django

00:23:48,410 --> 00:23:54,680
rest framework has this really nice HTML

00:23:51,650 --> 00:23:58,160
view it's kind of like swagger but it's

00:23:54,680 --> 00:24:00,650
not swagger and you can see basically

00:23:58,160 --> 00:24:03,470
the the rest interface that you're

00:24:00,650 --> 00:24:05,500
exposing to the world and you can do

00:24:03,470 --> 00:24:08,570
requests and stuff

00:24:05,500 --> 00:24:10,280
unfortunately it really wants Django

00:24:08,570 --> 00:24:14,090
Wolff to be a thing and if you don't

00:24:10,280 --> 00:24:16,610
have Django warth it just breaks so what

00:24:14,090 --> 00:24:18,230
we did was we just ignored that and put

00:24:16,610 --> 00:24:23,060
in another version of swagger and we're

00:24:18,230 --> 00:24:25,239
happy the catch though is our front-end

00:24:23,060 --> 00:24:27,190
apps actually are authentic a

00:24:25,239 --> 00:24:29,320
now there externally authenticated we

00:24:27,190 --> 00:24:31,509
have a separate authentication token

00:24:29,320 --> 00:24:35,289
that comes into them via you know

00:24:31,509 --> 00:24:38,379
Kerberos magic and so we run a little

00:24:35,289 --> 00:24:39,549
dummy SQLite database in those because

00:24:38,379 --> 00:24:41,609
they don't need to connect to the real

00:24:39,549 --> 00:24:44,019
database we can just store that

00:24:41,609 --> 00:24:45,940
effectively transient user information

00:24:44,019 --> 00:24:53,320
just in an SQLite database and that's

00:24:45,940 --> 00:24:55,840
good enough for us oh yeah so Jango who

00:24:53,320 --> 00:24:57,940
again opinionated about databases it

00:24:55,840 --> 00:24:59,769
really needs an identity column we did

00:24:57,940 --> 00:25:01,989
have to add some identity columns to our

00:24:59,769 --> 00:25:03,580
database some of our database tables and

00:25:01,989 --> 00:25:06,340
that's just a thing you have to know

00:25:03,580 --> 00:25:09,669
it's going to happen and you can't work

00:25:06,340 --> 00:25:11,379
with tables that have multiple column

00:25:09,669 --> 00:25:17,019
primary keys that's just not going to

00:25:11,379 --> 00:25:19,119
work we do have a need to process big

00:25:17,019 --> 00:25:21,369
jobs without impacting our micro

00:25:19,119 --> 00:25:25,029
services typically I would just add

00:25:21,369 --> 00:25:26,710
celery I mean just add celery right but

00:25:25,029 --> 00:25:29,019
you would just use celery because it's

00:25:26,710 --> 00:25:30,700
the it's there's a lot of prior art out

00:25:29,019 --> 00:25:33,879
there and it integrates pretty well with

00:25:30,700 --> 00:25:36,639
Django by default though Django sorry

00:25:33,879 --> 00:25:38,529
celery really wants to use RabbitMQ or

00:25:36,639 --> 00:25:40,179
some other message queue or the Django

00:25:38,529 --> 00:25:42,099
database now we don't have a django

00:25:40,179 --> 00:25:44,919
database we weren't going to get

00:25:42,099 --> 00:25:48,909
rabbitmq installed Redis wasn't around

00:25:44,919 --> 00:25:52,509
yet so we did use your whiskey spooling

00:25:48,909 --> 00:25:54,940
for a while it has two issues one us key

00:25:52,509 --> 00:25:57,129
I've mentioned already but two that

00:25:54,940 --> 00:26:00,249
stores the spool that stores the queued

00:25:57,129 --> 00:26:03,460
information on disk in your container in

00:26:00,249 --> 00:26:04,869
communities that has wonderful ideas

00:26:03,460 --> 00:26:07,690
about now I'm gonna just kill that

00:26:04,869 --> 00:26:10,029
container instead a new one so that was

00:26:07,690 --> 00:26:12,099
not going to be a good idea long term we

00:26:10,029 --> 00:26:14,049
ended up using ActiveMQ for queue

00:26:12,099 --> 00:26:15,749
processing because it's a supported

00:26:14,049 --> 00:26:18,429
message queue in our environment

00:26:15,749 --> 00:26:21,970
unfortunately activemq ain't so popular

00:26:18,429 --> 00:26:24,999
in Python world so there is some

00:26:21,970 --> 00:26:28,029
libraries but they're not very robust so

00:26:24,999 --> 00:26:31,119
we ran into some issues there so that's

00:26:28,029 --> 00:26:34,059
a thing rabbitmq quite popular Redis

00:26:31,119 --> 00:26:35,499
very popular go with those if you can we

00:26:34,059 --> 00:26:37,960
really should have pushed harder to get

00:26:35,499 --> 00:26:40,320
the Redis installed sooner so we could

00:26:37,960 --> 00:26:40,320
use it

00:26:40,509 --> 00:26:43,690
excuse me

00:26:44,500 --> 00:26:49,700
the final thing I'd like to touch on is

00:26:46,940 --> 00:26:51,409
performance so this generally hasn't

00:26:49,700 --> 00:26:54,409
been an issue because we've restricted

00:26:51,409 --> 00:26:56,690
most services to a smallish domain over

00:26:54,409 --> 00:26:58,700
one or two tables just serving up the

00:26:56,690 --> 00:27:02,630
data and the 20 to 40 millisecond

00:26:58,700 --> 00:27:05,659
response time is just fine our complex

00:27:02,630 --> 00:27:08,059
services though run response times of

00:27:05,659 --> 00:27:10,610
400 milliseconds for a single request

00:27:08,059 --> 00:27:13,600
and we'd be getting requests for

00:27:10,610 --> 00:27:16,399
hundreds of request responses at a time

00:27:13,600 --> 00:27:20,149
that math comes out at tens of seconds

00:27:16,399 --> 00:27:22,129
of responses and that's not good so we

00:27:20,149 --> 00:27:25,450
used various tooling to investigate

00:27:22,129 --> 00:27:29,539
hotspots in our less performant service

00:27:25,450 --> 00:27:31,970
the Django debug toolbar and silk which

00:27:29,539 --> 00:27:34,190
is another plugin for django super

00:27:31,970 --> 00:27:36,710
valuable for this we also used some

00:27:34,190 --> 00:27:39,950
custom profiling logging just logging

00:27:36,710 --> 00:27:41,480
timestamps in our code and we used a

00:27:39,950 --> 00:27:43,850
little bit of New Relic distributed

00:27:41,480 --> 00:27:50,179
tracing but to be honest nobody really

00:27:43,850 --> 00:27:53,029
knows how neural ik works we already

00:27:50,179 --> 00:27:55,129
knew our more complex services could be

00:27:53,029 --> 00:27:56,779
hitting dozens of tables and half a

00:27:55,129 --> 00:27:58,490
dozen downstream services when

00:27:56,779 --> 00:28:00,860
calculating their responses but the

00:27:58,490 --> 00:28:04,669
profiling gave us the solid numbers to

00:28:00,860 --> 00:28:06,889
work with silk is cool because it does

00:28:04,669 --> 00:28:09,139
code profile profiling as well as

00:28:06,889 --> 00:28:11,629
database profiling and it can work with

00:28:09,139 --> 00:28:14,179
non get requests whereas the debug

00:28:11,629 --> 00:28:17,889
toolbar is limited to get requests and

00:28:14,179 --> 00:28:20,269
some post requests it's a bit of a hack

00:28:17,889 --> 00:28:21,889
what you're seeing here though is the is

00:28:20,269 --> 00:28:24,980
the debug toolbar because I'm profiling

00:28:21,889 --> 00:28:27,169
a get request it's super nice to see so

00:28:24,980 --> 00:28:29,990
as I said we already knew we were

00:28:27,169 --> 00:28:33,259
probably doing a bad thing we had new

00:28:29,990 --> 00:28:35,389
teams and our focus was on getting it

00:28:33,259 --> 00:28:37,759
implemented right not necessarily

00:28:35,389 --> 00:28:40,009
getting it rented in a most optimal way

00:28:37,759 --> 00:28:42,529
we could work on the optimization later

00:28:40,009 --> 00:28:45,320
and that's what we're doing down so in

00:28:42,529 --> 00:28:47,419
this case just on the SQL we can quickly

00:28:45,320 --> 00:28:51,950
see that we have a ridiculous number of

00:28:47,419 --> 00:28:52,350
SQL queries does it say 201 duplicate

00:28:51,950 --> 00:28:56,100
clear

00:28:52,350 --> 00:28:58,169
is over for seconds so just a little bit

00:28:56,100 --> 00:28:59,549
of Investigation and and the debug

00:28:58,169 --> 00:29:01,259
toolbar gives you the tools for doing

00:28:59,549 --> 00:29:03,509
this I highly recommend you you poke

00:29:01,259 --> 00:29:05,190
around in it you can click on any one of

00:29:03,509 --> 00:29:08,279
those queries and see the exact code

00:29:05,190 --> 00:29:10,259
that's causing that query to happen so

00:29:08,279 --> 00:29:14,179
we went in did that and we reduced it

00:29:10,259 --> 00:29:14,179
down to 50 milliseconds over for queries

00:29:14,509 --> 00:29:20,820
so probably preaching to the janggo

00:29:18,029 --> 00:29:23,340
choir here but reducing the number of

00:29:20,820 --> 00:29:27,919
SQL queries was critical to us getting

00:29:23,340 --> 00:29:27,919
those services performance up to speed

00:29:27,950 --> 00:29:33,240
for a consumer displaying a large

00:29:30,600 --> 00:29:36,120
customer order for example though we

00:29:33,240 --> 00:29:39,990
still need the ability to price hundreds

00:29:36,120 --> 00:29:43,259
of items so what we do in our services

00:29:39,990 --> 00:29:45,809
is we provide batch interfaces allows

00:29:43,259 --> 00:29:48,990
the consumer to price a hundred items at

00:29:45,809 --> 00:29:51,539
once in one rest call that allows us to

00:29:48,990 --> 00:29:54,029
reduce the network overhead keepalive

00:29:51,539 --> 00:29:56,789
would help us there but it also allows

00:29:54,029 --> 00:29:59,549
us to squash all of those requests down

00:29:56,789 --> 00:30:02,210
into optimized SQL queries as well which

00:29:59,549 --> 00:30:04,950
keep alive isn't going to help us with

00:30:02,210 --> 00:30:10,620
batching is kind of a no-no in rest land

00:30:04,950 --> 00:30:12,509
but I say stuff those guys caching is

00:30:10,620 --> 00:30:15,000
also done at various levels in our

00:30:12,509 --> 00:30:19,139
service services to reduce the fan-out

00:30:15,000 --> 00:30:20,879
damage caused by large requests thanks

00:30:19,139 --> 00:30:22,830
to the fan out and sometimes back in

00:30:20,879 --> 00:30:24,929
again nature of micro services some

00:30:22,830 --> 00:30:27,200
services can be hit a stupid number of

00:30:24,929 --> 00:30:29,879
times during a normal processing day

00:30:27,200 --> 00:30:32,940
caching by consumers have calls to one

00:30:29,879 --> 00:30:35,700
service one endpoint reduced it from

00:30:32,940 --> 00:30:43,250
about 40,000 requests per minute to

00:30:35,700 --> 00:30:46,919
4,000 this is the simplest casing of all

00:30:43,250 --> 00:30:49,289
the LRU cache function is provided in

00:30:46,919 --> 00:30:50,580
the Python standard library here we're

00:30:49,289 --> 00:30:52,919
taking advantage of the fact that

00:30:50,580 --> 00:30:55,740
information about our branches doesn't

00:30:52,919 --> 00:30:57,360
change over a day so in our services

00:30:55,740 --> 00:30:58,860
they just have to request the

00:30:57,360 --> 00:31:01,799
information about a particular branch

00:30:58,860 --> 00:31:05,820
once and that'll be held on to for a day

00:31:01,799 --> 00:31:07,320
and the next day we'll get it afresh

00:31:05,820 --> 00:31:08,910
we are looking at other solutions for

00:31:07,320 --> 00:31:11,220
caching which would allow us to have

00:31:08,910 --> 00:31:13,800
shared Manish bandage cache turret

00:31:11,220 --> 00:31:16,230
dedicated to a set of workers but that's

00:31:13,800 --> 00:31:18,540
a whole other step that requires things

00:31:16,230 --> 00:31:22,710
like cache invalidation messages being

00:31:18,540 --> 00:31:24,930
sent around and other fun things the

00:31:22,710 --> 00:31:27,960
last thing I'd like to talk about is as

00:31:24,930 --> 00:31:30,150
a Python developer I've kind of taken

00:31:27,960 --> 00:31:32,250
for granted the ability to jump around

00:31:30,150 --> 00:31:35,100
the source code of whatever I'm working

00:31:32,250 --> 00:31:37,350
on is the rest interface doing something

00:31:35,100 --> 00:31:40,050
odd jump to the source of the Django

00:31:37,350 --> 00:31:43,350
rest framework and so often we had to do

00:31:40,050 --> 00:31:44,910
that or even Django underneath that if

00:31:43,350 --> 00:31:48,390
the database layer is throwing weird

00:31:44,910 --> 00:31:50,640
errors jump to the Django layer jump

00:31:48,390 --> 00:31:52,800
into the C source code of PI ODBC we've

00:31:50,640 --> 00:31:55,140
done this a number of times and you get

00:31:52,800 --> 00:31:58,080
answers you can file bugs you can file

00:31:55,140 --> 00:32:00,240
pull requests and get things fixed that

00:31:58,080 --> 00:32:03,030
open source ecosystem is very easy to

00:32:00,240 --> 00:32:05,820
take granted until it's just not there

00:32:03,030 --> 00:32:08,700
which is something we've run into in our

00:32:05,820 --> 00:32:11,760
Java programs and our Gennaro programs

00:32:08,700 --> 00:32:15,590
in particular we just have to guess at

00:32:11,760 --> 00:32:18,000
what's going on so support open source

00:32:15,590 --> 00:32:20,360
that's I think all I have time for so

00:32:18,000 --> 00:32:20,360
thank you

00:32:24,750 --> 00:32:26,810

YouTube URL: https://www.youtube.com/watch?v=jxr3Aar58ig


