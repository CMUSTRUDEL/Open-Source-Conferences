Title: Machine Learning and Cyber Security - Detecting malicious URLs in the haystack
Publication date: 2019-08-03
Playlist: PyCon Australia 2019
Description: 
	Alistair, Veatrissa L.

Today, security teams are in an increasingly one-sided battle to defend against a myriad of cyber attacks. Web-based attacks are often devastating, with conventional blacklists and reputation-based defence tactics not able to identify previously unseen malicious URLs. Is AI the solution?

https://2019.pycon-au.org/talks/machine-learning-and-cyber-security--detecting-malicious-urls-in-the-haystack

PyCon AU, the national Python Language conference, is on again this August in Sydney, at the International Convention Centre, Sydney, August 2 - 6 2019.

Video licence: CC BY-NC-SA 4.0 - https://creativecommons.org/licenses/by-nc-sa/4.0/

Python, PyCon, PyConAU

Fri Aug  2 17:20:00 2019 at Cockle Bay
Captions: 
	00:00:00,240 --> 00:00:05,370
thank you for coming up I'm staying to

00:00:02,700 --> 00:00:07,649
the very last session of the day it's

00:00:05,370 --> 00:00:09,150
been a great day today in the science

00:00:07,649 --> 00:00:11,250
and data track so thank you to all our

00:00:09,150 --> 00:00:14,130
speakers and all of you for coming to

00:00:11,250 --> 00:00:19,070
the sessions and making it so good so

00:00:14,130 --> 00:00:21,810
last up we have Alastair entries and

00:00:19,070 --> 00:00:24,090
okay Byers Alastair is a data scientist

00:00:21,810 --> 00:00:27,359
currently working cyber security domain

00:00:24,090 --> 00:00:29,400
namely identify namely identify and

00:00:27,359 --> 00:00:32,880
access management Identity and Access

00:00:29,400 --> 00:00:35,399
Management yeah it's been a long day he

00:00:32,880 --> 00:00:37,380
enjoys exercise cooking and data science

00:00:35,399 --> 00:00:38,969
not to mention AFL and most sports in

00:00:37,380 --> 00:00:43,200
his spare time he may also put together

00:00:38,969 --> 00:00:45,390
a comedy video or two interest is a

00:00:43,200 --> 00:00:47,340
part-time deep learning research student

00:00:45,390 --> 00:00:49,829
currently working the information

00:00:47,340 --> 00:00:52,980
security domain enjoys random strolls

00:00:49,829 --> 00:00:54,809
and food hunting in foreign cities but

00:00:52,980 --> 00:00:56,570
today they'll be both talking about

00:00:54,809 --> 00:00:59,250
machine learning and cybersecurity

00:00:56,570 --> 00:01:02,640
detecting malicious URLs in the haystack

00:00:59,250 --> 00:01:04,949
Oh welcome to him please beautiful can

00:01:02,640 --> 00:01:08,280
everyone hear me okay can everyone hear

00:01:04,949 --> 00:01:10,500
me okay well good yeah welcome and

00:01:08,280 --> 00:01:12,990
obvious thank you for staying back I

00:01:10,500 --> 00:01:13,409
know the Boat Show is probably on your

00:01:12,990 --> 00:01:16,320
mind

00:01:13,409 --> 00:01:17,790
I really do appreciate it I really

00:01:16,320 --> 00:01:19,140
personally felt like this since I put

00:01:17,790 --> 00:01:24,000
budgie smugglers on for the first time

00:01:19,140 --> 00:01:24,990
but I'll uh I'll give it a go so we

00:01:24,000 --> 00:01:27,090
obviously just had a little bit of an

00:01:24,990 --> 00:01:29,130
introduction this is Chris and I'm

00:01:27,090 --> 00:01:30,720
Alastair and we've been working in

00:01:29,130 --> 00:01:32,700
information security and data science

00:01:30,720 --> 00:01:34,020
for about 18 months and we're here to

00:01:32,700 --> 00:01:36,090
sort of share a bit about our journey as

00:01:34,020 --> 00:01:37,340
a team and some of the things that we've

00:01:36,090 --> 00:01:39,509
been doing

00:01:37,340 --> 00:01:43,320
but first I'll start with a little story

00:01:39,509 --> 00:01:45,470
so about five years ago I was developing

00:01:43,320 --> 00:01:48,810
a bunch of websites for small businesses

00:01:45,470 --> 00:01:50,670
we're talking fitness studios just your

00:01:48,810 --> 00:01:53,579
small sort of butler's just trying to

00:01:50,670 --> 00:01:55,979
make a start and I was maintaining and

00:01:53,579 --> 00:01:58,409
hosting them on the cloud and one

00:01:55,979 --> 00:02:00,540
afternoon a very angry art gallery gave

00:01:58,409 --> 00:02:02,790
me a call and they were like what is

00:02:00,540 --> 00:02:04,680
going on here there was pictures of nude

00:02:02,790 --> 00:02:06,450
men all through their gallery pages the

00:02:04,680 --> 00:02:09,300
website had been hacked and although

00:02:06,450 --> 00:02:11,459
some I guess art galleries may see nude

00:02:09,300 --> 00:02:12,310
men as art not this art gallery so this

00:02:11,459 --> 00:02:14,140
is how it works

00:02:12,310 --> 00:02:16,480
but in all seriousness this is my I

00:02:14,140 --> 00:02:18,010
guess introduction to I guess just how

00:02:16,480 --> 00:02:19,569
unfair the internet can be and it was

00:02:18,010 --> 00:02:21,520
probably my bad with regards to just not

00:02:19,569 --> 00:02:24,340
patching a WordPress website which is

00:02:21,520 --> 00:02:27,040
pretty simple but it was an introduction

00:02:24,340 --> 00:02:28,690
to just our I guess just how unfair it

00:02:27,040 --> 00:02:30,040
can be and the impact it can have and I

00:02:28,690 --> 00:02:31,660
was certainly in shock and I didn't know

00:02:30,040 --> 00:02:34,810
what to do at the time and it obviously

00:02:31,660 --> 00:02:36,010
cost a bit of time and effort to fix so

00:02:34,810 --> 00:02:37,810
why are we here

00:02:36,010 --> 00:02:40,510
if there's sort of three flavors to our

00:02:37,810 --> 00:02:43,060
presentation from a bit of a probably a

00:02:40,510 --> 00:02:44,650
foreign sort of standpoint we looked at

00:02:43,060 --> 00:02:46,570
the how to apply design thinking in a

00:02:44,650 --> 00:02:49,209
cyber security context namely threat

00:02:46,570 --> 00:02:50,590
detection secondly we employed a few

00:02:49,209 --> 00:02:52,510
data science frameworks to really help

00:02:50,590 --> 00:02:53,970
us with our I guess common language in

00:02:52,510 --> 00:02:56,769
our project and how to structure it and

00:02:53,970 --> 00:02:59,319
lastly using Python to make our machine

00:02:56,769 --> 00:03:00,610
learning dreams become reality just like

00:02:59,319 --> 00:03:04,470
the other face app that's out at the

00:03:00,610 --> 00:03:06,700
moment so how a project started

00:03:04,470 --> 00:03:08,590
typically we're actually in consulting

00:03:06,700 --> 00:03:09,850
so typically the boss comes along and

00:03:08,590 --> 00:03:10,510
they give you a spreadsheet of really

00:03:09,850 --> 00:03:12,790
ugly

00:03:10,510 --> 00:03:14,200
I guess use cases and it doesn't really

00:03:12,790 --> 00:03:15,880
motivate you there's no sort of I guess

00:03:14,200 --> 00:03:17,549
journey there to get to that point it's

00:03:15,880 --> 00:03:20,079
just like through this it's a line a

00:03:17,549 --> 00:03:21,970
statement I guess just defining a threat

00:03:20,079 --> 00:03:23,980
detection use case and it sort of had us

00:03:21,970 --> 00:03:25,720
at a crossroads so we did a bit of

00:03:23,980 --> 00:03:26,980
research and we looked around online and

00:03:25,720 --> 00:03:29,860
we sort of came across this design

00:03:26,980 --> 00:03:31,690
thinking I guess approach and it's all

00:03:29,860 --> 00:03:33,040
about human centered design of products

00:03:31,690 --> 00:03:34,720
it's putting yourself in the shoes of

00:03:33,040 --> 00:03:36,400
the end user at the start of your

00:03:34,720 --> 00:03:38,620
project and really seeing what makes

00:03:36,400 --> 00:03:40,600
them tick then you go along to divide it

00:03:38,620 --> 00:03:41,799
up to find a problem statement and then

00:03:40,600 --> 00:03:43,450
from the problem statement you start to

00:03:41,799 --> 00:03:46,450
come up with some ideas and then on to

00:03:43,450 --> 00:03:48,519
prototyping and testing we loved this so

00:03:46,450 --> 00:03:50,470
much that we sort of enforced a forced

00:03:48,519 --> 00:03:52,239
marriage with some data science

00:03:50,470 --> 00:03:53,859
processes and elements in those that we

00:03:52,239 --> 00:03:55,209
really loved and it was all underpinned

00:03:53,859 --> 00:03:56,890
by Python and we sort of used this

00:03:55,209 --> 00:03:58,720
framework that we came up with called

00:03:56,890 --> 00:03:59,799
the threat science framework to come up

00:03:58,720 --> 00:04:01,900
with all our sort of threat detection

00:03:59,799 --> 00:04:05,170
use cases and it's really in its infant

00:04:01,900 --> 00:04:07,480
phase I guess so first step of the

00:04:05,170 --> 00:04:09,250
threat science framework is to know the

00:04:07,480 --> 00:04:10,600
user so put yourself in the shoes of the

00:04:09,250 --> 00:04:12,280
end-user and in our case it was the

00:04:10,600 --> 00:04:13,570
security analyst in a Security

00:04:12,280 --> 00:04:15,280
Operations Center that were working with

00:04:13,570 --> 00:04:17,919
and really trying to understand their

00:04:15,280 --> 00:04:19,479
pain points their goals and a sort of

00:04:17,919 --> 00:04:23,229
understanding I guess what are they do

00:04:19,479 --> 00:04:24,550
in a day daily sort of context once you

00:04:23,229 --> 00:04:26,630
sort of do that you nail down the

00:04:24,550 --> 00:04:28,940
problem statement so tip

00:04:26,630 --> 00:04:30,139
you do this in design thinking and what

00:04:28,940 --> 00:04:31,820
I know is it enables you to do is

00:04:30,139 --> 00:04:35,060
actually focus on a concrete problem to

00:04:31,820 --> 00:04:36,229
solve next up you go into RDA which is

00:04:35,060 --> 00:04:37,639
where you come up with all your ideas

00:04:36,229 --> 00:04:39,470
that relate to that problem statement

00:04:37,639 --> 00:04:40,910
and then this is where our data science

00:04:39,470 --> 00:04:42,949
process that's sort of tailored to our

00:04:40,910 --> 00:04:44,990
sort of context kicks in and it's all

00:04:42,949 --> 00:04:46,250
underpinned by Python so we start to

00:04:44,990 --> 00:04:48,949
understand the threat that relates to

00:04:46,250 --> 00:04:50,300
our detection news case we acquire some

00:04:48,949 --> 00:04:51,770
data and we understand it you'll see

00:04:50,300 --> 00:04:54,020
some common elements from the Microsoft

00:04:51,770 --> 00:04:56,960
data science process here you do some

00:04:54,020 --> 00:04:58,759
feature engineering do some modeling and

00:04:56,960 --> 00:05:01,039
evaluation so you pick account it models

00:04:58,759 --> 00:05:02,539
train them evaluate performance and then

00:05:01,039 --> 00:05:04,460
you deploy it and this sort of goes

00:05:02,539 --> 00:05:06,500
around in a continuous sort of fashion

00:05:04,460 --> 00:05:09,740
with lots of feedback loops and here are

00:05:06,500 --> 00:05:10,940
here and they're cool so we'll take you

00:05:09,740 --> 00:05:12,770
through our journey with obviously

00:05:10,940 --> 00:05:14,810
detecting malicious urls using machine

00:05:12,770 --> 00:05:16,400
learning Python so first up we have to

00:05:14,810 --> 00:05:18,199
know the user so this is typically done

00:05:16,400 --> 00:05:20,750
by doing things like interviewing

00:05:18,199 --> 00:05:22,580
service safaris guided sewers and

00:05:20,750 --> 00:05:24,229
empathy maps and it's really about

00:05:22,580 --> 00:05:25,970
putting yourself in the shoes of the end

00:05:24,229 --> 00:05:27,830
user so sitting in a Security Operations

00:05:25,970 --> 00:05:29,710
Center for a day understanding the tools

00:05:27,830 --> 00:05:31,639
that they use on a daily basis and

00:05:29,710 --> 00:05:33,500
through this process we're able to

00:05:31,639 --> 00:05:35,150
unveil a few key themes or challenges

00:05:33,500 --> 00:05:36,229
that we see in the security industry and

00:05:35,150 --> 00:05:38,510
obviously folks in this room probably

00:05:36,229 --> 00:05:40,400
know a bunch more the key ones that we

00:05:38,510 --> 00:05:41,750
sort of focused on we're management of

00:05:40,400 --> 00:05:43,669
numerous security tools so those

00:05:41,750 --> 00:05:46,010
numerous tools at the disposal of

00:05:43,669 --> 00:05:48,080
security teams and obviously maintaining

00:05:46,010 --> 00:05:49,699
them keeping them sort of current as a

00:05:48,080 --> 00:05:51,830
real challenge there's this thing called

00:05:49,699 --> 00:05:53,030
alert fatigue so folks are getting a

00:05:51,830 --> 00:05:54,860
bunch of alerts and they're sort of

00:05:53,030 --> 00:05:56,599
inundated by alerts each and every day

00:05:54,860 --> 00:05:59,630
and that sort of diminishes performance

00:05:56,599 --> 00:06:01,940
and may um sort of impact defense

00:05:59,630 --> 00:06:03,770
capability as well you've also got high

00:06:01,940 --> 00:06:05,930
staff turnover so obviously the the

00:06:03,770 --> 00:06:07,430
environment and the the context of

00:06:05,930 --> 00:06:08,780
security it's very there's a lot of

00:06:07,430 --> 00:06:09,919
highly skilled staff they're obviously

00:06:08,780 --> 00:06:11,300
getting poached from here and there and

00:06:09,919 --> 00:06:15,050
that obviously leaves a skills gap in

00:06:11,300 --> 00:06:16,490
your team as well so something in design

00:06:15,050 --> 00:06:17,990
thinking that's really handy it's sort

00:06:16,490 --> 00:06:20,180
of a snapshot of your end user and we

00:06:17,990 --> 00:06:21,650
call it a persona so in our case it was

00:06:20,180 --> 00:06:23,300
this security analyst persona that we

00:06:21,650 --> 00:06:25,789
wanted to obviously build a product for

00:06:23,300 --> 00:06:28,430
and it's all about defining their goals

00:06:25,789 --> 00:06:29,659
their needs and their pain points so

00:06:28,430 --> 00:06:31,310
here you can obviously a snapshot so

00:06:29,659 --> 00:06:33,949
maintaining a security architecture

00:06:31,310 --> 00:06:35,360
you've got to defend against myriad

00:06:33,949 --> 00:06:36,800
threat vectors so they obviously want

00:06:35,360 --> 00:06:38,159
coverage across the whole attack

00:06:36,800 --> 00:06:40,949
lifecycle

00:06:38,159 --> 00:06:43,619
the needs around rapid instant response

00:06:40,949 --> 00:06:44,789
a rich toolset and I obviously want some

00:06:43,619 --> 00:06:46,139
free time to work on interesting

00:06:44,789 --> 00:06:47,639
projects there's no one likes to be dumb

00:06:46,139 --> 00:06:49,050
to be doing the same thing each and

00:06:47,639 --> 00:06:51,269
every day just responding to the same

00:06:49,050 --> 00:06:52,589
sorts of incidents and obviously the

00:06:51,269 --> 00:06:54,529
pain points around alert fatigue is

00:06:52,589 --> 00:06:56,999
something that really really focused on

00:06:54,529 --> 00:06:58,619
so cool we really have this snapshot of

00:06:56,999 --> 00:07:00,239
our end user we're saying to understand

00:06:58,619 --> 00:07:02,969
it empathize with them now it's trying

00:07:00,239 --> 00:07:04,409
to kick off nailing down the problem so

00:07:02,969 --> 00:07:06,239
nailing down the problem is all about

00:07:04,409 --> 00:07:08,339
defining a problem statement and here

00:07:06,239 --> 00:07:09,989
it's all about setting a context of the

00:07:08,339 --> 00:07:11,429
problem you're trying to solve and then

00:07:09,989 --> 00:07:12,839
defining a problem statement in terms of

00:07:11,429 --> 00:07:15,389
design thinking so that sort of looks

00:07:12,839 --> 00:07:17,399
like the structure that's mostly used is

00:07:15,389 --> 00:07:20,249
you've got your user their needs and

00:07:17,399 --> 00:07:21,509
then what they benefit from that need so

00:07:20,249 --> 00:07:23,129
here we've got security analysts need

00:07:21,509 --> 00:07:24,809
rapid and intelligent cyber defense

00:07:23,129 --> 00:07:26,519
capability so they can stand a chance

00:07:24,809 --> 00:07:29,490
against our growing and often superior

00:07:26,519 --> 00:07:31,019
threat so cool we had a we had a real I

00:07:29,490 --> 00:07:32,639
guess this brought us along a journey we

00:07:31,019 --> 00:07:34,829
had a problem statement we dem pies with

00:07:32,639 --> 00:07:36,209
the N user we sort of we're getting

00:07:34,829 --> 00:07:37,229
really sort of invested in the project

00:07:36,209 --> 00:07:40,079
rather than just looking at a

00:07:37,229 --> 00:07:42,119
spreadsheet and going from there now

00:07:40,079 --> 00:07:44,579
this is where the fun begins the id8

00:07:42,119 --> 00:07:47,729
phase so using a common design thinking

00:07:44,579 --> 00:07:49,829
I guess methodology here is to use how

00:07:47,729 --> 00:07:51,360
might we statements on sticky notes and

00:07:49,829 --> 00:07:53,009
it's just about getting a good diverse

00:07:51,360 --> 00:07:55,229
bunch of stakeholders into a room

00:07:53,009 --> 00:07:56,789
no no skeptics in the room it's just

00:07:55,229 --> 00:07:58,079
about putting all the ideas you can on a

00:07:56,789 --> 00:08:00,300
board and it's really about cultivating

00:07:58,079 --> 00:08:01,979
creativity and it's creativity from not

00:08:00,300 --> 00:08:04,019
just the creative folks it's from all

00:08:01,979 --> 00:08:05,669
walks of life it's all it's all about

00:08:04,019 --> 00:08:07,800
having a diverse set of stakeholders in

00:08:05,669 --> 00:08:09,839
the room and there's no ideas that are

00:08:07,800 --> 00:08:12,179
dumb ideas and some common techniques

00:08:09,839 --> 00:08:14,849
years here like brain storming brain

00:08:12,179 --> 00:08:17,159
riding and mind mapping as well and

00:08:14,849 --> 00:08:20,219
these are all really common techniques

00:08:17,159 --> 00:08:21,629
that you can sort of research online so

00:08:20,219 --> 00:08:22,860
cool we started to ID eight and then we

00:08:21,629 --> 00:08:24,629
came up with this big file might wave

00:08:22,860 --> 00:08:26,369
statement how might we build an

00:08:24,629 --> 00:08:27,749
automated and intelligent ecosystem of

00:08:26,369 --> 00:08:29,279
machine learning models that work in

00:08:27,749 --> 00:08:30,659
unison to provide superior defense

00:08:29,279 --> 00:08:32,729
against an ever-evolving threat

00:08:30,659 --> 00:08:35,729
landscape I know it's a real mouthful

00:08:32,729 --> 00:08:36,990
but it really got us excited and we and

00:08:35,729 --> 00:08:38,279
that was sort of our starting point in

00:08:36,990 --> 00:08:40,529
terms of the high level how might we've

00:08:38,279 --> 00:08:42,810
sort of vision but we had to start one

00:08:40,529 --> 00:08:44,880
idea at a time and that's one prototype

00:08:42,810 --> 00:08:46,769
at a time so how might we detect

00:08:44,880 --> 00:08:50,220
malicious URLs using machine learning

00:08:46,769 --> 00:08:52,050
and part them cool so we had a use case

00:08:50,220 --> 00:08:54,510
now now it's time to kick off the funds

00:08:52,050 --> 00:08:57,990
stuff with coding and get into our sort

00:08:54,510 --> 00:08:59,190
of data science process elements so it's

00:08:57,990 --> 00:09:01,589
all about starting to understand the

00:08:59,190 --> 00:09:03,000
threat so first and more foremost we're

00:09:01,589 --> 00:09:05,399
sort of dealing with detecting malicious

00:09:03,000 --> 00:09:07,140
urls and I guess there's a few different

00:09:05,399 --> 00:09:09,300
guises here you've got the common

00:09:07,140 --> 00:09:12,140
cybersquatting we're really popular I

00:09:09,300 --> 00:09:14,670
guess brand domains are squatted online

00:09:12,140 --> 00:09:16,470
you've got phishing attempts

00:09:14,670 --> 00:09:17,970
you've also which also related to spam

00:09:16,470 --> 00:09:19,380
and your can just go into your gmail

00:09:17,970 --> 00:09:20,279
sort of spam folder and find a lot of

00:09:19,380 --> 00:09:22,500
examples of this

00:09:20,279 --> 00:09:24,060
you've got typos scoring which is subtle

00:09:22,500 --> 00:09:25,890
differences in the domain string as well

00:09:24,060 --> 00:09:28,019
and then you've got your more randomized

00:09:25,890 --> 00:09:29,700
strings related to URLs that are

00:09:28,019 --> 00:09:31,790
commonly used with botnets and some

00:09:29,700 --> 00:09:34,260
command and control sort of arm vectors

00:09:31,790 --> 00:09:35,700
so now we sort of understand

00:09:34,260 --> 00:09:38,310
I guess the threat that we're dealing

00:09:35,700 --> 00:09:41,040
with and what we wanted to detect now it

00:09:38,310 --> 00:09:42,180
was time to acquire some data so we

00:09:41,040 --> 00:09:44,279
couldn't actually get our hands on some

00:09:42,180 --> 00:09:45,870
real-world die within our organization

00:09:44,279 --> 00:09:48,120
so we had to go out into the open source

00:09:45,870 --> 00:09:51,089
world and sort of consulting a few

00:09:48,120 --> 00:09:53,070
different papers were able to find the

00:09:51,089 --> 00:09:54,480
benign would be a benign data set as

00:09:53,070 --> 00:09:57,000
Alexa top 1 million would be a good

00:09:54,480 --> 00:09:59,430
starting point I know not all Alexa top

00:09:57,000 --> 00:10:01,740
1 million websites will be exactly

00:09:59,430 --> 00:10:03,390
benign and not malicious there's

00:10:01,740 --> 00:10:06,120
obviously some contamination there

00:10:03,390 --> 00:10:08,760
possibly especially at the pointy end at

00:10:06,120 --> 00:10:10,050
the end in the tail end sorry on the

00:10:08,760 --> 00:10:11,490
other side you've got the malicious data

00:10:10,050 --> 00:10:13,950
set that we chose which was fishtank

00:10:11,490 --> 00:10:15,540
which is a database of phishing URLs and

00:10:13,950 --> 00:10:16,490
then we used some enrichment so we

00:10:15,540 --> 00:10:18,630
looked at the Ayana

00:10:16,490 --> 00:10:20,399
designations which we can get by using

00:10:18,630 --> 00:10:23,459
the first octet of the underlying host

00:10:20,399 --> 00:10:27,810
IP under our urls to find out where the

00:10:23,459 --> 00:10:29,520
the IP address was designated from cool

00:10:27,810 --> 00:10:31,829
so we started to sort of build this I

00:10:29,520 --> 00:10:33,420
guess feature set some of the common I

00:10:31,829 --> 00:10:35,370
guess features that we saw in our data

00:10:33,420 --> 00:10:37,350
that we were able to extract using a bit

00:10:35,370 --> 00:10:39,300
of Python and a few api's was domain

00:10:37,350 --> 00:10:40,980
creation date consulting Whois database

00:10:39,300 --> 00:10:43,500
I know gdpr is probably gonna have a bit

00:10:40,980 --> 00:10:46,440
of a an impact on the amount of Whois

00:10:43,500 --> 00:10:47,940
data that you can get in the future we

00:10:46,440 --> 00:10:49,829
also looked at the expiry date so how

00:10:47,940 --> 00:10:52,709
soon is the domain going to be expiring

00:10:49,829 --> 00:10:56,040
related to that URL the underlying host

00:10:52,709 --> 00:10:57,600
IP if we use socket the domain its name

00:10:56,040 --> 00:11:00,480
itself and sort of looking at lexical

00:10:57,600 --> 00:11:01,920
features we looked at the registrar or

00:11:00,480 --> 00:11:04,529
the host who is server that related to

00:11:01,920 --> 00:11:05,930
the domain in the URL and a bunch of

00:11:04,529 --> 00:11:08,430
other ones

00:11:05,930 --> 00:11:09,839
so doing a little bit of exploratory

00:11:08,430 --> 00:11:11,670
data analysis I've just got some samples

00:11:09,839 --> 00:11:13,290
from our data there's obviously some

00:11:11,670 --> 00:11:15,990
really dodgy who is servers that we saw

00:11:13,290 --> 00:11:17,790
were to unveil in the form of public

00:11:15,990 --> 00:11:19,200
domain registry so it's a little bit of

00:11:17,790 --> 00:11:20,730
an these features had a little bit of

00:11:19,200 --> 00:11:22,709
information in here that would be worthy

00:11:20,730 --> 00:11:26,279
for us say a machine learning model

00:11:22,709 --> 00:11:28,260
downstream and we sort of used Seaborn

00:11:26,279 --> 00:11:31,470
and Matt pop lube to sort of plot these

00:11:28,260 --> 00:11:35,760
explore exploratory data charts out for

00:11:31,470 --> 00:11:36,870
us so second we've got creation bins so

00:11:35,760 --> 00:11:39,360
we did a bit of bidding on the creation

00:11:36,870 --> 00:11:41,040
date of the domain and as you can see

00:11:39,360 --> 00:11:42,660
here as you sort of get in the middle

00:11:41,040 --> 00:11:44,399
bit where you've got sort of more

00:11:42,660 --> 00:11:46,980
recently created domains you start to

00:11:44,399 --> 00:11:48,300
see more of a malicious count and then

00:11:46,980 --> 00:11:49,740
as you get the older domains you see

00:11:48,300 --> 00:11:52,350
more of a sort of benign count so

00:11:49,740 --> 00:11:54,029
obviously older more I guess established

00:11:52,350 --> 00:11:56,100
domains generally I'll burn up and I'm

00:11:54,029 --> 00:12:00,420
but obviously sometimes they can be

00:11:56,100 --> 00:12:01,680
malicious as well so now we've got this

00:12:00,420 --> 00:12:02,970
sort of feature set now it's time to

00:12:01,680 --> 00:12:05,370
prepare it for I'm ashamed learning

00:12:02,970 --> 00:12:07,100
phase and things that were used in here

00:12:05,370 --> 00:12:08,700
with things like normalization

00:12:07,100 --> 00:12:10,740
standardization of our continuous

00:12:08,700 --> 00:12:13,080
variables embeddings for categorical

00:12:10,740 --> 00:12:15,660
variables by leveraging the fast AI API

00:12:13,080 --> 00:12:18,170
built in Python and over and its

00:12:15,660 --> 00:12:20,970
underlying an architecture is a PI torch

00:12:18,170 --> 00:12:22,200
we also complimented the feature set

00:12:20,970 --> 00:12:23,490
with a few different features that we

00:12:22,200 --> 00:12:25,680
could sort of engineer from existing

00:12:23,490 --> 00:12:29,490
ones so digit percentage of the string

00:12:25,680 --> 00:12:30,779
special characters and we also looked at

00:12:29,490 --> 00:12:32,130
Shannon entropy of the string so

00:12:30,779 --> 00:12:34,440
randomness of characters and we actually

00:12:32,130 --> 00:12:36,540
found this this measure to be actually

00:12:34,440 --> 00:12:38,370
quite a poor feature and we sort of

00:12:36,540 --> 00:12:41,070
found later down the track that some NLP

00:12:38,370 --> 00:12:42,990
techniques around looking at randomness

00:12:41,070 --> 00:12:44,959
of strings will probably be superior so

00:12:42,990 --> 00:12:47,760
we're looking to use that in the future

00:12:44,959 --> 00:12:49,320
so cool we had a pretty luscious feature

00:12:47,760 --> 00:12:50,579
set I guess and something to start with

00:12:49,320 --> 00:12:53,610
so now it was time to kick off our

00:12:50,579 --> 00:13:05,329
modeling and evaluation so I'll hand it

00:12:53,610 --> 00:13:08,970
over to Trish amazing accuracy of 90%

00:13:05,329 --> 00:13:11,370
how do I know it is performing well on

00:13:08,970 --> 00:13:13,920
real world that are that the motor has

00:13:11,370 --> 00:13:16,079
not seen before does it actually work so

00:13:13,920 --> 00:13:17,459
this is why having a test that they

00:13:16,079 --> 00:13:19,800
represent and some data is very

00:13:17,459 --> 00:13:20,760
important it's a common practice to have

00:13:19,800 --> 00:13:22,980
around

00:13:20,760 --> 00:13:25,140
display the data into training set test

00:13:22,980 --> 00:13:27,089
and and validation set training set is

00:13:25,140 --> 00:13:30,089
used to train your model and tested is

00:13:27,089 --> 00:13:31,860
used to test the performance of your

00:13:30,089 --> 00:13:35,240
model on unseen data so that you know

00:13:31,860 --> 00:13:38,910
how well your model is working and

00:13:35,240 --> 00:13:41,310
validations that is used for parameter

00:13:38,910 --> 00:13:43,680
and model selection it's common to have

00:13:41,310 --> 00:13:45,750
around 20% of test set but that

00:13:43,680 --> 00:13:47,880
ultimately depends on the amount of data

00:13:45,750 --> 00:13:50,480
you have say you have if you have a

00:13:47,880 --> 00:13:52,920
million a massive data of a million rows

00:13:50,480 --> 00:13:57,630
one or two percent would be equally

00:13:52,920 --> 00:13:59,610
sufficient so we have attempted a few

00:13:57,630 --> 00:14:01,529
models for this use case and the top

00:13:59,610 --> 00:14:05,640
performing models deep neural network

00:14:01,529 --> 00:14:07,860
random forests and what embedding so new

00:14:05,640 --> 00:14:09,870
network your network weighs three layers

00:14:07,860 --> 00:14:12,150
and above are considered deep neural

00:14:09,870 --> 00:14:14,040
network the layers and hidden units

00:14:12,150 --> 00:14:17,490
allow the motor to learn complex feature

00:14:14,040 --> 00:14:19,260
and high dimensional data typically dip

00:14:17,490 --> 00:14:20,970
near now it requires a lot of tuning

00:14:19,260 --> 00:14:22,949
which means you need an extensive

00:14:20,970 --> 00:14:23,339
knowledge of the model in order to use

00:14:22,949 --> 00:14:25,290
it

00:14:23,339 --> 00:14:26,750
they usually train using conventional PI

00:14:25,290 --> 00:14:30,480
torch or

00:14:26,750 --> 00:14:32,699
tensorflow frameworks alternatively you

00:14:30,480 --> 00:14:36,660
can use pre trained models for transfer

00:14:32,699 --> 00:14:38,130
learning and libraries like faster I can

00:14:36,660 --> 00:14:40,500
make things a lot easier and faster

00:14:38,130 --> 00:14:41,940
especially for beginners who are keen to

00:14:40,500 --> 00:14:45,420
get their hands dirty and deepen your

00:14:41,940 --> 00:14:46,949
network on person class of deep learning

00:14:45,420 --> 00:14:50,070
so deep learning is known to be very

00:14:46,949 --> 00:14:51,870
powerful and it's able to do automatic

00:14:50,070 --> 00:14:53,970
feature instructions so you don't need

00:14:51,870 --> 00:14:56,250
to do a lot of the ameno and feature

00:14:53,970 --> 00:14:57,900
engineering the seventh age is that it

00:14:56,250 --> 00:15:00,810
requires massive amounts of data

00:14:57,900 --> 00:15:02,820
it requires huge computing power the

00:15:00,810 --> 00:15:06,300
architecture can be complex in how to

00:15:02,820 --> 00:15:08,190
tune and the resulting model may not be

00:15:06,300 --> 00:15:11,540
easily interpretable I think you don't

00:15:08,190 --> 00:15:14,090
know why it does what it is okay

00:15:11,540 --> 00:15:16,010
and we have random forest the random

00:15:14,090 --> 00:15:17,720
forest is an unsub of decision trees

00:15:16,010 --> 00:15:20,180
which basically means a collection of

00:15:17,720 --> 00:15:23,090
trees so decision trees predict the

00:15:20,180 --> 00:15:25,190
final label by splitting randomly at

00:15:23,090 --> 00:15:27,080
multiple decision points based on slider

00:15:25,190 --> 00:15:29,300
features patter model in this case

00:15:27,080 --> 00:15:32,060
having many trees provides a better

00:15:29,300 --> 00:15:34,010
generation and reduce overfitting the

00:15:32,060 --> 00:15:35,930
algorithm makes predictions by using

00:15:34,010 --> 00:15:38,390
majority word of each individual trees

00:15:35,930 --> 00:15:40,850
so some of the pros are it's quite

00:15:38,390 --> 00:15:43,760
commonly used and it gives you pretty

00:15:40,850 --> 00:15:46,250
good result it doesn't require a lot of

00:15:43,760 --> 00:15:48,800
scaling of data it's it can handle

00:15:46,250 --> 00:15:51,530
mixture of feature types the concert the

00:15:48,800 --> 00:15:53,150
model can be difficult to interpret as

00:15:51,530 --> 00:15:55,520
well just like getting your network and

00:15:53,150 --> 00:16:00,680
it's not suitable for high dimensional

00:15:55,520 --> 00:16:03,530
data word embedding is typically used

00:16:00,680 --> 00:16:07,000
associate words with their label take

00:16:03,530 --> 00:16:09,500
for instance take the use case of MDB

00:16:07,000 --> 00:16:11,660
movie review we are able to find words

00:16:09,500 --> 00:16:15,260
associated with positive and negative

00:16:11,660 --> 00:16:16,850
review in our use case we use character

00:16:15,260 --> 00:16:19,220
based word embedding which creates a

00:16:16,850 --> 00:16:21,950
vector representation of each character

00:16:19,220 --> 00:16:26,780
in the URL using multiple dimensions

00:16:21,950 --> 00:16:28,870
this was trained using tensor floor ok

00:16:26,780 --> 00:16:31,100
so this is the table that shows the

00:16:28,870 --> 00:16:34,610
performance of the models we have

00:16:31,100 --> 00:16:39,220
obtained and as you can see in our if

00:16:34,610 --> 00:16:41,390
the we know here ok ok

00:16:39,220 --> 00:16:43,070
evaluation method here we have a few

00:16:41,390 --> 00:16:45,620
methods of evaluating machine learning

00:16:43,070 --> 00:16:47,090
models so accuracy is pretty

00:16:45,620 --> 00:16:48,410
straightforward it's just a percentage

00:16:47,090 --> 00:16:51,110
of correct prediction over the total

00:16:48,410 --> 00:16:53,030
number and then we have f1 score

00:16:51,110 --> 00:16:55,010
f1 score is quite the standard

00:16:53,030 --> 00:16:59,210
evaluation method especially when it

00:16:55,010 --> 00:17:01,220
comes to competitions like cargo we

00:16:59,210 --> 00:17:02,630
think f1 score is most suitable for use

00:17:01,220 --> 00:17:05,300
case because it takes into consideration

00:17:02,630 --> 00:17:07,610
false positives and false negatives rate

00:17:05,300 --> 00:17:10,640
we don't want our model to give too many

00:17:07,610 --> 00:17:11,959
false positives to us to the security

00:17:10,640 --> 00:17:13,880
analysts because there was slaughter

00:17:11,959 --> 00:17:16,280
internal response and because they will

00:17:13,880 --> 00:17:17,530
be within a lot of time investigating

00:17:16,280 --> 00:17:20,720
false leads

00:17:17,530 --> 00:17:21,959
f1 score is also preferred our position

00:17:20,720 --> 00:17:24,510
haricots because of

00:17:21,959 --> 00:17:26,189
amazing precision or recall if actually

00:17:24,510 --> 00:17:28,620
trading off the other for example

00:17:26,189 --> 00:17:30,750
raising the value of precision actually

00:17:28,620 --> 00:17:32,700
gives you a lower recoil value whereas

00:17:30,750 --> 00:17:36,929
optimizing f1 gives you a good balance

00:17:32,700 --> 00:17:40,200
of Paris the diagram at the right is an

00:17:36,929 --> 00:17:42,450
example of confusion matrix which shows

00:17:40,200 --> 00:17:46,080
true positives to negative lips and

00:17:42,450 --> 00:17:47,940
vice-versa and here's the coefficient

00:17:46,080 --> 00:17:50,850
matrix for our very model the deep

00:17:47,940 --> 00:17:52,919
neural network so Commission matrix

00:17:50,850 --> 00:17:54,779
gives a good visual representation of

00:17:52,919 --> 00:17:57,210
your motor performance as you can see

00:17:54,779 --> 00:17:59,490
here our deep neural network has a

00:17:57,210 --> 00:18:06,690
higher false notif rate compared to

00:17:59,490 --> 00:18:08,820
false positive and so if my ability of

00:18:06,690 --> 00:18:11,250
machine learning models has become quite

00:18:08,820 --> 00:18:13,500
an interest slightly complex models like

00:18:11,250 --> 00:18:15,809
deep neural network are considered like

00:18:13,500 --> 00:18:18,809
boxes because it's difficult to know

00:18:15,809 --> 00:18:20,970
what's going on within the model ideally

00:18:18,809 --> 00:18:23,340
we want to avoid using models that rely

00:18:20,970 --> 00:18:26,149
on undesirable features such as those

00:18:23,340 --> 00:18:29,340
that will lead to biases in production

00:18:26,149 --> 00:18:32,039
for instance in in the context of image

00:18:29,340 --> 00:18:34,409
classification the model might be

00:18:32,039 --> 00:18:36,179
relying on our background instead of to

00:18:34,409 --> 00:18:39,740
classify whether a picture has a wolf in

00:18:36,179 --> 00:18:42,990
it instead of using the graph itself so

00:18:39,740 --> 00:18:44,909
introducing AB library Casa shop is a

00:18:42,990 --> 00:18:47,100
very cool library which allows for the

00:18:44,909 --> 00:18:49,470
insights into the internal working of

00:18:47,100 --> 00:18:51,960
models so using this you are able to get

00:18:49,470 --> 00:18:54,270
a global or local explanation of your

00:18:51,960 --> 00:18:56,669
model prediction Globo tells you which

00:18:54,270 --> 00:18:59,100
features influence the model as a whole

00:18:56,669 --> 00:19:01,140
and then local informs you which feature

00:18:59,100 --> 00:19:03,929
influenced the outcome of individual

00:19:01,140 --> 00:19:06,690
predictions here's an example of how it

00:19:03,929 --> 00:19:09,809
works so if you could take the milk and

00:19:06,690 --> 00:19:12,690
example the red is positive shop values

00:19:09,809 --> 00:19:15,120
increases the probability of it being a

00:19:12,690 --> 00:19:17,309
meerkat according to your model and blue

00:19:15,120 --> 00:19:21,270
is negative values that reduces

00:19:17,309 --> 00:19:23,730
probability of the class so from this we

00:19:21,270 --> 00:19:26,279
can this shows that the model is relying

00:19:23,730 --> 00:19:28,590
on the eyes to detect whether a picture

00:19:26,279 --> 00:19:30,779
has a meerkat you can find out more

00:19:28,590 --> 00:19:35,149
about this library on their github page

00:19:30,779 --> 00:19:35,149
which also contains more examples

00:19:35,690 --> 00:19:41,700
okay so parameter tuning what is the

00:19:39,720 --> 00:19:44,100
parameter tuning parameter tuning is

00:19:41,700 --> 00:19:46,650
just trying out different values for

00:19:44,100 --> 00:19:49,920
your model parameters in order to obtain

00:19:46,650 --> 00:19:50,520
a better result take you an hour as an

00:19:49,920 --> 00:19:51,630
example

00:19:50,520 --> 00:19:53,720
soon it will be trying out different

00:19:51,630 --> 00:19:56,040
number of layers number of hidden units

00:19:53,720 --> 00:19:58,290
learning rate and activation functions

00:19:56,040 --> 00:19:59,880
so we have two main methods of

00:19:58,290 --> 00:20:01,620
optimizing parameters they are great

00:19:59,880 --> 00:20:04,410
search and random search great search

00:20:01,620 --> 00:20:07,290
searches all safely through a range of

00:20:04,410 --> 00:20:10,530
values that you have provided and gives

00:20:07,290 --> 00:20:12,600
you the optimal combination the downside

00:20:10,530 --> 00:20:15,660
of this is it takes time and it's

00:20:12,600 --> 00:20:18,150
computationally expensive so and then on

00:20:15,660 --> 00:20:20,760
the other hand we have random search an

00:20:18,150 --> 00:20:25,170
unsub searches through the values that

00:20:20,760 --> 00:20:27,150
you have provided randomly and this

00:20:25,170 --> 00:20:29,760
require less processing time but you're

00:20:27,150 --> 00:20:33,120
not guaranteed to get optimal

00:20:29,760 --> 00:20:35,040
combination of the values so now I hand

00:20:33,120 --> 00:20:41,940
this back to Alistair for the closing

00:20:35,040 --> 00:20:43,170
 and ba-ba-boom so last bit the

00:20:41,940 --> 00:20:44,580
deployment is actually carrying under

00:20:43,170 --> 00:20:45,750
structure under construction and we're

00:20:44,580 --> 00:20:47,220
looking at things like starlet and

00:20:45,750 --> 00:20:48,690
fluxed and built last to build that out

00:20:47,220 --> 00:20:49,290
and obviously as you can see we're

00:20:48,690 --> 00:20:51,270
trying to work

00:20:49,290 --> 00:20:52,770
I guess hard on improving our model as

00:20:51,270 --> 00:20:55,770
well in terms of features and the

00:20:52,770 --> 00:20:57,360
evaluation we do just to fish shoutouts

00:20:55,770 --> 00:20:59,730
to Katie Ford for the wonderful artwork

00:20:57,360 --> 00:21:01,620
in our presentation egg Fang and Palmer

00:20:59,730 --> 00:21:05,370
and we continue to push us and obviously

00:21:01,620 --> 00:21:06,750
the wonderful Python community and yeah

00:21:05,370 --> 00:21:07,710
thank you for having us and I hope you

00:21:06,750 --> 00:21:13,670
have a great evening

00:21:07,710 --> 00:21:17,180
[Applause]

00:21:13,670 --> 00:21:24,130
thank you for that great talk so people

00:21:17,180 --> 00:21:24,130

YouTube URL: https://www.youtube.com/watch?v=ZhvlfNi-0aY


