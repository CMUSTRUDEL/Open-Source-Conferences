Title: "Sufficiently Advanced Testing" - Zac Hatfield-Dodds (PyCon AU 2019)
Publication date: 2019-08-03
Playlist: PyCon Australia 2019
Description: 
	Zac Hatfield-Dodds

Writing tests is great, and generating randomized tests even better... but we can push the techniques further still! What is a metamorphic relation good for?  How could (should?) you use a SAT solver for tests?  What about symbolic execution, guided fuzzing, delta debugging?  Come and find out!

https://2019.pycon-au.org/talks/sufficiently-advanced-testing

PyCon AU, the national Python Language conference, is on again this August in Sydney, at the International Convention Centre, Sydney, August 2 - 6 2019.

Video licence: CC BY-NC-SA 4.0 - https://creativecommons.org/licenses/by-nc-sa/4.0/

Python, PyCon, PyConAU

Sat Aug  3 13:30:00 2019 at C3.6
Captions: 
	00:00:03,920 --> 00:00:08,429
good afternoon everyone

00:00:06,089 --> 00:00:10,679
it's my incredible privilege this

00:00:08,429 --> 00:00:13,980
afternoon to introduce my colleague from

00:00:10,679 --> 00:00:17,010
the 3ai Institute at the ANU in Canberra

00:00:13,980 --> 00:00:19,380
as Zach Hatfield Dodds zach is a

00:00:17,010 --> 00:00:21,630
researcher at the 3ei Institute which is

00:00:19,380 --> 00:00:24,900
building a new Applied Science to manage

00:00:21,630 --> 00:00:27,840
the machines AI cyber-physical systems

00:00:24,900 --> 00:00:29,820
and other new technologies he started

00:00:27,840 --> 00:00:32,489
using Python to analyze huge

00:00:29,820 --> 00:00:35,190
environmental data sets and contributing

00:00:32,489 --> 00:00:38,280
to libraries like X array to make such

00:00:35,190 --> 00:00:39,510
analysis easier for all scientists now

00:00:38,280 --> 00:00:42,930
as a maintainer

00:00:39,510 --> 00:00:45,090
of hypothesis PI test and trio Zak is

00:00:42,930 --> 00:00:47,070
still passionate about making it easy to

00:00:45,090 --> 00:00:50,160
write software you can understand and

00:00:47,070 --> 00:00:52,230
rely on when not at a computer he can

00:00:50,160 --> 00:00:54,600
usually be found surrounded by books of

00:00:52,230 --> 00:00:58,340
all kinds somewhere out of phone range

00:00:54,600 --> 00:01:02,069
or both please make Zack welcome

00:00:58,340 --> 00:01:02,069
[Applause]

00:01:06,080 --> 00:01:11,310
microphone on might help a little so

00:01:09,810 --> 00:01:13,470
thanks so much for that welcome Cathy I

00:01:11,310 --> 00:01:15,150
no longer need to introduce myself

00:01:13,470 --> 00:01:17,689
because it turns out I already wrote an

00:01:15,150 --> 00:01:20,880
introduction for the abstract page I

00:01:17,689 --> 00:01:22,530
just also like to say thank you to all

00:01:20,880 --> 00:01:24,240
of the other people from the three aids

00:01:22,530 --> 00:01:25,710
who are here today and if you're

00:01:24,240 --> 00:01:27,090
interested in that come talk to us

00:01:25,710 --> 00:01:28,590
because we're running a new master's

00:01:27,090 --> 00:01:31,890
program we would applied cybernetics

00:01:28,590 --> 00:01:33,420
next year as well but let's get into the

00:01:31,890 --> 00:01:37,200
deep dive talk that I proposed on

00:01:33,420 --> 00:01:39,409
sufficiently advanced testing I'm going

00:01:37,200 --> 00:01:41,280
to be talking through four parts here

00:01:39,409 --> 00:01:43,140
which is based from how I actually

00:01:41,280 --> 00:01:45,930
started to think about what would make a

00:01:43,140 --> 00:01:47,250
deep dive talk this came out of the

00:01:45,930 --> 00:01:48,659
feedback from last year's Park on

00:01:47,250 --> 00:01:50,579
Australia where people said that they

00:01:48,659 --> 00:01:53,369
would really appreciate more expert

00:01:50,579 --> 00:01:54,720
level or deep dive content but of course

00:01:53,369 --> 00:01:56,549
because they haven't happened before I

00:01:54,720 --> 00:01:59,159
had no examples to base my own talk on

00:01:56,549 --> 00:02:00,840
so what am I going to try to do today I

00:01:59,159 --> 00:02:03,000
decided that I would pitch this for an

00:02:00,840 --> 00:02:05,250
audience which was comfortable coming to

00:02:03,000 --> 00:02:06,509
a talk advertised as expert level so

00:02:05,250 --> 00:02:07,950
there will be some terms that I'm not

00:02:06,509 --> 00:02:10,800
going to explain from first principles

00:02:07,950 --> 00:02:13,140
but I'm not aiming to require any

00:02:10,800 --> 00:02:13,900
specific expertise or experience with

00:02:13,140 --> 00:02:16,030
advanced

00:02:13,900 --> 00:02:18,489
frameworks the whole idea is that this

00:02:16,030 --> 00:02:19,989
is the introduction for experts in other

00:02:18,489 --> 00:02:23,409
things who haven't learned as much about

00:02:19,989 --> 00:02:25,269
testing as they would like to my goal is

00:02:23,409 --> 00:02:26,890
to focus more on ideas than specific

00:02:25,269 --> 00:02:28,720
tools especially because many of the

00:02:26,890 --> 00:02:32,019
ideas do not have a corresponding tool

00:02:28,720 --> 00:02:34,120
in Python at least not yet to change how

00:02:32,019 --> 00:02:35,829
you think about testing and right at the

00:02:34,120 --> 00:02:37,480
end to give you a single concrete

00:02:35,829 --> 00:02:39,099
takeaway something that you can

00:02:37,480 --> 00:02:40,870
implement on Monday to ensure that

00:02:39,099 --> 00:02:42,780
whatever your project or product is is

00:02:40,870 --> 00:02:46,389
better tested than it was before

00:02:42,780 --> 00:02:47,889
so the talk in four parts first I'm

00:02:46,389 --> 00:02:49,810
going to talk about the state of the art

00:02:47,889 --> 00:02:51,700
of testing how we come up with test

00:02:49,810 --> 00:02:53,950
cases and how we can make computers do

00:02:51,700 --> 00:02:55,690
it for us I'm then going to give a bit

00:02:53,950 --> 00:02:57,730
of an overview of how a project called

00:02:55,690 --> 00:02:59,500
hypothesis that I work on is implemented

00:02:57,730 --> 00:03:01,239
what it actually takes to put these

00:02:59,500 --> 00:03:02,220
techniques into practice with reasonable

00:03:01,239 --> 00:03:05,290
efficiency

00:03:02,220 --> 00:03:07,150
my favorite section perhaps is the third

00:03:05,290 --> 00:03:09,430
where I talk about techniques I think of

00:03:07,150 --> 00:03:11,590
is indistinguishable from magic things

00:03:09,430 --> 00:03:13,209
which are just super cool so cool then

00:03:11,590 --> 00:03:15,790
it seems they can't possibly work and

00:03:13,209 --> 00:03:19,389
yet I won't say they do but they might

00:03:15,790 --> 00:03:20,980
if we implemented them and then last of

00:03:19,389 --> 00:03:22,540
all of course I did promise a concrete

00:03:20,980 --> 00:03:24,129
takeaway so there will be that call to

00:03:22,540 --> 00:03:30,310
action with a specific thing that you

00:03:24,129 --> 00:03:32,349
can do on Monday so for the purpose of

00:03:30,310 --> 00:03:35,260
this talk I'm going to define testing as

00:03:32,349 --> 00:03:37,030
any technique where you assess whether

00:03:35,260 --> 00:03:38,859
or not your code is correct whether it's

00:03:37,030 --> 00:03:41,980
doing the right thing by actually

00:03:38,859 --> 00:03:44,109
executing the code and this is quite

00:03:41,980 --> 00:03:45,729
restrictive among the range of all

00:03:44,109 --> 00:03:47,049
techniques that we could use to assess

00:03:45,729 --> 00:03:51,790
whether our code is doing the right

00:03:47,049 --> 00:03:53,829
thing so we could for example use a tool

00:03:51,790 --> 00:03:55,599
like my PI for type checking so we

00:03:53,829 --> 00:03:58,060
annotate our code for each function we

00:03:55,599 --> 00:04:00,099
declare what type of argument we expect

00:03:58,060 --> 00:04:01,540
for it and this tool can actually read

00:04:00,099 --> 00:04:03,159
our source code and determine if there

00:04:01,540 --> 00:04:04,840
are any places where we're calling that

00:04:03,159 --> 00:04:07,349
function with the type that we didn't

00:04:04,840 --> 00:04:10,810
expect this is actually really useful

00:04:07,349 --> 00:04:11,919
but it's not testing one of my favorite

00:04:10,810 --> 00:04:15,159
techniques is getting enough sleep

00:04:11,919 --> 00:04:17,320
tonight before I find I write much

00:04:15,159 --> 00:04:20,049
better code and many fewer bugs if I'm

00:04:17,320 --> 00:04:21,969
not sleep deprived I also get twitchy if

00:04:20,049 --> 00:04:23,919
I have too much caffeine and if I hit

00:04:21,969 --> 00:04:27,430
the wrong keys that usually doesn't help

00:04:23,919 --> 00:04:28,979
either code review is another great one

00:04:27,430 --> 00:04:31,090
and there can be human Cobra for your

00:04:28,979 --> 00:04:33,430
workflow that's become familiar to most

00:04:31,090 --> 00:04:35,740
of us through github where you propose a

00:04:33,430 --> 00:04:37,509
change to some project and a different

00:04:35,740 --> 00:04:40,150
human not the author of the change has

00:04:37,509 --> 00:04:42,250
to review it first and the exact process

00:04:40,150 --> 00:04:44,169
of code review varies between projects

00:04:42,250 --> 00:04:45,910
but the fundamental idea is that at

00:04:44,169 --> 00:04:49,270
least one other person thinks it's a

00:04:45,910 --> 00:04:50,770
good idea to merge that change I at

00:04:49,270 --> 00:04:52,600
least find that very useful as the

00:04:50,770 --> 00:04:58,139
author of changes which should not

00:04:52,600 --> 00:05:01,539
always be merged yet but today testing

00:04:58,139 --> 00:05:06,580
so how exactly do we write tests how do

00:05:01,539 --> 00:05:08,169
we work out how we execute our code the

00:05:06,580 --> 00:05:10,090
traditional way of doing it which most

00:05:08,169 --> 00:05:12,580
of us will be familiar with as unit

00:05:10,090 --> 00:05:14,740
tests is we think of some input for a

00:05:12,580 --> 00:05:17,470
function so for addition we might try to

00:05:14,740 --> 00:05:20,229
add one and two and then we call our

00:05:17,470 --> 00:05:22,180
function your add one two and then we

00:05:20,229 --> 00:05:24,759
assert that we got the expected result

00:05:22,180 --> 00:05:28,270
that is three at least if I'm

00:05:24,759 --> 00:05:31,539
implementing addition but this has a

00:05:28,270 --> 00:05:33,010
couple of challenges the most serious I

00:05:31,539 --> 00:05:35,680
think is actually the one written on the

00:05:33,010 --> 00:05:37,780
slide that I don't know about you but

00:05:35,680 --> 00:05:39,970
for me at least if I think of an edge

00:05:37,780 --> 00:05:41,590
case I might write a test for it but

00:05:39,970 --> 00:05:43,650
it's probably not one that I completely

00:05:41,590 --> 00:05:47,889
forgot when I was writing the code and

00:05:43,650 --> 00:05:50,979
so however carefully I think about

00:05:47,889 --> 00:05:53,080
things or how many test cases I try to

00:05:50,979 --> 00:05:55,000
write there are certain things that

00:05:53,080 --> 00:05:57,400
would just never occur to me to test and

00:05:55,000 --> 00:05:58,990
sometimes that's because I truly don't

00:05:57,400 --> 00:06:00,789
understand the system that I'm working

00:05:58,990 --> 00:06:03,820
with I'll give an example of that later

00:06:00,789 --> 00:06:05,470
in the talk but even before we get to

00:06:03,820 --> 00:06:07,810
this kind of fundamental challenge which

00:06:05,470 --> 00:06:09,520
yeah it seems really serious but it

00:06:07,810 --> 00:06:12,639
doesn't really seem likely to come up

00:06:09,520 --> 00:06:15,490
that often we have this other one that

00:06:12,639 --> 00:06:19,599
humans don't scale as well as computers

00:06:15,490 --> 00:06:22,300
do so for every test case that we write

00:06:19,599 --> 00:06:24,970
a human actually has to sit and think

00:06:22,300 --> 00:06:27,430
carefully and type it out and so while

00:06:24,970 --> 00:06:30,000
this kind of Auto manual testing

00:06:27,430 --> 00:06:33,610
automated execution but manual creation

00:06:30,000 --> 00:06:35,409
is really useful for regression testing

00:06:33,610 --> 00:06:37,840
to make sure that no bugs don't reinjure

00:06:35,409 --> 00:06:39,370
our code base or for testing edge cases

00:06:37,840 --> 00:06:41,470
where we suspect that bugs might occur

00:06:39,370 --> 00:06:43,120
in the future I actually don't

00:06:41,470 --> 00:06:45,240
think it's suitable as the only form of

00:06:43,120 --> 00:06:47,410
testing that we do and whether that's

00:06:45,240 --> 00:06:49,270
what you might call unit testing and

00:06:47,410 --> 00:06:51,940
very small functions or integration or

00:06:49,270 --> 00:06:53,740
even end-to-end testing the kind of test

00:06:51,940 --> 00:06:56,230
where we specify exact inputs and

00:06:53,740 --> 00:06:59,320
outputs doesn't scale as well as I think

00:06:56,230 --> 00:07:05,080
we need our tests to scale so what could

00:06:59,320 --> 00:07:08,140
we do instead one great cute option is

00:07:05,080 --> 00:07:11,680
exhaustive testing and conceptually this

00:07:08,140 --> 00:07:14,890
is really simple all we do is we execute

00:07:11,680 --> 00:07:16,920
every possible behavior of our code and

00:07:14,890 --> 00:07:20,200
we check that each one is correct

00:07:16,920 --> 00:07:21,910
of course there's two problems here the

00:07:20,200 --> 00:07:24,100
first is that we probably don't have

00:07:21,910 --> 00:07:26,350
time to check more than a tiny fraction

00:07:24,100 --> 00:07:28,930
of the possibly trillions or infinite

00:07:26,350 --> 00:07:30,430
number of possible behaviors and the

00:07:28,930 --> 00:07:32,440
second is that it's really hard to tell

00:07:30,430 --> 00:07:34,990
whether the behavior is correct if you

00:07:32,440 --> 00:07:36,070
don't compare it to an exact output how

00:07:34,990 --> 00:07:39,490
do you know whether you got the right

00:07:36,070 --> 00:07:42,780
result and of course this gets even

00:07:39,490 --> 00:07:46,169
harder when your requirements are fuzzy

00:07:42,780 --> 00:07:50,350
we might call them business logic or

00:07:46,169 --> 00:07:53,890
user interviews or hallway usability

00:07:50,350 --> 00:07:56,110
testing and if you're on extremely hard

00:07:53,890 --> 00:08:00,729
mode the requirements might even change

00:07:56,110 --> 00:08:03,550
over time and building a system where

00:08:00,729 --> 00:08:05,200
the exhaustive testing takes longer much

00:08:03,550 --> 00:08:07,210
much longer than you expect to have

00:08:05,200 --> 00:08:09,940
before the requirements change does not

00:08:07,210 --> 00:08:12,460
sound like much fun for me but there is

00:08:09,940 --> 00:08:13,960
hope and that hope is that there are

00:08:12,460 --> 00:08:16,030
actually ways that we can work out what

00:08:13,960 --> 00:08:18,700
all possible behaviors of our code would

00:08:16,030 --> 00:08:20,590
be so mathematically we could think of

00:08:18,700 --> 00:08:22,570
code as being a kind of finite state

00:08:20,590 --> 00:08:24,460
machine so it gets some sequence of

00:08:22,570 --> 00:08:26,380
inputs and it has some state in its

00:08:24,460 --> 00:08:28,210
variables or its memory depending on how

00:08:26,380 --> 00:08:30,280
you represent it and we can

00:08:28,210 --> 00:08:33,909
mathematically reason about equivalent

00:08:30,280 --> 00:08:35,830
sets of inputs so in principle at least

00:08:33,909 --> 00:08:38,500
it's possible to get complete test

00:08:35,830 --> 00:08:40,150
coverage to try everything or at least

00:08:38,500 --> 00:08:41,320
something which is equivalent to

00:08:40,150 --> 00:08:43,719
anything else we could have tried

00:08:41,320 --> 00:08:48,959
without actually having to test every

00:08:43,719 --> 00:08:51,070
possible logical input and the oldest

00:08:48,959 --> 00:08:53,590
trick for this

00:08:51,070 --> 00:08:56,590
is simply to put complete garbage into

00:08:53,590 --> 00:08:58,960
the program and see what happens for any

00:08:56,590 --> 00:09:00,760
image parser for any network library for

00:08:58,960 --> 00:09:02,740
most command line tools putting in

00:09:00,760 --> 00:09:04,980
random input should not cause it to

00:09:02,740 --> 00:09:07,480
crash it should either do something

00:09:04,980 --> 00:09:09,340
hopefully something useful or emit a

00:09:07,480 --> 00:09:12,540
specific kind of error code maybe throw

00:09:09,340 --> 00:09:14,920
a particular exception in Python so

00:09:12,540 --> 00:09:17,320
let's consider how this might work right

00:09:14,920 --> 00:09:19,510
if we think of a very simple kind of

00:09:17,320 --> 00:09:21,370
program right this program only does one

00:09:19,510 --> 00:09:24,040
thing it's a single function and you

00:09:21,370 --> 00:09:27,370
call it with a string of bytes and then

00:09:24,040 --> 00:09:29,770
it returns true if it worked or false if

00:09:27,370 --> 00:09:31,750
it didn't work

00:09:29,770 --> 00:09:33,310
conveniently most programs are

00:09:31,750 --> 00:09:35,590
implemented on digital computers which

00:09:33,310 --> 00:09:38,680
operate on butts so the idea of thinking

00:09:35,590 --> 00:09:40,390
of a function which takes bytes actually

00:09:38,680 --> 00:09:41,500
matches up surprisingly well with a lot

00:09:40,390 --> 00:09:44,140
of programs that were actually

00:09:41,500 --> 00:09:45,850
interested in compiled programs for

00:09:44,140 --> 00:09:50,110
example almost always operate on that

00:09:45,850 --> 00:09:52,510
and so the oldest testing technique in

00:09:50,110 --> 00:09:55,120
the book once the human testers had done

00:09:52,510 --> 00:09:57,070
their work back in the days of Fortran

00:09:55,120 --> 00:10:00,280
but before jokes about real programmers

00:09:57,070 --> 00:10:02,290
only using Fortran because Fortran was

00:10:00,280 --> 00:10:03,760
the only language that was not assembly

00:10:02,290 --> 00:10:07,330
code where you had to write in raw

00:10:03,760 --> 00:10:09,220
hexadecimal you would take a deck of

00:10:07,330 --> 00:10:11,080
punched cards perhaps from an earlier

00:10:09,220 --> 00:10:13,600
draft of the program or perhaps from

00:10:11,080 --> 00:10:15,730
today's database dump for payroll and

00:10:13,600 --> 00:10:17,320
you would shuffle it up so that was

00:10:15,730 --> 00:10:20,140
nicely out of order and you would feed

00:10:17,320 --> 00:10:22,810
it into the computer and if the

00:10:20,140 --> 00:10:25,720
electromechanical computer stopped you

00:10:22,810 --> 00:10:27,910
had found a bug and in those days above

00:10:25,720 --> 00:10:30,100
might even be a physical insect caught

00:10:27,910 --> 00:10:31,930
in the machinery if there's anything

00:10:30,100 --> 00:10:33,820
that we got out of Moore's Law of

00:10:31,930 --> 00:10:35,980
scaling things down the upside is that

00:10:33,820 --> 00:10:41,410
bugs are now too large to fit inside our

00:10:35,980 --> 00:10:43,000
CPUs but this is an old technique so the

00:10:41,410 --> 00:10:44,740
image I've chosen to represent it

00:10:43,000 --> 00:10:47,230
actually predates digital computing

00:10:44,740 --> 00:10:49,870
entirely these are punched cards for a

00:10:47,230 --> 00:10:51,880
thing called a jacquard loom a tool of

00:10:49,870 --> 00:10:54,310
the first Industrial Revolution where

00:10:51,880 --> 00:10:56,470
English textile mills first learn to

00:10:54,310 --> 00:10:58,450
automate not just the weaving of cloth

00:10:56,470 --> 00:11:02,440
but the weaving of particular patterns

00:10:58,450 --> 00:11:04,660
of cloth and so the roll there that was

00:11:02,440 --> 00:11:07,510
produced entirely by a machine

00:11:04,660 --> 00:11:09,330
would have previously taken years of

00:11:07,510 --> 00:11:12,610
skilled labor and now only a few hours

00:11:09,330 --> 00:11:14,260
and of course there was an anti tech

00:11:12,610 --> 00:11:16,800
backlash then and the coining of the

00:11:14,260 --> 00:11:16,800
word Luddite

00:11:17,220 --> 00:11:22,180
what I'm talking about randomness though

00:11:19,860 --> 00:11:23,650
there are a couple of different things

00:11:22,180 --> 00:11:25,510
and I realized when I was giving a

00:11:23,650 --> 00:11:27,220
earlier version of this talk just to

00:11:25,510 --> 00:11:30,400
test it out that I'm using the word

00:11:27,220 --> 00:11:33,490
random a lot we can put in random inputs

00:11:30,400 --> 00:11:35,790
we can deal with random programs without

00:11:33,490 --> 00:11:38,800
actually defining the word random and

00:11:35,790 --> 00:11:40,540
one of the lovely or terrible things

00:11:38,800 --> 00:11:43,120
about the word random is that it can

00:11:40,540 --> 00:11:45,370
mean so many different things so when we

00:11:43,120 --> 00:11:47,740
talk about randomness in computing we

00:11:45,370 --> 00:11:49,930
might mean numbers which are truly

00:11:47,740 --> 00:11:51,580
unpredictable they come out of some kind

00:11:49,930 --> 00:11:54,070
of physical phenomenon that we can't

00:11:51,580 --> 00:11:57,130
predict or understand well or guess what

00:11:54,070 --> 00:11:58,810
the next number will be and so one of

00:11:57,130 --> 00:12:00,550
the coolest things on the internet as a

00:11:58,810 --> 00:12:02,830
source of randomness is that CloudFlare

00:12:00,550 --> 00:12:04,690
headquarters they seed some of their

00:12:02,830 --> 00:12:06,820
random number generators with a video

00:12:04,690 --> 00:12:09,880
pointing at a wall full of lava lamps

00:12:06,820 --> 00:12:11,530
and so as there is this wall full of

00:12:09,880 --> 00:12:14,650
lava lamps that helps keep the internet

00:12:11,530 --> 00:12:16,600
secure and I just love that but if you

00:12:14,650 --> 00:12:18,130
don't have a wall full of lava lamps

00:12:16,600 --> 00:12:19,960
handy there are still ways that you can

00:12:18,130 --> 00:12:21,790
get numbers which are sufficiently

00:12:19,960 --> 00:12:23,650
random or maybe you're even doing

00:12:21,790 --> 00:12:25,450
something like a statistical experiment

00:12:23,650 --> 00:12:27,550
a simulation where you want to be able

00:12:25,450 --> 00:12:29,590
to reproduce it later and know that your

00:12:27,550 --> 00:12:31,180
results were not just a coincidence but

00:12:29,590 --> 00:12:32,470
your code was actually working and maybe

00:12:31,180 --> 00:12:33,700
you could even fix a bug in your code

00:12:32,470 --> 00:12:35,590
and run it again and get the same

00:12:33,700 --> 00:12:37,930
results you can't do that with true

00:12:35,590 --> 00:12:39,910
randomness but you can do that with what

00:12:37,930 --> 00:12:42,490
we call pseudo-random number generators

00:12:39,910 --> 00:12:45,340
and so these are very complicated

00:12:42,490 --> 00:12:47,680
programs which will jump around the

00:12:45,340 --> 00:12:49,420
numbers in a very unpredictable way but

00:12:47,680 --> 00:12:51,250
if you set the internal state to

00:12:49,420 --> 00:12:52,810
something particular you'll always get

00:12:51,250 --> 00:12:55,420
the same sequence of numbers out when

00:12:52,810 --> 00:12:57,130
you drive it so pythons random module is

00:12:55,420 --> 00:12:58,960
actually a pseudo-random number

00:12:57,130 --> 00:13:00,250
generator and if you're thinking of

00:12:58,960 --> 00:13:01,990
doing something with security you should

00:13:00,250 --> 00:13:03,610
not use it because it's not truly random

00:13:01,990 --> 00:13:06,520
you should instead use the secrets

00:13:03,610 --> 00:13:09,670
module which is suitable for secret

00:13:06,520 --> 00:13:11,170
things that's because Python doesn't

00:13:09,670 --> 00:13:13,330
have what's called a cryptographically

00:13:11,170 --> 00:13:15,310
secure pseudo-random number generator

00:13:13,330 --> 00:13:16,990
which is far too many words to describe

00:13:15,310 --> 00:13:17,950
a simple thing it's a sequence of

00:13:16,990 --> 00:13:20,050
numbers where you

00:13:17,950 --> 00:13:23,530
can't predict what number will be next

00:13:20,050 --> 00:13:25,660
ever simply by observing them I think

00:13:23,530 --> 00:13:28,270
that's probably enough now this is a set

00:13:25,660 --> 00:13:30,760
of dice they're depending on how you

00:13:28,270 --> 00:13:33,820
count random pseudo random or not really

00:13:30,760 --> 00:13:35,680
random at all and the interesting thing

00:13:33,820 --> 00:13:37,420
about dice is you might think that

00:13:35,680 --> 00:13:39,960
there's an even chance of each number

00:13:37,420 --> 00:13:43,120
coming up each time you roll dice right

00:13:39,960 --> 00:13:46,210
but if you have dice like this that are

00:13:43,120 --> 00:13:49,210
not perfect cubes or not tossed by a

00:13:46,210 --> 00:13:51,640
very random robot it is actually likely

00:13:49,210 --> 00:13:54,790
that certain sides come to rest face up

00:13:51,640 --> 00:13:57,070
more often than others so if you have a

00:13:54,790 --> 00:13:59,350
heavy die for example with divots out to

00:13:57,070 --> 00:14:01,690
indicate the numbers if you roll it

00:13:59,350 --> 00:14:04,210
completely randomly it is slightly more

00:14:01,690 --> 00:14:07,450
likely to land with the six upwards was

00:14:04,210 --> 00:14:09,070
that side is slightly lighter but we

00:14:07,450 --> 00:14:10,960
wouldn't say that the die is non-random

00:14:09,070 --> 00:14:14,170
we would say that the dye does not have

00:14:10,960 --> 00:14:16,060
a uniform distribution and so for a

00:14:14,170 --> 00:14:18,610
thing to be random it is not necessary

00:14:16,060 --> 00:14:20,500
that every possible outcome be equally

00:14:18,610 --> 00:14:22,810
likely or have any other particular

00:14:20,500 --> 00:14:25,300
output it need not be like a bell curve

00:14:22,810 --> 00:14:28,180
or an exponential curve or any other

00:14:25,300 --> 00:14:29,770
curve or step function it is sufficient

00:14:28,180 --> 00:14:31,720
that it's difficult to predict the next

00:14:29,770 --> 00:14:34,200
thing for me to colloquially call it

00:14:31,720 --> 00:14:36,810
randomness everyone following so far

00:14:34,200 --> 00:14:40,630
glad to hear it

00:14:36,810 --> 00:14:42,070
and so with that digression about

00:14:40,630 --> 00:14:45,030
randomness let's go back to thinking

00:14:42,070 --> 00:14:49,810
about programs how do we work out what

00:14:45,030 --> 00:14:52,390
programs actually do one answer in

00:14:49,810 --> 00:14:54,450
Python and in other languages is to use

00:14:52,390 --> 00:14:57,700
tools which measure code coverage and

00:14:54,450 --> 00:14:59,620
code coverage tools fundamentally answer

00:14:57,700 --> 00:15:01,480
two different questions by instrumenting

00:14:59,620 --> 00:15:03,580
your code and checking which parts

00:15:01,480 --> 00:15:06,130
executed and logging that somehow and

00:15:03,580 --> 00:15:09,490
those two questions are first what just

00:15:06,130 --> 00:15:13,240
happened and second what didn't just

00:15:09,490 --> 00:15:15,550
happen and this it turns out is

00:15:13,240 --> 00:15:18,280
surprisingly useful if we know what

00:15:15,550 --> 00:15:21,070
happened we can track what logic in our

00:15:18,280 --> 00:15:22,930
code was actually executed you could use

00:15:21,070 --> 00:15:24,700
this in production to work out which

00:15:22,930 --> 00:15:27,160
parts of our code are most important to

00:15:24,700 --> 00:15:29,770
optimize or you could do the converse

00:15:27,160 --> 00:15:31,610
and at testing time you can look at what

00:15:29,770 --> 00:15:34,490
parts of our code will not execute

00:15:31,610 --> 00:15:36,769
by our tests if our tests we did execute

00:15:34,490 --> 00:15:38,420
some part of the code it's possible that

00:15:36,769 --> 00:15:39,950
it still wasn't well tested that it was

00:15:38,420 --> 00:15:41,000
executed incidentally when we were

00:15:39,950 --> 00:15:42,950
checking some other piece of

00:15:41,000 --> 00:15:45,890
functionality but if a particular

00:15:42,950 --> 00:15:47,300
function was never executed at all we

00:15:45,890 --> 00:15:50,750
can be pretty confident that it was not

00:15:47,300 --> 00:15:53,209
tested either and so there are different

00:15:50,750 --> 00:15:55,010
levels of granularity or just live

00:15:53,209 --> 00:15:57,200
different levels of detail that we can

00:15:55,010 --> 00:15:59,750
measure coverage at the simplest is

00:15:57,200 --> 00:16:01,610
function level decorate every function

00:15:59,750 --> 00:16:05,209
every class every method every module

00:16:01,610 --> 00:16:07,670
and just see if it gets executed this is

00:16:05,209 --> 00:16:08,480
fairly useful but in Python we can do

00:16:07,670 --> 00:16:11,240
better than that

00:16:08,480 --> 00:16:13,430
coverage dot PI one of the leading

00:16:11,240 --> 00:16:15,500
Python modules can actually hook him to

00:16:13,430 --> 00:16:19,010
the interpreter and report for each line

00:16:15,500 --> 00:16:20,390
of code was it executed or not these

00:16:19,010 --> 00:16:22,279
days you can even hook him to some more

00:16:20,390 --> 00:16:24,529
detail and go for each test function

00:16:22,279 --> 00:16:26,810
which lines of code were executed and

00:16:24,529 --> 00:16:30,050
this lets us go through and determine

00:16:26,810 --> 00:16:31,940
for example that the elf's block on some

00:16:30,050 --> 00:16:34,640
if statement was never executed because

00:16:31,940 --> 00:16:36,380
the condition was always true useful to

00:16:34,640 --> 00:16:38,199
know if you're looking to delete code or

00:16:36,380 --> 00:16:41,600
work out where you need additional tests

00:16:38,199 --> 00:16:44,300
or we can even go to branch coverage and

00:16:41,600 --> 00:16:46,160
branch coverage separately tracks each

00:16:44,300 --> 00:16:48,980
side of an if statement so if we had a

00:16:46,160 --> 00:16:51,140
if without an else and we always have

00:16:48,980 --> 00:16:53,089
that statement as true branch coverage

00:16:51,140 --> 00:16:54,680
can tell us that we don't actually need

00:16:53,089 --> 00:16:56,660
that if statement it's always been true

00:16:54,680 --> 00:17:00,399
you either need another test where it's

00:16:56,660 --> 00:17:03,079
false or you can delete the conditional

00:17:00,399 --> 00:17:05,059
coverage metrics are often in testing

00:17:03,079 --> 00:17:07,069
compared to a kind of maximum possible

00:17:05,059 --> 00:17:09,770
coverage which we get from analyzing the

00:17:07,069 --> 00:17:11,299
source code so we can go not just here

00:17:09,770 --> 00:17:13,819
is what was executed but here's what

00:17:11,299 --> 00:17:15,890
could have been executed and then could

00:17:13,819 --> 00:17:19,600
I just see a show of hands who here has

00:17:15,890 --> 00:17:22,490
ever used a percentage coverage metric

00:17:19,600 --> 00:17:26,410
awesome whoo he really loves percentage

00:17:22,490 --> 00:17:28,910
coverage few heads I'm not a huge fan

00:17:26,410 --> 00:17:31,309
it's a good indicator of the rough state

00:17:28,910 --> 00:17:33,110
of your code base but if you're using a

00:17:31,309 --> 00:17:35,660
threshold for coverage something where

00:17:33,110 --> 00:17:38,360
you say for example we need at least 70%

00:17:35,660 --> 00:17:40,000
coverage or at least 90% coverage for

00:17:38,360 --> 00:17:42,440
this pull request to be accepted

00:17:40,000 --> 00:17:44,630
unrelated refactorings can actually make

00:17:42,440 --> 00:17:45,380
that number go down if you delete

00:17:44,630 --> 00:17:47,270
trivial

00:17:45,380 --> 00:17:48,800
covered lines of code code which is not

00:17:47,270 --> 00:17:51,020
doing anything useful but is still

00:17:48,800 --> 00:17:55,100
executed by tests then you can make your

00:17:51,020 --> 00:17:56,870
coverage proportion worse and I'd know

00:17:55,100 --> 00:17:58,190
maybe this is old-fashioned but if I'm

00:17:56,870 --> 00:18:00,080
tracking some number that I think

00:17:58,190 --> 00:18:01,760
represents my code quality I don't want

00:18:00,080 --> 00:18:04,730
it to go down where my code quality goes

00:18:01,760 --> 00:18:06,950
up so if you can try to get coverage to

00:18:04,730 --> 00:18:08,810
spit out an exact number of uncovered

00:18:06,950 --> 00:18:11,600
lines and mandate that that never passes

00:18:08,810 --> 00:18:14,450
a particular threshold or you can simply

00:18:11,600 --> 00:18:16,070
annotate your code with no cover bits on

00:18:14,450 --> 00:18:18,560
the parts which you don't mind being

00:18:16,070 --> 00:18:20,690
uncovered and then require 100% coverage

00:18:18,560 --> 00:18:22,310
that's actually my preferred technique

00:18:20,690 --> 00:18:24,470
because it may forces you to make an

00:18:22,310 --> 00:18:26,720
explicit decision and one which you can

00:18:24,470 --> 00:18:28,490
grab for in your code base to find which

00:18:26,720 --> 00:18:34,610
parts of this code did we decide we're

00:18:28,490 --> 00:18:36,740
not important enough to test when you

00:18:34,610 --> 00:18:39,620
put these ideas together tracking of

00:18:36,740 --> 00:18:41,900
coverage and then random inputs you get

00:18:39,620 --> 00:18:45,200
a technique called fuzzing has anyone

00:18:41,900 --> 00:18:49,160
heard of fuzzing couple the rest of you

00:18:45,200 --> 00:18:52,310
are in for a treat fuzzing is the idea

00:18:49,160 --> 00:18:54,740
that uniformly random inputs the comb we

00:18:52,310 --> 00:18:57,260
will get from shuffled punched cards or

00:18:54,740 --> 00:18:59,750
from piping dev random into our binaries

00:18:57,260 --> 00:19:03,620
is unlikely to find any but the most

00:18:59,750 --> 00:19:06,320
trivial bugs almost all possible inputs

00:19:03,620 --> 00:19:08,750
will simply trip across some validation

00:19:06,320 --> 00:19:10,940
logic in an image parser it might be the

00:19:08,750 --> 00:19:14,210
bit that checks does this file start

00:19:10,940 --> 00:19:17,830
with percent PNG if not it is not a PNG

00:19:14,210 --> 00:19:21,890
file and your chance of random bytes

00:19:17,830 --> 00:19:24,410
matching that string is 1 in 256 to the

00:19:21,890 --> 00:19:28,400
power of 4 which is a fairly small

00:19:24,410 --> 00:19:31,460
number and so what we can do instead

00:19:28,400 --> 00:19:34,970
instead of putting in uniformly random

00:19:31,460 --> 00:19:37,370
bits we can use a genetic algorithm we

00:19:34,970 --> 00:19:39,980
can actually instrument our programs to

00:19:37,370 --> 00:19:42,440
watch the coverage tell what behavior is

00:19:39,980 --> 00:19:45,110
being executed and then start by putting

00:19:42,440 --> 00:19:46,250
in random things and then we find an

00:19:45,110 --> 00:19:48,860
input that does something a little

00:19:46,250 --> 00:19:50,990
different to the normal we can take that

00:19:48,860 --> 00:19:53,090
input and mutate it a bit change it

00:19:50,990 --> 00:19:54,920
around put it back in see what happens

00:19:53,090 --> 00:19:56,840
combine it with another one and pretty

00:19:54,920 --> 00:19:58,970
soon we're likely to find that an import

00:19:56,840 --> 00:20:00,919
which starts with a %

00:19:58,970 --> 00:20:02,120
percent PNG does something a little

00:20:00,919 --> 00:20:04,070
different it goes down a different

00:20:02,120 --> 00:20:06,230
branch and then when we add and it does

00:20:04,070 --> 00:20:08,600
something different again and before you

00:20:06,230 --> 00:20:11,330
know it you've developed this testing

00:20:08,600 --> 00:20:13,970
tool which will synthesize valid images

00:20:11,330 --> 00:20:16,010
for you out of thin air just by watching

00:20:13,970 --> 00:20:19,789
the behavior of the program that's meant

00:20:16,010 --> 00:20:23,809
to deal with them so based on that

00:20:19,789 --> 00:20:25,669
feedback coverage as a proxy for how

00:20:23,809 --> 00:20:28,070
much code is is executing and what code

00:20:25,669 --> 00:20:29,750
is this executing we can drive up the

00:20:28,070 --> 00:20:32,510
chance that we execute some part of the

00:20:29,750 --> 00:20:34,130
code which well that's the problem the

00:20:32,510 --> 00:20:38,659
only thing we can detect with the fuzzer

00:20:34,130 --> 00:20:41,870
is a crash and so the second part of

00:20:38,659 --> 00:20:44,510
this trick is a collection of ways to

00:20:41,870 --> 00:20:47,620
make bugs in our programs correspond to

00:20:44,510 --> 00:20:49,630
crashes instead of silent misbehavior in

00:20:47,620 --> 00:20:52,730
compiled languages there are many

00:20:49,630 --> 00:20:55,100
sanitizers which will do this or

00:20:52,730 --> 00:20:57,470
addresses for memory violations for

00:20:55,100 --> 00:20:59,630
undefined behavior but the one that's

00:20:57,470 --> 00:21:03,559
common across all languages including

00:20:59,630 --> 00:21:05,450
python is assertions so an assertion my

00:21:03,559 --> 00:21:08,270
favorite definition is an assertion is a

00:21:05,450 --> 00:21:12,799
statement in a program which will do

00:21:08,270 --> 00:21:14,090
nothing unless there is a bug so an

00:21:12,799 --> 00:21:16,130
assertion is something which should

00:21:14,090 --> 00:21:17,809
always be true it might or might not be

00:21:16,130 --> 00:21:20,600
executed depending on how you run Python

00:21:17,809 --> 00:21:23,030
but if it's false then it'll throw an

00:21:20,600 --> 00:21:26,299
assertion error and that exception will

00:21:23,030 --> 00:21:30,770
propagate and you'll get a crash or your

00:21:26,299 --> 00:21:33,950
test will fail this means that when we

00:21:30,770 --> 00:21:36,049
evolve bad inputs we can check not just

00:21:33,950 --> 00:21:38,690
do we have some kind of error which

00:21:36,049 --> 00:21:40,820
forces us to crash but do we trigger any

00:21:38,690 --> 00:21:42,169
assertion that we had and so if you

00:21:40,820 --> 00:21:43,610
start and end your functions with

00:21:42,169 --> 00:21:45,470
assertions that the input is roughly

00:21:43,610 --> 00:21:47,419
what you expect that the output is

00:21:45,470 --> 00:21:50,179
saying that things round-trip or in

00:21:47,419 --> 00:21:53,419
canonical formats you can often uncover

00:21:50,179 --> 00:21:55,610
your own misunderstandings or your

00:21:53,419 --> 00:21:58,130
future selfs misunderstanding of past

00:21:55,610 --> 00:22:04,020
code simply by running the same tests

00:21:58,130 --> 00:22:07,640
against it so that's part one

00:22:04,020 --> 00:22:09,809
we can go from complete randomness to

00:22:07,640 --> 00:22:11,700
generating things which are very likely

00:22:09,809 --> 00:22:15,059
to find bugs which would seem impossible

00:22:11,700 --> 00:22:16,920
by mere chance so it's time to get back

00:22:15,059 --> 00:22:19,290
into Python a little more and I'm going

00:22:16,920 --> 00:22:22,260
to talk about the implementation of a

00:22:19,290 --> 00:22:23,550
tool for property based testing I'm

00:22:22,260 --> 00:22:25,830
going to start by telling you what

00:22:23,550 --> 00:22:28,170
property based testing is not property

00:22:25,830 --> 00:22:30,780
based testing is not just trying a very

00:22:28,170 --> 00:22:32,760
large number of tests this is a super

00:22:30,780 --> 00:22:36,240
useful technique on github you can find

00:22:32,760 --> 00:22:38,910
the big list of naughty strings which is

00:22:36,240 --> 00:22:42,540
a text file several thousand lines long

00:22:38,910 --> 00:22:44,610
and every line is some bit of text which

00:22:42,540 --> 00:22:46,980
has caused a bug in some other piece of

00:22:44,610 --> 00:22:50,820
software some of them a sequel injection

00:22:46,980 --> 00:22:55,110
attacks others are cross-site scripting

00:22:50,820 --> 00:22:57,300
problems some are just emoji and I

00:22:55,110 --> 00:22:59,580
really wanted to put one in here which

00:22:57,300 --> 00:23:01,740
is Hebrew text which changes the

00:22:59,580 --> 00:23:03,059
direction first is left to right then

00:23:01,740 --> 00:23:04,679
it's right to left then it's left to

00:23:03,059 --> 00:23:10,590
right again but when I put it into my

00:23:04,679 --> 00:23:12,240
slides PowerPoint crashed so I don't

00:23:10,590 --> 00:23:13,620
mean to diminish the value of this kind

00:23:12,240 --> 00:23:15,570
of testing right if you're dealing with

00:23:13,620 --> 00:23:17,820
things which should accept arbitrary

00:23:15,570 --> 00:23:20,070
strings as input grab the big list of

00:23:17,820 --> 00:23:21,480
naughty strings try them all it's really

00:23:20,070 --> 00:23:24,510
easy with something like a PI test

00:23:21,480 --> 00:23:25,950
parameterize but there are a couple of

00:23:24,510 --> 00:23:27,480
problems which would make us not want to

00:23:25,950 --> 00:23:29,580
do this for literally everything right

00:23:27,480 --> 00:23:31,950
first of all someone has to come up with

00:23:29,580 --> 00:23:33,270
the big list and they accept pull

00:23:31,950 --> 00:23:36,750
requests so you can help out with that

00:23:33,270 --> 00:23:38,700
but the corporate the corpus has to come

00:23:36,750 --> 00:23:40,500
from somewhere this is great for things

00:23:38,700 --> 00:23:42,929
which have multiple implementations or

00:23:40,500 --> 00:23:45,390
implemented in multiple languages but

00:23:42,929 --> 00:23:48,140
when we find an error the one that we

00:23:45,390 --> 00:23:51,059
find will tend to be relatively complex

00:23:48,140 --> 00:23:53,970
if you've found something through this

00:23:51,059 --> 00:23:57,150
random process of fuzzing the thing that

00:23:53,970 --> 00:24:00,870
triggered above tends to be really nasty

00:23:57,150 --> 00:24:03,690
to debug and as we all know from stack

00:24:00,870 --> 00:24:06,390
overflow we should be posting minimal

00:24:03,690 --> 00:24:08,190
complete reproducing examples right this

00:24:06,390 --> 00:24:09,420
will just give you a reproducing example

00:24:08,190 --> 00:24:11,680
better than nothing

00:24:09,420 --> 00:24:14,740
but not ideal

00:24:11,680 --> 00:24:17,650
so property based testing is the idea

00:24:14,740 --> 00:24:19,000
that when you combine random inputs and

00:24:17,650 --> 00:24:20,830
in property based testing they're

00:24:19,000 --> 00:24:22,720
usually specified by the programmer in

00:24:20,830 --> 00:24:25,000
some way so instead of saying give me

00:24:22,720 --> 00:24:27,760
literally anything you would say for

00:24:25,000 --> 00:24:29,380
example give me two integers between 0

00:24:27,760 --> 00:24:32,260
and 100 and it would try many

00:24:29,380 --> 00:24:34,810
combinations of those and then instead

00:24:32,260 --> 00:24:37,300
of asserting that your code output a

00:24:34,810 --> 00:24:38,710
particular exact result which you don't

00:24:37,300 --> 00:24:41,680
know because you don't know what the

00:24:38,710 --> 00:24:43,870
exact input was you can make some

00:24:41,680 --> 00:24:46,300
assertion about a general property for

00:24:43,870 --> 00:24:48,220
example no matter what data I get from

00:24:46,300 --> 00:24:50,170
the user through this form I should be

00:24:48,220 --> 00:24:51,610
able to save it to the database and then

00:24:50,170 --> 00:24:53,350
bring it back and I should have the same

00:24:51,610 --> 00:24:55,680
data no matter how many times they save

00:24:53,350 --> 00:24:58,060
it to the database and bring it back or

00:24:55,680 --> 00:25:00,250
you might have something where if I

00:24:58,060 --> 00:25:03,880
convert it from JSON to XML then back to

00:25:00,250 --> 00:25:05,320
JSON I get the same data or this becomes

00:25:03,880 --> 00:25:07,120
really powerful if you have other

00:25:05,320 --> 00:25:09,460
properties for example where

00:25:07,120 --> 00:25:11,440
reimplemented it we can feed the same

00:25:09,460 --> 00:25:13,720
input into the old system and into the

00:25:11,440 --> 00:25:15,490
new system and assert that the new

00:25:13,720 --> 00:25:17,620
hotness gets the same result as the

00:25:15,490 --> 00:25:19,210
legacy version or the the

00:25:17,620 --> 00:25:20,860
single-threaded version has the same

00:25:19,210 --> 00:25:23,260
behavior as the multi-threaded version

00:25:20,860 --> 00:25:27,520
has anyone here ever been bitten by a

00:25:23,260 --> 00:25:30,580
multi-threading bug yeah it is a useful

00:25:27,520 --> 00:25:32,200
test and there are other properties as

00:25:30,580 --> 00:25:34,180
well so for something like a scientific

00:25:32,200 --> 00:25:35,500
simulation where the whole point of

00:25:34,180 --> 00:25:37,510
running it is we don't know what the

00:25:35,500 --> 00:25:40,120
output should be we might still have

00:25:37,510 --> 00:25:41,560
some other clues in thermodynamics we

00:25:40,120 --> 00:25:43,420
would know that if we start with a

00:25:41,560 --> 00:25:44,770
higher initial temperature the final

00:25:43,420 --> 00:25:47,230
temperature should probably also be

00:25:44,770 --> 00:25:49,540
higher and vice-versa if we're building

00:25:47,230 --> 00:25:51,610
a self-driving car we might say we don't

00:25:49,540 --> 00:25:53,320
know exactly what it should do but if we

00:25:51,610 --> 00:25:55,300
simulate adding a rain drop to the

00:25:53,320 --> 00:25:57,520
camera lens the car should not crash

00:25:55,300 --> 00:25:58,720
well the car should not confidently

00:25:57,520 --> 00:26:01,990
decide that it should turn across

00:25:58,720 --> 00:26:05,560
oncoming traffic I draw that example

00:26:01,990 --> 00:26:08,430
from a recent paper which I don't want

00:26:05,560 --> 00:26:08,430
their self-driving cars

00:26:08,550 --> 00:26:14,290
and at this point I owe you a really

00:26:11,650 --> 00:26:16,000
quick overview of hypothesis itself it's

00:26:14,290 --> 00:26:18,670
a library in Python for property based

00:26:16,000 --> 00:26:20,350
testing I'm a core developer so I might

00:26:18,670 --> 00:26:22,810
say it is the library and Python for

00:26:20,350 --> 00:26:25,750
property based testing mostly because I

00:26:22,810 --> 00:26:27,550
don't know of any competition all of the

00:26:25,750 --> 00:26:28,750
core developers are volunteers and in

00:26:27,550 --> 00:26:30,850
fact there are no non volunteer

00:26:28,750 --> 00:26:33,100
developers we have great documentation

00:26:30,850 --> 00:26:35,110
and focus a lot in usability so whatever

00:26:33,100 --> 00:26:36,580
your concrete problem is that you need

00:26:35,110 --> 00:26:39,130
to solve with hypothesis we have

00:26:36,580 --> 00:26:41,470
probably solved it and documented it but

00:26:39,130 --> 00:26:43,090
this is not a talked about hypothesis so

00:26:41,470 --> 00:26:45,490
much as a talk about the general family

00:26:43,090 --> 00:26:47,140
of testing techniques so if you want to

00:26:45,490 --> 00:26:49,390
learn about that one I've given other

00:26:47,140 --> 00:26:50,830
talks you can find on the internet but

00:26:49,390 --> 00:26:53,920
here I'm going to talk about the

00:26:50,830 --> 00:26:56,740
implementation how Hypothesis minimizes

00:26:53,920 --> 00:26:58,750
examples then how hypothesis runs its

00:26:56,740 --> 00:27:00,850
tests and finally how hypothesis

00:26:58,750 --> 00:27:02,560
generates inputs this is completely

00:27:00,850 --> 00:27:07,900
backwards but I promise it makes more

00:27:02,560 --> 00:27:09,820
sense backwards so our first challenge

00:27:07,900 --> 00:27:11,260
right I mentioned this that Stack

00:27:09,820 --> 00:27:14,770
Overflow will ask you for a minimal

00:27:11,260 --> 00:27:17,500
example is that if you use hypothesis

00:27:14,770 --> 00:27:19,480
and find a bug I don't have enough time

00:27:17,500 --> 00:27:21,460
to come around to your office and hand

00:27:19,480 --> 00:27:24,330
minimize it for you so we need to

00:27:21,460 --> 00:27:27,340
automate that process somehow

00:27:24,330 --> 00:27:29,740
fortunately because we're dealing under

00:27:27,340 --> 00:27:32,200
the hood with strings of bytes we can

00:27:29,740 --> 00:27:34,150
automatically try to minimize it well

00:27:32,200 --> 00:27:36,310
it's not always clear what might make a

00:27:34,150 --> 00:27:38,230
more minimal example if we're talking

00:27:36,310 --> 00:27:40,330
about nested dictionaries for example if

00:27:38,230 --> 00:27:42,250
we can find ourselves two strings of

00:27:40,330 --> 00:27:44,230
bytes there are a couple of pretty clear

00:27:42,250 --> 00:27:46,150
heuristics we could use the first is

00:27:44,230 --> 00:27:50,110
that shorter strings are simpler strings

00:27:46,150 --> 00:27:51,520
write less input is simpler and the

00:27:50,110 --> 00:27:54,400
second is that among strings of the same

00:27:51,520 --> 00:27:55,810
length we can break ties by imagining

00:27:54,400 --> 00:27:57,430
them as integers and going with

00:27:55,810 --> 00:28:00,280
whichever one has the lower integer

00:27:57,430 --> 00:28:04,540
value so we tend to prefer zeroes to

00:28:00,280 --> 00:28:07,270
ones for example and so if we imagine

00:28:04,540 --> 00:28:10,600
for a moment that we can operate on bad

00:28:07,270 --> 00:28:13,480
strings we have a couple of convenient

00:28:10,600 --> 00:28:15,310
things the first is that every input is

00:28:13,480 --> 00:28:18,430
unique if we're dealing only in byte

00:28:15,310 --> 00:28:20,539
strings every input can be ranked in

00:28:18,430 --> 00:28:22,909
comparison to another candidate input

00:28:20,539 --> 00:28:25,129
and this means that it would be valid to

00:28:22,909 --> 00:28:28,369
simply go this is the bite string that

00:28:25,129 --> 00:28:30,589
found a bug let's try just chopping it

00:28:28,369 --> 00:28:32,299
in half does the first half only find

00:28:30,589 --> 00:28:34,820
the same bug what about the second half

00:28:32,299 --> 00:28:38,209
and we can do a sequence of these

00:28:34,820 --> 00:28:40,579
operations analogous ly here the dotted

00:28:38,209 --> 00:28:42,409
lines between dots dogs are executions

00:28:40,579 --> 00:28:44,839
of the test the dashed lines indicate

00:28:42,409 --> 00:28:47,359
what we try to retake that input and

00:28:44,839 --> 00:28:49,699
make it smaller given any possible

00:28:47,359 --> 00:28:51,829
change to that input we can tell whether

00:28:49,699 --> 00:28:54,649
if the test still fails in the same way

00:28:51,829 --> 00:28:55,999
it would in fact be simpler if it's not

00:28:54,649 --> 00:28:59,029
simple and we don't even have to run the

00:28:55,999 --> 00:29:01,249
test we can just discard it and by

00:28:59,029 --> 00:29:03,649
running them we can slowly evolve our

00:29:01,249 --> 00:29:06,079
way down not necessarily to the simplest

00:29:03,649 --> 00:29:07,879
possible boat or the simplest possible

00:29:06,079 --> 00:29:12,019
input that triggers that bug but to a

00:29:07,879 --> 00:29:14,029
very much simpler one now there's a

00:29:12,019 --> 00:29:16,399
couple of benefits of this if we look at

00:29:14,029 --> 00:29:19,519
the diagram on the right of this binary

00:29:16,399 --> 00:29:22,159
tree all of these will say trigger the

00:29:19,519 --> 00:29:25,039
same bug and going around clockwise

00:29:22,159 --> 00:29:27,799
we've simplified it and by the time you

00:29:25,039 --> 00:29:29,629
see the one on the bottom left if you

00:29:27,799 --> 00:29:33,679
look at that and you think I have some

00:29:29,629 --> 00:29:35,539
bug in a binary tree function the bug

00:29:33,679 --> 00:29:37,909
might be related to the fact that the

00:29:35,539 --> 00:29:39,440
binary tree is unbalanced and in

00:29:37,909 --> 00:29:41,629
particular when you look at that you can

00:29:39,440 --> 00:29:43,069
go if it was possible to simplify it

00:29:41,629 --> 00:29:45,349
further it would have been simplified

00:29:43,069 --> 00:29:48,349
further so it must be something about

00:29:45,349 --> 00:29:50,809
the unbalanced nature of the tree so

00:29:48,349 --> 00:29:52,849
while this is not strictly required for

00:29:50,809 --> 00:29:55,940
property based testing to be useful in

00:29:52,849 --> 00:29:58,519
practice test case reduction is a really

00:29:55,940 --> 00:30:02,809
really important feature to make people

00:29:58,519 --> 00:30:06,229
enjoy using the tool let's go through to

00:30:02,809 --> 00:30:08,239
the middle part here we think about how

00:30:06,229 --> 00:30:11,359
do we treat unit tests as if there were

00:30:08,239 --> 00:30:13,399
foes targets I've said before right that

00:30:11,359 --> 00:30:15,409
we could think of any program

00:30:13,399 --> 00:30:17,440
potentially as taking some string of

00:30:15,409 --> 00:30:20,440
bytes as input and doing something and

00:30:17,440 --> 00:30:22,699
so that's effectively what we do

00:30:20,440 --> 00:30:26,179
hypothesis gives you a decorator which

00:30:22,699 --> 00:30:28,039
internally wraps the test and we'll try

00:30:26,179 --> 00:30:29,989
first of all rerunning every previous

00:30:28,039 --> 00:30:31,909
byte string that we've seen caused some

00:30:29,989 --> 00:30:33,860
particular bug so you don't have the

00:30:31,909 --> 00:30:35,120
usual problem of random tests that if

00:30:33,860 --> 00:30:36,980
you execute the test and they're

00:30:35,120 --> 00:30:40,010
executed again the bug may or may not

00:30:36,980 --> 00:30:41,570
happen the second time that sucks when

00:30:40,010 --> 00:30:43,370
you're debugging right when you're never

00:30:41,570 --> 00:30:45,200
quite sure if you've fixed it or if it's

00:30:43,370 --> 00:30:49,490
just decided to go away until tomorrow

00:30:45,200 --> 00:30:51,650
or next week or 3:00 a.m. so first we

00:30:49,490 --> 00:30:53,600
replay all of the existing bugs and then

00:30:51,650 --> 00:30:55,040
we generate a bunch more random bits so

00:30:53,600 --> 00:30:56,720
we do the kind of mutation or fuzzing

00:30:55,040 --> 00:30:58,480
and for each of them we just call the

00:30:56,720 --> 00:31:00,950
first target and if there's an exception

00:30:58,480 --> 00:31:03,320
then we grab whatever input caused it

00:31:00,950 --> 00:31:09,559
and we do the reduction step making

00:31:03,320 --> 00:31:12,140
sense and so the only wrinkle here right

00:31:09,559 --> 00:31:14,570
is how do we go from strings of bytes to

00:31:12,140 --> 00:31:17,570
the objects and the values that we

00:31:14,570 --> 00:31:19,640
actually use in Python and there's a

00:31:17,570 --> 00:31:21,770
couple of neat tricks the first is of

00:31:19,640 --> 00:31:23,650
course that in a computer everything is

00:31:21,770 --> 00:31:26,120
secretly bytes under the hood right

00:31:23,650 --> 00:31:28,460
numbers are bytes strings are bytes

00:31:26,120 --> 00:31:28,700
lists different bytes dictionaries are

00:31:28,460 --> 00:31:32,150
bytes

00:31:28,700 --> 00:31:34,309
everything is buts and so all we need to

00:31:32,150 --> 00:31:36,590
do is convert our bytes into some more

00:31:34,309 --> 00:31:38,210
meaningful value this is a known

00:31:36,590 --> 00:31:41,360
category of software and they're called

00:31:38,210 --> 00:31:43,429
passes and so a passer is a thing which

00:31:41,360 --> 00:31:45,110
takes some sequence of bytes or texts

00:31:43,429 --> 00:31:48,590
and converts it into other values for us

00:31:45,110 --> 00:31:50,000
and my favorite API for this which we

00:31:48,590 --> 00:31:52,850
use the hypothesis is something called a

00:31:50,000 --> 00:31:54,530
parser Combinator so a parser Combinator

00:31:52,850 --> 00:31:56,570
is a function which takes a couple of

00:31:54,530 --> 00:31:59,270
different passes potentially and sticks

00:31:56,570 --> 00:32:01,250
them together somehow most simply you

00:31:59,270 --> 00:32:03,740
could for example have a parser which is

00:32:01,250 --> 00:32:05,630
the list parser and so it recognizes an

00:32:03,740 --> 00:32:08,179
open square bracket and it knows to look

00:32:05,630 --> 00:32:10,010
for some value and then a comma and then

00:32:08,179 --> 00:32:12,440
another value or a closing square

00:32:10,010 --> 00:32:14,809
bracket so that's all the list passer

00:32:12,440 --> 00:32:16,940
needs to do so to get a parser for some

00:32:14,809 --> 00:32:20,210
particular list you need to tell it how

00:32:16,940 --> 00:32:22,309
to recognize individual elements and so

00:32:20,210 --> 00:32:25,460
in hypothesis we also have an integers

00:32:22,309 --> 00:32:27,799
strategy or a parser and so to get a

00:32:25,460 --> 00:32:29,960
list of integers you take the lists

00:32:27,799 --> 00:32:31,669
function and you pass it integers and

00:32:29,960 --> 00:32:36,740
optionally you can tell it how long you

00:32:31,669 --> 00:32:39,290
want it to be and so we implement

00:32:36,740 --> 00:32:41,990
strategies under the hood in the private

00:32:39,290 --> 00:32:44,840
API as classes which just have a get

00:32:41,990 --> 00:32:46,669
bits function so all they do is look at

00:32:44,840 --> 00:32:47,420
the next part of the input and then

00:32:46,669 --> 00:32:49,010
convert that

00:32:47,420 --> 00:32:52,220
if they can into whatever their output

00:32:49,010 --> 00:32:53,630
type is most of the strategies that we

00:32:52,220 --> 00:32:55,520
provide though don't even have to do

00:32:53,630 --> 00:32:57,530
that we can implement them in terms of

00:32:55,520 --> 00:32:59,660
other strategies and that's the public

00:32:57,530 --> 00:33:02,720
API to you define your own strategies

00:32:59,660 --> 00:33:04,490
for whatever type or class or collection

00:33:02,720 --> 00:33:09,920
or specific kind of data you need to

00:33:04,490 --> 00:33:11,930
call so below that there are a couple of

00:33:09,920 --> 00:33:13,340
other tricks we use and I'm skipping

00:33:11,930 --> 00:33:15,770
over so much of the cool stuff

00:33:13,340 --> 00:33:18,800
about how you can generate django models

00:33:15,770 --> 00:33:20,330
or pandas data frames or things accepted

00:33:18,800 --> 00:33:23,360
by a regular expression like you can

00:33:20,330 --> 00:33:24,710
take a regular expression and hypothesis

00:33:23,360 --> 00:33:26,330
will give you strings that match the

00:33:24,710 --> 00:33:28,160
regular expression it's super cool and

00:33:26,330 --> 00:33:31,970
that bit wasn't in my notes it's just so

00:33:28,160 --> 00:33:33,530
exciting under the hood there are a

00:33:31,970 --> 00:33:35,920
couple of implementation tricks that are

00:33:33,530 --> 00:33:39,140
quite important the first is that

00:33:35,920 --> 00:33:41,270
whenever you define a strategy if you're

00:33:39,140 --> 00:33:43,850
in the internal API or the public API we

00:33:41,270 --> 00:33:45,830
make sure this mostly doesn't matter but

00:33:43,850 --> 00:33:47,600
internally we try to implement all of

00:33:45,830 --> 00:33:49,610
our strategies in a way that shrinks

00:33:47,600 --> 00:33:51,320
well that allows the reducer to make

00:33:49,610 --> 00:33:53,570
progress using the operations that it

00:33:51,320 --> 00:33:54,890
knows about so one example of this is

00:33:53,570 --> 00:33:57,770
when we're generating a list of

00:33:54,890 --> 00:33:59,810
something the natural way to do this

00:33:57,770 --> 00:34:02,240
might be first get a number to decide

00:33:59,810 --> 00:34:03,770
how long the list will be and then get

00:34:02,240 --> 00:34:06,800
that many elements and put them in a

00:34:03,770 --> 00:34:09,470
list the problem is when it comes to

00:34:06,800 --> 00:34:11,080
reduce it to successfully reduce that

00:34:09,470 --> 00:34:14,360
one you would have to simultaneously

00:34:11,080 --> 00:34:16,940
reduce them integer by one and delete a

00:34:14,360 --> 00:34:18,380
list element and in general this is

00:34:16,940 --> 00:34:21,050
going to be less efficient than what we

00:34:18,380 --> 00:34:23,419
actually do which is we calculate given

00:34:21,050 --> 00:34:25,610
our expected list length with what

00:34:23,419 --> 00:34:29,150
probability should we add one additional

00:34:25,610 --> 00:34:30,770
element then we draw a number and if it

00:34:29,150 --> 00:34:32,570
or draw a boolean with that probability

00:34:30,770 --> 00:34:34,550
and if it's true then we get that

00:34:32,570 --> 00:34:36,710
element if it's false we're done and the

00:34:34,550 --> 00:34:39,530
list is over and that means that instead

00:34:36,710 --> 00:34:41,870
of having to delete or change two parts

00:34:39,530 --> 00:34:44,179
of the byte string in combination at the

00:34:41,870 --> 00:34:47,890
same time we can simply delete a region

00:34:44,179 --> 00:34:50,600
and it will locally have that effect

00:34:47,890 --> 00:34:52,250
defining test case reduction in terms of

00:34:50,600 --> 00:34:54,440
strategies rather than having to define

00:34:52,250 --> 00:34:56,210
something specific to for example each

00:34:54,440 --> 00:34:58,940
type of number gives us a couple of

00:34:56,210 --> 00:35:01,370
other examples if you imagine your test

00:34:58,940 --> 00:35:03,200
only takes even numbers for example

00:35:01,370 --> 00:35:04,700
with hypothesis approach you can simply

00:35:03,200 --> 00:35:07,580
take the number and then multiply it by

00:35:04,700 --> 00:35:09,680
two and that strategy will then only

00:35:07,580 --> 00:35:11,690
give you even numbers but when it

00:35:09,680 --> 00:35:13,460
shrinks every number it tries to produce

00:35:11,690 --> 00:35:15,170
will still be even if you're using

00:35:13,460 --> 00:35:17,000
something like quick check in Haskell

00:35:15,170 --> 00:35:19,130
you actually have to put another filter

00:35:17,000 --> 00:35:20,840
in place in your test to make sure that

00:35:19,130 --> 00:35:22,370
when you generated even numbers it

00:35:20,840 --> 00:35:24,740
didn't try to shrink by feeding you odd

00:35:22,370 --> 00:35:26,060
numbers that tends to get you unrelated

00:35:24,740 --> 00:35:29,270
errors which is not fun when you're

00:35:26,060 --> 00:35:32,300
debugging if you're wondering about the

00:35:29,270 --> 00:35:34,310
performance of this come talk to me in

00:35:32,300 --> 00:35:35,900
the hallway track but in short premature

00:35:34,310 --> 00:35:37,820
optimization is the root of all

00:35:35,900 --> 00:35:38,960
frustration in testing that's a lie

00:35:37,820 --> 00:35:41,060
there are lots of other frustrating

00:35:38,960 --> 00:35:45,200
things but it will be frustrating it's

00:35:41,060 --> 00:35:46,670
fast it's certainly fast enough and so

00:35:45,200 --> 00:35:49,640
now we get to my favorite section of the

00:35:46,670 --> 00:35:51,170
talk the cutting edge techniques that to

00:35:49,640 --> 00:35:55,820
my knowledge are not available in Python

00:35:51,170 --> 00:35:57,560
nor widely used at all sadly at least if

00:35:55,820 --> 00:35:59,990
you're an enormous nerd about testing

00:35:57,560 --> 00:36:02,600
there's this vicious cycle between

00:35:59,990 --> 00:36:06,020
having very few users the tool in not

00:36:02,600 --> 00:36:08,270
being awesome very few users very few

00:36:06,020 --> 00:36:12,160
developers the tooling is not awesome no

00:36:08,270 --> 00:36:14,750
one uses it we can change this together

00:36:12,160 --> 00:36:17,300
so if you're interested in these

00:36:14,750 --> 00:36:19,730
techniques consider that people have not

00:36:17,300 --> 00:36:21,290
tried investing significant effort in

00:36:19,730 --> 00:36:23,630
implementing them and found it's too

00:36:21,290 --> 00:36:24,950
hard in most cases a paper has been

00:36:23,630 --> 00:36:28,550
published and then they've not been

00:36:24,950 --> 00:36:30,710
tried at all so if you want to invest a

00:36:28,550 --> 00:36:32,530
week in trying to implement them you

00:36:30,710 --> 00:36:34,940
could get somewhere really cool and

00:36:32,530 --> 00:36:36,260
finally for each of them if people are

00:36:34,940 --> 00:36:38,330
still awake I hope you're still awake

00:36:36,260 --> 00:36:39,890
we're gonna have some audience votes at

00:36:38,330 --> 00:36:42,740
the end of each slide I'm going to ask

00:36:39,890 --> 00:36:43,330
you is this technique fantastic and we

00:36:42,740 --> 00:36:45,560
should use it

00:36:43,330 --> 00:36:48,440
flaky and it might work but only

00:36:45,560 --> 00:36:50,420
sometimes or futile it just doesn't seem

00:36:48,440 --> 00:36:54,560
worth the effort can I see a show of

00:36:50,420 --> 00:36:57,820
hands for fantastic some people are

00:36:54,560 --> 00:37:02,330
excited for flaky

00:36:57,820 --> 00:37:04,850
no one's flaky that's good futile no

00:37:02,330 --> 00:37:11,000
one's futile either oh one person I'm

00:37:04,850 --> 00:37:14,730
sorry it's not that bad yep

00:37:11,000 --> 00:37:16,680
first technique swarm testing this one

00:37:14,730 --> 00:37:18,750
is unusual among the more advanced

00:37:16,680 --> 00:37:20,520
magical techniques and it doesn't

00:37:18,750 --> 00:37:24,330
actually use any feedback or inspect

00:37:20,520 --> 00:37:25,890
your code at all this one simply finds

00:37:24,330 --> 00:37:29,030
more bugs with the same property based

00:37:25,890 --> 00:37:32,240
tests that you already wrote magic right

00:37:29,030 --> 00:37:34,170
the way it does this is by going

00:37:32,240 --> 00:37:36,360
traditionally property based testing

00:37:34,170 --> 00:37:38,640
would do a kind of uniform random

00:37:36,360 --> 00:37:40,710
exploration based on the state machine

00:37:38,640 --> 00:37:43,170
or the grammar of the inputs that were

00:37:40,710 --> 00:37:45,660
described so if you said integers any

00:37:43,170 --> 00:37:48,270
integer was equally likely if you are

00:37:45,660 --> 00:37:50,220
operating on a stack for example you

00:37:48,270 --> 00:37:52,020
will be about equally likely to push

00:37:50,220 --> 00:37:54,630
elements onto the stack or pop them off

00:37:52,020 --> 00:37:57,660
and what this means is you're extremely

00:37:54,630 --> 00:38:00,510
unlikely to it to exercise the really

00:37:57,660 --> 00:38:02,520
weird edge cases if it's equally likely

00:38:00,510 --> 00:38:04,710
that you add something or subtract

00:38:02,520 --> 00:38:06,930
something it's very unlikely that you do

00:38:04,710 --> 00:38:10,260
fifty of one in a row and trigger some

00:38:06,930 --> 00:38:12,660
kind of overflow bug and so what swarm

00:38:10,260 --> 00:38:14,610
testing does is it generates what the

00:38:12,660 --> 00:38:16,890
authors describe as a swarm of

00:38:14,610 --> 00:38:18,690
configurations so many different

00:38:16,890 --> 00:38:20,970
probabilities for example between adding

00:38:18,690 --> 00:38:22,800
and subtracting and then each time we go

00:38:20,970 --> 00:38:25,350
to generate an input we pick one of

00:38:22,800 --> 00:38:28,890
those and then we generate the rest of

00:38:25,350 --> 00:38:31,140
the input and so this would make it more

00:38:28,890 --> 00:38:33,300
likely that we generate weird things

00:38:31,140 --> 00:38:34,890
diverse things things which are unlike

00:38:33,300 --> 00:38:37,020
anything else our code has ever tried

00:38:34,890 --> 00:38:41,970
it's a way of making property based

00:38:37,020 --> 00:38:52,350
testing more creative so does this seem

00:38:41,970 --> 00:38:54,360
fantastic flaky futile we seem tired on

00:38:52,350 --> 00:38:56,370
it's either fantastic or a little bit

00:38:54,360 --> 00:38:58,890
flaky so it's at least situationally

00:38:56,370 --> 00:39:01,530
good right for what it's worth I tend to

00:38:58,890 --> 00:39:02,700
agree the advantage of this one is that

00:39:01,530 --> 00:39:04,830
it doesn't require any configuration

00:39:02,700 --> 00:39:06,210
from the user's right the user doesn't

00:39:04,830 --> 00:39:07,920
even need to know that swarm testing

00:39:06,210 --> 00:39:11,640
exists let alone what it's called or how

00:39:07,920 --> 00:39:13,080
cute ladybugs are and at worst it should

00:39:11,640 --> 00:39:14,610
be kind of harmless right it doesn't

00:39:13,080 --> 00:39:16,710
seem like changing the distribution of

00:39:14,610 --> 00:39:19,680
our random inputs would hurt even if it

00:39:16,710 --> 00:39:22,140
doesn't help much so why haven't we

00:39:19,680 --> 00:39:23,790
implemented this hypothesis we'd have to

00:39:22,140 --> 00:39:24,420
change the underlying model that we use

00:39:23,790 --> 00:39:26,340
quite so

00:39:24,420 --> 00:39:27,780
actually we plan to get around to it at

00:39:26,340 --> 00:39:31,320
some point but we're all volunteers and

00:39:27,780 --> 00:39:34,910
have no free time so technique number

00:39:31,320 --> 00:39:37,530
two targeted property based testing

00:39:34,910 --> 00:39:40,080
it's basically regular property based

00:39:37,530 --> 00:39:41,790
testing but we add one thing instead of

00:39:40,080 --> 00:39:44,250
tracking coverage the way that fuzzers

00:39:41,790 --> 00:39:46,530
do we give users an extra part of the

00:39:44,250 --> 00:39:48,420
API a target function where they can

00:39:46,530 --> 00:39:51,330
feed in some floating-point number to

00:39:48,420 --> 00:39:53,520
tell us how weird is this input how

00:39:51,330 --> 00:39:55,860
large is it how complex is it what's the

00:39:53,520 --> 00:39:57,720
compression ratio and then the engine

00:39:55,860 --> 00:40:00,390
will preferentially mutate towards

00:39:57,720 --> 00:40:03,120
things which maximize that metric longer

00:40:00,390 --> 00:40:07,440
lists lower compression ratios things

00:40:03,120 --> 00:40:10,470
which get higher antivirus scores and so

00:40:07,440 --> 00:40:12,360
just as fuzzing evolves things based on

00:40:10,470 --> 00:40:15,180
the coverage or eventually the number of

00:40:12,360 --> 00:40:16,860
bugs that's already found there we would

00:40:15,180 --> 00:40:19,320
then evolve inputs which tend to

00:40:16,860 --> 00:40:22,650
maximize whatever target metric you

00:40:19,320 --> 00:40:24,300
choose to feed in we actually tried

00:40:22,650 --> 00:40:26,220
doing this with coverage information in

00:40:24,300 --> 00:40:27,960
an earlier version of hypothesis but

00:40:26,220 --> 00:40:30,180
eventually took it out and there were

00:40:27,960 --> 00:40:32,580
two reasons for that the first was that

00:40:30,180 --> 00:40:34,140
while it was somewhat helpful running

00:40:32,580 --> 00:40:37,050
under coverage is slower than running

00:40:34,140 --> 00:40:38,520
without coverage and so when we looked

00:40:37,050 --> 00:40:41,700
at this we thought if what people want

00:40:38,520 --> 00:40:43,320
is to find many bugs per second or

00:40:41,700 --> 00:40:45,570
minute or hour of time that they spend

00:40:43,320 --> 00:40:47,310
running hypotheses often you would

00:40:45,570 --> 00:40:50,400
actually get more bugs if you run it

00:40:47,310 --> 00:40:52,890
with coverage disabled because it's four

00:40:50,400 --> 00:40:54,510
to five times faster so making it twice

00:40:52,890 --> 00:40:56,340
as likely to find a bug for each test

00:40:54,510 --> 00:40:58,860
case in fact reduces the number of bugs

00:40:56,340 --> 00:41:00,810
we find and the second is that the way

00:40:58,860 --> 00:41:04,020
coverage is implemented in Python it

00:41:00,810 --> 00:41:05,490
uses a trace function so extra code is

00:41:04,020 --> 00:41:07,560
called every time the stack frame

00:41:05,490 --> 00:41:09,240
changes in the interpreter and this

00:41:07,560 --> 00:41:11,640
means that it's incompatible with many

00:41:09,240 --> 00:41:13,500
debuggers and the time you most need a

00:41:11,640 --> 00:41:16,740
debugger might in fact be when you found

00:41:13,500 --> 00:41:18,540
a bug and it was kind of fragile so

00:41:16,740 --> 00:41:20,460
given that it wasn't helping much we

00:41:18,540 --> 00:41:22,050
took out the coverage based stuff but

00:41:20,460 --> 00:41:23,760
we're quite excited about the

00:41:22,050 --> 00:41:28,080
possibility of targeted property based

00:41:23,760 --> 00:41:30,960
testing who thinks this is fantastic who

00:41:28,080 --> 00:41:35,089
you think's it's flaky who thinks it's

00:41:30,960 --> 00:41:40,759
futile who hasn't put their hand up yet

00:41:35,089 --> 00:41:43,729
thank you my opinion on this one is that

00:41:40,759 --> 00:41:45,650
it's a fairly fragile technique while in

00:41:43,729 --> 00:41:48,319
certain situations it is impressively

00:41:45,650 --> 00:41:50,680
powerful it also relies on the use of

00:41:48,319 --> 00:41:53,509
choosing a useful target function and

00:41:50,680 --> 00:41:54,920
often there isn't a target function

00:41:53,509 --> 00:41:57,890
which corresponds really well with

00:41:54,920 --> 00:42:00,380
bugginess so we might be able to drive

00:41:57,890 --> 00:42:02,180
to particular extremes of our input

00:42:00,380 --> 00:42:04,059
space but whether or not that actually

00:42:02,180 --> 00:42:06,469
helps us find both is kind of unclear

00:42:04,059 --> 00:42:07,880
that said we do have an open pore

00:42:06,469 --> 00:42:09,469
request to implement in targeted

00:42:07,880 --> 00:42:11,569
property based testing so if you're

00:42:09,469 --> 00:42:15,349
really keen you can install hypothesis

00:42:11,569 --> 00:42:19,160
directly from get and use it third

00:42:15,349 --> 00:42:21,319
technique symbolic execution instead of

00:42:19,160 --> 00:42:24,619
executing your code with specific values

00:42:21,319 --> 00:42:26,779
if you're using symbolic execution you

00:42:24,619 --> 00:42:28,249
analyze the code you calculate the

00:42:26,779 --> 00:42:30,829
different branches that can be taken

00:42:28,249 --> 00:42:32,839
through and you make an exhaustive list

00:42:30,829 --> 00:42:35,900
of all the distinct paths through your

00:42:32,839 --> 00:42:38,029
code so this is a little more tractable

00:42:35,900 --> 00:42:40,039
than symbol then exhaustive testing

00:42:38,029 --> 00:42:42,319
right it might be that for the purposes

00:42:40,039 --> 00:42:45,289
of your code every positive integer is

00:42:42,319 --> 00:42:47,809
treated identically and so with symbolic

00:42:45,289 --> 00:42:51,799
execution you could analyze all of those

00:42:47,809 --> 00:42:53,569
at a single go I'll admit that

00:42:51,799 --> 00:42:55,489
by my definition of testing where your

00:42:53,569 --> 00:42:58,880
code is actually executed this is not

00:42:55,489 --> 00:42:59,239
testing but bear with me does it sound

00:42:58,880 --> 00:43:06,650
good

00:42:59,239 --> 00:43:10,160
fantastic fragile futile all of those

00:43:06,650 --> 00:43:12,380
are quite reasonable in my view this is

00:43:10,160 --> 00:43:15,079
somewhere between fragile and futile for

00:43:12,380 --> 00:43:17,390
large Python functions well you can do

00:43:15,079 --> 00:43:19,880
it reliably for small functions when you

00:43:17,390 --> 00:43:22,309
get up to larger code bases you come

00:43:19,880 --> 00:43:25,160
into a couple of problems the first is

00:43:22,309 --> 00:43:27,349
the Python is amazingly magical you can

00:43:25,160 --> 00:43:29,809
override dunder methods you can patch

00:43:27,349 --> 00:43:31,849
things at runtime you can execute code

00:43:29,809 --> 00:43:34,400
that was delivered as bytecode over the

00:43:31,849 --> 00:43:36,469
network and that means that it is really

00:43:34,400 --> 00:43:39,219
hard to be sure just from reading the

00:43:36,469 --> 00:43:41,719
source code exactly what Python will do

00:43:39,219 --> 00:43:43,460
this problem is made harder by the fact

00:43:41,719 --> 00:43:47,299
that Python doesn't actually have a

00:43:43,460 --> 00:43:48,330
standard semantic definition Python has

00:43:47,299 --> 00:43:50,960
a reference in

00:43:48,330 --> 00:43:53,100
patien which means that by definition

00:43:50,960 --> 00:43:56,730
python is whatever the cpython

00:43:53,100 --> 00:43:58,230
interpreted does and that makes it

00:43:56,730 --> 00:44:00,630
pretty hard to write a symbolic

00:43:58,230 --> 00:44:02,220
execution engine because the behavior of

00:44:00,630 --> 00:44:04,190
the c python interpreter keeps changing

00:44:02,220 --> 00:44:06,840
when they keep working on it

00:44:04,190 --> 00:44:08,820
that said I really like symbolic

00:44:06,840 --> 00:44:11,570
execution if only there was some way to

00:44:08,820 --> 00:44:15,080
make this work

00:44:11,570 --> 00:44:18,320
can colic execution is where we combine

00:44:15,080 --> 00:44:21,330
concrete values and symbolic execution

00:44:18,320 --> 00:44:23,250
it's a bait-and-switch right we do

00:44:21,330 --> 00:44:24,870
symbolic execution for a while and this

00:44:23,250 --> 00:44:26,940
is really cool and mathematical and

00:44:24,870 --> 00:44:29,070
abstract and then we're like oh no we

00:44:26,940 --> 00:44:31,860
have no idea what to do here we work out

00:44:29,070 --> 00:44:33,840
well what kind of specific actual Python

00:44:31,860 --> 00:44:36,900
value would have made it through this

00:44:33,840 --> 00:44:38,310
sequence of branches to get here then

00:44:36,900 --> 00:44:40,740
you generate it and you call the code

00:44:38,310 --> 00:44:44,010
and you see what happens it's total

00:44:40,740 --> 00:44:45,930
cheating and it's awesome I won't ask

00:44:44,010 --> 00:44:48,780
you whether this is fantastic fragile or

00:44:45,930 --> 00:44:50,310
futile I think because I have no idea to

00:44:48,780 --> 00:44:52,410
my knowledge no one is doing this for

00:44:50,310 --> 00:44:55,710
Python at all but it seems like it would

00:44:52,410 --> 00:44:58,290
be really cool I will note as well that

00:44:55,710 --> 00:45:00,960
I'm in practice because the chain of

00:44:58,290 --> 00:45:03,420
branches can get very complex we usually

00:45:00,960 --> 00:45:05,310
use what's called a Sat solver to work

00:45:03,420 --> 00:45:06,780
out what combination of values would

00:45:05,310 --> 00:45:09,870
actually get to a particular part of our

00:45:06,780 --> 00:45:12,120
code a Sat solver is a thing which can

00:45:09,870 --> 00:45:14,520
represent if your problem is represented

00:45:12,120 --> 00:45:16,080
as some set of simultaneous equations so

00:45:14,520 --> 00:45:17,880
I have a set of variables and you said

00:45:16,080 --> 00:45:20,760
all of which are either true or false

00:45:17,880 --> 00:45:25,590
and you have a set of equations you know

00:45:20,760 --> 00:45:30,150
a and B and B or C is true and not a and

00:45:25,590 --> 00:45:32,220
not D is true a Sat solver will use

00:45:30,150 --> 00:45:34,830
various heuristics and various special

00:45:32,220 --> 00:45:36,300
techniques to try to find some set of

00:45:34,830 --> 00:45:39,240
assignments to those variables which

00:45:36,300 --> 00:45:41,370
satisfies all of the equations so a Sat

00:45:39,240 --> 00:45:45,000
solver is a thing which solves the

00:45:41,370 --> 00:45:46,590
boolean satisfiability problem this is

00:45:45,000 --> 00:45:50,280
amazing because that problem is

00:45:46,590 --> 00:45:53,010
np-complete that means there is this

00:45:50,280 --> 00:45:55,140
class of problems where you can there is

00:45:53,010 --> 00:45:57,390
no efficient algorithm to find an answer

00:45:55,140 --> 00:45:59,910
but there are efficient ways to check an

00:45:57,390 --> 00:46:01,530
answer if you're thinking about the

00:45:59,910 --> 00:46:02,700
simultaneous equations

00:46:01,530 --> 00:46:04,650
checking the answer is really simple

00:46:02,700 --> 00:46:06,030
right you just substitute in the values

00:46:04,650 --> 00:46:08,910
and see if all the equations are correct

00:46:06,030 --> 00:46:10,410
but finding one takes time which is

00:46:08,910 --> 00:46:12,480
exponential in the number of things you

00:46:10,410 --> 00:46:14,520
have so sat solvers are like in

00:46:12,480 --> 00:46:18,630
principle impossible and yet they

00:46:14,520 --> 00:46:20,970
usually work I have no idea how that

00:46:18,630 --> 00:46:25,380
happens but I am so so delighted that

00:46:20,970 --> 00:46:28,350
they exist and the final technique which

00:46:25,380 --> 00:46:32,280
I will admit I am also really excited

00:46:28,350 --> 00:46:34,620
about is constructing programs so not

00:46:32,280 --> 00:46:37,050
just thinking about a list of numbers or

00:46:34,620 --> 00:46:39,180
some particular file format but getting

00:46:37,050 --> 00:46:41,550
our property based testing library or

00:46:39,180 --> 00:46:44,820
our fuzzing tool to generate Python code

00:46:41,550 --> 00:46:46,890
itself this would be pretty cool we

00:46:44,820 --> 00:46:49,680
could test everything from linters or

00:46:46,890 --> 00:46:52,530
Auto formatters yeah does the type

00:46:49,680 --> 00:46:54,960
checker work on arbitrary programs we

00:46:52,530 --> 00:46:56,730
could check competing implementations so

00:46:54,960 --> 00:46:59,130
see Python and pipe I could check that

00:46:56,730 --> 00:47:02,060
they execute when they execute any

00:46:59,130 --> 00:47:04,170
program they give the same output and

00:47:02,060 --> 00:47:05,970
there are a couple of ways that we could

00:47:04,170 --> 00:47:07,650
do this the first is that we could

00:47:05,970 --> 00:47:09,810
actually look at the grammar of Python

00:47:07,650 --> 00:47:12,180
source code the thing which describes

00:47:09,810 --> 00:47:14,100
what tokens are valid after a for

00:47:12,180 --> 00:47:15,600
statement for example you know you need

00:47:14,100 --> 00:47:18,630
a colon then you need some indentation

00:47:15,600 --> 00:47:20,610
and then you can have other code and we

00:47:18,630 --> 00:47:22,980
could generate arbitrary strings which

00:47:20,610 --> 00:47:28,380
would be passed by the Python grammar I

00:47:22,980 --> 00:47:31,020
tried this it worked right I found a bug

00:47:28,380 --> 00:47:33,020
in the C Python passer because it turns

00:47:31,020 --> 00:47:37,170
out that the grammar of Python is not

00:47:33,020 --> 00:47:39,330
exactly describing what C Python really

00:47:37,170 --> 00:47:42,300
does foiled by the reference

00:47:39,330 --> 00:47:43,980
implementation but there are other

00:47:42,300 --> 00:47:46,290
options we could use we could instead

00:47:43,980 --> 00:47:48,360
try to generate a syntax tree and then

00:47:46,290 --> 00:47:53,160
work out what programs source code

00:47:48,360 --> 00:47:55,590
corresponds to that syntax tree so super

00:47:53,160 --> 00:47:57,330
cool we could generate programs we could

00:47:55,590 --> 00:47:59,550
test our programming languages as well

00:47:57,330 --> 00:48:02,100
as the programs from writing them who

00:47:59,550 --> 00:48:04,820
thinks this sounds awesome who wants to

00:48:02,100 --> 00:48:10,620
work on it at the sprints with me whoa

00:48:04,820 --> 00:48:12,810
come see me later final bit right I

00:48:10,620 --> 00:48:13,890
promised that we would have the section

00:48:12,810 --> 00:48:14,980
where I gave you something you could

00:48:13,890 --> 00:48:16,300
actually use

00:48:14,980 --> 00:48:18,359
and for those of you who are going to

00:48:16,300 --> 00:48:20,800
help them with that last one on Monday

00:48:18,359 --> 00:48:22,930
but for the rest of you I've talked a

00:48:20,800 --> 00:48:25,690
lot about some cool tools and some great

00:48:22,930 --> 00:48:27,250
ideas but can you actually use any of

00:48:25,690 --> 00:48:29,400
this stuff has it does anyone feel that

00:48:27,250 --> 00:48:35,560
they've got stuff they can use already

00:48:29,400 --> 00:48:37,540
few people I want you all to go back to

00:48:35,560 --> 00:48:40,230
work or wherever you're going on Monday

00:48:37,540 --> 00:48:42,690
and write some property based tests

00:48:40,230 --> 00:48:44,950
sound good

00:48:42,690 --> 00:48:46,300
I'm getting some nods and some blank

00:48:44,950 --> 00:48:48,160
faces you're probably thinking Zack

00:48:46,300 --> 00:48:49,660
you've told us how cool you think these

00:48:48,160 --> 00:48:51,970
are but you haven't told us how to

00:48:49,660 --> 00:48:54,280
actually write them and you're right you

00:48:51,970 --> 00:48:57,910
know step one step one is to install

00:48:54,280 --> 00:49:00,460
hypothesis you type in pip install

00:48:57,910 --> 00:49:02,880
hypothesis or if you prefer Kondo you

00:49:00,460 --> 00:49:05,650
type in Kondo install hypothesis and

00:49:02,880 --> 00:49:07,390
there are a couple of things here first

00:49:05,650 --> 00:49:10,570
of all hypothesis is compatible with

00:49:07,390 --> 00:49:12,910
every supported version of Python from

00:49:10,570 --> 00:49:15,280
the PSF that means that we support

00:49:12,910 --> 00:49:18,640
Python 2.7 but we will drop it at the

00:49:15,280 --> 00:49:21,760
end of this year so if you are still

00:49:18,640 --> 00:49:25,990
using Python 2 you might want to think

00:49:21,760 --> 00:49:27,490
about moving to Python 3 soon hypothesis

00:49:25,990 --> 00:49:29,560
is compatible with a wide range of other

00:49:27,490 --> 00:49:31,510
things we have very few dependencies but

00:49:29,560 --> 00:49:33,070
many optional extensions and quite a

00:49:31,510 --> 00:49:35,170
healthy community ecosystem of

00:49:33,070 --> 00:49:38,859
third-party libraries so if you use

00:49:35,170 --> 00:49:40,240
numpy panda's django json schema we have

00:49:38,859 --> 00:49:44,170
plugins that will deal with all of those

00:49:40,240 --> 00:49:48,300
for you so you've installed hypothesis

00:49:44,170 --> 00:49:52,840
you're gonna do this right yeah step to

00:49:48,300 --> 00:49:55,600
migrate a single test you probably have

00:49:52,840 --> 00:49:57,580
a test in your code base which at some

00:49:55,600 --> 00:49:59,680
point just has an arbitrary value in it

00:49:57,580 --> 00:50:01,420
and you know that testing the add

00:49:59,680 --> 00:50:04,600
function could use more numbers than

00:50:01,420 --> 00:50:06,670
just 1 and 2 but you're in a hurry right

00:50:04,600 --> 00:50:08,200
so you typed the simple ones or you

00:50:06,670 --> 00:50:10,330
didn't want to debug really complicated

00:50:08,200 --> 00:50:13,780
ones and you were sure that 1 & 2 should

00:50:10,330 --> 00:50:16,330
equal 3 so find a test that looks

00:50:13,780 --> 00:50:18,760
something like this this test is simply

00:50:16,330 --> 00:50:21,340
that if we have a get report if we start

00:50:18,760 --> 00:50:23,830
a new git repository and we create a

00:50:21,340 --> 00:50:26,260
branch called new branch to checkout

00:50:23,830 --> 00:50:28,000
then the active branch will be the new

00:50:26,260 --> 00:50:31,570
branch

00:50:28,000 --> 00:50:33,010
kind of how it works so what happens

00:50:31,570 --> 00:50:35,500
when we want to abstract that a little

00:50:33,010 --> 00:50:39,400
more generalize it and not only consider

00:50:35,500 --> 00:50:41,260
the literal name new branch well step

00:50:39,400 --> 00:50:44,770
one is simply to move arbitrary

00:50:41,260 --> 00:50:47,710
constants to keyword arguments this test

00:50:44,770 --> 00:50:49,720
behaves identically to the old one it

00:50:47,710 --> 00:50:51,640
doesn't depend on hypothesis you can do

00:50:49,720 --> 00:50:55,750
this before step one though step one is

00:50:51,640 --> 00:50:58,180
great and what we've got now is a

00:50:55,750 --> 00:51:00,490
variable which indicates the branch name

00:50:58,180 --> 00:51:02,470
and so our test semantically is saying

00:51:00,490 --> 00:51:07,890
given any branch name this should pass

00:51:02,470 --> 00:51:10,270
right the next step is to move that

00:51:07,890 --> 00:51:13,030
particular specific argument to a

00:51:10,270 --> 00:51:15,040
hypothesis strategy so in this version

00:51:13,030 --> 00:51:17,740
we are using hypothesis we've got the

00:51:15,040 --> 00:51:19,570
given decorator and we have the

00:51:17,740 --> 00:51:22,480
corresponding arguments to given four

00:51:19,570 --> 00:51:26,050
arguments to our test function and in

00:51:22,480 --> 00:51:28,630
this case our strategy just generates

00:51:26,050 --> 00:51:30,970
the string new branch we haven't changed

00:51:28,630 --> 00:51:35,140
the test semantically yet but we have

00:51:30,970 --> 00:51:37,119
started to use hypotheses then of course

00:51:35,140 --> 00:51:37,570
abstraction is great right don't repeat

00:51:37,119 --> 00:51:40,000
yourself

00:51:37,570 --> 00:51:42,490
so we'll extract that out to a separate

00:51:40,000 --> 00:51:44,800
function which returns a strategy for

00:51:42,490 --> 00:51:46,900
valid branch names and this means that

00:51:44,800 --> 00:51:48,970
we could reuse the strategy across any

00:51:46,900 --> 00:51:52,240
test that's using the names of branches

00:51:48,970 --> 00:51:54,700
and when we eventually go back and

00:51:52,240 --> 00:51:55,890
improve that strategy all of our tests

00:51:54,700 --> 00:51:58,240
will get more powerful

00:51:55,890 --> 00:52:00,280
so if our requirements change we have a

00:51:58,240 --> 00:52:04,960
single place where we can change to

00:52:00,280 --> 00:52:07,660
improve our tests then we can try

00:52:04,960 --> 00:52:10,740
generalizing the strategy this is a

00:52:07,660 --> 00:52:12,970
strategy for arbitrary Unicode text I

00:52:10,740 --> 00:52:16,150
will give you a spoiler and say that

00:52:12,970 --> 00:52:19,390
this one fails it turns out you can't

00:52:16,150 --> 00:52:22,349
name a git bridge empty string you can't

00:52:19,390 --> 00:52:24,430
name it space you can't name it newline

00:52:22,349 --> 00:52:27,910
you're probably not meant to name it

00:52:24,430 --> 00:52:31,720
master either but master is a valid

00:52:27,910 --> 00:52:34,210
branch string so if you actually read

00:52:31,720 --> 00:52:36,099
the get manual for check reference

00:52:34,210 --> 00:52:37,810
format you will see that the rules are

00:52:36,099 --> 00:52:41,049
extremely complicated and that they vary

00:52:37,810 --> 00:52:43,089
by both operating system and file system

00:52:41,049 --> 00:52:47,799
because bred slaves are also stored as

00:52:43,089 --> 00:52:49,959
file names so we're just gonna take the

00:52:47,799 --> 00:52:52,599
easy way out and say sure we want text

00:52:49,959 --> 00:52:54,849
but we only want ASCII letters not even

00:52:52,599 --> 00:52:56,499
dashes or underscores because there are

00:52:54,849 --> 00:52:57,939
rules about how many dashes you can have

00:52:56,499 --> 00:53:01,059
in a row and it get branch David turns

00:52:57,939 --> 00:53:02,499
out and we need at least one letter you

00:53:01,059 --> 00:53:07,539
can't have an empty string as the name

00:53:02,499 --> 00:53:09,759
and no more than 95 letters because some

00:53:07,539 --> 00:53:11,709
get hosting websites arbitrarily cut off

00:53:09,759 --> 00:53:13,989
branch names at 100 characters and

00:53:11,709 --> 00:53:18,249
branch names technically include head

00:53:13,989 --> 00:53:20,259
slash as the first part so between 1 and

00:53:18,249 --> 00:53:23,739
95 letters gives us a valid git branch

00:53:20,259 --> 00:53:26,169
name what do we do then it's at least

00:53:23,739 --> 00:53:29,319
possible that this will generate the

00:53:26,169 --> 00:53:31,659
string of master being 5 escalators and

00:53:29,319 --> 00:53:34,869
so we add at the top of our test

00:53:31,659 --> 00:53:37,359
function an assumption an assumption or

00:53:34,869 --> 00:53:39,669
assume is a function from hypothesis

00:53:37,359 --> 00:53:41,079
which is much like an assertion but

00:53:39,669 --> 00:53:43,119
instead of indicating that the test has

00:53:41,079 --> 00:53:45,069
failed it indicates that the input is

00:53:43,119 --> 00:53:48,369
problematic in some way and just tells

00:53:45,069 --> 00:53:50,289
hypothesis look that one was okay but

00:53:48,369 --> 00:53:51,369
don't give it to me again and don't

00:53:50,289 --> 00:53:54,429
count that as a failure

00:53:51,369 --> 00:53:57,189
try again and so we can make our

00:53:54,429 --> 00:53:59,439
assumption right we can say any sequence

00:53:57,189 --> 00:54:02,049
of letters not the sequence master and

00:53:59,439 --> 00:54:03,639
this test should pass we've now

00:54:02,049 --> 00:54:06,069
refactored our test completely to use

00:54:03,639 --> 00:54:07,630
hypothesis and chances are we've

00:54:06,069 --> 00:54:09,579
discovered and had to read something

00:54:07,630 --> 00:54:11,799
about the manual it hadn't occurred to

00:54:09,579 --> 00:54:13,539
me at least to wonder what was a valid

00:54:11,799 --> 00:54:14,409
branch name and get because I always

00:54:13,539 --> 00:54:18,009
gave my things

00:54:14,409 --> 00:54:21,789
sensible branch names like targeted PBT

00:54:18,009 --> 00:54:23,789
or working on that bug fix or oh god why

00:54:21,789 --> 00:54:27,339
is this happening

00:54:23,789 --> 00:54:29,799
and the end result once we finalize

00:54:27,339 --> 00:54:32,139
refactoring this we might have a

00:54:29,799 --> 00:54:34,149
strategy for repositories as well so

00:54:32,139 --> 00:54:35,919
that instead of creating a new empty

00:54:34,149 --> 00:54:38,019
repository we actually say this property

00:54:35,919 --> 00:54:39,639
should be true of all of them and so

00:54:38,019 --> 00:54:41,439
it's not just the master branch that we

00:54:39,639 --> 00:54:43,689
want to exclude but we can say given any

00:54:41,439 --> 00:54:45,909
repository and any valid branch name if

00:54:43,689 --> 00:54:48,369
the branch name is not yet in the

00:54:45,909 --> 00:54:50,380
branches in the repository then checking

00:54:48,369 --> 00:54:52,119
out that bridge means that the currently

00:54:50,380 --> 00:54:53,940
active bridge will be whichever one we

00:54:52,119 --> 00:54:56,099
just checked out

00:54:53,940 --> 00:54:58,079
this is about as close to a genuinely

00:54:56,099 --> 00:55:00,119
mathematical property as you will see in

00:54:58,079 --> 00:55:02,819
code which is not doing simple data

00:55:00,119 --> 00:55:04,530
transformation you can test that stuff

00:55:02,819 --> 00:55:07,049
with our pollicis too right it's great

00:55:04,530 --> 00:55:08,910
it's easy but you can also test for more

00:55:07,049 --> 00:55:10,170
complicated stuff and I hope I've

00:55:08,910 --> 00:55:11,700
convinced you that you don't have to

00:55:10,170 --> 00:55:13,829
write these from scratch either you can

00:55:11,700 --> 00:55:15,900
find existing tests and incrementally

00:55:13,829 --> 00:55:19,710
migrate them to take advantage of

00:55:15,900 --> 00:55:21,539
something like hypothesis when you're

00:55:19,710 --> 00:55:23,700
ready to take that final third step

00:55:21,539 --> 00:55:25,339
though you can write a property-based

00:55:23,700 --> 00:55:27,750
test from scratch

00:55:25,339 --> 00:55:29,880
for your first one I strongly recommend

00:55:27,750 --> 00:55:32,250
choosing what we call a round trip

00:55:29,880 --> 00:55:34,349
property the best one is testing that

00:55:32,250 --> 00:55:36,119
when you write some data to a database

00:55:34,349 --> 00:55:38,520
or to disk and then read it you get the

00:55:36,119 --> 00:55:40,079
same data back this is something which

00:55:38,520 --> 00:55:41,789
should be true for basically any way

00:55:40,079 --> 00:55:44,549
that you store files or put stuff in a

00:55:41,789 --> 00:55:47,250
database right I hope you want the same

00:55:44,549 --> 00:55:48,539
data back this one is really useful

00:55:47,250 --> 00:55:50,849
because there tend to be a lot of

00:55:48,539 --> 00:55:53,400
different layers file systems have

00:55:50,849 --> 00:55:55,079
subtle rules about how large things can

00:55:53,400 --> 00:55:59,190
be or where they go or what they have to

00:55:55,079 --> 00:56:00,930
be named and often I discovered that I

00:55:59,190 --> 00:56:03,450
didn't quite understand what those rules

00:56:00,930 --> 00:56:06,299
were if you don't have a convenient pair

00:56:03,450 --> 00:56:08,309
of write and read functions you might be

00:56:06,299 --> 00:56:10,829
working on a networking thing a send and

00:56:08,309 --> 00:56:13,049
receive is quite similar or if you're

00:56:10,829 --> 00:56:16,440
working on a simpler project a set and

00:56:13,049 --> 00:56:18,539
then again of some property just testing

00:56:16,440 --> 00:56:21,770
that when you round-trip this it always

00:56:18,539 --> 00:56:24,270
works so let's go see a worked example

00:56:21,770 --> 00:56:27,359
this one's pretty simple we're testing

00:56:24,270 --> 00:56:30,299
that if we dump some value as a JSON

00:56:27,359 --> 00:56:32,400
string and then load that string

00:56:30,299 --> 00:56:35,130
interpreted as JSON to a value it's

00:56:32,400 --> 00:56:36,650
equal to the value we start up with does

00:56:35,130 --> 00:56:41,190
everyone think this property should hold

00:56:36,650 --> 00:56:43,799
show of hands it should be true show of

00:56:41,190 --> 00:56:46,670
hands it should be false you're

00:56:43,799 --> 00:56:46,670
suspicious Bunch

00:56:46,970 --> 00:56:51,480
so the first step right we can just try

00:56:49,410 --> 00:56:53,339
putting none in it and this test passes

00:56:51,480 --> 00:56:54,750
for none it turns out if you serialize

00:56:53,339 --> 00:56:56,940
it to null and then bring that back from

00:56:54,750 --> 00:56:58,890
JSON you get none again so we're all

00:56:56,940 --> 00:57:01,560
good so far and then incrementally we

00:56:58,890 --> 00:57:04,950
can improve that strategy we can go

00:57:01,560 --> 00:57:07,859
let's look at none or boolean or floats

00:57:04,950 --> 00:57:10,859
or text that's Unicode strings in Python

00:57:07,859 --> 00:57:16,220
3 it's just strings should this test

00:57:10,859 --> 00:57:20,760
pass it should pass it should not pass

00:57:16,220 --> 00:57:22,710
why doesn't it pass floats there is a

00:57:20,760 --> 00:57:27,140
special floating point value called not

00:57:22,710 --> 00:57:29,430
a number which is unequal to itself

00:57:27,140 --> 00:57:31,440
numbers are equal to themselves but

00:57:29,430 --> 00:57:34,740
fortunately this float is not a number

00:57:31,440 --> 00:57:37,320
and so again we can simply add an

00:57:34,740 --> 00:57:42,420
assumption so we say for any value which

00:57:37,320 --> 00:57:44,099
is equal to itself if we write it to

00:57:42,420 --> 00:57:46,890
JSON and then read it back to Python

00:57:44,099 --> 00:57:51,200
values the new value should be equal to

00:57:46,890 --> 00:57:57,270
the old value should this one pass yes

00:57:51,200 --> 00:57:59,369
no this one does pass but all we're

00:57:57,270 --> 00:58:02,609
dealing with here is JSON scalars right

00:57:59,369 --> 00:58:04,500
if we have lists or what JSON calls

00:58:02,609 --> 00:58:06,390
arrays lists or objects that it is

00:58:04,500 --> 00:58:08,030
Python dictionaries we're not generating

00:58:06,390 --> 00:58:10,440
those and we're not testing them

00:58:08,030 --> 00:58:13,170
fortunately with hypothesis we could

00:58:10,440 --> 00:58:16,890
also generate recursive data and so this

00:58:13,170 --> 00:58:20,250
strategy says starting with null or

00:58:16,890 --> 00:58:22,200
boolean Zoar floats or text we can take

00:58:20,250 --> 00:58:23,970
lists of whatever we have or

00:58:22,200 --> 00:58:26,670
dictionaries of strings to whatever it

00:58:23,970 --> 00:58:29,730
is we have and this recursive definition

00:58:26,670 --> 00:58:31,349
actually does describe all JSON and so

00:58:29,730 --> 00:58:35,550
we feed it into the same thing should

00:58:31,349 --> 00:58:38,000
this test pass it should pass it should

00:58:35,550 --> 00:58:38,000
not pass

00:58:39,360 --> 00:58:48,180
I didn't raise my head yeah this one it

00:58:44,670 --> 00:58:49,890
turns out fails I didn't know that this

00:58:48,180 --> 00:58:51,480
test fails until I was writing up a

00:58:49,890 --> 00:58:53,880
tutorial and I thought this will be a

00:58:51,480 --> 00:58:55,710
good example right I'll incrementally

00:58:53,880 --> 00:58:57,870
write a property-based test and it will

00:58:55,710 --> 00:59:02,370
fail but yeah we'll hit down right and

00:58:57,870 --> 00:59:05,520
that will show people it turns out that

00:59:02,370 --> 00:59:07,800
Python lists right two lists are equal

00:59:05,520 --> 00:59:09,330
if and only if they're both lists and

00:59:07,800 --> 00:59:12,810
then each of their corresponding

00:59:09,330 --> 00:59:15,720
elements are equal so a list with nan in

00:59:12,810 --> 00:59:21,150
it would not be equal to itself because

00:59:15,720 --> 00:59:23,790
nan is not equal to itself but Python

00:59:21,150 --> 00:59:26,640
has an optimization or if a list is

00:59:23,790 --> 00:59:30,890
compared to itself the comparison

00:59:26,640 --> 00:59:35,940
happens by identity because a is a

00:59:30,890 --> 00:59:37,800
equals returns true because not a number

00:59:35,940 --> 00:59:39,600
breaks pythons object equality model and

00:59:37,800 --> 00:59:42,030
so if you run this test it will Julie

00:59:39,600 --> 00:59:48,300
spit out for you a list with a single

00:59:42,030 --> 00:59:51,330
floating point not a number in it there

00:59:48,300 --> 00:59:55,250
we are folks sufficiently advanced

00:59:51,330 --> 00:59:55,250
testing so thank you very much

00:59:59,340 --> 01:00:04,390
Kru you talk we have about eight minutes

01:00:01,840 --> 01:00:06,430
for questions if there are questions if

01:00:04,390 --> 01:00:10,870
you hold up your hand I can give you the

01:00:06,430 --> 01:00:12,520
microphone that's how bodies work with

01:00:10,870 --> 01:00:14,050
type annotations at all if you're

01:00:12,520 --> 01:00:16,930
knowing the code something is an end can

01:00:14,050 --> 01:00:17,500
automatically strategy based on that yes

01:00:16,930 --> 01:00:20,500
it can

01:00:17,500 --> 01:00:22,540
so if you decorate at given and say

01:00:20,500 --> 01:00:24,790
value equals infer and you type

01:00:22,540 --> 01:00:27,160
annotated it will do that we also have a

01:00:24,790 --> 01:00:29,200
builds function which takes some class

01:00:27,160 --> 01:00:31,210
or function and then strategies

01:00:29,200 --> 01:00:32,920
corresponding to the arguments for it if

01:00:31,210 --> 01:00:35,020
you have type annotated required

01:00:32,920 --> 01:00:37,540
arguments with no user supplied

01:00:35,020 --> 01:00:44,080
strategies will recursively infer how to

01:00:37,540 --> 01:00:48,400
build it that one was hard to implement

01:00:44,080 --> 01:00:50,350
across versions thanks for the talk can

01:00:48,400 --> 01:00:54,280
you use async IO and care routines with

01:00:50,350 --> 01:00:57,070
a hypothesis hypothesis natively only

01:00:54,280 --> 01:00:59,320
calls sinc functions mostly because it's

01:00:57,070 --> 01:01:00,790
hard to know what event loop to use if

01:00:59,320 --> 01:01:03,520
you're using something like PI test

01:01:00,790 --> 01:01:04,570
async IO or PI test REO they have a

01:01:03,520 --> 01:01:06,220
plug-in which actually supports

01:01:04,570 --> 01:01:08,230
hypothesis so they understand how to

01:01:06,220 --> 01:01:11,260
insert a shim which converts a sink to

01:01:08,230 --> 01:01:13,570
sink code for us so you can write async

01:01:11,260 --> 01:01:16,080
tests if you use a test runner which

01:01:13,570 --> 01:01:16,080
supports that

01:01:20,900 --> 01:01:26,250
hi um you saw it seems like the biggest

01:01:24,510 --> 01:01:27,900
advantage of this is that you really can

01:01:26,250 --> 01:01:29,580
go into your testing with very little

01:01:27,900 --> 01:01:32,700
assumptions as to where the bugs might

01:01:29,580 --> 01:01:34,890
be found with the targeted PBT methods

01:01:32,700 --> 01:01:36,480
you're then adding some assumptions back

01:01:34,890 --> 01:01:38,430
in and so is there any disadvantage to

01:01:36,480 --> 01:01:40,980
kind of leading your tests down the

01:01:38,430 --> 01:01:42,150
wrong garden path potentially so this is

01:01:40,980 --> 01:01:44,400
one of the reasons I would think of that

01:01:42,150 --> 01:01:47,070
as a potentially fragile technique that

01:01:44,400 --> 01:01:48,870
if it turns out that your thing is

01:01:47,070 --> 01:01:50,790
particularly vulnerable to very small

01:01:48,870 --> 01:01:53,730
inputs but you've targeted very large

01:01:50,790 --> 01:01:55,380
inputs it's gonna spend most of its time

01:01:53,730 --> 01:02:00,990
generating things which won't find those

01:01:55,380 --> 01:02:02,520
small bugs if it works right yeah so

01:02:00,990 --> 01:02:04,830
part of the design would be making sure

01:02:02,520 --> 01:02:06,330
it balances a little between generating

01:02:04,830 --> 01:02:10,500
things that's been told to and other

01:02:06,330 --> 01:02:12,420
less directed exploration follow-up to

01:02:10,500 --> 01:02:15,060
the annotation question does it work

01:02:12,420 --> 01:02:17,190
with protocols such as protobuf or drift

01:02:15,060 --> 01:02:20,040
that like you can invert the underlying

01:02:17,190 --> 01:02:21,780
interfaces type so there is a

01:02:20,040 --> 01:02:23,610
third-party extension for protobufs you

01:02:21,780 --> 01:02:25,410
can hand it a part of a schema and it

01:02:23,610 --> 01:02:28,050
will generate messages that are matched

01:02:25,410 --> 01:02:29,910
by that in general we have support for a

01:02:28,050 --> 01:02:31,860
couple so type annotations regular

01:02:29,910 --> 01:02:33,930
expressions context-free grammars a few

01:02:31,860 --> 01:02:36,600
others there are more in third-party

01:02:33,930 --> 01:02:37,920
ones and of course if you can do it

01:02:36,600 --> 01:02:40,230
yourself you can just write a function

01:02:37,920 --> 01:02:41,820
which takes some schema of whatever kind

01:02:40,230 --> 01:02:44,490
and returns a strategy for things that

01:02:41,820 --> 01:02:45,900
match it so I don't think there's a

01:02:44,490 --> 01:02:48,740
thrift one but nor do I think it'll be

01:02:45,900 --> 01:02:48,740
that hard to write your own

01:02:53,920 --> 01:02:58,309
does a path assist natively do like

01:02:56,780 --> 01:03:00,069
operating system testing or do you have

01:02:58,309 --> 01:03:03,170
to do something else to get that kind of

01:03:00,069 --> 01:03:05,089
so Python sorry hypothesis is really

01:03:03,170 --> 01:03:08,180
designed for testing Python functions or

01:03:05,089 --> 01:03:10,400
Python code you can easily enough write

01:03:08,180 --> 01:03:12,020
Python tests which then themselves test

01:03:10,400 --> 01:03:14,089
operating system function but for

01:03:12,020 --> 01:03:15,680
compiled code I turn first to something

01:03:14,089 --> 01:03:22,329
like American fuzzy life a dedicated

01:03:15,680 --> 01:03:25,280
machine code fuzzing tool so hypothesis

01:03:22,329 --> 01:03:27,799
does not by default test across multiple

01:03:25,280 --> 01:03:29,869
operating systems but if you had a

01:03:27,799 --> 01:03:31,700
function which ran some piece of code on

01:03:29,869 --> 01:03:33,530
multiple operating systems you could

01:03:31,700 --> 01:03:37,190
then use hypothesis to assert that they

01:03:33,530 --> 01:03:38,660
all return the same result I have two

01:03:37,190 --> 01:03:40,280
questions first question is how do you

01:03:38,660 --> 01:03:41,660
convince your teammates to use

01:03:40,280 --> 01:03:44,299
hypothesis if you love it and your

01:03:41,660 --> 01:03:48,440
teammates don't what do you do install

01:03:44,299 --> 01:03:50,569
it first so this one is actually tricky

01:03:48,440 --> 01:03:52,700
the most effective way I've found this

01:03:50,569 --> 01:03:54,559
to migrate just a couple of tests so

01:03:52,700 --> 01:03:56,210
spend an afternoon on it and if you find

01:03:54,559 --> 01:03:59,539
a bug which your teammates believe is a

01:03:56,210 --> 01:04:01,220
bug first get the bug report in then

01:03:59,539 --> 01:04:04,670
tell them you found it with hypothesis

01:04:01,220 --> 01:04:06,619
and my second question is working a lot

01:04:04,670 --> 01:04:07,849
of ml and this is more general testing

01:04:06,619 --> 01:04:09,980
how do you go about testing and machine

01:04:07,849 --> 01:04:12,380
learning stacks and data science stacks

01:04:09,980 --> 01:04:13,880
in general that one is hard right this

01:04:12,380 --> 01:04:16,089
is part of the problem of how do we even

01:04:13,880 --> 01:04:18,260
know what the correct answer is

01:04:16,089 --> 01:04:20,510
sometimes there are properties you can

01:04:18,260 --> 01:04:21,589
check so after each training epoch for

01:04:20,510 --> 01:04:24,410
example you could check that the model

01:04:21,589 --> 01:04:26,059
weights have changed for every layer or

01:04:24,410 --> 01:04:28,099
you could make assertions about the

01:04:26,059 --> 01:04:29,869
balance that probabilities regardless of

01:04:28,099 --> 01:04:32,869
what they end up being must always be

01:04:29,869 --> 01:04:35,150
between zero and one or that adding

01:04:32,869 --> 01:04:36,799
certain desirable features does not

01:04:35,150 --> 01:04:39,140
decrease the score when you classify

01:04:36,799 --> 01:04:41,960
things like that so well you can't test

01:04:39,140 --> 01:04:43,309
the exact expected output you can still

01:04:41,960 --> 01:04:45,680
tell something about often if you

01:04:43,309 --> 01:04:48,770
perturb the input what kind of change do

01:04:45,680 --> 01:04:49,819
you expect in the output especially with

01:04:48,770 --> 01:04:51,619
machine learning that won't always

01:04:49,819 --> 01:04:53,440
indicate you have a bug it might just be

01:04:51,619 --> 01:04:58,010
that you've misunderstood your system

01:04:53,440 --> 01:05:00,400
it's hard we have time for one final

01:04:58,010 --> 01:05:00,400
question

01:05:07,020 --> 01:05:11,820
this is a question on unfastening in

01:05:09,240 --> 01:05:14,220
general like sometimes fuzzing can catch

01:05:11,820 --> 01:05:16,230
a lot of issues but there are rarely the

01:05:14,220 --> 01:05:18,450
producible in production and it can make

01:05:16,230 --> 01:05:20,790
the code much more complex and more

01:05:18,450 --> 01:05:21,840
defensive to basically make testing

01:05:20,790 --> 01:05:23,760
compliance but then the value in

01:05:21,840 --> 01:05:27,960
production is very low what's your

01:05:23,760 --> 01:05:31,680
opinion that sometimes you just don't

01:05:27,960 --> 01:05:33,450
care about certain bugs my instinct

01:05:31,680 --> 01:05:35,869
would always be try to catch that stuff

01:05:33,450 --> 01:05:40,110
when you're validating your inputs so

01:05:35,869 --> 01:05:41,640
whatever the bug is right either it is a

01:05:40,110 --> 01:05:43,740
bug that we care about for whatever

01:05:41,640 --> 01:05:47,280
reason in which case it will be good to

01:05:43,740 --> 01:05:48,630
return an explicit error or my view is

01:05:47,280 --> 01:05:51,030
it's not something we should consider a

01:05:48,630 --> 01:05:54,210
bug at all maybe it's behavior that is

01:05:51,030 --> 01:05:55,440
less than ideal but my view of a bug

01:05:54,210 --> 01:05:56,910
really is that it's something we would

01:05:55,440 --> 01:06:01,619
want to change about our code in order

01:05:56,910 --> 01:06:03,540
to consider it fixed so there are some

01:06:01,619 --> 01:06:05,130
people who dislike hypothesis because it

01:06:03,540 --> 01:06:06,840
finds all kinds of ways to trigger

01:06:05,130 --> 01:06:08,250
exceptions that they just don't want to

01:06:06,840 --> 01:06:09,450
hear about because there are hundreds of

01:06:08,250 --> 01:06:12,180
them and they already have a thousand

01:06:09,450 --> 01:06:13,230
open tickets I'm sympathetic I've been

01:06:12,180 --> 01:06:16,890
there too

01:06:13,230 --> 01:06:18,720
ultimately no testing no analysis no

01:06:16,890 --> 01:06:20,070
correct this technique is actually

01:06:18,720 --> 01:06:23,369
useful if you don't want to act on the

01:06:20,070 --> 01:06:24,720
results so in much the same way as I

01:06:23,369 --> 01:06:26,730
would not say the type checking is

01:06:24,720 --> 01:06:28,320
suitable for every codebase really

01:06:26,730 --> 01:06:31,560
intensive testing is not always suitable

01:06:28,320 --> 01:06:33,210
for every codebase but for when it is I

01:06:31,560 --> 01:06:36,770
hope you consider some of the tools I've

01:06:33,210 --> 01:06:37,900
spoken about today so thanks very much

01:06:36,770 --> 01:06:41,019
[Applause]

01:06:37,900 --> 01:06:41,019

YouTube URL: https://www.youtube.com/watch?v=NT7Gg6MEbZk


