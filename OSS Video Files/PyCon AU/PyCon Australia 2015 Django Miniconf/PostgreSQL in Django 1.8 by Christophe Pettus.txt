Title: PostgreSQL in Django 1.8 by Christophe Pettus
Publication date: 2015-08-06
Playlist: PyCon Australia 2015 Django Miniconf
Description: 
	Django 1.8 adds a whole bunch of cool new features that are specifically designed for PostgreSQL. We'll take a quick tour through them, and show when and how you can use them in real-world applications. We'll also talk about how to get the best performance out of PostgreSQL when using the Django ORM.

PyCon Australia is the national conference for users of the Python Programming Language. In 2015, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

July 31-August 4, Brisbane, Queensland, Australia
Captions: 
	00:00:09,580 --> 00:00:13,470
so how many people use post Chris in

00:00:11,830 --> 00:00:16,030
production right now

00:00:13,470 --> 00:00:18,540
that is within shouting distance of a

00:00:16,030 --> 00:00:22,390
hundred percent yes wise decision

00:00:18,540 --> 00:00:24,910
everybody so what I'm going to talk

00:00:22,390 --> 00:00:28,029
about is specifically new features that

00:00:24,910 --> 00:00:30,490
were introduced in django 1.8 to support

00:00:28,029 --> 00:00:33,130
Postgres in particular needless to say

00:00:30,490 --> 00:00:37,990
given the name of the my company this is

00:00:33,130 --> 00:00:40,360
not a very database agnostic talk so the

00:00:37,990 --> 00:00:43,180
my sequel and by sequel and Oracle

00:00:40,360 --> 00:00:44,680
people can go you know take a nap it'll

00:00:43,180 --> 00:00:46,440
be fine well I'll let you know what I've

00:00:44,680 --> 00:00:50,350
done

00:00:46,440 --> 00:00:52,540
so the the one thing I will talk about

00:00:50,350 --> 00:00:54,100
briefly is 1.7 introduced native

00:00:52,540 --> 00:00:57,040
migrations how many have switched over

00:00:54,100 --> 00:00:59,350
to the new migration architecture yes

00:00:57,040 --> 00:01:00,700
because there's they are like the best

00:00:59,350 --> 00:01:03,970
things ever how many people have used

00:01:00,700 --> 00:01:05,470
the limbic yeah how many people wish

00:01:03,970 --> 00:01:07,060
they had django migration seemed like

00:01:05,470 --> 00:01:07,720
every other framework in the entire

00:01:07,060 --> 00:01:11,830
world

00:01:07,720 --> 00:01:12,939
yeah it's they're really neat and but

00:01:11,830 --> 00:01:14,860
what we're going to talk about the

00:01:12,939 --> 00:01:17,049
payload of the talk as it were is Django

00:01:14,860 --> 00:01:18,759
contributes Chris which is a new module

00:01:17,049 --> 00:01:22,509
that came in and one ate with all sorts

00:01:18,759 --> 00:01:24,490
of really cool stuff so many features so

00:01:22,509 --> 00:01:27,969
little time so I better talk faster okay

00:01:24,490 --> 00:01:31,030
and of course I cannot that I did

00:01:27,969 --> 00:01:33,850
exactly none of this work nothing I I

00:01:31,030 --> 00:01:36,189
think I said mark like two emails with

00:01:33,850 --> 00:01:38,770
ideas and he did all the work so all

00:01:36,189 --> 00:01:41,109
credit to him I'm going to talk about

00:01:38,770 --> 00:01:43,179
migrations first though even though

00:01:41,109 --> 00:01:44,950
they're not post grist specific because

00:01:43,179 --> 00:01:46,030
they're an enabler for certain other

00:01:44,950 --> 00:01:47,679
features that we'll talk about

00:01:46,030 --> 00:01:49,710
specifically indexing on some of the

00:01:47,679 --> 00:01:52,990
cool new types that you have available

00:01:49,710 --> 00:01:54,939
and they're just amazing I just had to

00:01:52,990 --> 00:01:56,950
do an Olympic project so I'm still have

00:01:54,939 --> 00:01:58,869
the scars for that and Olympics fine you

00:01:56,950 --> 00:02:02,319
know but still

00:01:58,869 --> 00:02:04,869
so thanks Andrew for that just a quick

00:02:02,319 --> 00:02:06,280
overview of migrations is that the new

00:02:04,869 --> 00:02:09,700
migrations architecture is built around

00:02:06,280 --> 00:02:11,290
sequence of operations that and each

00:02:09,700 --> 00:02:12,400
operation moves the data back back or

00:02:11,290 --> 00:02:15,520
forward and it's through a schema

00:02:12,400 --> 00:02:16,990
migration timeline there's lots of

00:02:15,520 --> 00:02:18,850
individual operations but they're

00:02:16,990 --> 00:02:20,770
specifically to that we're interested in

00:02:18,850 --> 00:02:25,330
for the purposes of this talk which are

00:02:20,770 --> 00:02:26,590
run SQL and create extension run SQL

00:02:25,330 --> 00:02:28,060
does pretty much

00:02:26,590 --> 00:02:29,739
but you said you might imagine is it

00:02:28,060 --> 00:02:32,470
applies raw SQL directly to the database

00:02:29,739 --> 00:02:33,970
it's the well if we can't figure out any

00:02:32,470 --> 00:02:38,069
other way of getting this migration done

00:02:33,970 --> 00:02:40,450
we use this one operation and

00:02:38,069 --> 00:02:42,160
specifically if you can't if there's

00:02:40,450 --> 00:02:44,980
anything else that you can't do directly

00:02:42,160 --> 00:02:48,450
you use read SQL like creating indexes

00:02:44,980 --> 00:02:53,250
for the new types I'll talk about that

00:02:48,450 --> 00:02:55,690
this this is it from the new module

00:02:53,250 --> 00:02:59,670
contributor trip PostgreSQL it runs a

00:02:55,690 --> 00:03:03,220
create extension command post Chris in

00:02:59,670 --> 00:03:05,079
91 when did extensions come in nine one

00:03:03,220 --> 00:03:07,269
I think um introduced an extension

00:03:05,079 --> 00:03:10,090
architecture to replace the previous

00:03:07,269 --> 00:03:12,420
kind of clumsy way we had for

00:03:10,090 --> 00:03:14,650
introducing new features into Postgres

00:03:12,420 --> 00:03:16,269
create extension is the core command

00:03:14,650 --> 00:03:18,459
that you run inside the database to add

00:03:16,269 --> 00:03:20,019
an extension create extension is a

00:03:18,459 --> 00:03:21,670
django migration operation that

00:03:20,019 --> 00:03:23,410
basically wraps up a create extension

00:03:21,670 --> 00:03:25,030
for you so you don't have to use run SQL

00:03:23,410 --> 00:03:27,640
to do it

00:03:25,030 --> 00:03:30,790
the reason is each store which is a type

00:03:27,640 --> 00:03:32,950
that is exposed as part of the new

00:03:30,790 --> 00:03:34,810
features is an extension you have to

00:03:32,950 --> 00:03:39,670
create it in a database it isn't there

00:03:34,810 --> 00:03:40,870
automatically in core one other thing to

00:03:39,670 --> 00:03:42,400
know about using H store we'll talk

00:03:40,870 --> 00:03:44,139
about this in a bit is every if you use

00:03:42,400 --> 00:03:45,069
H store every single time you connect to

00:03:44,139 --> 00:03:47,019
the database you're going to give an

00:03:45,069 --> 00:03:53,139
extra query as part of the set up

00:03:47,019 --> 00:03:55,090
process so be aware of that so what we

00:03:53,139 --> 00:03:58,030
get in 1:8 are some new field types

00:03:55,090 --> 00:04:00,700
specifically a ray field range field HR

00:03:58,030 --> 00:04:06,329
fields and those are the three those

00:04:00,700 --> 00:04:08,739
three cool so array fields um

00:04:06,329 --> 00:04:10,720
arrays have been in Postgres since ever

00:04:08,739 --> 00:04:13,530
they're first-class types in Postgres

00:04:10,720 --> 00:04:17,320
you can declare a field that's an array

00:04:13,530 --> 00:04:19,000
if you're an extreme database person you

00:04:17,320 --> 00:04:20,979
might call this denormalized I don't

00:04:19,000 --> 00:04:24,729
think anyone is quite that ideologically

00:04:20,979 --> 00:04:26,650
pure about it and up until now there

00:04:24,729 --> 00:04:28,570
were various modules that their

00:04:26,650 --> 00:04:31,060
extensions and various modules like the

00:04:28,570 --> 00:04:32,889
internet that let you grab an array

00:04:31,060 --> 00:04:35,080
field you have an array field in your

00:04:32,889 --> 00:04:36,760
models but a rate the the new array

00:04:35,080 --> 00:04:39,010
field lets you use them directly as part

00:04:36,760 --> 00:04:42,760
of its I guess

00:04:39,010 --> 00:04:44,410
it's a contributor but you know you get

00:04:42,760 --> 00:04:47,410
it when you install Django so close

00:04:44,410 --> 00:04:50,530
enough they map into Python arrays

00:04:47,410 --> 00:04:55,120
Python lists sorry an array guy you can

00:04:50,530 --> 00:04:57,280
tell how old I am and there are

00:04:55,120 --> 00:05:01,060
differences between them something to be

00:04:57,280 --> 00:05:02,830
aware of is Python unlike Python lists

00:05:01,060 --> 00:05:04,780
PostgreSQL arrays are Holman gr of

00:05:02,830 --> 00:05:07,000
homogeneous type and they have a single

00:05:04,780 --> 00:05:09,040
type at the time you declare them so you

00:05:07,000 --> 00:05:10,990
have interets you have character you

00:05:09,040 --> 00:05:13,210
have R char array string arrays you have

00:05:10,990 --> 00:05:17,470
a specific type of array in Postgres so

00:05:13,210 --> 00:05:20,410
Postgres arrays cannot handle one comma

00:05:17,470 --> 00:05:22,810
quote unquote b comma daytime comma this

00:05:20,410 --> 00:05:24,610
come of that you you pick one type and

00:05:22,810 --> 00:05:26,230
you stick with it otherwise but they're

00:05:24,610 --> 00:05:28,960
close enough at analog that what else

00:05:26,230 --> 00:05:33,540
are you going to use in your in your

00:05:28,960 --> 00:05:37,000
Python the other thing is if you use it

00:05:33,540 --> 00:05:38,950
Postgres has old-school traditional

00:05:37,000 --> 00:05:41,730
rectangular multi-dimensional arrays

00:05:38,950 --> 00:05:43,510
they're not they're not lists of lists

00:05:41,730 --> 00:05:46,270
individual entries in the

00:05:43,510 --> 00:05:48,910
multi-dimensional array can be null and

00:05:46,270 --> 00:05:52,480
in in Python they're map to lists of

00:05:48,910 --> 00:05:54,880
lists but they have to be rectangular so

00:05:52,480 --> 00:05:56,230
each individual member has to have if

00:05:54,880 --> 00:05:57,700
you have a multi-dimensional array each

00:05:56,230 --> 00:06:02,410
individual member has to have the same

00:05:57,700 --> 00:06:04,630
size okay so you can declare them using

00:06:02,410 --> 00:06:08,710
the array field the array the array

00:06:04,630 --> 00:06:10,480
field model field and what can you do

00:06:08,710 --> 00:06:11,980
with them well the first thing is we get

00:06:10,480 --> 00:06:15,760
it we now get a double under store

00:06:11,980 --> 00:06:18,310
contains operator it matches the the Ray

00:06:15,760 --> 00:06:20,200
field on the left that if the array

00:06:18,310 --> 00:06:23,520
field on the Left contains all of the

00:06:20,200 --> 00:06:26,710
entries of the list on the right so that

00:06:23,520 --> 00:06:29,710
contains that but that doesn't contain

00:06:26,710 --> 00:06:31,450
that okay basically useful and obviously

00:06:29,710 --> 00:06:33,820
you can have a single value there if you

00:06:31,450 --> 00:06:39,220
want as a either with or without the

00:06:33,820 --> 00:06:42,450
list the in or out of a list and orders

00:06:39,220 --> 00:06:42,450
not important in contains

00:06:43,620 --> 00:06:49,350
if you want to do the reverse operation

00:06:44,730 --> 00:06:51,030
we have contained by Matt is if the list

00:06:49,350 --> 00:06:53,120
of if the list on the right contains all

00:06:51,030 --> 00:06:55,770
the entries of the lifts on the left so

00:06:53,120 --> 00:06:58,110
that's not contained by that but and

00:06:55,770 --> 00:07:01,080
that is not contained by that but that

00:06:58,110 --> 00:07:02,630
is contained by that and again order is

00:07:01,080 --> 00:07:05,430
not important to this one either

00:07:02,630 --> 00:07:09,360
okay that's neat

00:07:05,430 --> 00:07:11,550
there's and there's overlaps which these

00:07:09,360 --> 00:07:14,280
two overlap because they both have an A

00:07:11,550 --> 00:07:15,960
in them but that doesn't overlap because

00:07:14,280 --> 00:07:18,000
that one doesn't have a D it's actually

00:07:15,960 --> 00:07:20,070
the equivalent of double underscore

00:07:18,000 --> 00:07:21,570
contains or double underscore it is

00:07:20,070 --> 00:07:26,490
contained by but this way it's a single

00:07:21,570 --> 00:07:29,730
operation we also have under double or

00:07:26,490 --> 00:07:33,300
square length as LAN which returns the

00:07:29,730 --> 00:07:38,910
length as an integer so if you imagine

00:07:33,300 --> 00:07:40,650
the field winding there that's to notice

00:07:38,910 --> 00:07:42,690
note that if you're doing that if you

00:07:40,650 --> 00:07:43,950
unless you created an expression index

00:07:42,690 --> 00:07:44,280
and we'll talk about how to do that

00:07:43,950 --> 00:07:46,940
later

00:07:44,280 --> 00:07:49,290
this will always be a full table scan on

00:07:46,940 --> 00:07:51,630
it'll have to pick up and rattle every

00:07:49,290 --> 00:07:53,460
single entry in the table that underlies

00:07:51,630 --> 00:07:55,350
that model so you probably don't want to

00:07:53,460 --> 00:08:00,630
do this unless you've created this index

00:07:55,350 --> 00:08:05,850
or it's a very small table there's also

00:08:00,630 --> 00:08:08,220
a transfer a transform where you can say

00:08:05,850 --> 00:08:10,950
array field a double underscore 0 equals

00:08:08,220 --> 00:08:14,520
a which only queries the first element

00:08:10,950 --> 00:08:18,570
of the array if the if any of those

00:08:14,520 --> 00:08:20,160
member the fields do not have R of 0

00:08:18,570 --> 00:08:22,020
well in this case of 0 links but they

00:08:20,160 --> 00:08:24,120
that index is outside the range of the

00:08:22,020 --> 00:08:26,970
particular array value it returns false

00:08:24,120 --> 00:08:32,909
it doesn't throw an error it's probably

00:08:26,970 --> 00:08:34,680
the more useful behavior and you can't

00:08:32,909 --> 00:08:36,330
there's no direct way of specifying the

00:08:34,680 --> 00:08:38,940
program to the index programmatically of

00:08:36,330 --> 00:08:43,830
course so you just use a quark to build

00:08:38,940 --> 00:08:47,490
to build this this part you know so do

00:08:43,830 --> 00:08:49,650
slices do a slice that's 0 or 1 equal

00:08:47,490 --> 00:08:51,300
that same deal always which if the slice

00:08:49,650 --> 00:08:52,930
is invalid for a particular entry it

00:08:51,300 --> 00:08:56,590
always returns false

00:08:52,930 --> 00:08:58,600
and you can then also keep building

00:08:56,590 --> 00:09:00,040
things up like say contains so you can

00:08:58,600 --> 00:09:01,420
build these really wild expressions that

00:09:00,040 --> 00:09:02,890
I'm not sure how much utility they have

00:09:01,420 --> 00:09:07,240
but if you need it

00:09:02,890 --> 00:09:08,770
there it is okay now everything I've

00:09:07,240 --> 00:09:10,390
done so far is great but it's going to

00:09:08,770 --> 00:09:11,980
do a full table scan it's gonna walk

00:09:10,390 --> 00:09:13,900
through the entire table picking up each

00:09:11,980 --> 00:09:16,320
entry and looking at it which if it's a

00:09:13,900 --> 00:09:20,050
10 inch or a 10 row table is not so bad

00:09:16,320 --> 00:09:21,100
but the question is but we want indexes

00:09:20,050 --> 00:09:22,420
on these things because otherwise the

00:09:21,100 --> 00:09:24,970
performance will be terrible once you

00:09:22,420 --> 00:09:28,150
get reaching a table of table of a

00:09:24,970 --> 00:09:29,470
particular of any size so we just say DB

00:09:28,150 --> 00:09:34,410
index equals true like we do for any

00:09:29,470 --> 00:09:34,410
feeling we're done right no sorry

00:09:34,950 --> 00:09:39,370
because anytime you say DB index equals

00:09:37,540 --> 00:09:40,600
true what you get is a standard b-tree

00:09:39,370 --> 00:09:43,030
index in fact this will throw an error

00:09:40,600 --> 00:09:47,350
on in Postgres because you can't create

00:09:43,030 --> 00:09:49,840
a b-tree index on an array any non

00:09:47,350 --> 00:09:52,390
scalar type basically b-tree index is

00:09:49,840 --> 00:09:54,760
useless so let's talk a little bit about

00:09:52,390 --> 00:09:57,790
what we're talking about here which is

00:09:54,760 --> 00:10:00,670
how indexing the kinds of indexes we get

00:09:57,790 --> 00:10:02,200
out of PostgreSQL PostgreSQL supports

00:10:00,670 --> 00:10:03,340
multiple types of index in fact if you

00:10:02,200 --> 00:10:04,810
want you can go and write your own

00:10:03,340 --> 00:10:07,390
there's an API that you can write a

00:10:04,810 --> 00:10:09,070
whole new index type and this is not

00:10:07,390 --> 00:10:11,320
just a type for a new type you've

00:10:09,070 --> 00:10:13,810
defined but a whole new way of indexing

00:10:11,320 --> 00:10:15,130
data so if full-text search didn't exist

00:10:13,810 --> 00:10:17,170
and you wanted to write a full-text

00:10:15,130 --> 00:10:19,420
search index it had a lot of time and

00:10:17,170 --> 00:10:20,860
good c programming skills and infinite

00:10:19,420 --> 00:10:22,420
patience you could go and write this

00:10:20,860 --> 00:10:24,990
index type thank goodness other people

00:10:22,420 --> 00:10:24,990
have done this for us

00:10:26,010 --> 00:10:29,050
generally what you're familiar with what

00:10:27,910 --> 00:10:30,520
people are familiar with is b-tree

00:10:29,050 --> 00:10:33,190
indexes and when people are talking

00:10:30,520 --> 00:10:34,780
about this there's an index on this

00:10:33,190 --> 00:10:36,550
field what they usually mean is a b-tree

00:10:34,780 --> 00:10:38,740
index yeah I'm not going to go into how

00:10:36,550 --> 00:10:40,600
b-tree indexes work this well document

00:10:38,740 --> 00:10:43,180
it online but you basically get them

00:10:40,600 --> 00:10:45,940
there they're Vitry indexes are really

00:10:43,180 --> 00:10:47,410
good they're a very good solution to the

00:10:45,940 --> 00:10:49,810
problems they're fast they're relatively

00:10:47,410 --> 00:10:53,140
compact and they provide ordering you

00:10:49,810 --> 00:10:57,700
can walk a b-tree index for or in

00:10:53,140 --> 00:11:00,130
ascending or descending order but they

00:10:57,700 --> 00:11:02,230
do have some limitations specifically a

00:11:00,130 --> 00:11:05,080
b-tree index requires total ordering in

00:11:02,230 --> 00:11:06,640
impose mathematically this isn't true

00:11:05,080 --> 00:11:08,529
but in Postgres it requires total or

00:11:06,640 --> 00:11:11,350
on a type greater than less than or

00:11:08,529 --> 00:11:13,540
equals all have to be defined on a type

00:11:11,350 --> 00:11:16,300
in order to create a b-tree index on

00:11:13,540 --> 00:11:19,450
them so for integers and floats and

00:11:16,300 --> 00:11:23,110
strings those that's no problem you can

00:11:19,450 --> 00:11:24,970
always compare those types but composite

00:11:23,110 --> 00:11:26,769
types and more exotic types like points

00:11:24,970 --> 00:11:30,220
arrays or a store don't have total

00:11:26,769 --> 00:11:32,950
ordering because what they're there you

00:11:30,220 --> 00:11:34,480
don't have greater than or specially

00:11:32,950 --> 00:11:36,459
greater than or less than you could

00:11:34,480 --> 00:11:38,050
define it to me Arbor to mean something

00:11:36,459 --> 00:11:39,910
arbitrary but it's not clear that would

00:11:38,050 --> 00:11:41,470
be very useful they don't have they're

00:11:39,910 --> 00:11:43,510
not total order type so you can't create

00:11:41,470 --> 00:11:45,610
a b-tree index but they do have other

00:11:43,510 --> 00:11:47,680
operations that you can do on them like

00:11:45,610 --> 00:11:52,750
inclusion does this array have this

00:11:47,680 --> 00:11:55,300
value key containment which in the case

00:11:52,750 --> 00:11:56,649
of if you're a JSON looks JSON or each

00:11:55,300 --> 00:12:00,640
store you can say does this key value

00:11:56,649 --> 00:12:02,920
pair exist in this in this item and so

00:12:00,640 --> 00:12:04,300
for those post Chris defines two

00:12:02,920 --> 00:12:09,339
different index types which are called

00:12:04,300 --> 00:12:10,959
gist engine indexes again I'm not don't

00:12:09,339 --> 00:12:13,300
want to go into the details of what

00:12:10,959 --> 00:12:19,630
about just vs. Jim that's a pretty wild

00:12:13,300 --> 00:12:21,760
hairy feet and top talk but Jin indexes

00:12:19,630 --> 00:12:23,350
are used for types of basically first

00:12:21,760 --> 00:12:24,640
level of approximation if the actual

00:12:23,350 --> 00:12:26,529
authors of this code were here they'd be

00:12:24,640 --> 00:12:29,380
throwing things at me at this point but

00:12:26,529 --> 00:12:30,910
let's just say just in Jin indexes are

00:12:29,380 --> 00:12:32,079
for the types that could take keys and

00:12:30,910 --> 00:12:34,329
values if you were here for the last

00:12:32,079 --> 00:12:36,220
talk and heard about inverted index

00:12:34,329 --> 00:12:38,199
that's what a Jin index is it's a

00:12:36,220 --> 00:12:41,350
general in fact what Jin stands for

00:12:38,199 --> 00:12:43,329
generalized inverted index so that it

00:12:41,350 --> 00:12:45,940
contains keys and values like arrays

00:12:43,329 --> 00:12:48,820
which are all values no keys but same

00:12:45,940 --> 00:12:52,480
principle or each store or JSON B Jin

00:12:48,820 --> 00:12:54,430
indexes are what you want for four types

00:12:52,480 --> 00:12:56,740
that partition a mathematical space you

00:12:54,430 --> 00:12:59,949
can imagine a line is being broken up by

00:12:56,740 --> 00:13:06,279
ranges or a plane is broken up by points

00:12:59,949 --> 00:13:07,540
or rectangles you use it just index the

00:13:06,279 --> 00:13:08,980
good part about these is you don't

00:13:07,540 --> 00:13:10,510
really have to understand all this stuff

00:13:08,980 --> 00:13:12,399
you just you know the rights index

00:13:10,510 --> 00:13:13,959
create them they'll accelerate the right

00:13:12,399 --> 00:13:17,339
set of operators for you so that's the

00:13:13,959 --> 00:13:21,100
good part so indexing array fields

00:13:17,339 --> 00:13:23,470
arrays support gene indexes

00:13:21,100 --> 00:13:27,190
it accelerates these operations contains

00:13:23,470 --> 00:13:28,480
contained by an overlaps it doesn't help

00:13:27,190 --> 00:13:30,850
with late with length or slice

00:13:28,480 --> 00:13:32,560
operations though those are not indexed

00:13:30,850 --> 00:13:34,570
by the by a gene operation we'll talk

00:13:32,560 --> 00:13:39,820
about what you want to do if you want

00:13:34,570 --> 00:13:43,090
that what if what the the sequel looks

00:13:39,820 --> 00:13:44,860
like is you create it using say if

00:13:43,090 --> 00:13:46,390
you're used to the standards in text you

00:13:44,860 --> 00:13:47,920
just say at model paren field close

00:13:46,390 --> 00:13:50,860
brain you drop this a little bit extra

00:13:47,920 --> 00:13:52,870
here using gin field and it'll go away

00:13:50,860 --> 00:13:54,910
for a while maybe a long while if it's a

00:13:52,870 --> 00:13:58,810
big field and come back and now you have

00:13:54,910 --> 00:14:01,960
an index genetics is can be pretty large

00:13:58,810 --> 00:14:04,120
they're actually a b-tree of B trees and

00:14:01,960 --> 00:14:05,680
they tend to grow both with the number

00:14:04,120 --> 00:14:08,740
of the number of rows or indexing

00:14:05,680 --> 00:14:11,170
obviously and how many unique values it

00:14:08,740 --> 00:14:13,180
has to index if you have a lot of

00:14:11,170 --> 00:14:15,760
entropy in your data if like every row

00:14:13,180 --> 00:14:18,940
is its own field the gin index could be

00:14:15,760 --> 00:14:21,220
relatively large gin indexes can be

00:14:18,940 --> 00:14:23,830
quite small if you for example you have

00:14:21,220 --> 00:14:25,930
an array you know you have an array in

00:14:23,830 --> 00:14:27,670
every row but there are only 12 unique

00:14:25,930 --> 00:14:29,140
values across the entire table the

00:14:27,670 --> 00:14:32,890
genetics will be rolled will be much

00:14:29,140 --> 00:14:34,900
smaller for that it should be also noted

00:14:32,890 --> 00:14:36,670
they're not free to update they are kind

00:14:34,900 --> 00:14:39,640
of expensive to update as compared to a

00:14:36,670 --> 00:14:43,060
b-tree index so don't create one unless

00:14:39,640 --> 00:14:44,860
you need it you in development or in

00:14:43,060 --> 00:14:46,240
your staging system experimentally

00:14:44,860 --> 00:14:48,910
create one and see what kind of speed

00:14:46,240 --> 00:14:51,970
ups you get so if you have a small table

00:14:48,910 --> 00:14:53,650
and I don't have the idiosyncratic

00:14:51,970 --> 00:14:56,350
definition for small you know a hundred

00:14:53,650 --> 00:14:57,460
rows a thousand rows and thousand rows

00:14:56,350 --> 00:14:59,380
you were maybe getting into the space

00:14:57,460 --> 00:15:00,550
where the index could be useful but if

00:14:59,380 --> 00:15:07,030
you have ten rows of the table

00:15:00,550 --> 00:15:09,250
you don't need an index now let's say

00:15:07,030 --> 00:15:11,530
you want to index length this is kind of

00:15:09,250 --> 00:15:13,000
a specialized thing I'm mostly doing

00:15:11,530 --> 00:15:14,290
this because it introduces the idea of

00:15:13,000 --> 00:15:17,650
how to do a functional index in this

00:15:14,290 --> 00:15:20,020
regard you can create an index on an

00:15:17,650 --> 00:15:22,600
expression in PostgreSQL it doesn't have

00:15:20,020 --> 00:15:26,290
to be a single unique field value and

00:15:22,600 --> 00:15:28,150
that's what we're doing here we say

00:15:26,290 --> 00:15:29,680
we're creating an index that's a b-tree

00:15:28,150 --> 00:15:32,560
index because we're indexing the length

00:15:29,680 --> 00:15:34,990
of the array which is a scalar integer

00:15:32,560 --> 00:15:36,339
so no big deal creamy tree you notice

00:15:34,990 --> 00:15:37,810
there two parentheses here instead of

00:15:36,339 --> 00:15:39,459
one the two parentheses are the tip-off

00:15:37,810 --> 00:15:40,720
to post Chris that there's that what

00:15:39,459 --> 00:15:43,269
we're doing is an expression not a

00:15:40,720 --> 00:15:46,720
single value post Chris's get the length

00:15:43,269 --> 00:15:48,490
of an array field is array length and we

00:15:46,720 --> 00:15:50,410
say field comma 1 that comma one is

00:15:48,490 --> 00:15:52,389
which dimension in the array we're

00:15:50,410 --> 00:15:54,399
looking at again post Chris will raise a

00:15:52,389 --> 00:15:56,189
rectangular so we get so it's a single

00:15:54,399 --> 00:15:58,600
value for whichever dimension we go

00:15:56,189 --> 00:16:01,420
everything in post Chris arrays are also

00:15:58,600 --> 00:16:03,399
one base not zero based which is a

00:16:01,420 --> 00:16:04,480
source of endless amusement if you

00:16:03,399 --> 00:16:08,829
constantly switching back and forth

00:16:04,480 --> 00:16:11,439
between pi cat python and Postgres so

00:16:08,829 --> 00:16:14,139
this is just a reminder that the first

00:16:11,439 --> 00:16:18,579
element of every post Chris array is is

00:16:14,139 --> 00:16:21,879
bracket 1 not bracket 0 if you want to

00:16:18,579 --> 00:16:23,769
index slices you pick the slice you want

00:16:21,879 --> 00:16:27,100
to index and create an expression feel

00:16:23,769 --> 00:16:29,470
about that if you're thinking this seems

00:16:27,100 --> 00:16:31,180
of limited utility unless I just happen

00:16:29,470 --> 00:16:34,480
to be querying the array links all the

00:16:31,180 --> 00:16:36,009
time you're probably right but this kind

00:16:34,480 --> 00:16:38,379
of but these kinds of expression indexes

00:16:36,009 --> 00:16:40,600
can be very useful if you're routinely

00:16:38,379 --> 00:16:42,610
doing queries on an expression a

00:16:40,600 --> 00:16:44,889
particular expression post Chris is

00:16:42,610 --> 00:16:46,509
pretty smart and it'll figure out the

00:16:44,889 --> 00:16:50,319
truth at what you're the query is this

00:16:46,509 --> 00:16:54,360
that you're using this expression in the

00:16:50,319 --> 00:16:56,500
query and will use the index instead and

00:16:54,360 --> 00:17:00,610
oh by the way did I mention that they're

00:16:56,500 --> 00:17:02,680
one based so while I use array fields

00:17:00,610 --> 00:17:05,199
now that we've got them what do we do

00:17:02,680 --> 00:17:06,399
with them well the first thing is you

00:17:05,199 --> 00:17:07,689
want to put an array in the database

00:17:06,399 --> 00:17:09,280
frequently you're presented with an

00:17:07,689 --> 00:17:11,679
array as underlying data that's its

00:17:09,280 --> 00:17:14,860
sample data that you collected or some

00:17:11,679 --> 00:17:17,439
or its data from an instrument that

00:17:14,860 --> 00:17:20,709
comes in as an array so just store it is

00:17:17,439 --> 00:17:22,299
what it is I would say the thing I use

00:17:20,709 --> 00:17:24,010
the most for is a replacement for a many

00:17:22,299 --> 00:17:26,399
to many table here's an example of that

00:17:24,010 --> 00:17:28,720
is that in your typical you know

00:17:26,399 --> 00:17:30,760
imaginable social networking application

00:17:28,720 --> 00:17:36,039
you have things and people and people

00:17:30,760 --> 00:17:37,390
like things if the the way anybody would

00:17:36,039 --> 00:17:38,830
do this is they create a mini too many

00:17:37,390 --> 00:17:41,049
table in the middle well now you have

00:17:38,830 --> 00:17:44,740
you have a billion people and 10 billion

00:17:41,049 --> 00:17:45,760
things and you have a x times y many too

00:17:44,740 --> 00:17:47,620
many table

00:17:45,760 --> 00:17:50,559
ooh that doesn't sound very good

00:17:47,620 --> 00:17:52,780
suddenly you have a you know 2.5

00:17:50,559 --> 00:17:54,570
trillion row many-to-many table that

00:17:52,780 --> 00:17:57,610
will be slow

00:17:54,570 --> 00:17:57,910
you know so so please don't cook you

00:17:57,610 --> 00:18:00,190
know

00:17:57,910 --> 00:18:01,750
calling up your DBA and saying how can I

00:18:00,190 --> 00:18:05,470
make that run fast the answer is you

00:18:01,750 --> 00:18:08,350
can't um but generally people don't like

00:18:05,470 --> 00:18:11,080
that many individual items yeah let's

00:18:08,350 --> 00:18:12,970
say a thousand and that many and a

00:18:11,080 --> 00:18:15,460
single item may not be liked by that

00:18:12,970 --> 00:18:18,790
many people let's say ten thousand in

00:18:15,460 --> 00:18:20,470
that case just sickly the array of who

00:18:18,790 --> 00:18:25,360
likes what and what people like and what

00:18:20,470 --> 00:18:28,419
who likes this in an array and in index

00:18:25,360 --> 00:18:30,280
that field much faster would I actually

00:18:28,419 --> 00:18:33,790
build Facebook this way of course that

00:18:30,280 --> 00:18:36,010
David you do ultimate limits of scaling

00:18:33,790 --> 00:18:38,260
but to replace a really big many-to-many

00:18:36,010 --> 00:18:43,630
table this can be a very very useful

00:18:38,260 --> 00:18:45,460
thing also occasionally you want to

00:18:43,630 --> 00:18:47,500
denormalize and store the results of an

00:18:45,460 --> 00:18:49,480
expensive query for example you may

00:18:47,500 --> 00:18:51,760
maintain this many-to-many table but

00:18:49,480 --> 00:18:54,730
keep intermediate results in the like

00:18:51,760 --> 00:18:57,730
the last 25 things someone liked in an

00:18:54,730 --> 00:18:59,049
in an array for fast display do proceed

00:18:57,730 --> 00:19:00,760
with caution here because you don't want

00:18:59,049 --> 00:19:02,260
to go crazy on denormalization that can

00:19:00,760 --> 00:19:06,820
get you into trouble but that is one

00:19:02,260 --> 00:19:07,990
very good use for an array field okay so

00:19:06,820 --> 00:19:14,200
each store fields how many people have

00:19:07,990 --> 00:19:16,840
ever used H store and Postgres the this

00:19:14,200 --> 00:19:18,340
will it's funny because each sort of

00:19:16,840 --> 00:19:21,130
like nobody knew about it and now it's

00:19:18,340 --> 00:19:22,960
obsolete it's kind of but but it right

00:19:21,130 --> 00:19:24,669
now is the time to go and use H store

00:19:22,960 --> 00:19:26,380
everybody run out and add an H store

00:19:24,669 --> 00:19:28,090
field in your one point native

00:19:26,380 --> 00:19:32,530
application and then replace it with

00:19:28,090 --> 00:19:35,470
JSON be H stores been around for quite

00:19:32,530 --> 00:19:37,540
some time it's a semi built-in hash data

00:19:35,470 --> 00:19:41,740
store that's what the H stands for is

00:19:37,540 --> 00:19:44,830
it's a hash it's like a dict but it only

00:19:41,740 --> 00:19:47,290
takes strings as keys and values and so

00:19:44,830 --> 00:19:53,320
it's one it's a single level string key

00:19:47,290 --> 00:19:55,120
string value any number of pairs pre

00:19:53,320 --> 00:19:56,740
json it was the only way of storing this

00:19:55,120 --> 00:19:58,179
kind of unstructured data in PostgreSQL

00:19:56,740 --> 00:19:59,620
unless you turned it in you know unless

00:19:58,179 --> 00:20:01,120
you blob a fight in turned into

00:19:59,620 --> 00:20:02,590
string or something in some exotic

00:20:01,120 --> 00:20:04,330
format but it's the only built-in way

00:20:02,590 --> 00:20:09,880
that post Chris actually could analyze

00:20:04,330 --> 00:20:11,290
the innards of you have to install it in

00:20:09,880 --> 00:20:12,400
the Postgres database it's not part of

00:20:11,290 --> 00:20:16,120
core if your honor

00:20:12,400 --> 00:20:18,760
um Amazon RDS its installed for you it's

00:20:16,120 --> 00:20:21,580
not hard to install it's like on Debian

00:20:18,760 --> 00:20:23,350
the standard community Debian packages

00:20:21,580 --> 00:20:29,140
include contraband it's a create

00:20:23,350 --> 00:20:30,940
extension operation and the contribute

00:20:29,140 --> 00:20:32,679
puskás comes with an H store extension

00:20:30,940 --> 00:20:34,960
migration operation to its sort for you

00:20:32,679 --> 00:20:36,730
so you created empty operation an empty

00:20:34,960 --> 00:20:42,030
migration drop that extension into it

00:20:36,730 --> 00:20:45,429
you're done one thing that I noted it is

00:20:42,030 --> 00:20:47,080
because it's created every type in

00:20:45,429 --> 00:20:50,590
Postgres has the 32 bit number called

00:20:47,080 --> 00:20:52,630
the oeid the object identifier psycho PG

00:20:50,590 --> 00:20:55,330
to the interface library inside of

00:20:52,630 --> 00:20:57,160
python needs to know that OID so every

00:20:55,330 --> 00:20:59,320
time it connects once you've installed

00:20:57,160 --> 00:21:02,800
each store it has to send a query over

00:20:59,320 --> 00:21:04,300
to get the OID if so if you're using any

00:21:02,800 --> 00:21:05,650
kind of connection pooling or caching

00:21:04,300 --> 00:21:07,720
including the relatively new create

00:21:05,650 --> 00:21:10,240
connection reuse stuff that amarak did

00:21:07,720 --> 00:21:12,010
you're okay but just be aware that

00:21:10,240 --> 00:21:13,750
there's that tiny little bit of extra

00:21:12,010 --> 00:21:19,179
overhead that it's injected in by using

00:21:13,750 --> 00:21:22,600
a store in pump on the Python side its

00:21:19,179 --> 00:21:24,309
represent as a dict rule the big rule is

00:21:22,600 --> 00:21:26,800
the keys and values must be strings so

00:21:24,309 --> 00:21:28,770
no hierarchies no objects no nothing

00:21:26,800 --> 00:21:31,210
just keys just strings on both sides

00:21:28,770 --> 00:21:32,890
it's translated from to and from the

00:21:31,210 --> 00:21:35,800
database encoding automatically as you

00:21:32,890 --> 00:21:37,450
go in which means everybody is using

00:21:35,800 --> 00:21:41,309
utf-8 in their post course database

00:21:37,450 --> 00:21:41,309
right yes please say yes

00:21:41,610 --> 00:21:45,910
so what can you do so you created this

00:21:44,380 --> 00:21:47,530
each store field what can you do to it

00:21:45,910 --> 00:21:51,010
well you can do contained and contained

00:21:47,530 --> 00:21:54,700
by it works just like arrays only both

00:21:51,010 --> 00:21:56,740
the key and value have to match we also

00:21:54,700 --> 00:21:58,150
have has key which matches fields

00:21:56,740 --> 00:21:59,410
containing a particular keys so if you

00:21:58,150 --> 00:22:02,760
want to query for everything that has

00:21:59,410 --> 00:22:07,840
the key tag or something you can do that

00:22:02,760 --> 00:22:10,210
and has keys matches fields containing

00:22:07,840 --> 00:22:12,640
all of the keys there is a post Chris

00:22:10,210 --> 00:22:14,110
operation for any of the keys right now

00:22:12,640 --> 00:22:16,030
that's not exposed

00:22:14,110 --> 00:22:21,640
on the query set on query set operations

00:22:16,030 --> 00:22:23,410
but there's also keys to match the list

00:22:21,640 --> 00:22:24,940
of keys in the field it's generally used

00:22:23,410 --> 00:22:27,610
with other transforms so you say like

00:22:24,940 --> 00:22:31,090
keys filter keys which gives you an

00:22:27,610 --> 00:22:33,130
array which overlaps this so this isn't

00:22:31,090 --> 00:22:36,429
a way of saying do any of these keys

00:22:33,130 --> 00:22:38,049
exist in this field less efficiently

00:22:36,429 --> 00:22:40,059
than using the direct operation that's

00:22:38,049 --> 00:22:42,370
okay we'll get there

00:22:40,059 --> 00:22:44,230
and you also get values that works the

00:22:42,370 --> 00:22:49,330
same way only for the value side of the

00:22:44,230 --> 00:22:51,809
of the relation of the east or for

00:22:49,330 --> 00:22:54,220
indexing you create a gin and Nick's

00:22:51,809 --> 00:22:54,789
this indexes both the keys and the

00:22:54,220 --> 00:22:58,150
values

00:22:54,789 --> 00:23:02,260
so those tokens are both stored in the

00:22:58,150 --> 00:23:04,120
index and it accelerates contains has

00:23:02,260 --> 00:23:07,780
key it has keys but interestingly enough

00:23:04,120 --> 00:23:10,350
they're not contained by so but it's but

00:23:07,780 --> 00:23:14,590
these operations are accelerated by that

00:23:10,350 --> 00:23:18,820
by the index so why would you use an H

00:23:14,590 --> 00:23:21,340
store field well it's great for storing

00:23:18,820 --> 00:23:23,110
very rare attributes this this often

00:23:21,340 --> 00:23:24,340
comes up is somebody you designed your

00:23:23,110 --> 00:23:26,169
database and everything's fine and then

00:23:24,340 --> 00:23:29,260
the business people come and say you

00:23:26,169 --> 00:23:31,480
know like 2% of our customers need this

00:23:29,260 --> 00:23:33,309
field and then somebody comes on later

00:23:31,480 --> 00:23:35,740
and says well point 5 percent of our

00:23:33,309 --> 00:23:37,120
customers need this other field now of

00:23:35,740 --> 00:23:38,679
course you can roll out a schema

00:23:37,120 --> 00:23:40,630
migration and add those two fields which

00:23:38,679 --> 00:23:41,950
are only used for those customers but

00:23:40,630 --> 00:23:44,340
you're starting to get this hint that

00:23:41,950 --> 00:23:48,850
marketing is gonna say this to you a lot

00:23:44,340 --> 00:23:50,409
you can um if so basically if you have

00:23:48,850 --> 00:23:52,510
fields and there's more than one of them

00:23:50,409 --> 00:23:54,220
that's gonna be no like 95 percent of

00:23:52,510 --> 00:23:57,690
time maybe just create one each store

00:23:54,220 --> 00:24:00,190
field and make life easier on yourself

00:23:57,690 --> 00:24:02,289
one thing to remember though is no

00:24:00,190 --> 00:24:05,710
fields do take zero disk space in

00:24:02,289 --> 00:24:08,409
Postgres so you so you're not actually

00:24:05,710 --> 00:24:10,450
saving any disk space by doing this but

00:24:08,409 --> 00:24:12,250
you may be saving yourself having to do

00:24:10,450 --> 00:24:13,659
a schema migration every time somebody

00:24:12,250 --> 00:24:16,840
comes up with one of these new things

00:24:13,659 --> 00:24:19,360
they want a store of course if 20% of

00:24:16,840 --> 00:24:20,650
the customers of the Rideau by customer

00:24:19,360 --> 00:24:22,270
of course I mean rows in a particular

00:24:20,650 --> 00:24:23,830
table are going to have this field

00:24:22,270 --> 00:24:25,270
you're almost certainly better creating

00:24:23,830 --> 00:24:28,290
a separate relational field for it

00:24:25,270 --> 00:24:28,290
rather than

00:24:28,690 --> 00:24:34,630
rather than going the east or route the

00:24:32,350 --> 00:24:37,120
other thing is if the user can define

00:24:34,630 --> 00:24:38,559
new attributes on rows but you don't

00:24:37,120 --> 00:24:41,529
want to roll out a schema might have the

00:24:38,559 --> 00:24:43,779
user modifying your schema so for

00:24:41,529 --> 00:24:45,909
example if you have a let's say you have

00:24:43,779 --> 00:24:48,399
a packaged accounting application that's

00:24:45,909 --> 00:24:51,220
that's a web-based application and you

00:24:48,399 --> 00:24:53,200
let the user create five or ten or

00:24:51,220 --> 00:24:55,149
however many fields on their customer

00:24:53,200 --> 00:24:56,710
records you don't want to roll out a new

00:24:55,149 --> 00:24:58,720
schema migration every time some user

00:24:56,710 --> 00:25:00,580
somewhere says I want to add this

00:24:58,720 --> 00:25:02,980
particular tax code or something to this

00:25:00,580 --> 00:25:04,570
customer but you could create an each

00:25:02,980 --> 00:25:06,789
store field that is all of the user

00:25:04,570 --> 00:25:08,649
defined attributes so that's one that's

00:25:06,789 --> 00:25:13,960
a very common and very useful use of a

00:25:08,649 --> 00:25:15,250
store the reality is in Greenfield

00:25:13,960 --> 00:25:17,020
developments largely been replaced by

00:25:15,250 --> 00:25:18,640
JSON which does the same thing but it

00:25:17,020 --> 00:25:22,360
more flexibly and has more operations

00:25:18,640 --> 00:25:29,350
and you don't have to install it and

00:25:22,360 --> 00:25:31,600
we'll talk about each store later but

00:25:29,350 --> 00:25:33,370
there's no JSON field type in 1.8 so if

00:25:31,600 --> 00:25:35,909
you need it eats or if you need a store

00:25:33,370 --> 00:25:39,880
right away there it is waiting for you

00:25:35,909 --> 00:25:41,649
or you're plugging Jango on top of an

00:25:39,880 --> 00:25:48,370
existing database with H store of which

00:25:41,649 --> 00:25:50,140
there are a lot rig fields so Postgres

00:25:48,370 --> 00:25:53,640
has native range types a relatively new

00:25:50,140 --> 00:25:56,080
feature in Postgres but they are so cool

00:25:53,640 --> 00:25:59,380
reach type span a range of scalar types

00:25:56,080 --> 00:26:02,980
so for example 1 comma 8 has all those

00:25:59,380 --> 00:26:07,029
integers in it or they can also be

00:26:02,980 --> 00:26:09,250
exclusive so this one is up to the a the

00:26:07,029 --> 00:26:11,860
Parenti bracket is up to it including or

00:26:09,250 --> 00:26:17,110
down to and including the paren is up to

00:26:11,860 --> 00:26:19,870
but not including so that's Purdue so

00:26:17,110 --> 00:26:23,830
that so and the default if you don't do

00:26:19,870 --> 00:26:27,480
anything else is is down to and

00:26:23,830 --> 00:26:27,480
including but up to and not including

00:26:28,409 --> 00:26:33,460
you can also emit a bound to mean all

00:26:31,240 --> 00:26:36,850
values greater than or all values less

00:26:33,460 --> 00:26:38,529
than so and also some types like in the

00:26:36,850 --> 00:26:40,420
end with in Postgres that is have a

00:26:38,529 --> 00:26:43,090
special infinity value

00:26:40,420 --> 00:26:48,340
dates in particular have infinity as of

00:26:43,090 --> 00:26:51,850
a negative infinity as valid values all

00:26:48,340 --> 00:26:55,000
of this has materialized in Python by a

00:26:51,850 --> 00:26:56,980
psycho PG 2 type called range which is a

00:26:55,000 --> 00:26:59,200
base type that has various subtypes to

00:26:56,980 --> 00:27:00,820
handle specific things like integer

00:26:59,200 --> 00:27:02,830
ranges and date ranges and date/time

00:27:00,820 --> 00:27:04,270
ranges in day time with timestamp ranges

00:27:02,830 --> 00:27:05,650
and by the way you should always be

00:27:04,270 --> 00:27:11,170
using date/time with time stamp never

00:27:05,650 --> 00:27:13,150
use bear tape date/time so what we get

00:27:11,170 --> 00:27:14,620
out of the box and 1/8 is integer

00:27:13,150 --> 00:27:18,100
arrangement begins arrange for bit

00:27:14,620 --> 00:27:20,140
integers 8-bit integers floats date/time

00:27:18,100 --> 00:27:24,150
which is times that which is with

00:27:20,140 --> 00:27:24,150
timestamp thank goodness and date range

00:27:24,540 --> 00:27:28,210
we have contains and contained by and

00:27:26,950 --> 00:27:32,830
overlaps which works just the way you'd

00:27:28,210 --> 00:27:34,360
expect we also have these fully greater

00:27:32,830 --> 00:27:35,770
than employee less than if both the

00:27:34,360 --> 00:27:37,240
upper bound and lower bounds of field or

00:27:35,770 --> 00:27:39,130
less than or greater than the comparison

00:27:37,240 --> 00:27:42,130
value so if it's completely disjoint one

00:27:39,130 --> 00:27:43,419
way or the other you can match against

00:27:42,130 --> 00:27:47,320
fully greater than or fully less than

00:27:43,419 --> 00:27:49,299
and adjacent to matches if put up

00:27:47,320 --> 00:27:54,190
together they exactly there is no gap

00:27:49,299 --> 00:27:56,230
between them nor it nor there is not no

00:27:54,190 --> 00:27:57,940
gap or any overlap this is one place

00:27:56,230 --> 00:27:59,710
where it's important to understand the

00:27:57,940 --> 00:28:04,780
difference between an open and closed

00:27:59,710 --> 00:28:10,020
range because 1 comma 8 close 1 comma 8

00:28:04,780 --> 00:28:13,540
open range with the with paren will

00:28:10,020 --> 00:28:17,260
includes 8 or excuse me excludes 8 so

00:28:13,540 --> 00:28:19,780
but with a bracket it'll include 8 and

00:28:17,260 --> 00:28:22,600
so the compare this adjacent to will

00:28:19,780 --> 00:28:27,760
operate differently in those cases so be

00:28:22,600 --> 00:28:29,440
aware of that we have then not less than

00:28:27,760 --> 00:28:32,130
and not greater than which work as

00:28:29,440 --> 00:28:32,130
described

00:28:34,450 --> 00:28:40,420
and indexing them so indexes range field

00:28:38,470 --> 00:28:42,580
support gist indexes being as they are

00:28:40,420 --> 00:28:45,190
spade they partition the line align up

00:28:42,580 --> 00:28:47,320
into space which you use just by

00:28:45,190 --> 00:28:51,070
dropping the word gist in there it's

00:28:47,320 --> 00:28:56,170
easy and accelerates everything we've

00:28:51,070 --> 00:28:58,170
talked about whoo that's cool so why

00:28:56,170 --> 00:29:01,809
would you use a range shovel here and

00:28:58,170 --> 00:29:04,570
why what good why not just use high and

00:29:01,809 --> 00:29:08,559
low and you know deal with us well

00:29:04,570 --> 00:29:10,120
here's a really hard problem so the

00:29:08,559 --> 00:29:11,559
hotel booking problem don't allow two

00:29:10,120 --> 00:29:13,420
bookings to be inserted in database for

00:29:11,559 --> 00:29:15,250
the same room where the the reservation

00:29:13,420 --> 00:29:16,660
dates overlap you want a constraint

00:29:15,250 --> 00:29:19,210
violation when this comes in like a

00:29:16,660 --> 00:29:20,770
unique constraint violation how would

00:29:19,210 --> 00:29:22,870
you how can you do this in traditional

00:29:20,770 --> 00:29:24,540
SQL and the answer is you can't without

00:29:22,870 --> 00:29:26,860
writing a stored procedure

00:29:24,540 --> 00:29:28,120
there's no way to express that with

00:29:26,860 --> 00:29:30,640
traditional unique constraints because

00:29:28,120 --> 00:29:33,390
everything can be different no single

00:29:30,640 --> 00:29:36,000
thing is no the two of the two rate

00:29:33,390 --> 00:29:38,080
things are inserting or not aren't

00:29:36,000 --> 00:29:40,720
identical because there could be some

00:29:38,080 --> 00:29:42,400
overlap the only thing that would be the

00:29:40,720 --> 00:29:44,110
same as the the room but you want this

00:29:42,400 --> 00:29:47,410
to have the same room be able to book

00:29:44,110 --> 00:29:49,179
more than one time fortunately Postgres

00:29:47,410 --> 00:29:50,500
has a feature that supported that will

00:29:49,179 --> 00:29:52,330
let you do this it's called constraint

00:29:50,500 --> 00:29:53,830
exclusion it's also relatively new came

00:29:52,330 --> 00:29:58,510
in at the same time as range types and

00:29:53,830 --> 00:30:00,970
it's really neat it's a generalization

00:29:58,510 --> 00:30:03,580
of unique you can think of unique as

00:30:00,970 --> 00:30:05,260
being a way of saying if if an entry

00:30:03,580 --> 00:30:07,660
already exists in this index for this

00:30:05,260 --> 00:30:11,700
key and I try to put in another entry

00:30:07,660 --> 00:30:13,960
for this key throw an error constraint a

00:30:11,700 --> 00:30:18,070
constrain exclusion extends that so

00:30:13,960 --> 00:30:19,750
there more than one key value saying

00:30:18,070 --> 00:30:21,670
basically don't allow to equal entries

00:30:19,750 --> 00:30:25,000
based on this set of comparison

00:30:21,670 --> 00:30:28,420
operators not just equality in to the

00:30:25,000 --> 00:30:31,300
table any index supported boolean

00:30:28,420 --> 00:30:34,090
predicates so any Indian operation that

00:30:31,300 --> 00:30:35,650
returns a boolean can be used in the

00:30:34,090 --> 00:30:39,280
this constraint and they're ANDed

00:30:35,650 --> 00:30:42,670
together but there's a catch which is it

00:30:39,280 --> 00:30:45,100
has to be a single index and since range

00:30:42,670 --> 00:30:47,770
types require adjust index the index has

00:30:45,100 --> 00:30:49,270
to be a just index but

00:30:47,770 --> 00:30:52,510
simple scalar values like the room

00:30:49,270 --> 00:30:54,520
number art don't have just indexing by

00:30:52,510 --> 00:30:56,080
default so it seems like oh great I just

00:30:54,520 --> 00:30:57,760
sold you this great feature now we can't

00:30:56,080 --> 00:30:59,980
use it

00:30:57,760 --> 00:31:02,800
fortunately there is a contribute in

00:30:59,980 --> 00:31:04,840
Postgres that allows called b-tree gist

00:31:02,800 --> 00:31:07,270
that allows you to do create gifts

00:31:04,840 --> 00:31:08,710
indexes on simple types it's an

00:31:07,270 --> 00:31:10,120
extension it's part of contribs so if

00:31:08,710 --> 00:31:12,040
you're using like debian packaging at

00:31:10,120 --> 00:31:13,660
all it's there for you it has to be

00:31:12,040 --> 00:31:15,040
installed with the database but it ships

00:31:13,660 --> 00:31:16,780
with PostgreSQL this isn't something you

00:31:15,040 --> 00:31:19,180
have to go google up on the internet to

00:31:16,780 --> 00:31:20,500
find so if you use the create extension

00:31:19,180 --> 00:31:23,380
migration operation you can just just

00:31:20,500 --> 00:31:26,670
add it to your database so let's so how

00:31:23,380 --> 00:31:29,500
would we do this so let's take a look we

00:31:26,670 --> 00:31:32,920
import the bottles import the date range

00:31:29,500 --> 00:31:36,400
field and we create a booking seems

00:31:32,920 --> 00:31:38,020
pretty normal and this is what we get

00:31:36,400 --> 00:31:41,740
out of it we get the automatically

00:31:38,020 --> 00:31:45,370
created primary key we get the room and

00:31:41,740 --> 00:31:48,700
we get a date range ooh that's nice no

00:31:45,370 --> 00:31:52,930
no and we get a primary key there so

00:31:48,700 --> 00:31:56,380
what you'd expect we create this

00:31:52,930 --> 00:31:58,750
extension which this happens and now we

00:31:56,380 --> 00:32:03,040
create the separate index of consumer

00:31:58,750 --> 00:32:04,960
constraint so with the syntax is add and

00:32:03,040 --> 00:32:06,520
then the constraint and the constraint

00:32:04,960 --> 00:32:08,770
looks like this you say exclude which

00:32:06,520 --> 00:32:10,900
means this exclusive X using just just

00:32:08,770 --> 00:32:14,170
like we do them before room with equal

00:32:10,900 --> 00:32:16,240
date with at this switches overlap which

00:32:14,170 --> 00:32:18,760
is post Christa's overlap operator so

00:32:16,240 --> 00:32:20,710
what we're saying here is I want to

00:32:18,760 --> 00:32:23,440
create a constraint index and the if the

00:32:20,710 --> 00:32:26,560
room is equal and the dates overlap

00:32:23,440 --> 00:32:29,560
that's a match and only allow one entry

00:32:26,560 --> 00:32:31,240
in the entire table like this if I try

00:32:29,560 --> 00:32:34,870
to put another one in and that matches

00:32:31,240 --> 00:32:38,770
give an error people basically with me

00:32:34,870 --> 00:32:42,790
so far mostly mostly up fewer down I'll

00:32:38,770 --> 00:32:45,250
go with it in being altered so let's see

00:32:42,790 --> 00:32:47,140
how this works so we say ok I'm going to

00:32:45,250 --> 00:32:49,420
create a and this is one place where the

00:32:47,140 --> 00:32:50,590
where the having a Kludd open range kind

00:32:49,420 --> 00:32:51,880
of makes sense because you can think of

00:32:50,590 --> 00:32:56,590
this as the check-in and the checkout

00:32:51,880 --> 00:32:59,140
dates so I'm checking in on the

00:32:56,590 --> 00:33:00,130
September 1st leaving September 2nd save

00:32:59,140 --> 00:33:01,430
ok that's fine

00:33:00,130 --> 00:33:04,130
same room

00:33:01,430 --> 00:33:05,660
leaving September 2nd entering and

00:33:04,130 --> 00:33:08,230
coming in September 2nd leaving the 7th

00:33:05,660 --> 00:33:11,480
save that's fine here's a different room

00:33:08,230 --> 00:33:12,740
with a with an overlapping with it with

00:33:11,480 --> 00:33:15,230
exactly the same thing but that's fine

00:33:12,740 --> 00:33:18,170
because this is a different room ok so

00:33:15,230 --> 00:33:20,420
that but then let's try booking 1 2 3

00:33:18,170 --> 00:33:22,130
again but I'm checking in on the fifth

00:33:20,420 --> 00:33:23,840
leaving the 9th notice that these are

00:33:22,130 --> 00:33:25,790
not this not nothing's the same

00:33:23,840 --> 00:33:27,740
these dates aren't the same but they

00:33:25,790 --> 00:33:29,210
overlap this and so I get this

00:33:27,740 --> 00:33:30,920
incredibly long stack trace which I will

00:33:29,210 --> 00:33:33,110
not reproduce and here's the interesting

00:33:30,920 --> 00:33:35,510
part which is conflicted which is

00:33:33,110 --> 00:33:39,020
there's a key conflict so it just won't

00:33:35,510 --> 00:33:40,340
let you do that so that's so that's what

00:33:39,020 --> 00:33:41,870
you can do with constrain exclusion it's

00:33:40,340 --> 00:33:46,190
very nice it finally solves this hotel

00:33:41,870 --> 00:33:48,740
booking problem so why would we use

00:33:46,190 --> 00:33:51,650
range fields well to represent ranges we

00:33:48,740 --> 00:33:53,300
probably figured that out it's more

00:33:51,650 --> 00:33:56,720
natural I think than the high-low pair

00:33:53,300 --> 00:33:58,870
and you have mor more query operations

00:33:56,720 --> 00:34:01,490
like overlaps and things like that and

00:33:58,870 --> 00:34:03,080
data integrity operations available if

00:34:01,490 --> 00:34:07,670
you just do this traditional high-low

00:34:03,080 --> 00:34:10,190
separate fields so coming JSON fields

00:34:07,670 --> 00:34:13,100
they're not in 1.8 but they have landed

00:34:10,190 --> 00:34:16,070
for 1.9 these are fields that support

00:34:13,100 --> 00:34:17,929
arbitrary JSON structures they're still

00:34:16,070 --> 00:34:20,030
a work in progress so you know we'll see

00:34:17,929 --> 00:34:22,610
what we get when 1.9 is released but it

00:34:20,030 --> 00:34:24,919
looks pretty good one thing to note

00:34:22,610 --> 00:34:30,530
about Postgres is Postgres has two json

00:34:24,919 --> 00:34:32,600
types json and json be json stores the

00:34:30,530 --> 00:34:34,790
raw text of the JSON blob whitespace and

00:34:32,600 --> 00:34:37,060
all it is in fact a text type with with

00:34:34,790 --> 00:34:40,190
a JSON type wrapper around it

00:34:37,060 --> 00:34:42,830
it's JSON B is a compact indexable

00:34:40,190 --> 00:34:44,630
format it's kind of like B song for

00:34:42,830 --> 00:34:46,070
people who are familiar it's not B

00:34:44,630 --> 00:34:48,980
song but it's kind of it has the same

00:34:46,070 --> 00:34:52,220
design set of design calls so why would

00:34:48,980 --> 00:34:54,110
you ever use JSON instead of JSON B JSON

00:34:52,220 --> 00:34:57,770
is a little faster to insert since it

00:34:54,110 --> 00:35:00,080
doesn't have to convert the data and

00:34:57,770 --> 00:35:02,060
JSON the reason that we have these two

00:35:00,080 --> 00:35:03,920
features is these two types is that

00:35:02,060 --> 00:35:05,810
there are two very dubious features that

00:35:03,920 --> 00:35:08,630
unfortunately some people rely on in

00:35:05,810 --> 00:35:13,850
JSON which is duplicate object keys at

00:35:08,630 --> 00:35:14,619
the same level or or or a stable key

00:35:13,850 --> 00:35:16,869
order

00:35:14,619 --> 00:35:18,339
the spec for JSON does not say these are

00:35:16,869 --> 00:35:19,900
features but some people rely on them

00:35:18,339 --> 00:35:24,069
and these are bad people and should feel

00:35:19,900 --> 00:35:25,690
bad but we support it anyway this is an

00:35:24,069 --> 00:35:27,369
okay thing to use if you're just logging

00:35:25,690 --> 00:35:32,289
JSON and that you don't plan to query

00:35:27,369 --> 00:35:34,150
extensively why use JSON be pretty much

00:35:32,289 --> 00:35:37,630
everything else can be indexed in useful

00:35:34,150 --> 00:35:39,670
ways I like JSON and the forthcoming

00:35:37,630 --> 00:35:41,799
jisan field uses JSON bases just roll

00:35:39,670 --> 00:35:45,160
with it

00:35:41,799 --> 00:35:47,789
JSON B uses gin and mixing it supports

00:35:45,160 --> 00:35:51,430
these operators in Postgres which are

00:35:47,789 --> 00:35:56,619
path key includes includes any key

00:35:51,430 --> 00:35:58,569
includes all keys includes any key one

00:35:56,619 --> 00:36:00,489
thing about indexing is basically only

00:35:58,569 --> 00:36:03,279
the top-level object in the JSON

00:36:00,489 --> 00:36:06,099
document is indexed so we don't do deep

00:36:03,279 --> 00:36:07,359
level any key anywhere indexing yet

00:36:06,099 --> 00:36:10,900
that's a feature that's coming in

00:36:07,359 --> 00:36:14,400
Postgres you can query nested objects

00:36:10,900 --> 00:36:14,400
but only paths rooted to the top level

00:36:14,499 --> 00:36:18,279
why would you use JSON well people

00:36:16,630 --> 00:36:19,630
everywhere have their uses for JSON I

00:36:18,279 --> 00:36:21,460
probably don't have to sell you on it

00:36:19,630 --> 00:36:22,839
but just in case if you're logging JSON

00:36:21,460 --> 00:36:25,210
data if you're actually want to store

00:36:22,839 --> 00:36:26,680
something that's JSON one nice thing you

00:36:25,210 --> 00:36:29,109
can do with JSON is an audit table that

00:36:26,680 --> 00:36:30,759
spans multiple schemas this has been a

00:36:29,109 --> 00:36:32,170
big this is a big traditional problem in

00:36:30,759 --> 00:36:35,380
relational databases is you want to have

00:36:32,170 --> 00:36:37,509
one table that logs that logs auditing

00:36:35,380 --> 00:36:41,140
for everything but which schema do you

00:36:37,509 --> 00:36:43,119
use it's kind of a friendly way of

00:36:41,140 --> 00:36:45,099
pickling Python objects rather than you

00:36:43,119 --> 00:36:47,049
see pickle or something like that

00:36:45,099 --> 00:36:48,789
storing pickle Python objects directly

00:36:47,049 --> 00:36:50,200
in the database is not I would call the

00:36:48,789 --> 00:36:54,539
best practice in the entire world but

00:36:50,200 --> 00:36:56,650
sometimes you just got to do it and a

00:36:54,539 --> 00:36:57,880
end user defined attributes in rare

00:36:56,650 --> 00:36:59,589
fields Allah eats or basically

00:36:57,880 --> 00:37:03,489
completely subsumes all of a stores use

00:36:59,589 --> 00:37:05,259
cases I would say there are admin

00:37:03,489 --> 00:37:07,299
widgets which go with the new types

00:37:05,259 --> 00:37:08,289
these store in JSON widgets are really

00:37:07,299 --> 00:37:10,390
only good for debugging

00:37:08,289 --> 00:37:12,819
I wouldn't like put a blog author in

00:37:10,390 --> 00:37:14,349
front of these guys and the unaccented

00:37:12,819 --> 00:37:19,380
which amount of time to just read about

00:37:14,349 --> 00:37:19,380
in the documentation and any questions

00:37:30,540 --> 00:37:34,690
there we go

00:37:31,869 --> 00:37:36,160
thank you very much Kristoff just sort

00:37:34,690 --> 00:37:38,530
of leading into the where the future

00:37:36,160 --> 00:37:39,670
goes are now our glorious friend mark

00:37:38,530 --> 00:37:42,160
and the things that he's still working

00:37:39,670 --> 00:37:43,750
on what do you if you've keeping on top

00:37:42,160 --> 00:37:46,869
of it what do you know of that is coming

00:37:43,750 --> 00:37:48,730
in 1.9 in addition to this or if you

00:37:46,869 --> 00:37:51,790
don't know what else is in Postgres that

00:37:48,730 --> 00:37:53,380
is worth rapping that you think I'm

00:37:51,790 --> 00:37:54,520
feeling a little awkward speaking for

00:37:53,380 --> 00:37:55,930
mark because I feel like I'm you know

00:37:54,520 --> 00:37:58,060
standing over him telling program this

00:37:55,930 --> 00:37:59,589
the biggest thing that and this is

00:37:58,060 --> 00:38:01,960
something you can see from what there is

00:37:59,589 --> 00:38:04,990
a framework for creating these indexes

00:38:01,960 --> 00:38:07,839
in rather than having to use raw sequel

00:38:04,990 --> 00:38:10,270
that would be super to create this I

00:38:07,839 --> 00:38:12,880
know Mark has plans about this but it's

00:38:10,270 --> 00:38:14,349
it is very much a if he gets time kind

00:38:12,880 --> 00:38:16,750
of thing so I would say that's the

00:38:14,349 --> 00:38:18,490
biggest weather that's probably a one

00:38:16,750 --> 00:38:19,930
point ten feature I would guess because

00:38:18,490 --> 00:38:23,500
there's still design work to be done

00:38:19,930 --> 00:38:25,630
there if you know of anything stay there

00:38:23,500 --> 00:38:28,839
behind that I don't doubt that by all

00:38:25,630 --> 00:38:29,980
means lay it on me you've caught me on

00:38:28,839 --> 00:38:32,109
the spot I can take a look at my head

00:38:29,980 --> 00:38:33,550
okay no that's fine I thought I that was

00:38:32,109 --> 00:38:38,500
a leading question I actually don't know

00:38:33,550 --> 00:38:42,040
release notes have I've stunned everyone

00:38:38,500 --> 00:38:45,060
into silence okay that being the case

00:38:42,040 --> 00:38:45,060
thank you very much

00:38:55,579 --> 00:38:57,640

YouTube URL: https://www.youtube.com/watch?v=aSRk0L6D3Zs


