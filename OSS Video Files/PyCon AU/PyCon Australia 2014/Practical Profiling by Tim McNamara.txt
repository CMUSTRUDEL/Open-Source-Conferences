Title: Practical Profiling by Tim McNamara
Publication date: 2014-08-17
Playlist: PyCon Australia 2014
Description: 
	Profiling your code seems like something you should do. Unfortunately, it’s not something that always feels easy to do. This talk aims to give you the tools to improve the speed and memory efficiency of your applications, while minimising the productivity burden of adding new steps to your workflow. 

Most of the time will be spent looking at working with the profile and pstats modules within Python’s standard library. There will be a small focus on showing off some of the features of the pstats.Stats class. We will move from using these tools as one-shot print outs, to being able to use them over time to track performance.

Throughout the talk, we’ll spend some time peeking at source code from projects that are out in the wild. Looking through other people’s code will give us a great indication about how people are actually using the tools, rather than just what the documentation says.

The overarching goal of the talk will be to make profiling a practical part of your programming life. If nothing else, you’ll be able to quantify the gains that your coding as, by pointing to lower overheads due to your super efficient new code!

PyCon Australia is the national conference for users of the Python Programming Language. In August 2014, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

August 1-5, Brisbane, Queensland, Australia
Captions: 
	00:00:07,040 --> 00:00:12,270
so oh sorry thank you for your patience

00:00:10,350 --> 00:00:14,340
so early this afternoon um terming

00:00:12,270 --> 00:00:16,260
tomorrow gave us a talk about listening

00:00:14,340 --> 00:00:18,150
ghostwriter so his back again with his

00:00:16,260 --> 00:00:26,220
um talk on practical profiling please

00:00:18,150 --> 00:00:28,410
welcome him thanks everyone for having

00:00:26,220 --> 00:00:30,090
the energy to stick around and I'm

00:00:28,410 --> 00:00:32,160
hoping that we're going to have sort of

00:00:30,090 --> 00:00:35,730
an entertaining end to the rest of the

00:00:32,160 --> 00:00:37,320
day has anyone put a talk proposal in

00:00:35,730 --> 00:00:38,820
for something they really wanted to

00:00:37,320 --> 00:00:40,890
spend a couple of months researching

00:00:38,820 --> 00:00:43,469
because they kind of really wanted to

00:00:40,890 --> 00:00:46,680
figure out how to get it working anyone

00:00:43,469 --> 00:00:51,059
else point it myself okay so this is

00:00:46,680 --> 00:00:53,430
kind of not really a tutorial I'm there

00:00:51,059 --> 00:00:56,309
are plenty of research plenty of other

00:00:53,430 --> 00:00:58,230
talks even about profiling this is kind

00:00:56,309 --> 00:00:59,850
of my attempt at trying to figure out

00:00:58,230 --> 00:01:03,899
how to use the tools that are available

00:00:59,850 --> 00:01:10,459
and are documented in the ecosystem into

00:01:03,899 --> 00:01:13,530
my own personal workflow to get going

00:01:10,459 --> 00:01:16,860
there's profiling which kind of gives us

00:01:13,530 --> 00:01:19,619
evidence and then optimization which we

00:01:16,860 --> 00:01:21,770
can and they are sort of interrelated

00:01:19,619 --> 00:01:24,060
but we're mainly talking about

00:01:21,770 --> 00:01:27,240
instrumenting our code to gather

00:01:24,060 --> 00:01:31,280
evidence and not really talking so much

00:01:27,240 --> 00:01:35,520
about how to use that data to optimize

00:01:31,280 --> 00:01:37,319
but there was a little bit I just want

00:01:35,520 --> 00:01:39,270
to say one very very quickly if you're

00:01:37,319 --> 00:01:42,420
reading off desk sometimes it can be

00:01:39,270 --> 00:01:44,009
really helpful if you use temp FS to

00:01:42,420 --> 00:01:45,330
destroy everything around any real fair

00:01:44,009 --> 00:01:47,190
to so that's kind of the only

00:01:45,330 --> 00:01:55,739
optimization thing that is wanted to

00:01:47,190 --> 00:01:58,440
plug but yeah so I'd love to think that

00:01:55,739 --> 00:01:59,610
that once upon a time development looks

00:01:58,440 --> 00:02:01,440
a little bit like you've got this

00:01:59,610 --> 00:02:03,479
brainwave you move around to writing

00:02:01,440 --> 00:02:05,580
code get in run code and you kind of

00:02:03,479 --> 00:02:09,330
have this lovely big circle is really

00:02:05,580 --> 00:02:10,560
productive but now you've been told you

00:02:09,330 --> 00:02:11,790
know you've got your unit test that

00:02:10,560 --> 00:02:13,810
you've got to write first and you run

00:02:11,790 --> 00:02:16,250
those tests before you run the code

00:02:13,810 --> 00:02:19,940
I'm going to iterate through it again

00:02:16,250 --> 00:02:21,560
and again and again but if you're

00:02:19,940 --> 00:02:23,540
working with in a team environment you

00:02:21,560 --> 00:02:25,370
also need to kind of coordinate your

00:02:23,540 --> 00:02:27,230
work or what you're doing with them and

00:02:25,370 --> 00:02:29,000
you've got your answerable playbook

00:02:27,230 --> 00:02:30,530
because you need to deploy elastic

00:02:29,000 --> 00:02:33,980
infrastructure your dacha file so that

00:02:30,530 --> 00:02:36,320
everything is containerized and highly

00:02:33,980 --> 00:02:38,450
secure and you might also want to

00:02:36,320 --> 00:02:40,790
configure your own stn and maybe your

00:02:38,450 --> 00:02:43,070
own CDN if you're delivering static

00:02:40,790 --> 00:02:44,150
files then you run a test right deploy

00:02:43,070 --> 00:02:46,400
your infrastructure and then you can

00:02:44,150 --> 00:02:50,300
finally run your code and then you

00:02:46,400 --> 00:02:52,730
repeat but you know we have an extra

00:02:50,300 --> 00:02:56,990
introduced branching into this but I'll

00:02:52,730 --> 00:02:59,060
kind of stop there the other question

00:02:56,990 --> 00:03:00,020
that that's probably quite important for

00:02:59,060 --> 00:03:03,080
people when they're actually trying to

00:03:00,020 --> 00:03:06,910
get this in a day to day basis is do we

00:03:03,080 --> 00:03:06,910
where do we spend our time and energy

00:03:08,200 --> 00:03:14,060
there's a bunch of things that we can

00:03:10,490 --> 00:03:16,640
instrument and you know if we're using

00:03:14,060 --> 00:03:18,530
multiple processes distributed

00:03:16,640 --> 00:03:24,200
programming or multi threading it gets

00:03:18,530 --> 00:03:26,840
even harder I've been reading quite a

00:03:24,200 --> 00:03:29,810
few blog posts on tutorials and so forth

00:03:26,840 --> 00:03:35,120
around around the tools that are

00:03:29,810 --> 00:03:40,130
available and the sentiment out there

00:03:35,120 --> 00:03:41,750
isn't positive and the other thing is

00:03:40,130 --> 00:03:43,550
that from the users perspective the

00:03:41,750 --> 00:03:46,090
distinction between kind of the system

00:03:43,550 --> 00:03:49,880
python that you sort of apt-get install

00:03:46,090 --> 00:03:52,610
is a little bit different than the the

00:03:49,880 --> 00:03:54,320
Python standard library sometimes so the

00:03:52,610 --> 00:03:56,510
sub under user has had a little bit of

00:03:54,320 --> 00:04:01,490
difficulty figuring that distinction out

00:03:56,510 --> 00:04:03,140
to I really hope that someone is in here

00:04:01,490 --> 00:04:08,720
is that it isn't the developer of this

00:04:03,140 --> 00:04:12,590
code sheet thing so well this is some

00:04:08,720 --> 00:04:15,110
public code and what you've got here

00:04:12,590 --> 00:04:17,419
isn't is probably an iterative cycle of

00:04:15,110 --> 00:04:19,370
profiling specific Pete's bits of

00:04:17,419 --> 00:04:25,520
technology changing function names

00:04:19,370 --> 00:04:27,230
changing parameters within each of the

00:04:25,520 --> 00:04:28,550
variables kind of doing it and the

00:04:27,230 --> 00:04:29,960
wanting it to stop in the right place so

00:04:28,550 --> 00:04:32,690
you can actually check on things and

00:04:29,960 --> 00:04:35,000
just so that people I had a brief look

00:04:32,690 --> 00:04:38,540
this code sheet thing create sheet music

00:04:35,000 --> 00:04:43,220
or creates PDFs of sheet music from sq4

00:04:38,540 --> 00:04:45,770
as far as I can tell and so what is the

00:04:43,220 --> 00:04:50,060
right workflow to get everything working

00:04:45,770 --> 00:04:52,880
together because clearly as I have found

00:04:50,060 --> 00:04:55,160
it it's been really quite tough so we

00:04:52,880 --> 00:04:57,890
have all of these issues you know it's

00:04:55,160 --> 00:05:00,140
unclear it's another thing that we need

00:04:57,890 --> 00:05:02,870
to bolt on to our development cycle but

00:05:00,140 --> 00:05:04,760
really there are some useful reasons to

00:05:02,870 --> 00:05:06,020
actually consider profiling is something

00:05:04,760 --> 00:05:08,060
kind of good to do we've got this

00:05:06,020 --> 00:05:12,590
intuition there that faster code is

00:05:08,060 --> 00:05:14,330
better code and and and cooler more

00:05:12,590 --> 00:05:16,280
power efficient service means that we're

00:05:14,330 --> 00:05:19,670
going to be able to scale up as we as

00:05:16,280 --> 00:05:21,080
our system and our service grows and

00:05:19,670 --> 00:05:25,580
we're also going to be reducing our

00:05:21,080 --> 00:05:27,320
impact environmentally so this is just a

00:05:25,580 --> 00:05:32,270
very small survey about some of the

00:05:27,320 --> 00:05:33,890
tools that are available to you some of

00:05:32,270 --> 00:05:36,950
them you undoubtedly would have used in

00:05:33,890 --> 00:05:38,240
various ways before in particular we're

00:05:36,950 --> 00:05:41,780
going to be focusing on this thing

00:05:38,240 --> 00:05:44,240
memory profiler the C Python RC profile

00:05:41,780 --> 00:05:47,930
tools which comes in in this line

00:05:44,240 --> 00:05:49,490
profiler thing as well just because they

00:05:47,930 --> 00:05:52,610
seem quite practical and relatively

00:05:49,490 --> 00:05:54,770
widely adopted it can I just get is

00:05:52,610 --> 00:06:00,980
there anyone for which these tools are

00:05:54,770 --> 00:06:06,980
completely new ok that's just fine right

00:06:00,980 --> 00:06:08,570
so memory profiler I wanted to start

00:06:06,980 --> 00:06:10,070
here because it's the best example I

00:06:08,570 --> 00:06:12,680
think of quite a good user experience

00:06:10,070 --> 00:06:15,380
and we've kind of got our function this

00:06:12,680 --> 00:06:17,420
is unwrapped out of the documentation

00:06:15,380 --> 00:06:19,400
you know some sort of computationally

00:06:17,420 --> 00:06:21,560
expensive sorry memory expensive

00:06:19,400 --> 00:06:25,880
operation we're expanding these two

00:06:21,560 --> 00:06:30,260
lists quite quite big pretty bad grammar

00:06:25,880 --> 00:06:34,370
there but we then execute so that's

00:06:30,260 --> 00:06:37,160
ipython and we get this output for each

00:06:34,370 --> 00:06:39,530
line in our file what does this do

00:06:37,160 --> 00:06:40,360
before and after it's executed in terms

00:06:39,530 --> 00:06:42,610
of

00:06:40,360 --> 00:06:45,039
memory utilization so I think in terms

00:06:42,610 --> 00:06:47,259
of being a tool that's relatively easy

00:06:45,039 --> 00:06:49,150
to use that's what this is pretty good

00:06:47,259 --> 00:06:50,770
right you add a decorator to a function

00:06:49,150 --> 00:06:52,060
that you want to have profiled because

00:06:50,770 --> 00:06:54,009
you have some suspicions that that's

00:06:52,060 --> 00:07:01,120
relatively expensive and then you kind

00:06:54,009 --> 00:07:02,620
of get a really really handy output so

00:07:01,120 --> 00:07:03,819
as it kind of was touched upon in one of

00:07:02,620 --> 00:07:06,219
these quotes the standard library

00:07:03,819 --> 00:07:08,650
actually has three profilers it has two

00:07:06,219 --> 00:07:11,080
implementations of a deterministic

00:07:08,650 --> 00:07:12,759
profiler one's implemented in C and once

00:07:11,080 --> 00:07:15,009
implemented in Python that's easier for

00:07:12,759 --> 00:07:17,800
you as a developer to extend and this is

00:07:15,009 --> 00:07:21,129
the hotshot thing which is which which

00:07:17,800 --> 00:07:23,759
samples it's non deterministic but is

00:07:21,129 --> 00:07:26,830
easier to sort of turn on and off which

00:07:23,759 --> 00:07:29,680
I'm focusing on the see profile because

00:07:26,830 --> 00:07:32,110
it is very well documented robust and

00:07:29,680 --> 00:07:34,479
it's been around for a while so to use

00:07:32,110 --> 00:07:36,879
it we this is again as a shell command

00:07:34,479 --> 00:07:40,419
this is how it's often sort of seen

00:07:36,879 --> 00:07:43,300
Python dash module see profile provide

00:07:40,419 --> 00:07:44,560
an output result completely arbitrary

00:07:43,300 --> 00:07:46,690
it's just a file name so we're just

00:07:44,560 --> 00:07:50,909
going to call it result doc profile and

00:07:46,690 --> 00:07:50,909
our application is just called a pie and

00:07:51,930 --> 00:07:57,400
to interpret it so this result dot prof

00:07:55,509 --> 00:07:59,500
thing will be a binary file that is

00:07:57,400 --> 00:08:02,500
completely opaque to us peace debts is

00:07:59,500 --> 00:08:06,909
kind of comes to our in comes to our

00:08:02,500 --> 00:08:09,639
rescue it's a it's actually in the same

00:08:06,909 --> 00:08:13,419
document file if you go hunt for ce pro

00:08:09,639 --> 00:08:17,349
see profile in the documentation so we

00:08:13,419 --> 00:08:20,349
import this piece nets thing create a

00:08:17,349 --> 00:08:24,339
stats object we strip them that's the

00:08:20,349 --> 00:08:26,589
function directory names so that things

00:08:24,339 --> 00:08:28,750
are slightly more in more readable we

00:08:26,589 --> 00:08:31,629
could say sort by a cumulative time and

00:08:28,750 --> 00:08:34,029
print out the top 20 functions that took

00:08:31,629 --> 00:08:38,680
time we can also do this all increment

00:08:34,029 --> 00:08:43,300
sorry interactively via calling p stats

00:08:38,680 --> 00:08:47,410
module from the command line as well so

00:08:43,300 --> 00:08:49,270
he was my attempt at creating something

00:08:47,410 --> 00:08:53,050
expense computationally expensive to

00:08:49,270 --> 00:08:54,130
kind of talk about ignore everything

00:08:53,050 --> 00:08:56,800
really what

00:08:54,130 --> 00:08:58,900
really trying to consider is the

00:08:56,800 --> 00:09:02,670
difference between a comprehension and a

00:08:58,900 --> 00:09:04,840
for loop because I've heard often that

00:09:02,670 --> 00:09:07,210
comprehension zar much much faster than

00:09:04,840 --> 00:09:08,740
four loops and I kind of want to thought

00:09:07,210 --> 00:09:12,160
it might be something worthwhile testing

00:09:08,740 --> 00:09:14,080
out so any other thing I've also done is

00:09:12,160 --> 00:09:16,000
included my implementer or a sort of a

00:09:14,080 --> 00:09:20,830
relatively rubbish implementation of

00:09:16,000 --> 00:09:24,760
some this is the built in so if we just

00:09:20,830 --> 00:09:27,160
run Python Python dash M c pi phi c

00:09:24,760 --> 00:09:30,460
profile and worktop pi which is the name

00:09:27,160 --> 00:09:33,250
of the file that we just created this is

00:09:30,460 --> 00:09:41,020
the output that would get the ordering

00:09:33,250 --> 00:09:43,500
is by this column so relatively you know

00:09:41,020 --> 00:09:46,810
so we need to kind of adapt that to

00:09:43,500 --> 00:09:49,180
change this we provide the s-parameter

00:09:46,810 --> 00:09:52,450
which is kind of you more useful to us

00:09:49,180 --> 00:09:54,490
we can see that the use for loop indeed

00:09:52,450 --> 00:09:57,160
took much more than the used

00:09:54,490 --> 00:10:01,480
comprehensions function in fact a total

00:09:57,160 --> 00:10:05,350
time there was sort of 0.19 of a second

00:10:01,480 --> 00:10:12,010
versus 0.09 so roughly double for our

00:10:05,350 --> 00:10:14,170
particular case line profile it is

00:10:12,010 --> 00:10:18,910
exactly the same in terms of output for

00:10:14,170 --> 00:10:20,740
you that the memory profile example that

00:10:18,910 --> 00:10:23,440
we've already seen so you actually get

00:10:20,740 --> 00:10:26,290
this is your line this is the amount of

00:10:23,440 --> 00:10:27,940
time that Python spent in there and so

00:10:26,290 --> 00:10:29,440
forth I just thought since we've already

00:10:27,940 --> 00:10:33,610
looked at memory profiler will just kind

00:10:29,440 --> 00:10:35,830
of skip that one but I'm very very

00:10:33,610 --> 00:10:38,800
interested in considering what a

00:10:35,830 --> 00:10:41,020
reproducible say profiling workflow

00:10:38,800 --> 00:10:44,860
would actually look like how do we fit

00:10:41,020 --> 00:10:51,610
it into that really long go to loop that

00:10:44,860 --> 00:10:54,130
we we started with this is where happily

00:10:51,610 --> 00:10:56,530
doing hand wavy stuff I've got this

00:10:54,130 --> 00:10:59,050
intuition that hooking into the

00:10:56,530 --> 00:11:02,260
integration test is probably the best

00:10:59,050 --> 00:11:05,050
place if we run our profiler over the

00:11:02,260 --> 00:11:07,640
entire application one we're probably

00:11:05,050 --> 00:11:09,590
calling I mean it it's

00:11:07,640 --> 00:11:12,980
we're probably calling too much code in

00:11:09,590 --> 00:11:16,400
the sense that most of our code is going

00:11:12,980 --> 00:11:18,080
to be good enough in the butt and the

00:11:16,400 --> 00:11:21,170
other thing about integration tests is

00:11:18,080 --> 00:11:24,110
if we stay slightly higher than a unit

00:11:21,170 --> 00:11:27,590
to stay we don't encounter the problem

00:11:24,110 --> 00:11:31,130
that of specific functionality changes

00:11:27,590 --> 00:11:34,760
or we refactor the code hopefully our

00:11:31,130 --> 00:11:37,370
profiling results will be able to be

00:11:34,760 --> 00:11:39,140
measured and monitored over time more

00:11:37,370 --> 00:11:42,260
easily so this is just that of the

00:11:39,140 --> 00:11:44,390
intuition that I have I really feel that

00:11:42,260 --> 00:11:45,800
for this to be useful or a useful tool

00:11:44,390 --> 00:11:50,150
you need to be able to track your

00:11:45,800 --> 00:11:51,980
results over time and ideally sort of

00:11:50,150 --> 00:11:54,830
bolted on to the continuous integration

00:11:51,980 --> 00:11:57,200
or continuous deployment process because

00:11:54,830 --> 00:11:58,880
if we've already got like I know pick

00:11:57,200 --> 00:12:01,580
your continuous integration tool running

00:11:58,880 --> 00:12:03,980
and it's already building your code at

00:12:01,580 --> 00:12:05,330
the every commit it may as well run some

00:12:03,980 --> 00:12:07,640
and it's already doing all of your unit

00:12:05,330 --> 00:12:11,290
tests it may also do a couple of

00:12:07,640 --> 00:12:13,570
profiling runs as well but this is like

00:12:11,290 --> 00:12:16,070
but it has been sort of six weeks

00:12:13,570 --> 00:12:22,040
looking at how people actually use these

00:12:16,070 --> 00:12:26,410
tools and and I did that through this

00:12:22,040 --> 00:12:28,190
some ol Oh search of functionality um

00:12:26,410 --> 00:12:30,320
one thing that I found really

00:12:28,190 --> 00:12:33,470
interesting is that if you sort of

00:12:30,320 --> 00:12:36,680
search for input import and have the

00:12:33,470 --> 00:12:40,490
python filter on you get back 1.6

00:12:36,680 --> 00:12:42,320
million results so I think that's a and

00:12:40,490 --> 00:12:43,640
there's lots of duplication in there

00:12:42,320 --> 00:12:48,530
because of this multiple files and so

00:12:43,640 --> 00:12:51,080
forth but for the import profile was

00:12:48,530 --> 00:12:55,810
sort of not as useful actually as it

00:12:51,080 --> 00:13:01,070
happens but if you hunt for the call

00:12:55,810 --> 00:13:03,460
profile run you have far fewer results

00:13:01,070 --> 00:13:05,960
than I would have anticipated like and

00:13:03,460 --> 00:13:08,990
possibly that I'm just thinking about it

00:13:05,960 --> 00:13:11,470
now is because many of these tools are

00:13:08,990 --> 00:13:14,300
designed to be run from the command line

00:13:11,470 --> 00:13:16,460
but when people do try to create an

00:13:14,300 --> 00:13:18,380
automated and repeatable process for

00:13:16,460 --> 00:13:20,269
themselves there's actually very few

00:13:18,380 --> 00:13:24,929
people using

00:13:20,269 --> 00:13:27,869
using it so we tried to find some great

00:13:24,929 --> 00:13:30,779
examples of fantastic cases this is

00:13:27,869 --> 00:13:36,689
Wikipedia they've created I believe this

00:13:30,779 --> 00:13:41,749
this tool is called snuggle it's a flask

00:13:36,689 --> 00:13:44,399
application sorry bottle knowledge is

00:13:41,749 --> 00:13:46,409
and what they've done is in their

00:13:44,399 --> 00:13:48,539
command line flags they've added the

00:13:46,409 --> 00:13:54,470
option to be able to run a profiling job

00:13:48,539 --> 00:13:57,629
and they ought to to actually call it

00:13:54,470 --> 00:13:59,759
from within Python code you give a a

00:13:57,629 --> 00:14:01,919
string which is then executed and you

00:13:59,759 --> 00:14:06,899
provided the state so it's just throwing

00:14:01,919 --> 00:14:10,049
on all the state they're from from the

00:14:06,899 --> 00:14:14,849
rest of the module and the output file

00:14:10,049 --> 00:14:16,619
which is this name temporary file it'll

00:14:14,849 --> 00:14:19,259
then they don't the only thing that they

00:14:16,619 --> 00:14:20,789
seem to sort of care about is is the

00:14:19,259 --> 00:14:28,529
cumulative time and they only want the

00:14:20,789 --> 00:14:30,779
top ten functions this is a tiny little

00:14:28,529 --> 00:14:33,179
GUI application that was written for The

00:14:30,779 --> 00:14:36,629
One Laptop Per child also a sugar lamps

00:14:33,179 --> 00:14:41,669
project and talks about kids and hunger

00:14:36,629 --> 00:14:42,809
and and development issues and so what

00:14:41,669 --> 00:14:44,789
they do is they just import the main

00:14:42,809 --> 00:14:46,589
programmer on the main application some

00:14:44,789 --> 00:14:48,089
cited gather some evidence here that in

00:14:46,589 --> 00:14:49,829
the real world my intuition about

00:14:48,089 --> 00:14:51,269
staying at the integration electives

00:14:49,829 --> 00:14:54,209
level not worrying about the whole

00:14:51,269 --> 00:14:58,259
application I'm sort of losing the

00:14:54,209 --> 00:14:59,970
battle as it were and here's another

00:14:58,259 --> 00:15:03,600
application that I sort of plucked out

00:14:59,970 --> 00:15:05,459
of nowhere they you call the main

00:15:03,600 --> 00:15:10,409
function and then write it to a

00:15:05,459 --> 00:15:12,539
hard-coded location every time so this

00:15:10,409 --> 00:15:15,899
means that we have no ability to go and

00:15:12,539 --> 00:15:20,279
compare the today's results with next

00:15:15,899 --> 00:15:23,339
month's results this Katie cross thing

00:15:20,279 --> 00:15:24,989
is sort of a plugin not plugins going to

00:15:23,339 --> 00:15:27,359
be the definitely the wrong word it will

00:15:24,989 --> 00:15:31,529
enable I believe Ruby Python and

00:15:27,359 --> 00:15:33,170
JavaScript to be scripting languages

00:15:31,529 --> 00:15:40,470
within wider teddy

00:15:33,170 --> 00:15:42,570
projects and I assume this is testing

00:15:40,470 --> 00:15:45,690
the ability to convert Python integers

00:15:42,570 --> 00:15:47,640
into sort of see unsigned integers this

00:15:45,690 --> 00:15:49,950
thing just to guess I'm not quite sure

00:15:47,640 --> 00:15:54,360
how it works and likewise were strings

00:15:49,950 --> 00:15:56,700
constraint compatibility and he just

00:15:54,360 --> 00:15:58,110
called this this this run a thing what I

00:15:56,700 --> 00:16:02,820
wanna the reason why I've got this up

00:15:58,110 --> 00:16:04,560
here is not that it's indicative or

00:16:02,820 --> 00:16:05,730
representative good code it's just it's

00:16:04,560 --> 00:16:09,390
it looks like it's pretty unmaintained

00:16:05,730 --> 00:16:14,850
and they didn't really get very far so

00:16:09,390 --> 00:16:16,830
it's kind of the relief of being not the

00:16:14,850 --> 00:16:21,360
only one having problems with first is

00:16:16,830 --> 00:16:22,680
is kind of good and again so this is a

00:16:21,360 --> 00:16:24,920
tiny little GUI application all they're

00:16:22,680 --> 00:16:27,090
doing is running the main function and

00:16:24,920 --> 00:16:32,640
not saving the state so they can't

00:16:27,090 --> 00:16:34,260
maintain it over time canonical has this

00:16:32,640 --> 00:16:41,070
is what they do to profile their Django

00:16:34,260 --> 00:16:43,380
application they will remove the ability

00:16:41,070 --> 00:16:46,470
for this for gargoyle which which helps

00:16:43,380 --> 00:16:49,560
out with with testing Jenga eps a blood

00:16:46,470 --> 00:16:51,180
and they'll isolate every test by

00:16:49,560 --> 00:16:54,840
setting the time at 20 so there's no

00:16:51,180 --> 00:16:58,040
caching and then they use that class to

00:16:54,840 --> 00:17:01,350
which discovers tests they'll run

00:16:58,040 --> 00:17:06,150
everything in it again it through unit

00:17:01,350 --> 00:17:08,750
tests and but again and they're

00:17:06,150 --> 00:17:11,970
returning this is interesting actually

00:17:08,750 --> 00:17:14,190
this during this results here which is a

00:17:11,970 --> 00:17:17,150
string being passed into profile is

00:17:14,190 --> 00:17:23,430
actually being sucked out afterwards

00:17:17,150 --> 00:17:26,910
through locals and again they are using

00:17:23,430 --> 00:17:31,170
the whole application and that doesn't

00:17:26,910 --> 00:17:32,970
look like I just think that what will

00:17:31,170 --> 00:17:35,670
get no one no one's storing the results

00:17:32,970 --> 00:17:39,980
over time and and they're not they're

00:17:35,670 --> 00:17:39,980
not profiling components

00:17:40,539 --> 00:17:49,490
so there is code speed everyone's been

00:17:44,480 --> 00:17:53,270
to a speedy IP org that thing is open

00:17:49,490 --> 00:17:55,730
source and you can run it today it kind

00:17:53,270 --> 00:17:57,470
of you need to think about you need to

00:17:55,730 --> 00:17:59,690
go with the grain slightly because they

00:17:57,470 --> 00:18:01,909
are thinking about language

00:17:59,690 --> 00:18:07,250
implementations but the language is

00:18:01,909 --> 00:18:11,390
there and you can run nose with the

00:18:07,250 --> 00:18:12,710
profiler for the unit test layer oh and

00:18:11,390 --> 00:18:15,740
i saw this is relatively common and

00:18:12,710 --> 00:18:18,289
stack overflow you run from the shower

00:18:15,740 --> 00:18:22,120
python sort of the C Python send

00:18:18,289 --> 00:18:27,169
everything to output about you run nose

00:18:22,120 --> 00:18:29,770
is a sub command which if you're enough

00:18:27,169 --> 00:18:34,220
right if it works it works but it just

00:18:29,770 --> 00:18:40,309
that struck me as interesting but I I'm

00:18:34,220 --> 00:18:42,590
just I'm not sure if i can add much to

00:18:40,309 --> 00:18:45,470
the discussion so I'm sort of this is a

00:18:42,590 --> 00:18:48,549
question for you really I mean should

00:18:45,470 --> 00:18:54,950
project have like a profiling directory

00:18:48,549 --> 00:18:57,289
can I can i suck out using pythons

00:18:54,950 --> 00:19:00,080
introspect earn well dates easy to get

00:18:57,289 --> 00:19:01,580
can I get we run profiling and maybe you

00:19:00,080 --> 00:19:04,039
know could I look inside the directory

00:19:01,580 --> 00:19:05,659
where the modulars and kind of use

00:19:04,039 --> 00:19:07,789
heuristics to determine am I get

00:19:05,659 --> 00:19:11,840
repository and if I am can I pull out

00:19:07,789 --> 00:19:15,740
the current char so that I can also save

00:19:11,840 --> 00:19:19,159
all of that state in a file which I can

00:19:15,740 --> 00:19:24,230
then compare over time to previous and

00:19:19,159 --> 00:19:25,760
future results so um luckily we started

00:19:24,230 --> 00:19:28,309
a little bit late because we've gone

00:19:25,760 --> 00:19:30,440
we've we've had a relatively short talk

00:19:28,309 --> 00:19:34,880
this actually this is this is sort of

00:19:30,440 --> 00:19:37,399
the end I I'm genuinely curious if

00:19:34,880 --> 00:19:38,990
anyone in the audience has had and what

00:19:37,399 --> 00:19:41,120
their experiences are and how they

00:19:38,990 --> 00:19:42,440
integrate profiling with the rest of

00:19:41,120 --> 00:19:43,789
their workflow because I'm sure that the

00:19:42,440 --> 00:19:45,710
rest of the group the rest of us would

00:19:43,789 --> 00:19:50,000
be really interested in figuring this

00:19:45,710 --> 00:19:52,929
out if you do have any thoughts please

00:19:50,000 --> 00:19:52,929
do come down to the mics

00:19:54,460 --> 00:19:59,179
hi I have some thoughts and I'm going to

00:19:57,620 --> 00:20:01,250
try and turn them into a question but

00:19:59,179 --> 00:20:06,429
it's kind of a little bit still bill

00:20:01,250 --> 00:20:09,110
formed there are lots of stories about

00:20:06,429 --> 00:20:10,970
profiling but most often connected with

00:20:09,110 --> 00:20:12,320
optimization which comes as the next

00:20:10,970 --> 00:20:15,769
step such as the person who spent all

00:20:12,320 --> 00:20:17,779
their time finding which was the worst

00:20:15,769 --> 00:20:19,309
piece of their code and they spend all

00:20:17,779 --> 00:20:20,809
this time optimizing it until somebody

00:20:19,309 --> 00:20:23,720
said look do you realize you've just

00:20:20,809 --> 00:20:24,919
optimized the idle loop that is the loop

00:20:23,720 --> 00:20:27,919
that is executing when nothing else is

00:20:24,919 --> 00:20:32,480
happening and then there are situations

00:20:27,919 --> 00:20:35,179
where your your codes performance is so

00:20:32,480 --> 00:20:37,309
dependent on the data it's given I'm

00:20:35,179 --> 00:20:39,580
thinking you know various sorting

00:20:37,309 --> 00:20:43,970
algorithms have bad cases for insurance

00:20:39,580 --> 00:20:47,299
so really I guess I'm wondering whether

00:20:43,970 --> 00:20:50,649
it's not possible that people will use

00:20:47,299 --> 00:20:55,580
profiling when they have otherwise

00:20:50,649 --> 00:20:57,950
well-functioning code which for some set

00:20:55,580 --> 00:20:59,269
of inputs or on some situation has

00:20:57,950 --> 00:21:02,059
suddenly blown up in their faces and

00:20:59,269 --> 00:21:03,799
they go oh no what's happening I don't

00:21:02,059 --> 00:21:07,519
understand this I need something to help

00:21:03,799 --> 00:21:09,259
me do it to understand it and it's not

00:21:07,519 --> 00:21:12,799
something they're going to be deploying

00:21:09,259 --> 00:21:14,149
or using all the time so one way to

00:21:12,799 --> 00:21:17,809
think about that as a question would be

00:21:14,149 --> 00:21:22,190
to say like when can you justify taking

00:21:17,809 --> 00:21:24,019
half a day to like sit down and run

00:21:22,190 --> 00:21:26,120
these profilers over your code given

00:21:24,019 --> 00:21:28,029
that it is Python and that you kind of

00:21:26,120 --> 00:21:30,200
know that it's going to be somewhat slow

00:21:28,029 --> 00:21:32,450
slower than the other alternatives

00:21:30,200 --> 00:21:38,509
anyway it wouldn't it be best to spin

00:21:32,450 --> 00:21:41,149
that day on the next feature right true

00:21:38,509 --> 00:21:43,879
so if you're not in a capacity can I um

00:21:41,149 --> 00:21:45,860
just just come down feel free you're not

00:21:43,879 --> 00:21:50,990
interrupting we're right at the end it's

00:21:45,860 --> 00:21:52,279
more discussion time I don't have a good

00:21:50,990 --> 00:21:53,779
answer apart from the fact that in my

00:21:52,279 --> 00:21:56,330
side projects you know I it's

00:21:53,779 --> 00:21:58,250
interesting but again I wouldn't want to

00:21:56,330 --> 00:22:00,710
spend my own money if I was paying me as

00:21:58,250 --> 00:22:02,389
a developer to find things that are

00:22:00,710 --> 00:22:03,870
interesting i'd really rather serve my

00:22:02,389 --> 00:22:06,420
customers if i can

00:22:03,870 --> 00:22:08,130
have a follow-up question do when you

00:22:06,420 --> 00:22:12,120
started looking into this did you have

00:22:08,130 --> 00:22:14,340
any idea on what something you might

00:22:12,120 --> 00:22:15,960
find out that would satisfy you yes

00:22:14,340 --> 00:22:17,460
here's something really important that

00:22:15,960 --> 00:22:19,170
I've discovered about about profiling

00:22:17,460 --> 00:22:20,640
well why not I think that I think the

00:22:19,170 --> 00:22:22,650
line profile in the memory profile oh

00:22:20,640 --> 00:22:24,059
really really useful tools because they

00:22:22,650 --> 00:22:27,090
provide you very specific and very

00:22:24,059 --> 00:22:28,980
actionable outcomes so one of the

00:22:27,090 --> 00:22:32,550
problems with the sea with the with the

00:22:28,980 --> 00:22:34,350
standard profiling machinery is that it

00:22:32,550 --> 00:22:38,250
only provides you granulator you got

00:22:34,350 --> 00:22:42,150
granularity up to the function level and

00:22:38,250 --> 00:22:45,000
at least and if you can think about

00:22:42,150 --> 00:22:46,920
using those other two tools in a way

00:22:45,000 --> 00:22:49,559
that works within your workflow for

00:22:46,920 --> 00:22:54,570
everybody else then you've got the

00:22:49,559 --> 00:22:56,400
chance to be able to actually make a

00:22:54,570 --> 00:22:58,470
change to code that's relatively cheap

00:22:56,400 --> 00:23:00,059
and in terms of your own time and

00:22:58,470 --> 00:23:06,330
hopefully is very cheap in terms of the

00:23:00,059 --> 00:23:08,340
cost of running your code so on the

00:23:06,330 --> 00:23:10,140
clock I have another seven minutes to go

00:23:08,340 --> 00:23:14,460
but I'm really happy to sort of wrap up

00:23:10,140 --> 00:23:16,530
there if if people are keen to hope I

00:23:14,460 --> 00:23:18,929
don't know if we're ready to get on with

00:23:16,530 --> 00:23:21,630
the clothes and hopefully we get out

00:23:18,929 --> 00:23:23,929
five minutes early 40 thanks so much

00:23:21,630 --> 00:23:23,929
everyone

00:23:26,540 --> 00:23:28,600
you

00:23:35,789 --> 00:23:37,850

YouTube URL: https://www.youtube.com/watch?v=WNmtiT-rguA


