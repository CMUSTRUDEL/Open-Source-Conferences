Title: Verification: Truth in Statistics by Tennessee Leeuwenburg
Publication date: 2014-08-05
Playlist: PyCon Australia 2014
Description: 
	Come to this talk if you want to learn a few basic techniques for putting numerical data in context. If you've ever predicted anything, or tried to work out whether some number was "good enough", you'll probably get something out of this presentation. All techniques and tools demonstrated using Python.

Every day, decisions both big and small are made on the basis of the information published by the Bureau of Meteorology. These include simple decisions such as taking an umbrella or planning a barbecue. Our forecasts also inform Australia's emergency services on where extreme weather events may have occurred, to help with planning and preparation.
 
Understanding and communicating our strengths and weaknesses is very important, both as an organisation and also internally within the Environment and Research division. This presentation will focus on the statistical methods and systems used to evaluate the objective, scientific performance of our forecast systems. The name for this area of study is "Verification". While the concepts have come from the research environment, they are widely applicable and can help anyone who is assessing the performance of any system.
 
This presentation will include:
  -- An overview of the major ideas of verification
  -- How to create a 'skill score'
  -- The application of these concepts to thunderstorm forecasting
  -- How to use Python tools for verification analyses
  -- Tips on how to apply these ideas easily in other contexts
 
Obtaining relevant thunderstorm observational data can be particularly challenging, particularly pertaining to severe and damaging aspects: lightning, hail, heavy rain and very strong wind gusts. In order achieve a stronger footing, some new methods of analysis are under development. It is necessary to establish the scientific validity of the verification metrics at the same time as constructing the systems to support the data analysis.
 
A prototype web-based tool written in Python (and under active development by the presenter) will be demonstrated. This tool can run locally to provide an enhanced lab environment for assessing case study data, or be set up as a server for continuous monitoring and reporting.
 
No pre-existing knowledge of Python or statistics is assumed. The talk will include several technical aspects, such as working at different computing scales, usability and user experience, working with statistical algorithms, data visualisation for both web and journal publications, and the architectural challenges of a complex application.

PyCon Australia is the national conference for users of the Python Programming Language. In August 2014, we're heading to Brisbane to bring together students, enthusiasts, and professionals with a love of Python from around Australia, and all around the World. 

August 1-5, Brisbane, Queensland, Australia
Captions: 
	00:00:05,190 --> 00:00:09,660
keep the number of slides short enough

00:00:08,460 --> 00:00:11,820
that we can have a bit of a chat

00:00:09,660 --> 00:00:13,350
afterwards and I want to keep the

00:00:11,820 --> 00:00:14,910
presentation informal enough that

00:00:13,350 --> 00:00:17,100
everybody feels comfortable to have a

00:00:14,910 --> 00:00:19,260
discussion because I'd actually rather

00:00:17,100 --> 00:00:20,730
if we just had a big room and we could

00:00:19,260 --> 00:00:22,890
all just sit around and talk about the

00:00:20,730 --> 00:00:25,260
topic than may have to be a talking head

00:00:22,890 --> 00:00:26,460
for 45 minutes but that's not the format

00:00:25,260 --> 00:00:29,070
the format is I'm giving a presentation

00:00:26,460 --> 00:00:32,759
but just to loosen everybody up because

00:00:29,070 --> 00:00:35,550
someone please interrupt me anybody know

00:00:32,759 --> 00:00:36,930
okay brilliant all right and could I

00:00:35,550 --> 00:00:38,850
just get a show of hands not for

00:00:36,930 --> 00:00:40,800
anything but just just a show of hands

00:00:38,850 --> 00:00:42,749
brilliant okay thank you we're all here

00:00:40,800 --> 00:00:47,670
all right so what we're here to talk

00:00:42,749 --> 00:00:50,159
about is statistics so there's a lot of

00:00:47,670 --> 00:00:51,929
that there's a reason this slide exists

00:00:50,159 --> 00:00:53,819
there's a reason that that people say

00:00:51,929 --> 00:00:56,940
lies damn lies and statistics it's

00:00:53,819 --> 00:00:59,729
because it's very easy to fail to

00:00:56,940 --> 00:01:02,039
understand some small aspect of how

00:00:59,729 --> 00:01:04,440
statistic is derived and then get

00:01:02,039 --> 00:01:06,810
radically the wrong conclusion and take

00:01:04,440 --> 00:01:09,150
a potentially dramatic decision on the

00:01:06,810 --> 00:01:12,750
basis of a piece of evidence that that's

00:01:09,150 --> 00:01:16,890
very well trusted so verification is

00:01:12,750 --> 00:01:18,510
about avoiding this problem verification

00:01:16,890 --> 00:01:20,820
is about evidence it's about the role

00:01:18,510 --> 00:01:23,370
evidence plays in our lives it's about

00:01:20,820 --> 00:01:25,290
the challenge of gathering data that we

00:01:23,370 --> 00:01:27,360
can trust so that when we when we draw a

00:01:25,290 --> 00:01:29,660
conclusion we don't get get caught out

00:01:27,360 --> 00:01:31,950
but by our first principles not being

00:01:29,660 --> 00:01:33,720
thoroughly checked and it's about

00:01:31,950 --> 00:01:35,430
communicating that evidence to other

00:01:33,720 --> 00:01:37,680
people in ways that they can understand

00:01:35,430 --> 00:01:39,720
so I'm going to try and do that today

00:01:37,680 --> 00:01:42,090
communicate some some pieces of evidence

00:01:39,720 --> 00:01:44,460
to you in ways that I hope that you can

00:01:42,090 --> 00:01:45,900
understand and together arrive it may be

00:01:44,460 --> 00:01:49,950
a bit of an understanding of how to do

00:01:45,900 --> 00:01:52,380
that now I'm not a statistician I I'm

00:01:49,950 --> 00:01:55,050
just a computer scientist right now my

00:01:52,380 --> 00:01:57,270
guess is that that a solid thirds to

00:01:55,050 --> 00:01:59,220
three quarters of this audience it's

00:01:57,270 --> 00:02:01,909
going to be better at math than I am and

00:01:59,220 --> 00:02:05,670
that is fine because it takes all kinds

00:02:01,909 --> 00:02:07,920
so I'm a software engineer and I've done

00:02:05,670 --> 00:02:09,450
a lot of ongoing learning to get to

00:02:07,920 --> 00:02:11,190
grips with this particular topic so

00:02:09,450 --> 00:02:13,230
what's this talk structure going to be

00:02:11,190 --> 00:02:15,500
so I had a lot of feedback that this

00:02:13,230 --> 00:02:17,970
this section their examples and maths

00:02:15,500 --> 00:02:19,230
really should be should be cut down as

00:02:17,970 --> 00:02:21,150
much as possible

00:02:19,230 --> 00:02:22,830
everyone wanted to talk about kind of

00:02:21,150 --> 00:02:25,260
the number four and five stuff as much

00:02:22,830 --> 00:02:26,940
as possible now I sort of draw a line

00:02:25,260 --> 00:02:28,409
I'm like look I understand that everyone

00:02:26,940 --> 00:02:29,970
here is in software which is

00:02:28,409 --> 00:02:31,459
understanding how to write software but

00:02:29,970 --> 00:02:33,150
there's just a certain amount of

00:02:31,459 --> 00:02:35,250
understanding the problem that you're

00:02:33,150 --> 00:02:37,290
trying to solve that you need to have in

00:02:35,250 --> 00:02:38,519
order to come together to work on this

00:02:37,290 --> 00:02:40,920
kind of problem so we're just going to

00:02:38,519 --> 00:02:42,390
go through some basic techniques and

00:02:40,920 --> 00:02:45,060
then talk about things you could just

00:02:42,390 --> 00:02:47,579
like go away and usefully do and even if

00:02:45,060 --> 00:02:49,230
you don't know a lot you'll get get some

00:02:47,579 --> 00:02:51,030
bang for your buck by doing these things

00:02:49,230 --> 00:02:52,620
in your own time if some of them seem

00:02:51,030 --> 00:02:55,079
simple I'm not trying to insult

00:02:52,620 --> 00:02:56,549
anybody's intelligence I just want to

00:02:55,079 --> 00:02:59,489
make sure that this talk is very

00:02:56,549 --> 00:03:02,370
accessible so what's the background the

00:02:59,489 --> 00:03:05,220
basic terminology is verification is the

00:03:02,370 --> 00:03:06,980
comparison of something with the truth

00:03:05,220 --> 00:03:09,569
for some definition of the truth

00:03:06,980 --> 00:03:11,700
frequently it's very hard to really pin

00:03:09,569 --> 00:03:13,470
down what the truth is and as soon as

00:03:11,700 --> 00:03:15,299
you try to uh no focus on that and

00:03:13,470 --> 00:03:17,340
unpack it a little bit further you

00:03:15,299 --> 00:03:19,829
discover that your truth is not so much

00:03:17,340 --> 00:03:22,500
the truth that you thought it was one

00:03:19,829 --> 00:03:24,120
particular example of that at work is

00:03:22,500 --> 00:03:27,180
that we we measure where lightning

00:03:24,120 --> 00:03:29,370
strikes occur we have have observations

00:03:27,180 --> 00:03:30,690
of where lightning strikes occur but

00:03:29,370 --> 00:03:33,450
they're actually only accurate to the

00:03:30,690 --> 00:03:35,459
nearest six kilometres and so if you if

00:03:33,450 --> 00:03:37,079
you believe that that's the truth you

00:03:35,459 --> 00:03:39,569
also need to understand that it's not

00:03:37,079 --> 00:03:41,669
the perfect truth and so a lot of

00:03:39,569 --> 00:03:43,019
statistics and verification is about

00:03:41,669 --> 00:03:45,930
what's a valid inference from a

00:03:43,019 --> 00:03:47,700
particular observation or belief about

00:03:45,930 --> 00:03:50,280
the truth in as much as it's about a

00:03:47,700 --> 00:03:52,410
statistical technique there's a lot of

00:03:50,280 --> 00:03:57,959
intersection with with data science

00:03:52,410 --> 00:04:00,150
techniques too which is really if I went

00:03:57,959 --> 00:04:02,519
to work and said I'm a data scientist

00:04:00,150 --> 00:04:05,760
four hundred scientists would turn

00:04:02,519 --> 00:04:07,739
around and go you're not the this is how

00:04:05,760 --> 00:04:10,560
i feel about data science in general it

00:04:07,739 --> 00:04:12,180
really requires a community of people to

00:04:10,560 --> 00:04:14,190
bring it together and I was a bit

00:04:12,180 --> 00:04:15,629
awkward about it as a buzz word but it

00:04:14,190 --> 00:04:19,760
does just mean exactly what we're about

00:04:15,629 --> 00:04:23,250
to talk about so here comes the hard bit

00:04:19,760 --> 00:04:26,460
so this is not a very hard hard bit this

00:04:23,250 --> 00:04:28,919
is a comparison of some mega corporation

00:04:26,460 --> 00:04:31,800
com versus the official Bureau of

00:04:28,919 --> 00:04:33,810
Meteorology forecasts over over

00:04:31,800 --> 00:04:36,240
period and what this graph is showing

00:04:33,810 --> 00:04:38,099
you some things about what we believe is

00:04:36,240 --> 00:04:39,900
the truth of our performance now you

00:04:38,099 --> 00:04:42,539
could imagine drawing a graph like this

00:04:39,900 --> 00:04:44,759
to compare your company against another

00:04:42,539 --> 00:04:47,190
competitor so one of the first points is

00:04:44,759 --> 00:04:49,080
just the visual communication isn't a

00:04:47,190 --> 00:04:51,360
Mickey Mouse tool that's it's actually

00:04:49,080 --> 00:04:53,220
the first tool that everyone at work

00:04:51,360 --> 00:04:55,199
turns to it's not the last tool it's the

00:04:53,220 --> 00:04:57,270
first tool visualizing your results to

00:04:55,199 --> 00:04:58,800
yourself is that is the key aspect here

00:04:57,270 --> 00:05:01,860
so the first thing that we can see is

00:04:58,800 --> 00:05:05,340
that that blue line at the top that's

00:05:01,860 --> 00:05:07,319
that's mega corporation calm and and

00:05:05,340 --> 00:05:10,710
they're a little bit out the this this

00:05:07,319 --> 00:05:13,860
scale on the y-axis is root mean squared

00:05:10,710 --> 00:05:15,479
error for those who are familiar with

00:05:13,860 --> 00:05:17,639
that what it is is it's a kind of

00:05:15,479 --> 00:05:19,289
representative amount in the unit that

00:05:17,639 --> 00:05:22,020
you're talking about so here we're

00:05:19,289 --> 00:05:24,509
talking about temperature the unit is in

00:05:22,020 --> 00:05:26,780
in temperature and it is basically more

00:05:24,509 --> 00:05:30,419
or less the amount that you're wrong by

00:05:26,780 --> 00:05:32,340
representatively on average calculated a

00:05:30,419 --> 00:05:34,409
particular way so the first thing you

00:05:32,340 --> 00:05:36,750
can see is that the the next two lines

00:05:34,409 --> 00:05:40,770
both alternative Bureau of Meteorology

00:05:36,750 --> 00:05:42,779
systems and they're both very reliably a

00:05:40,770 --> 00:05:46,020
bit better than mega corporation calm

00:05:42,779 --> 00:05:50,400
now what's what's important about it is

00:05:46,020 --> 00:05:53,460
is that there's a predictable difference

00:05:50,400 --> 00:05:56,400
you know if they'd the difference is

00:05:53,460 --> 00:05:57,900
very regular it's very precise and now

00:05:56,400 --> 00:06:00,629
down the bottom there we see this thing

00:05:57,900 --> 00:06:03,029
here called bias and what that means is

00:06:00,629 --> 00:06:05,219
that the predictable component of that

00:06:03,029 --> 00:06:07,560
error so we've decomposed that that

00:06:05,219 --> 00:06:09,539
difference in the first sort of margin

00:06:07,560 --> 00:06:11,009
up there into the part that we can

00:06:09,539 --> 00:06:12,990
understand easily in the part that we

00:06:11,009 --> 00:06:14,729
can't and bias just means if you

00:06:12,990 --> 00:06:16,770
consistently added or subtracted a

00:06:14,729 --> 00:06:18,629
certain amount you would just always be

00:06:16,770 --> 00:06:21,180
more right so what this means is that

00:06:18,629 --> 00:06:24,090
mega-corporation com hasn't realized

00:06:21,180 --> 00:06:26,190
that if they just added about a half a

00:06:24,090 --> 00:06:30,690
degree that would just always be better

00:06:26,190 --> 00:06:32,699
so it's you know these sort of basic

00:06:30,690 --> 00:06:35,550
techniques you know that they're not

00:06:32,699 --> 00:06:37,590
deployed by major companies you know

00:06:35,550 --> 00:06:39,629
that these people have the resources to

00:06:37,590 --> 00:06:41,219
go hang on I think I should have add you

00:06:39,629 --> 00:06:43,469
know some small amount to my temperature

00:06:41,219 --> 00:06:45,470
forecast now I kind of agree it's not

00:06:43,469 --> 00:06:47,180
especially important to be

00:06:45,470 --> 00:06:49,280
completely perfect about a temperature

00:06:47,180 --> 00:06:51,680
forecast but it is a good way when you

00:06:49,280 --> 00:06:53,450
come back to understanding a complex

00:06:51,680 --> 00:06:55,580
system to go I this is a little bit

00:06:53,450 --> 00:06:57,050
Apple you know be more exact you know

00:06:55,580 --> 00:06:59,780
you can use it to push yourself to a

00:06:57,050 --> 00:07:01,130
greater degree of exactness sometimes

00:06:59,780 --> 00:07:03,200
you know you need to understand the

00:07:01,130 --> 00:07:05,780
impact of an error in order to decide

00:07:03,200 --> 00:07:07,190
whether it's important and perhaps that

00:07:05,780 --> 00:07:11,420
that's why this particular example

00:07:07,190 --> 00:07:15,080
hasn't been corrected here's another

00:07:11,420 --> 00:07:17,600
another graph so what this here shows is

00:07:15,080 --> 00:07:19,250
the performance according to something

00:07:17,600 --> 00:07:21,310
called an s-1 skill school which I'm not

00:07:19,250 --> 00:07:24,110
going to describe other than to say

00:07:21,310 --> 00:07:26,960
small is good it's like golf you know

00:07:24,110 --> 00:07:28,820
your score system like golf and what we

00:07:26,960 --> 00:07:30,970
have here is the progression of this

00:07:28,820 --> 00:07:33,860
skill on meet mean sea level pressure

00:07:30,970 --> 00:07:35,240
nobody's very directly interested in

00:07:33,860 --> 00:07:36,560
mean sea level pressure but it means

00:07:35,240 --> 00:07:38,570
that we've got the structure of what's

00:07:36,560 --> 00:07:40,790
going on in the atmosphere generally

00:07:38,570 --> 00:07:42,290
right if you were appalling ly wrong

00:07:40,790 --> 00:07:43,730
about me and sea level pressure you

00:07:42,290 --> 00:07:45,110
couldn't be right about everything else

00:07:43,730 --> 00:07:47,600
at the same time so it's sort of a

00:07:45,110 --> 00:07:49,820
representative thing we can look at but

00:07:47,600 --> 00:07:52,010
once again the the observation network

00:07:49,820 --> 00:07:55,520
is somewhat sparse the definition of

00:07:52,010 --> 00:07:57,919
true is is up for debate nonetheless

00:07:55,520 --> 00:08:00,290
it's pretty undeniable that there's been

00:07:57,919 --> 00:08:02,270
a general downward trend over the years

00:08:00,290 --> 00:08:05,060
so one of the things you can use that to

00:08:02,270 --> 00:08:07,220
say is our investment paying off if you

00:08:05,060 --> 00:08:09,020
understand what the s-1 skill score

00:08:07,220 --> 00:08:11,180
means in terms of impacts for your

00:08:09,020 --> 00:08:13,310
customer then you can use it to justify

00:08:11,180 --> 00:08:14,360
business decision if you just understand

00:08:13,310 --> 00:08:16,610
what it means for your scientific

00:08:14,360 --> 00:08:18,650
algorithms you can justify scientific

00:08:16,610 --> 00:08:20,660
direction write up a research paper

00:08:18,650 --> 00:08:24,530
agree to pursue a particular direction

00:08:20,660 --> 00:08:26,479
of research etc etc once again the use

00:08:24,530 --> 00:08:30,140
of the visual means of communication of

00:08:26,479 --> 00:08:32,089
these ideas is especially critical very

00:08:30,140 --> 00:08:34,310
few people will walk around with a

00:08:32,089 --> 00:08:36,020
working understanding of the performance

00:08:34,310 --> 00:08:39,320
characteristics of these systems as

00:08:36,020 --> 00:08:42,260
numbers everyone will will pursue a

00:08:39,320 --> 00:08:45,200
visual visual means of comparison and

00:08:42,260 --> 00:08:47,540
one of the things that that that does is

00:08:45,200 --> 00:08:49,520
it hooks into our all of our spatial

00:08:47,540 --> 00:08:51,710
sort of awareness around you know the

00:08:49,520 --> 00:08:53,480
weight of things visually basically

00:08:51,710 --> 00:08:55,820
works pretty well it's sort of the best

00:08:53,480 --> 00:08:58,310
way to hook into other people's

00:08:55,820 --> 00:08:59,240
intuitive ideas about the scale the

00:08:58,310 --> 00:09:01,910
scale of things and

00:08:59,240 --> 00:09:03,800
you can work as scientist or a data

00:09:01,910 --> 00:09:05,060
scientist or whatever to make sure that

00:09:03,800 --> 00:09:06,920
you've crafted this graph that you can

00:09:05,060 --> 00:09:08,540
understand the other thing is you can't

00:09:06,920 --> 00:09:11,600
really just understand it at a glance

00:09:08,540 --> 00:09:14,120
like I've I've spent like way more than

00:09:11,600 --> 00:09:15,950
I want to of this talk just pointing it

00:09:14,120 --> 00:09:18,290
lines that go downwards and explaining

00:09:15,950 --> 00:09:20,930
what they mean and and this will happen

00:09:18,290 --> 00:09:22,779
you know people need to increase i guess

00:09:20,930 --> 00:09:25,940
like their literacy around these things

00:09:22,779 --> 00:09:28,370
in order to understand a graph fast as

00:09:25,940 --> 00:09:30,380
opposed to you know take some time to to

00:09:28,370 --> 00:09:31,520
digest it but if it's a written report

00:09:30,380 --> 00:09:33,770
or something you know it's not such a

00:09:31,520 --> 00:09:34,910
big deal but for a presentation like

00:09:33,770 --> 00:09:36,500
this you know i got a lot of feedback

00:09:34,910 --> 00:09:37,730
like there's too many lines and i

00:09:36,500 --> 00:09:40,880
haven't talked about what all the lines

00:09:37,730 --> 00:09:42,380
mean and does it make it like what are

00:09:40,880 --> 00:09:45,050
all of those blips me know of any events

00:09:42,380 --> 00:09:47,420
that i could plot on this that explain

00:09:45,050 --> 00:09:49,279
aspects of that graph and why does that

00:09:47,420 --> 00:09:50,959
one line stop and the next one starts so

00:09:49,279 --> 00:09:53,089
there's a lot of non communicated

00:09:50,959 --> 00:09:55,430
aspects to this graph but they do all

00:09:53,089 --> 00:09:58,100
mean something so for people of i guess

00:09:55,430 --> 00:10:00,020
if you have a culture of communicating

00:09:58,100 --> 00:10:01,700
through a particular particular plot

00:10:00,020 --> 00:10:06,170
particular set of metrics you can use

00:10:01,700 --> 00:10:08,600
this approach if not not so much ok so

00:10:06,170 --> 00:10:10,880
what it can do for you i tried to put

00:10:08,600 --> 00:10:13,250
some thought into what it can do for

00:10:10,880 --> 00:10:15,529
people who aren't forecasting things so

00:10:13,250 --> 00:10:18,440
has anyone ever hear tried to predict

00:10:15,529 --> 00:10:23,779
anything in their workplace heaps

00:10:18,440 --> 00:10:25,640
awesome ok i don't really need to go

00:10:23,779 --> 00:10:28,100
into that a lot further for those who

00:10:25,640 --> 00:10:29,300
haven't tried to predict anything i can

00:10:28,100 --> 00:10:32,290
imagine the kinds of things you might

00:10:29,300 --> 00:10:34,910
like to predict anything that either has

00:10:32,290 --> 00:10:36,410
something of personal interest like that

00:10:34,910 --> 00:10:38,839
like you know machine learning is

00:10:36,410 --> 00:10:41,029
incredibly interesting and more and more

00:10:38,839 --> 00:10:43,399
accessible these days and that's how i

00:10:41,029 --> 00:10:45,470
got into it in the first place was just

00:10:43,399 --> 00:10:47,959
because it was fantastically interesting

00:10:45,470 --> 00:10:49,490
and fun and not at all because I cared

00:10:47,959 --> 00:10:52,370
about it from a work perspective but

00:10:49,490 --> 00:10:54,440
I've now pulled the two together so I'd

00:10:52,370 --> 00:10:56,930
actually say don't try and solve a work

00:10:54,440 --> 00:10:59,149
problem just get interested but if you

00:10:56,930 --> 00:11:03,770
do have a work related problem server

00:10:59,149 --> 00:11:05,540
load capacity failure rates you could

00:11:03,770 --> 00:11:10,100
try getting into developer metrics but

00:11:05,540 --> 00:11:11,900
that's a minefield anyway ok so

00:11:10,100 --> 00:11:13,700
interesting things to do so

00:11:11,900 --> 00:11:15,110
this next part of the talk I want to

00:11:13,700 --> 00:11:17,600
talk about things that you could just go

00:11:15,110 --> 00:11:18,650
away and just do like some super easy

00:11:17,600 --> 00:11:20,150
things that if you've got nothing

00:11:18,650 --> 00:11:22,490
nothing else you want to take away from

00:11:20,150 --> 00:11:25,010
the talk like practice doing these you

00:11:22,490 --> 00:11:28,160
know make a graph derive some simple

00:11:25,010 --> 00:11:30,920
statistics find out find out what your

00:11:28,160 --> 00:11:32,750
competitors are doing and then you know

00:11:30,920 --> 00:11:35,090
some some of the dangers in there and

00:11:32,750 --> 00:11:36,920
then what are the big problems so though

00:11:35,090 --> 00:11:39,560
this is looking ahead more to the last

00:11:36,920 --> 00:11:41,570
part of the talk but the existing tools

00:11:39,560 --> 00:11:43,220
are a bit clunky and deficient there are

00:11:41,570 --> 00:11:44,750
some amazing tools but they're not

00:11:43,220 --> 00:11:46,340
really function they're not kind of they

00:11:44,750 --> 00:11:47,750
don't completely cover the kinds of

00:11:46,340 --> 00:11:49,730
things that we sort of really want to do

00:11:47,750 --> 00:11:51,890
and that I think that software engineers

00:11:49,730 --> 00:11:54,200
and the open source community could

00:11:51,890 --> 00:11:55,940
bring to enhancing the experience of

00:11:54,200 --> 00:11:58,490
working with statistics and make them

00:11:55,940 --> 00:12:00,470
more accessible and then yes so this

00:11:58,490 --> 00:12:01,880
last point that I think software

00:12:00,470 --> 00:12:03,530
engineering the science even though

00:12:01,880 --> 00:12:05,180
they've been working very closely for

00:12:03,530 --> 00:12:06,500
many years I think it can go further and

00:12:05,180 --> 00:12:09,020
I think you can go further and open

00:12:06,500 --> 00:12:10,700
source that said python is one of the

00:12:09,020 --> 00:12:15,050
best languages in the best communities

00:12:10,700 --> 00:12:17,510
already so the first kind of simple plot

00:12:15,050 --> 00:12:21,140
is a scatter plot hands up who just

00:12:17,510 --> 00:12:23,570
understands this at a glance cool so

00:12:21,140 --> 00:12:26,240
like most of the room okay that's great

00:12:23,570 --> 00:12:27,980
now hands up if you think that this is

00:12:26,240 --> 00:12:31,280
one of the best ways to start looking at

00:12:27,980 --> 00:12:32,720
data not very many okay that now that's

00:12:31,280 --> 00:12:34,610
interesting to me because this is one of

00:12:32,720 --> 00:12:36,980
the first ways that i tend to start

00:12:34,610 --> 00:12:38,960
looking at data and one of the reasons

00:12:36,980 --> 00:12:41,510
for that is that most kinds of

00:12:38,960 --> 00:12:44,510
relationship can be visually detected in

00:12:41,510 --> 00:12:47,900
a scatter plot so i personally feel like

00:12:44,510 --> 00:12:50,450
if you wanted to communicate to someone

00:12:47,900 --> 00:12:52,520
who doesn't understand a lot about

00:12:50,450 --> 00:12:54,230
statistics a scatter plot is something

00:12:52,520 --> 00:12:56,420
you can show them and you can talk about

00:12:54,230 --> 00:12:59,780
the inherent visual structure in the

00:12:56,420 --> 00:13:01,400
diagram and even if and for someone

00:12:59,780 --> 00:13:02,690
working with things if you have a kind

00:13:01,400 --> 00:13:04,610
of a hypothesis that you want to

00:13:02,690 --> 00:13:06,500
understand the scatter plot is one of

00:13:04,610 --> 00:13:09,170
the best ways for you to just visually

00:13:06,500 --> 00:13:10,880
without having to manipulate or process

00:13:09,170 --> 00:13:12,260
the data to just throw it up visually

00:13:10,880 --> 00:13:14,900
and get your first first visual

00:13:12,260 --> 00:13:16,730
understanding of what's going on so what

00:13:14,900 --> 00:13:19,040
this is showing is a slight negative

00:13:16,730 --> 00:13:20,450
correlation between the two two

00:13:19,040 --> 00:13:22,520
variables that we're looking at a

00:13:20,450 --> 00:13:24,530
positive one a perfect positive would be

00:13:22,520 --> 00:13:24,930
sloping up at 45 and a perfect negative

00:13:24,530 --> 00:13:27,510
would

00:13:24,930 --> 00:13:29,730
be down at 45 so what this is showing is

00:13:27,510 --> 00:13:32,310
a week but definite relationship between

00:13:29,730 --> 00:13:35,880
the two so for me I feel like it's one

00:13:32,310 --> 00:13:37,410
of the it's quick it's also pretty true

00:13:35,880 --> 00:13:40,710
like you haven't had to do a lot of data

00:13:37,410 --> 00:13:43,380
manipulation to arrive at this graph you

00:13:40,710 --> 00:13:46,470
but anything that's point-based you

00:13:43,380 --> 00:13:48,270
you've often if it's not point if it's

00:13:46,470 --> 00:13:50,399
area or time-based you often end up

00:13:48,270 --> 00:13:52,260
doing a bit of interpolation or a bit of

00:13:50,399 --> 00:13:53,940
averaging or a bit of massaging and

00:13:52,260 --> 00:13:56,520
whereas this gives you a pretty direct

00:13:53,940 --> 00:13:58,860
look at underlying data which offline

00:13:56,520 --> 00:14:01,649
find pretty useful so for me it's well

00:13:58,860 --> 00:14:04,709
worth doing the other one is a spatial

00:14:01,649 --> 00:14:07,380
plot so in this particular case what you

00:14:04,709 --> 00:14:09,420
can see is the I mean you know whether

00:14:07,380 --> 00:14:12,420
weather systems have an inherent spatial

00:14:09,420 --> 00:14:14,100
structure it's immediately visible here

00:14:12,420 --> 00:14:17,070
that that there is a spatial structure

00:14:14,100 --> 00:14:18,660
to what's going on a system is an

00:14:17,070 --> 00:14:20,940
object-based way of understanding the

00:14:18,660 --> 00:14:22,860
data if you didn't have this you would

00:14:20,940 --> 00:14:25,110
it would instantly be apparent if you

00:14:22,860 --> 00:14:28,910
compared this to to noise or something

00:14:25,110 --> 00:14:32,130
like that so particularly it invested

00:14:28,910 --> 00:14:34,830
investigative stages of the analysis

00:14:32,130 --> 00:14:36,690
when you don't know what the best plot

00:14:34,830 --> 00:14:38,370
to communicate the true essence of

00:14:36,690 --> 00:14:41,190
what's going on I think these are some

00:14:38,370 --> 00:14:43,680
really good techniques the next thing

00:14:41,190 --> 00:14:46,800
that I'm going to move into is probably

00:14:43,680 --> 00:14:48,690
where I I expect what depends on exactly

00:14:46,800 --> 00:14:50,459
who showed up but this is where we we

00:14:48,690 --> 00:14:53,540
might lose some people in terms of the

00:14:50,459 --> 00:14:56,450
number of hands that get thrown up so

00:14:53,540 --> 00:15:00,720
hands up if you know what a p-value is

00:14:56,450 --> 00:15:06,089
okay still lots but definitely fewer ok

00:15:00,720 --> 00:15:07,529
so I p-values are you know the standard

00:15:06,089 --> 00:15:10,890
double negative thinking it just

00:15:07,529 --> 00:15:16,079
confuses everybody you know who doesn't

00:15:10,890 --> 00:15:17,880
not understand this ok so I think one of

00:15:16,079 --> 00:15:19,950
the big problems with it is that is this

00:15:17,880 --> 00:15:23,399
double negative thinking but in general

00:15:19,950 --> 00:15:25,200
at least as I've used it which is not

00:15:23,399 --> 00:15:27,120
completely extensively but just for some

00:15:25,200 --> 00:15:29,579
basic works i'm online work and a few

00:15:27,120 --> 00:15:31,589
things of my own is it's the probability

00:15:29,579 --> 00:15:34,680
that I'm just totally wrong about my

00:15:31,589 --> 00:15:37,680
assumption it's it's you know it's exit

00:15:34,680 --> 00:15:41,130
you know it's the most basic exception

00:15:37,680 --> 00:15:43,140
zedge that you could have so if I've

00:15:41,130 --> 00:15:45,570
done something interesting then it's

00:15:43,140 --> 00:15:52,649
very unlikely that what I've done will

00:15:45,570 --> 00:15:55,410
mean nothing and so so a very Lopes oh

00:15:52,649 --> 00:15:57,480
so basically a very very low p value

00:15:55,410 --> 00:15:59,880
means that it's almost certain that at

00:15:57,480 --> 00:16:02,130
least something is happening into in

00:15:59,880 --> 00:16:04,200
what you're doing and and generally I

00:16:02,130 --> 00:16:07,020
regarded it it's very much the starting

00:16:04,200 --> 00:16:09,330
point but not the ending point it does

00:16:07,020 --> 00:16:11,610
make a few assumptions or at least

00:16:09,330 --> 00:16:14,190
depending on the specific implementation

00:16:11,610 --> 00:16:16,320
of the p value that you've chosen it can

00:16:14,190 --> 00:16:18,330
make a few assumptions so if anyone who

00:16:16,320 --> 00:16:21,440
hasn't done one before there's this one

00:16:18,330 --> 00:16:24,570
inside pi called mann-whitney u which

00:16:21,440 --> 00:16:27,089
rather than working with the absolute

00:16:24,570 --> 00:16:30,000
values of the data or this or the

00:16:27,089 --> 00:16:32,100
distribution will work on a comparison

00:16:30,000 --> 00:16:33,839
of how many elements of the first one

00:16:32,100 --> 00:16:36,180
are bigger than elements of the second

00:16:33,839 --> 00:16:37,680
one and user a sort of ranking approach

00:16:36,180 --> 00:16:40,350
and then look at that so it sort of

00:16:37,680 --> 00:16:41,910
takes away a little bit of some of the

00:16:40,350 --> 00:16:44,010
assumptions that you might be making and

00:16:41,910 --> 00:16:46,589
it's a little bit more robust than some

00:16:44,010 --> 00:16:49,200
of the other choices so if you if you

00:16:46,589 --> 00:16:51,570
have a hypothesis like more people wag

00:16:49,200 --> 00:16:53,430
work on fridays you can break up your

00:16:51,570 --> 00:16:55,560
data into Friday's and the rest of the

00:16:53,430 --> 00:16:57,420
week and you can run a pee test but that

00:16:55,560 --> 00:17:00,900
doesn't mean you're right about the

00:16:57,420 --> 00:17:02,490
cause so it might for example there was

00:17:00,900 --> 00:17:04,589
a great Dilbert cartoon saying you know

00:17:02,490 --> 00:17:06,270
forty percent of annual leave is taken

00:17:04,589 --> 00:17:08,579
on mondays and fridays this is a

00:17:06,270 --> 00:17:10,140
terrible terrible thing well it's true

00:17:08,579 --> 00:17:15,510
but that's also forty percent of days

00:17:10,140 --> 00:17:17,640
right so so so you do need to you do

00:17:15,510 --> 00:17:20,910
need to realize that it's the starting

00:17:17,640 --> 00:17:22,470
point the next thing that will be I

00:17:20,910 --> 00:17:25,500
think familiar to everyone in the room

00:17:22,470 --> 00:17:28,140
but potentially if you if you're going

00:17:25,500 --> 00:17:29,580
well is this true okay like let's look

00:17:28,140 --> 00:17:31,140
at how many days it was more than

00:17:29,580 --> 00:17:32,850
average or below average and try to

00:17:31,140 --> 00:17:34,679
calculate something if you're not

00:17:32,850 --> 00:17:36,420
careful you're above average days it

00:17:34,679 --> 00:17:38,550
will actually cancel out your below

00:17:36,420 --> 00:17:39,840
average days because you you'll be above

00:17:38,550 --> 00:17:42,290
the mean and below the mean it'll

00:17:39,840 --> 00:17:45,030
average out but actually you're wrong

00:17:42,290 --> 00:17:46,559
but by that amount quite often so if you

00:17:45,030 --> 00:17:48,620
want to know how precise you can be

00:17:46,559 --> 00:17:51,600
rather than just what the average is

00:17:48,620 --> 00:17:57,299
stay positive square everything

00:17:51,600 --> 00:17:58,770
I love that mean okay so I want to talk

00:17:57,299 --> 00:18:01,049
about now about where you go after

00:17:58,770 --> 00:18:03,179
you've done done it you've got this idea

00:18:01,049 --> 00:18:05,100
you know you've broken your data up into

00:18:03,179 --> 00:18:06,570
you know mundane monday and friday

00:18:05,100 --> 00:18:08,179
because they're around the weekend

00:18:06,570 --> 00:18:10,260
versus the rest of your data and

00:18:08,179 --> 00:18:12,450
definitely like something is happening

00:18:10,260 --> 00:18:14,850
but you know maybe it's maybe it's not

00:18:12,450 --> 00:18:16,559
maybe the cause is wrong maybe you've

00:18:14,850 --> 00:18:19,020
got four or five factors in your data

00:18:16,559 --> 00:18:22,230
that you want to do and you now need to

00:18:19,020 --> 00:18:25,140
test specifically whether your

00:18:22,230 --> 00:18:29,190
hypothesis is right and how much of

00:18:25,140 --> 00:18:30,570
what's going on can it explain so root

00:18:29,190 --> 00:18:33,299
mean squared error is a good way of

00:18:30,570 --> 00:18:35,669
doing that that's where you take the

00:18:33,299 --> 00:18:38,429
above you know above the mean the

00:18:35,669 --> 00:18:42,030
positive error- to the low the mean-

00:18:38,429 --> 00:18:44,909
error you know and work with them as as

00:18:42,030 --> 00:18:46,650
both contributing to two problems or

00:18:44,909 --> 00:18:48,750
error so that the idea is you want to be

00:18:46,650 --> 00:18:50,760
precise you don't sometimes you will

00:18:48,750 --> 00:18:52,409
actually only care about the positive

00:18:50,760 --> 00:18:54,150
error or only care about the negative

00:18:52,409 --> 00:18:55,799
error that does happen and we do get

00:18:54,150 --> 00:18:57,600
into it it's a really good starting

00:18:55,799 --> 00:18:59,340
point and the fundamental advantage of

00:18:57,600 --> 00:19:00,960
is when you say some say to someone all

00:18:59,340 --> 00:19:02,940
we have an error of about two degrees

00:19:00,960 --> 00:19:05,100
they don't need to understand something

00:19:02,940 --> 00:19:06,929
complicated about statistics because

00:19:05,100 --> 00:19:08,730
everyone in the world understands the

00:19:06,929 --> 00:19:10,409
degrees or if it's not degrees you can

00:19:08,730 --> 00:19:12,150
go a number of days of leave your

00:19:10,409 --> 00:19:14,669
manager will already understand the

00:19:12,150 --> 00:19:16,559
concept of days of leave or hours worked

00:19:14,669 --> 00:19:18,210
or something like that you don't need to

00:19:16,559 --> 00:19:21,929
explain a new unit of measurement to

00:19:18,210 --> 00:19:24,960
them the one that I particularly like is

00:19:21,929 --> 00:19:29,159
this one called called R squared so if

00:19:24,960 --> 00:19:30,840
you have some kind of prediction and the

00:19:29,159 --> 00:19:33,690
these sort of points which occur so the

00:19:30,840 --> 00:19:37,890
idea is the the dots represent points

00:19:33,690 --> 00:19:39,750
that actually happened and the line on

00:19:37,890 --> 00:19:42,659
the right the F represents your sort of

00:19:39,750 --> 00:19:44,340
forecast about what happened and the y

00:19:42,659 --> 00:19:47,220
bar on the Left represents the average

00:19:44,340 --> 00:19:50,179
of what happened the r-squared is

00:19:47,220 --> 00:19:51,990
basically the difference between

00:19:50,179 --> 00:19:54,059
assuming that the mean was going to

00:19:51,990 --> 00:19:55,350
happen in terms of this you know the

00:19:54,059 --> 00:19:57,780
amount so that the difference between

00:19:55,350 --> 00:19:59,340
the observed and the average versus the

00:19:57,780 --> 00:20:01,350
difference between the observed and your

00:19:59,340 --> 00:20:04,950
forecast and so that that relationship

00:20:01,350 --> 00:20:05,639
is actually really solid and saying well

00:20:04,950 --> 00:20:08,249
if you've managed

00:20:05,639 --> 00:20:10,739
to reduce the area compared to the mean

00:20:08,249 --> 00:20:12,329
by a significant amount then you know

00:20:10,739 --> 00:20:14,519
like you've nailed it your forecast has

00:20:12,329 --> 00:20:16,889
a lot of explanatory power you can feel

00:20:14,519 --> 00:20:19,979
quite confident that what you've done is

00:20:16,889 --> 00:20:22,709
a good thing so the this is a fairly

00:20:19,979 --> 00:20:24,299
easy to calculate kind of metric it's

00:20:22,709 --> 00:20:26,759
something you can do something he can do

00:20:24,299 --> 00:20:32,129
fast it's not mathematically complicated

00:20:26,759 --> 00:20:35,909
and it's explainable I've basically just

00:20:32,129 --> 00:20:37,409
said all of that okay so one of the

00:20:35,909 --> 00:20:40,440
things about the r-squared is that it

00:20:37,409 --> 00:20:42,509
does use the mean the thing over on the

00:20:40,440 --> 00:20:43,979
left is the basis for comparison if you

00:20:42,509 --> 00:20:45,209
have three or four alternatives that you

00:20:43,979 --> 00:20:47,279
want to evaluate if you're in a

00:20:45,209 --> 00:20:50,190
forecasting situation you can either

00:20:47,279 --> 00:20:51,779
compare their r-squared values or what

00:20:50,190 --> 00:20:55,200
you can do is say in some case in the

00:20:51,779 --> 00:20:59,039
mean is so rudimentary that it's not

00:20:55,200 --> 00:21:00,959
actually a good basis so like at the

00:20:59,039 --> 00:21:02,759
weather bureau rather than saying we

00:21:00,959 --> 00:21:06,029
compared to the average temperature all

00:21:02,759 --> 00:21:09,989
year day or night hey we nailed it we

00:21:06,029 --> 00:21:13,489
you know we compare it to climate ology

00:21:09,989 --> 00:21:18,169
which is the the average long-term

00:21:13,489 --> 00:21:20,279
expected expected value of these things

00:21:18,169 --> 00:21:22,499
okay so what you can do then is

00:21:20,279 --> 00:21:25,950
establish a reference standard for that

00:21:22,499 --> 00:21:27,239
for the basis for comparison okay this

00:21:25,950 --> 00:21:29,399
is something else you can try at home

00:21:27,239 --> 00:21:31,229
I'm not going to explain what you can do

00:21:29,399 --> 00:21:33,269
with this table of values but there are

00:21:31,229 --> 00:21:36,119
an enormous number of metrics that you

00:21:33,269 --> 00:21:39,029
can calculate based on correct forecasts

00:21:36,119 --> 00:21:41,219
false alarms mrs. and correct negatives

00:21:39,029 --> 00:21:43,409
in terms of establishing different kinds

00:21:41,219 --> 00:21:46,919
of skills score for your system and the

00:21:43,409 --> 00:21:49,950
various ones will penalize different

00:21:46,919 --> 00:21:52,049
kinds of biases differently so for some

00:21:49,950 --> 00:21:53,519
people if you have a lot of false alarms

00:21:52,049 --> 00:21:55,739
you'll have a kind of boy oh boy who

00:21:53,519 --> 00:21:58,109
cried wolf problem and and your system

00:21:55,739 --> 00:22:00,479
won't be valuable on the other hand a

00:21:58,109 --> 00:22:01,950
lot of people are very sensitive to mrs.

00:22:00,479 --> 00:22:03,779
you know they might be very sensitive to

00:22:01,950 --> 00:22:05,820
it to something occurring that wasn't

00:22:03,779 --> 00:22:07,320
forecast and so they want to hear about

00:22:05,820 --> 00:22:09,539
it even if you're even if your

00:22:07,320 --> 00:22:11,249
confidence is low so you can use this

00:22:09,539 --> 00:22:13,349
essentially table of values you could

00:22:11,249 --> 00:22:15,239
just start recording this database that

00:22:13,349 --> 00:22:16,679
would be a good first step and then you

00:22:15,239 --> 00:22:19,019
can go in and look at some of the

00:22:16,679 --> 00:22:19,450
metrics that are linked to in terms of

00:22:19,019 --> 00:22:22,450
further

00:22:19,450 --> 00:22:24,070
information and the interest of time I'm

00:22:22,450 --> 00:22:27,389
not going to talk about the general form

00:22:24,070 --> 00:22:27,389
of a skill score from that matrix

00:22:27,659 --> 00:22:35,169
gotchas hidden variables are a gotcha

00:22:32,250 --> 00:22:37,419
always so just make sure that you but

00:22:35,169 --> 00:22:39,220
there's no magic bullet to a hidden

00:22:37,419 --> 00:22:40,750
variable that you don't know is there

00:22:39,220 --> 00:22:42,850
you know that's where you think that

00:22:40,750 --> 00:22:44,470
that one particular cause is leading to

00:22:42,850 --> 00:22:46,149
the consequence but you don't understand

00:22:44,470 --> 00:22:47,730
it's actually related to another thing

00:22:46,149 --> 00:22:50,110
that you haven't included in your model

00:22:47,730 --> 00:22:51,519
there's no magic bullet but what you do

00:22:50,110 --> 00:22:54,399
need to do is make sure that you have

00:22:51,519 --> 00:22:58,149
had enough consideration of what's going

00:22:54,399 --> 00:23:00,070
on so that might be you assume that

00:22:58,149 --> 00:23:02,649
people are more likely to take sick days

00:23:00,070 --> 00:23:05,769
on mondays or fridays but actually

00:23:02,649 --> 00:23:07,360
what's going on is you're more like no I

00:23:05,769 --> 00:23:08,769
tried to come up with an example on the

00:23:07,360 --> 00:23:10,299
fly and failed I was going to say to

00:23:08,769 --> 00:23:11,980
what people are just more likely to take

00:23:10,299 --> 00:23:13,600
a long weekend but those two things

00:23:11,980 --> 00:23:16,840
aren't related to hidden variable is

00:23:13,600 --> 00:23:18,100
more likely to be a related concept but

00:23:16,840 --> 00:23:19,600
there might be things that you fail to

00:23:18,100 --> 00:23:21,610
capture in your model which are leading

00:23:19,600 --> 00:23:23,380
to the same cause from from the apparent

00:23:21,610 --> 00:23:27,159
inputs but there's more thinking that

00:23:23,380 --> 00:23:28,750
you need to do rounding can lead to

00:23:27,159 --> 00:23:30,190
problems we had a problem where our

00:23:28,750 --> 00:23:31,659
observers were writing down the

00:23:30,190 --> 00:23:33,720
temperature this was actually a number

00:23:31,659 --> 00:23:35,830
of years ago like we've moved on but

00:23:33,720 --> 00:23:37,809
they would have to write it to the

00:23:35,830 --> 00:23:39,490
nearest half degree or maybe whole

00:23:37,809 --> 00:23:41,740
degree and they would round up so they

00:23:39,490 --> 00:23:43,419
were told the direction of rounding and

00:23:41,740 --> 00:23:45,760
this actually introduced a bias into the

00:23:43,419 --> 00:23:47,620
observations so instead of rounding up

00:23:45,760 --> 00:23:50,110
we told them to round to the nearest odd

00:23:47,620 --> 00:23:52,330
number because that would be up or down

00:23:50,110 --> 00:23:56,110
roughly fifty percent of the time yield

00:23:52,330 --> 00:23:58,360
as you scale variants can be a big deal

00:23:56,110 --> 00:24:00,370
we have the weather models do very well

00:23:58,360 --> 00:24:02,470
at broad scale but don't necessarily

00:24:00,370 --> 00:24:04,840
capture topography so if you assess them

00:24:02,470 --> 00:24:07,269
at a fine scale they'll get a very bad

00:24:04,840 --> 00:24:09,460
score in many situations but if you

00:24:07,269 --> 00:24:12,639
assess them at the broad scale they've

00:24:09,460 --> 00:24:13,899
got really a lot of skill and it's not

00:24:12,639 --> 00:24:16,779
just a matter of being fair to the

00:24:13,899 --> 00:24:19,299
models if you can understand how to like

00:24:16,779 --> 00:24:21,250
what what is a valid inference where is

00:24:19,299 --> 00:24:23,500
the skill is the skill and the broad

00:24:21,250 --> 00:24:25,450
strokes as the skill in the detail can

00:24:23,500 --> 00:24:28,409
we unpack the kind of inferences that we

00:24:25,450 --> 00:24:31,720
can support from our data analysis

00:24:28,409 --> 00:24:33,430
scores can be sensitive to data size so

00:24:31,720 --> 00:24:36,010
sometimes if you just have

00:24:33,430 --> 00:24:37,450
the prediction system and it's you know

00:24:36,010 --> 00:24:39,550
it's got a pretty kind of constant set

00:24:37,450 --> 00:24:41,700
of skill and you run it over a small sub

00:24:39,550 --> 00:24:44,920
small amount of data versus a large site

00:24:41,700 --> 00:24:46,720
piece of data sometimes various metrics

00:24:44,920 --> 00:24:48,850
can penalize the inclusion of the

00:24:46,720 --> 00:24:50,230
additional data even though basically

00:24:48,850 --> 00:24:52,890
the performance hasn't gotten any worse

00:24:50,230 --> 00:24:56,470
and a lot of the more more sophisticated

00:24:52,890 --> 00:24:58,240
scores are about including factors that

00:24:56,470 --> 00:25:01,060
you know avoid these problems of

00:24:58,240 --> 00:25:02,620
penalizing large data sets and then

00:25:01,060 --> 00:25:06,250
errors and observations which I've

00:25:02,620 --> 00:25:08,140
talked about already okay I wanted to

00:25:06,250 --> 00:25:09,760
talk briefly about thunderstorm

00:25:08,140 --> 00:25:11,110
forecasting to make this more concrete

00:25:09,760 --> 00:25:13,980
so this is something that I'm doing at

00:25:11,110 --> 00:25:16,600
the moat at the moment at work in a very

00:25:13,980 --> 00:25:18,010
prototyping research II kind of way you

00:25:16,600 --> 00:25:19,690
know we haven't really got hard evidence

00:25:18,010 --> 00:25:21,670
yet I just wanted to introduce someone

00:25:19,690 --> 00:25:23,800
introduced the audience to the concept

00:25:21,670 --> 00:25:26,650
of coming at this maybe from the first

00:25:23,800 --> 00:25:28,420
time so thunderstorm forecasting is

00:25:26,650 --> 00:25:30,160
often more about forecasting the

00:25:28,420 --> 00:25:33,100
direction and speed of movement of

00:25:30,160 --> 00:25:35,380
currently existing thunderstorms because

00:25:33,100 --> 00:25:37,300
that's relatively easy as opposed to the

00:25:35,380 --> 00:25:40,720
development of a new thunderstorm from

00:25:37,300 --> 00:25:42,760
scratch out in the environment which are

00:25:40,720 --> 00:25:44,880
called in situ storms or as I like to

00:25:42,760 --> 00:25:47,980
think of them ninja thunderstorms and

00:25:44,880 --> 00:25:49,830
and that's the only reason I put that in

00:25:47,980 --> 00:25:52,060
there is because I like that slide so

00:25:49,830 --> 00:25:53,590
one of the things that lightning that

00:25:52,060 --> 00:25:55,440
thunderstorm forecasting is often

00:25:53,590 --> 00:25:58,120
assessed on is the speed and direction

00:25:55,440 --> 00:26:00,550
accuracy of the predicted movement of a

00:25:58,120 --> 00:26:03,270
thunderstorm but I find that's really

00:26:00,550 --> 00:26:05,770
abstract you know people aren't nests

00:26:03,270 --> 00:26:07,930
are directly there's no physical

00:26:05,770 --> 00:26:10,690
phenomena a thunderstorm this physical

00:26:07,930 --> 00:26:12,250
phenomena rain hail lightning you know

00:26:10,690 --> 00:26:14,680
those are the those are the impacting

00:26:12,250 --> 00:26:15,970
aspects of a thunderstorm so while we

00:26:14,680 --> 00:26:18,250
use the the thunderstorm as an

00:26:15,970 --> 00:26:20,920
abstraction to describe what you know

00:26:18,250 --> 00:26:22,990
going on in the atmosphere when we want

00:26:20,920 --> 00:26:24,760
to link that to impact on people rather

00:26:22,990 --> 00:26:26,410
than just understand it more abstractly

00:26:24,760 --> 00:26:29,560
we need to go into something like

00:26:26,410 --> 00:26:32,590
lightning so this is where we took three

00:26:29,560 --> 00:26:34,030
of our thunderstorm warnings counted up

00:26:32,590 --> 00:26:36,430
the number of lightning strikes that

00:26:34,030 --> 00:26:37,990
were in the area versus out the area so

00:26:36,430 --> 00:26:40,840
this doesn't support that full table

00:26:37,990 --> 00:26:43,270
because I did what I this is assuming a

00:26:40,840 --> 00:26:45,190
warning is present what happened rather

00:26:43,270 --> 00:26:46,570
than a generalized analysis of what

00:26:45,190 --> 00:26:47,230
happens when we don't have a warning out

00:26:46,570 --> 00:26:48,580
but

00:26:47,230 --> 00:26:50,470
what we can see here is that we can

00:26:48,580 --> 00:26:51,940
calculate the probability of a detection

00:26:50,470 --> 00:26:53,980
so given that there's a warning out and

00:26:51,940 --> 00:26:56,080
given that a lightning strike occurred

00:26:53,980 --> 00:26:57,910
what is the probability that it's one

00:26:56,080 --> 00:27:00,760
that we forecast versus being hit by

00:26:57,910 --> 00:27:02,980
something unexpected so in a warning

00:27:00,760 --> 00:27:04,390
situation there's still a forty percent

00:27:02,980 --> 00:27:08,500
chance that if you get hit by lightning

00:27:04,390 --> 00:27:11,260
it's not under a warning area so it for

00:27:08,500 --> 00:27:13,210
that specific warning so i really don't

00:27:11,260 --> 00:27:15,309
I would genuinely expect that this

00:27:13,210 --> 00:27:17,350
wouldn't generalize that's just like one

00:27:15,309 --> 00:27:19,120
example but I think it's enough of a

00:27:17,350 --> 00:27:21,100
it's enough of a when it's the first

00:27:19,120 --> 00:27:23,710
thing you look at it's enough motivation

00:27:21,100 --> 00:27:25,870
to go I should investigate this further

00:27:23,710 --> 00:27:27,309
it's probably important that people

00:27:25,870 --> 00:27:29,049
understand something about a

00:27:27,309 --> 00:27:31,480
thunderstorm forecasts if they care

00:27:29,049 --> 00:27:34,059
about lightning so it's the kind of

00:27:31,480 --> 00:27:36,280
thing where there's a bit there's the

00:27:34,059 --> 00:27:38,230
presence of additional evidence to

00:27:36,280 --> 00:27:41,169
support us doing a greater analysis of

00:27:38,230 --> 00:27:43,919
lightning risk I've done the same thing

00:27:41,169 --> 00:27:47,080
with very very heavy rainfall Oh

00:27:43,919 --> 00:27:48,850
wonderful it projects just fine so what

00:27:47,080 --> 00:27:50,710
we can see here is that in some of our

00:27:48,850 --> 00:27:52,840
warnings so the first ones they're very

00:27:50,710 --> 00:27:55,419
heavy rainfall pixels are entirely in

00:27:52,840 --> 00:27:56,919
the warning area in the threat area but

00:27:55,419 --> 00:27:59,620
later on for these other warnings

00:27:56,919 --> 00:28:01,900
there's actually a very high amount of

00:27:59,620 --> 00:28:04,240
very heavy rainfall occurring outside of

00:28:01,900 --> 00:28:06,160
the thunderstorm warnings now very heavy

00:28:04,240 --> 00:28:08,440
rainfall we need to want to unpack that

00:28:06,160 --> 00:28:11,110
further is there anything else that we

00:28:08,440 --> 00:28:13,240
that that causes very heavy rainfall in

00:28:11,110 --> 00:28:15,520
other warning products are people

00:28:13,240 --> 00:28:17,049
expecting to get multiple warnings about

00:28:15,520 --> 00:28:19,270
very heavy rainfall or are they just

00:28:17,049 --> 00:28:21,160
looking at the thunderstorm warning so a

00:28:19,270 --> 00:28:23,620
lot of the time when you find a piece of

00:28:21,160 --> 00:28:27,160
evidence all you have is about a million

00:28:23,620 --> 00:28:29,770
more questions and arriving at what's

00:28:27,160 --> 00:28:31,750
important to communicate it is a lot of

00:28:29,770 --> 00:28:33,370
the problem because I mean I I could

00:28:31,750 --> 00:28:35,020
just I could you know come here with

00:28:33,370 --> 00:28:37,419
just like a million pieces of

00:28:35,020 --> 00:28:38,770
information about thunderstorms and no

00:28:37,419 --> 00:28:40,840
one would walk out any of the wiser

00:28:38,770 --> 00:28:42,010
other than Tennessee probably doesn't

00:28:40,840 --> 00:28:44,740
understand what's important about

00:28:42,010 --> 00:28:46,600
thunderstorms you really need to this is

00:28:44,740 --> 00:28:49,059
more the tools you use at first as a

00:28:46,600 --> 00:28:52,090
researcher and then you go okay I can

00:28:49,059 --> 00:28:53,950
explain away the 18 and the 31 but not

00:28:52,090 --> 00:28:56,049
the 10 or the six because the 18 and the

00:28:53,950 --> 00:28:58,750
31 were covered by a rain warning for

00:28:56,049 --> 00:29:00,340
example so you need to do more work but

00:28:58,750 --> 00:29:00,820
it's an example of how you can very

00:29:00,340 --> 00:29:03,190
quickly

00:29:00,820 --> 00:29:06,100
use some of these statistics probability

00:29:03,190 --> 00:29:07,840
of detection false alarm rate etc to

00:29:06,100 --> 00:29:09,429
communicate with scientific colleagues

00:29:07,840 --> 00:29:11,529
or other people who understand those

00:29:09,429 --> 00:29:14,049
terminologies about the important

00:29:11,529 --> 00:29:16,630
aspects of your of your system but you

00:29:14,049 --> 00:29:18,250
first need to do the understanding work

00:29:16,630 --> 00:29:19,539
yourself so that you make sure that

00:29:18,250 --> 00:29:22,419
you're communicating something that's

00:29:19,539 --> 00:29:24,700
that's very relevant so it's your job to

00:29:22,419 --> 00:29:26,500
decide what's relevant and then you can

00:29:24,700 --> 00:29:28,149
use these statistics to communicate and

00:29:26,500 --> 00:29:32,019
compare and contrast with other forecast

00:29:28,149 --> 00:29:34,120
systems so something you could do is go

00:29:32,019 --> 00:29:36,159
to the bureau's external web page look

00:29:34,120 --> 00:29:38,139
at their skill in forecasting in general

00:29:36,159 --> 00:29:40,330
and then if you cut if you come up with

00:29:38,139 --> 00:29:41,830
a forecasting system for server load you

00:29:40,330 --> 00:29:42,909
can tell your manager whether it's more

00:29:41,830 --> 00:29:48,159
or less accurate than the weather

00:29:42,909 --> 00:29:52,389
forecast and I like that idea alright so

00:29:48,159 --> 00:29:55,570
the next that's the slidy bit now we've

00:29:52,389 --> 00:29:57,850
got a tool that I you that I've I call

00:29:55,570 --> 00:30:00,129
it a sketch of a piece of software it's

00:29:57,850 --> 00:30:02,230
not a real piece of software something I

00:30:00,129 --> 00:30:05,799
built for myself demonstrate concepts

00:30:02,230 --> 00:30:07,750
and potentially deploy and then with

00:30:05,799 --> 00:30:09,220
luck a little bit they'll also still be

00:30:07,750 --> 00:30:12,159
time for a better conversation about

00:30:09,220 --> 00:30:14,289
future where I see some you know maybe a

00:30:12,159 --> 00:30:16,210
bit pie in the sky but ideas about where

00:30:14,289 --> 00:30:21,419
open source could could help take this

00:30:16,210 --> 00:30:28,179
kind of software and analysis further so

00:30:21,419 --> 00:30:33,909
let me is it running yes it's running

00:30:28,179 --> 00:30:37,389
okay is it reasonably viewable on this

00:30:33,909 --> 00:30:39,700
projector it is now reasonably viewable

00:30:37,389 --> 00:30:46,330
on this projector okay so what this is

00:30:39,700 --> 00:30:50,370
my first web application ever yeah you

00:30:46,330 --> 00:30:50,370
can tell because I use bootstrap which

00:30:50,669 --> 00:30:56,649
is a wonderful wonderful tool everybody

00:30:53,679 --> 00:30:58,899
should just use bootstrap okay so this

00:30:56,649 --> 00:31:02,590
is for me it's a mixture of it's an

00:30:58,899 --> 00:31:05,470
all-in-one data collection analysis

00:31:02,590 --> 00:31:07,960
experiment and learning environment that

00:31:05,470 --> 00:31:10,419
could be used on a server in a kind of

00:31:07,960 --> 00:31:13,629
you know cloudy everybody can look at it

00:31:10,419 --> 00:31:14,650
kind of way or an organizational you

00:31:13,629 --> 00:31:16,570
know there's a project

00:31:14,650 --> 00:31:18,610
and everybody can use a kind of way or

00:31:16,570 --> 00:31:20,320
I've got a bunch of stuff on my laptop

00:31:18,610 --> 00:31:22,510
I'm hacking on kind of way which is

00:31:20,320 --> 00:31:23,950
pretty much mostly how I use it so

00:31:22,510 --> 00:31:25,810
consists of currently running

00:31:23,950 --> 00:31:28,060
experiments so experiments just think of

00:31:25,810 --> 00:31:30,040
it as like your project directory a

00:31:28,060 --> 00:31:32,470
learning environment which I'm quite

00:31:30,040 --> 00:31:34,600
happy about so the concept here is that

00:31:32,470 --> 00:31:36,490
if I need another developer to be

00:31:34,600 --> 00:31:38,350
working on verification I don't want

00:31:36,490 --> 00:31:39,580
them to be struggling to know how to do

00:31:38,350 --> 00:31:43,300
it and I don't want them to be short of

00:31:39,580 --> 00:31:45,460
resources so most of these videos are

00:31:43,300 --> 00:31:48,130
internal I'm hoping after Pikkon I can

00:31:45,460 --> 00:31:50,860
add one to this that's that everyone can

00:31:48,130 --> 00:31:52,990
watch but we have something like 22

00:31:50,860 --> 00:31:55,870
hours worth of video on this specific

00:31:52,990 --> 00:31:58,660
topic that we've accumulated internally

00:31:55,870 --> 00:32:00,520
at the weather bureau so straight away

00:31:58,660 --> 00:32:02,920
if people want to go to the underlying

00:32:00,520 --> 00:32:04,570
you know the original developers of a

00:32:02,920 --> 00:32:06,340
lot of these skill scores are still

00:32:04,570 --> 00:32:08,140
around and they you know they're still

00:32:06,340 --> 00:32:11,200
working there pushing the envelope in

00:32:08,140 --> 00:32:13,150
terms of you know spatial spatial

00:32:11,200 --> 00:32:15,760
analysis and probability analysis and

00:32:13,150 --> 00:32:17,680
all of their work is available to any

00:32:15,760 --> 00:32:19,780
developer as well as that worked

00:32:17,680 --> 00:32:21,490
examples of how to come up with these

00:32:19,780 --> 00:32:24,370
scores are available through the ipython

00:32:21,490 --> 00:32:27,160
notebook so straight away if you need to

00:32:24,370 --> 00:32:29,260
take some techniques you can view how

00:32:27,160 --> 00:32:31,690
they're applied in an isolated and

00:32:29,260 --> 00:32:34,930
specific way that concentrates on that

00:32:31,690 --> 00:32:36,280
particular score or technique and then

00:32:34,930 --> 00:32:37,750
you can take that away to your piece of

00:32:36,280 --> 00:32:40,120
software so straight away you've got

00:32:37,750 --> 00:32:42,370
this sort of this worked examples

00:32:40,120 --> 00:32:44,410
laboratory kind of experimental

00:32:42,370 --> 00:32:45,940
environment and they that those

00:32:44,410 --> 00:32:47,800
notebooks they're all they're alive and

00:32:45,940 --> 00:32:49,450
they all have access to all of the data

00:32:47,800 --> 00:32:51,460
and all of the experiments so that you

00:32:49,450 --> 00:32:53,140
can just hack on them with reference to

00:32:51,460 --> 00:32:56,550
all of the data sets that you've got to

00:32:53,140 --> 00:32:59,320
your hearts hearts content notebooks are

00:32:56,550 --> 00:33:02,170
amazing but they're not a very good way

00:32:59,320 --> 00:33:03,610
to build software you know as a system

00:33:02,170 --> 00:33:05,700
they're not a system software tool

00:33:03,610 --> 00:33:07,630
they're an amazing experimental tool

00:33:05,700 --> 00:33:10,330
fantastic for exploring something

00:33:07,630 --> 00:33:12,310
sending to someone else and sharing but

00:33:10,330 --> 00:33:14,230
their you know their abject Lee horrible

00:33:12,310 --> 00:33:16,150
at you know trying to actually build an

00:33:14,230 --> 00:33:18,640
entire system out of you know you would

00:33:16,150 --> 00:33:20,200
never try to well I would hope you would

00:33:18,640 --> 00:33:22,600
never try to run them through the

00:33:20,200 --> 00:33:25,180
ipython notebook command line extension

00:33:22,600 --> 00:33:27,580
in crime for example to support your

00:33:25,180 --> 00:33:28,240
system you really should be going and

00:33:27,580 --> 00:33:29,860
building things

00:33:28,240 --> 00:33:32,340
and that that's what these experiments

00:33:29,860 --> 00:33:36,340
potentially are is that these

00:33:32,340 --> 00:33:39,880
experiments support the sharing of code

00:33:36,340 --> 00:33:42,820
so in this we've got you know some code

00:33:39,880 --> 00:33:46,390
here that you know processing one of our

00:33:42,820 --> 00:33:48,360
data formats get you know converting

00:33:46,390 --> 00:33:51,070
them into areas etc so that if you

00:33:48,360 --> 00:33:53,320
question a result that someone is shared

00:33:51,070 --> 00:33:55,660
through the data tool you go straight to

00:33:53,320 --> 00:33:57,670
their code there's no concept of asking

00:33:55,660 --> 00:34:00,940
them to release it at an open source and

00:33:57,670 --> 00:34:02,650
even if they're not you know version

00:34:00,940 --> 00:34:04,660
control even if they're not on you know

00:34:02,650 --> 00:34:06,460
using git or your whatever your company

00:34:04,660 --> 00:34:07,809
uses for version control even if they've

00:34:06,460 --> 00:34:09,669
just got something on their desktop

00:34:07,809 --> 00:34:11,679
they've been hacking on you know in

00:34:09,669 --> 00:34:13,720
their lunch hour they can still give you

00:34:11,679 --> 00:34:15,220
a URL to their desktop and you can just

00:34:13,720 --> 00:34:17,980
look at their local installation and you

00:34:15,220 --> 00:34:19,540
can just inspect their code so it one of

00:34:17,980 --> 00:34:21,879
the things we do have trouble with is

00:34:19,540 --> 00:34:24,010
you know legacy code that was developed

00:34:21,879 --> 00:34:26,350
outside of the normal project hosting

00:34:24,010 --> 00:34:29,169
repositories things that just exist on

00:34:26,350 --> 00:34:30,879
people's desks if people were a bit more

00:34:29,169 --> 00:34:34,750
willing to expose their data in their

00:34:30,879 --> 00:34:37,149
code as an ordinary practice and get a

00:34:34,750 --> 00:34:39,580
little bit less worried about whether

00:34:37,149 --> 00:34:40,960
it's perfect or ready for operations or

00:34:39,580 --> 00:34:42,700
whether it's been through code review

00:34:40,960 --> 00:34:44,889
and just go you know what hey everybody

00:34:42,700 --> 00:34:46,510
this is this is what I'm doing you know

00:34:44,889 --> 00:34:48,100
if you really want to know that's fine I

00:34:46,510 --> 00:34:50,260
don't expect you to read it but it's

00:34:48,100 --> 00:34:53,619
available so first of all the codes

00:34:50,260 --> 00:34:56,830
available the data is very in spectabile

00:34:53,619 --> 00:34:58,810
so in this case we've got largely you

00:34:56,830 --> 00:35:00,990
know this this is the contents of an ax

00:34:58,810 --> 00:35:05,770
f file and it's basically see a

00:35:00,990 --> 00:35:09,220
combination of cs csv sections and you

00:35:05,770 --> 00:35:13,210
know keyvaluepair sections so you can go

00:35:09,220 --> 00:35:15,490
in you can inspect the raw data you can

00:35:13,210 --> 00:35:18,070
move it through a pipeline process and

00:35:15,490 --> 00:35:20,230
start inspecting inspecting it as a

00:35:18,070 --> 00:35:22,090
structured data so if you're putting

00:35:20,230 --> 00:35:24,310
together some kind of processing

00:35:22,090 --> 00:35:26,020
pipeline first of all that's good

00:35:24,310 --> 00:35:28,090
practice not everyone's going to have a

00:35:26,020 --> 00:35:31,150
methodology about how they approach an

00:35:28,090 --> 00:35:33,460
experiment this provides just one

00:35:31,150 --> 00:35:36,130
potential methodology just out of the

00:35:33,460 --> 00:35:38,050
box it's in spectabile you haven't had

00:35:36,130 --> 00:35:40,630
to do anything you haven't had to load

00:35:38,050 --> 00:35:41,630
your data into Microsoft Excel you

00:35:40,630 --> 00:35:45,710
haven't had to

00:35:41,630 --> 00:35:48,380
you know writer conversion layer will

00:35:45,710 --> 00:35:50,440
see it in a couple of minutes if I've

00:35:48,380 --> 00:35:55,160
still got time a lot of fast running out

00:35:50,440 --> 00:35:58,490
I'm good about how more sophisticated

00:35:55,160 --> 00:36:00,859
data types can be inspected all through

00:35:58,490 --> 00:36:03,079
this web interface method and how

00:36:00,859 --> 00:36:05,839
automated plotting an automated charting

00:36:03,079 --> 00:36:08,900
cannons support data discovery and data

00:36:05,839 --> 00:36:11,720
investigation in new ways so this is

00:36:08,900 --> 00:36:13,519
that that's something that's often for

00:36:11,720 --> 00:36:14,930
me has been an assumption of a lot of

00:36:13,519 --> 00:36:17,630
scientific literature is that you

00:36:14,930 --> 00:36:19,450
already somehow understand a fair bit

00:36:17,630 --> 00:36:22,099
about the data that you're working with

00:36:19,450 --> 00:36:25,190
whereas if you really don't if you're

00:36:22,099 --> 00:36:27,170
just given some some file and say well

00:36:25,190 --> 00:36:29,599
this just has like a raise of data in it

00:36:27,170 --> 00:36:31,160
and you need to work out how the vectors

00:36:29,599 --> 00:36:33,890
are represented at a speed and direction

00:36:31,160 --> 00:36:36,230
or you know magnitude that they

00:36:33,890 --> 00:36:38,329
magnitude and direction or U and V and

00:36:36,230 --> 00:36:40,339
what does it look like you know there

00:36:38,329 --> 00:36:42,339
should be this period of play where

00:36:40,339 --> 00:36:47,450
you're learning your data beforehand and

00:36:42,339 --> 00:36:50,539
so that that's an explicit step analysis

00:36:47,450 --> 00:36:53,059
results so this is lead time in minutes

00:36:50,539 --> 00:36:55,730
by distance error in kilometers of

00:36:53,059 --> 00:36:58,190
thunderstorms so if you look at a

00:36:55,730 --> 00:37:01,279
thunderstorm warning in half an hour's

00:36:58,190 --> 00:37:05,059
time for this particular data set there

00:37:01,279 --> 00:37:06,740
was a 22 kilometer error on the center

00:37:05,059 --> 00:37:08,990
effective leader center of mass of the

00:37:06,740 --> 00:37:10,970
thing so that this particular data set

00:37:08,990 --> 00:37:14,839
these thunderstorms went off track quite

00:37:10,970 --> 00:37:18,170
fast this is basically I got this for

00:37:14,839 --> 00:37:20,900
free out of pandas it just supports plot

00:37:18,170 --> 00:37:23,059
my data and something comes out if it's

00:37:20,900 --> 00:37:24,650
a simple if it's simple data something

00:37:23,059 --> 00:37:25,910
that something meaningful comes out if

00:37:24,650 --> 00:37:28,490
it's complicated data something

00:37:25,910 --> 00:37:30,200
meaningless comes out so supporting some

00:37:28,490 --> 00:37:32,720
configuration on that is down the wire

00:37:30,200 --> 00:37:35,420
but the point is is that even though it

00:37:32,720 --> 00:37:37,849
makes no sense not to plot the lead time

00:37:35,420 --> 00:37:39,799
as the x-axis I can actually still

00:37:37,849 --> 00:37:41,420
follow through the samples and go what

00:37:39,799 --> 00:37:44,150
lead time did a particular distance

00:37:41,420 --> 00:37:46,910
error occurred so no this is not a

00:37:44,150 --> 00:37:48,950
professional plot yes I can just look at

00:37:46,910 --> 00:37:51,950
it and understand what's going on so

00:37:48,950 --> 00:37:53,690
that i think i would never include this

00:37:51,950 --> 00:37:55,350
in a publication i would never

00:37:53,690 --> 00:37:57,060
ordinarily include this in a

00:37:55,350 --> 00:37:58,770
presentation where I cared about we're

00:37:57,060 --> 00:38:00,780
communicating the results was important

00:37:58,770 --> 00:38:02,280
but when you when you're not at that

00:38:00,780 --> 00:38:04,200
level when you're at the what's in my

00:38:02,280 --> 00:38:05,820
data and what's going on level it's just

00:38:04,200 --> 00:38:07,050
perfectly fine just to be able to click

00:38:05,820 --> 00:38:09,630
and look and click and look and click

00:38:07,050 --> 00:38:11,100
and look and support the first hour and

00:38:09,630 --> 00:38:15,120
a half of looking at what it is that

00:38:11,100 --> 00:38:17,880
you're working with and then there's

00:38:15,120 --> 00:38:20,720
other aspects to this so shareable

00:38:17,880 --> 00:38:27,020
images everything gets a unique URL

00:38:20,720 --> 00:38:30,320
shareable code and support full support

00:38:27,020 --> 00:38:33,600
for writing up your reports in markdown

00:38:30,320 --> 00:38:35,310
with links back into the rest of the

00:38:33,600 --> 00:38:39,360
system so that when you're writing

00:38:35,310 --> 00:38:40,830
writing your reports the inclusion of

00:38:39,360 --> 00:38:43,290
graphs and things like that is quite

00:38:40,830 --> 00:38:45,780
straightforward and as well as that if

00:38:43,290 --> 00:38:48,000
someone's reading your report or reading

00:38:45,780 --> 00:38:49,980
one of your graphs on the system they

00:38:48,000 --> 00:38:52,290
know that they can get back at the data

00:38:49,980 --> 00:38:54,510
that created that graph so if they have

00:38:52,290 --> 00:38:56,940
a question about Oh what did it you know

00:38:54,510 --> 00:38:58,710
that's why on earth did you not just use

00:38:56,940 --> 00:39:00,870
the x-axis for lead time what's what's

00:38:58,710 --> 00:39:02,370
going on there they can just go back and

00:39:00,870 --> 00:39:04,650
just you know just download that data

00:39:02,370 --> 00:39:06,270
and play with it and you know if I've

00:39:04,650 --> 00:39:08,730
missed the hidden variable and they want

00:39:06,270 --> 00:39:11,370
to go I wonder how this relates to you

00:39:08,730 --> 00:39:13,350
know the which month it is does it vary

00:39:11,370 --> 00:39:17,880
by month it's pretty easy for them to

00:39:13,350 --> 00:39:21,750
just get out and share the data so look

00:39:17,880 --> 00:39:23,610
I don't know whether this is an amazing

00:39:21,750 --> 00:39:25,650
idea or not it's just something I wanted

00:39:23,610 --> 00:39:28,590
to talk about so I would like to

00:39:25,650 --> 00:39:30,510
encourage everybody to not feel too

00:39:28,590 --> 00:39:32,940
critical of it and feel like it's an

00:39:30,510 --> 00:39:35,130
okay thing to just share random software

00:39:32,940 --> 00:39:36,420
you know it's a software conference I

00:39:35,130 --> 00:39:39,780
think we should be allowed to just talk

00:39:36,420 --> 00:39:41,970
about the ideas that we've had so I'm

00:39:39,780 --> 00:39:44,370
going to shoot back to shoot back to the

00:39:41,970 --> 00:39:47,370
final two or three slides of this

00:39:44,370 --> 00:39:48,870
presentation now and then then I think

00:39:47,370 --> 00:39:51,540
there should be some room for discussion

00:39:48,870 --> 00:39:54,120
so one of the main things is the skills

00:39:51,540 --> 00:39:55,800
you need to do this come from a lot of

00:39:54,120 --> 00:39:57,060
dis a lot of different disciplines and

00:39:55,800 --> 00:40:01,260
if you're coming at this for the first

00:39:57,060 --> 00:40:02,750
time it can be very confusing so mainly

00:40:01,260 --> 00:40:05,490
you're going to want to work in a team

00:40:02,750 --> 00:40:06,800
if it's a professional context you're

00:40:05,490 --> 00:40:08,760
not going to want to do this on your own

00:40:06,800 --> 00:40:10,290
probably even if you want to do it

00:40:08,760 --> 00:40:12,150
personal interest you should do

00:40:10,290 --> 00:40:14,430
something like jump on Kaggle and find

00:40:12,150 --> 00:40:16,140
some random people on the internet and

00:40:14,430 --> 00:40:19,440
hey crazy let's get to know each other

00:40:16,140 --> 00:40:22,410
and write some code but you should

00:40:19,440 --> 00:40:24,660
expect that it's going to push you in

00:40:22,410 --> 00:40:28,260
ways push you to develop knowledge that

00:40:24,660 --> 00:40:30,300
you don't have now that I added the zone

00:40:28,260 --> 00:40:31,920
of confusion I feel like it's important

00:40:30,300 --> 00:40:33,780
to acknowledge loans of confusion in

00:40:31,920 --> 00:40:37,140
life I think it makes me feel better

00:40:33,780 --> 00:40:38,960
anyway but whoever put this together is

00:40:37,140 --> 00:40:43,110
just bang on with the original image

00:40:38,960 --> 00:40:44,850
okay so tools for the future so enhanced

00:40:43,110 --> 00:40:47,130
data browsing I've talked about I think

00:40:44,850 --> 00:40:49,380
that that's really important the ability

00:40:47,130 --> 00:40:52,020
to just throw files at a system and have

00:40:49,380 --> 00:40:53,970
any almost any kind of visualization of

00:40:52,020 --> 00:40:55,860
what the data is data is underneath and

00:40:53,970 --> 00:40:59,180
have a system that's competent at

00:40:55,860 --> 00:41:03,600
assessing assessing and showing data

00:40:59,180 --> 00:41:05,280
intelligent databases that the reason I

00:41:03,600 --> 00:41:08,520
say that is because actually data is

00:41:05,280 --> 00:41:10,800
hard to move them code and it's hot so

00:41:08,520 --> 00:41:12,990
if you have a database that naturally

00:41:10,800 --> 00:41:14,730
supports like if everybody had a data

00:41:12,990 --> 00:41:17,000
tool and the data tool actually worked

00:41:14,730 --> 00:41:19,290
and it was actually really good then

00:41:17,000 --> 00:41:22,530
anyone who had the data could do some

00:41:19,290 --> 00:41:25,290
kind of pretty easy inspection pretty

00:41:22,530 --> 00:41:26,790
easy results pretty easy i squared you

00:41:25,290 --> 00:41:29,730
know i remit you know really good

00:41:26,790 --> 00:41:30,870
support for these and you know your

00:41:29,730 --> 00:41:32,010
tools would just kind of come with the

00:41:30,870 --> 00:41:34,680
data so that's what i mean by

00:41:32,010 --> 00:41:36,900
intelligent databases so at some level

00:41:34,680 --> 00:41:39,150
some level it's important to you know

00:41:36,900 --> 00:41:41,130
split the database off because it's a

00:41:39,150 --> 00:41:42,750
separate concept from the system but

00:41:41,130 --> 00:41:45,810
another level when you want to share and

00:41:42,750 --> 00:41:48,570
collaborate the tools are becoming so

00:41:45,810 --> 00:41:50,190
complex that you kind of need to collab

00:41:48,570 --> 00:41:51,690
you need to share your environment these

00:41:50,190 --> 00:41:53,370
days as well and I mean that's why the

00:41:51,690 --> 00:41:55,680
cloud is such a big things because

00:41:53,370 --> 00:41:57,450
people people don't want to be their own

00:41:55,680 --> 00:41:58,980
system administrator and cope with the

00:41:57,450 --> 00:42:00,570
version changes of these scientific

00:41:58,980 --> 00:42:02,040
libraries and run through and make sure

00:42:00,570 --> 00:42:04,650
that everything still works they want

00:42:02,040 --> 00:42:06,510
that to a degree to be done for them and

00:42:04,650 --> 00:42:08,970
that that's I guess where I think open

00:42:06,510 --> 00:42:11,430
source could come in is by providing as

00:42:08,970 --> 00:42:13,320
it already is with like the ipython

00:42:11,430 --> 00:42:16,380
notebook people have just revolutionized

00:42:13,320 --> 00:42:19,200
how like enormous numbers of people look

00:42:16,380 --> 00:42:21,240
at problems but but it can go further

00:42:19,200 --> 00:42:23,490
you know that there are other ass

00:42:21,240 --> 00:42:25,890
effective data analysis that the that

00:42:23,490 --> 00:42:29,190
ipython notebook isn't really about so

00:42:25,890 --> 00:42:31,530
data sharing is a huge if you're trying

00:42:29,190 --> 00:42:34,500
to like and it's very real like I tried

00:42:31,530 --> 00:42:36,270
to enter a Kaggle competition the data

00:42:34,500 --> 00:42:40,050
download was something like 300

00:42:36,270 --> 00:42:42,660
gigabytes chrome didn't support data

00:42:40,050 --> 00:42:44,460
download resumption and I needed a

00:42:42,660 --> 00:42:46,680
cookie to download the data and the

00:42:44,460 --> 00:42:49,140
server was in the US so I didn't get a

00:42:46,680 --> 00:42:51,210
fast download speed and no one made it

00:42:49,140 --> 00:42:54,510
available by a bit torrent and so it

00:42:51,210 --> 00:42:56,850
took me two weeks of 20 minutes in the

00:42:54,510 --> 00:42:58,650
evening units of time to actually

00:42:56,850 --> 00:43:02,040
complete the task of downloading an

00:42:58,650 --> 00:43:04,230
entire data file by which time I got

00:43:02,040 --> 00:43:05,430
sick and then didn't do anything for a

00:43:04,230 --> 00:43:07,140
fortnight and then it was two days

00:43:05,430 --> 00:43:09,240
before pike on and just nothing happened

00:43:07,140 --> 00:43:12,480
so you know these barriers to entry

00:43:09,240 --> 00:43:14,100
really stop people and you know everyone

00:43:12,480 --> 00:43:16,320
thinks we live in this amazing time of

00:43:14,100 --> 00:43:18,840
broadband and cloud and computers are

00:43:16,320 --> 00:43:20,369
free and disks are cheap but they're not

00:43:18,840 --> 00:43:22,680
actually cheap enough that I go you know

00:43:20,369 --> 00:43:25,560
what I'm gonna spend 20 bucks on an

00:43:22,680 --> 00:43:28,580
Amazon ec2 instance to do a regression

00:43:25,560 --> 00:43:30,359
analysis because I just feel like it I

00:43:28,580 --> 00:43:31,650
think I'm like oh you know what I'd

00:43:30,359 --> 00:43:33,480
actually really rather just run

00:43:31,650 --> 00:43:36,330
something on my laptop for free on a

00:43:33,480 --> 00:43:38,310
smaller data set so actually I think in

00:43:36,330 --> 00:43:39,660
terms of supporting play and open

00:43:38,310 --> 00:43:41,400
communities and learning I actually

00:43:39,660 --> 00:43:43,770
don't think the tools that we have are

00:43:41,400 --> 00:43:45,450
there so for example if the data tool

00:43:43,770 --> 00:43:47,760
magically somehow sat on top of a

00:43:45,450 --> 00:43:50,130
bittorrent layer that wasn't full of

00:43:47,760 --> 00:43:52,859
random content you could actually have

00:43:50,130 --> 00:43:54,840
you know sharding of data across a bunch

00:43:52,859 --> 00:43:57,930
of people who are running data tools you

00:43:54,840 --> 00:44:01,020
could have an open genuinely open source

00:43:57,930 --> 00:44:02,640
distributed way of sharing the data to

00:44:01,020 --> 00:44:05,520
make the downloads more accessible if it

00:44:02,640 --> 00:44:07,470
was open data of executing on other

00:44:05,520 --> 00:44:09,570
people's you know small components are

00:44:07,470 --> 00:44:12,390
these things if you can distribute in a

00:44:09,570 --> 00:44:14,520
supportive way and really allowing a

00:44:12,390 --> 00:44:17,040
much more open scientific community and

00:44:14,520 --> 00:44:19,619
I think we could move that way by making

00:44:17,040 --> 00:44:21,600
those tools better than the ones that

00:44:19,619 --> 00:44:24,890
you get by paying for them and I think

00:44:21,600 --> 00:44:24,890
that that's an interesting concept

00:44:30,650 --> 00:44:32,710

YouTube URL: https://www.youtube.com/watch?v=c0DE_UfRiXE


