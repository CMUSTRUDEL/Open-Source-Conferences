Title: Breaking up arrays up into chunks for fun and science with Xarray and Dask
Publication date: 2016-08-16
Playlist: Science & Data 2016 (Miniconf)
Description: 
	Andrew Hicks
https://2016.pycon-au.org/schedule/176/view_talk
Xarray is n-dimensional array package bringing numpy and pandas-style interfaces to labelled data.  Its main use is for manipulating scientific datasets stored in NetCDF file format.

The Dask package brings task graphs for parallel computation of arrays, by breaking them up into smaller chunks, for lazy processing of arrays. It can handle larger-than-memory dataset, scaling from a single machine to a cluster.

When used together, then can be used to analyse all sorts of scientific data.  This talk will look at using them to analyse a timeseries of Earth-observation from Landsat satellites.
Captions: 
	00:00:00,020 --> 00:00:05,629
everyone I've only got slides up here so

00:00:03,810 --> 00:00:07,980
I'm going to be doing the awkward

00:00:05,629 --> 00:00:12,120
sideways things so I'll try to make sure

00:00:07,980 --> 00:00:14,460
I talk this way and look that way but

00:00:12,120 --> 00:00:14,880
not at the same time so I'm going to

00:00:14,460 --> 00:00:16,920
talk about

00:00:14,880 --> 00:00:19,910
x-ray and ask which are two of the

00:00:16,920 --> 00:00:21,810
libraries we use for the data cube

00:00:19,910 --> 00:00:23,220
module that we're building it to your

00:00:21,810 --> 00:00:32,940
science Australia in collaboration with

00:00:23,220 --> 00:00:34,559
CSIRO and NCI the so my colleague Fay

00:00:32,940 --> 00:00:38,070
before lunch talked a lot about the

00:00:34,559 --> 00:00:39,840
organization structure and what we're

00:00:38,070 --> 00:00:45,840
trying to do I'm gonna delve into the

00:00:39,840 --> 00:00:47,460
technical aspects so before I get

00:00:45,840 --> 00:00:50,100
started I'm there are some really good

00:00:47,460 --> 00:00:52,079
talks which in hindsight this slide

00:00:50,100 --> 00:00:54,719
should probably come at the end there's

00:00:52,079 --> 00:00:57,050
some great site high videos on this by

00:00:54,719 --> 00:00:59,910
the two creators of each of the products

00:00:57,050 --> 00:01:04,439
and I recommend checking them out for a

00:00:59,910 --> 00:01:05,280
bit more detail so as we heard in

00:01:04,439 --> 00:01:08,340
Tennessee's talk

00:01:05,280 --> 00:01:10,729
everyone loves numpy there it's real

00:01:08,340 --> 00:01:13,890
easy to do things it's really easy to

00:01:10,729 --> 00:01:16,170
get data manipulate it as long as it's

00:01:13,890 --> 00:01:22,680
the same type but it can be multiple

00:01:16,170 --> 00:01:25,619
dimensions and everyone also loves

00:01:22,680 --> 00:01:28,140
pandas and the advantage with a panda's

00:01:25,619 --> 00:01:30,810
data frame is that you can have multiple

00:01:28,140 --> 00:01:34,650
types you have fancy indexing that you

00:01:30,810 --> 00:01:36,930
can pull out particular rows and then

00:01:34,650 --> 00:01:39,720
great support for data types like

00:01:36,930 --> 00:01:45,750
daytime objects that you can do great by

00:01:39,720 --> 00:01:51,960
you can and then do computation on those

00:01:45,750 --> 00:01:53,399
groups or separately so x-ray which was

00:01:51,960 --> 00:01:55,610
originally started as an open source

00:01:53,399 --> 00:01:59,909
project out of the climate Corporation

00:01:55,610 --> 00:02:02,009
and has now become part of continuum is

00:01:59,909 --> 00:02:07,729
all about multi-dimensional arrays that

00:02:02,009 --> 00:02:07,729
I labeled using pandas style labeling

00:02:09,880 --> 00:02:17,300
so here we've got an example of creating

00:02:13,370 --> 00:02:21,410
an x-ray so inside it's just an umpire

00:02:17,300 --> 00:02:24,800
ray it's the data itself you then have

00:02:21,410 --> 00:02:30,350
data arrays to label what each of the

00:02:24,800 --> 00:02:32,510
axes are and the axes are named so I've

00:02:30,350 --> 00:02:35,120
made an excel looking thing it's got

00:02:32,510 --> 00:02:37,550
columns called a B and C rows one and

00:02:35,120 --> 00:02:39,650
two I'm not very inventive when it comes

00:02:37,550 --> 00:02:41,540
to this and then they've just got some

00:02:39,650 --> 00:02:44,660
numbers in there and the good thing is

00:02:41,540 --> 00:02:48,230
you can use panda style indexing and

00:02:44,660 --> 00:02:52,370
just say I want column a and you

00:02:48,230 --> 00:02:55,940
maintain the row labels and it with the

00:02:52,370 --> 00:03:00,440
object you get back as a result says

00:02:55,940 --> 00:03:02,240
that it's still column a and there's an

00:03:00,440 --> 00:03:06,530
example at the bottom of the pant does

00:03:02,240 --> 00:03:08,300
fancy indexing we can go from A to B and

00:03:06,530 --> 00:03:10,100
if that wasn't right next to it you

00:03:08,300 --> 00:03:12,490
would do all the ones in between and

00:03:10,100 --> 00:03:17,170
again a lack of imagination in my car

00:03:12,490 --> 00:03:19,820
and so underneath it's manipulating the

00:03:17,170 --> 00:03:24,040
the numpy array and giving you a view in

00:03:19,820 --> 00:03:28,700
a slice only one of those things and

00:03:24,040 --> 00:03:31,580
into the underlying data and so

00:03:28,700 --> 00:03:34,100
computation it brings across all of the

00:03:31,580 --> 00:03:36,350
things you can do in non-pay so max

00:03:34,100 --> 00:03:41,150
means standard to be standard deviation

00:03:36,350 --> 00:03:44,000
percentiles all of the youthanks and any

00:03:41,150 --> 00:03:45,800
numpy where you'd say access is zero in

00:03:44,000 --> 00:03:49,520
x-ray you don't have to remember that

00:03:45,800 --> 00:03:52,310
one and zero and which dimensions which

00:03:49,520 --> 00:03:58,420
you can just use the name with the

00:03:52,310 --> 00:03:58,420
dimension and it keeps it a lot cleaner

00:03:58,750 --> 00:04:03,860
and and the good thing about that is if

00:04:02,540 --> 00:04:08,450
you've ever had to deal with numpy

00:04:03,860 --> 00:04:11,600
arrays and do maths on them if you have

00:04:08,450 --> 00:04:14,810
a scaler your broadcasts out to the full

00:04:11,600 --> 00:04:16,430
array if you have a 2d array and a 3d

00:04:14,810 --> 00:04:19,760
array you can work on them and it works

00:04:16,430 --> 00:04:22,760
out based on order and size which one to

00:04:19,760 --> 00:04:23,510
scale out with x-ray it's a lot easy to

00:04:22,760 --> 00:04:25,280
understand

00:04:23,510 --> 00:04:27,110
is it matches name for name of the

00:04:25,280 --> 00:04:31,010
dimensions so you can bring in another

00:04:27,110 --> 00:04:37,070
data set and it all fits very nicely

00:04:31,010 --> 00:04:40,460
together so the big power of x-ray comes

00:04:37,070 --> 00:04:43,100
from instead of writing a num passing

00:04:40,460 --> 00:04:46,400
through an umpire a of reading directly

00:04:43,100 --> 00:04:47,990
from a netcdf file so I'm anyone that's

00:04:46,400 --> 00:05:04,820
stealing with science data it's probably

00:04:47,990 --> 00:05:09,350
come across so anyone that's anyone

00:05:04,820 --> 00:05:11,420
that's dealt with climate data really

00:05:09,350 --> 00:05:13,940
large gridded data sets especially if

00:05:11,420 --> 00:05:15,740
they're multi-dimensional over time or

00:05:13,940 --> 00:05:21,110
climate data that's over different

00:05:15,740 --> 00:05:23,330
parameters it gets it's it's a bit

00:05:21,110 --> 00:05:25,910
awkward to use and the underlying netcdf

00:05:23,330 --> 00:05:28,280
library that there's a Python version to

00:05:25,910 --> 00:05:31,490
open up the files manipulate them access

00:05:28,280 --> 00:05:34,460
and write back out it's it's not the

00:05:31,490 --> 00:05:38,500
most pythonic thing you can work with

00:05:34,460 --> 00:05:42,560
but it does give you a numpy raise so

00:05:38,500 --> 00:05:48,200
nip I should have spelled check this

00:05:42,560 --> 00:05:52,790
better so netcdf an x-ray worked really

00:05:48,200 --> 00:05:56,090
well together by design so it's as

00:05:52,790 --> 00:05:58,580
simple as passing in in this case I'm

00:05:56,090 --> 00:06:00,410
using an open dot URL so it's going to a

00:05:58,580 --> 00:06:06,050
thread server at the supercomputer at

00:06:00,410 --> 00:06:07,730
Anu and pulling back data and so it can

00:06:06,050 --> 00:06:10,760
tell me about the coordinates so in this

00:06:07,730 --> 00:06:14,420
case I've just got an X Y and a time

00:06:10,760 --> 00:06:17,900
dimension to my data and I've got labels

00:06:14,420 --> 00:06:20,180
for each of those things and they've got

00:06:17,900 --> 00:06:25,120
their own data types and anyone familiar

00:06:20,180 --> 00:06:27,950
with pandas this all seemed familiar and

00:06:25,120 --> 00:06:31,010
then it's got my sizes so the sizes of

00:06:27,950 --> 00:06:33,770
the dimensions a common across all the

00:06:31,010 --> 00:06:36,660
data arrays that live inside the data

00:06:33,770 --> 00:06:39,870
set which is on the next slide

00:06:36,660 --> 00:06:42,420
so this dataset contains a couple of

00:06:39,870 --> 00:06:48,180
them unimaginably band names bands

00:06:42,420 --> 00:06:50,940
called band 10 20 30 40 50 and then a

00:06:48,180 --> 00:06:55,230
couple of extra things in there so all

00:06:50,940 --> 00:06:56,430
of those arrays share the same so that

00:06:55,230 --> 00:06:59,280
share the same dimensions they're the

00:06:56,430 --> 00:07:02,340
same size and they share the same labels

00:06:59,280 --> 00:07:04,380
so on that data set object you can apply

00:07:02,340 --> 00:07:06,900
the same functions across all the

00:07:04,380 --> 00:07:09,720
variables at once so across all the

00:07:06,900 --> 00:07:11,610
bands say selecting a certain set of

00:07:09,720 --> 00:07:16,020
time or a certain subset of the space

00:07:11,610 --> 00:07:21,180
and you get back a data set that just

00:07:16,020 --> 00:07:23,160
contains that smaller amount one of the

00:07:21,180 --> 00:07:25,340
other things that's important is that it

00:07:23,160 --> 00:07:28,400
contains all the metadata of the

00:07:25,340 --> 00:07:32,310
original file in an attribute dictionary

00:07:28,400 --> 00:07:40,350
and every variable as well has its own

00:07:32,310 --> 00:07:44,340
set of metadata and one of the good

00:07:40,350 --> 00:07:46,620
things about an x-ray so the pandas

00:07:44,340 --> 00:07:49,620
plotting instead of remembering the

00:07:46,620 --> 00:07:52,200
order of dimensions and in your data

00:07:49,620 --> 00:07:54,930
array you can just use the dimension

00:07:52,200 --> 00:07:58,890
name so here I'm selecting so I cell is

00:07:54,930 --> 00:08:00,870
selecting by index and SEL SEL is

00:07:58,890 --> 00:08:06,510
selecting by label and that can either

00:08:00,870 --> 00:08:08,160
be a natural value or a slice and and if

00:08:06,510 --> 00:08:10,620
you're selecting by label for a single

00:08:08,160 --> 00:08:13,200
value you can also say give it a method

00:08:10,620 --> 00:08:14,010
of choose the nearest pointer here which

00:08:13,200 --> 00:08:15,420
is important if you've got

00:08:14,010 --> 00:08:17,940
floating-point numbers like latitudes

00:08:15,420 --> 00:08:23,760
and longitudes you're not gonna have the

00:08:17,940 --> 00:08:26,700
exact number and so we're going from my

00:08:23,760 --> 00:08:31,380
data set get me the data variable ban 20

00:08:26,700 --> 00:08:33,990
select the index one time slice and then

00:08:31,380 --> 00:08:38,070
plot it and it comes built in with some

00:08:33,990 --> 00:08:41,660
nice matplotlib settings that label your

00:08:38,070 --> 00:08:45,600
arrays label your plots dimensions and

00:08:41,660 --> 00:08:47,880
scale and include the time that even

00:08:45,600 --> 00:08:52,010
though with we've chosen a single point

00:08:47,880 --> 00:08:52,010
in time it includes the label

00:08:52,700 --> 00:08:58,200
so the other half of the story is dusk

00:08:55,290 --> 00:09:01,920
and as we heard earlier in the day dusk

00:08:58,200 --> 00:09:05,040
is a distributed task and that task is

00:09:01,920 --> 00:09:12,420
in this case is getting a portion of an

00:09:05,040 --> 00:09:14,160
array so a task array wraps a set of

00:09:12,420 --> 00:09:18,420
functions that say this is how you

00:09:14,160 --> 00:09:19,980
retrieve portions of essentially a numpy

00:09:18,420 --> 00:09:22,380
array and it does it anything you need

00:09:19,980 --> 00:09:27,780
in an interface that matches the numpy

00:09:22,380 --> 00:09:31,920
array interface so down the bottom we've

00:09:27,780 --> 00:09:34,590
got a task computation graph and the

00:09:31,920 --> 00:09:39,270
circles of the functions and so as you

00:09:34,590 --> 00:09:42,440
read the top to get any data from a

00:09:39,270 --> 00:09:45,510
chunk which we've defined in one and to

00:09:42,440 --> 00:09:49,950
one diminutive chunk one in one

00:09:45,510 --> 00:09:54,090
dimension two and the other is get a

00:09:49,950 --> 00:09:55,470
portion of the array so it's it's a

00:09:54,090 --> 00:09:57,210
fairly simple concept that instead of

00:09:55,470 --> 00:10:01,170
storing an array use during a function

00:09:57,210 --> 00:10:05,340
to get an array and the chunking is sort

00:10:01,170 --> 00:10:07,950
of where the power comes from because

00:10:05,340 --> 00:10:09,240
you're then working on smaller parts

00:10:07,950 --> 00:10:12,240
things that can actually fit into memory

00:10:09,240 --> 00:10:13,740
if you're dealing with more data than

00:10:12,240 --> 00:10:15,840
you have in memory you then have to

00:10:13,740 --> 00:10:18,360
manually iterate over it rather than

00:10:15,840 --> 00:10:21,600
just pointing to ask at the array we're

00:10:18,360 --> 00:10:24,720
pulling stuff out so this monstrous

00:10:21,600 --> 00:10:27,450
chart is I've done a little bit of maths

00:10:24,720 --> 00:10:31,170
of not even that much maths I'm

00:10:27,450 --> 00:10:35,130
multiplying the array by the reverse of

00:10:31,170 --> 00:10:36,810
the array in one dimension and so you

00:10:35,130 --> 00:10:39,930
can see it's sharing the down the bottom

00:10:36,810 --> 00:10:41,220
the very the level get this portion get

00:10:39,930 --> 00:10:43,560
this portion get this portion get this

00:10:41,220 --> 00:10:48,660
portion and then it's reusing those

00:10:43,560 --> 00:10:51,390
pieces as it does the multiplication so

00:10:48,660 --> 00:10:54,080
all of these are small tasks that can

00:10:51,390 --> 00:11:00,480
get broken up and done by a scheduler

00:10:54,080 --> 00:11:02,450
and the schedulers perform a task return

00:11:00,480 --> 00:11:04,290
the answer and it builds on the

00:11:02,450 --> 00:11:06,180
computation graph

00:11:04,290 --> 00:11:08,579
until you get all the way to the thing

00:11:06,180 --> 00:11:13,199
at the top that you requested and it

00:11:08,579 --> 00:11:15,329
shares the intermediate steps and it

00:11:13,199 --> 00:11:17,880
gets powerful because without doing

00:11:15,329 --> 00:11:20,610
anything by default you get a threaded

00:11:17,880 --> 00:11:23,730
scheduler that works using all the cause

00:11:20,610 --> 00:11:26,509
in your machine so you get an instant

00:11:23,730 --> 00:11:29,430
speed-up of array nuts it gets broken up

00:11:26,509 --> 00:11:33,509
very nicely it knows which parts need

00:11:29,430 --> 00:11:35,459
what there's other options to use a

00:11:33,509 --> 00:11:38,279
process pool if you've got something

00:11:35,459 --> 00:11:41,310
like the netcdf library which is what

00:11:38,279 --> 00:11:45,000
xray uses under the hood to read the

00:11:41,310 --> 00:11:47,009
data it's got some problems with the C

00:11:45,000 --> 00:11:51,990
library so it can only open one file at

00:11:47,009 --> 00:11:53,759
a time per process it you can get a

00:11:51,990 --> 00:11:57,209
speed up there if you're okay with the

00:11:53,759 --> 00:12:00,120
hit of transferring data across

00:11:57,209 --> 00:12:02,240
processors the cool thing which I'm not

00:12:00,120 --> 00:12:04,980
going to talk too much about is

00:12:02,240 --> 00:12:07,649
distributed which takes the the dash

00:12:04,980 --> 00:12:10,350
scheduler model and spreads it across

00:12:07,649 --> 00:12:12,870
cluster of computers that each run

00:12:10,350 --> 00:12:19,410
workers that get given the jobs by the

00:12:12,870 --> 00:12:22,199
scheduler so the great thing about dusk

00:12:19,410 --> 00:12:24,899
and x-ray is that x-rays got tasks built

00:12:22,199 --> 00:12:28,649
into it just by passing the chunks

00:12:24,899 --> 00:12:31,889
parameter to say when you pull out data

00:12:28,649 --> 00:12:34,319
pull out 500 by 500 by 5 pixels at a

00:12:31,889 --> 00:12:37,380
time and that works that's sort of your

00:12:34,319 --> 00:12:41,670
building block of your computation and

00:12:37,380 --> 00:12:45,500
it works just the same way as the rest

00:12:41,670 --> 00:12:48,990
of as a normal x-ray object backed with

00:12:45,500 --> 00:12:50,579
numpy the great thing is it doesn't

00:12:48,990 --> 00:12:52,350
actually read any data then it's all

00:12:50,579 --> 00:12:53,970
lazy evaluated so it happens

00:12:52,350 --> 00:12:56,610
straightaway it just needs to know about

00:12:53,970 --> 00:12:59,880
the dimensions and the labels the the

00:12:56,610 --> 00:13:01,649
contents of the data remain on disk so

00:12:59,880 --> 00:13:05,490
it's really good for scientists when you

00:13:01,649 --> 00:13:10,470
want to get something play with it do a

00:13:05,490 --> 00:13:12,660
series of computation on it yep a series

00:13:10,470 --> 00:13:16,079
of computation and then spit out the

00:13:12,660 --> 00:13:17,640
answer and just query parts of it when

00:13:16,079 --> 00:13:19,830
you do the clearing of a small part of

00:13:17,640 --> 00:13:21,440
arrey say you picking your time slice

00:13:19,830 --> 00:13:23,880
and you wanna print it out plot it

00:13:21,440 --> 00:13:26,360
that's when it works out all the things

00:13:23,880 --> 00:13:29,010
it needs to do just to get those chunks

00:13:26,360 --> 00:13:30,300
it folders back the computation tree and

00:13:29,010 --> 00:13:32,250
will only read the smallest amount of

00:13:30,300 --> 00:13:38,430
data it can rounding up to the nearest

00:13:32,250 --> 00:13:40,350
chunk and so you can do that until to

00:13:38,430 --> 00:13:42,840
test and then once that's done and

00:13:40,350 --> 00:13:46,770
you're ready to process your entire huge

00:13:42,840 --> 00:13:48,780
archive of data you can throw it at a

00:13:46,770 --> 00:13:51,210
scheduler and then let it just sit there

00:13:48,780 --> 00:13:53,400
and using all of your cause process the

00:13:51,210 --> 00:13:54,780
entire thing and because it's only doing

00:13:53,400 --> 00:13:57,990
a small amount of time a small amount of

00:13:54,780 --> 00:13:59,730
processing at each time it can don't fit

00:13:57,990 --> 00:14:03,240
into memory for a job that wouldn't

00:13:59,730 --> 00:14:06,210
normally so we use this in the data cube

00:14:03,240 --> 00:14:08,700
and just realize I've got the wrong

00:14:06,210 --> 00:14:12,090
slides up so as we heard earlier it's a

00:14:08,700 --> 00:14:20,400
collaboration between Geoscience NCI and

00:14:12,090 --> 00:14:23,940
CSIRO and so here is a map of Melbourne

00:14:20,400 --> 00:14:30,780
and the blue lines that you can't really

00:14:23,940 --> 00:14:31,740
see that well so this is an outline of a

00:14:30,780 --> 00:14:35,010
scene

00:14:31,740 --> 00:14:37,560
so in Landsat satellite processing

00:14:35,010 --> 00:14:41,580
follows the same path give or take a bit

00:14:37,560 --> 00:14:44,580
and as it flies overhead it chops up the

00:14:41,580 --> 00:14:46,770
data into a scene and that's what

00:14:44,580 --> 00:14:53,870
generally gets processed by downstream

00:14:46,770 --> 00:14:53,870
by USGS and GA is sort of a unit of data

00:14:53,960 --> 00:15:04,050
it's got overlaps as well both as it

00:14:58,980 --> 00:15:07,920
goes along and the path and the row the

00:15:04,050 --> 00:15:10,290
rows overlap so you can see in between

00:15:07,920 --> 00:15:12,180
here you've got a note about so this

00:15:10,290 --> 00:15:15,510
means you don't have nice gridded data

00:15:12,180 --> 00:15:19,890
which is fully populated in there the

00:15:15,510 --> 00:15:23,100
time dimension in fact it's about 30

00:15:19,890 --> 00:15:24,780
sick looking to say that because I don't

00:15:23,100 --> 00:15:29,760
really remember there's not a lot of

00:15:24,780 --> 00:15:31,640
time between from scene to scene and so

00:15:29,760 --> 00:15:34,890
but as we heard earlier it's a 16 day

00:15:31,640 --> 00:15:38,510
cycle to get back to that same scene so

00:15:34,890 --> 00:15:40,980
it's a it feels like it's gridded data

00:15:38,510 --> 00:15:42,540
but when you look at it it's just a

00:15:40,980 --> 00:15:47,610
slither of data going around around the

00:15:42,540 --> 00:15:50,940
world and here's the marketing slide but

00:15:47,610 --> 00:15:53,850
they used to sell the project so you've

00:15:50,940 --> 00:15:59,430
got the slices and they don't really

00:15:53,850 --> 00:16:03,480
line up in space or in time so we drill

00:15:59,430 --> 00:16:07,950
through them tile everything up and then

00:16:03,480 --> 00:16:11,220
for a particular tile its you've got a

00:16:07,950 --> 00:16:19,020
3d data set that you can work with a lot

00:16:11,220 --> 00:16:24,390
easier again I apologize I went and

00:16:19,020 --> 00:16:30,870
changed somewhere I have slides that

00:16:24,390 --> 00:16:33,690
don't don't have this and so at the very

00:16:30,870 --> 00:16:36,840
very top you can see we're making a data

00:16:33,690 --> 00:16:39,020
cube object giving it a config and then

00:16:36,840 --> 00:16:41,640
we're saying loading load some data

00:16:39,020 --> 00:16:45,620
giving their bounding box in space and

00:16:41,640 --> 00:16:51,300
time and the same sort of style here

00:16:45,620 --> 00:16:53,300
we're giving it chunks to use and so

00:16:51,300 --> 00:16:56,310
internally it'll create an X array and

00:16:53,300 --> 00:16:58,740
add ask array that knows about the

00:16:56,310 --> 00:17:00,540
particular files it gets so instead of

00:16:58,740 --> 00:17:04,260
before we saw it opening a file and

00:17:00,540 --> 00:17:05,880
x-ray allows you to an open mini files

00:17:04,260 --> 00:17:09,480
at once if you have like a common file

00:17:05,880 --> 00:17:12,630
name path we use a database in the

00:17:09,480 --> 00:17:14,459
backend to look up where all the Landsat

00:17:12,630 --> 00:17:18,120
data is and all the other satellite data

00:17:14,459 --> 00:17:20,970
we store return the results and populate

00:17:18,120 --> 00:17:23,720
it that way so you don't you just talk

00:17:20,970 --> 00:17:27,209
about a which product you want and

00:17:23,720 --> 00:17:29,100
there's other ways to define what you

00:17:27,209 --> 00:17:33,210
want based on satellite type and

00:17:29,100 --> 00:17:34,470
properties and then you get back an

00:17:33,210 --> 00:17:36,630
x-ray and we're hoping this is a much

00:17:34,470 --> 00:17:39,840
easier way to work with data than having

00:17:36,630 --> 00:17:42,080
a directory full of scenes that don't

00:17:39,840 --> 00:17:42,080
line up

00:17:42,350 --> 00:17:45,990
that are in slightly different

00:17:44,100 --> 00:17:48,690
projections that it's it's a lot of work

00:17:45,990 --> 00:17:51,600
to bring it together we're hoping the

00:17:48,690 --> 00:17:56,010
x-ray that you get returned is an

00:17:51,600 --> 00:17:58,800
efficient way to work so in the request

00:17:56,010 --> 00:18:01,320
I just did it was 54 gigs worth of data

00:17:58,800 --> 00:18:02,730
but because I was using tasks it's still

00:18:01,320 --> 00:18:04,140
on disk I've just got an object that

00:18:02,730 --> 00:18:06,260
tells me how to get the data when I need

00:18:04,140 --> 00:18:06,260
it

00:18:06,530 --> 00:18:14,100
so anyone that's in remote sensing nose

00:18:09,750 --> 00:18:16,860
or in ecology knows about the NDVI which

00:18:14,100 --> 00:18:18,270
is an index of vegetation and you can

00:18:16,860 --> 00:18:23,640
pair the red band and the near-infrared

00:18:18,270 --> 00:18:26,570
band of your satellite image and the

00:18:23,640 --> 00:18:31,640
ratio gives you a good idea about the

00:18:26,570 --> 00:18:33,930
level of vegetation for that pixel and

00:18:31,640 --> 00:18:37,560
so the great thing is you can just say

00:18:33,930 --> 00:18:40,410
get the near-infrared x-ray data array

00:18:37,560 --> 00:18:43,260
and the red one and do some basic maths

00:18:40,410 --> 00:18:46,530
this just is near-infrared over here as

00:18:43,260 --> 00:18:52,110
well and it spits you back an x-ray

00:18:46,530 --> 00:18:54,090
containing everything lazy loaded you

00:18:52,110 --> 00:18:57,330
can then go get me the mean across time

00:18:54,090 --> 00:19:00,990
as you would with numpy and with a

00:18:57,330 --> 00:19:03,960
little bit of work and then here you see

00:19:00,990 --> 00:19:05,310
it's internally it's an x-ray when you

00:19:03,960 --> 00:19:09,170
actually want to get the data you can do

00:19:05,310 --> 00:19:11,730
anything that'll cast it to the number

00:19:09,170 --> 00:19:14,010
so if you use it as an array and try to

00:19:11,730 --> 00:19:15,990
get the value in calculate with it it'll

00:19:14,010 --> 00:19:19,380
fetch the data otherwise you can

00:19:15,990 --> 00:19:23,850
explicitly say load and it'll process

00:19:19,380 --> 00:19:26,460
the computation graph made by doing the

00:19:23,850 --> 00:19:27,960
mean operation and then work out what it

00:19:26,460 --> 00:19:30,570
needs to get to do the mean operation

00:19:27,960 --> 00:19:32,820
which is doing the the plus and the

00:19:30,570 --> 00:19:36,650
minus and divide all the way back to

00:19:32,820 --> 00:19:36,650
here's the function to pull out the data

00:19:37,670 --> 00:19:44,850
so right now the the data cube we've got

00:19:41,910 --> 00:19:48,780
a database setup on NCI running it for

00:19:44,850 --> 00:19:51,200
internal partners for the project so a

00:19:48,780 --> 00:19:54,230
lot of sciro and partner organizations

00:19:51,200 --> 00:19:57,290
using it

00:19:54,230 --> 00:20:00,260
or you can build your own so it's all

00:19:57,290 --> 00:20:03,620
open-source Postgres with SQL SQL

00:20:00,260 --> 00:20:04,910
alchemy and a couple of other faiths and

00:20:03,620 --> 00:20:07,370
tools that I think a lot of people would

00:20:04,910 --> 00:20:09,500
be familiar with if you have your own

00:20:07,370 --> 00:20:14,840
set of data so we've had people around

00:20:09,500 --> 00:20:17,330
the world try this so the a couple of

00:20:14,840 --> 00:20:19,970
space agencies have been trying to get

00:20:17,330 --> 00:20:26,300
their own data and seeing how it's being

00:20:19,970 --> 00:20:27,740
used and it seems to be going okay so

00:20:26,300 --> 00:20:30,140
what we really want to be able to do is

00:20:27,740 --> 00:20:35,150
make it so that anyone running Python on

00:20:30,140 --> 00:20:36,440
their laptop or PC anywhere can use the

00:20:35,150 --> 00:20:38,690
data set that we've got and the way

00:20:36,440 --> 00:20:42,670
we're going to do that is exposing the

00:20:38,690 --> 00:20:44,960
database just through a restful api and

00:20:42,670 --> 00:20:46,820
allow access to the data instead of

00:20:44,960 --> 00:20:48,320
directly accessing the files going

00:20:46,820 --> 00:20:51,620
through the threads opened app server

00:20:48,320 --> 00:20:53,630
which we saw in the first example which

00:20:51,620 --> 00:20:55,100
means you can access any particular

00:20:53,630 --> 00:20:59,150
piece of space and time of the data you

00:20:55,100 --> 00:21:01,730
want with just a query and not have to

00:20:59,150 --> 00:21:04,490
download many many files it'll just pull

00:21:01,730 --> 00:21:06,350
down what you want and I don't know when

00:21:04,490 --> 00:21:12,760
this is happening but it's sort of next

00:21:06,350 --> 00:21:12,760
on the schedule Thanks any questions

00:21:19,240 --> 00:21:23,800
other questions yes already

00:21:26,630 --> 00:21:31,160
thank you very much quickly ask

00:21:29,780 --> 00:21:33,190
you two questions one is you chose a

00:21:31,160 --> 00:21:35,960
chunk size does it make much difference

00:21:33,190 --> 00:21:37,760
your choice of chunk size and can I

00:21:35,960 --> 00:21:40,850
choose it for you perhaps if it makes a

00:21:37,760 --> 00:21:43,790
difference on performance and if I've

00:21:40,850 --> 00:21:45,620
got small data where it's a gigabyte

00:21:43,790 --> 00:21:47,480
data set and it doesn't matter is that

00:21:45,620 --> 00:21:48,950
give you much of a performance he should

00:21:47,480 --> 00:21:51,230
I just use sort of dusk anywhere and

00:21:48,950 --> 00:21:53,440
scale as I need it or is it gonna sort

00:21:51,230 --> 00:21:59,870
of make its life or small things

00:21:53,440 --> 00:22:02,740
so with chunk size first if you have too

00:21:59,870 --> 00:22:06,070
many chunks internally dusk uses

00:22:02,740 --> 00:22:06,070
dictionary object

00:22:06,169 --> 00:22:09,700
if you do sort of the the basic maths of

00:22:07,940 --> 00:22:13,999
how many chunks you're gonna get

00:22:09,700 --> 00:22:16,279
performance gets really bad a certain

00:22:13,999 --> 00:22:17,779
point the number of just the the

00:22:16,279 --> 00:22:20,029
dictionary operations it has to do to

00:22:17,779 --> 00:22:23,840
find the dependencies starts to get a

00:22:20,029 --> 00:22:27,190
bit ridiculous on the other hand having

00:22:23,840 --> 00:22:29,779
a chunk like you also want chunks that

00:22:27,190 --> 00:22:31,970
if the underlying thing is reading data

00:22:29,779 --> 00:22:36,139
you don't want to read data that's too

00:22:31,970 --> 00:22:39,529
small because you'll get so say with the

00:22:36,139 --> 00:22:42,639
roster file system at NCI and if you're

00:22:39,529 --> 00:22:44,749
doing it in a supercomputer application

00:22:42,639 --> 00:22:49,249
if you're reading anything less than a

00:22:44,749 --> 00:22:52,039
Meg you're really wasting time that it's

00:22:49,249 --> 00:22:53,480
it's reading maybe by default anyway and

00:22:52,039 --> 00:22:56,139
you're just reading a smaller part

00:22:53,480 --> 00:23:00,230
doesn't matter

00:22:56,139 --> 00:23:01,429
picking the chunk size is also tricky

00:23:00,230 --> 00:23:05,019
because if you're using netcdf

00:23:01,429 --> 00:23:07,879
underneath it's got an internal chunk

00:23:05,019 --> 00:23:12,499
size the way if you've got compression

00:23:07,879 --> 00:23:14,769
turned on the way it stores data so in

00:23:12,499 --> 00:23:17,600
terms of can it guess something for you

00:23:14,769 --> 00:23:19,820
it's it could do it but it would

00:23:17,600 --> 00:23:22,850
probably do it badly and I I wouldn't

00:23:19,820 --> 00:23:25,600
have a good handle on sort of a

00:23:22,850 --> 00:23:27,529
heuristic to find out what works and

00:23:25,600 --> 00:23:30,259
I've forgotten the second part of your

00:23:27,529 --> 00:23:32,239
question are you is it much for

00:23:30,259 --> 00:23:33,859
performance he was just just tiny data

00:23:32,239 --> 00:23:37,309
set where so we're got a fitting memory

00:23:33,859 --> 00:23:39,489
anyway so you've got to look at how

00:23:37,309 --> 00:23:44,299
efficient is how many codes you've got

00:23:39,489 --> 00:23:45,859
and whether that works in spreading

00:23:44,299 --> 00:23:47,409
across eight cores if you've got an

00:23:45,859 --> 00:23:50,239
eight core machine

00:23:47,409 --> 00:23:57,750
are you i/o bound right you see the you

00:23:50,239 --> 00:24:00,750
handle so it's it could be yeah

00:23:57,750 --> 00:24:02,540
Thanks thanks for your talk just

00:24:00,750 --> 00:24:05,940
wondering if this data works well for

00:24:02,540 --> 00:24:08,900
sparse matrices at all if you can if you

00:24:05,940 --> 00:24:12,720
can use sparse datasets under the hood

00:24:08,900 --> 00:24:14,580
in terms of you've you've got image data

00:24:12,720 --> 00:24:16,830
obviously which is quite dense if we've

00:24:14,580 --> 00:24:19,500
got text data which is quite sparse

00:24:16,830 --> 00:24:22,410
dictionary is there any benefit of using

00:24:19,500 --> 00:24:26,490
this sort of system for a large sparse

00:24:22,410 --> 00:24:30,030
data sense it could be so I'm not sure

00:24:26,490 --> 00:24:31,620
if x-ray would be a good fit and it

00:24:30,030 --> 00:24:34,590
might be I haven't really thought about

00:24:31,620 --> 00:24:38,100
the problem das has a couple of other

00:24:34,590 --> 00:24:41,940
collection types so it's also got a Dada

00:24:38,100 --> 00:24:44,340
pandas dataframe version and a bag

00:24:41,940 --> 00:24:44,700
object that works really well with it

00:24:44,340 --> 00:24:47,670
already

00:24:44,700 --> 00:24:48,900
so probably depending on the

00:24:47,670 --> 00:24:53,100
dimensionality of your daughter

00:24:48,900 --> 00:24:55,320
using a desk data frame gives you all

00:24:53,100 --> 00:24:59,070
the power of a panda's data frame with

00:24:55,320 --> 00:25:02,160
the ability to have that computation for

00:24:59,070 --> 00:25:04,470
you thanks sorry another question how

00:25:02,160 --> 00:25:08,190
would you say this compares to spark and

00:25:04,470 --> 00:25:12,210
in the distributed sense I'm not very

00:25:08,190 --> 00:25:14,630
familiar with spark so okay nice Thanks

00:25:12,210 --> 00:25:14,630
you'd say that

00:25:24,130 --> 00:25:29,630
so you mentioned multi-processing and I

00:25:26,990 --> 00:25:32,240
came a while ago from background where I

00:25:29,630 --> 00:25:34,970
was using the scaler Peck which is based

00:25:32,240 --> 00:25:38,330
on MPI the scallop accuses this idea of

00:25:34,970 --> 00:25:41,030
block cyclic layouts for data and I was

00:25:38,330 --> 00:25:44,180
just wondering um how well task works

00:25:41,030 --> 00:25:46,430
with specifically with MPI

00:25:44,180 --> 00:25:52,070
has there been any projects that have

00:25:46,430 --> 00:25:53,360
used both that and say MPI for pi not

00:25:52,070 --> 00:25:56,330
that I've seen

00:25:53,360 --> 00:25:59,060
and so the distributed library I talked

00:25:56,330 --> 00:26:01,640
about before is a sort of branching off

00:25:59,060 --> 00:26:05,240
and the work of task which does the

00:26:01,640 --> 00:26:09,820
cluster implementation and it doesn't

00:26:05,240 --> 00:26:12,380
use MPI it just uses HTTP he comes and

00:26:09,820 --> 00:26:16,760
pickling up your data and your functions

00:26:12,380 --> 00:26:21,590
to get processed remotely so I don't

00:26:16,760 --> 00:26:23,780
know anything about the the the thing

00:26:21,590 --> 00:26:26,420
you were talking about and what it would

00:26:23,780 --> 00:26:28,790
say that there's a talk on Sunday by

00:26:26,420 --> 00:26:31,250
Nathan from Bureau of Meteorology that

00:26:28,790 --> 00:26:35,230
will include some tasks and distributed

00:26:31,250 --> 00:26:35,230
as well so I recommend going to see that

00:26:36,310 --> 00:26:44,990
question um you say xra uses netcdf do

00:26:43,460 --> 00:26:51,470
you know if it's got plans to use any

00:26:44,990 --> 00:26:54,980
other formats like grip or hdf5 so hdf5

00:26:51,470 --> 00:26:59,060
I think because that's MIT's EDF is a

00:26:54,980 --> 00:27:01,450
type of hdf I believe well I could be

00:26:59,060 --> 00:27:01,450
completely wrong

00:27:06,730 --> 00:27:11,660
so the people that didn't hear that

00:27:08,870 --> 00:27:13,310
netcdf 3 was its own thing net city or 4

00:27:11,660 --> 00:27:20,120
is a type with hdf5

00:27:13,310 --> 00:27:23,060
I think so hdf yes there is they are

00:27:20,120 --> 00:27:28,460
extending the API of X ray to be able to

00:27:23,060 --> 00:27:29,930
add custom backends and and we're not so

00:27:28,460 --> 00:27:31,650
in this case we don't actually use the

00:27:29,930 --> 00:27:33,390
netcdf library we

00:27:31,650 --> 00:27:37,100
through raster i/o which wraps jido

00:27:33,390 --> 00:27:39,690
which then wraps the netcdf library so

00:27:37,100 --> 00:27:43,220
the way we get data in is we point

00:27:39,690 --> 00:27:48,210
restaurant at it and say read this

00:27:43,220 --> 00:27:51,330
jpeg2000 read this geo TIFF and then we

00:27:48,210 --> 00:27:52,860
when we write it out we write it as

00:27:51,330 --> 00:27:55,140
netcdf but there's nothing stopping you

00:27:52,860 --> 00:27:57,630
pointing at it had any data set and just

00:27:55,140 --> 00:28:02,250
doing the the reprojection on-the-fly if

00:27:57,630 --> 00:28:03,540
you need to but I said so that was

00:28:02,250 --> 00:28:06,600
answering the question from a data cue

00:28:03,540 --> 00:28:10,860
point of view but x-ray yeah there's

00:28:06,600 --> 00:28:12,450
alternate backends I don't know if

00:28:10,860 --> 00:28:18,150
they've gotten very far with a grid

00:28:12,450 --> 00:28:19,590
point giving thanks thank you very much

00:28:18,150 --> 00:28:23,130
Andrew and here is your official

00:28:19,590 --> 00:28:25,220
speakers mug if you would thank Andrew

00:28:23,130 --> 00:28:25,220

YouTube URL: https://www.youtube.com/watch?v=0dO-iC16xUo


