Title: Panel: Automated Canary Analysis
Publication date: 2017-09-22
Playlist: Spinnaker Summit 2017
Description: 
	Panelists include engineers from OpsMX, Armory, Netflix, and Google. Moderated by Vinay Shah from Netflix.  

From Spinnaker Summit 2017
Captions: 
	00:00:04,160 --> 00:00:12,389
welcome everyone hopefully you all had a

00:00:09,240 --> 00:00:18,480
good lunch and are not in a food coma of

00:00:12,389 --> 00:00:20,550
any time during this analysis discussion

00:00:18,480 --> 00:00:20,910
I think this is the only thing happening

00:00:20,550 --> 00:00:25,789
right now

00:00:20,910 --> 00:00:27,869
all right so no confusions there so

00:00:25,789 --> 00:00:30,420
let's start with a quick set of

00:00:27,869 --> 00:00:33,630
introductions and then we'll get to the

00:00:30,420 --> 00:00:35,880
meat of the topic here I am Vanessa I am

00:00:33,630 --> 00:00:38,270
an engineering manager at Netflix and

00:00:35,880 --> 00:00:42,600
will be moderating this panel discussion

00:00:38,270 --> 00:00:46,739
let's start start from here quickly

00:00:42,600 --> 00:00:50,070
introduce yourself hi I'm go paul de

00:00:46,739 --> 00:00:51,690
midi on the CEO of MX which stands for

00:00:50,070 --> 00:00:55,469
operations machine

00:00:51,690 --> 00:00:57,649
we specialize in cannery and test

00:00:55,469 --> 00:01:01,980
analysis automation of risk assessment

00:00:57,649 --> 00:01:05,010
prior to option max I built operational

00:01:01,980 --> 00:01:07,680
analytics platforms that large cloud

00:01:05,010 --> 00:01:09,600
providers as SK Telecom uses to manage

00:01:07,680 --> 00:01:11,670
their enterprise managed Enterprise

00:01:09,600 --> 00:01:14,070
after crises before that I was in the

00:01:11,670 --> 00:01:16,500
data center world built a lot of data

00:01:14,070 --> 00:01:17,850
centers one of the ones that you might

00:01:16,500 --> 00:01:21,380
be knowing is the Hong Kong stock

00:01:17,850 --> 00:01:24,900
exchange data center try that I was a

00:01:21,380 --> 00:01:31,439
aspiring professor I had a PhD and I all

00:01:24,900 --> 00:01:33,479
I wanted to do was become a professor my

00:01:31,439 --> 00:01:35,520
name is Jared Todd I work for Google I

00:01:33,479 --> 00:01:37,530
work on I'm the tech lead for the canary

00:01:35,520 --> 00:01:41,909
analysis service it's a I guess it's

00:01:37,530 --> 00:01:43,680
sibling to Netflix is a CA in my spare

00:01:41,909 --> 00:01:47,850
time I work on evaluating spinnaker for

00:01:43,680 --> 00:01:50,759
our internal use cases at Google I'm mad

00:01:47,850 --> 00:01:52,259
that is me in the picture I'll work on

00:01:50,759 --> 00:01:59,430
this clinical project at Google I

00:01:52,259 --> 00:02:02,250
somehow been working with the ACA team

00:01:59,430 --> 00:02:09,799
for a quite a while now on into the new

00:02:02,250 --> 00:02:13,109
canary service hello

00:02:09,799 --> 00:02:14,909
my name is Chris my name is Chris and

00:02:13,109 --> 00:02:16,590
I'm a senior data scientist at Netflix

00:02:14,909 --> 00:02:19,560
I'm on the fault detection engineering

00:02:16,590 --> 00:02:20,819
team along with Vinay we are responsible

00:02:19,560 --> 00:02:23,430
for the automated canarian house

00:02:20,819 --> 00:02:26,459
solution at Netflix I've been with

00:02:23,430 --> 00:02:30,719
Netflix for just over four years now and

00:02:26,459 --> 00:02:33,689
it's been fantastic hi my name is Isaac

00:02:30,719 --> 00:02:36,739
mascara I'm CEO and co-founder of armory

00:02:33,689 --> 00:03:11,639
we help enterprises get started in

00:02:36,739 --> 00:03:15,090
vinegar so canary in a coal mine has

00:03:11,639 --> 00:03:17,819
been a thing that has been going on for

00:03:15,090 --> 00:03:22,889
centuries as miners have been using it

00:03:17,819 --> 00:03:24,569
but canary has as a tool during your

00:03:22,889 --> 00:03:27,180
software deployment or configuration

00:03:24,569 --> 00:03:30,359
deployment is still what I believe in

00:03:27,180 --> 00:03:32,489
each area by the way my definition of

00:03:30,359 --> 00:03:38,009
Nicias something that doesn't have its

00:03:32,489 --> 00:03:40,349
own Wikipedia page so what I would like

00:03:38,009 --> 00:03:44,069
to start off with is you know in the

00:03:40,349 --> 00:03:47,639
last yesterday and and on this morning

00:03:44,069 --> 00:03:49,470
you have you heard kind of explanation

00:03:47,639 --> 00:03:53,519
of what canary analysis means for

00:03:49,470 --> 00:03:56,819
Netflix and in some ways but now we have

00:03:53,519 --> 00:03:58,709
this period set of panel let's start by

00:03:56,819 --> 00:04:01,079
just explaining in defining what is

00:03:58,709 --> 00:04:02,159
canary mean for you what is Canadian

00:04:01,079 --> 00:04:04,969
Alice's what is gonna be interesting

00:04:02,159 --> 00:04:04,969
mean for you

00:04:13,959 --> 00:04:24,169
so to me anytime you put a new build

00:04:20,120 --> 00:04:26,449
into production and you validate it

00:04:24,169 --> 00:04:31,190
through any analysis is what I would

00:04:26,449 --> 00:04:32,570
call a variation of Kennedy now Netflix

00:04:31,190 --> 00:04:35,330
would define it as one percent of

00:04:32,570 --> 00:04:37,340
traffic somebody would define it as blue

00:04:35,330 --> 00:04:40,669
green red black rolling

00:04:37,340 --> 00:04:44,570
blue green rolling update in your sort

00:04:40,669 --> 00:04:49,160
of kubernetes sort of DCOs world anytime

00:04:44,570 --> 00:04:51,110
you expose a release to put into

00:04:49,160 --> 00:04:53,780
production and you validate it that's

00:04:51,110 --> 00:04:56,150
what I would define as as a cannery and

00:04:53,780 --> 00:04:57,919
obviously we can we can shorten that

00:04:56,150 --> 00:05:03,590
definition and saying we're exposing it

00:04:57,919 --> 00:05:07,039
1% of of traffic yeah I would agree with

00:05:03,590 --> 00:05:08,449
that initially I say we also consider we

00:05:07,039 --> 00:05:10,639
canary things that aren't just builds

00:05:08,449 --> 00:05:13,910
some configuration changes can also be

00:05:10,639 --> 00:05:15,889
canary and the percentage of people who

00:05:13,910 --> 00:05:17,750
see that change varies by the service

00:05:15,889 --> 00:05:19,280
percent you know one percent may be too

00:05:17,750 --> 00:05:22,280
small to get an equal signal so we don't

00:05:19,280 --> 00:05:24,380
canary at that level and then yeah

00:05:22,280 --> 00:05:27,909
analysis is you know automating

00:05:24,380 --> 00:05:29,810
detection of anomalies in that canary I

00:05:27,909 --> 00:05:31,789
can't add too much of that other than

00:05:29,810 --> 00:05:33,349
that um like a meaningful system would

00:05:31,789 --> 00:05:36,320
have to avoid a bunch of sort of manual

00:05:33,349 --> 00:05:38,330
human drudgery and be consumable and not

00:05:36,320 --> 00:05:43,699
require like finding Chris and asking

00:05:38,330 --> 00:05:45,169
him how the thing works available it's

00:05:43,699 --> 00:05:47,780
really tough being on the end all the

00:05:45,169 --> 00:05:50,419
good answers have been given what they

00:05:47,780 --> 00:05:51,830
said I think to be more pragmatic and a

00:05:50,419 --> 00:05:54,199
little bit more specific I think canary

00:05:51,830 --> 00:05:57,070
analysis is is really a hybrid of two

00:05:54,199 --> 00:05:59,780
things it's it's some type of canary

00:05:57,070 --> 00:06:02,240
really cycled for the the process of

00:05:59,780 --> 00:06:04,970
deploying something it's a new server

00:06:02,240 --> 00:06:07,280
change or config change and that coupled

00:06:04,970 --> 00:06:09,110
with some type of judgment that judgment

00:06:07,280 --> 00:06:11,330
can be human you know you can be looking

00:06:09,110 --> 00:06:13,669
at dashboards or could be automated like

00:06:11,330 --> 00:06:14,900
we do it I think that's me the hybrid of

00:06:13,669 --> 00:06:16,940
both you have the setup in the

00:06:14,900 --> 00:06:18,560
infrastructure you have the maturity and

00:06:16,940 --> 00:06:20,270
in the infrastructure in the automation

00:06:18,560 --> 00:06:21,550
there and the combining that with those

00:06:20,270 --> 00:06:23,199
observability

00:06:21,550 --> 00:06:26,590
getting the metrics and as well as doing

00:06:23,199 --> 00:06:28,949
the analysis whether that's humans your

00:06:26,590 --> 00:06:35,080
farm to doubt to Mechanical Turk or its

00:06:28,949 --> 00:06:37,150
or its automated like we do you guys

00:06:35,080 --> 00:06:38,500
took all the good words

00:06:37,150 --> 00:06:39,940
I guess just really to add to everything

00:06:38,500 --> 00:06:42,669
they're saying I think there's a you

00:06:39,940 --> 00:06:44,110
know really it's I guess but everything

00:06:42,669 --> 00:06:47,560
they started with the goal of reducing

00:06:44,110 --> 00:06:51,340
risk and doing some sort of risk

00:06:47,560 --> 00:06:55,270
assessment and doing it at a low cost

00:06:51,340 --> 00:06:58,199
because outside of canarian I think

00:06:55,270 --> 00:07:01,659
people have tried to reduce the risk by

00:06:58,199 --> 00:07:03,430
potentially doing a bunch of you know

00:07:01,659 --> 00:07:06,039
automated integration tests but the cost

00:07:03,430 --> 00:07:07,539
of that is so high that you know adding

00:07:06,039 --> 00:07:08,770
adding the the risk assessment it's

00:07:07,539 --> 00:07:15,069
important part and that's the goal is to

00:07:08,770 --> 00:07:18,340
retain risk reduction anybody can start

00:07:15,069 --> 00:07:21,430
we don't have a start for fear why do

00:07:18,340 --> 00:07:24,009
you think or why do you guys think it's

00:07:21,430 --> 00:07:26,380
not as ubiquitous or commoditize as

00:07:24,009 --> 00:07:28,509
things like monitoring or some of the

00:07:26,380 --> 00:07:31,090
other operation related stuff that we

00:07:28,509 --> 00:07:33,940
have what's what's preventing the

00:07:31,090 --> 00:07:40,180
industry from just saying we can Erie of

00:07:33,940 --> 00:07:42,909
course we all do it it's just not that

00:07:40,180 --> 00:07:46,539
easy I think even with the monitoring

00:07:42,909 --> 00:07:48,279
stuff what's really interesting is even

00:07:46,539 --> 00:07:49,930
though it is relatively commoditized we

00:07:48,279 --> 00:07:52,180
still run into a bunch of enterprises

00:07:49,930 --> 00:07:53,319
who are not really monitoring a lot of

00:07:52,180 --> 00:07:55,930
things and still trying to figure out

00:07:53,319 --> 00:07:57,490
how to monitor their systems and as soon

00:07:55,930 --> 00:07:59,409
as they figure that out it's like oh man

00:07:57,490 --> 00:08:01,659
now now there's containers and not have

00:07:59,409 --> 00:08:03,669
to kind of refigure that story out so I

00:08:01,659 --> 00:08:05,560
mean you gave a good talk yesterday

00:08:03,669 --> 00:08:09,340
around the canal it's just a big part of

00:08:05,560 --> 00:08:10,539
that is observability and I think a lot

00:08:09,340 --> 00:08:12,669
of these enterprises are still

00:08:10,539 --> 00:08:15,340
struggling with that and so without that

00:08:12,669 --> 00:08:17,340
you can't even get to canary so that's

00:08:15,340 --> 00:08:20,800
the first part and the second part is

00:08:17,340 --> 00:08:22,569
part of the canary Ang's you're gonna

00:08:20,800 --> 00:08:24,909
have to have orchestration the ability

00:08:22,569 --> 00:08:27,639
to actually deploy in a consistent in a

00:08:24,909 --> 00:08:29,139
safe manner that also doesn't exist in

00:08:27,639 --> 00:08:32,409
many of the enterprises that we talk to

00:08:29,139 --> 00:08:33,969
and so those are prerequisites to even

00:08:32,409 --> 00:08:34,730
having the you know the chance that

00:08:33,969 --> 00:08:36,560
canary

00:08:34,730 --> 00:08:38,120
and without that it's it's practically

00:08:36,560 --> 00:08:40,070
impossible so that's why you see it and

00:08:38,120 --> 00:08:41,180
that's why you see you know companies

00:08:40,070 --> 00:08:42,830
like Netflix oh I've been doing for so

00:08:41,180 --> 00:08:45,590
long because they've solved those two

00:08:42,830 --> 00:08:49,240
problems long time ago and now they can

00:08:45,590 --> 00:08:52,400
start doing more advanced analysis I

00:08:49,240 --> 00:08:54,530
think to add to that it's also more from

00:08:52,400 --> 00:08:56,060
a culture and company perspective its

00:08:54,530 --> 00:08:58,100
willingness to have you know to take

00:08:56,060 --> 00:08:59,630
that risk on and doing a canary you know

00:08:58,100 --> 00:09:01,370
the idea of the care is to mitigate risk

00:08:59,630 --> 00:09:03,140
but you know you are during that canary

00:09:01,370 --> 00:09:04,520
deployment or you know when you shift

00:09:03,140 --> 00:09:06,410
some traffic over into that canary

00:09:04,520 --> 00:09:09,530
you're introducing potential risk for

00:09:06,410 --> 00:09:10,580
those users and so you you know to some

00:09:09,530 --> 00:09:11,990
degree you know we're doing this in

00:09:10,580 --> 00:09:14,210
production you could be you know

00:09:11,990 --> 00:09:16,460
potentially introducing an impact of

00:09:14,210 --> 00:09:19,100
production and so you know as a company

00:09:16,460 --> 00:09:20,330
or as a start-up or as a developer yet

00:09:19,100 --> 00:09:22,460
be willing to you know take even that

00:09:20,330 --> 00:09:26,060
little bit of risk to do the canary as

00:09:22,460 --> 00:09:27,650
well and not echo the same sentiments

00:09:26,060 --> 00:09:29,630
that Isaac had in terms like

00:09:27,650 --> 00:09:31,640
orchestration and need to be able to you

00:09:29,630 --> 00:09:34,220
know create the infrastructure to

00:09:31,640 --> 00:09:35,960
automate that and while we are room fold

00:09:34,220 --> 00:09:42,560
people who like spinnaker and use

00:09:35,960 --> 00:09:46,160
spinnaker not everyone does not yet just

00:09:42,560 --> 00:09:48,380
to add to what Isaac and Chris said the

00:09:46,160 --> 00:09:50,510
third company ously the monitoring and

00:09:48,380 --> 00:09:52,340
orchestration is necessary and they're

00:09:50,510 --> 00:09:55,850
just coming along now the third

00:09:52,340 --> 00:09:58,930
component is a general-purpose sort of a

00:09:55,850 --> 00:10:01,460
cannery system that first can be trusted

00:09:58,930 --> 00:10:03,290
verifiable and testable so you can just

00:10:01,460 --> 00:10:06,380
run a cannery but you may not believe in

00:10:03,290 --> 00:10:10,060
it and easy to onboard I think that's

00:10:06,380 --> 00:10:12,920
sort of the I'm hoping that's the

00:10:10,060 --> 00:10:17,530
general purpose system that the cannery

00:10:12,920 --> 00:10:17,530
analysis micro service would evolve into

00:10:21,610 --> 00:10:27,920
just a quick raise of hands from the

00:10:24,410 --> 00:10:31,690
audience who all are using our operating

00:10:27,920 --> 00:10:31,690
Canadian Alice's in their organization

00:10:35,140 --> 00:10:41,350
and so for the rest of you guys any

00:10:38,810 --> 00:10:44,930
thoughts questions for the panel on why

00:10:41,350 --> 00:10:46,710
your organization's are not investing in

00:10:44,930 --> 00:10:52,470
this place and in

00:10:46,710 --> 00:11:03,360
you would like to discuss just just toss

00:10:52,470 --> 00:11:05,100
the microphone out just me for the

00:11:03,360 --> 00:11:07,650
longest time I guess it was there's no

00:11:05,100 --> 00:11:09,930
real standard for kind of doing Canaries

00:11:07,650 --> 00:11:12,420
in a spinnaker way seeing the

00:11:09,930 --> 00:11:13,860
announcements with open source project

00:11:12,420 --> 00:11:20,570
like that is awesome and it's kind of

00:11:13,860 --> 00:11:20,570
helping frame doing it all later

00:11:56,840 --> 00:12:06,240
and based on the system and the

00:12:00,930 --> 00:12:10,110
thresholds having API based approach to

00:12:06,240 --> 00:12:13,110
decide whether it can go to production

00:12:10,110 --> 00:12:17,190
whatever percentage it is we are not

00:12:13,110 --> 00:12:19,290
using any open source cannery stuff but

00:12:17,190 --> 00:12:22,320
we built our own and it is still

00:12:19,290 --> 00:12:24,960
maturing and the key is having

00:12:22,320 --> 00:12:28,320
observability spec that everyone can

00:12:24,960 --> 00:12:30,600
refer to and having the centralized

00:12:28,320 --> 00:12:34,170
system where the metrics can the

00:12:30,600 --> 00:12:40,230
thresholds can be configured but to make

00:12:34,170 --> 00:12:47,940
the decision engine stores the data for

00:12:40,230 --> 00:12:51,960
some auditing as well yeah you guys

00:12:47,940 --> 00:12:54,720
mentioned about safety and about the

00:12:51,960 --> 00:12:56,400
fact that this is not a replacement for

00:12:54,720 --> 00:12:59,160
testing I heard it in a few talks that

00:12:56,400 --> 00:13:00,300
we had some people will argue that here

00:12:59,160 --> 00:13:02,130
we have a good testing

00:13:00,300 --> 00:13:05,160
you know we have been releasing our

00:13:02,130 --> 00:13:06,930
bills all the time after testing so why

00:13:05,160 --> 00:13:09,660
do Canaries what's what's the goal their

00:13:06,930 --> 00:13:11,220
name what or vice versa should I replace

00:13:09,660 --> 00:13:13,440
my testing framework with connealy

00:13:11,220 --> 00:13:15,000
analysis framework and reduce my cost

00:13:13,440 --> 00:13:25,800
over there what are your thoughts on

00:13:15,000 --> 00:13:28,170
that we see two kinds of customers I

00:13:25,800 --> 00:13:31,770
mean basically we are a vendor and we

00:13:28,170 --> 00:13:34,770
see people that want speed they want the

00:13:31,770 --> 00:13:37,860
traditional the one the one of these the

00:13:34,770 --> 00:13:39,780
ones would be the prime users of things

00:13:37,860 --> 00:13:42,240
like cannery and there they need

00:13:39,780 --> 00:13:46,020
consistency so they got a lot of

00:13:42,240 --> 00:13:47,850
releases going on to maybe 5000

00:13:46,020 --> 00:13:51,570
developers they need they want to have a

00:13:47,850 --> 00:13:54,180
consistent gate and policy and that that

00:13:51,570 --> 00:13:56,220
IT organization can enforce and some of

00:13:54,180 --> 00:13:57,750
them are looking at cannery for that and

00:13:56,220 --> 00:14:00,180
then obviously there's an automated

00:13:57,750 --> 00:14:04,620
decisioning that needs to happen and

00:14:00,180 --> 00:14:06,870
that you can say is a runtime analysis

00:14:04,620 --> 00:14:10,200
which is typically or not all of that is

00:14:06,870 --> 00:14:12,140
done in a traditional testing stages and

00:14:10,200 --> 00:14:14,310
we've also seen customers who

00:14:12,140 --> 00:14:16,320
interestingly looked at our candy and

00:14:14,310 --> 00:14:18,450
said hey can we use it in our load

00:14:16,320 --> 00:14:20,250
testing environment and then they would

00:14:18,450 --> 00:14:22,470
and then we tweak the algorithms and

00:14:20,250 --> 00:14:25,830
saying okay it sort of makes sense so so

00:14:22,470 --> 00:14:27,900
in some sense the consistency policy the

00:14:25,830 --> 00:14:30,510
speed with which you you can make a

00:14:27,900 --> 00:14:32,310
decision and you can do a lot of

00:14:30,510 --> 00:14:35,040
analysis you can analyze for memory

00:14:32,310 --> 00:14:38,100
leaks and things like that and also you

00:14:35,040 --> 00:14:40,890
can catch faults sooner so in some sense

00:14:38,100 --> 00:14:43,050
it does not replace the the traditional

00:14:40,890 --> 00:14:46,560
testing functionality but it can augment

00:14:43,050 --> 00:14:48,660
it that's sort of you I was gonna say

00:14:46,560 --> 00:14:50,940
exactly that it doesn't replace testing

00:14:48,660 --> 00:14:53,370
I think of canary analysis is like the

00:14:50,940 --> 00:14:54,810
last step to a safe rollout because

00:14:53,370 --> 00:14:56,280
ultimately there's no substitute for

00:14:54,810 --> 00:14:57,330
running in production you can do all the

00:14:56,280 --> 00:14:59,370
testing you want your test environment

00:14:57,330 --> 00:15:03,090
but production traffic is production

00:14:59,370 --> 00:15:04,470
traffic and so we often get the same

00:15:03,090 --> 00:15:08,970
pushback like it just slows things down

00:15:04,470 --> 00:15:11,070
but we have you know years of

00:15:08,970 --> 00:15:12,570
experiences say it's better to do this

00:15:11,070 --> 00:15:13,769
you're going to be here now safer world

00:15:12,570 --> 00:15:17,009
outside overall if

00:15:13,769 --> 00:15:18,360
to the canary stage yeah I mean that

00:15:17,009 --> 00:15:19,439
makes a lot of sense and I think the

00:15:18,360 --> 00:15:21,209
challenge for us as part of the

00:15:19,439 --> 00:15:22,709
spinnaker project is to make it so that

00:15:21,209 --> 00:15:24,660
it doesn't feel like it slowed you down

00:15:22,709 --> 00:15:26,910
it should really increase your velocity

00:15:24,660 --> 00:15:28,019
and especially if you can get as quick

00:15:26,910 --> 00:15:29,459
as possible the point where you have

00:15:28,019 --> 00:15:31,769
enough confidence to roll it out to all

00:15:29,459 --> 00:15:32,910
your users that's that's an improvement

00:15:31,769 --> 00:15:34,559
that's not slowing it down but that's

00:15:32,910 --> 00:15:36,569
that's a challenge for us make it

00:15:34,559 --> 00:15:38,100
consumable make it easy to use and

00:15:36,569 --> 00:15:40,199
especially when a new application or

00:15:38,100 --> 00:15:41,850
service is being on-boarded let them

00:15:40,199 --> 00:15:43,529
learn from what other similar sort of

00:15:41,850 --> 00:15:45,569
shaped services and applications have

00:15:43,529 --> 00:15:47,189
already done build on their success and

00:15:45,569 --> 00:15:50,759
don't kind of start from scratch and

00:15:47,189 --> 00:15:53,309
roll your own each time yeah I think if

00:15:50,759 --> 00:15:55,619
you look at canoeing it's really just an

00:15:53,309 --> 00:15:58,860
additional tool to reduce risk before

00:15:55,619 --> 00:16:01,290
you go - the way that I kind of see it

00:15:58,860 --> 00:16:02,519
is if you look at the tools you have you

00:16:01,290 --> 00:16:04,439
have things like you know testing

00:16:02,519 --> 00:16:06,389
integration testing Canarian could be

00:16:04,439 --> 00:16:07,829
that additional tool the cost of

00:16:06,389 --> 00:16:10,949
integration testing is typically the

00:16:07,829 --> 00:16:13,799
highest so if you assess a particular

00:16:10,949 --> 00:16:16,860
area of your application and you want to

00:16:13,799 --> 00:16:18,329
build an integration test for it if the

00:16:16,860 --> 00:16:20,220
cost of doing it is low meaning you

00:16:18,329 --> 00:16:21,779
don't have to orchestrate databases and

00:16:20,220 --> 00:16:24,540
queues and all these other dependencies

00:16:21,779 --> 00:16:26,309
around it in order to kind of assess to

00:16:24,540 --> 00:16:28,079
reduce the risk by building the

00:16:26,309 --> 00:16:31,350
integration test great but in a lot of

00:16:28,079 --> 00:16:33,269
cases and that isn't possible in order

00:16:31,350 --> 00:16:35,040
to build an integration test to reduce

00:16:33,269 --> 00:16:36,449
the risk is very very expensive and this

00:16:35,040 --> 00:16:38,939
is where I think canarian comes in and

00:16:36,449 --> 00:16:41,040
gives you that tool to say look to

00:16:38,939 --> 00:16:42,360
orchestrate this integration test is too

00:16:41,040 --> 00:16:44,879
expensive and it won't catch the bug

00:16:42,360 --> 00:16:46,439
anyways let's move this to canary and

00:16:44,879 --> 00:16:48,660
let canary in catch it so it's just an

00:16:46,439 --> 00:16:51,480
additional tool but it doesn't negate

00:16:48,660 --> 00:16:54,559
the other tools that you have you should

00:16:51,480 --> 00:16:57,720
all be doing more testing by the way I

00:16:54,559 --> 00:17:01,259
think to add maybe reiterate to some

00:16:57,720 --> 00:17:02,549
degree you know given some complex

00:17:01,259 --> 00:17:05,010
environments whether you know you have a

00:17:02,549 --> 00:17:06,480
complex microservice infrastructure it

00:17:05,010 --> 00:17:08,039
can be you know like house except very

00:17:06,480 --> 00:17:09,689
expensive and time-consuming to try and

00:17:08,039 --> 00:17:12,539
set up you know full integration tests

00:17:09,689 --> 00:17:14,399
where you can simulation engineering and

00:17:12,539 --> 00:17:16,020
so Canaries allow you to you know to get

00:17:14,399 --> 00:17:17,520
production workload and to test these

00:17:16,020 --> 00:17:19,110
more complex environments whether you

00:17:17,520 --> 00:17:20,520
don't you maybe your dependencies change

00:17:19,110 --> 00:17:22,350
upstream but you know when you're

00:17:20,520 --> 00:17:24,959
testing and so Canaries can allow you to

00:17:22,350 --> 00:17:26,279
you don't get traffic and to in the

00:17:24,959 --> 00:17:28,409
production environment and to don't

00:17:26,279 --> 00:17:30,210
handle these complex environment and so

00:17:28,409 --> 00:17:31,799
you know you end up getting the traffic

00:17:30,210 --> 00:17:50,100
what your users would hopefully normally

00:17:31,799 --> 00:17:59,880
get but do more testing like a bee and

00:17:50,100 --> 00:18:01,950
canary so how long do you think because

00:17:59,880 --> 00:18:03,720
in some in some cases it's all about the

00:18:01,950 --> 00:18:06,600
right sample size and if you may have

00:18:03,720 --> 00:18:08,970
very limited size of users for whatever

00:18:06,600 --> 00:18:10,620
maybe it's a distributed system that

00:18:08,970 --> 00:18:12,360
only gets traffic maybe once a week or

00:18:10,620 --> 00:18:13,620
whatever it may be how do you kind of

00:18:12,360 --> 00:18:16,380
draw the line on that are there any hard

00:18:13,620 --> 00:18:25,590
requirements you noticed or advise

00:18:16,380 --> 00:18:33,870
against 30 minutes for everything just

00:18:25,590 --> 00:18:35,070
30 minutes is the is the answer but it

00:18:33,870 --> 00:18:36,899
really depends on the service like you

00:18:35,070 --> 00:18:39,330
said is if you have a micro service that

00:18:36,899 --> 00:18:42,330
gets traffic for 20 minutes once every

00:18:39,330 --> 00:18:44,700
week you know caring every other time is

00:18:42,330 --> 00:18:45,779
probably not gonna be useful so it

00:18:44,700 --> 00:18:46,830
really depends on the service right

00:18:45,779 --> 00:18:47,970
there so we try to mitigate at risk

00:18:46,830 --> 00:18:49,260
you're trying to assess risk and

00:18:47,970 --> 00:18:50,309
determine what the impact this is going

00:18:49,260 --> 00:18:53,220
to be it so you have to look at the

00:18:50,309 --> 00:18:54,750
service and figure out you know at what

00:18:53,220 --> 00:18:56,279
point do I think I've you know had

00:18:54,750 --> 00:18:57,600
enough customer traffic through this or

00:18:56,279 --> 00:18:59,340
enough traffic through the micro service

00:18:57,600 --> 00:19:00,960
to you know have an accurate assessment

00:18:59,340 --> 00:19:03,120
of risk that's gonna depend upon the

00:19:00,960 --> 00:19:05,909
number of requests coming through it the

00:19:03,120 --> 00:19:07,860
load on it but you know within Netflix

00:19:05,909 --> 00:19:10,679
we typically recommend a minimum of

00:19:07,860 --> 00:19:12,600
about 30 minutes that's all right lower

00:19:10,679 --> 00:19:15,360
bound that's that's primarily because of

00:19:12,600 --> 00:19:18,000
our Atlas our telemetry stores stores

00:19:15,360 --> 00:19:19,980
data at the minute granularity so at a

00:19:18,000 --> 00:19:21,899
minimum at a 30 minutes we get 30 data

00:19:19,980 --> 00:19:23,130
points if you ever tried to try to do

00:19:21,899 --> 00:19:26,220
something with a 10 data points or

00:19:23,130 --> 00:19:27,720
you're eyeballing your it can be tough

00:19:26,220 --> 00:19:30,240
so we say you know usually around a

00:19:27,720 --> 00:19:33,299
minimum of 30 but a lot of our services

00:19:30,240 --> 00:19:34,650
canary for a couple hours we've even

00:19:33,299 --> 00:19:37,110
seen some services

00:19:34,650 --> 00:19:38,970
with really critical changes go 96 hours

00:19:37,110 --> 00:19:41,370
and so in this case they're looking at

00:19:38,970 --> 00:19:42,840
you know a couple days of full cycle

00:19:41,370 --> 00:19:44,850
traffic you know peak and trough peak

00:19:42,840 --> 00:19:47,190
and trough and so on so it's really up

00:19:44,850 --> 00:19:48,600
to the service owner and their

00:19:47,190 --> 00:19:49,830
experience to determine are they're

00:19:48,600 --> 00:19:52,260
gonna get enough traffic through this to

00:19:49,830 --> 00:19:54,210
make an accurate decision what are you

00:19:52,260 --> 00:19:55,230
like a sufficiently intelligent system

00:19:54,210 --> 00:19:56,160
should be able to answer that question

00:19:55,230 --> 00:19:57,810
for you

00:19:56,160 --> 00:20:00,120
like once your organization spends

00:19:57,810 --> 00:20:01,710
enough time and money sort of teaching

00:20:00,120 --> 00:20:03,780
that system things it should be able to

00:20:01,710 --> 00:20:04,980
answer for your type of service what's

00:20:03,780 --> 00:20:06,420
the amount of time you have to run it

00:20:04,980 --> 00:20:11,940
for us you don't spend more time and

00:20:06,420 --> 00:20:14,040
money waiting we think of a score which

00:20:11,940 --> 00:20:15,990
is pass/fail or warning whatever and

00:20:14,040 --> 00:20:18,000
then we think of a confidence in that

00:20:15,990 --> 00:20:21,060
score the confidence can be calculated

00:20:18,000 --> 00:20:22,770
by the number of data points you collect

00:20:21,060 --> 00:20:25,620
for this cannery as well as what you

00:20:22,770 --> 00:20:27,510
learnt of this service in the past so we

00:20:25,620 --> 00:20:29,760
like to abstract it and sort of you know

00:20:27,510 --> 00:20:31,470
just give up a score and a confidence

00:20:29,760 --> 00:20:32,910
and initially you can have a 90 score or

00:20:31,470 --> 00:20:35,460
a zero confidence which is meaningless

00:20:32,910 --> 00:20:39,090
and in our experience we found that two

00:20:35,460 --> 00:20:44,340
hours is and when for most services it's

00:20:39,090 --> 00:20:46,140
sort of a fairly confident I mean that's

00:20:44,340 --> 00:20:49,590
sort of but I think 30 minutes is

00:20:46,140 --> 00:21:07,530
minimum but yeah so that's the concept

00:20:49,590 --> 00:21:09,180
we have kind of longer times can you

00:21:07,530 --> 00:21:12,810
talk a little bit about how this falls

00:21:09,180 --> 00:21:16,080
into falls into a model where every get

00:21:12,810 --> 00:21:19,140
commit trigger is kind of a new pipeline

00:21:16,080 --> 00:21:20,220
and a new deployment because we're

00:21:19,140 --> 00:21:23,010
definitely getting pressure at least

00:21:20,220 --> 00:21:24,990
from above just getting that time short

00:21:23,010 --> 00:21:26,820
like getting code in front of customers

00:21:24,990 --> 00:21:29,580
as quickly as possible and so I'm

00:21:26,820 --> 00:21:32,130
wondering do you guys like aggregate

00:21:29,580 --> 00:21:34,590
these commits or kind of how does this

00:21:32,130 --> 00:21:38,550
fit in that model or does it not fit at

00:21:34,590 --> 00:21:40,140
all kind of thing so I guess the example

00:21:38,550 --> 00:21:42,900
I gave is kind of an outlier so it was

00:21:40,140 --> 00:21:46,470
like a very big change and it was being

00:21:42,900 --> 00:21:47,740
done to mitigate some really big risk so

00:21:46,470 --> 00:21:49,720
that's not the cut the norm

00:21:47,740 --> 00:21:51,330
kind of the normal use cases our

00:21:49,720 --> 00:21:55,480
Canaries maybe run for a few hours

00:21:51,330 --> 00:21:57,430
maximum but if I'm not sure if any of

00:21:55,480 --> 00:21:58,630
you attended the presentation yesterday

00:21:57,430 --> 00:22:00,730
where I talked about these developer

00:21:58,630 --> 00:22:02,020
Canaries he said yeah our developers can

00:22:00,730 --> 00:22:05,110
never developer branch and they can

00:22:02,020 --> 00:22:07,420
carry those and so in that kind of model

00:22:05,110 --> 00:22:09,160
is it's not being aggregated up to say a

00:22:07,420 --> 00:22:11,290
master branch as developers can run

00:22:09,160 --> 00:22:13,420
their own Canaries against live no

00:22:11,290 --> 00:22:15,880
production traffic and get an assessment

00:22:13,420 --> 00:22:17,560
of their developer kind of branch before

00:22:15,880 --> 00:22:18,760
it gets rolled up master of course

00:22:17,560 --> 00:22:21,960
master is going to go through a canary

00:22:18,760 --> 00:22:24,610
as well to assess kind of everyone's

00:22:21,960 --> 00:22:26,320
commits as well but that's kind of like

00:22:24,610 --> 00:22:28,390
how we do it at Netflix I'm not sure

00:22:26,320 --> 00:22:31,150
about say Google yeah I was just gonna

00:22:28,390 --> 00:22:33,370
say at Google we have varying Canary

00:22:31,150 --> 00:22:36,040
times based on I'll say the scope of the

00:22:33,370 --> 00:22:37,240
change I'm gonna count contradict Chris

00:22:36,040 --> 00:22:40,690
and say you are minimum canary time is

00:22:37,240 --> 00:22:43,180
five minutes because it's a really small

00:22:40,690 --> 00:22:44,620
change but after that it's after that is

00:22:43,180 --> 00:22:48,040
configurable by the user you can have

00:22:44,620 --> 00:22:50,350
days around and it totally depends on

00:22:48,040 --> 00:22:51,670
how big is a change and how risky is it

00:22:50,350 --> 00:22:55,540
how long do you how much confidence do

00:22:51,670 --> 00:23:00,130
you want to have in that change one

00:22:55,540 --> 00:23:01,750
thing you could do is to send your

00:23:00,130 --> 00:23:04,300
metrics faster like sampling rate

00:23:01,750 --> 00:23:06,940
instead of doing once a minute if you do

00:23:04,300 --> 00:23:10,390
it maybe once a second then you can

00:23:06,940 --> 00:23:12,730
literally squeeze it down to external

00:23:10,390 --> 00:23:16,210
yeah actually some of our customers do

00:23:12,730 --> 00:23:20,830
that I guess just to add though is is

00:23:16,210 --> 00:23:22,600
there's a challenge is canary analysis

00:23:20,830 --> 00:23:24,430
is used or should be used to help you

00:23:22,600 --> 00:23:25,750
know assess the risk and there's some

00:23:24,430 --> 00:23:27,040
trade off so you have to make is you

00:23:25,750 --> 00:23:29,650
know if you're on a community for a day

00:23:27,040 --> 00:23:31,780
you know you you potentially get a

00:23:29,650 --> 00:23:33,220
representative sample of what your users

00:23:31,780 --> 00:23:35,610
would see you so if you have you know a

00:23:33,220 --> 00:23:37,450
web service that has much endpoints and

00:23:35,610 --> 00:23:39,250
maybe you know some of those endpoints

00:23:37,450 --> 00:23:40,630
get healthy hit less frequently if

00:23:39,250 --> 00:23:42,700
you're on a really quick canary those

00:23:40,630 --> 00:23:44,080
endpoints not may not get exercised and

00:23:42,700 --> 00:23:45,850
maybe there's a problem that exists

00:23:44,080 --> 00:23:47,950
through that code path and so if a

00:23:45,850 --> 00:23:50,320
canary you gotta weigh the pros and cons

00:23:47,950 --> 00:23:53,530
right it's got a web service that has a

00:23:50,320 --> 00:23:55,270
thousand endpoints and you know 99 of

00:23:53,530 --> 00:23:58,270
them don't really get hit except for

00:23:55,270 --> 00:23:59,410
like once every four days you have to

00:23:58,270 --> 00:24:01,280
balance the you know how long do you

00:23:59,410 --> 00:24:03,440
want around the canary forward versus

00:24:01,280 --> 00:24:07,790
how fast a velocity do you want to run

00:24:03,440 --> 00:24:10,400
as an organization yeah I mean I think

00:24:07,790 --> 00:24:13,100
this goes back to the you know the kind

00:24:10,400 --> 00:24:16,160
of question we had is you know Canarian

00:24:13,100 --> 00:24:18,650
is just one tool to reduce risk you know

00:24:16,160 --> 00:24:20,630
using spinnaker it comes with a bunch of

00:24:18,650 --> 00:24:22,880
different deployment strategies so you

00:24:20,630 --> 00:24:26,030
can use red black and rollin red black

00:24:22,880 --> 00:24:27,470
now to also help reduce risk so canarian

00:24:26,030 --> 00:24:29,600
can be shortened but then have a

00:24:27,470 --> 00:24:31,730
different type of deployment strategy to

00:24:29,600 --> 00:24:33,050
roll out to the rest of the servers that

00:24:31,730 --> 00:24:35,660
I give you the flexibility to easily

00:24:33,050 --> 00:24:36,980
roll back if there is a problem so

00:24:35,660 --> 00:24:39,380
you're really gonna have to combine a

00:24:36,980 --> 00:24:42,290
bunch of different things Canarian you

00:24:39,380 --> 00:24:43,910
know isn't the end-all be-all but if

00:24:42,290 --> 00:24:45,830
that you know and it is the trade-off

00:24:43,910 --> 00:24:48,830
right it is the trade-off of should I

00:24:45,830 --> 00:24:50,420
just release this immediately or release

00:24:48,830 --> 00:24:53,090
a little bit slower to gain to gain

00:24:50,420 --> 00:24:55,580
confidence in it and then it comes back

00:24:53,090 --> 00:24:57,830
to what does your company value I mean

00:24:55,580 --> 00:24:58,910
if you look at Facebook's you know that

00:24:57,830 --> 00:25:00,710
whole thing is move fast and break

00:24:58,910 --> 00:25:02,270
things they valued moving fast at the

00:25:00,710 --> 00:25:03,620
cost of breaking things and you just

00:25:02,270 --> 00:25:05,540
need to figure out what that is for your

00:25:03,620 --> 00:25:07,160
company and everybody's everybody's

00:25:05,540 --> 00:25:08,780
decision here around what that should be

00:25:07,160 --> 00:25:10,220
is going to be very different based on

00:25:08,780 --> 00:25:11,900
the company values and it just comes

00:25:10,220 --> 00:25:14,360
back to the people what they want what

00:25:11,900 --> 00:25:15,830
they need and then you you can make you

00:25:14,360 --> 00:25:19,780
can implement those decisions with all

00:25:15,830 --> 00:25:19,780
of these tools that spinnaker gives you

00:25:22,000 --> 00:25:27,050
just a follow-up question on that we

00:25:25,160 --> 00:25:29,060
talked about Canadian Alice's and we

00:25:27,050 --> 00:25:30,860
talked about automated Canadian Alice's

00:25:29,060 --> 00:25:32,900
and automated being this notion that

00:25:30,860 --> 00:25:35,540
helps you provide speed so you can do it

00:25:32,900 --> 00:25:37,550
more often how awesome a tit can a

00:25:35,540 --> 00:25:39,290
Canadian Alice's system be like can you

00:25:37,550 --> 00:25:42,680
trust this core always like from your

00:25:39,290 --> 00:25:44,930
experiences what's what's been the

00:25:42,680 --> 00:25:52,940
practical usage of the automated power

00:25:44,930 --> 00:25:55,940
of it so Google System has a set of

00:25:52,940 --> 00:25:58,730
default analysis that it runs users can

00:25:55,940 --> 00:26:00,500
add more and customizing if they like do

00:25:58,730 --> 00:26:05,630
people trust the results not always

00:26:00,500 --> 00:26:08,270
should they probably just math but it's

00:26:05,630 --> 00:26:09,830
that is a you know getting users to

00:26:08,270 --> 00:26:11,960
trust the results is a continual battle

00:26:09,830 --> 00:26:13,730
we do a lot of fielding user questions

00:26:11,960 --> 00:26:15,080
like why did why do you guys say this is

00:26:13,730 --> 00:26:16,250
bad I think it's good

00:26:15,080 --> 00:26:18,740
and we have to do a lot of explaining in

00:26:16,250 --> 00:26:21,290
that regard didn't Google haven't

00:26:18,740 --> 00:26:23,630
noticed today apparently yeah I saw the

00:26:21,290 --> 00:26:32,870
news I don't know what happened just

00:26:23,630 --> 00:26:34,910
when she was asked that question I think

00:26:32,870 --> 00:26:36,950
for the most part you can trust it but I

00:26:34,910 --> 00:26:40,670
think you know again going back to the

00:26:36,950 --> 00:26:41,900
observability one the the automated

00:26:40,670 --> 00:26:43,820
system is gonna catch it if you're not

00:26:41,900 --> 00:26:45,680
sending it the right metrics which I

00:26:43,820 --> 00:26:47,000
would in a lot like I said a lot of

00:26:45,680 --> 00:26:48,860
enterprises that's probably the case

00:26:47,000 --> 00:26:50,570
they're not actually observing

00:26:48,860 --> 00:26:52,160
everything they need to be and then the

00:26:50,570 --> 00:26:55,070
second thing is your application changes

00:26:52,160 --> 00:26:57,890
over time so what you might have thought

00:26:55,070 --> 00:26:59,720
was an important metric no longer

00:26:57,890 --> 00:27:02,300
becomes important or there may be

00:26:59,720 --> 00:27:04,850
another particular metric or attribute

00:27:02,300 --> 00:27:05,990
of your application that does deem it a

00:27:04,850 --> 00:27:07,990
good or a bad thing because it's not

00:27:05,990 --> 00:27:10,310
just about system level metrics about

00:27:07,990 --> 00:27:12,560
what is the customer experiencing with

00:27:10,310 --> 00:27:14,150
your piece of software and that metric

00:27:12,560 --> 00:27:16,070
isn't always tied to a system level

00:27:14,150 --> 00:27:17,600
metric so it's important to kind of

00:27:16,070 --> 00:27:20,210
revisit the the metrics you're looking

00:27:17,600 --> 00:27:22,130
at revisit how your application is

00:27:20,210 --> 00:27:24,290
changing over time and if you don't do

00:27:22,130 --> 00:27:26,230
that then there may and there will be

00:27:24,290 --> 00:27:29,030
cases in which the canary won't catch it

00:27:26,230 --> 00:27:32,360
so it's not you know there are

00:27:29,030 --> 00:27:34,880
opportunity for it to fail so from our

00:27:32,360 --> 00:27:37,910
experience what we've noticed is that if

00:27:34,880 --> 00:27:40,160
you if you look at the good the bad and

00:27:37,910 --> 00:27:43,730
unsure if you sort of look at those

00:27:40,160 --> 00:27:46,310
three zones a lot of times developers

00:27:43,730 --> 00:27:49,040
would say okay yeah that's good and when

00:27:46,310 --> 00:27:52,160
it's clearly bad it's bad this is zone

00:27:49,040 --> 00:27:54,200
in which we are not sure I think I think

00:27:52,160 --> 00:27:56,390
if we just develop a framework like that

00:27:54,200 --> 00:28:00,100
and you start saying okay this is the

00:27:56,390 --> 00:28:04,040
range then you start building a trust

00:28:00,100 --> 00:28:06,020
the second part of the answer is if you

00:28:04,040 --> 00:28:09,710
think about an application that's

00:28:06,020 --> 00:28:11,840
changing and when you think about like

00:28:09,710 --> 00:28:14,930
an average an advanced sort of a

00:28:11,840 --> 00:28:17,870
customer of ours collects about two to

00:28:14,930 --> 00:28:21,410
three thousand matrix service so so a

00:28:17,870 --> 00:28:23,780
human being cannot process or even

00:28:21,410 --> 00:28:25,550
comprehend so many metrics and

00:28:23,780 --> 00:28:28,160
especially when an application is

00:28:25,550 --> 00:28:28,519
changing and yes but humans have great

00:28:28,160 --> 00:28:31,099
into

00:28:28,519 --> 00:28:33,679
and domain knowledge which you know a

00:28:31,099 --> 00:28:35,269
system like ours would like to learn

00:28:33,679 --> 00:28:36,409
through rules that they can import as

00:28:35,269 --> 00:28:39,799
well as some amount of machine learning

00:28:36,409 --> 00:28:41,779
and that's where we cannot quite compete

00:28:39,799 --> 00:28:43,190
with with a human being but then there's

00:28:41,779 --> 00:28:45,320
also subjected to biases like

00:28:43,190 --> 00:28:46,969
confirmation bias and false alarms and

00:28:45,320 --> 00:28:49,219
things like that which are avoided

00:28:46,969 --> 00:28:52,339
that's what we've seen practically but I

00:28:49,219 --> 00:28:54,830
hope that like what he said I think that

00:28:52,339 --> 00:28:56,779
they should start building a trust and

00:28:54,830 --> 00:28:59,419
and that's sort of what pops alex is

00:28:56,779 --> 00:29:02,869
trying to do after all it's just math

00:28:59,419 --> 00:29:06,429
right I think it does take takes time

00:29:02,869 --> 00:29:06,429
for people to build trust on the system

00:29:10,880 --> 00:29:16,310
[Laughter]

00:29:17,229 --> 00:29:22,309
for the canary what is your strategy

00:29:19,700 --> 00:29:23,989
when it fails so do you in place and

00:29:22,309 --> 00:29:25,339
update and enhance and fix or when you

00:29:23,989 --> 00:29:31,279
decide to back out and do something

00:29:25,339 --> 00:29:33,859
different or how do you handle that one

00:29:31,279 --> 00:29:36,349
thing that I think Chris yesterday

00:29:33,859 --> 00:29:39,379
talked about is when a canary analysis

00:29:36,349 --> 00:29:43,570
fails typically sometimes we give the

00:29:39,379 --> 00:29:46,999
human being you know the ability to

00:29:43,570 --> 00:29:50,779
basically a manual judge is inserted so

00:29:46,999 --> 00:29:52,579
they can sort of do that and based on

00:29:50,779 --> 00:29:55,389
the organization they can decide to roll

00:29:52,579 --> 00:29:57,619
back I mean Optimax when we say

00:29:55,389 --> 00:30:03,019
automated analysis we don't restrict it

00:29:57,619 --> 00:30:07,159
to just cannery when all of that is to

00:30:03,019 --> 00:30:08,809
us so based on your deploy strategy then

00:30:07,159 --> 00:30:12,769
it fails at a certain stage you might

00:30:08,809 --> 00:30:18,579
want to take a which is usually

00:30:12,769 --> 00:30:20,749
automated or a human can yeah I think

00:30:18,579 --> 00:30:23,690
Google's from the position of the canary

00:30:20,749 --> 00:30:26,119
analysis system Google's position is

00:30:23,690 --> 00:30:27,639
that it's the caller's responsibility to

00:30:26,119 --> 00:30:30,049
decide what to do with that verdict

00:30:27,639 --> 00:30:32,059
Google Google system only gives a

00:30:30,049 --> 00:30:34,179
pass/fail or we're not sure and the

00:30:32,059 --> 00:30:36,499
caller can decide what to do typically

00:30:34,179 --> 00:30:38,869
well I can't say what today it's

00:30:36,499 --> 00:30:39,950
probably fit you know every answer you

00:30:38,869 --> 00:30:42,999
could think I was probably taken on that

00:30:39,950 --> 00:30:42,999
action on that verdict

00:30:51,900 --> 00:31:05,290
now I was the now do you mean like when

00:31:02,170 --> 00:31:06,760
a canary system returns a failure from

00:31:05,290 --> 00:31:09,460
the like it's not good or when the

00:31:06,760 --> 00:31:12,610
canary novel system fails itself not

00:31:09,460 --> 00:31:14,170
good okay then then much like Google you

00:31:12,610 --> 00:31:17,890
know it's user configurable for us at

00:31:14,170 --> 00:31:20,440
Netflix you know users can go into a

00:31:17,890 --> 00:31:22,270
manual judgment stage if you know if the

00:31:20,440 --> 00:31:24,370
passes you know continue with the

00:31:22,270 --> 00:31:26,230
pipeline rollout into production if it's

00:31:24,370 --> 00:31:27,820
in an uncertain zone maybe we present to

00:31:26,230 --> 00:31:30,040
the user you know you need to go in and

00:31:27,820 --> 00:31:32,320
manually determine what to do with this

00:31:30,040 --> 00:31:34,120
and most times and when we enter in a

00:31:32,320 --> 00:31:36,360
failure scenario the pipelines

00:31:34,120 --> 00:31:38,530
terminated cleanup happens and so on

00:31:36,360 --> 00:31:40,240
from the spinnaker point of view it's

00:31:38,530 --> 00:31:41,590
just another sort of tool in the toolbox

00:31:40,240 --> 00:31:43,180
and you can use it to build your your

00:31:41,590 --> 00:31:45,100
workflows that makes sense for you and

00:31:43,180 --> 00:31:46,540
it's I think Isaac pretty much touched

00:31:45,100 --> 00:31:48,790
on this earlier that we finally now have

00:31:46,540 --> 00:31:51,010
all the tools to build like discipline

00:31:48,790 --> 00:31:52,120
rollout strategies including Canaries

00:31:51,010 --> 00:31:53,980
whether they're automated or some

00:31:52,120 --> 00:31:56,800
combination of automated and manual and

00:31:53,980 --> 00:31:58,000
it's up to the team and I hope that all

00:31:56,800 --> 00:31:59,230
the stuff gets to a point that it's not

00:31:58,000 --> 00:32:00,850
just up to a team but they can learn

00:31:59,230 --> 00:32:02,200
from what other teams have done because

00:32:00,850 --> 00:32:03,970
if you have a service that fits a

00:32:02,200 --> 00:32:05,650
certain shape you shouldn't have to find

00:32:03,970 --> 00:32:09,810
somebody and say how long do you canary

00:32:05,650 --> 00:32:09,810
for or what air pipe lines look like

00:32:14,820 --> 00:32:23,290
yeah so you keep talking about Canarian

00:32:21,370 --> 00:32:26,380
live traffic do you have any experience

00:32:23,290 --> 00:32:37,930
or thoughts on doing a canary against

00:32:26,380 --> 00:32:41,740
like a load test yes I believe it was in

00:32:37,930 --> 00:32:43,300
Andy's keynote in which he talked about

00:32:41,740 --> 00:32:46,360
a framework we have at Netflix called

00:32:43,300 --> 00:32:48,370
citrus which is about kind of squeezing

00:32:46,360 --> 00:32:50,230
or load testing instances and in the

00:32:48,370 --> 00:32:52,030
past we've talked about using a tool or

00:32:50,230 --> 00:32:53,500
technique like load testing or the

00:32:52,030 --> 00:32:55,240
squeezing type framework to either do

00:32:53,500 --> 00:32:57,070
types of validation on canary

00:32:55,240 --> 00:33:01,539
or to use a canary analysis type of

00:32:57,070 --> 00:33:03,130
process to validate that the the squeeze

00:33:01,539 --> 00:33:05,470
testing is is performing in a certain

00:33:03,130 --> 00:33:07,149
manner or how does this instance or this

00:33:05,470 --> 00:33:09,549
application when squeezed or under load

00:33:07,149 --> 00:33:10,450
differ from say stuff in production and

00:33:09,549 --> 00:33:11,710
so on

00:33:10,450 --> 00:33:13,899
we thought about but we haven't

00:33:11,710 --> 00:33:22,990
necessarily gone beyond the thought

00:33:13,899 --> 00:33:25,690
process yet we have direct experience in

00:33:22,990 --> 00:33:28,450
terms of so the way we think about is

00:33:25,690 --> 00:33:30,490
there's a data exhaust coming out from

00:33:28,450 --> 00:33:31,870
you know in a load testing environment

00:33:30,490 --> 00:33:33,549
or integration testing environment there

00:33:31,870 --> 00:33:35,440
are there customers that actually try

00:33:33,549 --> 00:33:38,200
when you have micro-services doing

00:33:35,440 --> 00:33:41,320
integration testing so we get the data

00:33:38,200 --> 00:33:43,059
exhaust and analyze it I mean there's a

00:33:41,320 --> 00:33:45,340
certain normalization that has to happen

00:33:43,059 --> 00:33:47,500
in terms of because the load test ran

00:33:45,340 --> 00:33:49,510
yesterday and today it's running this

00:33:47,500 --> 00:33:51,909
there's differences in environment and

00:33:49,510 --> 00:33:53,289
so on we need to normalize but pretty

00:33:51,909 --> 00:33:56,620
straightforward we could we could

00:33:53,289 --> 00:33:57,580
especially in the load stayed it's it's

00:33:56,620 --> 00:34:12,730
pretty straightforward

00:33:57,580 --> 00:34:15,669
we've had good success there I do I will

00:34:12,730 --> 00:34:17,770
bring it or throw it's asking for a

00:34:15,669 --> 00:34:23,740
gmail s re friend who may or may not

00:34:17,770 --> 00:34:25,659
have had an outage this morning so we're

00:34:23,740 --> 00:34:27,580
talking here about Canarian services

00:34:25,659 --> 00:34:30,159
that were rolling out today like your

00:34:27,580 --> 00:34:32,429
service with your canary analysis have

00:34:30,159 --> 00:34:34,690
you given any thought in Canarian or

00:34:32,429 --> 00:34:36,700
analyzing your clients upstream

00:34:34,690 --> 00:34:38,470
downstream usage of your service take

00:34:36,700 --> 00:34:39,609
for example a deep back-end that serves

00:34:38,470 --> 00:34:42,159
100 million QPS

00:34:39,609 --> 00:34:43,690
and a front-end that is rolling out that

00:34:42,159 --> 00:34:45,609
now as a regression you'll catch that

00:34:43,690 --> 00:34:47,379
but what if the back-end is rolling out

00:34:45,609 --> 00:34:49,510
that has a regression for your front-end

00:34:47,379 --> 00:34:51,280
and they're not testing that because all

00:34:49,510 --> 00:35:03,780
of their tests fail then your noise to

00:34:51,280 --> 00:35:03,780
them we're working on is good luck

00:35:08,280 --> 00:35:15,250
thank you this is kind of off topic but

00:35:12,369 --> 00:35:17,410
we we have spent a lot of time

00:35:15,250 --> 00:35:19,420
internally in Thomson Reuters talking

00:35:17,410 --> 00:35:29,760
about the difference between red black

00:35:19,420 --> 00:35:34,420
and blue green it's officially red black

00:35:29,760 --> 00:35:56,650
it's always red and if any of you

00:35:34,420 --> 00:36:09,550
disagree that's right well let me tell

00:35:56,650 --> 00:36:11,950
you Stephen manual intervention where

00:36:09,550 --> 00:36:15,579
you have to view and see how over the

00:36:11,950 --> 00:36:17,770
last time so you can they're their

00:36:15,579 --> 00:36:19,540
thresholds right so I say hey it almost

00:36:17,770 --> 00:36:23,200
met the requirements you push it through

00:36:19,540 --> 00:36:24,970
is there any thought around looking at

00:36:23,200 --> 00:36:26,710
previous Canaries because eventually

00:36:24,970 --> 00:36:28,270
you'll be ending up in this degrading

00:36:26,710 --> 00:36:29,560
canary that's always getting worse in

00:36:28,270 --> 00:36:33,160
the last one but it's just somewhat

00:36:29,560 --> 00:36:35,500
acceptable is that like any thoughts

00:36:33,160 --> 00:36:38,589
around that or like how that kind of

00:36:35,500 --> 00:36:42,160
handled it like using as a metric or our

00:36:38,589 --> 00:36:43,810
system does that to a degree we do look

00:36:42,160 --> 00:36:45,849
at historical evaluations to see how

00:36:43,810 --> 00:36:48,329
they perform but we don't look at the

00:36:45,849 --> 00:36:51,310
level of badness it's either bad or good

00:36:48,329 --> 00:36:52,510
but that what you've mentioned is

00:36:51,310 --> 00:36:54,099
something we have considered because it

00:36:52,510 --> 00:36:56,079
does make a lot of sense to look at how

00:36:54,099 --> 00:36:57,550
is it historically performed to make

00:36:56,079 --> 00:36:59,980
sure we don't have this slope this

00:36:57,550 --> 00:37:03,339
gradual slope the other thing too in

00:36:59,980 --> 00:37:05,530
most cases what you know when when you

00:37:03,339 --> 00:37:07,150
have alerts and metrics or monitors

00:37:05,530 --> 00:37:09,400
inside of something like data dog what

00:37:07,150 --> 00:37:12,040
typically that is is the bounds there so

00:37:09,400 --> 00:37:13,780
while the canary may degrade what you

00:37:12,040 --> 00:37:16,000
should be able to do is if it starts to

00:37:13,780 --> 00:37:17,560
deploy that should be caught fairly

00:37:16,000 --> 00:37:19,900
early on but your standard monitoring

00:37:17,560 --> 00:37:20,650
and alerting if you have bounds there so

00:37:19,900 --> 00:37:21,640
typically there's an

00:37:20,650 --> 00:37:24,309
other system to kind of touch that

00:37:21,640 --> 00:37:25,960
although I agree it would be better to

00:37:24,309 --> 00:37:35,710
be able to kind of be analyzed during

00:37:25,960 --> 00:37:37,960
the canary phase are there any kinds of

00:37:35,710 --> 00:37:39,819
anti patterns or mistakes that are

00:37:37,960 --> 00:37:43,410
commonly made by organizations that are

00:37:39,819 --> 00:37:46,240
first starting to do canary analysis

00:37:43,410 --> 00:37:49,180
I'll go I have a good use case on this

00:37:46,240 --> 00:37:53,020
one which is there's certain

00:37:49,180 --> 00:37:55,029
applications that have unequally

00:37:53,020 --> 00:37:56,589
distributed load meaning like if I shoot

00:37:55,029 --> 00:37:58,529
a request at this server and I shoot one

00:37:56,589 --> 00:38:01,779
request at this server this will behave

00:37:58,529 --> 00:38:03,579
much more erratic than this one and then

00:38:01,779 --> 00:38:06,809
being able to compare those becomes very

00:38:03,579 --> 00:38:08,859
very difficult now what that means is

00:38:06,809 --> 00:38:11,319
maybe the application needs to be

00:38:08,859 --> 00:38:13,150
reacted but when you're looking at large

00:38:11,319 --> 00:38:16,960
enterprises who have a lot of legacy

00:38:13,150 --> 00:38:21,369
applications you see a lot of that kind

00:38:16,960 --> 00:38:23,829
of erratic kind of behavior now new new

00:38:21,369 --> 00:38:25,480
kind of micro service architectures try

00:38:23,829 --> 00:38:28,869
and try to smooth that over and try to

00:38:25,480 --> 00:38:32,980
have a a or a more kind of distributed

00:38:28,869 --> 00:38:34,569
load so it's hard to apply that so in

00:38:32,980 --> 00:38:36,490
some cases you're gonna want to actually

00:38:34,569 --> 00:38:40,750
fix the application before you just kind

00:38:36,490 --> 00:38:44,589
of slap canary on top of it another

00:38:40,750 --> 00:38:48,339
place where I think beginners make a

00:38:44,589 --> 00:38:51,670
mistake are they try and use too large

00:38:48,339 --> 00:38:52,630
of a canary deployment you know they

00:38:51,670 --> 00:38:54,880
think that it's going to give better

00:38:52,630 --> 00:38:56,470
signal and data and that's true but you

00:38:54,880 --> 00:38:58,450
know the idea of canary analysis is to

00:38:56,470 --> 00:38:59,799
mitigate the risk and if your canary

00:38:58,450 --> 00:39:02,440
deployment is 50 percent of your

00:38:59,799 --> 00:39:08,529
production cluster you might as well do

00:39:02,440 --> 00:39:10,510
a red black and so then the natural

00:39:08,529 --> 00:39:13,289
question is well how big should carry

00:39:10,510 --> 00:39:15,490
cluster be and the answer is it depends

00:39:13,289 --> 00:39:17,890
but that's that's another mistake we've

00:39:15,490 --> 00:39:20,079
seen in a sense of early adopters and

00:39:17,890 --> 00:39:26,380
people trying to Canaries too large of a

00:39:20,079 --> 00:39:29,260
canary deployment throwing every metric

00:39:26,380 --> 00:39:30,849
you can think of at the system one of

00:39:29,260 --> 00:39:32,680
the metrics at Google systems export is

00:39:30,849 --> 00:39:33,849
the timestamp of the build if you put

00:39:32,680 --> 00:39:34,350
that in the carrying out system you're

00:39:33,849 --> 00:39:39,630
going to get it

00:39:34,350 --> 00:39:41,250
I think this goes back to like some a

00:39:39,630 --> 00:39:43,050
previous comment make sure you really

00:39:41,250 --> 00:39:44,430
curate what you're putting in the carbon

00:39:43,050 --> 00:39:46,380
in garbage out if you don't have good

00:39:44,430 --> 00:39:48,060
metrics and they don't provide a good

00:39:46,380 --> 00:40:05,580
signal about the goodness of your canary

00:39:48,060 --> 00:40:09,380
it's probably not worth evaluating what

00:40:05,580 --> 00:40:09,380
happens when your baseline isn't healthy

00:40:09,770 --> 00:40:19,470
doesn't happen world's perfect it's a

00:40:15,870 --> 00:40:21,870
fascinating question because we see it

00:40:19,470 --> 00:40:23,310
frequently to be honest you know we are

00:40:21,870 --> 00:40:25,700
in a virtualized environments and

00:40:23,310 --> 00:40:27,840
sometimes you do get bad servers and

00:40:25,700 --> 00:40:29,430
it's a very hard problem to solve

00:40:27,840 --> 00:40:31,590
because we assume the baselines are gold

00:40:29,430 --> 00:40:32,910
standard and you know we assume that

00:40:31,590 --> 00:40:35,460
canary we're comparing the canary

00:40:32,910 --> 00:40:36,960
against a baseline so we're looking at

00:40:35,460 --> 00:40:39,510
ways to try and identify whether or not

00:40:36,960 --> 00:40:41,850
our baseline is actually healthy or how

00:40:39,510 --> 00:40:43,590
comparable to say production it is or if

00:40:41,850 --> 00:40:45,270
there are the say outlying instances in

00:40:43,590 --> 00:41:01,620
that in that group but it does happen

00:40:45,270 --> 00:41:04,310
and then we fail the canary so what's

00:41:01,620 --> 00:41:07,770
the future of the canary analysis

00:41:04,310 --> 00:41:12,260
framework to whatever where do you guys

00:41:07,770 --> 00:41:12,260
see it going in the next few years also

00:41:12,290 --> 00:41:27,000
sentience all aware the way we think

00:41:23,370 --> 00:41:30,300
about the future of canary analysis I

00:41:27,000 --> 00:41:33,570
think is to start with doing a canary

00:41:30,300 --> 00:41:36,810
then probably expand to doing blue green

00:41:33,570 --> 00:41:38,190
rolling update and probably start I mean

00:41:36,810 --> 00:41:39,870
we already have customers that are

00:41:38,190 --> 00:41:41,760
asking hey can I do it in low test

00:41:39,870 --> 00:41:45,600
integration test and Chris has already

00:41:41,760 --> 00:41:47,650
talked about doing deploy or Canaries so

00:41:45,600 --> 00:41:51,360
I think at

00:41:47,650 --> 00:41:53,500
point it will be a unified data layer

00:41:51,360 --> 00:41:55,780
analytics layer that connects all the

00:41:53,500 --> 00:41:58,480
stages when we also have customers that

00:41:55,780 --> 00:42:02,980
say my sonar call my my static code

00:41:58,480 --> 00:42:04,870
analysis is going to give me input so so

00:42:02,980 --> 00:42:07,900
essentially there's a layer that will

00:42:04,870 --> 00:42:10,570
connect all from the the code the gate

00:42:07,900 --> 00:42:12,730
sonar cubes to all the stages into

00:42:10,570 --> 00:42:15,100
production I think that's the way I see

00:42:12,730 --> 00:42:17,080
the whole the data analysis can

00:42:15,100 --> 00:42:19,300
reanalysis layer sort of taking but

00:42:17,080 --> 00:42:22,480
that's obviously and eventually it's

00:42:19,300 --> 00:42:25,030
probably ops s core the application will

00:42:22,480 --> 00:42:26,920
have some operational logic within it

00:42:25,030 --> 00:42:31,750
which will interact with the system

00:42:26,920 --> 00:42:33,280
that's you know I I don't think Chris is

00:42:31,750 --> 00:42:35,950
being facetious in his statement like

00:42:33,280 --> 00:42:38,920
one of the goals of Google's Canary

00:42:35,950 --> 00:42:40,480
system is it's you have to be because we

00:42:38,920 --> 00:42:42,250
have a configuration system people want

00:42:40,480 --> 00:42:43,510
to use it but unfortunately to configure

00:42:42,250 --> 00:42:45,910
it correct that you'd have to have be a

00:42:43,510 --> 00:42:48,790
statistician and a lot of people aren't

00:42:45,910 --> 00:42:51,490
and they end up with bad configs so we

00:42:48,790 --> 00:42:53,800
already have a lot of signals about what

00:42:51,490 --> 00:42:55,000
fusers are what the operator cares about

00:42:53,800 --> 00:42:56,920
for the service right they have alerts

00:42:55,000 --> 00:42:58,450
probably about what metrics they care

00:42:56,920 --> 00:43:00,550
about we should just look at those and

00:42:58,450 --> 00:43:02,050
see how they're doing they may have an

00:43:00,550 --> 00:43:03,370
SLA defined somewhere that in some

00:43:02,050 --> 00:43:05,830
system we can go see how they're doing

00:43:03,370 --> 00:43:07,060
against or SLA there are general truths

00:43:05,830 --> 00:43:08,910
like it shouldn't crash it shouldn't

00:43:07,060 --> 00:43:12,430
return more errors we can look at those

00:43:08,910 --> 00:43:13,810
so our goal is basically like less user

00:43:12,430 --> 00:43:16,810
configuration by doing more

00:43:13,810 --> 00:43:20,080
automatically and obviously you know

00:43:16,810 --> 00:43:21,190
machine learning like we you the system

00:43:20,080 --> 00:43:23,650
should just figure out when things have

00:43:21,190 --> 00:43:25,000
gone badly maybe even through some more

00:43:23,650 --> 00:43:30,670
automatic detection of metrics so we

00:43:25,000 --> 00:43:33,520
aren't looking at explicitly I think

00:43:30,670 --> 00:43:36,040
with our work around Cayenne it's

00:43:33,520 --> 00:43:38,170
building a community and to kind of

00:43:36,040 --> 00:43:40,900
create you know canary analysis of the

00:43:38,170 --> 00:43:43,000
first class citizen in spinnaker and you

00:43:40,900 --> 00:43:44,020
know sharing that knowledge and you know

00:43:43,000 --> 00:43:46,090
again creating that community for

00:43:44,020 --> 00:43:47,020
everyone else to leverage and use and

00:43:46,090 --> 00:43:48,070
then getting the feedback from the

00:43:47,020 --> 00:43:53,020
community about how we can make that

00:43:48,070 --> 00:43:54,220
better is I think we're for a road map

00:43:53,020 --> 00:43:58,140
perspective where we want to go with

00:43:54,220 --> 00:43:58,140
with canary analysis at Netflix as well

00:43:59,300 --> 00:44:06,860
I think obviously everything you guys

00:44:03,350 --> 00:44:11,300
said is definitely correct and right on

00:44:06,860 --> 00:44:14,630
I think though with spinnaker

00:44:11,300 --> 00:44:17,480
there's just something bigger happening

00:44:14,630 --> 00:44:18,590
it's all part about just the application

00:44:17,480 --> 00:44:21,440
developer experience and getting

00:44:18,590 --> 00:44:24,770
something into production so canary will

00:44:21,440 --> 00:44:28,280
start to fill in gaps and start to fill

00:44:24,770 --> 00:44:30,980
in where things aren't automated today

00:44:28,280 --> 00:44:32,060
or it is difficult so and then those

00:44:30,980 --> 00:44:33,620
gaps you guys have mentioned it's like

00:44:32,060 --> 00:44:36,920
machine learning everybody's not a

00:44:33,620 --> 00:44:39,590
statistician just getting to this full

00:44:36,920 --> 00:44:41,930
automation and canarian will fill in

00:44:39,590 --> 00:44:44,150
that role I mean there was a time that

00:44:41,930 --> 00:44:46,490
like automated tests were ubiquitous and

00:44:44,150 --> 00:44:47,870
I think we're headed in the direction of

00:44:46,490 --> 00:44:49,820
automated canary analysis being

00:44:47,870 --> 00:44:52,730
ubiquitous we just have to make it easy

00:44:49,820 --> 00:44:54,590
we're getting there and you touched on

00:44:52,730 --> 00:44:56,480
that yes yesterday a bit in your talk

00:44:54,590 --> 00:44:59,120
which is like not just canary the

00:44:56,480 --> 00:45:00,950
application but the configuration and

00:44:59,120 --> 00:45:03,890
and all that and infrastructure Network

00:45:00,950 --> 00:45:06,380
changes it's canary a lot of different

00:45:03,890 --> 00:45:10,100
things not just is this service good or

00:45:06,380 --> 00:45:12,370
not so I think you know Andy touched on

00:45:10,100 --> 00:45:14,690
it as well it's all about delivery right

00:45:12,370 --> 00:45:17,180
and canary will be a huge part of that

00:45:14,690 --> 00:45:19,840
that story and spinnaker story we

00:45:17,180 --> 00:45:19,840
continue to move on

00:45:30,490 --> 00:45:39,290
so thinking about the Canaries some of

00:45:36,260 --> 00:45:41,930
the most valuable data that we would

00:45:39,290 --> 00:45:45,440
like to have is hard to attribute to the

00:45:41,930 --> 00:45:47,540
canary fleet I mean you mentioned even

00:45:45,440 --> 00:45:50,770
the dream of your network configuration

00:45:47,540 --> 00:45:53,360
changing unless you know which

00:45:50,770 --> 00:45:56,000
downstream impacted things went through

00:45:53,360 --> 00:45:57,620
the change network configuration you

00:45:56,000 --> 00:46:01,160
don't know what to look at and even in

00:45:57,620 --> 00:46:04,360
similar common cases of application

00:46:01,160 --> 00:46:07,580
changes and you are looking at impact on

00:46:04,360 --> 00:46:11,210
downstream clients even if it's somewhat

00:46:07,580 --> 00:46:14,060
like Netflix like yes theoretically you

00:46:11,210 --> 00:46:16,070
should know which clients were directed

00:46:14,060 --> 00:46:18,920
via Zul into there so if you have really

00:46:16,070 --> 00:46:20,810
good tracing maybe you have it but most

00:46:18,920 --> 00:46:24,620
people don't have that good of tracing

00:46:20,810 --> 00:46:27,440
and I suspect that even companies with a

00:46:24,620 --> 00:46:32,530
larger team on this also run into limits

00:46:27,440 --> 00:46:35,660
of their tracing so how do you deal with

00:46:32,530 --> 00:46:38,930
limited visibility and attribute ability

00:46:35,660 --> 00:46:41,620
of downstream issues this delayed repeat

00:46:38,930 --> 00:46:41,620
is really strange

00:46:54,520 --> 00:47:06,220
we have Zul it's a problem if we only

00:47:03,410 --> 00:47:08,120
think of canary and clients and

00:47:06,220 --> 00:47:10,160
something we've been thinking about more

00:47:08,120 --> 00:47:11,630
and more you know within a carry canary

00:47:10,160 --> 00:47:14,930
of all the canary but my beginning some

00:47:11,630 --> 00:47:17,780
canary traffic you saw up streaming down

00:47:14,930 --> 00:47:19,010
streams and also at the same time some

00:47:17,780 --> 00:47:20,540
of those live stream is now series might

00:47:19,010 --> 00:47:22,510
be carrying did we make it easy on

00:47:20,540 --> 00:47:25,190
spinnaker and that's what really

00:47:22,510 --> 00:47:28,580
confusion all is my canary taking canary

00:47:25,190 --> 00:47:30,650
traffic from an upstream we don't have a

00:47:28,580 --> 00:47:32,740
solution to that yet you know the idea

00:47:30,650 --> 00:47:36,230
of you know having these nice you know

00:47:32,740 --> 00:47:38,200
segregated deployments is is great but

00:47:36,230 --> 00:47:40,450
when you know what velocity Ram

00:47:38,200 --> 00:47:41,950
more people at canary there's nothing to

00:47:40,450 --> 00:47:43,300
say that our upstream that we're now

00:47:41,950 --> 00:47:46,570
getting traffic in our canary as a

00:47:43,300 --> 00:47:47,920
canary as well but we do within Zul we

00:47:46,570 --> 00:47:49,780
do try and do things like sticky

00:47:47,920 --> 00:47:52,170
Canaries where a certain user traffic

00:47:49,780 --> 00:47:55,060
coming in through the front door Netflix

00:47:52,170 --> 00:47:56,650
will be annotated all the way through

00:47:55,060 --> 00:47:58,510
our infrastructure that you know this is

00:47:56,650 --> 00:48:00,250
going to go to a canary or this is

00:47:58,510 --> 00:48:01,930
canary traffic where this is gonna go to

00:48:00,250 --> 00:48:03,340
a baseline traffic and then the rest of

00:48:01,930 --> 00:48:06,630
our infrastructure pulls that out and is

00:48:03,340 --> 00:48:08,560
able to label it within our telemetry

00:48:06,630 --> 00:48:13,260
it's the other thing I would add to that

00:48:08,560 --> 00:48:15,610
is this really it may come down to

00:48:13,260 --> 00:48:18,430
building defensibility into your

00:48:15,610 --> 00:48:20,380
application such that instead of going

00:48:18,430 --> 00:48:22,480
what will happen if this fail assume

00:48:20,380 --> 00:48:24,670
that it will fail and what do you do

00:48:22,480 --> 00:48:26,110
then with the downstream service how

00:48:24,670 --> 00:48:29,170
will your application behave if the

00:48:26,110 --> 00:48:30,310
downstream service is to fail and so if

00:48:29,170 --> 00:48:32,080
there's a feed service that you're

00:48:30,310 --> 00:48:33,880
depending on and they fails well maybe

00:48:32,080 --> 00:48:36,210
you have a cache or maybe you have

00:48:33,880 --> 00:48:38,890
something that's recently saved so

00:48:36,210 --> 00:48:42,760
that's what I've seen most people kind

00:48:38,890 --> 00:48:46,090
of deal with that instead of waiting for

00:48:42,760 --> 00:49:04,660
it to fail just assume that it will and

00:48:46,090 --> 00:49:06,820
then what are you something that I think

00:49:04,660 --> 00:49:08,650
if people kind of understood your

00:49:06,820 --> 00:49:11,290
question it's very important and I'd

00:49:08,650 --> 00:49:13,990
give a case with respect to Netflix with

00:49:11,290 --> 00:49:17,590
some of our devices when we would a CA

00:49:13,990 --> 00:49:19,660
those new releases the function in which

00:49:17,590 --> 00:49:21,370
to choose which devices would be a CA

00:49:19,660 --> 00:49:24,100
was a hashing function but it turned out

00:49:21,370 --> 00:49:26,290
it always selected the same devices and

00:49:24,100 --> 00:49:29,050
so we had members that always were

00:49:26,290 --> 00:49:30,760
getting a CA now we never did but it's

00:49:29,050 --> 00:49:32,800
it's it's something to think about when

00:49:30,760 --> 00:49:34,480
you a CA you know at scale you don't

00:49:32,800 --> 00:49:36,850
want to always provide you know that

00:49:34,480 --> 00:49:38,950
terrible experience let's say it's the

00:49:36,850 --> 00:49:42,580
same poor salon you know whatever the

00:49:38,950 --> 00:49:44,050
ps/2 you know whatever California or

00:49:42,580 --> 00:49:44,800
something so it's something to think

00:49:44,050 --> 00:49:48,100
through I think it's a very good

00:49:44,800 --> 00:49:51,010
question and certainly there needs to be

00:49:48,100 --> 00:49:52,880
a lot more maturing there I challenge

00:49:51,010 --> 00:50:14,760
your arms

00:49:52,880 --> 00:50:16,500
way over there so where I'm at is that

00:50:14,760 --> 00:50:18,330
the next evolution of continuous

00:50:16,500 --> 00:50:20,280
delivery is basically separating

00:50:18,330 --> 00:50:23,010
deployment and feature launches using

00:50:20,280 --> 00:50:26,220
your future toggle service and and I see

00:50:23,010 --> 00:50:29,010
that Canaries are still relevant to the

00:50:26,220 --> 00:50:32,130
deployment but you still need to run

00:50:29,010 --> 00:50:35,700
them after a feature toggle or granules

00:50:32,130 --> 00:50:45,720
rollout strategy on the feature level do

00:50:35,700 --> 00:50:48,360
you have any thoughts on this I mean yes

00:50:45,720 --> 00:50:49,530
you should do it we do it in tight

00:50:48,360 --> 00:50:51,660
Google we have a separate feature

00:50:49,530 --> 00:50:53,640
service it calls into our canary service

00:50:51,660 --> 00:50:57,000
when it makes a change it makes a change

00:50:53,640 --> 00:50:59,730
to a small set of servers and we canary

00:50:57,000 --> 00:51:00,690
that so totally possible that's one of

00:50:59,730 --> 00:51:03,300
the things I like about these services

00:51:00,690 --> 00:51:05,250
is there they're very extensible right

00:51:03,300 --> 00:51:06,870
like because their data is basically

00:51:05,250 --> 00:51:08,850
just a stream of monitoring data you can

00:51:06,870 --> 00:51:11,010
use them to do a lot of things and so

00:51:08,850 --> 00:51:12,690
you can set up the callers that citizen

00:51:11,010 --> 00:51:13,380
understands the process this concept of

00:51:12,690 --> 00:51:14,850
a canary

00:51:13,380 --> 00:51:17,550
you can introduce automatic canary

00:51:14,850 --> 00:51:18,930
analysis and we do something very

00:51:17,550 --> 00:51:20,190
similar in Netflix where we have the

00:51:18,930 --> 00:51:22,260
idea of fast properties which are

00:51:20,190 --> 00:51:24,750
dynamic feature flags and we have these

00:51:22,260 --> 00:51:26,460
pipelines that our developers can use to

00:51:24,750 --> 00:51:29,340
canary these feature flags so it's not

00:51:26,460 --> 00:51:31,380
just used for we don't just use Kerry

00:51:29,340 --> 00:51:32,940
analysis for soft server deployments we

00:51:31,380 --> 00:51:34,860
do it for like developer Canaries fast

00:51:32,940 --> 00:51:37,410
properties these feature flags much like

00:51:34,860 --> 00:51:40,290
Google and again it's just data and if

00:51:37,410 --> 00:51:42,750
you can separate the data nicely your

00:51:40,290 --> 00:51:45,840
telemetry or observability then make the

00:51:42,750 --> 00:51:49,350
problem becomes easier so the next

00:51:45,840 --> 00:51:52,140
question then is you think feature total

00:51:49,350 --> 00:51:53,640
service will become a part of spinnaker

00:51:52,140 --> 00:51:58,650
or this is something you would keep

00:51:53,640 --> 00:52:03,700
outside speaker Andy he was listening

00:51:58,650 --> 00:52:19,100
know that's best properties for us

00:52:03,700 --> 00:52:22,660
is is that okay the inside of the

00:52:19,100 --> 00:52:30,200
Netflix sort of flavored and vinegar

00:52:22,660 --> 00:52:32,630
with enough switches it shows up the

00:52:30,200 --> 00:52:46,250
last question and if you guys have more

00:52:32,630 --> 00:52:46,820
questions in trying to embrace eating my

00:52:46,250 --> 00:52:50,060
own dogs

00:52:46,820 --> 00:52:53,240
good morning weather canary analysis can

00:52:50,060 --> 00:52:59,060
be rarely implemented in deploying

00:52:53,240 --> 00:53:00,410
spinnaker itself see why not I mean many

00:52:59,060 --> 00:53:03,410
folks are using spinnaker to deploy

00:53:00,410 --> 00:53:05,000
spinnaker it's just another sort of

00:53:03,410 --> 00:53:08,380
stage you can build into your deployment

00:53:05,000 --> 00:53:11,270
workflows so I think the answer is yes

00:53:08,380 --> 00:53:13,370
so the thought process me is that in

00:53:11,270 --> 00:53:16,040
terms of feeding the data in because

00:53:13,370 --> 00:53:18,020
we're talking about pipeline I'm

00:53:16,040 --> 00:53:24,410
wondering how to actually assemble such

00:53:18,020 --> 00:53:32,240
data I don't understand the question

00:53:24,410 --> 00:53:34,160
assemblé which data yeah so there are no

00:53:32,240 --> 00:53:36,110
metrics being recorded from the new

00:53:34,160 --> 00:53:38,750
canary service we built yet it's on the

00:53:36,110 --> 00:53:39,860
list of things we need to do all of the

00:53:38,750 --> 00:53:42,080
surrounding bits that you would build

00:53:39,860 --> 00:53:44,300
into your workflows do do record with

00:53:42,080 --> 00:53:45,230
metrics into the you know we talked

00:53:44,300 --> 00:53:47,120
talked about an integration with

00:53:45,230 --> 00:53:48,710
spectator there are other things there

00:53:47,120 --> 00:53:50,870
you can use but the canary service

00:53:48,710 --> 00:53:52,280
itself and the open source the new

00:53:50,870 --> 00:53:57,590
service doesn't have any support for

00:53:52,280 --> 00:53:59,660
this yet but we'll all right you're

00:53:57,590 --> 00:54:02,250
running out of time please give a warm

00:53:59,660 --> 00:54:06,700
thank you for the panelists

00:54:02,250 --> 00:54:09,650
[Applause]

00:54:06,700 --> 00:54:11,950
thank you guys the next session is right

00:54:09,650 --> 00:54:11,950

YouTube URL: https://www.youtube.com/watch?v=JeAV1NBmU-Y


