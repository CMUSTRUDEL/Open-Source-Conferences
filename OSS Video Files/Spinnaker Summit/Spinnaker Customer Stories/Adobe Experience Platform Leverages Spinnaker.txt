Title: Adobe Experience Platform Leverages Spinnaker
Publication date: 2020-04-06
Playlist: Spinnaker Customer Stories
Description: 
	Learn about Adobe Experience Platformâ€™s experience using Spinnaker installed with Kubernetes. This team turned cumbersome and error-prone, script-based deployments of critical applications into a fast and easy process. The result? Better security, higher availability, and lower costs. Read more here: https://medium.com/adobetech/experiences-with-spinnaker-on-adobe-experience-platform-bae6cf351f34
Captions: 
	00:00:02,929 --> 00:00:09,959
Hey can you hear me okay hi I'm Dan

00:00:07,589 --> 00:00:12,029
Popescu I'm an SRE in Adobe and I'm

00:00:09,959 --> 00:00:15,209
joined today by Constantin morado a

00:00:12,029 --> 00:00:18,210
colleague of mine and we're gonna tackle

00:00:15,209 --> 00:00:21,600
the topic of deploying real-time apps on

00:00:18,210 --> 00:00:27,000
thousands of servers with no headaches

00:00:21,600 --> 00:00:29,910
let's see a bit of context we work for

00:00:27,000 --> 00:00:31,949
Adobe audience manager which is a core

00:00:29,910 --> 00:00:35,489
component of Adobe experience cloud

00:00:31,949 --> 00:00:40,559
which allows you to create unique

00:00:35,489 --> 00:00:43,319
audience profiles and then identify

00:00:40,559 --> 00:00:45,809
segments like important segments for

00:00:43,319 --> 00:00:48,269
your audience and then use those on any

00:00:45,809 --> 00:00:52,050
digital channels so basically it allows

00:00:48,269 --> 00:00:55,399
you to understand your audience by

00:00:52,050 --> 00:00:58,229
combining data from multiple sources and

00:00:55,399 --> 00:01:02,120
today we're going to focus more on the

00:00:58,229 --> 00:01:07,259
edge component which is responsible for

00:01:02,120 --> 00:01:10,920
real-time data manipulation yeah so

00:01:07,259 --> 00:01:14,159
let's move forward we've talked about

00:01:10,920 --> 00:01:18,289
the topic it tackles the deployment part

00:01:14,159 --> 00:01:22,590
aspect of real-time applications but we

00:01:18,289 --> 00:01:24,840
had to overcome a lot of challenges to

00:01:22,590 --> 00:01:29,100
be able to have an easy-to-use

00:01:24,840 --> 00:01:32,609
deployment platform while transitioning

00:01:29,100 --> 00:01:35,159
to a unified on-call schema so in the

00:01:32,609 --> 00:01:36,719
past we used to have a series performing

00:01:35,159 --> 00:01:39,539
all sorts of like most of the

00:01:36,719 --> 00:01:41,670
operational tests but now we wanted to

00:01:39,539 --> 00:01:44,670
also involve the engineering teams but

00:01:41,670 --> 00:01:47,880
they had to have an easy-to-use platform

00:01:44,670 --> 00:01:51,329
to just jump right into the deployment

00:01:47,880 --> 00:01:53,070
aspect of the applications what we also

00:01:51,329 --> 00:01:57,509
wanted to reduce the operational burden

00:01:53,070 --> 00:01:59,429
so we want it basically easy-to-use

00:01:57,509 --> 00:02:01,920
interface that you can click and just

00:01:59,429 --> 00:02:04,020
deploy your applications on a large

00:02:01,920 --> 00:02:06,810
number of servers on multiple

00:02:04,020 --> 00:02:09,330
geographical regions and here you can

00:02:06,810 --> 00:02:13,260
see typical deployment

00:02:09,330 --> 00:02:16,920
model for pipeline in our case we were

00:02:13,260 --> 00:02:22,470
used to deploy some servers to stage

00:02:16,920 --> 00:02:26,460
environment then some canneries on the

00:02:22,470 --> 00:02:28,860
improv on multiple regions and then if

00:02:26,460 --> 00:02:31,260
everything perform a lot of validations

00:02:28,860 --> 00:02:35,280
and if everything is okay then we used

00:02:31,260 --> 00:02:39,540
to have rollout deployment window but

00:02:35,280 --> 00:02:41,850
this procedure lasted like hours four or

00:02:39,540 --> 00:02:44,280
five even more when we were talking

00:02:41,850 --> 00:02:49,860
about thousands of servers and we will

00:02:44,280 --> 00:02:53,310
see how how we fix this this issue all

00:02:49,860 --> 00:02:56,190
right so regarding the the deployment

00:02:53,310 --> 00:02:59,160
part we are concentrating more on the

00:02:56,190 --> 00:03:03,870
real time services which is basically

00:02:59,160 --> 00:03:07,709
our set of micro and macro services that

00:03:03,870 --> 00:03:09,810
we have inside audience manager these

00:03:07,709 --> 00:03:13,280
are basically web apps that receive a

00:03:09,810 --> 00:03:16,590
lot of HTTP requests from our clients

00:03:13,280 --> 00:03:19,709
for instance if you go to a given

00:03:16,590 --> 00:03:21,989
website the client might want to create

00:03:19,709 --> 00:03:24,090
a digital profile for you even if you

00:03:21,989 --> 00:03:27,000
are authenticated on or on a dedicated

00:03:24,090 --> 00:03:30,150
and to that end it will integrate with

00:03:27,000 --> 00:03:32,370
WDS manager basically have a JavaScript

00:03:30,150 --> 00:03:35,130
library if it's a website or an SDK if

00:03:32,370 --> 00:03:38,430
it's a mobile app that will make calls

00:03:35,130 --> 00:03:40,170
to our web services the main web service

00:03:38,430 --> 00:03:42,120
is the data collection service which

00:03:40,170 --> 00:03:44,970
we'll discuss a bit and see how we

00:03:42,120 --> 00:03:46,560
tackle diplomas for that series but

00:03:44,970 --> 00:03:48,930
there are a lot of other you know

00:03:46,560 --> 00:03:51,540
streaming services that we use to pass

00:03:48,930 --> 00:03:52,890
the data from the you know the edge

00:03:51,540 --> 00:03:57,690
which is the project that we are working

00:03:52,890 --> 00:04:00,600
on back to the Keystone which is the our

00:03:57,690 --> 00:04:04,680
main data center where we have this big

00:04:00,600 --> 00:04:07,980
HBase data store with a ton of MapReduce

00:04:04,680 --> 00:04:10,230
jobs on top of that and also the export

00:04:07,980 --> 00:04:12,600
part which is basically all burning data

00:04:10,230 --> 00:04:16,650
to the customer base or customers or to

00:04:12,600 --> 00:04:19,440
other parties so to sum up the H

00:04:16,650 --> 00:04:21,090
architecture is comprised of this main

00:04:19,440 --> 00:04:25,830
web app

00:04:21,090 --> 00:04:27,330
just call DCs it has multi-region

00:04:25,830 --> 00:04:31,919
deployment so basically you have it

00:04:27,330 --> 00:04:35,760
deployed on a few hundreds of servers in

00:04:31,919 --> 00:04:37,889
eight regions into play in in AWS so we

00:04:35,760 --> 00:04:40,770
tried to leverage as many services as

00:04:37,889 --> 00:04:44,160
possible from there that includes s3 for

00:04:40,770 --> 00:04:47,610
data storage also we are looking for

00:04:44,160 --> 00:04:50,910
Canisius to to stream the data and SQS

00:04:47,610 --> 00:04:54,090
for message passing and all that the

00:04:50,910 --> 00:04:57,570
application itself is quite old it has

00:04:54,090 --> 00:05:00,210
like I think 11 years so it doesn't yet

00:04:57,570 --> 00:05:02,750
have the micro service aspect of it is

00:05:00,210 --> 00:05:05,190
more more like a monolith that

00:05:02,750 --> 00:05:07,530
historical was very hard to deploy and

00:05:05,190 --> 00:05:10,200
what we did in the past maybe it might

00:05:07,530 --> 00:05:12,210
be familiar with for you some of you

00:05:10,200 --> 00:05:14,850
guys what we in the past was basically

00:05:12,210 --> 00:05:18,120
because it was so hard to deploy we

00:05:14,850 --> 00:05:20,550
basically delayed the deployment part so

00:05:18,120 --> 00:05:23,789
we deploy like every month every one

00:05:20,550 --> 00:05:25,830
month or two months but that meant we

00:05:23,789 --> 00:05:27,900
were introducing a lot of code changes

00:05:25,830 --> 00:05:30,419
in a given deployment so if something

00:05:27,900 --> 00:05:32,430
went wrong that meant it was hard to

00:05:30,419 --> 00:05:34,410
debug and see what was the actual code

00:05:32,430 --> 00:05:36,090
changed I introduced that problem the

00:05:34,410 --> 00:05:38,310
main issues that we are seeing and we

00:05:36,090 --> 00:05:40,889
are trying to look at is the number of

00:05:38,310 --> 00:05:43,500
errors that this web app generates the

00:05:40,889 --> 00:05:45,300
request time because we have SLA s for

00:05:43,500 --> 00:05:47,580
our customers but also if the request

00:05:45,300 --> 00:05:49,620
time increases that means we need to add

00:05:47,580 --> 00:05:53,010
more servers to process the same amount

00:05:49,620 --> 00:05:54,930
of requests so there are a few key

00:05:53,010 --> 00:05:57,900
metrics that we look at when we whenever

00:05:54,930 --> 00:06:00,630
we deploy a new application and what we

00:05:57,900 --> 00:06:02,580
want to do is basically what the way we

00:06:00,630 --> 00:06:04,530
did like that mentioned earlier with the

00:06:02,580 --> 00:06:06,479
way we do deployments was basically have

00:06:04,530 --> 00:06:09,630
the infrastructure set up let's say we

00:06:06,479 --> 00:06:13,530
have 100 nodes in each region and then

00:06:09,630 --> 00:06:14,760
go on each of those running servers run

00:06:13,530 --> 00:06:16,800
some instable playbooks

00:06:14,760 --> 00:06:20,880
that would deploy a new version

00:06:16,800 --> 00:06:24,060
basically ssh to each batch they say

00:06:20,880 --> 00:06:27,570
take 10 server set at a time upgrade the

00:06:24,060 --> 00:06:29,099
the application apply the new

00:06:27,570 --> 00:06:30,419
configuration changes restart

00:06:29,099 --> 00:06:32,490
application and move to the next batch

00:06:30,419 --> 00:06:33,620
so basically up to be ran as an S people

00:06:32,490 --> 00:06:36,229
play block form

00:06:33,620 --> 00:06:38,449
from a developer's laptop which has a

00:06:36,229 --> 00:06:41,030
set of issues for instance the left of

00:06:38,449 --> 00:06:42,860
might die right in my ran out of battery

00:06:41,030 --> 00:06:45,919
for you I lose connection or you might

00:06:42,860 --> 00:06:48,470
have problems with the SSH connection

00:06:45,919 --> 00:06:51,020
the the limits and so forth also it was

00:06:48,470 --> 00:06:52,850
very hard to audit this it was also very

00:06:51,020 --> 00:06:54,710
stressful for the developer because they

00:06:52,850 --> 00:06:56,479
had to actually stay there for five or

00:06:54,710 --> 00:06:59,030
six hours till the ansible playbook

00:06:56,479 --> 00:07:01,400
finished so these are the issues that we

00:06:59,030 --> 00:07:03,650
try to eliminate and move to something

00:07:01,400 --> 00:07:09,020
that was more automated and more

00:07:03,650 --> 00:07:12,889
reliable to that end we looked at an

00:07:09,020 --> 00:07:15,760
open some open source solutions one of

00:07:12,889 --> 00:07:18,889
them is spinnaker which was actually

00:07:15,760 --> 00:07:25,880
developed by Netflix and Google and it

00:07:18,889 --> 00:07:28,250
was very easy to use tool for us because

00:07:25,880 --> 00:07:30,830
it allowed us to take this existing

00:07:28,250 --> 00:07:33,889
application but from little to no

00:07:30,830 --> 00:07:37,130
changes to the actual app and deploy it

00:07:33,889 --> 00:07:40,490
using spinnaker so what spinnaker is is

00:07:37,130 --> 00:07:42,560
a set of micro services that you can run

00:07:40,490 --> 00:07:45,110
you can even run it now in kubernetes is

00:07:42,560 --> 00:07:46,550
very easy to set up what we did two

00:07:45,110 --> 00:07:50,450
years ago when we started this we

00:07:46,550 --> 00:07:52,580
actually deployed it in in Amazon using

00:07:50,450 --> 00:07:55,610
the VMs little machines it was a bit

00:07:52,580 --> 00:07:57,500
more cumbersome but now right now with

00:07:55,610 --> 00:07:59,120
kubernetes I think it's it takes like 10

00:07:57,500 --> 00:08:02,539
minutes to set it up

00:07:59,120 --> 00:08:06,139
so what Spinnaker's allows us to do is

00:08:02,539 --> 00:08:07,789
two things one is to have what the basic

00:08:06,139 --> 00:08:09,560
principle behind it is the immutable

00:08:07,789 --> 00:08:11,840
infrastructure part so that means

00:08:09,560 --> 00:08:14,360
instead of going to the existing servers

00:08:11,840 --> 00:08:16,699
and applying changes there exists the

00:08:14,360 --> 00:08:18,430
production server side and apply changes

00:08:16,699 --> 00:08:21,229
while those services are running and

00:08:18,430 --> 00:08:23,900
possibly introducing some some you know

00:08:21,229 --> 00:08:26,120
errors there's some some issues instead

00:08:23,900 --> 00:08:28,160
of doing that in place you whenever you

00:08:26,120 --> 00:08:30,169
want to deploy a new app you spin up a

00:08:28,160 --> 00:08:33,409
whole new cluster or a whole new fleet

00:08:30,169 --> 00:08:35,839
of servers using your new app so

00:08:33,409 --> 00:08:37,430
basically at any given time when you do

00:08:35,839 --> 00:08:39,200
a deployment you have the old stable

00:08:37,430 --> 00:08:41,330
version let's say 100 servers for a

00:08:39,200 --> 00:08:43,159
given region and then you create a new

00:08:41,330 --> 00:08:46,010
server group alongside that and your

00:08:43,159 --> 00:08:47,170
auto scale group for AWS but it has

00:08:46,010 --> 00:08:49,899
support for other crop

00:08:47,170 --> 00:08:51,850
writers as well and you around the new

00:08:49,899 --> 00:08:54,220
version and the secret sauce here here

00:08:51,850 --> 00:08:57,339
is the fact that you put all both these

00:08:54,220 --> 00:08:59,110
clusters under the same load balancer so

00:08:57,339 --> 00:09:01,180
for instance let's say you have the

00:08:59,110 --> 00:09:03,610
whole cluster with 100 let's say 90 80

00:09:01,180 --> 00:09:05,440
servers you create a new cluster with

00:09:03,610 --> 00:09:07,720
two server they say this cannery

00:09:05,440 --> 00:09:10,000
deployments now we have a total of 100

00:09:07,720 --> 00:09:13,180
servers might eat with all version 2

00:09:10,000 --> 00:09:15,160
with a new version put them all in under

00:09:13,180 --> 00:09:16,899
the load balancer which means that the

00:09:15,160 --> 00:09:18,760
new version will receive 2 percent of

00:09:16,899 --> 00:09:20,260
the traffic so if something is wrong

00:09:18,760 --> 00:09:22,480
with the new version let's say

00:09:20,260 --> 00:09:24,639
interstate code change that it means

00:09:22,480 --> 00:09:27,339
behaving you are only impacting a small

00:09:24,639 --> 00:09:29,589
fraction of the traffic and the the

00:09:27,339 --> 00:09:31,170
whole idea here is to limit the blast

00:09:29,589 --> 00:09:36,310
radius whenever introduce a code change

00:09:31,170 --> 00:09:37,990
so basically what spiracles are though

00:09:36,310 --> 00:09:40,120
it would allows you to do it offers this

00:09:37,990 --> 00:09:42,100
deployment strategy out-of-the-box

00:09:40,120 --> 00:09:47,139
basically this can redeployment or the

00:09:42,100 --> 00:09:49,449
red/black deployment and the idea here

00:09:47,139 --> 00:09:50,769
in spinnaker you can the way it works

00:09:49,449 --> 00:09:54,490
conspirator is basically create a

00:09:50,769 --> 00:09:58,949
pipeline I know how many of you heard of

00:09:54,490 --> 00:10:02,260
spinnaker alright and Jenkins

00:09:58,949 --> 00:10:04,089
alright so you can think about it as a

00:10:02,260 --> 00:10:05,680
Jenkins pipeline but it's the

00:10:04,089 --> 00:10:06,760
continuation of the Jenkins pipeline so

00:10:05,680 --> 00:10:09,670
you have the drink inspire find that

00:10:06,760 --> 00:10:11,440
takes your code builds it compiles it

00:10:09,670 --> 00:10:13,870
and creates an artifact to be that the

00:10:11,440 --> 00:10:17,410
jar file an RPM or Debian file of docker

00:10:13,870 --> 00:10:19,480
image and after that you feed that into

00:10:17,410 --> 00:10:21,519
spinnaker and say okay I have this

00:10:19,480 --> 00:10:23,980
artifact I want to deploy it I want to

00:10:21,519 --> 00:10:25,930
be played in a given cloud provider by

00:10:23,980 --> 00:10:28,420
baw it might be kubernetes might be

00:10:25,930 --> 00:10:30,579
another call provider and I want to have

00:10:28,420 --> 00:10:31,930
this deployment strategy this is a

00:10:30,579 --> 00:10:32,680
docker image things are pretty

00:10:31,930 --> 00:10:35,199
straightforward

00:10:32,680 --> 00:10:38,110
but things are getting more complicated

00:10:35,199 --> 00:10:40,089
if you have something like an RPM or a

00:10:38,110 --> 00:10:41,830
debian for a for a Linux file for or

00:10:40,089 --> 00:10:44,740
even a jar world

00:10:41,830 --> 00:10:48,640
unarchive so first in our case where we

00:10:44,740 --> 00:10:50,800
deploy in AWS we we have Medicare RPM

00:10:48,640 --> 00:10:53,050
packages containing our application and

00:10:50,800 --> 00:10:55,000
what we do in spinnaker we have this

00:10:53,050 --> 00:10:56,770
pipeline that says okay whenever the

00:10:55,000 --> 00:11:00,030
Jenkins job has finished and has created

00:10:56,770 --> 00:11:02,680
that RPM it will publish it into an

00:11:00,030 --> 00:11:05,890
repository it might be bin tray you

00:11:02,680 --> 00:11:08,560
might be artifactory once it's there we

00:11:05,890 --> 00:11:11,770
have spinnaker around the pipeline that

00:11:08,560 --> 00:11:15,310
says ok I want to spin up a box install

00:11:11,770 --> 00:11:17,380
install application make all the changes

00:11:15,310 --> 00:11:19,720
that I want to do to that application be

00:11:17,380 --> 00:11:23,800
that that it can include apply the

00:11:19,720 --> 00:11:25,660
configuration call any other services

00:11:23,800 --> 00:11:28,330
that I want to call to fetch some data

00:11:25,660 --> 00:11:30,970
and after the application is set up I

00:11:28,330 --> 00:11:33,130
want to do a snapshot I do a snapshot

00:11:30,970 --> 00:11:36,070
and create an image which is basically a

00:11:33,130 --> 00:11:39,190
big file that we store in s3 in the

00:11:36,070 --> 00:11:41,200
cloud and once the fire wants the image

00:11:39,190 --> 00:11:44,020
there which is for Amazon it's an ami

00:11:41,200 --> 00:11:45,940
Amazon image once the image is there or

00:11:44,020 --> 00:11:48,790
you can speak of it as an ISO file right

00:11:45,940 --> 00:11:50,980
or find that you have on a CD when you

00:11:48,790 --> 00:11:53,320
start the OS but this one is a file that

00:11:50,980 --> 00:11:56,470
also contains the OS and the application

00:11:53,320 --> 00:11:57,940
so have this is image and then we have

00:11:56,470 --> 00:12:00,460
the second stage which is the deployment

00:11:57,940 --> 00:12:02,050
part where we can take this image which

00:12:00,460 --> 00:12:03,940
contains application which is fully set

00:12:02,050 --> 00:12:05,740
up and deploy it on a number of servers

00:12:03,940 --> 00:12:07,360
it can be one server or it can be one

00:12:05,740 --> 00:12:09,220
thousand servers but the nice thing

00:12:07,360 --> 00:12:12,340
about it is the fact that it should be

00:12:09,220 --> 00:12:13,840
consistent across this fleet of servers

00:12:12,340 --> 00:12:19,030
that we are going to deploy these are

00:12:13,840 --> 00:12:20,920
new servers that we are spinning up yeah

00:12:19,030 --> 00:12:22,600
and another thing is because we are

00:12:20,920 --> 00:12:25,900
doing all this from spinnaker which also

00:12:22,600 --> 00:12:28,360
has a new I also has an API which we can

00:12:25,900 --> 00:12:31,300
call from jenkees we are no longer using

00:12:28,360 --> 00:12:36,570
the developers laptop which means we can

00:12:31,300 --> 00:12:36,570
also have audit and logging and all that

00:12:37,020 --> 00:12:44,990
okay so Kosta mention that we basically

00:12:42,089 --> 00:12:48,390
adopted the immutable infrastructure

00:12:44,990 --> 00:12:51,060
concept let's say so for this we had to

00:12:48,390 --> 00:12:53,970
start making our DM eyes we chose a

00:12:51,060 --> 00:12:59,339
multi-layer approach basically we

00:12:53,970 --> 00:13:01,560
started first building our base EMI this

00:12:59,339 --> 00:13:04,350
image contains all the common software

00:13:01,560 --> 00:13:09,060
which is shared between servers this can

00:13:04,350 --> 00:13:12,510
contain things like hello the SSH config

00:13:09,060 --> 00:13:16,050
for four instances or the load exporter

00:13:12,510 --> 00:13:19,649
for Prometheus or the matrix client and

00:13:16,050 --> 00:13:23,490
so on and we bake this base ami we save

00:13:19,649 --> 00:13:25,770
in AWS and we use this as a base image

00:13:23,490 --> 00:13:27,930
on top of which with bake the

00:13:25,770 --> 00:13:30,930
application in mind which is application

00:13:27,930 --> 00:13:32,190
specific configurations we also perform

00:13:30,930 --> 00:13:35,399
configuration management for all the

00:13:32,190 --> 00:13:38,040
applications within the ami so that when

00:13:35,399 --> 00:13:40,490
we deploy this image no changes are

00:13:38,040 --> 00:13:43,410
performed on the on the actual servers

00:13:40,490 --> 00:13:46,200
during the bake process we also fetch

00:13:43,410 --> 00:13:48,209
secrets so whenever we need to store

00:13:46,200 --> 00:13:52,950
secrets on the actual production servers

00:13:48,209 --> 00:13:57,240
we basically burnt them in the image and

00:13:52,950 --> 00:13:59,970
thus reducing the API calls to other

00:13:57,240 --> 00:14:03,270
external services once the machine is

00:13:59,970 --> 00:14:05,130
started and we also perform cannon and

00:14:03,270 --> 00:14:08,190
always patching this is especially

00:14:05,130 --> 00:14:10,050
important when you are considered the

00:14:08,190 --> 00:14:12,540
fact that sometimes you need to patch

00:14:10,050 --> 00:14:16,050
your servers for known vulnerabilities

00:14:12,540 --> 00:14:18,540
and you have to do them fast so we

00:14:16,050 --> 00:14:20,060
usually patch the DM eyes and then on

00:14:18,540 --> 00:14:25,290
the next deployment window we just

00:14:20,060 --> 00:14:26,790
deploy all the fixes and then once we

00:14:25,290 --> 00:14:30,540
have the application in mind this is

00:14:26,790 --> 00:14:36,060
copied across all of our AWS region and

00:14:30,540 --> 00:14:38,579
used to deploy once the instance is

00:14:36,060 --> 00:14:41,459
started so this is uses the pre baked

00:14:38,579 --> 00:14:45,510
application EMI we need to provision the

00:14:41,459 --> 00:14:48,209
instance so basically start all the

00:14:45,510 --> 00:14:48,560
services on it but also we need to do

00:14:48,209 --> 00:14:51,889
some

00:14:48,560 --> 00:14:54,110
extra configurations such as setting up

00:14:51,889 --> 00:14:56,300
the hostname or mounting and formatting

00:14:54,110 --> 00:15:00,350
the disks which are not available when

00:14:56,300 --> 00:15:02,449
you're baking the EMI with Packer this

00:15:00,350 --> 00:15:05,540
tool is an internal build tool so it's a

00:15:02,449 --> 00:15:07,670
java application it's and it leverages

00:15:05,540 --> 00:15:13,160
the auto scale group lifecycle hooks

00:15:07,670 --> 00:15:15,860
these are basically some small apps

00:15:13,160 --> 00:15:19,819
provided by the auto scale group in AWS

00:15:15,860 --> 00:15:23,600
which allows you to to take some actions

00:15:19,819 --> 00:15:26,269
when the instance is in a specific state

00:15:23,600 --> 00:15:28,370
when it's starting or shutting down so

00:15:26,269 --> 00:15:32,029
we leverage those lifecycle books and

00:15:28,370 --> 00:15:35,509
based on those we provision our our

00:15:32,029 --> 00:15:37,430
machine this means we start the all the

00:15:35,509 --> 00:15:44,269
services and we validate that everything

00:15:37,430 --> 00:15:46,579
is okay yeah and for for your

00:15:44,269 --> 00:15:49,399
application if there are two cases right

00:15:46,579 --> 00:15:52,730
if it's a stateless application whenever

00:15:49,399 --> 00:15:55,250
you switch to the new to the new version

00:15:52,730 --> 00:15:57,920
you can just shut down the old server

00:15:55,250 --> 00:15:59,509
fleet and be done with it as long as you

00:15:57,920 --> 00:16:02,569
have removed it from the from the load

00:15:59,509 --> 00:16:04,819
balancer however what happens when the

00:16:02,569 --> 00:16:06,980
application is service stateful in our

00:16:04,819 --> 00:16:09,199
case the the main application this yes

00:16:06,980 --> 00:16:11,839
is stay free in the sense that it keeps

00:16:09,199 --> 00:16:14,240
some temporary data on disk for like

00:16:11,839 --> 00:16:16,279
five or ten minutes before pushing it or

00:16:14,240 --> 00:16:19,309
seaming it back to the to our back-end

00:16:16,279 --> 00:16:21,910
so because of that we can't just shut it

00:16:19,309 --> 00:16:24,680
down automatically we need to have this

00:16:21,910 --> 00:16:27,290
custom logic that says ok before

00:16:24,680 --> 00:16:29,660
shutting down this old server I want to

00:16:27,290 --> 00:16:33,439
make sure that I pushed the data to the

00:16:29,660 --> 00:16:35,959
back end before you know power it off to

00:16:33,439 --> 00:16:38,089
that extent we have created a simple

00:16:35,959 --> 00:16:41,089
application that integrates with a nice

00:16:38,089 --> 00:16:43,370
feature from a Douglas called lifecycle

00:16:41,089 --> 00:16:46,309
hooks so basically the autoscale group

00:16:43,370 --> 00:16:48,889
in AWS which contains all the servers in

00:16:46,309 --> 00:16:52,939
a given cluster gives you this feature

00:16:48,889 --> 00:16:56,509
where we can make you can send a signal

00:16:52,939 --> 00:16:58,790
to you whenever a server is about to get

00:16:56,509 --> 00:17:01,459
terminated so what we do we have this

00:16:58,790 --> 00:17:03,679
application which is a Java daemon app

00:17:01,459 --> 00:17:06,589
runs alongside the domain up on the cell

00:17:03,679 --> 00:17:09,620
phone on each server so this app is

00:17:06,589 --> 00:17:11,510
running there and listen Li listening

00:17:09,620 --> 00:17:13,730
for this signal from from the autoscaler

00:17:11,510 --> 00:17:17,089
group that says hey this is about to

00:17:13,730 --> 00:17:18,169
begin terminated when the this sub

00:17:17,089 --> 00:17:22,309
called shredder

00:17:18,169 --> 00:17:24,409
receive this signal it will run the you

00:17:22,309 --> 00:17:26,839
know the shutdown logic in our case

00:17:24,409 --> 00:17:28,960
basically upload some data to to s3 or

00:17:26,839 --> 00:17:32,659
push some data to kinases and or

00:17:28,960 --> 00:17:35,230
whatever logic we want to have after the

00:17:32,659 --> 00:17:37,340
the shut off script gets executed

00:17:35,230 --> 00:17:39,080
shredder will send the signal back to

00:17:37,340 --> 00:17:42,380
daughter scale group that says ok I have

00:17:39,080 --> 00:17:44,059
done my shut down logic you can

00:17:42,380 --> 00:17:46,640
terminate these systems so basically to

00:17:44,059 --> 00:17:49,309
send this shutdown complete event to

00:17:46,640 --> 00:17:51,169
total scale group when that happens the

00:17:49,309 --> 00:17:54,049
box will get terminated

00:17:51,169 --> 00:17:56,630
so to recap here the the workflow the

00:17:54,049 --> 00:17:59,149
deployment workflow we have the baking

00:17:56,630 --> 00:18:03,200
stage that that nation basically string

00:17:59,149 --> 00:18:04,580
up one server that we'll use to create

00:18:03,200 --> 00:18:06,890
to basically create our application

00:18:04,580 --> 00:18:09,320
basically install the RPM install the

00:18:06,890 --> 00:18:11,770
debian file or run puppet if you want

00:18:09,320 --> 00:18:15,409
shift for whatever you want to do there

00:18:11,770 --> 00:18:17,029
then do a snapshot if every is ok you'll

00:18:15,409 --> 00:18:18,679
have this name so that you can deploy on

00:18:17,029 --> 00:18:20,870
multiple servers so in the end proceed

00:18:18,679 --> 00:18:22,640
to the deployment phase where you have

00:18:20,870 --> 00:18:24,710
the all truster you deploy your new

00:18:22,640 --> 00:18:26,840
cluster then switch the traffic to the

00:18:24,710 --> 00:18:28,399
new cluster from the load balancer the

00:18:26,840 --> 00:18:31,039
old cast will not have any more traffic

00:18:28,399 --> 00:18:33,320
you can decommission it and then you can

00:18:31,039 --> 00:18:35,929
choose here to either use something like

00:18:33,320 --> 00:18:37,399
a life cycle hook to make the clean up

00:18:35,929 --> 00:18:39,049
or if it's a stateless app you can just

00:18:37,399 --> 00:18:42,770
shut it down and be done with it

00:18:39,049 --> 00:18:44,870
one important aspect here is what

00:18:42,770 --> 00:18:46,070
happens in case of a failure what

00:18:44,870 --> 00:18:48,620
happens in case of a failure with a new

00:18:46,070 --> 00:18:51,830
version that you detect a bit later

00:18:48,620 --> 00:18:53,510
let's say you have 100 100 nodes with

00:18:51,830 --> 00:18:54,860
all version 100 nodes with a new version

00:18:53,510 --> 00:18:56,929
you switch the traffic to the new

00:18:54,860 --> 00:18:58,970
version and then after a couple of hours

00:18:56,929 --> 00:19:01,730
you see an increase in the number of

00:18:58,970 --> 00:19:03,409
errors obviously you would like to roll

00:19:01,730 --> 00:19:07,250
back as soon as possible to the old

00:19:03,409 --> 00:19:11,270
stable version to that end you can have

00:19:07,250 --> 00:19:14,480
the old version still being stepping up

00:19:11,270 --> 00:19:15,770
and run in parallel both clusters it

00:19:14,480 --> 00:19:17,570
obviously means to your

00:19:15,770 --> 00:19:19,070
double the money right you have 100

00:19:17,570 --> 00:19:20,779
notes with all version 100 with a new

00:19:19,070 --> 00:19:22,640
version but it might be something that

00:19:20,779 --> 00:19:24,679
you are might be willing to pay for for

00:19:22,640 --> 00:19:27,409
a few hours and till you see that

00:19:24,679 --> 00:19:30,230
everything is ok with a new version or

00:19:27,409 --> 00:19:33,169
if you wanna you wanna you know limit

00:19:30,230 --> 00:19:35,929
the cost you can remove the service

00:19:33,169 --> 00:19:38,299
order from the old cluster so be 0 and

00:19:35,929 --> 00:19:39,649
100 if you detect an issue then you can

00:19:38,299 --> 00:19:41,929
switch to the whole cluster by spinning

00:19:39,649 --> 00:19:44,149
up from the old image but that might

00:19:41,929 --> 00:19:45,919
take a few more minutes if you have the

00:19:44,149 --> 00:19:47,960
whole cast of running switching to the

00:19:45,919 --> 00:19:49,460
to that one it takes you know just the

00:19:47,960 --> 00:19:51,740
switch in the load balancer it takes

00:19:49,460 --> 00:19:53,539
like 30 seconds to do it if you have

00:19:51,740 --> 00:19:55,669
decommission the whole cluster you need

00:19:53,539 --> 00:19:57,230
to spin up the the servers which might

00:19:55,669 --> 00:19:58,820
take 10 minutes or 20 minutes so it

00:19:57,230 --> 00:20:05,750
might have by restarting tool to think

00:19:58,820 --> 00:20:09,350
about it alright so in terms of

00:20:05,750 --> 00:20:12,500
provisioning the Decius instance we

00:20:09,350 --> 00:20:14,690
start with the dcs image which we baked

00:20:12,500 --> 00:20:17,750
this contains the application contains

00:20:14,690 --> 00:20:19,159
the configuration contains basically for

00:20:17,750 --> 00:20:21,289
this years we are running purpose so

00:20:19,159 --> 00:20:23,450
basically running puppy with a master

00:20:21,289 --> 00:20:26,450
list approach which configures the

00:20:23,450 --> 00:20:28,909
system to our liking where we have the

00:20:26,450 --> 00:20:30,940
application of configuration the who

00:20:28,909 --> 00:20:36,590
have actually multiple applications that

00:20:30,940 --> 00:20:40,220
we are configuring and basically this is

00:20:36,590 --> 00:20:44,090
a one server with a few services running

00:20:40,220 --> 00:20:45,860
on it what we do with the the you know

00:20:44,090 --> 00:20:47,390
the init skip that we have the instance

00:20:45,860 --> 00:20:50,500
provisioning scheme that we have we

00:20:47,390 --> 00:20:54,320
basic add add bootstrap we configure

00:20:50,500 --> 00:20:55,789
each service to you know to pick the

00:20:54,320 --> 00:20:57,770
right configuration for that specific

00:20:55,789 --> 00:20:59,960
region if we have multiple regions and

00:20:57,770 --> 00:21:03,080
do some validations to see that

00:20:59,960 --> 00:21:06,559
everything is set up okay and also for

00:21:03,080 --> 00:21:07,760
this years we do a warm-up where we

00:21:06,559 --> 00:21:10,039
basically generate some synthetic

00:21:07,760 --> 00:21:11,870
request to that server just to basically

00:21:10,039 --> 00:21:16,909
warm it up before is in the production

00:21:11,870 --> 00:21:18,500
traffic this is happening that instance

00:21:16,909 --> 00:21:21,710
bootstrapping right so if you have the

00:21:18,500 --> 00:21:24,529
image and then you try to deploy it on a

00:21:21,710 --> 00:21:27,320
thousand servers you want to limit the

00:21:24,529 --> 00:21:28,460
amount of operations that you do at

00:21:27,320 --> 00:21:29,390
bootstrapping

00:21:28,460 --> 00:21:30,770
because first

00:21:29,390 --> 00:21:32,600
if you are calling an external service

00:21:30,770 --> 00:21:35,000
at bootstrapping and you have 1,000

00:21:32,600 --> 00:21:36,590
servers that is calling graph 53 or is

00:21:35,000 --> 00:21:38,840
calling the puppet master or is calling

00:21:36,590 --> 00:21:41,150
another service if the service is down

00:21:38,840 --> 00:21:43,400
you are not going to be able to spin up

00:21:41,150 --> 00:21:45,020
that that server so basically we are

00:21:43,400 --> 00:21:47,900
trying to move all that logic to the

00:21:45,020 --> 00:21:49,549
baked part so baked part basically spin

00:21:47,900 --> 00:21:54,160
up one instance if everything's okay

00:21:49,549 --> 00:21:56,780
then I'm 100% sure that I can deploy 100

00:21:54,160 --> 00:21:59,540
to the baked face and then at the

00:21:56,780 --> 00:22:01,640
Diploma phase try to limit the amount of

00:21:59,540 --> 00:22:03,530
external services as much as possible in

00:22:01,640 --> 00:22:06,140
our cases we was not possible to remove

00:22:03,530 --> 00:22:08,210
all of these calls with us we still do

00:22:06,140 --> 00:22:11,059
one call to ruff 53 to basically

00:22:08,210 --> 00:22:13,610
register register the the DNS entry but

00:22:11,059 --> 00:22:14,840
that's about it we also all the rest

00:22:13,610 --> 00:22:17,450
what that we are doing is basically

00:22:14,840 --> 00:22:22,580
setup the disks which is a local

00:22:17,450 --> 00:22:24,679
operation which might still fail and and

00:22:22,580 --> 00:22:28,240
the basically warm up this years which

00:22:24,679 --> 00:22:28,240
basically generate some requests

00:22:29,680 --> 00:22:35,110
oh yeah let's see yeah let's see

00:22:32,050 --> 00:22:39,330
spinnaker in action we have a small

00:22:35,110 --> 00:22:43,930
movie this is a scale up procedure

00:22:39,330 --> 00:22:46,600
basically in which we've boosted up 500

00:22:43,930 --> 00:22:49,810
servers these are each of those green

00:22:46,600 --> 00:22:52,780
boxes represent a single instance those

00:22:49,810 --> 00:22:56,080
are really powerful machines so each of

00:22:52,780 --> 00:23:00,160
those green boxes is a c36 large

00:22:56,080 --> 00:23:02,280
instance which which has 32 cores and 60

00:23:00,160 --> 00:23:04,540
gigs of ram if i'm not mistaken and

00:23:02,280 --> 00:23:06,700
during this phase the provisional tail

00:23:04,540 --> 00:23:08,500
takes care of like bootstrapping the

00:23:06,700 --> 00:23:10,660
instances and once all of them turn

00:23:08,500 --> 00:23:14,170
green it means that they are ready to

00:23:10,660 --> 00:23:20,050
receive traffic and we have the reverse

00:23:14,170 --> 00:23:24,730
procedure as well next night the reverse

00:23:20,050 --> 00:23:28,350
procedure in which you need to scale in

00:23:24,730 --> 00:23:30,370
your infrastructure but because in this

00:23:28,350 --> 00:23:32,290
specific scenario we are talking about

00:23:30,370 --> 00:23:34,990
the stateful application we have the

00:23:32,290 --> 00:23:37,390
shredder that goes dimension which takes

00:23:34,990 --> 00:23:40,650
care of actually cleaning up bringing up

00:23:37,390 --> 00:23:44,200
the instance before shutting down the

00:23:40,650 --> 00:23:46,660
the actual server so in which case we

00:23:44,200 --> 00:23:49,720
don't lose any critical data so

00:23:46,660 --> 00:23:54,240
basically a scale to 500 instances and

00:23:49,720 --> 00:23:54,240
then a scale to one instance scale

00:23:55,600 --> 00:24:01,240
so basically this is an example of

00:23:58,170 --> 00:24:05,110
pipelining spinnaker it's pretty much

00:24:01,240 --> 00:24:08,680
freeform you can basically create a

00:24:05,110 --> 00:24:10,840
pipeline that has the series of stages

00:24:08,680 --> 00:24:11,590
that you can combine whenever however

00:24:10,840 --> 00:24:14,320
you like

00:24:11,590 --> 00:24:16,720
it does have a set of pre-built stage

00:24:14,320 --> 00:24:19,510
types for instance the baked part which

00:24:16,720 --> 00:24:20,860
might be something for CentOS or my visa

00:24:19,510 --> 00:24:24,970
fee for Ubuntu or it might be something

00:24:20,860 --> 00:24:28,500
for kubernetes for docker it also has

00:24:24,970 --> 00:24:30,790
you know check type of deployment stage

00:24:28,500 --> 00:24:34,960
manual validation stage and all that

00:24:30,790 --> 00:24:38,050
what we see here is basically we assume

00:24:34,960 --> 00:24:39,880
that the image was baked in another

00:24:38,050 --> 00:24:42,640
pipeline so the first stage there that

00:24:39,880 --> 00:24:44,980
you're seeing is the Loki you know

00:24:42,640 --> 00:24:46,570
finding that the ami that was pre built

00:24:44,980 --> 00:24:48,250
so basically this is doing a lookup in a

00:24:46,570 --> 00:24:51,520
table that says I want to find the

00:24:48,250 --> 00:24:54,520
latest dcs ami the latest image once we

00:24:51,520 --> 00:24:56,980
find that image we can basically deploy

00:24:54,520 --> 00:24:58,240
on a number of regions what we are doing

00:24:56,980 --> 00:25:00,820
here is basically we are deploying

00:24:58,240 --> 00:25:03,160
canneries in each region and you can

00:25:00,820 --> 00:25:04,840
select which easier to deploy to for

00:25:03,160 --> 00:25:07,660
instance right now for this deployment

00:25:04,840 --> 00:25:09,610
we are we only deploy to Tokyo so

00:25:07,660 --> 00:25:12,430
basically what this does is find the a

00:25:09,610 --> 00:25:14,440
mine and then deploy to Canaries in the

00:25:12,430 --> 00:25:16,900
Tokyo region so basically spinning up a

00:25:14,440 --> 00:25:19,260
new server group a new auto-scale group

00:25:16,900 --> 00:25:22,630
with just two servers in that region

00:25:19,260 --> 00:25:27,280
after that what we are doing is

00:25:22,630 --> 00:25:30,370
basically monitoring that canary right

00:25:27,280 --> 00:25:31,660
now we are doing that manually in the

00:25:30,370 --> 00:25:34,000
sense that we are looking graph fauna

00:25:31,660 --> 00:25:35,350
and chicken some dashboards look at the

00:25:34,000 --> 00:25:38,470
number of Pharaohs look at the request

00:25:35,350 --> 00:25:41,470
time compare that with the old stable

00:25:38,470 --> 00:25:44,230
version but the nice thing about spirit

00:25:41,470 --> 00:25:46,720
is the fact that it added half a year

00:25:44,230 --> 00:25:49,120
six months ago a new feature a new

00:25:46,720 --> 00:25:51,100
service called automatic canary analysis

00:25:49,120 --> 00:25:53,320
which does that automatically it

00:25:51,100 --> 00:25:55,840
basically allows you to fetch some

00:25:53,320 --> 00:25:59,740
matrix from Prometheus or a graph of

00:25:55,840 --> 00:26:01,360
graphite or other matrix source specify

00:25:59,740 --> 00:26:04,510
the dimetric name that you want to look

00:26:01,360 --> 00:26:07,270
at specify some thresholds and it will

00:26:04,510 --> 00:26:08,450
take care of monitoring those those

00:26:07,270 --> 00:26:10,490
metrics and

00:26:08,450 --> 00:26:11,780
everything is okay with the cannery it

00:26:10,490 --> 00:26:15,380
will proceed with a full deployment

00:26:11,780 --> 00:26:18,080
right now for us it's a manual judgment

00:26:15,380 --> 00:26:21,560
part where we deploy a cannery we look

00:26:18,080 --> 00:26:24,650
at the the dashboard and then click

00:26:21,560 --> 00:26:26,870
proceed and then we scale up the new

00:26:24,650 --> 00:26:30,830
server to 100 servers and the

00:26:26,870 --> 00:26:34,730
coefficient of all done so what we are

00:26:30,830 --> 00:26:37,480
seeing here is the the later part of the

00:26:34,730 --> 00:26:40,310
process where we are scaling down the

00:26:37,480 --> 00:26:42,230
the whole fleet the whole server feet

00:26:40,310 --> 00:26:49,490
after we make sure that the new version

00:26:42,230 --> 00:26:53,740
is behaving okay so the achievements

00:26:49,490 --> 00:26:56,330
that we had with moving to this approach

00:26:53,740 --> 00:26:59,360
basically the most important thing was

00:26:56,330 --> 00:27:02,780
the deployment time like we mentioned

00:26:59,360 --> 00:27:04,760
earlier for running the sensible

00:27:02,780 --> 00:27:06,470
playbook playbooks from the developers

00:27:04,760 --> 00:27:09,260
laptop it took a lot of time it was

00:27:06,470 --> 00:27:12,440
error-prone it didn't ensure consistency

00:27:09,260 --> 00:27:14,810
because if you are running SSH comments

00:27:12,440 --> 00:27:16,850
on a hundred notes you might have some

00:27:14,810 --> 00:27:20,120
errors on one of those servers or total

00:27:16,850 --> 00:27:22,340
servers and my movie to this new

00:27:20,120 --> 00:27:25,400
approach the deployment time decreased

00:27:22,340 --> 00:27:27,170
dramatically but also it allows us to

00:27:25,400 --> 00:27:28,670
have quick roll backs with the project

00:27:27,170 --> 00:27:30,980
we mentioned earlier because we have two

00:27:28,670 --> 00:27:32,900
servers and we don't have just one that

00:27:30,980 --> 00:27:35,030
we are already in place because we have

00:27:32,900 --> 00:27:37,790
two we can quickly roll back to it it

00:27:35,030 --> 00:27:40,820
takes very little time we have

00:27:37,790 --> 00:27:45,040
consistency also very important the way

00:27:40,820 --> 00:27:48,710
we had it earlier where we have once one

00:27:45,040 --> 00:27:51,110
cluster of servers yeah that you are

00:27:48,710 --> 00:27:54,080
already in place that meant that those

00:27:51,110 --> 00:27:56,690
servers were running 24/7 so basically

00:27:54,080 --> 00:27:58,700
if you want to upgrade it agree the OS

00:27:56,690 --> 00:28:00,890
you have to reboot it right if you wanna

00:27:58,700 --> 00:28:03,710
change the instance type then you have

00:28:00,890 --> 00:28:05,720
to create a whole new cluster right do I

00:28:03,710 --> 00:28:08,870
have to use terraform troposphere or

00:28:05,720 --> 00:28:10,550
confirmational or other solutions with

00:28:08,870 --> 00:28:12,410
this new approach basically at each

00:28:10,550 --> 00:28:13,730
deployment we are free to change the

00:28:12,410 --> 00:28:16,340
instance type we are free to change the

00:28:13,730 --> 00:28:18,350
OS we are free to basically operate an

00:28:16,340 --> 00:28:20,030
experiment with

00:28:18,350 --> 00:28:22,429
current instance typing in this case

00:28:20,030 --> 00:28:24,460
which basically allowed us to find the

00:28:22,429 --> 00:28:26,570
newest type that was actually more

00:28:24,460 --> 00:28:28,370
performant for the class of four

00:28:26,570 --> 00:28:29,750
application that we're running and we

00:28:28,370 --> 00:28:32,780
are actually we were actually able to

00:28:29,750 --> 00:28:35,090
save to have a 30% performance increase

00:28:32,780 --> 00:28:37,039
just by changing license type but to

00:28:35,090 --> 00:28:38,980
find the right it says type we actually

00:28:37,039 --> 00:28:42,260
have to do like five or six deployments

00:28:38,980 --> 00:28:44,870
trying out multiple instance types under

00:28:42,260 --> 00:28:48,679
real production traffic right under real

00:28:44,870 --> 00:28:51,169
load so basically speak allowed us to

00:28:48,679 --> 00:28:57,740
basically add deployment phase to choose

00:28:51,169 --> 00:29:01,820
the the instance type okay

00:28:57,740 --> 00:29:04,880
cos we talked about this year the data

00:29:01,820 --> 00:29:07,070
collection system map that we've moved

00:29:04,880 --> 00:29:09,289
to spinnaker but we also have virus

00:29:07,070 --> 00:29:11,320
which is another java application this

00:29:09,289 --> 00:29:14,720
time we are talking about the stateless

00:29:11,320 --> 00:29:18,980
applications so no critical data is

00:29:14,720 --> 00:29:21,710
stored on the instance itself we used to

00:29:18,980 --> 00:29:23,390
have around 2.5 k instances ready to

00:29:21,710 --> 00:29:26,360
cross several regions of a large number

00:29:23,390 --> 00:29:29,480
of machines and in the peak times we

00:29:26,360 --> 00:29:32,600
used to have around 700,000 HTTP

00:29:29,480 --> 00:29:34,549
requests per second managing deployments

00:29:32,600 --> 00:29:37,090
on this kind of infrastructure was

00:29:34,549 --> 00:29:39,710
really difficult in our case at least

00:29:37,090 --> 00:29:42,409
once we moved to spinnaker

00:29:39,710 --> 00:29:44,870
the deployment part looks pretty simple

00:29:42,409 --> 00:29:47,360
so we make a single VM I in a single

00:29:44,870 --> 00:29:50,780
region then we used at EMI to deploy

00:29:47,360 --> 00:29:54,500
across all of our partners so across all

00:29:50,780 --> 00:29:56,659
of our regions and since this is a

00:29:54,500 --> 00:30:01,340
stateful stateless application we don't

00:29:56,659 --> 00:30:05,600
care about data which is stored on the

00:30:01,340 --> 00:30:08,720
disk itself so right now when we are

00:30:05,600 --> 00:30:12,309
performing iris deployments on top of

00:30:08,720 --> 00:30:15,559
spinnaker with the immutable

00:30:12,309 --> 00:30:18,770
infrastructure mindset with deploying in

00:30:15,559 --> 00:30:21,770
less than 10 minutes for 200 instances

00:30:18,770 --> 00:30:25,010
because we it was easy for us to go to

00:30:21,770 --> 00:30:28,169
higher spec instance types to change the

00:30:25,010 --> 00:30:32,039
waste in a single deployment window

00:30:28,169 --> 00:30:36,690
and we ended up lowered the cost by 78%

00:30:32,039 --> 00:30:38,519
so if before it was also almost

00:30:36,690 --> 00:30:40,619
impossible to perform deployments on

00:30:38,519 --> 00:30:43,109
iris without actually affecting the

00:30:40,619 --> 00:30:44,730
application itself on two hundred five

00:30:43,109 --> 00:30:47,129
hundred two thousand five hundred

00:30:44,730 --> 00:30:50,100
distances was really really difficult

00:30:47,129 --> 00:30:56,190
but right now with spinnaker this is a

00:30:50,100 --> 00:30:58,499
trivial operation okay so in terms of

00:30:56,190 --> 00:31:01,109
the lessons learned about using

00:30:58,499 --> 00:31:03,869
spinnaker after you see spinnaker so the

00:31:01,109 --> 00:31:06,269
main idea for us was to stop SS aging to

00:31:03,869 --> 00:31:08,519
start authenticate on each server and do

00:31:06,269 --> 00:31:09,899
something more smart for instance is the

00:31:08,519 --> 00:31:12,480
same idea with kubernetes right you

00:31:09,899 --> 00:31:13,859
don't authenticate one container you

00:31:12,480 --> 00:31:16,049
basically have the docker image and you

00:31:13,859 --> 00:31:18,090
say I want to have 1,000 containers with

00:31:16,049 --> 00:31:19,769
with this docker image it was the same

00:31:18,090 --> 00:31:22,379
thing for us but we treat all machines

00:31:19,769 --> 00:31:24,840
where instead of SSH into each no

00:31:22,379 --> 00:31:27,119
running simple proposal and all that we

00:31:24,840 --> 00:31:32,480
want to have an image that we deploy to

00:31:27,119 --> 00:31:35,039
a thousand servers to that end we did

00:31:32,480 --> 00:31:37,019
encounter a series of issues with this

00:31:35,039 --> 00:31:40,350
approach basically the thing that we

00:31:37,019 --> 00:31:42,960
mentioned earlier at if we have at it

00:31:40,350 --> 00:31:45,779
says boost app basically whenever you

00:31:42,960 --> 00:31:48,749
spin up 1007 if you have that in its

00:31:45,779 --> 00:31:50,669
crib calling external services it was

00:31:48,749 --> 00:31:52,889
error-prone because the external service

00:31:50,669 --> 00:31:55,200
might have a rate limit or in my beat

00:31:52,889 --> 00:31:57,509
down for instance if you are calling if

00:31:55,200 --> 00:31:59,369
you are fetching the package the RPM or

00:31:57,509 --> 00:32:01,379
the debian files from on artifactory

00:31:59,369 --> 00:32:03,570
from bin tray that might be down might

00:32:01,379 --> 00:32:09,509
be slow so you want to move that to the

00:32:03,570 --> 00:32:11,429
big part another thing was setting up

00:32:09,509 --> 00:32:13,289
spinnaker itself noting that I mentioned

00:32:11,429 --> 00:32:16,320
at the beginning of the session in our

00:32:13,289 --> 00:32:18,989
case we had to use sent aways basically

00:32:16,320 --> 00:32:20,759
spinnaker is more or less was more or

00:32:18,989 --> 00:32:22,739
less built for Ubuntu so we had to

00:32:20,759 --> 00:32:26,429
create RPM packages for CentOS

00:32:22,739 --> 00:32:29,429
it was a pain to do it it was it was

00:32:26,429 --> 00:32:30,419
also very hard to create all the setup

00:32:29,429 --> 00:32:32,249
in AWS

00:32:30,419 --> 00:32:35,789
to basically allow spinnaker access to

00:32:32,249 --> 00:32:37,830
deploy to our AWS accounts so basically

00:32:35,789 --> 00:32:40,320
creating all those I am policies was a

00:32:37,830 --> 00:32:41,570
bit hard like I mentioned earlier things

00:32:40,320 --> 00:32:44,660
are starting to get better

00:32:41,570 --> 00:32:47,540
because with the you know migration to

00:32:44,660 --> 00:32:50,600
kubernetes even if you are not deploying

00:32:47,540 --> 00:32:52,280
to kubernetes but just have spinnaker

00:32:50,600 --> 00:32:54,880
around on kubernetes on small kubernetes

00:32:52,280 --> 00:32:57,620
Kuster it will save you a lot of effort

00:32:54,880 --> 00:32:58,250
things should be a lot easier in that

00:32:57,620 --> 00:33:01,460
regard

00:32:58,250 --> 00:33:03,500
also the documentation is getting better

00:33:01,460 --> 00:33:06,110
for spinnaker it has quite an active

00:33:03,500 --> 00:33:08,120
community we are actually trying to

00:33:06,110 --> 00:33:09,230
contribute to it but we are not adobe is

00:33:08,120 --> 00:33:11,510
not the main contributor like I

00:33:09,230 --> 00:33:13,250
mentioned it's Netflix and Google but I

00:33:11,510 --> 00:33:16,580
would strongly recommend it for for

00:33:13,250 --> 00:33:20,300
deployment for the deployment deploying

00:33:16,580 --> 00:33:24,650
your applications also it has spherical

00:33:20,300 --> 00:33:27,920
has you know already is cluster that its

00:33:24,650 --> 00:33:29,900
caches data to basically it fetches the

00:33:27,920 --> 00:33:32,630
data from it readable Azure the article

00:33:29,900 --> 00:33:34,610
provider and uses radius to to store

00:33:32,630 --> 00:33:37,250
that as a cache so that it doesn't call

00:33:34,610 --> 00:33:40,040
AWS every single time to that end we are

00:33:37,250 --> 00:33:41,780
using elastic case from AWS and we did

00:33:40,040 --> 00:33:43,760
encounter issues where it was on the

00:33:41,780 --> 00:33:46,340
provision so we had to actually have

00:33:43,760 --> 00:33:52,160
this strong ready server for spinnaker

00:33:46,340 --> 00:33:55,190
to to to be okay with it so this is our

00:33:52,160 --> 00:34:00,380
current state right now our data

00:33:55,190 --> 00:34:04,100
collection system Auto scales by itself

00:34:00,380 --> 00:34:06,410
so based on the traffic pattern we scale

00:34:04,100 --> 00:34:09,490
up or scale in the infrastructure and

00:34:06,410 --> 00:34:11,960
this is done using auto scale policies

00:34:09,490 --> 00:34:13,580
so basically we monitored a number of

00:34:11,960 --> 00:34:16,100
requests or the load on the servers and

00:34:13,580 --> 00:34:20,360
based on that we can easily scale

00:34:16,100 --> 00:34:22,070
infrastructure up on or down so right

00:34:20,360 --> 00:34:24,110
now both a studies and engineers are

00:34:22,070 --> 00:34:27,020
performing day-to-day operational tests

00:34:24,110 --> 00:34:31,880
so we migrated to a unified on-call

00:34:27,020 --> 00:34:33,710
schema we also have been using lately

00:34:31,880 --> 00:34:37,280
spinnaker in a multi kubernetes cluster

00:34:33,710 --> 00:34:39,770
setup so we hooked spinnaker across

00:34:37,280 --> 00:34:42,020
multiple kubernetes clusters and from a

00:34:39,770 --> 00:34:45,950
single you are you can deploy your app

00:34:42,020 --> 00:34:48,530
easily on different AWS accounts or in

00:34:45,950 --> 00:34:50,030
different regions but also on different

00:34:48,530 --> 00:34:51,650
cloud providers

00:34:50,030 --> 00:34:54,770
so right now we are experimenting

00:34:51,650 --> 00:34:56,600
deploying applications in both AWS and

00:34:54,770 --> 00:35:01,610
Asia using spinnaker and the immutable

00:34:56,600 --> 00:35:04,130
infrastructure concept and yeah and a

00:35:01,610 --> 00:35:06,970
lot of projects within Adobe have

00:35:04,130 --> 00:35:12,710
started using spinnaker for their

00:35:06,970 --> 00:35:16,550
deployments that's about it so here is

00:35:12,710 --> 00:35:19,250
our contact information in case you want

00:35:16,550 --> 00:35:23,270
to find out more the ec2 shredder which

00:35:19,250 --> 00:35:26,350
we've open source can be taken from our

00:35:23,270 --> 00:35:31,910
github repo so in case you have any

00:35:26,350 --> 00:35:34,180
questions now it's the time to to ask

00:35:31,910 --> 00:35:34,180
them

00:35:38,270 --> 00:35:44,000
all right be sure to also rate the

00:35:41,450 --> 00:35:46,790
session if you found it helpful and

00:35:44,000 --> 00:35:48,710
thank you so much for having us today

00:35:46,790 --> 00:35:50,889
thank you

00:35:48,710 --> 00:35:50,889

YouTube URL: https://www.youtube.com/watch?v=Pc_V33UrpWk


