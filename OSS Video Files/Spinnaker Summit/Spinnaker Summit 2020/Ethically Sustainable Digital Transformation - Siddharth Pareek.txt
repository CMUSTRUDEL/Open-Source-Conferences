Title: Ethically Sustainable Digital Transformation - Siddharth Pareek
Publication date: 2021-01-28
Playlist: Spinnaker Summit 2020
Description: 
	Post COVID19 the urge and the need for digital transformation have taken great strides. Hence plans and actions thereof are moving at a faster rate than never before in order to achieve the goals and objectives set across by the respective organization. However in this frantic race, how much one is focusing on environmental sustainability and the ethical aspect of the digital transformation. Probably many would have heard either for the first or after a long time while reading this abstract here. In this presentation Siddharth will talk about: 1) Why Digital Ethics Matter 2) How Digital Transformation linked with Sustainability. 3) What are the Challenges while defining digital ethics 4) Opportunities that lies ahead for Organizations
Captions: 
	00:00:00,530 --> 00:00:03,629
[Music]

00:00:05,440 --> 00:00:08,400
hello

00:00:06,000 --> 00:00:10,480
good day everyone and uh welcome to the

00:00:08,400 --> 00:00:12,719
spinnaker summit 2020

00:00:10,480 --> 00:00:13,840
i hope you are enjoying with the great

00:00:12,719 --> 00:00:17,520
speakers lined up

00:00:13,840 --> 00:00:20,400
and absolutely of wonderful content uh

00:00:17,520 --> 00:00:22,320
being shared across here my name is sad

00:00:20,400 --> 00:00:24,680
parikh and i'll be talking about

00:00:22,320 --> 00:00:27,439
ethnically sustainable digital

00:00:24,680 --> 00:00:31,840
transformation

00:00:27,439 --> 00:00:31,840
so let's kick off

00:00:31,920 --> 00:00:38,160
so this is about me uh why

00:00:35,360 --> 00:00:39,360
work for natwest group uh more about not

00:00:38,160 --> 00:00:42,840
first group in

00:00:39,360 --> 00:00:44,480
a couple of few slides there in the

00:00:42,840 --> 00:00:47,840
session uh

00:00:44,480 --> 00:00:50,960
i work as the global devops

00:00:47,840 --> 00:00:53,360
coa practice lead member

00:00:50,960 --> 00:00:54,480
out there i'm also the co-author of the

00:00:53,360 --> 00:00:56,719
white paper

00:00:54,480 --> 00:00:57,600
on digital skills that was recently

00:00:56,719 --> 00:01:00,160
published

00:00:57,600 --> 00:01:01,199
amongst the board of the expert panel

00:01:00,160 --> 00:01:03,680
for

00:01:01,199 --> 00:01:05,040
devops institute cloud connection

00:01:03,680 --> 00:01:07,119
council

00:01:05,040 --> 00:01:08,720
and the dasa devops agile and skill

00:01:07,119 --> 00:01:11,439
association so

00:01:08,720 --> 00:01:13,840
this is about me let's kick off the

00:01:11,439 --> 00:01:13,840
session

00:01:16,400 --> 00:01:23,759
technology is

00:01:19,920 --> 00:01:25,360
has not the ethics ethics are the moral

00:01:23,759 --> 00:01:28,720
principles that govern

00:01:25,360 --> 00:01:31,840
a person or a group's behavior

00:01:28,720 --> 00:01:34,400
so with this uh let me introduce about

00:01:31,840 --> 00:01:36,400
the organization which i represent which

00:01:34,400 --> 00:01:38,880
is the natwest group

00:01:36,400 --> 00:01:41,520
the nightmares group and its brands are

00:01:38,880 --> 00:01:43,920
made up of hundreds of past banks

00:01:41,520 --> 00:01:45,600
they were all different large and small

00:01:43,920 --> 00:01:48,799
city and country

00:01:45,600 --> 00:01:51,040
traditional and innovative and grew to

00:01:48,799 --> 00:01:54,000
serve the banking needs of

00:01:51,040 --> 00:01:54,880
unique communities all over the united

00:01:54,000 --> 00:01:57,200
kingdom

00:01:54,880 --> 00:01:59,840
each one has left its mark on our

00:01:57,200 --> 00:02:02,479
identity today each of our brands

00:01:59,840 --> 00:02:03,759
has its own unique history so let's talk

00:02:02,479 --> 00:02:06,960
about the first

00:02:03,759 --> 00:02:10,479
natwest or national westminster uh

00:02:06,960 --> 00:02:13,360
bank which was launched in 1970

00:02:10,479 --> 00:02:14,480
but traces his origin to more than 200

00:02:13,360 --> 00:02:16,879
smaller banks

00:02:14,480 --> 00:02:17,760
founded in communities all over england

00:02:16,879 --> 00:02:19,840
and wolves

00:02:17,760 --> 00:02:22,560
royal bank of scotland founded in

00:02:19,840 --> 00:02:24,879
edinburgh in 1727 and went on to become

00:02:22,560 --> 00:02:28,319
one of the biggest banks in scotland

00:02:24,879 --> 00:02:30,480
also bank established in belfast in 1836

00:02:28,319 --> 00:02:32,480
and subsequently expanded throughout the

00:02:30,480 --> 00:02:33,360
ireland isle of man bank the first

00:02:32,480 --> 00:02:35,440
company

00:02:33,360 --> 00:02:38,560
to be formed under the isle of man's

00:02:35,440 --> 00:02:41,040
company act of 1865 and has remained

00:02:38,560 --> 00:02:42,239
an important part of life on the island

00:02:41,040 --> 00:02:43,840
ever since coach

00:02:42,239 --> 00:02:46,319
the london-based private bank

00:02:43,840 --> 00:02:48,239
established in 1692

00:02:46,319 --> 00:02:50,400
charlene company the oldest name is

00:02:48,239 --> 00:02:52,480
still trading in british banking dating

00:02:50,400 --> 00:02:54,560
back to the 1640s

00:02:52,480 --> 00:02:55,680
drama this traces its origin to a

00:02:54,560 --> 00:02:59,360
business founded by

00:02:55,680 --> 00:03:02,000
london goldsmiths in about 1712.

00:02:59,360 --> 00:03:02,640
halt started as an army pageant scene

00:03:02,000 --> 00:03:05,920
about

00:03:02,640 --> 00:03:08,080
1809 and later developed into a bank by

00:03:05,920 --> 00:03:09,519
introducing banking services for the

00:03:08,080 --> 00:03:11,840
army officers

00:03:09,519 --> 00:03:13,599
lombard started as a railway wagon

00:03:11,840 --> 00:03:17,360
leasing company in rotten

00:03:13,599 --> 00:03:21,360
in 1861.

00:03:17,360 --> 00:03:23,040
coming to our 2019 annual report here is

00:03:21,360 --> 00:03:25,040
what it looks like

00:03:23,040 --> 00:03:27,200
the bank delivered a performance which

00:03:25,040 --> 00:03:28,000
was generating a pre-tax operating

00:03:27,200 --> 00:03:31,440
profit of

00:03:28,000 --> 00:03:34,480
over 4.2 billion pounds we have

00:03:31,440 --> 00:03:37,840
asper 2019 annual report over

00:03:34,480 --> 00:03:38,560
seven million digitally active users and

00:03:37,840 --> 00:03:40,640
i think

00:03:38,560 --> 00:03:41,599
with this covert with this pandemic

00:03:40,640 --> 00:03:45,040
happens

00:03:41,599 --> 00:03:47,840
this has grown tremendously we are also

00:03:45,040 --> 00:03:50,319
becoming more diversive and inclusive

00:03:47,840 --> 00:03:52,560
bank our renewed sense of purpose

00:03:50,319 --> 00:03:53,920
is reflected in continued efforts to

00:03:52,560 --> 00:03:56,640
become more diverse

00:03:53,920 --> 00:03:58,159
and inclusive we are making progress

00:03:56,640 --> 00:04:00,879
towards our goal of having

00:03:58,159 --> 00:04:01,360
at least 30 percent senior womenship in

00:04:00,879 --> 00:04:03,599
our

00:04:01,360 --> 00:04:05,840
top three leadership players in each of

00:04:03,599 --> 00:04:08,159
our businesses by 2020

00:04:05,840 --> 00:04:09,519
and also to be fully gender balanced

00:04:08,159 --> 00:04:14,159
across the bank

00:04:09,519 --> 00:04:17,040
by 2030.

00:04:14,159 --> 00:04:19,040
knowing what's right doesn't mean much

00:04:17,040 --> 00:04:21,359
unless you do what's right

00:04:19,040 --> 00:04:22,400
that is what theodore roosevelt talked

00:04:21,359 --> 00:04:24,960
about

00:04:22,400 --> 00:04:26,639
and with this let me introduce the term

00:04:24,960 --> 00:04:31,440
for the session today

00:04:26,639 --> 00:04:31,440
the talk today which is ethics

00:04:31,759 --> 00:04:35,919
ethics is the discipline of making a

00:04:34,880 --> 00:04:39,759
principal

00:04:35,919 --> 00:04:42,880
decision between right and wrong

00:04:39,759 --> 00:04:46,000
focusing on how persons can behave

00:04:42,880 --> 00:04:47,919
not how they behave and while the

00:04:46,000 --> 00:04:49,120
subject has struggled in the past to

00:04:47,919 --> 00:04:52,160
gain recognition

00:04:49,120 --> 00:04:52,720
from the business community now things

00:04:52,160 --> 00:04:56,240
are

00:04:52,720 --> 00:04:58,479
happily very different in a

00:04:56,240 --> 00:04:59,440
highly competitive market where

00:04:58,479 --> 00:05:02,800
credibility

00:04:59,440 --> 00:05:05,919
and ideals are now as important

00:05:02,800 --> 00:05:09,120
as goods and services ethics is

00:05:05,919 --> 00:05:12,360
not only an important factor within an

00:05:09,120 --> 00:05:15,360
enterprise it represents a key

00:05:12,360 --> 00:05:15,360
differentiator

00:05:16,000 --> 00:05:20,960
so where does this digital ethics uh

00:05:18,639 --> 00:05:22,320
term originated or where that idea was

00:05:20,960 --> 00:05:25,759
resonated

00:05:22,320 --> 00:05:28,160
in 1985 james moore wrote an

00:05:25,759 --> 00:05:29,520
award-winning essay that argued for the

00:05:28,160 --> 00:05:33,360
spatial status

00:05:29,520 --> 00:05:37,120
of what he called computer ethics

00:05:33,360 --> 00:05:40,160
as a field of study in its own right

00:05:37,120 --> 00:05:43,280
you can pick digital ethics from here on

00:05:40,160 --> 00:05:43,919
he defined this as the analysis of the

00:05:43,280 --> 00:05:48,160
nature

00:05:43,919 --> 00:05:50,560
and social impact of computer technology

00:05:48,160 --> 00:05:52,639
and the corresponding formulation and

00:05:50,560 --> 00:05:55,680
justification of policies

00:05:52,639 --> 00:05:57,120
for the ethical uh use of search

00:05:55,680 --> 00:06:00,240
technology

00:05:57,120 --> 00:06:04,400
hence the goal of a mature digital

00:06:00,240 --> 00:06:07,759
ethics is to rest on a form of analysis

00:06:04,400 --> 00:06:08,720
that can predict or explain the impact

00:06:07,759 --> 00:06:12,319
of the

00:06:08,720 --> 00:06:15,120
emerging technologies on society

00:06:12,319 --> 00:06:15,840
and prescribe policies to ensure

00:06:15,120 --> 00:06:19,120
socially

00:06:15,840 --> 00:06:22,240
desirable outcome

00:06:19,120 --> 00:06:25,680
moose analysis of the issue

00:06:22,240 --> 00:06:29,039
facing the development and institutional

00:06:25,680 --> 00:06:35,840
application of digital ethics is still

00:06:29,039 --> 00:06:35,840
highly relevant today

00:06:36,240 --> 00:06:43,280
ethics begins where the regulation

00:06:40,240 --> 00:06:46,800
ends with this

00:06:43,280 --> 00:06:48,720
let me talk about how much impact does

00:06:46,800 --> 00:06:51,840
this digital transformation

00:06:48,720 --> 00:06:55,120
journeys up in today's time

00:06:51,840 --> 00:06:56,160
has impacted our nature environment or

00:06:55,120 --> 00:06:59,840
in other words

00:06:56,160 --> 00:06:59,840
the carbon footprint

00:07:00,240 --> 00:07:03,599
if you talk about the resource

00:07:02,560 --> 00:07:07,280
consumption

00:07:03,599 --> 00:07:08,960
on average 52 percent of all data stored

00:07:07,280 --> 00:07:12,080
by organization worldwide

00:07:08,960 --> 00:07:15,120
is dark because there is little idea

00:07:12,080 --> 00:07:17,599
about its quality or

00:07:15,120 --> 00:07:18,880
meaning from those responsible for

00:07:17,599 --> 00:07:22,560
handling it

00:07:18,880 --> 00:07:26,400
so according to 2019 um veritas

00:07:22,560 --> 00:07:29,440
middle east data book survey

00:07:26,400 --> 00:07:30,000
for example in the uae dark data stands

00:07:29,440 --> 00:07:33,440
at around

00:07:30,000 --> 00:07:36,479
47 percent much has been said

00:07:33,440 --> 00:07:39,199
about the economic cost of dark data but

00:07:36,479 --> 00:07:40,880
so far the environmental cost has often

00:07:39,199 --> 00:07:44,000
been ignored

00:07:40,880 --> 00:07:47,120
analysis experts that by 2025

00:07:44,000 --> 00:07:48,720
the volume of that data the global store

00:07:47,120 --> 00:07:53,759
will rise from 33

00:07:48,720 --> 00:07:56,639
zetabytes in 2018 to 175 zero bytes

00:07:53,759 --> 00:07:57,120
and for your uh reference zeta byte is

00:07:56,639 --> 00:08:00,479
one

00:07:57,120 --> 00:08:01,759
sixtillion bytes this suggests that

00:08:00,479 --> 00:08:05,680
there will be

00:08:01,759 --> 00:08:08,479
91 zetabytes of dark data in five years

00:08:05,680 --> 00:08:11,039
unless people change their habits over

00:08:08,479 --> 00:08:13,680
four times the amount we have now

00:08:11,039 --> 00:08:14,879
and all the resources associated and

00:08:13,680 --> 00:08:18,560
powering the network

00:08:14,879 --> 00:08:22,080
in which it exists digital devices

00:08:18,560 --> 00:08:24,400
gartner estimates that there will be

00:08:22,080 --> 00:08:25,520
approximately over nine billion

00:08:24,400 --> 00:08:28,800
connected device

00:08:25,520 --> 00:08:30,879
by 2017 with a number which will expect

00:08:28,800 --> 00:08:33,599
to rise more than 20 billion

00:08:30,879 --> 00:08:35,680
by the year end seventy to ninety

00:08:33,599 --> 00:08:36,959
percent of the total pollution caused by

00:08:35,680 --> 00:08:40,320
a digital device

00:08:36,959 --> 00:08:42,800
is caused during its manufacturer

00:08:40,320 --> 00:08:43,360
what this mean is that the moment you

00:08:42,800 --> 00:08:45,920
buy an

00:08:43,360 --> 00:08:46,720
e-reader you acquire something that has

00:08:45,920 --> 00:08:50,320
already

00:08:46,720 --> 00:08:52,880
caused very significant pollution

00:08:50,320 --> 00:08:53,519
it needs to be used a lot before it is

00:08:52,880 --> 00:08:55,519
better

00:08:53,519 --> 00:08:57,040
for the environment than reading in

00:08:55,519 --> 00:09:00,560
print

00:08:57,040 --> 00:09:04,399
the email uh co2 edition every day

00:09:00,560 --> 00:09:08,480
we send and receive over 125 billion

00:09:04,399 --> 00:09:09,360
business emails and 117 billion consumer

00:09:08,480 --> 00:09:11,440
emails

00:09:09,360 --> 00:09:12,720
with little realization of the pollution

00:09:11,440 --> 00:09:16,640
this creates

00:09:12,720 --> 00:09:20,160
60 of the emails goes unopened

00:09:16,640 --> 00:09:23,760
a carbon footprint of 1.5 million

00:09:20,160 --> 00:09:26,800
unuseful tons of co2 sending an email

00:09:23,760 --> 00:09:29,120
adds an extra 4 grams of co2

00:09:26,800 --> 00:09:32,000
to the environment according to the

00:09:29,120 --> 00:09:35,760
studies by spices.org

00:09:32,000 --> 00:09:37,200
sending 65 mil emails is equivalent of

00:09:35,760 --> 00:09:40,720
driving a car

00:09:37,200 --> 00:09:43,360
one kilometer or approximately 0.6 miles

00:09:40,720 --> 00:09:45,200
putting this into perspective this is

00:09:43,360 --> 00:09:48,240
also supported by the servers

00:09:45,200 --> 00:09:48,720
routers and the machine themselves you

00:09:48,240 --> 00:09:51,920
will bring

00:09:48,720 --> 00:09:55,200
50 gram of co2 into the air with an

00:09:51,920 --> 00:09:58,959
attachment attached it is same

00:09:55,200 --> 00:10:01,760
as burning 120 grams of coal to send

00:09:58,959 --> 00:10:04,480
five of these letters and what about the

00:10:01,760 --> 00:10:07,360
8-bit advice bins

00:10:04,480 --> 00:10:08,640
that are unwarranted it is reported that

00:10:07,360 --> 00:10:12,000
spam emails

00:10:08,640 --> 00:10:15,680
also unopened account for 0.3

00:10:12,000 --> 00:10:18,800
grams of co2 and with the number of spam

00:10:15,680 --> 00:10:19,760
emails reaching an all-time low in 2015

00:10:18,800 --> 00:10:23,040
way back

00:10:19,760 --> 00:10:23,519
the figures are increasing again and 14

00:10:23,040 --> 00:10:26,399
span

00:10:23,519 --> 00:10:28,320
emails were sent over every day in the

00:10:26,399 --> 00:10:30,640
year 2016.

00:10:28,320 --> 00:10:31,680
think of you know we are five years down

00:10:30,640 --> 00:10:35,040
the lane now

00:10:31,680 --> 00:10:35,760
since you can't stop such emails this is

00:10:35,040 --> 00:10:40,160
basically an

00:10:35,760 --> 00:10:43,279
automatic edition of 4.2 grams of co2

00:10:40,160 --> 00:10:46,480
per person per day and an ear

00:10:43,279 --> 00:10:49,680
without ever clicking on their emails

00:10:46,480 --> 00:10:54,399
that means a business user generates

00:10:49,680 --> 00:10:57,360
around 15 33 grams of co2 emissions

00:10:54,399 --> 00:10:59,279
which is just from spam and automated

00:10:57,360 --> 00:11:01,680
emails such as newsletters

00:10:59,279 --> 00:11:03,519
electricity consumption the fact that

00:11:01,680 --> 00:11:06,000
the digital economy

00:11:03,519 --> 00:11:06,640
uh generates tremendous demand for

00:11:06,000 --> 00:11:10,320
computing

00:11:06,640 --> 00:11:11,200
power is no escape and the powering and

00:11:10,320 --> 00:11:14,320
the cooling

00:11:11,200 --> 00:11:16,079
of servers requires enormous quantity of

00:11:14,320 --> 00:11:18,640
energy

00:11:16,079 --> 00:11:19,680
the energy demand of let's say the

00:11:18,640 --> 00:11:22,800
bitcoin

00:11:19,680 --> 00:11:26,000
has measured to be approximately

00:11:22,800 --> 00:11:29,519
equal to 20 mega

00:11:26,000 --> 00:11:33,200
tons of co2 or 1 million

00:11:29,519 --> 00:11:34,160
translated files the carbon footprints

00:11:33,200 --> 00:11:37,120
of the song

00:11:34,160 --> 00:11:37,680
despicator is typically equal to the

00:11:37,120 --> 00:11:41,120
annual

00:11:37,680 --> 00:11:44,480
emission of around 100 000

00:11:41,120 --> 00:11:45,600
taxis with almost five billion views on

00:11:44,480 --> 00:11:48,079
youtube

00:11:45,600 --> 00:11:48,880
overall it is predicted that the digital

00:11:48,079 --> 00:11:52,000
economy

00:11:48,880 --> 00:11:55,360
will account for around seven percent of

00:11:52,000 --> 00:11:56,160
world electricity consumption and is

00:11:55,360 --> 00:11:59,720
expected

00:11:56,160 --> 00:12:02,720
to grow to 12 percent by

00:11:59,720 --> 00:12:02,720
2020.

00:12:04,560 --> 00:12:11,360
liberty applies to physics

00:12:07,839 --> 00:12:13,200
not ethics that is what albert einstein

00:12:11,360 --> 00:12:16,240
said

00:12:13,200 --> 00:12:17,920
so let's move on to what could we

00:12:16,240 --> 00:12:22,839
possibly do

00:12:17,920 --> 00:12:25,839
to make digital transformation ethically

00:12:22,839 --> 00:12:25,839
sustainable

00:12:27,920 --> 00:12:35,200
the recent capgemini research institute

00:12:32,399 --> 00:12:36,560
found out that executives in nine out of

00:12:35,200 --> 00:12:39,040
ten companies

00:12:36,560 --> 00:12:40,880
agreed that the use of artificial

00:12:39,040 --> 00:12:43,600
intelligence systems

00:12:40,880 --> 00:12:45,920
over the last two to three years has

00:12:43,600 --> 00:12:47,920
resulted in ethical problems

00:12:45,920 --> 00:12:50,320
half of the surveyed customers which is

00:12:47,920 --> 00:12:52,240
approximately 47 percent

00:12:50,320 --> 00:12:54,399
claimed that in the last two to three

00:12:52,240 --> 00:12:57,920
years they have encountered at least two

00:12:54,399 --> 00:12:58,560
forms of ai uses that have resulted in

00:12:57,920 --> 00:13:01,600
ethical

00:12:58,560 --> 00:13:02,800
issues 62 persons said they they would

00:13:01,600 --> 00:13:05,839
put greater

00:13:02,800 --> 00:13:09,279
trust in a business whose ai

00:13:05,839 --> 00:13:12,639
interaction they viewed as ethical

00:13:09,279 --> 00:13:14,399
so what should be done the one thing is

00:13:12,639 --> 00:13:17,120
the first thing that could be done is

00:13:14,399 --> 00:13:19,600
the ai partners who subscribe to human

00:13:17,120 --> 00:13:22,880
ethical values and social conduct

00:13:19,600 --> 00:13:24,320
must be looked for managing bias and

00:13:22,880 --> 00:13:27,600
possible misuse

00:13:24,320 --> 00:13:30,399
would be two significant elements

00:13:27,600 --> 00:13:32,240
point number two for clients and

00:13:30,399 --> 00:13:35,440
employee facing teams

00:13:32,240 --> 00:13:38,399
are such as hr marketing communication

00:13:35,440 --> 00:13:39,440
and customer service ensuring ethical

00:13:38,399 --> 00:13:42,880
use of the ai

00:13:39,440 --> 00:13:46,639
applications educating and informing the

00:13:42,880 --> 00:13:49,440
users to build faith in the ai system

00:13:46,639 --> 00:13:51,440
providing users with more autonomy and

00:13:49,440 --> 00:13:54,079
the right to pursue recourse

00:13:51,440 --> 00:13:55,199
and engaging internally and externally

00:13:54,079 --> 00:13:59,680
proactively

00:13:55,199 --> 00:14:02,399
on the ai issues to build the confidence

00:13:59,680 --> 00:14:03,519
point number three integrating ethics

00:14:02,399 --> 00:14:07,199
into the policy

00:14:03,519 --> 00:14:11,120
of the company by setting up a board of

00:14:07,199 --> 00:14:14,160
ethics or naming a chief ethics officer

00:14:11,120 --> 00:14:17,040
who works closely with business units

00:14:14,160 --> 00:14:17,519
and supervises efforts to direct the use

00:14:17,040 --> 00:14:20,480
of

00:14:17,519 --> 00:14:21,120
technology in beneficial ways for

00:14:20,480 --> 00:14:24,079
example

00:14:21,120 --> 00:14:25,760
salesforce has appointed a chief ethical

00:14:24,079 --> 00:14:28,959
and human use officer

00:14:25,760 --> 00:14:32,079
to guide the company's use of technology

00:14:28,959 --> 00:14:35,600
point number four to be accountable uh

00:14:32,079 --> 00:14:38,800
to all entities you need to integrate

00:14:35,600 --> 00:14:39,920
privacy designs into ai systems you need

00:14:38,800 --> 00:14:42,639
to increase

00:14:39,920 --> 00:14:43,839
data or transparency so that for

00:14:42,639 --> 00:14:47,360
training purposes

00:14:43,839 --> 00:14:48,959
or ai developers have access to broad

00:14:47,360 --> 00:14:51,680
data set

00:14:48,959 --> 00:14:53,839
you need to hire ethics to collaborate

00:14:51,680 --> 00:14:56,800
with the creators of software

00:14:53,839 --> 00:14:58,000
and corporate decision makers in tantrum

00:14:56,800 --> 00:15:01,519
to stop violence

00:14:58,000 --> 00:15:04,560
have good legal standards

00:15:01,519 --> 00:15:07,760
so to summarize on this slide

00:15:04,560 --> 00:15:08,639
it is the confrontation between on the

00:15:07,760 --> 00:15:12,160
one hand

00:15:08,639 --> 00:15:14,959
the utilian calculations that decide

00:15:12,160 --> 00:15:16,720
optimal well-being and on the other hand

00:15:14,959 --> 00:15:19,920
if human life is to have

00:15:16,720 --> 00:15:20,639
meaning at all the ethical duties that

00:15:19,920 --> 00:15:23,680
we need to

00:15:20,639 --> 00:15:26,720
overcome the real danger of

00:15:23,680 --> 00:15:29,839
a ai whatever science fiction

00:15:26,720 --> 00:15:33,040
they tell us is not that machines

00:15:29,839 --> 00:15:33,600
become aware and turns against us the

00:15:33,040 --> 00:15:37,199
real

00:15:33,600 --> 00:15:42,320
danger is that the

00:15:37,199 --> 00:15:42,320
ai reduces human beings

00:15:42,959 --> 00:15:49,920
without regard for human beliefs

00:15:46,320 --> 00:15:53,440
ideals and expectations to mere

00:15:49,920 --> 00:15:56,079
numbers and unit it is our job

00:15:53,440 --> 00:15:58,160
now to set the right limits for

00:15:56,079 --> 00:16:01,040
artificial intelligence

00:15:58,160 --> 00:16:02,079
we have to ensure the legal standards

00:16:01,040 --> 00:16:05,440
and principles

00:16:02,079 --> 00:16:06,560
are adopted by this most exciting

00:16:05,440 --> 00:16:10,000
technologies

00:16:06,560 --> 00:16:13,519
at its heart its place is human beings

00:16:10,000 --> 00:16:17,360
our future depends on ensuring that

00:16:13,519 --> 00:16:20,839
tomorrow's ai systems honor the beliefs

00:16:17,360 --> 00:16:23,839
and values that make them gay as

00:16:20,839 --> 00:16:23,839
humans

00:16:24,160 --> 00:16:26,959
the next is

00:16:28,199 --> 00:16:34,160
transparency

00:16:31,199 --> 00:16:35,680
the fundamental principle that govern

00:16:34,160 --> 00:16:38,720
professional conduct

00:16:35,680 --> 00:16:40,560
must be transparency and integrity in

00:16:38,720 --> 00:16:44,000
the digital world

00:16:40,560 --> 00:16:47,360
organizations must use information

00:16:44,000 --> 00:16:48,160
in responsible and ethical ways and that

00:16:47,360 --> 00:16:51,279
means

00:16:48,160 --> 00:16:55,519
not using it in ways that are deemed

00:16:51,279 --> 00:16:56,639
invasive misleading or disrespectful to

00:16:55,519 --> 00:16:59,440
others

00:16:56,639 --> 00:17:00,480
being open means that organizations need

00:16:59,440 --> 00:17:03,680
to state

00:17:00,480 --> 00:17:04,400
their data use intentions and allow

00:17:03,680 --> 00:17:07,679
their clients

00:17:04,400 --> 00:17:08,880
to give their consent the amount of

00:17:07,679 --> 00:17:12,000
consumer data

00:17:08,880 --> 00:17:15,439
that they collect and monetize

00:17:12,000 --> 00:17:19,120
is also criticized by the organizations

00:17:15,439 --> 00:17:21,439
the disconnection or the lack of clarity

00:17:19,120 --> 00:17:24,079
around the value exchange between

00:17:21,439 --> 00:17:27,199
clients and service provider

00:17:24,079 --> 00:17:30,559
is part of the challenge here

00:17:27,199 --> 00:17:34,000
and any advantages obtained from

00:17:30,559 --> 00:17:38,559
personal data collection must be

00:17:34,000 --> 00:17:42,320
stored by both parties and not used for

00:17:38,559 --> 00:17:43,280
monetary benefit the second aspect over

00:17:42,320 --> 00:17:45,760
here is

00:17:43,280 --> 00:17:47,840
is about improving transparency around

00:17:45,760 --> 00:17:49,120
business models which are powered by

00:17:47,840 --> 00:17:51,919
data

00:17:49,120 --> 00:17:53,039
now business here should take steps to

00:17:51,919 --> 00:17:55,919
help customers

00:17:53,039 --> 00:17:59,120
understand the complexities that might

00:17:55,919 --> 00:18:02,400
currently be opaque in data transactions

00:17:59,120 --> 00:18:06,559
it could help to restore faith to find

00:18:02,400 --> 00:18:08,240
ways to create a two-way equal exchange

00:18:06,559 --> 00:18:10,080
of data

00:18:08,240 --> 00:18:12,880
constructive communications with

00:18:10,080 --> 00:18:15,840
customers on data monetization

00:18:12,880 --> 00:18:18,080
for example can help to bring greater

00:18:15,840 --> 00:18:21,120
transparency and relationships

00:18:18,080 --> 00:18:24,400
that are more trusted

00:18:21,120 --> 00:18:25,520
so to summarize uh the companies can

00:18:24,400 --> 00:18:28,720
create trust

00:18:25,520 --> 00:18:29,440
with stakeholders by exhibiting good

00:18:28,720 --> 00:18:32,799
conduct

00:18:29,440 --> 00:18:33,840
proactively and transparently it doesn't

00:18:32,799 --> 00:18:36,240
really matter

00:18:33,840 --> 00:18:37,200
whether people are interested in seeing

00:18:36,240 --> 00:18:40,320
the money

00:18:37,200 --> 00:18:41,600
and data behind it or not simply

00:18:40,320 --> 00:18:44,880
recognizing that

00:18:41,600 --> 00:18:47,760
organizations have open policies create

00:18:44,880 --> 00:18:48,960
more trust that they are doing the right

00:18:47,760 --> 00:18:52,799
thing

00:18:48,960 --> 00:18:55,520
transparency goes beyond policies

00:18:52,799 --> 00:18:56,960
that clarify data collection and use

00:18:55,520 --> 00:18:59,679
practices

00:18:56,960 --> 00:19:00,960
companies should report the use of

00:18:59,679 --> 00:19:03,840
automated

00:19:00,960 --> 00:19:04,799
let's say decian systems that impact

00:19:03,840 --> 00:19:07,440
clients and when

00:19:04,799 --> 00:19:08,559
issues arrived should remain

00:19:07,440 --> 00:19:12,160
concentrated

00:19:08,559 --> 00:19:16,640
on the client ensuring both speed

00:19:12,160 --> 00:19:16,640
and consistency in response

00:19:18,400 --> 00:19:25,520
the next is we need to go beyond

00:19:21,600 --> 00:19:26,559
just compliance now ethical technology

00:19:25,520 --> 00:19:29,120
knowledge

00:19:26,559 --> 00:19:29,840
recognition and the decision-making

00:19:29,120 --> 00:19:31,760
process

00:19:29,840 --> 00:19:33,919
should be part of the cultural dna of

00:19:31,760 --> 00:19:36,640
the company and not just a compliance or

00:19:33,919 --> 00:19:38,080
policy practice it is important that

00:19:36,640 --> 00:19:40,400
everyone in the company

00:19:38,080 --> 00:19:42,320
understand possible ethical dilemmas

00:19:40,400 --> 00:19:44,559
related to technology

00:19:42,320 --> 00:19:46,799
ethical reform drivers into better

00:19:44,559 --> 00:19:47,840
future one built on truly ethical

00:19:46,799 --> 00:19:50,400
businesses

00:19:47,840 --> 00:19:51,120
but that isn't a fact it's pretty hard

00:19:50,400 --> 00:19:53,919
in truth

00:19:51,120 --> 00:19:54,880
a need in time most of the corporate

00:19:53,919 --> 00:19:58,080
world has

00:19:54,880 --> 00:20:01,200
focused around what not to do or how

00:19:58,080 --> 00:20:03,280
not to get fined for decades

00:20:01,200 --> 00:20:04,400
compliance if i need to call out in a

00:20:03,280 --> 00:20:06,720
single word

00:20:04,400 --> 00:20:07,760
every so often as an after thought

00:20:06,720 --> 00:20:10,159
ethics and it's

00:20:07,760 --> 00:20:11,679
even more murky brother values had a

00:20:10,159 --> 00:20:14,799
little affection

00:20:11,679 --> 00:20:17,120
the ussa's and tom schuser world found

00:20:14,799 --> 00:20:19,200
bran that focused on morals and ethics

00:20:17,120 --> 00:20:22,320
to be acceptance to the law

00:20:19,200 --> 00:20:25,280
not anymore we are entering an

00:20:22,320 --> 00:20:26,480
era in which every single businesses

00:20:25,280 --> 00:20:28,720
must go from

00:20:26,480 --> 00:20:30,080
self-protective compliance with the

00:20:28,720 --> 00:20:32,960
check the box

00:20:30,080 --> 00:20:35,360
to a long-term emphasis on ethics

00:20:32,960 --> 00:20:37,520
principles and compliance

00:20:35,360 --> 00:20:39,440
companies if they have not already need

00:20:37,520 --> 00:20:42,559
to start making the changes now

00:20:39,440 --> 00:20:44,559
part is difficult to interest in

00:20:42,559 --> 00:20:46,400
the other concern is the constant

00:20:44,559 --> 00:20:48,960
adjustment to federal ethical

00:20:46,400 --> 00:20:50,960
legislation is one of the key challenges

00:20:48,960 --> 00:20:52,640
of adhering to the specific norms of

00:20:50,960 --> 00:20:55,600
ethical behavior

00:20:52,640 --> 00:20:57,919
an agile compliance platform ensures you

00:20:55,600 --> 00:21:00,559
still be prepared to adapt to new laws

00:20:57,919 --> 00:21:03,120
and keep up with the ethical requirement

00:21:00,559 --> 00:21:04,720
so to summarize the question that

00:21:03,120 --> 00:21:08,080
organization should ask

00:21:04,720 --> 00:21:09,280
themselves are such as uh to reduce the

00:21:08,080 --> 00:21:10,960
cost of compliance

00:21:09,280 --> 00:21:13,200
what technology investments are we

00:21:10,960 --> 00:21:13,840
exploring how do we use technology to

00:21:13,200 --> 00:21:17,200
ensure

00:21:13,840 --> 00:21:19,360
that we comply with our more successful

00:21:17,200 --> 00:21:22,159
programs

00:21:19,360 --> 00:21:24,320
and the last bit is the data protection

00:21:22,159 --> 00:21:25,840
ethics which should go beyond the legal

00:21:24,320 --> 00:21:29,200
requirements

00:21:25,840 --> 00:21:31,840
i adore the data all of us love the data

00:21:29,200 --> 00:21:32,799
without it there would be no technology

00:21:31,840 --> 00:21:36,000
no media

00:21:32,799 --> 00:21:36,720
nothing at all digital transformation is

00:21:36,000 --> 00:21:39,200
in truth

00:21:36,720 --> 00:21:40,559
a matter of data and the right

00:21:39,200 --> 00:21:43,919
information

00:21:40,559 --> 00:21:46,000
no one today knows what personal data is

00:21:43,919 --> 00:21:46,640
stored or processed and what happens to

00:21:46,000 --> 00:21:50,480
it

00:21:46,640 --> 00:21:54,159
not a market single noses you are not

00:21:50,480 --> 00:21:56,400
not me there is a need for laws and

00:21:54,159 --> 00:21:58,559
rules whether you like it or not

00:21:56,400 --> 00:22:00,240
since for the right reasons and paying

00:21:58,559 --> 00:22:03,360
all the attention it needs

00:22:00,240 --> 00:22:04,480
we owe to the clients individuals to

00:22:03,360 --> 00:22:07,280
value their data

00:22:04,480 --> 00:22:07,840
and make the right use of it since the

00:22:07,280 --> 00:22:11,120
data

00:22:07,840 --> 00:22:14,159
is about individuals and about people

00:22:11,120 --> 00:22:14,720
since individuals are not data just as

00:22:14,159 --> 00:22:18,000
your

00:22:14,720 --> 00:22:20,320
email address service tickets or cases

00:22:18,000 --> 00:22:21,679
are not so consideration that

00:22:20,320 --> 00:22:24,880
organization should take

00:22:21,679 --> 00:22:26,799
is to employ privacy of architects

00:22:24,880 --> 00:22:28,480
to determine their priorities and the

00:22:26,799 --> 00:22:30,320
privacy's law that they may have to

00:22:28,480 --> 00:22:32,159
comply with

00:22:30,320 --> 00:22:35,039
compliance with data protection

00:22:32,159 --> 00:22:37,200
legislations also does not guarantee

00:22:35,039 --> 00:22:38,480
that digital technologies are used

00:22:37,200 --> 00:22:41,679
effectively

00:22:38,480 --> 00:22:43,760
ethics going beyond legal standards is a

00:22:41,679 --> 00:22:46,000
far-reaching subject

00:22:43,760 --> 00:22:48,320
however enforcing the general data

00:22:46,000 --> 00:22:50,960
protection regulation the gdpr

00:22:48,320 --> 00:22:53,360
and its roots let's say will work as a

00:22:50,960 --> 00:22:56,640
good entry point for businesses to begin

00:22:53,360 --> 00:22:57,840
discussing digital ethics as processes

00:22:56,640 --> 00:22:59,919
are digitized

00:22:57,840 --> 00:23:00,960
concerns eventually arise about the

00:22:59,919 --> 00:23:03,520
source of the data

00:23:00,960 --> 00:23:04,159
used third party data access data

00:23:03,520 --> 00:23:06,960
protection

00:23:04,159 --> 00:23:08,080
replication storage and archiving

00:23:06,960 --> 00:23:09,919
comparison between

00:23:08,080 --> 00:23:11,520
countries particularly when it comes to

00:23:09,919 --> 00:23:13,760
handling personal data

00:23:11,520 --> 00:23:14,799
may expose various perceptions of

00:23:13,760 --> 00:23:17,280
privacy

00:23:14,799 --> 00:23:18,960
and this component of the creation of

00:23:17,280 --> 00:23:21,520
strategies for

00:23:18,960 --> 00:23:22,720
digital ethics is comparable to the

00:23:21,520 --> 00:23:25,600
context

00:23:22,720 --> 00:23:27,760
sensitive adoption of business

00:23:25,600 --> 00:23:29,280
strategies to confirm with the cultural

00:23:27,760 --> 00:23:32,000
values

00:23:29,280 --> 00:23:33,919
this enables the economic objectives of

00:23:32,000 --> 00:23:37,200
the business to be reconciled

00:23:33,919 --> 00:23:41,200
with trustworthy and transparent data

00:23:37,200 --> 00:23:44,880
handling so to summarize

00:23:41,200 --> 00:23:46,240
the epistemic gravitas and the moral

00:23:44,880 --> 00:23:48,840
rational

00:23:46,240 --> 00:23:50,000
for evaluating and handling digital

00:23:48,840 --> 00:23:52,480
technologies

00:23:50,000 --> 00:23:53,760
should be given by a mature field of

00:23:52,480 --> 00:23:56,240
digital ethics

00:23:53,760 --> 00:23:56,960
with the aim of maintaining the benefits

00:23:56,240 --> 00:23:59,840
of digital

00:23:56,960 --> 00:24:02,080
information while mitigating the

00:23:59,840 --> 00:24:04,640
potential harm

00:24:02,080 --> 00:24:06,480
as new affordance are delivered through

00:24:04,640 --> 00:24:09,760
digital tools

00:24:06,480 --> 00:24:12,000
new ethical dilemmas arise and

00:24:09,760 --> 00:24:13,679
a rigorous structure must be available

00:24:12,000 --> 00:24:16,480
to resolve them

00:24:13,679 --> 00:24:18,400
there is an urgent need to build and

00:24:16,480 --> 00:24:19,520
apply perspectives from this field of

00:24:18,400 --> 00:24:21,840
research

00:24:19,520 --> 00:24:23,840
given the spatial characteristics of

00:24:21,840 --> 00:24:26,799
digital technologies

00:24:23,840 --> 00:24:27,520
conceptual malleability transformating

00:24:26,799 --> 00:24:30,400
effects

00:24:27,520 --> 00:24:31,360
and the invisibility factor and these

00:24:30,400 --> 00:24:35,039
variables

00:24:31,360 --> 00:24:38,159
often make it nearly impossible

00:24:35,039 --> 00:24:41,360
to predict anticipate and

00:24:38,159 --> 00:24:44,320
mitigate any and all unforeseen

00:24:41,360 --> 00:24:45,679
impacts on the digital technology lack

00:24:44,320 --> 00:24:48,240
of 2024

00:24:45,679 --> 00:24:50,320
side however is not an excuse for

00:24:48,240 --> 00:24:52,880
letting the steering wheel go

00:24:50,320 --> 00:24:54,320
those in a position to influence and

00:24:52,880 --> 00:24:55,440
control the course of digital

00:24:54,320 --> 00:24:58,480
application

00:24:55,440 --> 00:25:02,400
have a responsibility to integrate

00:24:58,480 --> 00:25:05,360
ethics as a main innovation feature

00:25:02,400 --> 00:25:06,080
the successful companies in the digital

00:25:05,360 --> 00:25:09,520
economy

00:25:06,080 --> 00:25:10,720
will not only be mindful of ethical

00:25:09,520 --> 00:25:14,480
principles such as

00:25:10,720 --> 00:25:15,760
trust integrity justice confidentiality

00:25:14,480 --> 00:25:18,640
and accountability

00:25:15,760 --> 00:25:19,440
what will actively follow them to do the

00:25:18,640 --> 00:25:22,960
right thing

00:25:19,440 --> 00:25:26,159
and make above reproach decisions

00:25:22,960 --> 00:25:29,279
and final words digital transformation

00:25:26,159 --> 00:25:32,400
will affect all areas of society

00:25:29,279 --> 00:25:33,919
and to reach a sustainable inclusive and

00:25:32,400 --> 00:25:38,799
trustworthy outcomes

00:25:33,919 --> 00:25:38,799
business will need to be forced for good

00:25:38,960 --> 00:25:44,720
so let's strike the conversations uh

00:25:42,159 --> 00:25:45,760
if you have any ideas of how we can

00:25:44,720 --> 00:25:47,760
drive this idea

00:25:45,760 --> 00:25:50,159
of ethics into practice within wider

00:25:47,760 --> 00:25:51,919
community let's have conversations

00:25:50,159 --> 00:25:54,080
if you're looking for some consulting

00:25:51,919 --> 00:25:56,320
but no cost just a virtual tea and

00:25:54,080 --> 00:25:56,720
coffee in this pandemic times to drive

00:25:56,320 --> 00:25:58,480
it

00:25:56,720 --> 00:26:00,080
within your organization do get in touch

00:25:58,480 --> 00:26:02,240
with me if you

00:26:00,080 --> 00:26:03,440
uh through your efforts have gained some

00:26:02,240 --> 00:26:05,679
successes or

00:26:03,440 --> 00:26:06,480
you have some failure stories to share

00:26:05,679 --> 00:26:08,080
across

00:26:06,480 --> 00:26:09,679
uh let's talk let's have the

00:26:08,080 --> 00:26:12,080
conversation

00:26:09,679 --> 00:26:13,440
and with this i would like to thank uh

00:26:12,080 --> 00:26:16,960
also

00:26:13,440 --> 00:26:19,919
all these folks on which my talk

00:26:16,960 --> 00:26:20,480
has been based their research uh has

00:26:19,919 --> 00:26:23,679
been done

00:26:20,480 --> 00:26:26,000
on which my this whole presentation

00:26:23,679 --> 00:26:28,799
has been prepared so i would like to

00:26:26,000 --> 00:26:31,760
thank each one of these uh

00:26:28,799 --> 00:26:32,480
institutions and the organizations with

00:26:31,760 --> 00:26:35,440
this

00:26:32,480 --> 00:26:35,760
thank you so much have a lovely day uh

00:26:35,440 --> 00:26:38,960
and

00:26:35,760 --> 00:26:40,080
hope you enjoy the rest of the spinnaker

00:26:38,960 --> 00:26:47,919
summit

00:26:40,080 --> 00:26:47,919

YouTube URL: https://www.youtube.com/watch?v=ultTBmZZ7HA


