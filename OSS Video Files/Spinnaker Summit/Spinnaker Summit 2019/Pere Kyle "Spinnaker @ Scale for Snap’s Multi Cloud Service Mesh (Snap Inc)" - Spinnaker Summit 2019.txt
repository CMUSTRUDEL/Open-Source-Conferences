Title: Pere Kyle "Spinnaker @ Scale for Snap’s Multi Cloud Service Mesh (Snap Inc)" - Spinnaker Summit 2019
Publication date: 2019-12-03
Playlist: Spinnaker Summit 2019
Description: 
	In this talk we give the viewer a rare look at Snap’s cloud infrastructure, as well as the Service Mesh paradigm which is becoming increasingly popular amongst large tech companies. We plan to dive into the unique issues surrounding deploying to Service Mesh architectures, and how Snap is using Spinnaker to solve them. The talk will also highlight multiple different OSS technologies in use at Snap in conjunction with Spinnaker (Kubernetes, Envoy, Haproxy).

We have decided to go dual speaker in this talk to give the viewer two complementing voices. Pere is the original advocate and implementer of Spinnaker at Snap, pushing the project along through multiple scaling hurdles. Pere brings unique experience in scaling the Kubernetes use case of Spinnaker, as he has 4 years of Kubernetes deployment experience, and Snap has one of the largest Kubernetes uses in the industry. Jacques brings a wealth of experience in the security realm launching sensitive and challenging projects at Amazon (SWF, Amazon Go), and Snap (Service Mesh). He will discuss security best practices with respect to deploying Spinnaker, and highlight issues he found/fixed while working on this project.

Our talk will begin by giving the definition of what constitutes a Service Mesh, to give the viewer necessary context for the rest of the talk. Next, we will dive into some overviews to how Snap has implemented a Service Mesh in their organization, and talk briefly about the tooling involved. Next, we will dive into the issues around deploying to a Service Mesh type system, and how we can use Spinnaker to solve these issues. With the context of Snaps service mesh defined, we will move the talk towards more Spinnaker specific issues.

Next part of the talk will involve a deep dive on deploying Spinnaker to Kubernetes, and what scaling problems we have had/solved. This will give the viewer some good guidance on how they should deploy Spinnaker at their own organization. We will show the viewer our original and improved architecture designs for Spinnaker and give some detailed learnings that are actionable for any Spinnaker install. We will then go into detail on how we integrated a service into Spinnaker to enable Snap specific business rules, showing the viewer the extensibility of Spinnakers API. We will conclude the talk with future improvements planned to our system, and any future work we have slated for Spinnaker OSS.
Captions: 
	00:00:06,330 --> 00:00:12,900
[Laughter]

00:00:10,429 --> 00:00:16,890
my name is Perry I'm a software engineer

00:00:12,900 --> 00:00:19,260
at Snap I've been there for two years

00:00:16,890 --> 00:00:21,960
and primarily focusing on how can we

00:00:19,260 --> 00:00:25,019
deliver the snap chat app and its core

00:00:21,960 --> 00:00:28,050
features to our users as fast as

00:00:25,019 --> 00:00:29,550
possible and interestingly enough that I

00:00:28,050 --> 00:00:32,040
got there except I was always

00:00:29,550 --> 00:00:34,230
continuously deployed it's one of the

00:00:32,040 --> 00:00:37,200
advantages when you start from scratch

00:00:34,230 --> 00:00:38,550
and you have one big monolith which is

00:00:37,200 --> 00:00:41,730
something we'll talk about how we're

00:00:38,550 --> 00:00:44,640
breaking apart today but before that I

00:00:41,730 --> 00:00:47,280
wanted to make a huge shout out to the

00:00:44,640 --> 00:00:49,469
community the contributors sponsoring

00:00:47,280 --> 00:00:51,239
the speakers everyone new users and

00:00:49,469 --> 00:00:52,920
their input that helps us that we're

00:00:51,239 --> 00:00:55,079
kind of in our box and seeing how the

00:00:52,920 --> 00:00:56,250
users in their equites been occur but I

00:00:55,079 --> 00:00:57,899
want to get a big round of applause for

00:00:56,250 --> 00:01:00,359
everyone that's helped me along the way

00:00:57,899 --> 00:01:03,079
and I couldn't have made without all of

00:01:00,359 --> 00:01:03,079
you guys help

00:01:08,080 --> 00:01:14,210
see yeah so spit so Santa had a

00:01:11,420 --> 00:01:16,340
monolithic problem which is probably

00:01:14,210 --> 00:01:19,610
similar to what maybe you dealt with

00:01:16,340 --> 00:01:22,580
here so snapchat famously or infamously

00:01:19,610 --> 00:01:25,040
has always been a huge App Engine

00:01:22,580 --> 00:01:26,570
customer so what does that mean happens

00:01:25,040 --> 00:01:27,920
it's kind of a platform as a service

00:01:26,570 --> 00:01:30,020
that's offered on the Google cloud you

00:01:27,920 --> 00:01:32,000
just kind of make a container or you

00:01:30,020 --> 00:01:33,440
make like your code you just kind of

00:01:32,000 --> 00:01:35,560
employ it for your laptop and it shows

00:01:33,440 --> 00:01:38,869
up and it's Auto scale and it's great

00:01:35,560 --> 00:01:41,210
where does it go wrong though people

00:01:38,869 --> 00:01:44,180
just tend to build everything in the one

00:01:41,210 --> 00:01:46,160
same API a new feature let's just merge

00:01:44,180 --> 00:01:48,170
it into master idioms us like it shows

00:01:46,160 --> 00:01:51,560
up in the API we're good like who cares

00:01:48,170 --> 00:01:53,720
if that feature was in the proper place

00:01:51,560 --> 00:01:56,630
or was able to be regionalised because

00:01:53,720 --> 00:01:59,720
App Engine by design can't visualize so

00:01:56,630 --> 00:02:03,200
at least a few tricks so where do we go

00:01:59,720 --> 00:02:04,880
up there we have a bunch of different

00:02:03,200 --> 00:02:07,430
options we could do but we decided on

00:02:04,880 --> 00:02:10,850
the server's mesh at snap and why is

00:02:07,430 --> 00:02:13,060
that because that is going to be it is a

00:02:10,850 --> 00:02:15,680
multi cloud company so we want to have

00:02:13,060 --> 00:02:18,049
the best experience for our users and

00:02:15,680 --> 00:02:19,489
our developers as needed so if there's

00:02:18,049 --> 00:02:20,959
something in that developer really wants

00:02:19,489 --> 00:02:22,730
to use in AWS then they should be able

00:02:20,959 --> 00:02:25,010
to use that in conjunction with features

00:02:22,730 --> 00:02:26,239
that we developed for Google and we want

00:02:25,010 --> 00:02:29,600
to make it easy for our developers to

00:02:26,239 --> 00:02:31,220
understand the boundaries would not have

00:02:29,600 --> 00:02:32,630
to even think about the cloud boundary

00:02:31,220 --> 00:02:34,910
or how they would even talk to each

00:02:32,630 --> 00:02:37,220
other so then what is a service mesh

00:02:34,910 --> 00:02:38,450
people probably have pretty oh and you

00:02:37,220 --> 00:02:41,150
might have read the docs and your eyes

00:02:38,450 --> 00:02:43,640
glazed over I know I did the first time

00:02:41,150 --> 00:02:47,130
so at the other day that service mesh is

00:02:43,640 --> 00:02:49,230
a pretty simple architecture if you

00:02:47,130 --> 00:02:50,760
get down into its core all it really

00:02:49,230 --> 00:02:52,650
means is that you take the networking

00:02:50,760 --> 00:02:54,840
stack and put it with your application

00:02:52,650 --> 00:02:56,580
so what that allows you to do is you can

00:02:54,840 --> 00:02:58,170
make changes out of bands here

00:02:56,580 --> 00:03:00,350
networking stack without having to

00:02:58,170 --> 00:03:03,180
change your cloud or having to change

00:03:00,350 --> 00:03:04,220
rally like rallying tables or anything

00:03:03,180 --> 00:03:07,560
crazy

00:03:04,220 --> 00:03:09,810
in that sort of way so also enables like

00:03:07,560 --> 00:03:11,520
service to cut discovery so we can my

00:03:09,810 --> 00:03:13,770
Auto discover when somebody influenced a

00:03:11,520 --> 00:03:15,570
new service instead of like going into

00:03:13,770 --> 00:03:18,960
my like animal file and saying add these

00:03:15,570 --> 00:03:21,720
four new IPs and snap service mesh it

00:03:18,960 --> 00:03:22,980
automatically will route those to the

00:03:21,720 --> 00:03:25,110
sidecar one of the most interesting

00:03:22,980 --> 00:03:26,940
things about this architecture it

00:03:25,110 --> 00:03:29,520
eliminates the need for globe balancers

00:03:26,940 --> 00:03:33,630
so we only have essentially four load

00:03:29,520 --> 00:03:35,430
balancers in the mesh that handle a lot

00:03:33,630 --> 00:03:37,200
of traffic so basically everyone's in

00:03:35,430 --> 00:03:39,420
their own network they talk on like a

00:03:37,200 --> 00:03:40,980
very private BBC you have great latency

00:03:39,420 --> 00:03:43,050
you don't have to worry about making

00:03:40,980 --> 00:03:44,760
mistakes and accidentally going to your

00:03:43,050 --> 00:03:46,830
public IP and going into the internet

00:03:44,760 --> 00:03:49,290
and coming back in because we designed

00:03:46,830 --> 00:03:51,210
it so you just get so that's basically

00:03:49,290 --> 00:03:52,770
with a service message so as you can see

00:03:51,210 --> 00:03:55,350
though it's quite a bit more moving

00:03:52,770 --> 00:03:58,070
parts to deal with so that means we have

00:03:55,350 --> 00:04:00,480
more services now we don't just have one

00:03:58,070 --> 00:04:02,130
big mom with the cap it was like oh we

00:04:00,480 --> 00:04:03,930
just deploy this app and now snapchats

00:04:02,130 --> 00:04:05,940
updated right good features like ingest

00:04:03,930 --> 00:04:09,120
chips like memories or something it's

00:04:05,940 --> 00:04:10,740
it's going it's really good to go now

00:04:09,120 --> 00:04:12,090
we're actually roll out hundreds of new

00:04:10,740 --> 00:04:14,040
features right and they're all separate

00:04:12,090 --> 00:04:15,750
services which is by design a better way

00:04:14,040 --> 00:04:17,130
to move but that creates a lot of

00:04:15,750 --> 00:04:19,380
problems with how we're going to deploy

00:04:17,130 --> 00:04:20,760
this like how do we bridge the gap

00:04:19,380 --> 00:04:22,000
between these services that might have

00:04:20,760 --> 00:04:24,250
to rely on App Engine

00:04:22,000 --> 00:04:25,780
like rely on some like legacy service

00:04:24,250 --> 00:04:28,000
but it has to be deployed in conjunction

00:04:25,780 --> 00:04:30,310
with dementia and that's where the

00:04:28,000 --> 00:04:32,500
division of the one deployment tool came

00:04:30,310 --> 00:04:34,720
about so I own the deployment tool that

00:04:32,500 --> 00:04:37,420
was deploying off the snapchat web app

00:04:34,720 --> 00:04:39,100
and I was tasked with like how could we

00:04:37,420 --> 00:04:40,300
support the service measure like how

00:04:39,100 --> 00:04:43,180
could we make this ignition field work

00:04:40,300 --> 00:04:45,550
better and my vision was that deployment

00:04:43,180 --> 00:04:47,020
tool was not well-suited for deploying

00:04:45,550 --> 00:04:49,600
kubernetes and I didn't want to stay

00:04:47,020 --> 00:04:52,540
here all day trying to like update SDKs

00:04:49,600 --> 00:04:56,290
every time a cloud decided changed

00:04:52,540 --> 00:04:59,110
however GCL B or lb gets propagated in a

00:04:56,290 --> 00:05:01,480
system for how it behaves so we found

00:04:59,110 --> 00:05:03,460
spinnaker that was being adopted by

00:05:01,480 --> 00:05:06,160
mobile Cloudsdale they kept it up to

00:05:03,460 --> 00:05:08,380
date recently I solved a lot of problems

00:05:06,160 --> 00:05:09,669
with like teams that would come to us

00:05:08,380 --> 00:05:10,870
you might have had this happen in your

00:05:09,669 --> 00:05:13,450
work we're like well I think this

00:05:10,870 --> 00:05:15,070
employer like a cloud foundry thing and

00:05:13,450 --> 00:05:17,230
like I need to use data stack sort of

00:05:15,070 --> 00:05:18,910
Allah you could say like oh yeah that

00:05:17,230 --> 00:05:20,320
kind of supports it if it doesn't you

00:05:18,910 --> 00:05:23,169
can check real quick and be like this is

00:05:20,320 --> 00:05:24,640
on the roadmap and you know people have

00:05:23,169 --> 00:05:26,380
their weird-ass house deployed scripts

00:05:24,640 --> 00:05:28,360
people get really attached in scripts

00:05:26,380 --> 00:05:29,800
you're like I spent four weeks getting

00:05:28,360 --> 00:05:32,380
this Python script working I'm not

00:05:29,800 --> 00:05:34,720
giving it up but my cold dead by and you

00:05:32,380 --> 00:05:37,840
know makes me do anything else that was

00:05:34,720 --> 00:05:41,530
a tough challenge so he just had to like

00:05:37,840 --> 00:05:42,640
basically just women by design on that

00:05:41,530 --> 00:05:45,000
one there's still some people out there

00:05:42,640 --> 00:05:47,919
there like that and then like our

00:05:45,000 --> 00:05:50,020
deployment velocity was just going up by

00:05:47,919 --> 00:05:51,520
and seeing at night like in the old

00:05:50,020 --> 00:05:53,050
world we were very happy if we got

00:05:51,520 --> 00:05:55,000
thirty-five performance a day which is

00:05:53,050 --> 00:05:57,370
quite a lot for that large amount

00:05:55,000 --> 00:05:59,650
Chaffee but still now we can deploy much

00:05:57,370 --> 00:06:01,630
faster because it can be safer like if

00:05:59,650 --> 00:06:03,729
like a small feature and you can't like

00:06:01,630 --> 00:06:05,890
for instance see an icon on your friend

00:06:03,729 --> 00:06:08,560
and the friend feed that's not a huge

00:06:05,890 --> 00:06:09,510
deal but if the before if that outage

00:06:08,560 --> 00:06:11,610
happened

00:06:09,510 --> 00:06:14,880
take out the entire rap so now you can

00:06:11,610 --> 00:06:16,260
just mitigate risk and you know no one

00:06:14,880 --> 00:06:18,120
really knew how to deploy to kubernetes

00:06:16,260 --> 00:06:20,220
I guess it wasn't really a great story

00:06:18,120 --> 00:06:22,410
around that time ago like you were just

00:06:20,220 --> 00:06:24,840
like this just a cool apply it's fine a

00:06:22,410 --> 00:06:27,270
Jenkins job could apply it's all you

00:06:24,840 --> 00:06:30,150
ever need that I didn't believe in that

00:06:27,270 --> 00:06:31,560
and people were kind of trying to figure

00:06:30,150 --> 00:06:33,950
out surprisingly they didn't like that

00:06:31,560 --> 00:06:36,660
there was no visualization in kubernetes

00:06:33,950 --> 00:06:40,650
gku kind of had some but like it wasn't

00:06:36,660 --> 00:06:42,240
consistent across the clouds so what

00:06:40,650 --> 00:06:43,680
does this enable us so when we have a

00:06:42,240 --> 00:06:45,390
standardized infrastructure a

00:06:43,680 --> 00:06:46,950
standardized networking stack and

00:06:45,390 --> 00:06:48,450
metrics and everything else which is

00:06:46,950 --> 00:06:50,640
kind of a compass in of our mesh

00:06:48,450 --> 00:06:52,380
platform like we control the sidecar to

00:06:50,640 --> 00:06:54,720
control the off what does that allow us

00:06:52,380 --> 00:06:56,280
to do that allows us to know things

00:06:54,720 --> 00:06:58,290
about their cluster we know that way you

00:06:56,280 --> 00:06:59,850
can propagate Spinnaker's credentials to

00:06:58,290 --> 00:07:02,850
that cluster so that I can do stuff

00:06:59,850 --> 00:07:04,350
that's big the kubernetes cluster we

00:07:02,850 --> 00:07:05,610
know what their metric naming schemes

00:07:04,350 --> 00:07:08,310
are going to be ahead of time so we can

00:07:05,610 --> 00:07:10,220
make a Cayenne to canary that config

00:07:08,310 --> 00:07:12,780
that works for all mesh services and

00:07:10,220 --> 00:07:15,480
this enables us to know what region

00:07:12,780 --> 00:07:17,310
they're in because by design we keep

00:07:15,480 --> 00:07:18,990
track of in our control plan through

00:07:17,310 --> 00:07:21,390
what's availability and failure zones

00:07:18,990 --> 00:07:22,980
you're in and that allows us to do so

00:07:21,390 --> 00:07:23,960
mobile apps for instance or regional

00:07:22,980 --> 00:07:26,580
rollouts

00:07:23,960 --> 00:07:28,710
automated pipelines and stuff like that

00:07:26,580 --> 00:07:32,220
so that's what we'll get to now like so

00:07:28,710 --> 00:07:34,620
how today can unsnap developer make a

00:07:32,220 --> 00:07:35,940
spinnaker to deploy in pipelines so we

00:07:34,620 --> 00:07:38,100
kind of took a different route than some

00:07:35,940 --> 00:07:40,500
of the like infrastructure it's code

00:07:38,100 --> 00:07:43,110
thing here design we have our own

00:07:40,500 --> 00:07:45,360
service that sits idly with spinnaker

00:07:43,110 --> 00:07:47,040
that allows us to generate mesh base

00:07:45,360 --> 00:07:49,560
config so why don't we do that

00:07:47,040 --> 00:07:51,120
it's because we need to we have a whole

00:07:49,560 --> 00:07:52,800
bunch of metadata sources and micro

00:07:51,120 --> 00:07:55,260
services that we can query they get all

00:07:52,800 --> 00:07:58,320
the information I need to Longbourn a

00:07:55,260 --> 00:08:00,020
cluster to spinnaker so today leaves the

00:07:58,320 --> 00:08:01,730
spring cloud config

00:08:00,020 --> 00:08:04,880
in addition you invited on the Scots

00:08:01,730 --> 00:08:07,430
talk earlier today I believe and that's

00:08:04,880 --> 00:08:09,200
kind of what we use so all doing counts

00:08:07,430 --> 00:08:10,640
come into our provisioning service in

00:08:09,200 --> 00:08:12,530
the mess because we handle provisioning

00:08:10,640 --> 00:08:14,510
now that developers that's key so they

00:08:12,530 --> 00:08:15,980
can't sit there and like make themselves

00:08:14,510 --> 00:08:18,920
open in the internet and remove all our

00:08:15,980 --> 00:08:20,930
back so we provision the our back we

00:08:18,920 --> 00:08:22,520
know it's all there we message a service

00:08:20,930 --> 00:08:24,770
on boards at the spinnaker it's been a

00:08:22,520 --> 00:08:27,290
fix up all new clusters within get rid

00:08:24,770 --> 00:08:29,210
take 8 minutes which is a huge huge

00:08:27,290 --> 00:08:31,760
advantage from the old 2 hours for all

00:08:29,210 --> 00:08:35,270
of my cloud driver pots to refresh so

00:08:31,760 --> 00:08:37,160
what does that look like today so this

00:08:35,270 --> 00:08:39,170
is kind of like I didn't have time to go

00:08:37,160 --> 00:08:40,610
into like what this whole UI is but this

00:08:39,170 --> 00:08:43,130
is a switchboard UI so this would be

00:08:40,610 --> 00:08:45,500
like kind of like our UI or SEO has some

00:08:43,130 --> 00:08:47,210
sort of equivalent all of our services

00:08:45,500 --> 00:08:48,770
hang out in this UI so when you make a

00:08:47,210 --> 00:08:51,620
new service on the service mission so

00:08:48,770 --> 00:08:53,630
now you come into this UI you see you

00:08:51,620 --> 00:08:55,040
want to make a service we provision some

00:08:53,630 --> 00:08:57,350
sort of identity for you that you can

00:08:55,040 --> 00:08:58,700
use you say here's my team members

00:08:57,350 --> 00:09:00,980
they're in this Google Group and that

00:08:58,700 --> 00:09:02,300
allows your team members to now also

00:09:00,980 --> 00:09:03,500
manage your service so this is great

00:09:02,300 --> 00:09:05,600
because this allows you to just

00:09:03,500 --> 00:09:07,400
collaborate really quickly you can say

00:09:05,600 --> 00:09:09,410
we know ownership of services which is

00:09:07,400 --> 00:09:11,030
key like how many people have dealt with

00:09:09,410 --> 00:09:12,590
that at your work you're like what is

00:09:11,030 --> 00:09:15,140
this stupid service that's crashing who

00:09:12,590 --> 00:09:17,210
owns this thing like you're trying to

00:09:15,140 --> 00:09:19,010
find them github commits in there five

00:09:17,210 --> 00:09:21,560
people that work there four years ago

00:09:19,010 --> 00:09:24,560
and you don't know who I'm saying this

00:09:21,560 --> 00:09:27,050
solves the ownership problem so going

00:09:24,560 --> 00:09:30,590
back and from there where do we get to

00:09:27,050 --> 00:09:33,400
today so we started off about a year ago

00:09:30,590 --> 00:09:36,160
and we've been ongoing since then

00:09:33,400 --> 00:09:38,560
in the last month we've done 10,000

00:09:36,160 --> 00:09:41,230
pipeline runs so that's an execution of

00:09:38,560 --> 00:09:43,300
pipeline to completion I mean under

00:09:41,230 --> 00:09:45,940
unique pipeline runs a 300 different

00:09:43,300 --> 00:09:48,880
unique pipeline config to run and also

00:09:45,940 --> 00:09:51,550
so many different applications and we

00:09:48,880 --> 00:09:53,740
have about a rule over 170 developers

00:09:51,550 --> 00:09:56,380
that use it every month

00:09:53,740 --> 00:09:58,720
so it's been working pretty well for us

00:09:56,380 --> 00:10:01,060
and it's been a really good to get

00:09:58,720 --> 00:10:04,540
another deployment handle on our system

00:10:01,060 --> 00:10:08,120
that's it for me hope you enjoyed the

00:10:04,540 --> 00:10:11,289
conference and thanks a lot

00:10:08,120 --> 00:10:11,289
[Applause]

00:10:17,740 --> 00:10:19,800

YouTube URL: https://www.youtube.com/watch?v=-3dkP7WxHsQ


