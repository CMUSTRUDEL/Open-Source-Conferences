Title: Eric Zimanyi, Ethan Rogers, Maggie Neterval "State of the Kubernetes Provider (Google)"
Publication date: 2019-12-03
Playlist: Spinnaker Summit 2019
Description: 
	The third annual Spinnaker Summit (Diamond Sponsors: Netflix, Google and Armory) was held at the Hard Rock Hotel in San Diego, CA from November 15-17, 2019 and welcomed over 500 members of the rapidly growing Spinnaker open source community.
Captions: 
	00:00:01,280 --> 00:00:06,810
please go forth what's up everybody

00:00:05,100 --> 00:00:09,210
thank you for coming I hope you are

00:00:06,810 --> 00:00:10,679
having a great first day of the

00:00:09,210 --> 00:00:12,809
spinnaker summit can we get a round of

00:00:10,679 --> 00:00:17,550
applause if everybody has enjoyed their

00:00:12,809 --> 00:00:20,010
time so far sweet as daniel said I'm

00:00:17,550 --> 00:00:22,920
Ethan Rogers I'm from armory I'm joined

00:00:20,010 --> 00:00:26,310
by my co leads for the kubernetes sig

00:00:22,920 --> 00:00:28,800
eric and maggie and what we wanted to do

00:00:26,310 --> 00:00:30,599
today is just give you like an overview

00:00:28,800 --> 00:00:33,270
of where we've come over the last year

00:00:30,599 --> 00:00:37,290
as far as kubernetes goes within

00:00:33,270 --> 00:00:39,030
spinnaker so just before before we kind

00:00:37,290 --> 00:00:41,070
of dive in just to give an overview of

00:00:39,030 --> 00:00:42,390
where we're at so first we're going to

00:00:41,070 --> 00:00:45,960
just talk a little bit about the history

00:00:42,390 --> 00:00:48,300
of kubernetes within spinnaker I'm sure

00:00:45,960 --> 00:00:51,360
a lot of you have kind of read and heard

00:00:48,300 --> 00:00:53,190
about the v2 provider and the problems

00:00:51,360 --> 00:00:54,989
that it solved so we just wanted to kind

00:00:53,190 --> 00:00:57,329
of give you a little bit of a history

00:00:54,989 --> 00:00:59,399
lesson then we're going to talk about

00:00:57,329 --> 00:01:00,719
some features and performance

00:00:59,399 --> 00:01:03,809
improvements that we've made we've come

00:01:00,719 --> 00:01:06,960
kind of a long way in the last year with

00:01:03,809 --> 00:01:08,939
just how well kubernetes interacts and

00:01:06,960 --> 00:01:10,920
fits into the spinnaker ecosystem so

00:01:08,939 --> 00:01:12,990
we'll talk a little bit about that then

00:01:10,920 --> 00:01:16,020
we'll talk about the future where we

00:01:12,990 --> 00:01:17,520
want to go and on a large part you the

00:01:16,020 --> 00:01:20,250
community or what actually helped us

00:01:17,520 --> 00:01:22,020
drive this so if you hear anything in

00:01:20,250 --> 00:01:23,460
that slide or you see anything that may

00:01:22,020 --> 00:01:25,770
be missing come up and tell us after

00:01:23,460 --> 00:01:27,299
afterwards we'd love to hear him then

00:01:25,770 --> 00:01:29,009
we're gonna talk a little bit about our

00:01:27,299 --> 00:01:30,689
sig which is our kind of community

00:01:29,009 --> 00:01:33,060
gathering space that we've been running

00:01:30,689 --> 00:01:35,610
for the last year and we have a really

00:01:33,060 --> 00:01:36,750
good attendance and yeah so we're just

00:01:35,610 --> 00:01:38,970
going to talk a little bit about that

00:01:36,750 --> 00:01:40,950
and then one thing that we love to do at

00:01:38,970 --> 00:01:43,500
the end of every sig meeting is a open

00:01:40,950 --> 00:01:46,070
discussion so this is just gonna give

00:01:43,500 --> 00:01:48,659
you guys a chance to ask questions to

00:01:46,070 --> 00:01:50,310
let us know what you think about

00:01:48,659 --> 00:01:51,770
kubernetes within spinnaker and how we

00:01:50,310 --> 00:01:55,890
can make it better

00:01:51,770 --> 00:01:58,619
so how did we get here let's dive into

00:01:55,890 --> 00:02:02,759
the Wayback Machine and take a look at

00:01:58,619 --> 00:02:07,560
where we came from so kubernetes well

00:02:02,759 --> 00:02:11,220
spinnaker the v1 provider was introduced

00:02:07,560 --> 00:02:13,560
in late 2015 this is what we call the

00:02:11,220 --> 00:02:16,290
kind of first iteration of Cooper net

00:02:13,560 --> 00:02:19,040
within spinnaker it was modeled very

00:02:16,290 --> 00:02:23,250
closely to the VM based providers within

00:02:19,040 --> 00:02:25,370
spinnaker so GCP AWS all of those other

00:02:23,250 --> 00:02:28,830
cloud providers that were already there

00:02:25,370 --> 00:02:30,900
we basically took kubernetes and said

00:02:28,830 --> 00:02:32,849
how can we map the concepts of

00:02:30,900 --> 00:02:35,370
kubernetes to all of these things so

00:02:32,849 --> 00:02:37,019
what we did was we abstracted a lot of

00:02:35,370 --> 00:02:38,880
the common cloud concepts that were

00:02:37,019 --> 00:02:43,250
standard across providers like Auto

00:02:38,880 --> 00:02:46,920
scale groups or some type of capacity

00:02:43,250 --> 00:02:48,870
scaling and stuff like that we had cert

00:02:46,920 --> 00:02:54,600
server group security groups and load

00:02:48,870 --> 00:02:57,000
balancers and we wanted it to basically

00:02:54,600 --> 00:02:59,099
perform the same function as ec2 and GCE

00:02:57,000 --> 00:03:00,360
we wanted to take take a workload

00:02:59,099 --> 00:03:02,220
and place it on some infrastructure

00:03:00,360 --> 00:03:04,380
running somewhere like that is

00:03:02,220 --> 00:03:07,410
essentially what kubernetes is doing if

00:03:04,380 --> 00:03:10,049
you think about kubernetes and what it

00:03:07,410 --> 00:03:12,450
does for your small cluster and then you

00:03:10,049 --> 00:03:14,880
scale it out you get what all of the

00:03:12,450 --> 00:03:17,459
major cloud providers do like ace ec2

00:03:14,880 --> 00:03:19,760
and GC P so we take workloads and we

00:03:17,459 --> 00:03:22,769
take and we place it on infrastructure

00:03:19,760 --> 00:03:25,470
and one of the big benefits of being

00:03:22,769 --> 00:03:28,140
modeled after VM based providers is you

00:03:25,470 --> 00:03:30,810
could create a server group in GCE AWS

00:03:28,140 --> 00:03:32,730
kubernetes and it would all feel similar

00:03:30,810 --> 00:03:35,790
right the abstractions aren't exactly

00:03:32,730 --> 00:03:37,829
the same some of the details and

00:03:35,790 --> 00:03:39,959
implementation details of each

00:03:37,829 --> 00:03:42,180
individual cloud provider leaked out but

00:03:39,959 --> 00:03:45,500
when you could configure a server group

00:03:42,180 --> 00:03:47,609
in AWS you kind of had similar

00:03:45,500 --> 00:03:51,569
configurations for kubernetes and that

00:03:47,609 --> 00:03:54,989
was a big plus you can see here this is

00:03:51,569 --> 00:03:59,160
the the wizard for creating a service

00:03:54,989 --> 00:04:02,130
which is analogous to a load balancer we

00:03:59,160 --> 00:04:04,859
had a configuration wizard for deploying

00:04:02,130 --> 00:04:07,350
a replica set or a deployment depending

00:04:04,859 --> 00:04:08,310
on what you wanted but I guess the point

00:04:07,350 --> 00:04:09,840
that I'm trying to make with these

00:04:08,310 --> 00:04:12,480
pictures is everything was very GUI

00:04:09,840 --> 00:04:14,910
based one of the challenges we had was

00:04:12,480 --> 00:04:17,639
we had kind of this interim data model

00:04:14,910 --> 00:04:20,130
where you would configure these things

00:04:17,639 --> 00:04:21,930
in like spinnaker land and they kind of

00:04:20,130 --> 00:04:23,789
mapped to all of the options in like a

00:04:21,930 --> 00:04:26,030
kubernetes deployment but they weren't

00:04:23,789 --> 00:04:26,030
perfect

00:04:26,169 --> 00:04:30,939
and then we started getting a lot of

00:04:27,789 --> 00:04:34,030
questions like where's the yam all right

00:04:30,939 --> 00:04:36,340
everybody who's done kubernetes is loves

00:04:34,030 --> 00:04:39,669
ya Mille it's kind of made its

00:04:36,340 --> 00:04:42,129
resurgence and become very prominent in

00:04:39,669 --> 00:04:44,590
our industry especially within

00:04:42,129 --> 00:04:46,449
kubernetes and so we wanted to address

00:04:44,590 --> 00:04:49,150
that right we wanted to more closely

00:04:46,449 --> 00:04:51,009
align with the kubernetes community how

00:04:49,150 --> 00:04:53,199
they interact interacted with kubernetes

00:04:51,009 --> 00:04:56,139
and really wanted to be able to adopt

00:04:53,199 --> 00:04:57,999
the tools that they were using so within

00:04:56,139 --> 00:05:01,389
a couple years

00:04:57,999 --> 00:05:05,590
the v2 provider was introduced in 2018

00:05:01,389 --> 00:05:08,349
I believe at the last spinnaker summit

00:05:05,590 --> 00:05:10,090
we were really starting to talk about it

00:05:08,349 --> 00:05:13,719
really starting to use it with a lot of

00:05:10,090 --> 00:05:16,000
a lot of customers and so that

00:05:13,719 --> 00:05:18,939
introduced a lot of new features we had

00:05:16,000 --> 00:05:21,460
this concept of artifacts kubernetes is

00:05:18,939 --> 00:05:25,029
very manifest based it's very you know

00:05:21,460 --> 00:05:26,349
the idea of storing your manifests in

00:05:25,029 --> 00:05:28,089
source control is like a first-class

00:05:26,349 --> 00:05:29,379
citizen within kubernetes and other

00:05:28,089 --> 00:05:32,409
tooling so we wanted to be able to

00:05:29,379 --> 00:05:35,669
support that but we also had we also

00:05:32,409 --> 00:05:38,560
still needed to map the concepts to

00:05:35,669 --> 00:05:41,050
spinnaker abstractions right there's

00:05:38,560 --> 00:05:43,539
everything is pretty similar for Auto

00:05:41,050 --> 00:05:45,460
skill groups or replica set services or

00:05:43,539 --> 00:05:49,839
load balancers and stuff like that so we

00:05:45,460 --> 00:05:52,029
continued to do that and we kind of

00:05:49,839 --> 00:05:53,620
started doing this thing where we would

00:05:52,029 --> 00:05:55,419
just meet every few weeks and talk about

00:05:53,620 --> 00:05:56,830
how the development was going and this

00:05:55,419 --> 00:05:58,629
is really what kind of kicked off the

00:05:56,830 --> 00:06:00,939
kubernetes sig so we called it the

00:05:58,629 --> 00:06:03,699
kubernetes v2 developer meeting and then

00:06:00,939 --> 00:06:05,770
over time we transitioned into just a

00:06:03,699 --> 00:06:09,699
general kubernetes meeting and it's gone

00:06:05,770 --> 00:06:11,379
really well and I believe we might have

00:06:09,699 --> 00:06:13,270
switched the order of this so I have a

00:06:11,379 --> 00:06:14,770
note hand off to Eric but I will

00:06:13,270 --> 00:06:17,409
actually hand off to Maggie to talk

00:06:14,770 --> 00:06:18,009
about features that we've added Thank

00:06:17,409 --> 00:06:21,370
You Ethan

00:06:18,009 --> 00:06:22,930
so as Ethan mentioned the v2 provider

00:06:21,370 --> 00:06:25,419
instead of having you know a similar

00:06:22,930 --> 00:06:27,310
wizard to the VM based providers just

00:06:25,419 --> 00:06:28,750
kind of exposes input for you to input

00:06:27,310 --> 00:06:31,389
yeah Mel that represents whatever

00:06:28,750 --> 00:06:32,889
resources you need and so some of our

00:06:31,389 --> 00:06:34,389
feature work this year just centered

00:06:32,889 --> 00:06:36,399
around enhancing those to really add

00:06:34,389 --> 00:06:37,959
value above and beyond if you could just

00:06:36,399 --> 00:06:38,950
cute control apply those resources

00:06:37,959 --> 00:06:41,050
yourself

00:06:38,950 --> 00:06:44,200
um so a bunch of these take place in the

00:06:41,050 --> 00:06:45,670
manifest deployment stages so a common

00:06:44,200 --> 00:06:47,890
complaint we got from members of the sig

00:06:45,670 --> 00:06:49,780
was that it doesn't necessarily play

00:06:47,890 --> 00:06:51,790
super nicely with home where you can

00:06:49,780 --> 00:06:53,140
override a namespace so we built

00:06:51,790 --> 00:06:56,020
first-class support for that in

00:06:53,140 --> 00:06:58,180
spinnaker another issue that helm users

00:06:56,020 --> 00:07:00,040
were running into was spinnaker uses

00:06:58,180 --> 00:07:02,620
spring expression language and so

00:07:00,040 --> 00:07:04,180
unfortunately having curly brace dollar

00:07:02,620 --> 00:07:05,740
sign and your home templates wouldn't

00:07:04,180 --> 00:07:07,120
play nicely there so we allow you to

00:07:05,740 --> 00:07:09,640
kind of override the default error

00:07:07,120 --> 00:07:12,490
behavior of spinnaker can evaluate those

00:07:09,640 --> 00:07:14,560
expressions and then finally one really

00:07:12,490 --> 00:07:16,900
cool value add that these kind of cute

00:07:14,560 --> 00:07:19,540
control apply analogous stages give you

00:07:16,900 --> 00:07:21,490
is the ability to dynamically target a

00:07:19,540 --> 00:07:23,170
different resource in kubernetes to do

00:07:21,490 --> 00:07:25,390
the operation too so for example if you

00:07:23,170 --> 00:07:27,370
wanted to patch or delete a certain

00:07:25,390 --> 00:07:30,040
resource you can input into spinnaker I

00:07:27,370 --> 00:07:32,380
want to do this to the largest one the

00:07:30,040 --> 00:07:34,630
second newest one etc and so that really

00:07:32,380 --> 00:07:36,040
kind of unlocks some workflows that will

00:07:34,630 --> 00:07:40,720
be pretty difficult to like orchestrate

00:07:36,040 --> 00:07:42,880
yourself through a script and another

00:07:40,720 --> 00:07:45,040
way we kind of saw to add value over the

00:07:42,880 --> 00:07:46,420
built in deployment object in kubernetes

00:07:45,040 --> 00:07:48,580
which doesn't really give you a great

00:07:46,420 --> 00:07:51,160
way to do a blue/green is by having

00:07:48,580 --> 00:07:52,690
spinnaker manage that for you so

00:07:51,160 --> 00:07:55,000
something that's kind of hard to do in

00:07:52,690 --> 00:07:56,950
kubernetes is manipulate labels to

00:07:55,000 --> 00:07:58,870
direct traffic yourself for some kind of

00:07:56,950 --> 00:08:00,730
a complex rollout and so we decided to

00:07:58,870 --> 00:08:03,130
build first-class support for that into

00:08:00,730 --> 00:08:04,960
the deploy manifest stage so that you

00:08:03,130 --> 00:08:07,060
can kind of have spinnaker take care of

00:08:04,960 --> 00:08:08,740
what it means to associate a service

00:08:07,060 --> 00:08:10,510
with a workload and how you want to

00:08:08,740 --> 00:08:11,890
direct traffic and should it be on right

00:08:10,510 --> 00:08:13,660
away and what should I do with the

00:08:11,890 --> 00:08:15,520
previous version of that workload once

00:08:13,660 --> 00:08:17,440
the new one is safely taking a traffic

00:08:15,520 --> 00:08:19,450
and so this diagram just kind of shows a

00:08:17,440 --> 00:08:20,830
matrix of the strategies available to

00:08:19,450 --> 00:08:22,660
you and some of those terms would

00:08:20,830 --> 00:08:24,550
probably look familiar from Netflix so a

00:08:22,660 --> 00:08:26,380
red-black is analogous to a blue green

00:08:24,550 --> 00:08:28,060
and then a Highlander is similar with

00:08:26,380 --> 00:08:29,140
the addition that if you know you're

00:08:28,060 --> 00:08:30,190
kind of working under resource

00:08:29,140 --> 00:08:32,050
constraints and you want to immediately

00:08:30,190 --> 00:08:35,890
destroy the old version spanker can go

00:08:32,050 --> 00:08:37,600
ahead and take care of that for you I'm

00:08:35,890 --> 00:08:43,960
gonna pass it back to Ethan for some

00:08:37,600 --> 00:08:46,510
more future talk yeah so to kind of like

00:08:43,960 --> 00:08:48,460
keep with the the theme of being able to

00:08:46,510 --> 00:08:51,010
adopt kubernetes tools one of the things

00:08:48,460 --> 00:08:52,390
that we saw new users of spinnaker

00:08:51,010 --> 00:08:52,889
coming in was they wanted to be able to

00:08:52,390 --> 00:08:55,290
use

00:08:52,889 --> 00:08:58,259
like helm to keep generating their

00:08:55,290 --> 00:09:00,720
manifests right I think a lot of people

00:08:58,259 --> 00:09:03,179
in here probably praising the release of

00:09:00,720 --> 00:09:04,679
helm 3 and its remover of tiller but

00:09:03,179 --> 00:09:07,109
this is actually not a problem that

00:09:04,679 --> 00:09:08,399
we've been dealing with since we

00:09:07,109 --> 00:09:10,109
introduced the big manifest stage

00:09:08,399 --> 00:09:13,679
because we purely use it as a template

00:09:10,109 --> 00:09:16,019
engine so we've added we've had support

00:09:13,679 --> 00:09:18,299
for helm ever since we reintroduced this

00:09:16,019 --> 00:09:21,299
we recently added support for customize

00:09:18,299 --> 00:09:22,799
and a new git repo artifact type so if

00:09:21,299 --> 00:09:25,439
you've been tracking the development of

00:09:22,799 --> 00:09:27,720
some of this stuff you'll know that we

00:09:25,439 --> 00:09:31,079
introduced the git repo artifact type to

00:09:27,720 --> 00:09:33,959
help aid in our ability to use customize

00:09:31,079 --> 00:09:37,679
as a template renderer there's a lot of

00:09:33,959 --> 00:09:40,529
really interesting templating tools and

00:09:37,679 --> 00:09:42,480
in manifest generation tools that will

00:09:40,529 --> 00:09:45,389
probably benefit from this git repo

00:09:42,480 --> 00:09:47,489
artifact provider as well if you've

00:09:45,389 --> 00:09:49,649
heard of captain it's a pretty similar

00:09:47,489 --> 00:09:52,889
to customized so we're looking at doing

00:09:49,649 --> 00:09:55,470
that and integrating that as well

00:09:52,889 --> 00:09:57,029
next a something that a lot of really

00:09:55,470 --> 00:09:58,230
big organizations have been excited

00:09:57,029 --> 00:10:01,199
about is this concept of dynamic

00:09:58,230 --> 00:10:04,049
accounts this is actually something that

00:10:01,199 --> 00:10:06,209
I and pivotal have both worked on I

00:10:04,049 --> 00:10:09,839
don't know if Scott Frederick is in here

00:10:06,209 --> 00:10:13,679
but he introduced the first iteration of

00:10:09,839 --> 00:10:17,189
cloud config 2 to cloud driver what is

00:10:13,679 --> 00:10:19,139
this enable I think as kubernetes has

00:10:17,189 --> 00:10:20,970
started to take a foothold in many

00:10:19,139 --> 00:10:24,119
organizations we're seeing customers

00:10:20,970 --> 00:10:26,369
that have hundreds upwards of hi

00:10:24,119 --> 00:10:28,169
hundreds of accounts and what they're

00:10:26,369 --> 00:10:29,910
doing is they're actually just creating

00:10:28,169 --> 00:10:31,980
new kubernetes clusters for every team

00:10:29,910 --> 00:10:35,779
that on boards maybe every application

00:10:31,980 --> 00:10:38,009
and if you're familiar with how

00:10:35,779 --> 00:10:39,989
Spinnaker's accounts are configured you

00:10:38,009 --> 00:10:42,509
know that it's challenging to roll out

00:10:39,989 --> 00:10:44,610
new accounts and in this like automated

00:10:42,509 --> 00:10:46,829
world that we have where you can

00:10:44,610 --> 00:10:48,569
automate creating a new kubernetes

00:10:46,829 --> 00:10:50,819
cluster adding it to your config

00:10:48,569 --> 00:10:52,889
manually is kind of a bummer

00:10:50,819 --> 00:10:55,619
and so dynamic accounts really enables

00:10:52,889 --> 00:10:58,649
us to go the next step how do we how do

00:10:55,619 --> 00:11:00,119
we make spinnaker configurable without

00:10:58,649 --> 00:11:02,730
ever having to take it down or do a

00:11:00,119 --> 00:11:06,179
redeploy so dynamic accounts and further

00:11:02,730 --> 00:11:06,840
like dynamic configuration really is

00:11:06,179 --> 00:11:10,950
going to help push

00:11:06,840 --> 00:11:14,700
to that next level and so with that

00:11:10,950 --> 00:11:17,100
talking about Ag scaling farther out

00:11:14,700 --> 00:11:18,810
into this world where we have hundreds

00:11:17,100 --> 00:11:20,850
and thousands of clusters I'd like to

00:11:18,810 --> 00:11:22,860
hand it over to Eric who's gonna talk a

00:11:20,850 --> 00:11:26,600
lot about the impermanence improvements

00:11:22,860 --> 00:11:26,600
that we've made over the last year

00:11:26,720 --> 00:11:32,700
great so as Ethan said one of the big

00:11:30,270 --> 00:11:34,740
focuses in the kubernetes space over the

00:11:32,700 --> 00:11:37,590
last year was improving the performance

00:11:34,740 --> 00:11:40,350
of the kubernetes provider when dealing

00:11:37,590 --> 00:11:42,510
with large clusters many accounts I

00:11:40,350 --> 00:11:44,340
don't know if any of you who've operated

00:11:42,510 --> 00:11:45,510
spinnaker have heard of cloud driver if

00:11:44,340 --> 00:11:47,490
you've ever seen it on your metrics

00:11:45,510 --> 00:11:48,810
dashboards or anything like that if you

00:11:47,490 --> 00:11:54,420
haven't I'm gonna introduce it for you

00:11:48,810 --> 00:11:56,340
in the next slide so I guess before I

00:11:54,420 --> 00:11:57,480
talk in a little bit of detail about

00:11:56,340 --> 00:11:59,820
some of the improvements that we made

00:11:57,480 --> 00:12:01,860
I'll briefly go over kind of what the

00:11:59,820 --> 00:12:04,110
caching architecture is that is behind

00:12:01,860 --> 00:12:06,840
spinnaker and a lot of this base caching

00:12:04,110 --> 00:12:08,070
architecture is the same across various

00:12:06,840 --> 00:12:10,170
providers but I'll talk about it

00:12:08,070 --> 00:12:16,080
specifically in the context of the

00:12:10,170 --> 00:12:18,060
kubernetes v2 provider so the spinnaker

00:12:16,080 --> 00:12:19,830
is continuously polling all of your

00:12:18,060 --> 00:12:22,170
architect all of your infrastructure to

00:12:19,830 --> 00:12:24,210
kind of build its state of the world so

00:12:22,170 --> 00:12:25,710
it's I think it's configurable but it's

00:12:24,210 --> 00:12:26,850
every minute or two minutes kind of

00:12:25,710 --> 00:12:28,800
pulling and saying okay tell me

00:12:26,850 --> 00:12:31,980
everything that you know about all the

00:12:28,800 --> 00:12:34,620
infrastructure that is deployed and then

00:12:31,980 --> 00:12:37,410
it's storing all of that in its cache

00:12:34,620 --> 00:12:39,540
which historically was only Redis now

00:12:37,410 --> 00:12:41,040
there's the option to use sequel I know

00:12:39,540 --> 00:12:43,080
a lot of people have started moving over

00:12:41,040 --> 00:12:45,810
to sequel because it is really a better

00:12:43,080 --> 00:12:47,280
fit for the relational model of the data

00:12:45,810 --> 00:12:49,110
that's being stored there and has better

00:12:47,280 --> 00:12:50,490
performance characteristics but

00:12:49,110 --> 00:12:54,720
obviously there's still a lot of Redis

00:12:50,490 --> 00:12:57,660
usage out there as well and a lot of the

00:12:54,720 --> 00:13:00,000
memory and CPU usage of cloud driver

00:12:57,660 --> 00:13:02,160
comes from these caching agents that are

00:13:00,000 --> 00:13:04,020
doing all this work to figure out what

00:13:02,160 --> 00:13:06,060
the state of the world is and so in the

00:13:04,020 --> 00:13:09,660
case of kubernetes that's actually just

00:13:06,060 --> 00:13:11,670
doing Cube control lists on all the

00:13:09,660 --> 00:13:13,230
clusters the UF configured for other

00:13:11,670 --> 00:13:15,330
providers it's kind of hitting whatever

00:13:13,230 --> 00:13:17,960
API is relevant for understanding what's

00:13:15,330 --> 00:13:17,960
deployed there

00:13:18,930 --> 00:13:22,050
I think it's one slight comedies you

00:13:20,700 --> 00:13:24,029
know right now we're doing this via

00:13:22,050 --> 00:13:25,290
shelling out to keep control list we

00:13:24,029 --> 00:13:26,940
have thought about kind of maybe it's

00:13:25,290 --> 00:13:29,100
better to use a client library for that

00:13:26,940 --> 00:13:31,920
I think at the time that the v2 provider

00:13:29,100 --> 00:13:34,050
was written there was a lot of stuff

00:13:31,920 --> 00:13:35,940
that wasn't exposed through the client

00:13:34,050 --> 00:13:37,770
library kind of there's a lot of logic

00:13:35,940 --> 00:13:39,930
built in to keep control which is slowly

00:13:37,770 --> 00:13:41,130
kind of getting better so that is

00:13:39,930 --> 00:13:41,760
something that we could think about in

00:13:41,130 --> 00:13:43,890
the future

00:13:41,760 --> 00:13:45,720
moving stuff moving away from just

00:13:43,890 --> 00:13:49,920
shelling out to keep control and using

00:13:45,720 --> 00:13:51,600
the client library and so then when we

00:13:49,920 --> 00:13:53,640
have another micro service that wants to

00:13:51,600 --> 00:13:55,170
know something about what you have

00:13:53,640 --> 00:13:57,930
deployed instead of going directly

00:13:55,170 --> 00:14:01,140
talking to your cluster it asks cloud

00:13:57,930 --> 00:14:02,339
driver which then asks the cache kind of

00:14:01,140 --> 00:14:05,490
what's going on with this particular

00:14:02,339 --> 00:14:07,050
deployment so as an example if Orca is

00:14:05,490 --> 00:14:09,000
in the middle of a pipeline and wants to

00:14:07,050 --> 00:14:11,180
know hey is this replica set that I've

00:14:09,000 --> 00:14:13,770
just deployed stable and ready for use

00:14:11,180 --> 00:14:15,750
then Orca is going to ask cloud driver

00:14:13,770 --> 00:14:17,850
who's gonna look in the cache and return

00:14:15,750 --> 00:14:21,150
that data and similarly if you want to

00:14:17,850 --> 00:14:22,890
load your clusters tab in deck deck of

00:14:21,150 --> 00:14:24,570
course only talks to gate but then gate

00:14:22,890 --> 00:14:27,320
will ask cloud driver and same thing

00:14:24,570 --> 00:14:27,320
will look in the cache

00:14:27,360 --> 00:14:32,610
I guess there's one exception here is

00:14:29,790 --> 00:14:34,530
that if wive manifest mode is on

00:14:32,610 --> 00:14:36,120
some of you may have enabled that for

00:14:34,530 --> 00:14:38,520
performance reasons in the past if you

00:14:36,120 --> 00:14:40,170
haven't enabled it don't we think that

00:14:38,520 --> 00:14:42,660
we fixed all those performance issues I

00:14:40,170 --> 00:14:46,440
won't tell you how and if you know how

00:14:42,660 --> 00:14:49,440
don't tell anyone else here and but if

00:14:46,440 --> 00:14:52,050
that's on then actually cloud driver

00:14:49,440 --> 00:14:53,670
just directly queries the cluster when

00:14:52,050 --> 00:14:57,570
it's doing a deployment so you don't

00:14:53,670 --> 00:14:59,220
have to wait for the cache top date and

00:14:57,570 --> 00:15:01,560
so what happens if caching is

00:14:59,220 --> 00:15:03,990
inefficient so the first thing that

00:15:01,560 --> 00:15:06,780
happens is that you get really high CPU

00:15:03,990 --> 00:15:09,089
and memory usage of cloud driver so this

00:15:06,780 --> 00:15:12,300
is an actual graph of cloud driver

00:15:09,089 --> 00:15:14,880
memory usage if you have a lot of stuff

00:15:12,300 --> 00:15:17,670
deployed to your cluster funny story is

00:15:14,880 --> 00:15:19,290
actually every every emoji has kind of a

00:15:17,670 --> 00:15:20,550
Unicode code point if you look at the

00:15:19,290 --> 00:15:22,620
description of this one is actually

00:15:20,550 --> 00:15:25,890
cloud driver memory usage which is how I

00:15:22,620 --> 00:15:27,890
found it and then the second thing that

00:15:25,890 --> 00:15:30,180
can happen is that you can end up with

00:15:27,890 --> 00:15:32,850
pipeline deploys timing out

00:15:30,180 --> 00:15:34,740
because they're waiting for something to

00:15:32,850 --> 00:15:36,720
show up in the cash but the cash is

00:15:34,740 --> 00:15:40,380
refreshing so slowly that it never

00:15:36,720 --> 00:15:42,089
actually shows up there in time so some

00:15:40,380 --> 00:15:46,260
of you may or may not have seen this

00:15:42,089 --> 00:15:47,520
issue where you're waiting for a refresh

00:15:46,260 --> 00:15:49,980
that's right if you've ever seen a

00:15:47,520 --> 00:15:53,670
forced cash refresh stage take exactly

00:15:49,980 --> 00:15:55,649
12 minutes might be that your cash is

00:15:53,670 --> 00:15:58,500
not updating fast enough so I wanted to

00:15:55,649 --> 00:16:00,810
actually do a demo of waiting 12 minutes

00:15:58,500 --> 00:16:02,550
with the forced cash refresh but my

00:16:00,810 --> 00:16:04,260
section is only 12 minutes so I figured

00:16:02,550 --> 00:16:10,800
I'd probably like want some other slides

00:16:04,260 --> 00:16:12,000
too and so with that context this is

00:16:10,800 --> 00:16:13,830
just kind of the end result I won't

00:16:12,000 --> 00:16:15,000
obviously go into all of the kind of

00:16:13,830 --> 00:16:17,670
performance improvements that went into

00:16:15,000 --> 00:16:21,630
there but after kind of a lot of months

00:16:17,670 --> 00:16:24,180
of work this is just the total number of

00:16:21,630 --> 00:16:26,250
yeah this is number of allocated objects

00:16:24,180 --> 00:16:28,470
by the JVM during a caching cycle of

00:16:26,250 --> 00:16:29,940
cloud driver mcc you've gone from in

00:16:28,470 --> 00:16:32,160
this particular example I forget how

00:16:29,940 --> 00:16:33,600
many accounts I had configured and how

00:16:32,160 --> 00:16:34,230
much was in those accounts but it was a

00:16:33,600 --> 00:16:35,970
lot

00:16:34,230 --> 00:16:37,650
we've gone from a hundred and thirty

00:16:35,970 --> 00:16:39,300
three million to thirty seven million

00:16:37,650 --> 00:16:42,990
objects that's basically like a factor

00:16:39,300 --> 00:16:44,790
of roughly three to four X reduction in

00:16:42,990 --> 00:16:48,120
object allocations we just really

00:16:44,790 --> 00:16:50,339
reduces the pressure on the JVM and this

00:16:48,120 --> 00:16:52,560
eliminated one bug where I think some

00:16:50,339 --> 00:16:54,450
users were seeing just cloud revert

00:16:52,560 --> 00:16:56,430
dying with the garbage collection

00:16:54,450 --> 00:16:57,930
overhead exceeded which is what happens

00:16:56,430 --> 00:17:00,209
when Java just can't keep up with the

00:16:57,930 --> 00:17:02,790
number of objects you're creating and

00:17:00,209 --> 00:17:03,930
then also contributed just for people

00:17:02,790 --> 00:17:06,120
who were still able to run it just

00:17:03,930 --> 00:17:08,880
reducing that CPU usage so that maybe

00:17:06,120 --> 00:17:10,829
you don't need like a 450 CPU core

00:17:08,880 --> 00:17:12,449
machine to run cloud driver so divide

00:17:10,829 --> 00:17:13,949
that by like three now and that's what

00:17:12,449 --> 00:17:21,600
you need so there's still a bit of work

00:17:13,949 --> 00:17:23,610
to do it's kind of a sort of a different

00:17:21,600 --> 00:17:26,480
axis of work that we did in the cloud

00:17:23,610 --> 00:17:30,660
driver performance and resiliency space

00:17:26,480 --> 00:17:32,340
is looking at what happens looking at

00:17:30,660 --> 00:17:34,970
kind of reducing startup time and

00:17:32,340 --> 00:17:36,960
increasing the resiliency towards having

00:17:34,970 --> 00:17:40,320
kubernetes clusters that are unreachable

00:17:36,960 --> 00:17:42,150
so I think one thing that's very common

00:17:40,320 --> 00:17:42,260
with the kubernetes provider that wasn't

00:17:42,150 --> 00:17:44,090
a

00:17:42,260 --> 00:17:46,550
common with other providers is that

00:17:44,090 --> 00:17:48,380
you're very frequently adding and

00:17:46,550 --> 00:17:51,130
removing clusters as teams on board

00:17:48,380 --> 00:17:53,180
clusters teams removed them and so you

00:17:51,130 --> 00:17:55,220
pretty frequently end up with a

00:17:53,180 --> 00:17:57,410
situation where maybe your cloud rubric

00:17:55,220 --> 00:17:59,780
and Figg has a cluster still in there

00:17:57,410 --> 00:18:01,160
that you turn down and haven't removed

00:17:59,780 --> 00:18:03,320
from your cloud report configure anymore

00:18:01,160 --> 00:18:04,880
or maybe it is a cluster that should be

00:18:03,320 --> 00:18:06,740
there but for some reason it's

00:18:04,880 --> 00:18:09,260
unreachable due to counter some network

00:18:06,740 --> 00:18:12,740
partition or something like that and so

00:18:09,260 --> 00:18:14,690
before some recent changes start up

00:18:12,740 --> 00:18:15,980
would basically block waiting trying to

00:18:14,690 --> 00:18:17,420
talk to that cluster it would eventually

00:18:15,980 --> 00:18:20,420
timeout but I think it would take

00:18:17,420 --> 00:18:21,590
something like 15 or 20 minutes just

00:18:20,420 --> 00:18:25,250
trying to communicate with that cluster

00:18:21,590 --> 00:18:26,990
before it finally timed out and then if

00:18:25,250 --> 00:18:28,850
the cluster went down while spinnaker

00:18:26,990 --> 00:18:30,230
was already up you would see a lot of

00:18:28,850 --> 00:18:31,550
degraded performance because there were

00:18:30,230 --> 00:18:33,500
a number of workflows that kind of

00:18:31,550 --> 00:18:40,520
depended on talking to you all of the

00:18:33,500 --> 00:18:42,950
available clusters so in order to help

00:18:40,520 --> 00:18:45,380
both of those problems what we did was

00:18:42,950 --> 00:18:47,180
actually I should mention one specific

00:18:45,380 --> 00:18:48,440
thing that we do on startup so the

00:18:47,180 --> 00:18:51,800
reason this was taking a long time on

00:18:48,440 --> 00:18:53,210
startup is that on startup we were

00:18:51,800 --> 00:18:54,800
trying to understand what permissions

00:18:53,210 --> 00:18:57,320
spinnaker was running ask so that we

00:18:54,800 --> 00:18:59,480
could fail fast right away if spinnaker

00:18:57,320 --> 00:19:01,340
didn't have permission to list

00:18:59,480 --> 00:19:02,990
deployments list network policies in a

00:19:01,340 --> 00:19:05,300
particular cluster we would just mark

00:19:02,990 --> 00:19:07,160
that as not something from a vinegar has

00:19:05,300 --> 00:19:08,660
permission to do and then stop trying as

00:19:07,160 --> 00:19:10,880
opposed to just throwing errors

00:19:08,660 --> 00:19:13,730
throughout the entire lifetime of the

00:19:10,880 --> 00:19:15,400
process so that was kind of what was

00:19:13,730 --> 00:19:17,360
causing startups to take a long time

00:19:15,400 --> 00:19:19,580
both in the case of an unreachable

00:19:17,360 --> 00:19:20,960
cluster and also just in the case where

00:19:19,580 --> 00:19:22,610
you had a lot of accounts because that's

00:19:20,960 --> 00:19:24,410
just a lot of work to do on startup to

00:19:22,610 --> 00:19:26,120
go talk to every single cluster that you

00:19:24,410 --> 00:19:28,940
have and try to figure out what

00:19:26,120 --> 00:19:31,700
kubernetes kinds are readable so to help

00:19:28,940 --> 00:19:33,980
both of those problems remove this

00:19:31,700 --> 00:19:35,570
permission currying out of the single

00:19:33,980 --> 00:19:38,570
threaded startup loop and kind of

00:19:35,570 --> 00:19:40,670
deferred that to on-demand so we still

00:19:38,570 --> 00:19:42,110
only check everything once but we do it

00:19:40,670 --> 00:19:44,090
on demand the first time it's needed

00:19:42,110 --> 00:19:46,400
which frees up that startup thread so

00:19:44,090 --> 00:19:48,680
that things start up a lot faster and

00:19:46,400 --> 00:19:51,470
that also pushes errors down to only

00:19:48,680 --> 00:19:53,180
affecting the particular cluster that's

00:19:51,470 --> 00:19:56,119
unreachable or that has issues

00:19:53,180 --> 00:19:58,580
so now as

00:19:56,119 --> 00:20:00,259
wagwan use kind of a boring image it's

00:19:58,580 --> 00:20:02,539
just a log line from the cloud driver

00:20:00,259 --> 00:20:04,519
logs but if you've seen that line say

00:20:02,539 --> 00:20:05,659
like 47 minutes the start of cloud

00:20:04,519 --> 00:20:07,789
driver this is probably gonna be pretty

00:20:05,659 --> 00:20:10,039
exciting if you haven't seen that yeah

00:20:07,789 --> 00:20:14,299
it's just a boring line of white text

00:20:10,039 --> 00:20:16,220
there so startup is much faster and also

00:20:14,299 --> 00:20:18,559
now if one of your clusters is

00:20:16,220 --> 00:20:20,360
unreachable it will only affect that

00:20:18,559 --> 00:20:21,499
cluster you can still deploy do

00:20:20,360 --> 00:20:23,179
everything else with all the other

00:20:21,499 --> 00:20:25,039
clusters you'll see errors in the logs

00:20:23,179 --> 00:20:26,840
for that particular cluster but it won't

00:20:25,039 --> 00:20:29,239
affect your other workflows you won't

00:20:26,840 --> 00:20:34,460
see deck starting meters spinning

00:20:29,239 --> 00:20:37,450
forever because it's timing out and so I

00:20:34,460 --> 00:20:40,100
guess in summary for this section

00:20:37,450 --> 00:20:43,039
you know these performance improvements

00:20:40,100 --> 00:20:44,779
have helped us you know allow the

00:20:43,039 --> 00:20:47,480
kubernetes v2 provider to scale to much

00:20:44,779 --> 00:20:50,269
larger installations so I guess along

00:20:47,480 --> 00:20:51,799
two axes number one just number of

00:20:50,269 --> 00:20:53,330
accounts that you have configured and

00:20:51,799 --> 00:20:55,909
number two just amount of stuff you have

00:20:53,330 --> 00:20:57,919
deployed in each account so obviously

00:20:55,909 --> 00:21:00,230
still some more work to do in the space

00:20:57,919 --> 00:21:01,940
definitely interested to hear anyone's

00:21:00,230 --> 00:21:03,529
continued performance problems and work

00:21:01,940 --> 00:21:05,389
with you on them but at least at this

00:21:03,529 --> 00:21:07,549
point you've unblocked kind of some more

00:21:05,389 --> 00:21:10,909
headspace in terms of being able to

00:21:07,549 --> 00:21:12,859
deploy be able to manage larger clusters

00:21:10,909 --> 00:21:16,639
and more clusters with the kubernetes v2

00:21:12,859 --> 00:21:18,590
provider and so with that I will pass it

00:21:16,639 --> 00:21:20,989
over to Maggie to talk a little bit

00:21:18,590 --> 00:21:23,440
about kind of what our plans are for the

00:21:20,989 --> 00:21:23,440
coming year

00:21:23,739 --> 00:21:28,879
thank you Eric

00:21:25,730 --> 00:21:30,799
all right so a lot of our future work is

00:21:28,879 --> 00:21:33,919
kind of centered around the problems of

00:21:30,799 --> 00:21:36,259
how should users manage the complexity

00:21:33,919 --> 00:21:37,730
of using kubernetes with spinnaker to

00:21:36,259 --> 00:21:39,889
what extent should spinnaker teach

00:21:37,730 --> 00:21:41,119
kubernetes to beginning users of both

00:21:39,889 --> 00:21:42,769
spinnaker and kubernetes

00:21:41,119 --> 00:21:46,220
and kind of what is the right level of

00:21:42,769 --> 00:21:48,559
abstraction to expose in spinnaker and

00:21:46,220 --> 00:21:50,899
so as Ethan kind of went over the v1

00:21:48,559 --> 00:21:52,909
provider mimicked the wizard based model

00:21:50,899 --> 00:21:54,409
of the more VM based providers and sort

00:21:52,909 --> 00:21:56,570
of exposed a similar level of

00:21:54,409 --> 00:21:57,950
abstraction we kind of figured out that

00:21:56,570 --> 00:21:59,779
you know wasn't the right answer as

00:21:57,950 --> 00:22:01,879
people move towards more of a get offs

00:21:59,779 --> 00:22:03,859
workflow and instead we kind of expose

00:22:01,879 --> 00:22:06,320
input for representation of any Cooper

00:22:03,859 --> 00:22:07,940
nodes resources you wanted which I think

00:22:06,320 --> 00:22:09,380
we're discovering to an extent did

00:22:07,940 --> 00:22:10,790
potentially leave some

00:22:09,380 --> 00:22:12,890
people who are just getting started with

00:22:10,790 --> 00:22:14,150
kubernetes or who maybe just kind of

00:22:12,890 --> 00:22:16,220
want to get a proof-of-concept set up

00:22:14,150 --> 00:22:17,570
behind and so I think one area of our

00:22:16,220 --> 00:22:19,130
future work will be investigating you

00:22:17,570 --> 00:22:21,620
know is there kind of an easier level of

00:22:19,130 --> 00:22:23,180
abstraction to expose in the v2 provider

00:22:21,620 --> 00:22:25,720
kind of alongside the morgue adopts

00:22:23,180 --> 00:22:28,310
workflow for that subset of users

00:22:25,720 --> 00:22:30,110
another area of work I'm sure many of

00:22:28,310 --> 00:22:31,730
y'all heard the Netflix talk on their

00:22:30,110 --> 00:22:33,200
new effort towards managed delivery I

00:22:31,730 --> 00:22:35,480
think something we'd love to see is kind

00:22:33,200 --> 00:22:37,910
of convergence on what that type of spec

00:22:35,480 --> 00:22:41,960
would look like for kubernetes so that's

00:22:37,910 --> 00:22:43,760
another thread of work yeah and then I

00:22:41,960 --> 00:22:46,010
think finally I'm along the line of

00:22:43,760 --> 00:22:48,230
exposing you know kubernetes specific

00:22:46,010 --> 00:22:50,300
complexity to spinnaker users right now

00:22:48,230 --> 00:22:52,010
there are some resources that are common

00:22:50,300 --> 00:22:55,400
to many kubernetes workflows that aren't

00:22:52,010 --> 00:22:57,470
necessarily exposed in the UI spinnaker

00:22:55,400 --> 00:22:59,660
kind of has its own concept of you know

00:22:57,470 --> 00:23:01,400
clusters and load balancers and

00:22:59,660 --> 00:23:02,660
firewalls being sort of the only things

00:23:01,400 --> 00:23:05,330
that matter and what we're finding as we

00:23:02,660 --> 00:23:07,310
talk to more kubernetes users is that's

00:23:05,330 --> 00:23:09,410
just not necessarily true and so kind of

00:23:07,310 --> 00:23:11,690
deciding which kubernetes only resources

00:23:09,410 --> 00:23:13,730
to expose how to expose them how to

00:23:11,690 --> 00:23:15,890
potentially adjust the naming to just be

00:23:13,730 --> 00:23:17,930
less confusing for people who are kind

00:23:15,890 --> 00:23:21,410
of only coming to spinnaker to use

00:23:17,930 --> 00:23:23,630
kubernetes and with that if any of this

00:23:21,410 --> 00:23:25,790
sounds interesting to you both the

00:23:23,630 --> 00:23:27,770
future work and any of the previous work

00:23:25,790 --> 00:23:29,300
we mentioned that are ongoing efforts we

00:23:27,770 --> 00:23:31,190
would just absolutely love to have you

00:23:29,300 --> 00:23:34,220
at the cig it's definitely my favorite

00:23:31,190 --> 00:23:36,740
hour of the week so we meet every other

00:23:34,220 --> 00:23:38,030
week it kind of feels like everyone is

00:23:36,740 --> 00:23:40,580
in the same room even though it's over

00:23:38,030 --> 00:23:42,410
hangout it was really great to meet a

00:23:40,580 --> 00:23:43,940
lot of the recurring cig members today

00:23:42,410 --> 00:23:46,640
at the summit

00:23:43,940 --> 00:23:49,040
please come even if you aren't yet using

00:23:46,640 --> 00:23:50,840
you know spinnaker and kubernetes or if

00:23:49,040 --> 00:23:52,310
you're still using the v1 provider or if

00:23:50,840 --> 00:23:54,530
you're just evaluating or if you're a

00:23:52,310 --> 00:23:56,480
power user and whether you're on a

00:23:54,530 --> 00:24:01,490
central team or an end user we would

00:23:56,480 --> 00:24:03,410
just absolutely love to have you so with

00:24:01,490 --> 00:24:05,690
that just a few of the logos of

00:24:03,410 --> 00:24:07,790
companies that regularly attend and this

00:24:05,690 --> 00:24:11,030
is just a subset often we have you know

00:24:07,790 --> 00:24:13,130
25 to 30 people on the call so please

00:24:11,030 --> 00:24:14,450
come and I will just pass it off to Eric

00:24:13,130 --> 00:24:19,490
for a little more info on like what you

00:24:14,450 --> 00:24:22,040
could possibly bring to the cig great so

00:24:19,490 --> 00:24:23,330
um if you do come to this egg which we

00:24:22,040 --> 00:24:24,950
hope you do just

00:24:23,330 --> 00:24:26,780
kind of some thoughts about questions

00:24:24,950 --> 00:24:28,790
ideas that you can bring so I think one

00:24:26,780 --> 00:24:31,850
of the things that we really like to

00:24:28,790 --> 00:24:33,350
hear is things that spinnaker the

00:24:31,850 --> 00:24:35,990
kubernetes feature provider didn't quite

00:24:33,350 --> 00:24:38,420
solve for you things that we should

00:24:35,990 --> 00:24:40,460
think about in terms of adding features

00:24:38,420 --> 00:24:41,630
or closing gaps or honestly maybe

00:24:40,460 --> 00:24:42,830
something that's just a bug that we

00:24:41,630 --> 00:24:45,440
thought was actually working properly

00:24:42,830 --> 00:24:48,140
and I think one really important point

00:24:45,440 --> 00:24:49,610
about that is we want to hear about it

00:24:48,140 --> 00:24:51,830
even if it's something that you managed

00:24:49,610 --> 00:24:53,510
to find a workaround to solve because

00:24:51,830 --> 00:24:56,870
they know a lot of you and a lot of the

00:24:53,510 --> 00:24:58,760
people that attend the sig are operators

00:24:56,870 --> 00:25:01,850
of spinnaker at your company and maybe

00:24:58,760 --> 00:25:03,230
you're kind of the dev tools platform

00:25:01,850 --> 00:25:06,530
team I think there's a million different

00:25:03,230 --> 00:25:08,480
names for it and you have kind of

00:25:06,530 --> 00:25:10,760
customers or users at your company that

00:25:08,480 --> 00:25:12,200
bring things to you and sometimes you

00:25:10,760 --> 00:25:14,180
find kind of some workaround that works

00:25:12,200 --> 00:25:15,380
for you and so that might just solve the

00:25:14,180 --> 00:25:17,990
problem and you could forget about it

00:25:15,380 --> 00:25:19,460
there but if you know in thinking about

00:25:17,990 --> 00:25:21,260
that problem with your user you think

00:25:19,460 --> 00:25:23,180
hey there'd be a way for spinnaker to

00:25:21,260 --> 00:25:24,830
solve this problem better or I really

00:25:23,180 --> 00:25:26,720
don't like the workaround that I had to

00:25:24,830 --> 00:25:28,250
do for this I'll close my eyes and just

00:25:26,720 --> 00:25:29,510
kind of do it please bring it to the

00:25:28,250 --> 00:25:31,010
stakes that we can talk about that and

00:25:29,510 --> 00:25:32,660
think about whether that's a reasonable

00:25:31,010 --> 00:25:34,970
problem for spinnaker to solve so you

00:25:32,660 --> 00:25:36,980
don't need your work around anymore and

00:25:34,970 --> 00:25:39,500
a couple of examples of that these are

00:25:36,980 --> 00:25:41,060
pretty small examples but good examples

00:25:39,500 --> 00:25:43,040
of people bringing problems to the sig

00:25:41,060 --> 00:25:46,130
and us kind of talking together about

00:25:43,040 --> 00:25:49,400
what a good solution would be first one

00:25:46,130 --> 00:25:50,960
is spell evaluation interacting poorly

00:25:49,400 --> 00:25:52,190
with hell manifest so Maggie talked

00:25:50,960 --> 00:25:53,720
about that a little bit earlier that

00:25:52,190 --> 00:25:55,250
just came out of someone bring that

00:25:53,720 --> 00:25:57,140
problem to the sig and there were

00:25:55,250 --> 00:26:00,020
workarounds involved a lot a lot of back

00:25:57,140 --> 00:26:02,480
slashes more like more back slashes than

00:26:00,020 --> 00:26:04,190
you've ever seen but we brought you know

00:26:02,480 --> 00:26:06,200
we talked about that at the sig and

00:26:04,190 --> 00:26:09,920
eventually came up with what is I think

00:26:06,200 --> 00:26:11,840
old much better solution and the second

00:26:09,920 --> 00:26:14,600
solution is having an override namespace

00:26:11,840 --> 00:26:16,310
option in the deploy manifest stage I

00:26:14,600 --> 00:26:17,870
think originally we didn't have that

00:26:16,310 --> 00:26:19,610
because the point was that you should

00:26:17,870 --> 00:26:21,650
just include the namespace in your

00:26:19,610 --> 00:26:24,410
manifest but I think what we learned

00:26:21,650 --> 00:26:25,250
from talking to people in the sig he's

00:26:24,410 --> 00:26:27,680
that a lot of people were using

00:26:25,250 --> 00:26:29,900
spinnaker to deploy helm charts and helm

00:26:27,680 --> 00:26:32,870
charts often don't specify the namespace

00:26:29,900 --> 00:26:34,820
so unless there was some way for you to

00:26:32,870 --> 00:26:35,730
override that using spinnaker it was

00:26:34,820 --> 00:26:37,110
just ending up in the dip

00:26:35,730 --> 00:26:38,970
name space so kind of after some

00:26:37,110 --> 00:26:45,360
discussions at the cig we added this

00:26:38,970 --> 00:26:46,890
this option here another thing this is

00:26:45,360 --> 00:26:49,770
kind of a little bit of a offshoot of

00:26:46,890 --> 00:26:51,990
this cig but we've started trying to be

00:26:49,770 --> 00:26:55,530
much better about triaging incoming

00:26:51,990 --> 00:26:57,360
github issues to the project so I think

00:26:55,530 --> 00:26:59,820
if you've reported github issue in the

00:26:57,360 --> 00:27:02,040
past you may or may not have encountered

00:26:59,820 --> 00:27:03,720
spinnaker bots who shows up after 45

00:27:02,040 --> 00:27:05,730
days marks the issue stale and then

00:27:03,720 --> 00:27:07,800
shows up after 45 more days and closes

00:27:05,730 --> 00:27:08,940
it we really want to reduce the number

00:27:07,800 --> 00:27:11,160
of cases about happening because that's

00:27:08,940 --> 00:27:13,440
really not a great experience and so

00:27:11,160 --> 00:27:15,510
what we've started doing Maggie thandai

00:27:13,440 --> 00:27:16,830
and I every couple of weeks just going

00:27:15,510 --> 00:27:19,680
through and reading through every issue

00:27:16,830 --> 00:27:21,960
that is related to kubernetes that gets

00:27:19,680 --> 00:27:24,720
reported in the spinnaker spinnaker repo

00:27:21,960 --> 00:27:27,000
triaging those into you know ones that

00:27:24,720 --> 00:27:28,830
we should fix ones we should close and I

00:27:27,000 --> 00:27:31,350
guess the tie back to the sig is there's

00:27:28,830 --> 00:27:32,640
a class of those that we bring to the

00:27:31,350 --> 00:27:35,310
sig for further discussion

00:27:32,640 --> 00:27:36,870
so look to see us kind of commenting and

00:27:35,310 --> 00:27:37,860
bring these things up if you feel

00:27:36,870 --> 00:27:40,890
there's an issue that's not getting

00:27:37,860 --> 00:27:43,860
attention please bring it to the sig we

00:27:40,890 --> 00:27:45,920
can talk about it there as well and then

00:27:43,860 --> 00:27:48,510
one other point that I'll plug is a

00:27:45,920 --> 00:27:49,740
subset of the ones that we look at the

00:27:48,510 --> 00:27:52,620
issue and say hey this is a bug we

00:27:49,740 --> 00:27:54,150
should fix it obviously the three of us

00:27:52,620 --> 00:27:56,640
don't necessarily have bandwidth to fix

00:27:54,150 --> 00:27:58,200
all these issues so we've started

00:27:56,640 --> 00:27:59,070
tagging things beginner-friendly if we

00:27:58,200 --> 00:28:01,350
think that it's something that's

00:27:59,070 --> 00:28:03,360
accessible for a new contributor to do

00:28:01,350 --> 00:28:04,680
so these are ones that are pre vetted as

00:28:03,360 --> 00:28:06,600
hey we've looked at this we think this

00:28:04,680 --> 00:28:08,460
is a valid issue that should be fixed

00:28:06,600 --> 00:28:10,890
and we think it's something to be a good

00:28:08,460 --> 00:28:13,140
first or second issue so please if you

00:28:10,890 --> 00:28:14,880
are interested in contributing that's a

00:28:13,140 --> 00:28:20,010
great place to find some some places to

00:28:14,880 --> 00:28:21,380
contribute and I think with that just

00:28:20,010 --> 00:28:23,700
want to thank everyone for listening and

00:28:21,380 --> 00:28:26,180
we'll use whatever time we have left for

00:28:23,700 --> 00:28:26,180
questions

00:28:31,460 --> 00:28:35,490
all right a quick announcement before we

00:28:33,660 --> 00:28:37,860
start with questions if you could all go

00:28:35,490 --> 00:28:40,140
on to the spinnaker summit app by Moe

00:28:37,860 --> 00:28:41,450
dev and rate and give feedback for the

00:28:40,140 --> 00:28:44,220
talk that would be greatly appreciated

00:28:41,450 --> 00:28:45,480
now if anybody has questions please

00:28:44,220 --> 00:28:47,780
raise your hand and I'll bring the mic

00:28:45,480 --> 00:28:47,780
to you

00:28:56,040 --> 00:29:00,180
you mentioned the dynamic account

00:28:58,260 --> 00:29:03,480
configuration that's there is that

00:29:00,180 --> 00:29:07,650
specifically for kubernetes itself as

00:29:03,480 --> 00:29:10,890
the provider or spinnaker in general so

00:29:07,650 --> 00:29:14,030
it has only been introduced to support

00:29:10,890 --> 00:29:16,140
kubernetes and Cloud Foundry the

00:29:14,030 --> 00:29:18,930
implementation though could possibly

00:29:16,140 --> 00:29:23,460
lend itself to like other cloud

00:29:18,930 --> 00:29:25,320
providers as well so we haven't really

00:29:23,460 --> 00:29:27,450
had too much interest from any of the

00:29:25,320 --> 00:29:28,530
other kinds of providers like AWS or I

00:29:27,450 --> 00:29:30,930
don't know have you guys heard it for

00:29:28,530 --> 00:29:33,960
Google cloud No

00:29:30,930 --> 00:29:35,190
so if I mean if somebody wanted to go in

00:29:33,960 --> 00:29:42,930
and do that it could they could

00:29:35,190 --> 00:29:45,360
certainly do that okay so we use v1 and

00:29:42,930 --> 00:29:46,280
that force cache refresh issue happens

00:29:45,360 --> 00:29:48,270
all the time

00:29:46,280 --> 00:29:51,170
sort of those caching improvements

00:29:48,270 --> 00:29:53,580
happening to the v1 provider as well

00:29:51,170 --> 00:29:55,140
know so all the improvements have

00:29:53,580 --> 00:29:58,050
happened over the last year of v2 and

00:29:55,140 --> 00:29:59,520
we're really focusing more on v2 to try

00:29:58,050 --> 00:30:02,100
to kind of pull those improvements there

00:29:59,520 --> 00:30:04,350
I think one thing we'd love to talk to

00:30:02,100 --> 00:30:05,910
you about is kind of why you're using v1

00:30:04,350 --> 00:30:07,350
and kind of what a migration path would

00:30:05,910 --> 00:30:08,670
be to v2 and we realize like they're

00:30:07,350 --> 00:30:09,900
pretty different and so the idea is not

00:30:08,670 --> 00:30:11,370
like hey let's just like convince

00:30:09,900 --> 00:30:13,470
everyone to move over but like I guess

00:30:11,370 --> 00:30:15,660
to phrase it another way like what would

00:30:13,470 --> 00:30:18,630
we need to add to v2 in order to

00:30:15,660 --> 00:30:20,850
convince you to move over to v2 I think

00:30:18,630 --> 00:30:22,980
we're convinced that like it's a better

00:30:20,850 --> 00:30:25,380
path forward however we're so ingrained

00:30:22,980 --> 00:30:27,420
like we have a kind of a snowflake II

00:30:25,380 --> 00:30:28,880
hacky way of generating our pipeline

00:30:27,420 --> 00:30:30,960
JSON

00:30:28,880 --> 00:30:33,180
we've been on spinnaker for a few years

00:30:30,960 --> 00:30:35,250
and you know p1 was just there so now

00:30:33,180 --> 00:30:36,840
it's a nonzero amount of work to migrate

00:30:35,250 --> 00:30:38,580
so yeah I guess phrase another way like

00:30:36,840 --> 00:30:39,690
what could we do to make that migration

00:30:38,580 --> 00:30:42,210
easier as well

00:30:39,690 --> 00:30:44,280
you know obviously I don't think it will

00:30:42,210 --> 00:30:46,920
ever be a zero effort migration but

00:30:44,280 --> 00:30:48,660
maybe we can help make that easier than

00:30:46,920 --> 00:30:51,060
asking you to rewrite all your pipelines

00:30:48,660 --> 00:30:52,860
I think I'll take a way to make me there

00:30:51,060 --> 00:30:54,000
I think we can make it easier than ask

00:30:52,860 --> 00:30:55,200
me to rewrite all your pipeline so

00:30:54,000 --> 00:30:58,640
definitely something I would love to

00:30:55,200 --> 00:30:58,640
talk about thank you

00:31:07,440 --> 00:31:14,490
I heard Lee mentioned about the captain

00:31:10,530 --> 00:31:16,920
I think it was captain it was like one

00:31:14,490 --> 00:31:19,710
of the first few slides can you say bit

00:31:16,920 --> 00:31:22,080
more is it already at backlog item for

00:31:19,710 --> 00:31:25,920
you what what do you think about it why

00:31:22,080 --> 00:31:28,320
and all that yeah so I have see like a

00:31:25,920 --> 00:31:31,080
month ago I talked with the creator or

00:31:28,320 --> 00:31:32,700
two of the creators of captain and they

00:31:31,080 --> 00:31:34,260
they were interested in adding it

00:31:32,700 --> 00:31:36,510
they're also interested in figuring out

00:31:34,260 --> 00:31:38,820
how you could use it to do like pipeline

00:31:36,510 --> 00:31:40,620
generation I think one of their goals

00:31:38,820 --> 00:31:43,500
with that project is to be just like

00:31:40,620 --> 00:31:45,870
ubiquitous tool that can be used in a

00:31:43,500 --> 00:31:48,030
lot of different areas it's not

00:31:45,870 --> 00:31:50,340
something that's on either of our team's

00:31:48,030 --> 00:31:53,040
backlogs but the creator said that he

00:31:50,340 --> 00:31:55,110
was interested in contributing so is

00:31:53,040 --> 00:31:56,580
that if it's something that you're like

00:31:55,110 --> 00:31:59,100
interested in I think there might be a

00:31:56,580 --> 00:32:00,690
github issue for it

00:31:59,100 --> 00:32:03,950
if there's not we could create one and

00:32:00,690 --> 00:32:03,950
start tracking interest there

00:32:12,179 --> 00:32:19,129
it's coming like hmm and we could talk

00:32:16,169 --> 00:32:19,129
more about that afterward

00:32:23,630 --> 00:32:29,740
no more questions all right

00:32:30,789 --> 00:32:37,959
we'll start on it soon it's a different

00:32:34,839 --> 00:32:39,969
question I swear and I think it's it's a

00:32:37,959 --> 00:32:43,239
request for a clarification you put up a

00:32:39,969 --> 00:32:45,849
slide about Bluegreen deployments in the

00:32:43,239 --> 00:32:51,669
v2 provider I think or was it red black

00:32:45,849 --> 00:32:53,169
but whatever yes those yeah I might

00:32:51,669 --> 00:32:55,419
write that those only work on replica

00:32:53,169 --> 00:32:58,269
sets or do they work on deployments too

00:32:55,419 --> 00:33:00,009
you are correct so if you want to use a

00:32:58,269 --> 00:33:01,899
built-in rollout strategy that

00:33:00,009 --> 00:33:03,759
kubernetes gives you with a deployment

00:33:01,899 --> 00:33:05,709
we would recommend continuing to use a

00:33:03,759 --> 00:33:07,839
deployment and if you would like

00:33:05,709 --> 00:33:10,059
spinnaker to manage your rollout which

00:33:07,839 --> 00:33:12,249
it's going to do by managing the labels

00:33:10,059 --> 00:33:13,929
of the replica sets you do need to use a

00:33:12,249 --> 00:33:15,489
replica set because if spinnaker were to

00:33:13,929 --> 00:33:17,440
try to edit the labels on the deployment

00:33:15,489 --> 00:33:18,849
it would change its back and trigger and

00:33:17,440 --> 00:33:20,979
other Rolo's you kind of do you need to

00:33:18,849 --> 00:33:24,509
decide based on your needs which

00:33:20,979 --> 00:33:26,619
resource to use all right the whole

00:33:24,509 --> 00:33:28,239
changing labels on the deployment and

00:33:26,619 --> 00:33:30,039
pausing the deployment would be really

00:33:28,239 --> 00:33:40,259
exciting if speaker knew how to do that

00:33:30,039 --> 00:33:40,259
to any other hints

00:33:47,580 --> 00:33:53,020
hi how my dumb red black deployments

00:33:51,100 --> 00:33:57,880
work with something in conjunction with

00:33:53,020 --> 00:34:00,100
sto that's a really good question so we

00:33:57,880 --> 00:34:02,950
have support for sto and spin echo in

00:34:00,100 --> 00:34:04,990
spinnaker so far as if you had your own

00:34:02,950 --> 00:34:07,120
yeah mph or sto and wanted to basically

00:34:04,990 --> 00:34:08,710
do the equivalent of running queue

00:34:07,120 --> 00:34:11,080
control apply on it but with a spinnaker

00:34:08,710 --> 00:34:12,880
stage and basically manage it yourself

00:34:11,080 --> 00:34:15,790
that is available but it's not

00:34:12,880 --> 00:34:18,880
integrated in a first-class way so I

00:34:15,790 --> 00:34:21,100
would not recommend using sto as a

00:34:18,880 --> 00:34:22,720
service mesh and then also having a

00:34:21,100 --> 00:34:24,400
spinnaker managed rollout strategy

00:34:22,720 --> 00:34:27,160
because you kind of like if you are

00:34:24,400 --> 00:34:29,860
opting in to sto I would guess that you

00:34:27,160 --> 00:34:32,830
kind of need to hand control over like

00:34:29,860 --> 00:34:34,600
traffic routing completely to SEO so

00:34:32,830 --> 00:34:36,070
yeah I think that those would have to be

00:34:34,600 --> 00:34:37,210
two separate paths but it is something

00:34:36,070 --> 00:34:39,010
that we've talked about it they said

00:34:37,210 --> 00:34:40,570
like what would first-class support for

00:34:39,010 --> 00:34:42,610
SD look like in spinnaker what user

00:34:40,570 --> 00:34:44,110
stories would we be trying to solve for

00:34:42,610 --> 00:34:45,910
if there was a first-class integration

00:34:44,110 --> 00:34:48,690
so we'd love to hear your thoughts and

00:34:45,910 --> 00:34:48,690
episode

00:34:54,560 --> 00:34:59,680
any more questions all right thank you

00:34:58,970 --> 00:35:08,239
very much

00:34:59,680 --> 00:35:08,239

YouTube URL: https://www.youtube.com/watch?v=0uIRFzMayZ8


