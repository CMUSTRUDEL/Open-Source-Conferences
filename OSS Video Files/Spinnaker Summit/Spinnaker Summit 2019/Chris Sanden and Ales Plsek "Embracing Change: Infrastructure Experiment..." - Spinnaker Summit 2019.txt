Title: Chris Sanden and Ales Plsek "Embracing Change: Infrastructure Experiment..." - Spinnaker Summit 2019
Publication date: 2019-12-03
Playlist: Spinnaker Summit 2019
Description: 
	The third annual Spinnaker Summit (Diamond Sponsors: Netflix, Google and Armory) was held at the Hard Rock Hotel in San Diego, CA from November 15-17, 2019 and welcomed over 500 members of the rapidly growing Spinnaker open source community.
Captions: 
	00:00:06,330 --> 00:00:10,980
[Laughter]

00:00:15,920 --> 00:00:20,630
and then I'm a senior data scientist at

00:00:17,869 --> 00:00:22,010
Netflix and this is a lush he's a senior

00:00:20,630 --> 00:00:24,110
software engineer working on the

00:00:22,010 --> 00:00:26,180
resilience engineering team and we're

00:00:24,110 --> 00:00:28,430
here today to talk about infrastructure

00:00:26,180 --> 00:00:30,770
experimentation with spinnaker and how

00:00:28,430 --> 00:00:34,430
you can embrace change through these new

00:00:30,770 --> 00:00:36,980
technologies and methodologies so

00:00:34,430 --> 00:00:38,780
experimentation as a concept is quite

00:00:36,980 --> 00:00:42,190
popular right now you may be familiar

00:00:38,780 --> 00:00:45,350
with like a bee testing technologies and

00:00:42,190 --> 00:00:47,510
methodologies and we typically say a bee

00:00:45,350 --> 00:00:50,000
methodology is used for testing products

00:00:47,510 --> 00:00:52,130
and feature releases but today we're not

00:00:50,000 --> 00:00:53,210
gonna be talking about testing products

00:00:52,130 --> 00:00:55,670
or features we're gonna be talking about

00:00:53,210 --> 00:00:57,290
testing infrastructure so you want to

00:00:55,670 --> 00:01:00,320
make changes to your infrastructure how

00:00:57,290 --> 00:01:03,470
do we do that safely and to do it in a

00:01:00,320 --> 00:01:05,689
more measured way and this is this

00:01:03,470 --> 00:01:07,100
necessitated by the fact that you know

00:01:05,689 --> 00:01:09,649
continuous integration and delivery

00:01:07,100 --> 00:01:12,130
along with deployment automation allows

00:01:09,649 --> 00:01:14,689
us to move at a faster and faster rate

00:01:12,130 --> 00:01:16,189
evolving our infrastructure ever so

00:01:14,689 --> 00:01:18,680
slightly every day every hour every

00:01:16,189 --> 00:01:21,409
minute and every time we decide to make

00:01:18,680 --> 00:01:23,780
a change to our environment we have the

00:01:21,409 --> 00:01:26,540
opportunity to introduce regressions or

00:01:23,780 --> 00:01:28,159
issues and so over time the rate of

00:01:26,540 --> 00:01:29,390
change of our environment goes up but

00:01:28,159 --> 00:01:32,690
also the probability of something going

00:01:29,390 --> 00:01:34,850
bad goes up over time as well and while

00:01:32,690 --> 00:01:37,250
this curve is just kind of arbitrary

00:01:34,850 --> 00:01:38,900
curve the reality is that the faster we

00:01:37,250 --> 00:01:41,210
go the more likely we are to cause

00:01:38,900 --> 00:01:43,760
something to go wrong and this has

00:01:41,210 --> 00:01:45,320
real-world implications so Netflix we

00:01:43,760 --> 00:01:47,180
want to ensure that all of our members

00:01:45,320 --> 00:01:48,290
have a great quality of experience to

00:01:47,180 --> 00:01:49,790
ensure that when you want to watch that

00:01:48,290 --> 00:01:52,360
brand-new television show or movie you

00:01:49,790 --> 00:01:55,549
hit the play button but it actually does

00:01:52,360 --> 00:01:57,020
and this is an example of a news article

00:01:55,549 --> 00:01:59,119
that came out you know where we broke

00:01:57,020 --> 00:02:00,439
that promise and we had an issue but

00:01:59,119 --> 00:02:02,030
more importantly we want to make sure

00:02:00,439 --> 00:02:03,740
every individual user has a great

00:02:02,030 --> 00:02:05,420
experience and in this case Courtney had

00:02:03,740 --> 00:02:07,369
a little bit of an existential crisis

00:02:05,420 --> 00:02:12,319
and there's the things we want to

00:02:07,369 --> 00:02:14,230
prevent and with that that's where

00:02:12,319 --> 00:02:16,459
experimentation can come in and help us

00:02:14,230 --> 00:02:19,099
experimentation as the technique allows

00:02:16,459 --> 00:02:21,590
us to really minimize the blast radius

00:02:19,099 --> 00:02:23,750
of site changes and to also allow us the

00:02:21,590 --> 00:02:25,340
opportunity to be more measured so this

00:02:23,750 --> 00:02:27,319
is kind of a very high-level picture of

00:02:25,340 --> 00:02:29,270
what we mean by quote infrastructure

00:02:27,319 --> 00:02:29,819
experimentation where we have some

00:02:29,270 --> 00:02:31,200
change

00:02:29,819 --> 00:02:32,999
want to make to the infrastructure or

00:02:31,200 --> 00:02:34,680
something we want to measure we roll it

00:02:32,999 --> 00:02:36,030
up and we send out a little bit of

00:02:34,680 --> 00:02:38,400
traffic to it and this a little bit of

00:02:36,030 --> 00:02:40,560
traffic is going to allow us to kind of

00:02:38,400 --> 00:02:42,599
get a sense or feel of how's this new

00:02:40,560 --> 00:02:46,230
feature how's this new change going to

00:02:42,599 --> 00:02:48,180
impact our overall infrastructure a key

00:02:46,230 --> 00:02:50,129
important takeaway here is that we are

00:02:48,180 --> 00:02:52,590
again routing a very very small amount

00:02:50,129 --> 00:02:54,180
of traffic to the experiment while the

00:02:52,590 --> 00:02:58,049
rest is going to some say production

00:02:54,180 --> 00:02:59,780
system now we need some way to

00:02:58,049 --> 00:03:02,129
accomplish all of this we need some

00:02:59,780 --> 00:03:04,169
mechanism for doing this delivery and

00:03:02,129 --> 00:03:08,459
for us that delivery mechanism is

00:03:04,169 --> 00:03:09,870
spinnaker it is our yeah it is our

00:03:08,459 --> 00:03:12,930
delivery vehicle of choice in this case

00:03:09,870 --> 00:03:14,459
for helping to orchestrate orchestrate

00:03:12,930 --> 00:03:16,409
experiments you know spinnaker is a very

00:03:14,459 --> 00:03:18,150
powerful tool and we're taking advantage

00:03:16,409 --> 00:03:22,409
here of kind of the orchestration

00:03:18,150 --> 00:03:25,019
capabilities that spinnaker offers so

00:03:22,409 --> 00:03:26,819
our hope and goal of this talk is one to

00:03:25,019 --> 00:03:28,500
kind of demonstrate that spinnaker can

00:03:26,819 --> 00:03:30,569
be a foundational element to doing more

00:03:28,500 --> 00:03:32,099
than just delivery is that you can build

00:03:30,569 --> 00:03:33,810
off a spinner here and start to move

00:03:32,099 --> 00:03:35,879
towards what we call experimentation and

00:03:33,810 --> 00:03:37,169
then from it's that we're going to kind

00:03:35,879 --> 00:03:38,909
of demonstrate and show how you can

00:03:37,169 --> 00:03:41,069
build further on experimentation and

00:03:38,909 --> 00:03:42,930
move more towards automating experiments

00:03:41,069 --> 00:03:43,970
and eventually getting to the end goal

00:03:42,930 --> 00:03:46,439
of what we call continuous

00:03:43,970 --> 00:03:48,449
experimentation where these concepts and

00:03:46,439 --> 00:03:50,069
methodologies are integrated into your

00:03:48,449 --> 00:03:53,250
software development lifecycle and

00:03:50,069 --> 00:03:55,079
something that happens every day so with

00:03:53,250 --> 00:03:56,459
that in mind let's do a little context

00:03:55,079 --> 00:04:00,419
setting and let's give a very gentle

00:03:56,459 --> 00:04:02,340
introduction to experimentation so the

00:04:00,419 --> 00:04:04,439
part of experimentation that's really

00:04:02,340 --> 00:04:06,629
fascinating is that it allows us to ask

00:04:04,439 --> 00:04:09,180
questions allows us to make observations

00:04:06,629 --> 00:04:10,769
and to formulate those into some type of

00:04:09,180 --> 00:04:12,659
experiment now at the core of

00:04:10,769 --> 00:04:14,849
experimentation is this idea of forming

00:04:12,659 --> 00:04:18,030
a hypothesis some question we want to

00:04:14,849 --> 00:04:19,500
answer and once we form that hypothesis

00:04:18,030 --> 00:04:21,630
and we have a question we want to answer

00:04:19,500 --> 00:04:24,060
we set up an experiment rerun it and

00:04:21,630 --> 00:04:25,380
then we analyze the results and this is

00:04:24,060 --> 00:04:27,060
true of whether we're talking about a/b

00:04:25,380 --> 00:04:28,860
experiments where they were talking

00:04:27,060 --> 00:04:31,020
talking about medical trials or in this

00:04:28,860 --> 00:04:32,520
case of infrastructure experiments they

00:04:31,020 --> 00:04:36,060
all derived from they're very similar

00:04:32,520 --> 00:04:37,979
steps and there are many different ways

00:04:36,060 --> 00:04:39,150
to do experiments and for the remaining

00:04:37,979 --> 00:04:41,099
of this talk we're going to talk about

00:04:39,150 --> 00:04:43,020
one called randomized controlled

00:04:41,099 --> 00:04:43,590
experiments sometimes referred to as

00:04:43,020 --> 00:04:46,260
randomized

00:04:43,590 --> 00:04:48,900
controlled trials and this is a very

00:04:46,260 --> 00:04:51,090
popular kind of experiment design so

00:04:48,900 --> 00:04:53,970
imagine I'm interested in testing a new

00:04:51,090 --> 00:04:56,280
drug or testing a new technique for say

00:04:53,970 --> 00:04:58,470
a medical procedure and I want to see

00:04:56,280 --> 00:04:59,700
how good it works the general

00:04:58,470 --> 00:05:02,040
construction of an experiment in that

00:04:59,700 --> 00:05:03,360
case is where we have some population so

00:05:02,040 --> 00:05:06,000
let's say we have a million people in

00:05:03,360 --> 00:05:07,590
the world and we can take that million

00:05:06,000 --> 00:05:08,130
people and we can divide them into two

00:05:07,590 --> 00:05:10,440
groups

00:05:08,130 --> 00:05:12,030
so we randomly select a hundred thousand

00:05:10,440 --> 00:05:13,050
people from that first group we put them

00:05:12,030 --> 00:05:14,670
in something called the treatment group

00:05:13,050 --> 00:05:15,720
as the name implies they're going to

00:05:14,670 --> 00:05:17,880
either get the new drug or they're gonna

00:05:15,720 --> 00:05:19,050
get the treatment the second group we're

00:05:17,880 --> 00:05:20,610
going to create is called the control

00:05:19,050 --> 00:05:23,190
group and they're either gonna get a

00:05:20,610 --> 00:05:24,510
placebo or nothing and then because it's

00:05:23,190 --> 00:05:27,480
a medical trial it's going to run for a

00:05:24,510 --> 00:05:29,370
very long time months days years we have

00:05:27,480 --> 00:05:30,450
to do some follow-up and so that

00:05:29,370 --> 00:05:33,090
follow-up allows us to make observations

00:05:30,450 --> 00:05:34,680
and also to collect evidence that we can

00:05:33,090 --> 00:05:37,200
then use to kind of compare the results

00:05:34,680 --> 00:05:39,390
because it's key two takeaways here is

00:05:37,200 --> 00:05:41,910
that one our users or population is

00:05:39,390 --> 00:05:43,950
randomly assigned so there's no bias

00:05:41,910 --> 00:05:45,510
here we just flip a coin this person

00:05:43,950 --> 00:05:48,240
flip a coin heads they get treatment

00:05:45,510 --> 00:05:49,560
tails and you get the control so our rat

00:05:48,240 --> 00:05:52,470
we have random assignment of our

00:05:49,560 --> 00:05:56,810
population and the second is that with

00:05:52,470 --> 00:05:58,950
everything being equal if everything is

00:05:56,810 --> 00:06:00,720
contingent on this difference in the

00:05:58,950 --> 00:06:02,430
treatment group then any result we

00:06:00,720 --> 00:06:04,350
observe should be associated with the

00:06:02,430 --> 00:06:06,480
idea or the fact that we gave the sum

00:06:04,350 --> 00:06:08,910
this group the treatment group a drug or

00:06:06,480 --> 00:06:10,560
a treatment and so we can take this this

00:06:08,910 --> 00:06:13,080
kind of experimental design imply to

00:06:10,560 --> 00:06:14,100
infrastructure as well although we're

00:06:13,080 --> 00:06:16,320
not working on people we're gonna be

00:06:14,100 --> 00:06:18,930
working on servers and kind of requests

00:06:16,320 --> 00:06:20,940
in an infrastructure and this is kind of

00:06:18,930 --> 00:06:23,190
the general construction what we mean by

00:06:20,940 --> 00:06:24,630
an infrastructure experiment it's going

00:06:23,190 --> 00:06:25,830
to look very familiar to some who are

00:06:24,630 --> 00:06:27,900
familiar with the canary testing

00:06:25,830 --> 00:06:30,270
strategies or with the canary analysis

00:06:27,900 --> 00:06:31,950
strategies even so much so that we call

00:06:30,270 --> 00:06:34,680
this now the canary strategy for doing

00:06:31,950 --> 00:06:36,030
infrastructure experimentation so in

00:06:34,680 --> 00:06:37,530
this construction you can see kind of

00:06:36,030 --> 00:06:39,930
very similar analogies to the previous

00:06:37,530 --> 00:06:41,520
diagram we have some canary group which

00:06:39,930 --> 00:06:42,600
represents our treatment group this is

00:06:41,520 --> 00:06:43,980
going to be some change you're

00:06:42,600 --> 00:06:46,350
interested in making in your environment

00:06:43,980 --> 00:06:49,050
and it's going to be running on one or

00:06:46,350 --> 00:06:50,640
more servers containers instances we

00:06:49,050 --> 00:06:51,930
also introduced a baseline group this is

00:06:50,640 --> 00:06:53,070
going to be our control group this is

00:06:51,930 --> 00:06:54,270
going to have no change

00:06:53,070 --> 00:06:56,130
it's going to be running the exact same

00:06:54,270 --> 00:06:56,850
version or configuration that production

00:06:56,130 --> 00:07:00,270
house

00:06:56,850 --> 00:07:01,950
and then from a routing perspective we

00:07:00,270 --> 00:07:03,470
can see that only a very small amount of

00:07:01,950 --> 00:07:05,640
traffic is gonna be sent to both that

00:07:03,470 --> 00:07:07,830
canary group and that baseline group

00:07:05,640 --> 00:07:09,450
with the vast majority of the traffic

00:07:07,830 --> 00:07:11,160
going to the production again this

00:07:09,450 --> 00:07:14,250
allows us to really minimize that blast

00:07:11,160 --> 00:07:15,480
radius of making changes now important

00:07:14,250 --> 00:07:18,510
characteristic is that this routing

00:07:15,480 --> 00:07:20,190
layer should be routing our requests in

00:07:18,510 --> 00:07:22,020
a very randomized fashion

00:07:20,190 --> 00:07:24,990
there should be no bias or inherent

00:07:22,020 --> 00:07:26,610
stickiness to the request such that you

00:07:24,990 --> 00:07:28,110
would get say a bunch of the same

00:07:26,610 --> 00:07:29,940
requests going to baseline and none of

00:07:28,110 --> 00:07:31,680
those going to the canary again we want

00:07:29,940 --> 00:07:34,110
that randomized allocation of requests

00:07:31,680 --> 00:07:35,160
going to all the servers then from that

00:07:34,110 --> 00:07:36,990
we're going to collect evidence very

00:07:35,160 --> 00:07:38,910
similar to our prior example and then

00:07:36,990 --> 00:07:40,350
we'll do some analysis but this is our

00:07:38,910 --> 00:07:44,040
general canary strategy for doing

00:07:40,350 --> 00:07:45,360
infrastructure experimentation now there

00:07:44,040 --> 00:07:46,080
are many different types of experiments

00:07:45,360 --> 00:07:48,870
you may want to do in your

00:07:46,080 --> 00:07:50,250
infrastructure and we've loosely kind of

00:07:48,870 --> 00:07:51,900
broken them down into four categories

00:07:50,250 --> 00:07:53,460
here there's going to be overlap between

00:07:51,900 --> 00:07:55,560
these for example there might be overlap

00:07:53,460 --> 00:07:57,780
between system and performance but the

00:07:55,560 --> 00:08:00,060
general four categories are let's say

00:07:57,780 --> 00:08:01,620
you want to deduce or assess you know

00:08:00,060 --> 00:08:03,300
safety or risk of any change you're

00:08:01,620 --> 00:08:04,380
making in the environment and that could

00:08:03,300 --> 00:08:07,080
be maybe you're making a change to your

00:08:04,380 --> 00:08:08,310
code maybe adjusting a property and you

00:08:07,080 --> 00:08:10,050
want to set up an experiment to be able

00:08:08,310 --> 00:08:12,780
to validate or measure how does that

00:08:10,050 --> 00:08:14,910
change impact your environment or what's

00:08:12,780 --> 00:08:17,370
the safety of that or how safe is that

00:08:14,910 --> 00:08:19,290
change to make second category is a

00:08:17,370 --> 00:08:21,390
systems test or a systems experiment

00:08:19,290 --> 00:08:23,040
where you might be interested in tuning

00:08:21,390 --> 00:08:24,990
or changing various aspects of the base

00:08:23,040 --> 00:08:26,430
system so for example let's say you want

00:08:24,990 --> 00:08:29,820
to change the underlying instance type

00:08:26,430 --> 00:08:31,230
and or container of parameters you can

00:08:29,820 --> 00:08:33,240
run an experiment to validate or to

00:08:31,230 --> 00:08:34,290
measure ten of those differences the

00:08:33,240 --> 00:08:35,430
third being performance

00:08:34,290 --> 00:08:37,770
in this case maybe you want to tune

00:08:35,430 --> 00:08:39,479
thread pools concurrency limits some

00:08:37,770 --> 00:08:40,919
aspect of the application and you want

00:08:39,479 --> 00:08:43,290
to measure and see how well it performs

00:08:40,919 --> 00:08:44,640
and then finally we introduced something

00:08:43,290 --> 00:08:46,860
called the resilience category of

00:08:44,640 --> 00:08:48,900
experimentation types and this includes

00:08:46,860 --> 00:08:51,270
kind of two categories chaos testing or

00:08:48,900 --> 00:08:53,550
chaos experimentation and load testing

00:08:51,270 --> 00:08:55,080
in a lesson a little bit late later in

00:08:53,550 --> 00:08:56,010
the presentation we'll go into further

00:08:55,080 --> 00:09:00,450
detail on these two categories

00:08:56,010 --> 00:09:02,580
specifically so let's go through a quick

00:09:00,450 --> 00:09:06,270
example to kind of ground this in more

00:09:02,580 --> 00:09:09,240
of a concrete example so let's say I own

00:09:06,270 --> 00:09:10,640
an application it's a back-end micro

00:09:09,240 --> 00:09:12,690
service it's just a

00:09:10,640 --> 00:09:16,140
request/response service it takes a

00:09:12,690 --> 00:09:17,550
piece of unit of work in and responds so

00:09:16,140 --> 00:09:19,500
I have a bunch of servers represented by

00:09:17,550 --> 00:09:21,750
little green Chiclets or boxes here and

00:09:19,500 --> 00:09:24,390
they're part of some application cluster

00:09:21,750 --> 00:09:26,190
or deployment and they're all fronted by

00:09:24,390 --> 00:09:28,170
some load balancer and for this example

00:09:26,190 --> 00:09:29,580
let's say it's doing round-robin so it's

00:09:28,170 --> 00:09:32,010
just the low bouncers are sending

00:09:29,580 --> 00:09:33,589
requests equally or in some randomized

00:09:32,010 --> 00:09:35,640
fashion through all of the servers and

00:09:33,589 --> 00:09:36,839
for construction of the problem let's

00:09:35,640 --> 00:09:38,820
say we're doing with live production

00:09:36,839 --> 00:09:41,640
traffic here it's a very simple example

00:09:38,820 --> 00:09:43,310
of a micro service and it's also

00:09:41,640 --> 00:09:46,020
collecting telemetry and metrics and

00:09:43,310 --> 00:09:47,700
let's say as a developer I noticed that

00:09:46,020 --> 00:09:48,870
there's a bug in my application it's for

00:09:47,700 --> 00:09:51,089
throwing all more errors it's throwing

00:09:48,870 --> 00:09:53,460
more five hundreds or four hundreds and

00:09:51,089 --> 00:09:55,170
I have an idea of how I want to fix that

00:09:53,460 --> 00:09:58,410
or I have an idea of what's causing the

00:09:55,170 --> 00:10:00,900
problem so I want to use experimentation

00:09:58,410 --> 00:10:02,010
to address that so what I have to do is

00:10:00,900 --> 00:10:03,960
I have to go back to our experiment

00:10:02,010 --> 00:10:06,390
construction and if we recall I need to

00:10:03,960 --> 00:10:08,580
form a hypothesis so I have a general

00:10:06,390 --> 00:10:10,290
idea that I have a bug in my service I

00:10:08,580 --> 00:10:12,810
need to fix it and then I want to

00:10:10,290 --> 00:10:15,390
measure it so we need to design some

00:10:12,810 --> 00:10:17,640
type of question around that and that's

00:10:15,390 --> 00:10:20,160
where kind of a hypothesis will help us

00:10:17,640 --> 00:10:22,320
and so in this case I know that I need

00:10:20,160 --> 00:10:24,750
to implement a fix so we construct our

00:10:22,320 --> 00:10:25,980
hypothesis around if we do this thing so

00:10:24,750 --> 00:10:28,290
if I implement this fix

00:10:25,980 --> 00:10:31,110
then we should observe a reduction in

00:10:28,290 --> 00:10:32,880
our server HTTP errors you can see that

00:10:31,110 --> 00:10:35,640
this is constructed as a if-then

00:10:32,880 --> 00:10:38,070
statement if I do this then this should

00:10:35,640 --> 00:10:40,140
happen our hypothesis should be very

00:10:38,070 --> 00:10:41,310
specific and precise and should be

00:10:40,140 --> 00:10:44,040
something that is testable and

00:10:41,310 --> 00:10:45,510
measurable we want to keep it you know

00:10:44,040 --> 00:10:46,710
we don't want to keep or have vague

00:10:45,510 --> 00:10:49,560
statements we want something that's very

00:10:46,710 --> 00:10:52,290
easy to test and in this case we're

00:10:49,560 --> 00:10:54,870
gonna pull out and look at HTTP errors

00:10:52,290 --> 00:10:56,490
it's built right into our hypothesis so

00:10:54,870 --> 00:10:57,750
let's say I do implement the fix we left

00:10:56,490 --> 00:11:00,270
our experiment run for some period of

00:10:57,750 --> 00:11:02,040
time and we and we use our canary

00:11:00,270 --> 00:11:03,420
strategy to roll out that infrastructure

00:11:02,040 --> 00:11:05,370
so again we're creating the canary

00:11:03,420 --> 00:11:06,540
creating a control group of baseline and

00:11:05,370 --> 00:11:09,180
we let the infrastructure run for a

00:11:06,540 --> 00:11:11,220
period of time and then we decide and we

00:11:09,180 --> 00:11:13,170
go look at some graphs and this is what

00:11:11,220 --> 00:11:15,720
we observed so in this case the blue

00:11:13,170 --> 00:11:17,760
line or big blue squiggly line is the

00:11:15,720 --> 00:11:20,370
measurements collected from the baseline

00:11:17,760 --> 00:11:21,990
group and so that's the error rate but

00:11:20,370 --> 00:11:23,730
we can see by introducing our fix the

00:11:21,990 --> 00:11:24,360
error rate is now quite considerably

00:11:23,730 --> 00:11:25,860
lower

00:11:24,360 --> 00:11:27,360
and so we can make some general

00:11:25,860 --> 00:11:29,189
conclusions about this that you know by

00:11:27,360 --> 00:11:31,769
implementing the fix we do observe a

00:11:29,189 --> 00:11:33,739
reduction in our HTTP errors therefore

00:11:31,769 --> 00:11:35,730
our hypothesis has been validated

00:11:33,739 --> 00:11:37,079
now the power of experimentation comes

00:11:35,730 --> 00:11:39,540
in the fact that we can ask follow-up

00:11:37,079 --> 00:11:40,980
questions experiments done and we can go

00:11:39,540 --> 00:11:43,079
back and now ask more exploratory

00:11:40,980 --> 00:11:45,329
questions as well we can construct

00:11:43,079 --> 00:11:47,279
additional hypotheses so for example if

00:11:45,329 --> 00:11:49,709
we said we if we implement the fix we

00:11:47,279 --> 00:11:52,319
should not observe a change in some of

00:11:49,709 --> 00:11:53,670
our utilization metrics as well and so

00:11:52,319 --> 00:11:55,379
this is the kind of the powers you can

00:11:53,670 --> 00:11:57,809
keep adding or you keep iterating on

00:11:55,379 --> 00:12:00,420
experimentation and so in our classic

00:11:57,809 --> 00:12:03,720
example here let's say we do this but

00:12:00,420 --> 00:12:06,779
now we see that we do impact CPU

00:12:03,720 --> 00:12:08,399
utilization with this change and so in

00:12:06,779 --> 00:12:10,170
the red line in this case represents the

00:12:08,399 --> 00:12:12,239
CPU utilization of the canary or our

00:12:10,170 --> 00:12:14,100
change and the blue for the baseline of

00:12:12,239 --> 00:12:15,660
the control group this is a very

00:12:14,100 --> 00:12:16,889
powerful concept because it now allows

00:12:15,660 --> 00:12:19,769
us to kind of trade-off

00:12:16,889 --> 00:12:22,139
the decisions here is are we willing to

00:12:19,769 --> 00:12:23,999
accept a higher CPU utilization for a

00:12:22,139 --> 00:12:26,939
reduced error rate and now we have very

00:12:23,999 --> 00:12:28,799
precise measures we can now say with

00:12:26,939 --> 00:12:29,759
some confidence how is this can going to

00:12:28,799 --> 00:12:32,549
be scaled up into our production

00:12:29,759 --> 00:12:34,649
environment so with that in mind I'm now

00:12:32,549 --> 00:12:36,389
going to pass it over to a lashe who's

00:12:34,649 --> 00:12:38,699
going to talk more in detail about how

00:12:36,389 --> 00:12:41,549
to actually do this in production or in

00:12:38,699 --> 00:12:44,239
practice with spinnaker at Netflix we

00:12:41,549 --> 00:12:47,089
are also quite heavy users of spinnaker

00:12:44,239 --> 00:12:49,739
that shouldn't come as any surprise and

00:12:47,089 --> 00:12:51,899
we use vinegar every day to deliver us

00:12:49,739 --> 00:12:54,959
our software artifacts to production and

00:12:51,899 --> 00:12:57,809
that's why it makes spinnaker a great

00:12:54,959 --> 00:13:00,239
candidate for introducing the value of

00:12:57,809 --> 00:13:02,579
experimentation into the lives of our

00:13:00,239 --> 00:13:04,499
software developers so in this section

00:13:02,579 --> 00:13:07,110
we want to talk about how to orchestrate

00:13:04,499 --> 00:13:10,889
an experiment and more specifically how

00:13:07,110 --> 00:13:14,160
you can do it using spinnaker so we if

00:13:10,889 --> 00:13:17,399
we ever revisit the phases of the of the

00:13:14,160 --> 00:13:19,980
experiment that we have defined we can

00:13:17,399 --> 00:13:21,869
see that we could probably easily try to

00:13:19,980 --> 00:13:24,209
run an experiment manually so we could

00:13:21,869 --> 00:13:26,569
ask ourselves a question deploy some

00:13:24,209 --> 00:13:30,119
clusters let them run for some time

00:13:26,569 --> 00:13:31,709
hopefully they will be handling some

00:13:30,119 --> 00:13:34,019
traffic and then after some time we'll

00:13:31,709 --> 00:13:36,570
just look at the dashboards and evaluate

00:13:34,019 --> 00:13:39,570
the success or failure of the experiment

00:13:36,570 --> 00:13:42,900
but that would be quite error-prone and

00:13:39,570 --> 00:13:45,240
manual so we don't want to do that

00:13:42,900 --> 00:13:46,920
instead if we look at these steps we

00:13:45,240 --> 00:13:48,990
actually can realize that there are some

00:13:46,920 --> 00:13:51,480
features already available today in

00:13:48,990 --> 00:13:54,420
spinnaker that can help us with this

00:13:51,480 --> 00:13:57,600
orchestration of the experiment so for

00:13:54,420 --> 00:13:59,580
the hypothesis formulation we can use

00:13:57,600 --> 00:14:02,780
the Canary config so the Canary config

00:13:59,580 --> 00:14:05,250
is a is the UI element that is today

00:14:02,780 --> 00:14:07,140
implemented in spinnaker that allows you

00:14:05,250 --> 00:14:09,900
to define metrics that you want to look

00:14:07,140 --> 00:14:11,520
at for your experiment you can group the

00:14:09,900 --> 00:14:13,590
metrics together into categories and

00:14:11,520 --> 00:14:16,290
then assign values so that way you are

00:14:13,590 --> 00:14:18,980
defining sort of a formal specification

00:14:16,290 --> 00:14:22,440
of what they what your hypothesis is

00:14:18,980 --> 00:14:24,690
here is a simple example or actually an

00:14:22,440 --> 00:14:27,810
example of an economic config that we

00:14:24,690 --> 00:14:29,130
are using at Netflix here one of the

00:14:27,810 --> 00:14:31,470
categories that we are looking at are

00:14:29,130 --> 00:14:33,840
the requests rates and we would like to

00:14:31,470 --> 00:14:35,970
as part of that this hypothesis we would

00:14:33,840 --> 00:14:38,670
like to verify that the error rates are

00:14:35,970 --> 00:14:40,200
not going up and as part of the as we

00:14:38,670 --> 00:14:44,550
once we are running the experiment and

00:14:40,200 --> 00:14:46,140
also the successful RPS are same as D as

00:14:44,550 --> 00:14:48,170
the baseline cannery that we are running

00:14:46,140 --> 00:14:51,390
baseline cluster that we are running

00:14:48,170 --> 00:14:53,580
going specifically into the single

00:14:51,390 --> 00:14:56,130
metric definition this is how we are

00:14:53,580 --> 00:14:58,010
defining that for the error rates we are

00:14:56,130 --> 00:15:00,990
interested in the increase so we want to

00:14:58,010 --> 00:15:04,140
fail the cannery if there is an increase

00:15:00,990 --> 00:15:05,970
in error rates and we also quantify the

00:15:04,140 --> 00:15:08,880
effect size of this increase which is

00:15:05,970 --> 00:15:10,890
20% so if there is more than 20% errors

00:15:08,880 --> 00:15:12,840
recorded by the canary cluster then we

00:15:10,890 --> 00:15:14,730
want to fail the experiment comparing to

00:15:12,840 --> 00:15:16,470
the baseline cluster and then in the

00:15:14,730 --> 00:15:18,600
bottom you can define how you want to

00:15:16,470 --> 00:15:20,880
fetch these metrics or these values for

00:15:18,600 --> 00:15:22,380
these metrics from your monitoring

00:15:20,880 --> 00:15:26,400
system so in this case we are using

00:15:22,380 --> 00:15:27,990
Atlas but of course vinegar integrated

00:15:26,400 --> 00:15:30,780
many other monitoring tools so you will

00:15:27,990 --> 00:15:33,600
be able to use them to define where the

00:15:30,780 --> 00:15:35,910
metrics are coming from so this is from

00:15:33,600 --> 00:15:37,590
the Canary config the next step is that

00:15:35,910 --> 00:15:40,230
you want to deploy or you want to setup

00:15:37,590 --> 00:15:42,330
your experiment so that that's what you

00:15:40,230 --> 00:15:45,540
can do with spinnaker using the

00:15:42,330 --> 00:15:47,220
deployment stage this is where spinnaker

00:15:45,540 --> 00:15:49,500
really excels at

00:15:47,220 --> 00:15:51,270
and then you can run the experiment so

00:15:49,500 --> 00:15:54,410
these two steps are actually implemented

00:15:51,270 --> 00:15:57,440
in spinnaker using the canary stage and

00:15:54,410 --> 00:16:01,170
the purpose of this whole stage is to

00:15:57,440 --> 00:16:04,290
deploy the clusters and let them run and

00:16:01,170 --> 00:16:06,030
then gather enough data or evidence for

00:16:04,290 --> 00:16:08,870
you for the final step of your

00:16:06,030 --> 00:16:11,490
experiment which is the analysis stage

00:16:08,870 --> 00:16:13,140
here we can see in a simple example of

00:16:11,490 --> 00:16:15,210
the canary stage being used in a

00:16:13,140 --> 00:16:17,760
pipeline so you can just add it to a for

00:16:15,210 --> 00:16:21,150
example a deployment pipeline and then

00:16:17,760 --> 00:16:23,130
once the canal runs it will run it it

00:16:21,150 --> 00:16:26,010
will run the canary analysis is one of

00:16:23,130 --> 00:16:28,590
the stages of the pipeline will either

00:16:26,010 --> 00:16:30,870
the canary analysis either succeed or

00:16:28,590 --> 00:16:32,490
fails and that can also stop your

00:16:30,870 --> 00:16:35,040
pipeline or let it proceed to the

00:16:32,490 --> 00:16:36,480
deployment stage so we have the canary

00:16:35,040 --> 00:16:38,640
stage defined we have gathered enough

00:16:36,480 --> 00:16:40,710
data and we have the canary conflicted

00:16:38,640 --> 00:16:43,140
fine so that's why we can analyze the

00:16:40,710 --> 00:16:45,030
data and we can make a judgment on if

00:16:43,140 --> 00:16:48,180
this should be a successful experiment

00:16:45,030 --> 00:16:51,240
or not so this is what we call canary

00:16:48,180 --> 00:16:53,070
analysis in spinnaker terminology and

00:16:51,240 --> 00:16:55,050
this is where it called comes together

00:16:53,070 --> 00:16:57,480
so we will compare the metrics collected

00:16:55,050 --> 00:16:58,830
from the baseline in Canary using the

00:16:57,480 --> 00:17:00,900
canary configurate will compute the

00:16:58,830 --> 00:17:05,069
scores and that way we can judge if the

00:17:00,900 --> 00:17:07,110
experiment as fast or failed here is an

00:17:05,069 --> 00:17:10,350
example of such an experiment that we

00:17:07,110 --> 00:17:12,689
have run we have achieved the score of

00:17:10,350 --> 00:17:14,250
100 you can see that there is it's we

00:17:12,689 --> 00:17:15,720
are clearly seeing that what is the

00:17:14,250 --> 00:17:17,880
scope so we are getting data from the

00:17:15,720 --> 00:17:19,819
baseline and canary and four in each

00:17:17,880 --> 00:17:22,170
individual metrics we can see a graph of

00:17:19,819 --> 00:17:24,990
comparison of how the metric is doing

00:17:22,170 --> 00:17:26,579
and we can see there was no significant

00:17:24,990 --> 00:17:28,590
or statistically significant difference

00:17:26,579 --> 00:17:32,510
between the baseline and canary so so

00:17:28,590 --> 00:17:35,190
that why the canary analysis past

00:17:32,510 --> 00:17:37,110
applying these concepts to the example

00:17:35,190 --> 00:17:39,060
that we've seen before is that it's

00:17:37,110 --> 00:17:40,920
showed here where we can see that the

00:17:39,060 --> 00:17:43,680
canary stage is in charge of the rolling

00:17:40,920 --> 00:17:45,960
of the baseline and canary and then the

00:17:43,680 --> 00:17:50,280
canary analysis will look at the metrics

00:17:45,960 --> 00:17:52,860
and will make the judgment okay so we

00:17:50,280 --> 00:17:55,560
can now orchestrate an experiment using

00:17:52,860 --> 00:17:59,250
spinnaker but we've been doing that for

00:17:55,560 --> 00:18:01,630
for a couple of years already now and

00:17:59,250 --> 00:18:04,270
we have defined or identified some

00:18:01,630 --> 00:18:06,640
challenges related to orchestration of

00:18:04,270 --> 00:18:08,530
experiments so first when you are

00:18:06,640 --> 00:18:10,120
creating your canary config you really

00:18:08,530 --> 00:18:11,800
need to define what kind of metrics you

00:18:10,120 --> 00:18:14,470
want to look at how you categorize them

00:18:11,800 --> 00:18:16,660
what are the weights so you'll find

00:18:14,470 --> 00:18:18,670
yourself frequently going back to the

00:18:16,660 --> 00:18:20,350
canary config revisiting iterating over

00:18:18,670 --> 00:18:22,090
the values over the metrics that you are

00:18:20,350 --> 00:18:23,830
collecting so this is quite

00:18:22,090 --> 00:18:26,740
time-consuming and will take you some

00:18:23,830 --> 00:18:28,780
time before you get it right the next

00:18:26,740 --> 00:18:30,580
when you are deploying the experiment or

00:18:28,780 --> 00:18:32,230
setting it up you need to make sure that

00:18:30,580 --> 00:18:34,200
you are running the right versions so

00:18:32,230 --> 00:18:36,940
you are comparing the apples to apples

00:18:34,200 --> 00:18:38,530
that you're sizing up the the clusters

00:18:36,940 --> 00:18:40,390
correctly so those are all the

00:18:38,530 --> 00:18:43,060
considerations that you need to make in

00:18:40,390 --> 00:18:44,260
the setup phase and then when you're

00:18:43,060 --> 00:18:46,570
running the experiment it's really

00:18:44,260 --> 00:18:48,840
important to set up the run time of the

00:18:46,570 --> 00:18:51,460
experiment correctly because this will

00:18:48,840 --> 00:18:53,530
directly impact the accuracy of your

00:18:51,460 --> 00:18:55,930
final result because if you are running

00:18:53,530 --> 00:18:58,810
the experiment for two short amount of

00:18:55,930 --> 00:19:02,500
time you will not record enough evidence

00:18:58,810 --> 00:19:03,850
to make a accurate judgment and once so

00:19:02,500 --> 00:19:05,920
once you design an experiment you are

00:19:03,850 --> 00:19:09,820
able to run it it succeeds you can see

00:19:05,920 --> 00:19:11,860
the result the final challenge is we

00:19:09,820 --> 00:19:13,390
believe is that the main value from

00:19:11,860 --> 00:19:15,370
experimentation comes when you are able

00:19:13,390 --> 00:19:18,250
to run these experiments regularly and

00:19:15,370 --> 00:19:19,870
and that way you need to somehow think

00:19:18,250 --> 00:19:22,080
about how to integrate the

00:19:19,870 --> 00:19:26,830
experimentation into your daily

00:19:22,080 --> 00:19:29,380
development life cycle so we are very

00:19:26,830 --> 00:19:31,060
well aware of these challenges and so

00:19:29,380 --> 00:19:32,590
that's why I would like to share some of

00:19:31,060 --> 00:19:34,750
the patterns that we use or that we have

00:19:32,590 --> 00:19:37,630
identified over the years that should

00:19:34,750 --> 00:19:41,350
hopefully help you to adopt some of

00:19:37,630 --> 00:19:43,360
these principles of experimentation so

00:19:41,350 --> 00:19:45,670
the first pattern that we have sort of

00:19:43,360 --> 00:19:49,210
identified is we call it a retrospective

00:19:45,670 --> 00:19:51,550
validation and this this is a very

00:19:49,210 --> 00:19:53,650
simple pattern that you can you can

00:19:51,550 --> 00:19:54,940
start using today because it's not

00:19:53,650 --> 00:19:57,370
introducing any change into our

00:19:54,940 --> 00:19:59,770
infrastructure what it does is that

00:19:57,370 --> 00:20:01,900
instead of deploying any canary or bass

00:19:59,770 --> 00:20:03,790
on a cluster you just select already

00:20:01,900 --> 00:20:06,010
existing instances or nodes from your

00:20:03,790 --> 00:20:08,110
clusters to the part either baseline and

00:20:06,010 --> 00:20:10,090
canary or canary

00:20:08,110 --> 00:20:12,010
and and then you just dream line the

00:20:10,090 --> 00:20:13,570
process of experimentation so instead of

00:20:12,010 --> 00:20:16,360
setting up and running the experiment

00:20:13,570 --> 00:20:18,730
you just formalize your canary config

00:20:16,360 --> 00:20:21,309
and then you apply it to the data devar

00:20:18,730 --> 00:20:23,140
there are being collected by from these

00:20:21,309 --> 00:20:25,419
from these two sets of existing

00:20:23,140 --> 00:20:27,700
instances there is no change to your

00:20:25,419 --> 00:20:30,730
infrastructure and you can already today

00:20:27,700 --> 00:20:32,559
set it set this up you can run you can

00:20:30,730 --> 00:20:36,510
create a simple pipeline with just one

00:20:32,559 --> 00:20:39,940
stage where you will define what are the

00:20:36,510 --> 00:20:43,779
what are the nodes that you want to

00:20:39,940 --> 00:20:46,029
assign to each individual baseline or

00:20:43,779 --> 00:20:48,159
cross canary cluster and also you will

00:20:46,029 --> 00:20:51,010
just select this analysis type to be

00:20:48,159 --> 00:20:53,380
with respective analysis and and that

00:20:51,010 --> 00:20:54,880
way you run and you see the the pipeline

00:20:53,380 --> 00:20:57,399
finishes just in four seconds which

00:20:54,880 --> 00:21:00,370
which in spinnaker times is almost

00:20:57,399 --> 00:21:04,139
immediately and so you get the hundred

00:21:00,370 --> 00:21:06,669
percent result and this way you sort of

00:21:04,139 --> 00:21:09,460
experiment with the canary canary config

00:21:06,669 --> 00:21:11,740
and you are able to see if you are

00:21:09,460 --> 00:21:14,260
reporting all the data correctly if you

00:21:11,740 --> 00:21:16,679
are measuring what you are measuring and

00:21:14,260 --> 00:21:19,029
if you are actually passing with 100

00:21:16,679 --> 00:21:21,850
because if you are not it probably means

00:21:19,029 --> 00:21:24,100
that your instances that are you are

00:21:21,850 --> 00:21:25,960
running and your main cluster are not

00:21:24,100 --> 00:21:28,120
behaving equally so it's really hard

00:21:25,960 --> 00:21:29,889
probably to continue with the

00:21:28,120 --> 00:21:31,419
experimentation or with even more

00:21:29,889 --> 00:21:35,799
advanced patterns of experimentation

00:21:31,419 --> 00:21:37,600
because you do not be able to get any

00:21:35,799 --> 00:21:39,730
meaningful data so this is the first

00:21:37,600 --> 00:21:41,159
sanitation step that you can do when

00:21:39,730 --> 00:21:43,330
playing with the analysis or

00:21:41,159 --> 00:21:44,710
experimentation without actually

00:21:43,330 --> 00:21:48,460
changing anything in your in your

00:21:44,710 --> 00:21:51,429
clusters and here you can see I was

00:21:48,460 --> 00:21:53,590
running multiple of these in a very

00:21:51,429 --> 00:21:55,600
short time just to get the canary config

00:21:53,590 --> 00:21:59,799
right and just to see if I'm collecting

00:21:55,600 --> 00:22:03,070
all the metrics correctly so once you do

00:21:59,799 --> 00:22:05,380
that the next phase is a what we call a

00:22:03,070 --> 00:22:08,110
experiment again this is very simple

00:22:05,380 --> 00:22:10,240
idea that we recommend when you're

00:22:08,110 --> 00:22:11,919
starting with experimentation which is

00:22:10,240 --> 00:22:15,039
that you can run you can actually

00:22:11,919 --> 00:22:16,389
already run experiment where you will

00:22:15,039 --> 00:22:19,120
use the canary stage to deploy a

00:22:16,389 --> 00:22:21,100
baseline and cannery but into the canary

00:22:19,120 --> 00:22:21,660
cluster you will just deploy the same

00:22:21,100 --> 00:22:23,850
version

00:22:21,660 --> 00:22:25,770
you're deploying into the baseline so

00:22:23,850 --> 00:22:27,360
again you are eliminating any changes

00:22:25,770 --> 00:22:29,790
that could be introduced by the any code

00:22:27,360 --> 00:22:31,620
changes or property changes and what you

00:22:29,790 --> 00:22:33,300
want to do is you just want to sanitize

00:22:31,620 --> 00:22:36,480
the whole process of setting up your

00:22:33,300 --> 00:22:40,320
experiment and that again the goal is to

00:22:36,480 --> 00:22:43,200
get a successful result so here we have

00:22:40,320 --> 00:22:44,940
run again you can just set this up as a

00:22:43,200 --> 00:22:47,760
separate pipeline where you introduce

00:22:44,940 --> 00:22:50,220
the stage with the canary config and

00:22:47,760 --> 00:22:51,870
there you just set up the versions to be

00:22:50,220 --> 00:22:54,240
an identical and then you run the

00:22:51,870 --> 00:22:56,970
experiment so this way you are gaining

00:22:54,240 --> 00:22:59,070
trust into how you're setting up to your

00:22:56,970 --> 00:23:02,580
infrastructure to be running the

00:22:59,070 --> 00:23:04,260
experiment and you can really once you

00:23:02,580 --> 00:23:06,450
are able to do this once you are able to

00:23:04,260 --> 00:23:08,940
do this repeat repeatedly and you are

00:23:06,450 --> 00:23:11,100
giving getting a consistent result then

00:23:08,940 --> 00:23:13,740
you can actually start doing any kind of

00:23:11,100 --> 00:23:17,730
experimentation that and introducing

00:23:13,740 --> 00:23:19,740
changes into your experiments so we are

00:23:17,730 --> 00:23:21,360
getting to the last pattern that we have

00:23:19,740 --> 00:23:25,410
identified and that's probably the most

00:23:21,360 --> 00:23:28,470
common which is the a B experiment that

00:23:25,410 --> 00:23:29,940
that gets that you can apply to your

00:23:28,470 --> 00:23:32,160
deployment pipelines so you can

00:23:29,940 --> 00:23:34,590
introduce a canary stage into your

00:23:32,160 --> 00:23:36,450
deployment pipeline which will measure

00:23:34,590 --> 00:23:38,400
the amount of change and it will

00:23:36,450 --> 00:23:40,950
evaluate if the change is impacting your

00:23:38,400 --> 00:23:44,190
baseline or your canary in any any way

00:23:40,950 --> 00:23:45,570
and and then you can make sure that the

00:23:44,190 --> 00:23:49,520
change doesn't go to production

00:23:45,570 --> 00:23:52,920
unless it's passing the canary analysis

00:23:49,520 --> 00:23:55,140
so this is really all the previous

00:23:52,920 --> 00:23:58,890
patterns should help you getting into

00:23:55,140 --> 00:24:00,840
this point and this is one of the today

00:23:58,890 --> 00:24:03,540
it's become one of the key building

00:24:00,840 --> 00:24:05,580
points when you're you are deploying

00:24:03,540 --> 00:24:09,690
software to to production running the

00:24:05,580 --> 00:24:12,120
canary analysis so now we have seen some

00:24:09,690 --> 00:24:15,270
how we view experimentation at Netflix

00:24:12,120 --> 00:24:18,930
and we know what is sort of the formal

00:24:15,270 --> 00:24:20,310
definition of experimentation and so now

00:24:18,930 --> 00:24:21,930
we would like to show you how we have

00:24:20,310 --> 00:24:24,330
embraced these principles of

00:24:21,930 --> 00:24:28,440
experimentation within our organization

00:24:24,330 --> 00:24:31,200
and how we have grown from that so our

00:24:28,440 --> 00:24:33,420
initial motivation was to make the

00:24:31,200 --> 00:24:35,020
experimentation as easy as possible for

00:24:33,420 --> 00:24:36,370
our developers so

00:24:35,020 --> 00:24:40,360
don't have to worry about how to sit on

00:24:36,370 --> 00:24:42,820
the experiments and really to to just

00:24:40,360 --> 00:24:44,590
they are able to introduce the

00:24:42,820 --> 00:24:46,960
experimentation into their software

00:24:44,590 --> 00:24:48,700
development life cycles so and that is

00:24:46,960 --> 00:24:51,460
the reason why we have built chap

00:24:48,700 --> 00:24:54,850
so chop is a soft standing tool in our

00:24:51,460 --> 00:24:57,460
ecosystem with the Netflix it is built

00:24:54,850 --> 00:24:59,590
outside of spinnaker it is leveraging

00:24:57,460 --> 00:25:01,720
spinnaker and many other places but we

00:24:59,590 --> 00:25:04,420
have specifically decided to build this

00:25:01,720 --> 00:25:07,240
tool as a separate tool because we want

00:25:04,420 --> 00:25:08,650
to everything in chop is designed around

00:25:07,240 --> 00:25:10,870
the experiment experiment is the

00:25:08,650 --> 00:25:13,870
first-class entity in this system so

00:25:10,870 --> 00:25:16,060
here this allows our users to define

00:25:13,870 --> 00:25:17,770
really easily experiments to sort of

00:25:16,060 --> 00:25:20,470
define an extended version of your

00:25:17,770 --> 00:25:23,620
Canary config and then you can you can

00:25:20,470 --> 00:25:25,510
run this experiment within chap you can

00:25:23,620 --> 00:25:27,370
at the end you can analyze so we add

00:25:25,510 --> 00:25:29,560
extra features to analysis of the

00:25:27,370 --> 00:25:32,470
experiments and also we are adding

00:25:29,560 --> 00:25:34,450
features towards automation where we

00:25:32,470 --> 00:25:36,130
want to run the experiment automatically

00:25:34,450 --> 00:25:37,740
so we mode want to make it as easy as

00:25:36,130 --> 00:25:41,230
possible for developers to run these

00:25:37,740 --> 00:25:42,970
experiments so let me just go through a

00:25:41,230 --> 00:25:46,660
couple of key features that we have

00:25:42,970 --> 00:25:48,400
built into job so first when our users

00:25:46,660 --> 00:25:50,770
start using chap the first thing they

00:25:48,400 --> 00:25:53,200
are their encounter is the definition of

00:25:50,770 --> 00:25:55,660
the test case so test case is sort of a

00:25:53,200 --> 00:25:57,850
specification of an experiment or a

00:25:55,660 --> 00:26:00,340
specification of an experiment it's an

00:25:57,850 --> 00:26:04,750
extended version of a canary config in

00:26:00,340 --> 00:26:06,670
very easy terms and this allows to our

00:26:04,750 --> 00:26:08,710
users to define the test case once and

00:26:06,670 --> 00:26:10,420
then each time they run an experiment

00:26:08,710 --> 00:26:12,670
they can link the test case to the

00:26:10,420 --> 00:26:14,860
experiment so they they sort of form and

00:26:12,670 --> 00:26:17,890
continues continuity between each

00:26:14,860 --> 00:26:20,050
experiment because they sort of are

00:26:17,890 --> 00:26:21,430
reusing the same test case so that way

00:26:20,050 --> 00:26:24,220
you can measure how your system is

00:26:21,430 --> 00:26:26,680
evolving through multiple experiments

00:26:24,220 --> 00:26:28,690
that you are running over time so this

00:26:26,680 --> 00:26:31,630
is a very important concept that we have

00:26:28,690 --> 00:26:33,780
built into chat the another important

00:26:31,630 --> 00:26:35,830
important concept is that we have

00:26:33,780 --> 00:26:37,570
thought about what are the different

00:26:35,830 --> 00:26:38,940
experiment types that you can run or

00:26:37,570 --> 00:26:41,610
that you would like to run

00:26:38,940 --> 00:26:45,510
and we identified some experiment

00:26:41,610 --> 00:26:48,330
families that we are recognizing in chop

00:26:45,510 --> 00:26:50,730
and that we that our users can use

00:26:48,330 --> 00:26:52,530
whenever building the experiments so

00:26:50,730 --> 00:26:54,600
these three different experiment types

00:26:52,530 --> 00:26:57,570
our change experiment production load

00:26:54,600 --> 00:26:59,810
test experiment and curves experiment so

00:26:57,570 --> 00:27:02,820
for the change experiment this is a very

00:26:59,810 --> 00:27:05,490
extending on the idea of the strategy of

00:27:02,820 --> 00:27:07,080
canary strategy so we will deploy a

00:27:05,490 --> 00:27:09,330
baseline in canary chap will deploy

00:27:07,080 --> 00:27:11,310
those two and we'll run the experiment

00:27:09,330 --> 00:27:13,080
we'll monitor the health of these two

00:27:11,310 --> 00:27:14,880
clusters and then at the end we'll

00:27:13,080 --> 00:27:17,820
generate the report so that's very

00:27:14,880 --> 00:27:20,210
similar to what we have seen what you

00:27:17,820 --> 00:27:23,070
could accomplish with the canary config

00:27:20,210 --> 00:27:25,770
so the next experiment that is a bit

00:27:23,070 --> 00:27:28,770
more involved an auto advance is the

00:27:25,770 --> 00:27:30,240
production load test experiment also

00:27:28,770 --> 00:27:33,120
with the Netflix known as Kiwis

00:27:30,240 --> 00:27:35,280
experiment so here you start again with

00:27:33,120 --> 00:27:37,740
a baseline and canary both taking the

00:27:35,280 --> 00:27:39,090
same amount of traffic but as you

00:27:37,740 --> 00:27:42,030
progress with the experiment you're

00:27:39,090 --> 00:27:45,480
running it the Chop is is acting as a

00:27:42,030 --> 00:27:47,820
sort of control plane for the routing

00:27:45,480 --> 00:27:49,530
layer and it's in well-defined steps its

00:27:47,820 --> 00:27:51,990
routing more and more traffic to the

00:27:49,530 --> 00:27:53,790
canary and then we during the experiment

00:27:51,990 --> 00:27:55,830
we are monitoring the canary canary

00:27:53,790 --> 00:27:57,540
all the time and we are measuring how

00:27:55,830 --> 00:27:59,760
the canary is behaving under this

00:27:57,540 --> 00:28:01,890
increased load and this gives us

00:27:59,760 --> 00:28:03,450
multiple multiple benefits of this

00:28:01,890 --> 00:28:05,580
experiment or results of this experiment

00:28:03,450 --> 00:28:07,530
so our users are can use it to do

00:28:05,580 --> 00:28:09,390
performance tests where they can

00:28:07,530 --> 00:28:11,850
evaluate for example tune their

00:28:09,390 --> 00:28:13,470
concurrency limits trade tools they can

00:28:11,850 --> 00:28:16,110
determine what are the corrects or

00:28:13,470 --> 00:28:18,690
optimal sizes of their instances or

00:28:16,110 --> 00:28:21,780
instance types or correct sizes for

00:28:18,690 --> 00:28:24,120
their continual resources but also this

00:28:21,780 --> 00:28:26,460
gives us in the end is a very clear

00:28:24,120 --> 00:28:29,330
number for what's the highest number of

00:28:26,460 --> 00:28:31,830
requests this instance can sustain for

00:28:29,330 --> 00:28:33,330
for an important amount of time and

00:28:31,830 --> 00:28:36,480
that's why we can use this information

00:28:33,330 --> 00:28:39,750
when we are scaling our clusters where

00:28:36,480 --> 00:28:41,940
we are capacity planning and also we can

00:28:39,750 --> 00:28:45,120
use it as parameter for our horizontal

00:28:41,940 --> 00:28:47,400
auto scaling of these clusters so this

00:28:45,120 --> 00:28:49,500
is a very popular experiment type and

00:28:47,400 --> 00:28:51,840
the final experiment is the chaos

00:28:49,500 --> 00:28:52,360
experiment again this is building on top

00:28:51,840 --> 00:28:55,600
of the

00:28:52,360 --> 00:28:57,010
the change experiment both based on in

00:28:55,600 --> 00:28:59,890
Canary are getting the same amount of

00:28:57,010 --> 00:29:04,030
traffic but the cannery is also getting

00:28:59,890 --> 00:29:06,460
an extra treatment where in a form of

00:29:04,030 --> 00:29:10,570
faults we are injecting different types

00:29:06,460 --> 00:29:12,580
of faults into into the canary cluster

00:29:10,570 --> 00:29:15,220
and that way again we are measuring how

00:29:12,580 --> 00:29:17,650
the canary cluster is behaving comparing

00:29:15,220 --> 00:29:20,320
to the baseline and this gives us

00:29:17,650 --> 00:29:23,500
information about how the system is

00:29:20,320 --> 00:29:25,270
resilient to failures another feature

00:29:23,500 --> 00:29:27,310
that we have in chap is this real-time

00:29:25,270 --> 00:29:29,740
monitoring we already mentioned it in

00:29:27,310 --> 00:29:31,720
couple of those experiment types so chap

00:29:29,740 --> 00:29:33,790
is monitoring both baseline and canary

00:29:31,720 --> 00:29:35,320
as the experiment is progressing we

00:29:33,790 --> 00:29:37,060
don't have to wait until the end to run

00:29:35,320 --> 00:29:38,980
the canary analysis but we are

00:29:37,060 --> 00:29:41,200
continuously almost in one minute steps

00:29:38,980 --> 00:29:43,000
are very granular very fine-grain steps

00:29:41,200 --> 00:29:46,570
we are monitoring the health of these

00:29:43,000 --> 00:29:48,370
two systems and then we look at if there

00:29:46,570 --> 00:29:49,540
is any kind of deviation between the two

00:29:48,370 --> 00:29:51,210
clusters we will shut down the

00:29:49,540 --> 00:29:54,610
experiment so that way we are

00:29:51,210 --> 00:29:56,110
eliminating any sort of customer pain

00:29:54,610 --> 00:29:58,390
but we could introduce through the

00:29:56,110 --> 00:29:59,860
experiment and also we don't have to

00:29:58,390 --> 00:30:02,380
wait till the end of the experiment to

00:29:59,860 --> 00:30:04,630
show the result if we see that the

00:30:02,380 --> 00:30:06,970
experiment will clearly fail so we can

00:30:04,630 --> 00:30:09,700
just shut down the experiment early and

00:30:06,970 --> 00:30:11,980
then once we finish the experiment we

00:30:09,700 --> 00:30:13,720
run the analysis and again we built on

00:30:11,980 --> 00:30:16,090
top of the concepts that we are overly

00:30:13,720 --> 00:30:18,910
already available in spinnaker today so

00:30:16,090 --> 00:30:20,770
we run canary analysis but we don't just

00:30:18,910 --> 00:30:22,720
run one canary analysis or one canary

00:30:20,770 --> 00:30:25,840
config we have identified what are the

00:30:22,720 --> 00:30:27,670
common common ideas that people usually

00:30:25,840 --> 00:30:29,710
use when they are creating canary

00:30:27,670 --> 00:30:31,180
conflicts within Netflix and then we

00:30:29,710 --> 00:30:33,820
have determined what are this sort of

00:30:31,180 --> 00:30:35,470
the canned canary conflicts that can be

00:30:33,820 --> 00:30:38,320
applied to any kind of experiment that

00:30:35,470 --> 00:30:40,120
we can run and that way users don't

00:30:38,320 --> 00:30:41,500
really have to define or maintain these

00:30:40,120 --> 00:30:43,000
canary conflicts and we just

00:30:41,500 --> 00:30:45,490
automatically apply them to any

00:30:43,000 --> 00:30:47,590
experiment that could be run of course

00:30:45,490 --> 00:30:49,900
users can define their own extra custom

00:30:47,590 --> 00:30:53,980
conflicts for any specific experiment

00:30:49,900 --> 00:30:55,900
and so as we said the true value from

00:30:53,980 --> 00:30:57,850
experimentation comes when you can run

00:30:55,900 --> 00:31:01,090
this experiment multiple times over the

00:30:57,850 --> 00:31:03,850
time over over your software development

00:31:01,090 --> 00:31:05,800
lifecycle and that's why we build two

00:31:03,850 --> 00:31:09,130
custom stages into spinnaker

00:31:05,800 --> 00:31:11,440
that allows you to to run or trigger

00:31:09,130 --> 00:31:13,480
chop experiments from each individual of

00:31:11,440 --> 00:31:15,850
these stages so here we are defining a

00:31:13,480 --> 00:31:18,610
pipeline that will run a squeeze test or

00:31:15,850 --> 00:31:21,310
a performance load test on your service

00:31:18,610 --> 00:31:23,530
so this will trigger a chop experiment

00:31:21,310 --> 00:31:26,290
will wait until this experiment finishes

00:31:23,530 --> 00:31:28,630
and then we'll get the result of the

00:31:26,290 --> 00:31:30,610
experiment and we can either continue

00:31:28,630 --> 00:31:34,090
with the pipeline or terminate the

00:31:30,610 --> 00:31:37,270
pipeline if the experiment failed and

00:31:34,090 --> 00:31:40,000
this is where this this diagram really

00:31:37,270 --> 00:31:42,210
illustrates the success of chap because

00:31:40,000 --> 00:31:44,950
these are three different pipelines

00:31:42,210 --> 00:31:47,260
defined for one of the services that we

00:31:44,950 --> 00:31:49,810
are maintaining or we are running in in

00:31:47,260 --> 00:31:51,970
a Netflix back-end and each of these

00:31:49,810 --> 00:31:53,680
back each of these pipelines is actually

00:31:51,970 --> 00:31:57,940
running a different sort of experiment

00:31:53,680 --> 00:32:00,510
so the users or the owners of the of

00:31:57,940 --> 00:32:03,010
this application decided they will

00:32:00,510 --> 00:32:04,930
create a first pipeline that will create

00:32:03,010 --> 00:32:06,790
and that will put their software

00:32:04,930 --> 00:32:08,980
artifacts production this is running

00:32:06,790 --> 00:32:11,130
daily and they as part of that pipeline

00:32:08,980 --> 00:32:14,200
they are running a change experiment

00:32:11,130 --> 00:32:16,810
using chap so the second pipe the 2nd

00:32:14,200 --> 00:32:19,650
pipeline is the chaos experiment that is

00:32:16,810 --> 00:32:21,280
running once a week again tracking any

00:32:19,650 --> 00:32:23,860
resiliency regressions

00:32:21,280 --> 00:32:25,960
so again formalized as a pipeline and

00:32:23,860 --> 00:32:27,700
then the last pipeline is a performance

00:32:25,960 --> 00:32:29,650
load test that is running every day

00:32:27,700 --> 00:32:30,970
again tracking any performance

00:32:29,650 --> 00:32:36,370
regressions if you're in your

00:32:30,970 --> 00:32:38,260
application so this this way the are the

00:32:36,370 --> 00:32:40,840
service owners of this application were

00:32:38,260 --> 00:32:45,580
able to embrace chap and introduce it

00:32:40,840 --> 00:32:47,650
into their everyday pipelines and now we

00:32:45,580 --> 00:32:49,330
would like to also as I said we are

00:32:47,650 --> 00:32:52,780
leveraging when we are implementing chap

00:32:49,330 --> 00:32:55,030
we leveraged many tools within Netflix

00:32:52,780 --> 00:32:58,300
ecosystem so now we would like to just

00:32:55,030 --> 00:33:00,850
show you how we are using them just to

00:32:58,300 --> 00:33:03,630
illustrate how once you embrace vinegar

00:33:00,850 --> 00:33:05,890
how easy it is to build on top of that

00:33:03,630 --> 00:33:08,980
so let's say we want to conduct an

00:33:05,890 --> 00:33:10,930
experiment on the my service so will

00:33:08,980 --> 00:33:13,330
using the chap will define a test case

00:33:10,930 --> 00:33:16,920
we'll start a new experiment using this

00:33:13,330 --> 00:33:19,040
test case during the experiment setup

00:33:16,920 --> 00:33:21,110
chap will contact spinach

00:33:19,040 --> 00:33:23,600
and spinnaker will roll out the baseline

00:33:21,110 --> 00:33:26,900
in canary clusters also during the setup

00:33:23,600 --> 00:33:28,940
we instruct the routing layer to to send

00:33:26,900 --> 00:33:30,920
traffic to these new clusters and also

00:33:28,940 --> 00:33:32,679
optionally if this is a chaos experiment

00:33:30,920 --> 00:33:36,710
we can also set up the fault injection

00:33:32,679 --> 00:33:38,090
service for this experiment during the

00:33:36,710 --> 00:33:39,890
run of the experiment we are

00:33:38,090 --> 00:33:42,350
continuously monitoring the hope of both

00:33:39,890 --> 00:33:45,350
of the clusters we can shut down early

00:33:42,350 --> 00:33:48,230
and and then once we finish we use again

00:33:45,350 --> 00:33:49,820
spin occur to to run canary analysis on

00:33:48,230 --> 00:33:53,660
all these canary convicts that are

00:33:49,820 --> 00:33:55,130
defined for this specific experiment so

00:33:53,660 --> 00:33:58,400
this is illustrating how we've been able

00:33:55,130 --> 00:34:01,549
to leverage spinnaker to actually sort

00:33:58,400 --> 00:34:04,850
of design these advanced types of

00:34:01,549 --> 00:34:08,240
experiments and this brings us to the

00:34:04,850 --> 00:34:10,940
conclusion so what we wanted to say is

00:34:08,240 --> 00:34:14,899
that spinnaker is really important to

00:34:10,940 --> 00:34:17,359
when you want to make really advanced

00:34:14,899 --> 00:34:19,280
the deployment flows for your

00:34:17,359 --> 00:34:21,740
infrastructure but this is not the

00:34:19,280 --> 00:34:24,050
really the end of the journey this once

00:34:21,740 --> 00:34:25,399
you do that this is only opening all the

00:34:24,050 --> 00:34:27,859
new horizons where you can run different

00:34:25,399 --> 00:34:31,510
types of experiments or different types

00:34:27,859 --> 00:34:34,550
of activities on top of your orchestrate

00:34:31,510 --> 00:34:38,060
infrastructure and that's why we define

00:34:34,550 --> 00:34:39,740
experiment two just to show you what

00:34:38,060 --> 00:34:41,600
what we believe are the principles of

00:34:39,740 --> 00:34:44,840
experimentation and how those can be

00:34:41,600 --> 00:34:46,129
applied effectively to experiment that

00:34:44,840 --> 00:34:49,310
you can run on top of your

00:34:46,129 --> 00:34:51,919
infrastructure and once you do that this

00:34:49,310 --> 00:34:53,990
opens the door to automation to the

00:34:51,919 --> 00:34:56,720
definition of more advanced experiment

00:34:53,990 --> 00:34:59,540
types and then so this is where they

00:34:56,720 --> 00:35:01,520
chaps it and then once we have chap you

00:34:59,540 --> 00:35:02,570
can you can just introduce the

00:35:01,520 --> 00:35:04,580
continuous integration or

00:35:02,570 --> 00:35:07,430
experimentation into your software

00:35:04,580 --> 00:35:08,810
development life cycles and with that I

00:35:07,430 --> 00:35:10,850
wanted to thank you for your attention

00:35:08,810 --> 00:35:13,840
and if you have any questions we'll be

00:35:10,850 --> 00:35:13,840
happy to answer those

00:35:15,170 --> 00:35:25,089
[Applause]

00:35:16,960 --> 00:35:25,089
and we have stickers thank you

00:35:30,500 --> 00:35:37,599
it's not hey unfortunately your question

00:35:39,240 --> 00:35:44,880
having concern of using any kind of

00:35:42,359 --> 00:35:46,800
artificial traffic instead of real

00:35:44,880 --> 00:35:49,230
traffic to do this canary analysis

00:35:46,800 --> 00:35:51,720
experiments because if you want to use

00:35:49,230 --> 00:35:52,470
real real traffic to do this is kind of

00:35:51,720 --> 00:35:54,690
thing

00:35:52,470 --> 00:35:56,819
why thing is like traffic barriers from

00:35:54,690 --> 00:35:59,550
time to time and a deed second point is

00:35:56,819 --> 00:36:00,830
it can be very costly of using real

00:35:59,550 --> 00:36:02,780
traffic

00:36:00,830 --> 00:36:05,420
but the use of the cave but user can be

00:36:02,780 --> 00:36:09,530
impacted

00:36:05,420 --> 00:36:12,440
yes yes yeah so we find tremendous value

00:36:09,530 --> 00:36:15,080
in losing using live traffic because

00:36:12,440 --> 00:36:16,940
this is where we can see how the service

00:36:15,080 --> 00:36:19,280
is actually reacting to the real traffic

00:36:16,940 --> 00:36:22,250
so because if you if you do any kind of

00:36:19,280 --> 00:36:24,260
load simulation you may not get the

00:36:22,250 --> 00:36:25,760
patterns right of the traffic patterns

00:36:24,260 --> 00:36:27,980
right and maybe then you are not

00:36:25,760 --> 00:36:30,380
measuring the right thing but so that's

00:36:27,980 --> 00:36:32,360
why the the live traffic scenario is

00:36:30,380 --> 00:36:35,630
really important for us and that's where

00:36:32,360 --> 00:36:37,850
we focused first but also it is it is

00:36:35,630 --> 00:36:40,510
true that we are exhibiting different

00:36:37,850 --> 00:36:44,390
sorts of ways how to generate traffic

00:36:40,510 --> 00:36:46,490
either simulated or capture and reply so

00:36:44,390 --> 00:36:49,360
we are definitely looking into these

00:36:46,490 --> 00:36:49,360
different options

00:36:53,040 --> 00:36:59,610
[Laughter]

00:36:57,550 --> 00:36:59,610

YouTube URL: https://www.youtube.com/watch?v=IjTTs1sxlXs


