Title: Gopinath Rebala - Creating Custom Judge for Kayenta
Publication date: 2018-12-13
Playlist: Spinnaker Summit 2018
Description: 
	
Captions: 
	00:00:01,270 --> 00:00:05,390
[Music]

00:00:09,780 --> 00:00:13,270
[Music]

00:00:21,420 --> 00:00:25,320
kinda is designed to be a standalone

00:00:23,160 --> 00:00:30,529
system it doesn't have to work with

00:00:25,320 --> 00:00:33,540
spinnaker and it you know of course is

00:00:30,529 --> 00:00:38,070
the libraries of spinnaker to have this

00:00:33,540 --> 00:00:41,790
extensibility scale it uses readies and

00:00:38,070 --> 00:00:45,300
Orca it uses the storage systems like s3

00:00:41,790 --> 00:00:47,040
if you have configured GCS G for storing

00:00:45,300 --> 00:00:49,580
the intermediate data that it extracts

00:00:47,040 --> 00:00:51,449
on the stories it has quite a few

00:00:49,580 --> 00:00:56,699
integrations with data stores

00:00:51,449 --> 00:00:59,489
it had Prometheus Strank driver and data

00:00:56,699 --> 00:01:02,850
log now I think in flux DB is also in

00:00:59,489 --> 00:01:05,780
their signal effects is coming soon it's

00:01:02,850 --> 00:01:08,909
very nicely integrated UI with spinnaker

00:01:05,780 --> 00:01:10,710
you can actually see the configurations

00:01:08,909 --> 00:01:14,159
you can run it in a retrospective mode

00:01:10,710 --> 00:01:17,700
as well as the real-time so it's a

00:01:14,159 --> 00:01:20,130
pretty cool stuff so yesterday some of

00:01:17,700 --> 00:01:23,490
you may have attended the metrics talk

00:01:20,130 --> 00:01:27,390
given by Michael graph this is a simple

00:01:23,490 --> 00:01:32,670
flow further kind of one is to fetch the

00:01:27,390 --> 00:01:35,549
metrics so deploy have seen in the UI in

00:01:32,670 --> 00:01:39,090
scientist set up in the spinnaker you

00:01:35,549 --> 00:01:43,350
have to give it a scope and specify what

00:01:39,090 --> 00:01:45,030
is your baseline which is the real thing

00:01:43,350 --> 00:01:48,770
and then the canary which is experiment

00:01:45,030 --> 00:01:52,229
and once the canvas

00:01:48,770 --> 00:01:54,170
this starts API is called it goes and

00:01:52,229 --> 00:01:58,409
fetches the data it cleans the data

00:01:54,170 --> 00:02:00,659
aligns all the data together and passes

00:01:58,409 --> 00:02:02,880
it to the judge which does a little bit

00:02:00,659 --> 00:02:03,659
more cleaning with respect to Nan's and

00:02:02,880 --> 00:02:05,670
things like that

00:02:03,659 --> 00:02:07,979
there's the metric comparison using

00:02:05,670 --> 00:02:11,580
classifiers and then computes the score

00:02:07,979 --> 00:02:13,319
so there's three stages there one is the

00:02:11,580 --> 00:02:15,780
data cleaning one is the comparison

00:02:13,319 --> 00:02:18,000
these are the classifiers and the judge

00:02:15,780 --> 00:02:23,730
itself can use one or more classifiers

00:02:18,000 --> 00:02:27,990
depending on how you want to use that so

00:02:23,730 --> 00:02:32,420
this is a little bit more detailed than

00:02:27,990 --> 00:02:34,440
the previous one once the canary starts

00:02:32,420 --> 00:02:38,340
the judge

00:02:34,440 --> 00:02:41,430
the kind of system breaks it down into

00:02:38,340 --> 00:02:44,070
multiple tasks it's a data fetching part

00:02:41,430 --> 00:02:46,650
it does a lot of retries there are some

00:02:44,070 --> 00:02:48,450
additional reliability things that are

00:02:46,650 --> 00:02:51,030
built into that for the collection of

00:02:48,450 --> 00:02:53,400
the data and then the matrix can be

00:02:51,030 --> 00:02:55,920
grouped for scoring there are weights

00:02:53,400 --> 00:02:59,370
that you can give to the groups and

00:02:55,920 --> 00:03:01,050
those are all done at that point and

00:02:59,370 --> 00:03:04,470
then send it to the judge judge

00:03:01,050 --> 00:03:07,410
interface itself is very simple it takes

00:03:04,470 --> 00:03:10,020
the metric pairs essentially the

00:03:07,410 --> 00:03:12,480
baseline and Kennedy pairs of the data

00:03:10,020 --> 00:03:15,300
which are aligned with the timestamps

00:03:12,480 --> 00:03:17,070
and it expects a result back with the

00:03:15,300 --> 00:03:19,110
configuration that's passed in the

00:03:17,070 --> 00:03:23,130
configuration is parametric

00:03:19,110 --> 00:03:26,790
configuration maybe you can quickly look

00:03:23,130 --> 00:03:29,130
at how the configuration looks so you

00:03:26,790 --> 00:03:31,950
can go select metrics from your data

00:03:29,130 --> 00:03:34,440
source and for each one of the metrics

00:03:31,950 --> 00:03:38,250
you can specify what group that falls

00:03:34,440 --> 00:03:41,010
into it you can specify the direction if

00:03:38,250 --> 00:03:44,340
it needs to fail enough on is it

00:03:41,010 --> 00:03:46,920
increase or decrease or either and and

00:03:44,340 --> 00:03:49,380
the criticality refers to the system

00:03:46,920 --> 00:03:51,510
where if a particular metric that we

00:03:49,380 --> 00:03:54,360
think is critical fails you fail the

00:03:51,510 --> 00:03:57,530
entire canary right and the nan

00:03:54,360 --> 00:04:00,300
strategies and the filter templates

00:03:57,530 --> 00:04:02,940
Cisco essentially refers to in

00:04:00,300 --> 00:04:05,370
communities kind of a thing maybe it's

00:04:02,940 --> 00:04:07,530
the namespace or the server group that's

00:04:05,370 --> 00:04:09,900
being installed replica said that's

00:04:07,530 --> 00:04:11,760
being deployed it depends on a little

00:04:09,900 --> 00:04:16,190
bit on the matrix store that you are

00:04:11,760 --> 00:04:19,590
using how you specify these scopes and

00:04:16,190 --> 00:04:22,080
you can also provide label bindings in

00:04:19,590 --> 00:04:24,270
some of this metric stores if you group

00:04:22,080 --> 00:04:26,610
by if you have multiple metrics that are

00:04:24,270 --> 00:04:28,050
coming in which all have slightly

00:04:26,610 --> 00:04:30,420
different tags for example CPU

00:04:28,050 --> 00:04:33,570
utilization can have a system versus

00:04:30,420 --> 00:04:35,550
user versus idle you can get all of them

00:04:33,570 --> 00:04:39,870
as separate groups and compare them

00:04:35,550 --> 00:04:42,270
separately fine the judge interface like

00:04:39,870 --> 00:04:44,580
I said is a fairly straightforward it

00:04:42,270 --> 00:04:47,840
takes the canary config which is what we

00:04:44,580 --> 00:04:52,120
saw in the UI for individual metrics

00:04:47,840 --> 00:04:55,240
so it's only takes score thresholds is

00:04:52,120 --> 00:04:58,580
what it refers to you as pass or fail

00:04:55,240 --> 00:05:00,680
classification so when it scores for a

00:04:58,580 --> 00:05:03,680
group you can say whether it's a pass or

00:05:00,680 --> 00:05:05,570
fail based on the threshold minimum

00:05:03,680 --> 00:05:09,320
threshold and the maximum threshold that

00:05:05,570 --> 00:05:13,490
is set for the judge for example you can

00:05:09,320 --> 00:05:15,200
say 70 or below it's a fail 90 area bar

00:05:13,490 --> 00:05:17,900
is a pass somewhere it's in the gray

00:05:15,200 --> 00:05:21,470
area right but but individual metrics

00:05:17,900 --> 00:05:22,070
themselves have a zero 100 pass outfit

00:05:21,470 --> 00:05:24,440
that's it

00:05:22,070 --> 00:05:30,850
that's a classifier the way the

00:05:24,440 --> 00:05:34,610
algorithm that's being used and once we

00:05:30,850 --> 00:05:36,580
call the judge that the class groups

00:05:34,610 --> 00:05:39,260
that needs to be implemented or

00:05:36,580 --> 00:05:42,440
essentially the judge class judge

00:05:39,260 --> 00:05:45,170
basically is a overall class that calls

00:05:42,440 --> 00:05:48,380
the classifier but individual metric

00:05:45,170 --> 00:05:50,870
classifier is a way of saying pass or

00:05:48,380 --> 00:05:52,940
fail but in doodle metric you can think

00:05:50,870 --> 00:05:56,060
of class whereas let's say you're taking

00:05:52,940 --> 00:05:58,880
an average for the metric the classifier

00:05:56,060 --> 00:06:02,180
would then look at average of baseline

00:05:58,880 --> 00:06:04,430
average of Kennedy and then says if they

00:06:02,180 --> 00:06:07,730
are same it's a pass if they're not it's

00:06:04,430 --> 00:06:10,550
a fail that's a pretty strict comparison

00:06:07,730 --> 00:06:12,110
which usually always fails but as an

00:06:10,550 --> 00:06:16,250
example that will be the classifier

00:06:12,110 --> 00:06:18,350
right so it calls the first it costs the

00:06:16,250 --> 00:06:22,190
data processors some of this data that's

00:06:18,350 --> 00:06:23,660
coming in for example errors in some of

00:06:22,190 --> 00:06:25,790
these collection mechanisms if there are

00:06:23,660 --> 00:06:28,220
no errors there is no data for the time

00:06:25,790 --> 00:06:30,620
lines it only sends their data when

00:06:28,220 --> 00:06:33,050
there is an error it's also incremental

00:06:30,620 --> 00:06:34,850
sometimes right so those things we need

00:06:33,050 --> 00:06:37,370
to take care of end if the data is

00:06:34,850 --> 00:06:39,320
coming in that's has not a number in

00:06:37,370 --> 00:06:41,410
them so you have to decide whether you

00:06:39,320 --> 00:06:43,970
want to replace that with a zero or

00:06:41,410 --> 00:06:46,220
ignore that indeed our replicate the

00:06:43,970 --> 00:06:47,530
same data those kind of things can be

00:06:46,220 --> 00:06:51,170
done with the data processors

00:06:47,530 --> 00:06:53,350
classifiers as we discussed is the where

00:06:51,170 --> 00:06:55,490
it can have an average classifier or

00:06:53,350 --> 00:06:57,980
some other classifier right now the

00:06:55,490 --> 00:06:59,439
default implementation is something

00:06:57,980 --> 00:07:02,930
called mann-whitney

00:06:59,439 --> 00:07:06,229
regarding tax classifier what this one

00:07:02,930 --> 00:07:09,650
does is a it's a nonparametric

00:07:06,229 --> 00:07:12,110
classifier if you're familiar with the

00:07:09,650 --> 00:07:14,000
statistical terms the parametric

00:07:12,110 --> 00:07:16,550
classifiers usually are parameters that

00:07:14,000 --> 00:07:18,620
you use to compare one another that

00:07:16,550 --> 00:07:21,830
would be something like your mean

00:07:18,620 --> 00:07:24,169
standard deviation all right variance

00:07:21,830 --> 00:07:26,569
those kind of parameters you will say I

00:07:24,169 --> 00:07:28,099
have the distribution for the baseline

00:07:26,569 --> 00:07:32,210
that is coming in I have the

00:07:28,099 --> 00:07:34,039
distribution for the Kennedy it hariya

00:07:32,210 --> 00:07:36,259
compare these two distributions there

00:07:34,039 --> 00:07:37,940
are multiple ways of doing it the simple

00:07:36,259 --> 00:07:40,069
ones would be something like a t-test

00:07:37,940 --> 00:07:41,659
which is a pretty common which assumes

00:07:40,069 --> 00:07:44,150
certain things about the distribution

00:07:41,659 --> 00:07:46,789
like the normal distribution and then

00:07:44,150 --> 00:07:48,889
you can say is my mean the same is the

00:07:46,789 --> 00:07:52,039
standard deviation different based on

00:07:48,889 --> 00:07:53,840
that you'll say it's a pass or fail you

00:07:52,039 --> 00:07:57,979
cannot you can say if my standard

00:07:53,840 --> 00:08:00,860
deviation is ten percent within the

00:07:57,979 --> 00:08:03,080
range and the mean is ten percent within

00:08:00,860 --> 00:08:05,180
the range passive but mann-whitney

00:08:03,080 --> 00:08:07,129
classifier is an interesting one here it

00:08:05,180 --> 00:08:12,190
does not use these parameters it just

00:08:07,129 --> 00:08:16,069
uses fix an element from the baseline

00:08:12,190 --> 00:08:18,379
from the canary and says is it above or

00:08:16,069 --> 00:08:20,779
below the median that I expect from the

00:08:18,379 --> 00:08:22,879
baseline and it does that statistically

00:08:20,779 --> 00:08:25,159
for all the parameters and if it comes

00:08:22,879 --> 00:08:26,539
out to be almost the same half of them

00:08:25,159 --> 00:08:30,620
are about half of them are below it says

00:08:26,539 --> 00:08:32,180
yeah it's a pass they look very close so

00:08:30,620 --> 00:08:37,099
those are that's the default classifier

00:08:32,180 --> 00:08:41,860
that's implemented so we can quickly

00:08:37,099 --> 00:08:41,860
look at the default judge implementation

00:08:43,149 --> 00:08:51,649
so this is the kind of project I'm this

00:08:50,089 --> 00:08:54,649
is IntelliJ this is not not my

00:08:51,649 --> 00:08:56,990
development machine so that's the kind

00:08:54,649 --> 00:08:59,899
of project a as you can see the way it's

00:08:56,990 --> 00:09:02,540
organized each one of kinda core is the

00:08:59,899 --> 00:09:06,320
base one that has our car radius

00:09:02,540 --> 00:09:08,390
interactions and you can see this Atlas

00:09:06,320 --> 00:09:11,750
data dog

00:09:08,390 --> 00:09:13,520
GCS in flux DB these are all the data

00:09:11,750 --> 00:09:17,520
stores in some form of

00:09:13,520 --> 00:09:21,029
for this particular talk we are mostly

00:09:17,520 --> 00:09:24,330
interested in the kind to judge in the

00:09:21,029 --> 00:09:27,360
kind of judge if you see it's also

00:09:24,330 --> 00:09:33,089
organized as classifiers this is what we

00:09:27,360 --> 00:09:35,760
just spoke about and Skouras is where it

00:09:33,089 --> 00:09:38,010
takes the classification output for

00:09:35,760 --> 00:09:40,940
individual metrics say you have a one

00:09:38,010 --> 00:09:43,830
CPU metric one memory metric and one

00:09:40,940 --> 00:09:45,570
latency networking kind of metric it

00:09:43,830 --> 00:09:47,880
takes those metrics each of these groups

00:09:45,570 --> 00:09:49,800
currently have weights so the scorer is

00:09:47,880 --> 00:09:52,970
the one that applies those weights to

00:09:49,800 --> 00:09:54,779
individual groups and then computes them

00:09:52,970 --> 00:09:57,930
there are a lot of changes that are

00:09:54,779 --> 00:10:02,580
coming but you know that's the current

00:09:57,930 --> 00:10:06,350
implementation right and and the

00:10:02,580 --> 00:10:08,930
detectors is another thing where it uses

00:10:06,350 --> 00:10:12,000
removes the anomalies in the data

00:10:08,930 --> 00:10:14,130
anomalies are defined as something that

00:10:12,000 --> 00:10:17,550
you don't expect to see it very short

00:10:14,130 --> 00:10:19,800
bursts or something like that so for us

00:10:17,550 --> 00:10:22,760
to compare the baseline and Kennedy you

00:10:19,800 --> 00:10:26,670
want to make sure we are comparing their

00:10:22,760 --> 00:10:30,180
normal behavior versus trying to do

00:10:26,670 --> 00:10:32,520
something anomalous behavior so if there

00:10:30,180 --> 00:10:34,649
is a small spike then you would remove

00:10:32,520 --> 00:10:37,290
that small spike there are multiple

00:10:34,649 --> 00:10:39,329
techniques I think we have these

00:10:37,290 --> 00:10:44,459
implementations as IQR implementation

00:10:39,329 --> 00:10:46,920
Sigma detectors right simply saying if I

00:10:44,459 --> 00:10:49,860
will compute 95 percentile anything

00:10:46,920 --> 00:10:51,839
above I will remove usually don't want

00:10:49,860 --> 00:10:53,520
to remove more than 5% of the data to

00:10:51,839 --> 00:10:59,339
make sure the distribution remains the

00:10:53,520 --> 00:11:04,680
same that is being done and the judge is

00:10:59,339 --> 00:11:06,660
the one that's a implementation here you

00:11:04,680 --> 00:11:09,930
can see the judge has this canary

00:11:06,660 --> 00:11:13,020
configures input thresholds that are

00:11:09,930 --> 00:11:15,510
being sent to return as a pass or fail

00:11:13,020 --> 00:11:17,730
with the data these are the ones that

00:11:15,510 --> 00:11:20,000
you would alright and the matrix pair

00:11:17,730 --> 00:11:20,000
list

00:11:23,259 --> 00:11:27,649
symmetric playlists scored thresholds

00:11:25,550 --> 00:11:30,470
and Kennedy configure output is the

00:11:27,649 --> 00:11:33,499
canary judge result the canary judge

00:11:30,470 --> 00:11:37,299
result will include pass/fail for each

00:11:33,499 --> 00:11:39,709
or nota metric pays for all score and

00:11:37,299 --> 00:11:41,600
the group score because we have some

00:11:39,709 --> 00:11:49,329
metrics that we can group it also

00:11:41,600 --> 00:11:52,790
computes the group score for them then

00:11:49,329 --> 00:11:57,189
so what we'll do today is take a simple

00:11:52,790 --> 00:12:00,019
example to add to the mann-whitney

00:11:57,189 --> 00:12:02,749
classifier we will add a threshold based

00:12:00,019 --> 00:12:05,809
classifier it's basically saying okay if

00:12:02,749 --> 00:12:07,279
you have two distributions it may not

00:12:05,809 --> 00:12:09,589
have the same distribution when we

00:12:07,279 --> 00:12:11,449
compare with mann-whitney but there's

00:12:09,589 --> 00:12:14,480
close enough developers don't really

00:12:11,449 --> 00:12:15,860
care they are ten percent off from each

00:12:14,480 --> 00:12:18,549
so there are five percent off maybe

00:12:15,860 --> 00:12:21,049
because of the way the metric has chosen

00:12:18,549 --> 00:12:25,579
they start off at different levels but

00:12:21,049 --> 00:12:27,529
they continue and it fails but really

00:12:25,579 --> 00:12:30,199
developer doesn't care for them to be

00:12:27,529 --> 00:12:33,920
failed and the other one that we will do

00:12:30,199 --> 00:12:37,790
is we can if we say we can compute

00:12:33,920 --> 00:12:40,339
weights for these metrics externally so

00:12:37,790 --> 00:12:42,439
we have some sometimes when you select

00:12:40,339 --> 00:12:45,019
particularly Netflix kind of scenario

00:12:42,439 --> 00:12:46,339
they have extensive metric collection

00:12:45,019 --> 00:12:49,100
mechanisms they have gateways they

00:12:46,339 --> 00:12:51,350
collect data for each of these api's if

00:12:49,100 --> 00:12:53,990
a service has ten different API is it

00:12:51,350 --> 00:12:56,929
collects ten metrics for API got 100

00:12:53,990 --> 00:13:00,769
metrics just at the API level and so in

00:12:56,929 --> 00:13:02,629
those situations the developers are not

00:13:00,769 --> 00:13:04,490
really fully aware what's important

00:13:02,629 --> 00:13:07,639
what's not based on traffic patterns

00:13:04,490 --> 00:13:09,110
there are ways you can compute which are

00:13:07,639 --> 00:13:11,240
important which are not based on the

00:13:09,110 --> 00:13:14,449
long term data so let's say we compute

00:13:11,240 --> 00:13:16,910
those weights externally then we can

00:13:14,449 --> 00:13:19,569
assign it to them so the one example

00:13:16,910 --> 00:13:19,569
here is

00:13:25,170 --> 00:13:31,690
here this is a CPU time I think so they

00:13:30,040 --> 00:13:34,780
started off at slightly different they

00:13:31,690 --> 00:13:38,140
continued they're almost the same but

00:13:34,780 --> 00:13:40,210
they but you can see that they are in

00:13:38,140 --> 00:13:42,490
different levels right if you're doing a

00:13:40,210 --> 00:13:44,500
nonparametric comparison clearly they're

00:13:42,490 --> 00:13:47,830
not the same one is always about the

00:13:44,500 --> 00:13:50,830
other so this time kind of thing will

00:13:47,830 --> 00:13:52,930
fail but if you take a parametric

00:13:50,830 --> 00:13:57,520
comparison and say hey where is my mean

00:13:52,930 --> 00:13:59,530
is it within the range of some 5% then

00:13:57,520 --> 00:14:02,790
yes they are within the range and you

00:13:59,530 --> 00:14:04,990
can pass them this is a real example

00:14:02,790 --> 00:14:06,810
there are other ways of dealing with

00:14:04,990 --> 00:14:10,330
this but for this purpose of the demo

00:14:06,810 --> 00:14:16,120
we're going to do implementation for

00:14:10,330 --> 00:14:18,450
this and so here what we will do is will

00:14:16,120 --> 00:14:20,950
create a percentage classifier

00:14:18,450 --> 00:14:24,120
essentially copy-paste the existing kind

00:14:20,950 --> 00:14:27,420
of classifier with its interface add

00:14:24,120 --> 00:14:30,640
code to compare based on the

00:14:27,420 --> 00:14:33,430
distribution metrics and then return

00:14:30,640 --> 00:14:37,990
pass our foil to it what we'll also do

00:14:33,430 --> 00:14:40,270
is in in statistical world people use

00:14:37,990 --> 00:14:42,430
something called ensemble approach when

00:14:40,270 --> 00:14:46,270
you don't know what is right you do four

00:14:42,430 --> 00:14:47,770
things and then say you know I'll leave

00:14:46,270 --> 00:14:49,710
it to God and see which one works kind

00:14:47,770 --> 00:14:52,600
of thing so this ensemble approach

00:14:49,710 --> 00:14:54,520
actually in this particular case but

00:14:52,600 --> 00:14:55,930
combining one Whitney and threshold

00:14:54,520 --> 00:14:59,350
actually gives slightly different better

00:14:55,930 --> 00:15:01,540
results we'll just say how to combine

00:14:59,350 --> 00:15:05,350
those two classifiers within the church

00:15:01,540 --> 00:15:08,830
and get a better result right when you

00:15:05,350 --> 00:15:12,700
do a compare it checks what is the

00:15:08,830 --> 00:15:15,460
percent change from the control which is

00:15:12,700 --> 00:15:17,800
a baseline to experiment which is the

00:15:15,460 --> 00:15:20,260
Kennedy that is deployed here we are

00:15:17,800 --> 00:15:22,420
also making some assumptions on when

00:15:20,260 --> 00:15:24,640
you're comparing these metrics there are

00:15:22,420 --> 00:15:27,460
some control parameters that we assumed

00:15:24,640 --> 00:15:29,920
to be the same that there is the input

00:15:27,460 --> 00:15:32,740
load that they are processing is

00:15:29,920 --> 00:15:36,490
equivalent to each other that's exactly

00:15:32,740 --> 00:15:38,709
the reason why we deploy both the

00:15:36,490 --> 00:15:41,320
and Kennedy at the same time to compare

00:15:38,709 --> 00:15:43,570
we also are negating lot of the

00:15:41,320 --> 00:15:45,880
long-term effects if his system has been

00:15:43,570 --> 00:15:48,430
running for a long time there probably

00:15:45,880 --> 00:15:50,560
were high loads at some point that would

00:15:48,430 --> 00:15:53,170
have increased is it's a memory cache

00:15:50,560 --> 00:15:55,180
use age but at this point they may not

00:15:53,170 --> 00:15:58,060
be high but still the cache would look

00:15:55,180 --> 00:16:03,490
high right those are all assumed to be

00:15:58,060 --> 00:16:07,510
controlled in here we just do check is

00:16:03,490 --> 00:16:11,080
pass we basically used our threshold and

00:16:07,510 --> 00:16:13,480
lower thresholds so you can also have

00:16:11,080 --> 00:16:15,700
this little bit more sophisticated

00:16:13,480 --> 00:16:17,940
maybe Netflix internally has the

00:16:15,700 --> 00:16:20,800
implementation you can say if it is

00:16:17,940 --> 00:16:23,350
latency kind of a metric if it is higher

00:16:20,800 --> 00:16:25,510
by 10% you should fail but if it is

00:16:23,350 --> 00:16:27,430
lower by 20%

00:16:25,510 --> 00:16:30,339
you should still pass you can have

00:16:27,430 --> 00:16:33,339
things like that set up depending on the

00:16:30,339 --> 00:16:36,640
metric so CPU utilization would be

00:16:33,339 --> 00:16:38,440
similar if it's a higher CPU utilization

00:16:36,640 --> 00:16:40,810
you might want to fail but if it is a

00:16:38,440 --> 00:16:42,430
lower it's okay but it should not be too

00:16:40,810 --> 00:16:44,890
low if it is too low then there's

00:16:42,430 --> 00:16:48,730
something else wrong right you know so

00:16:44,890 --> 00:16:51,339
all it does is gets with looks it looks

00:16:48,730 --> 00:16:54,490
at it within the thresholds which is

00:16:51,339 --> 00:17:00,029
high low and then if it will pass if it

00:16:54,490 --> 00:17:02,560
is all within the range right so that's

00:17:00,029 --> 00:17:05,980
pretty much I wanted to show in terms of

00:17:02,560 --> 00:17:07,510
learnings you have to careful learning

00:17:05,980 --> 00:17:08,890
about what kind of matrix you want to

00:17:07,510 --> 00:17:12,130
choose how many matrix you want to

00:17:08,890 --> 00:17:16,329
choose to get less false positives or

00:17:12,130 --> 00:17:17,770
false negatives for example so the

00:17:16,329 --> 00:17:20,290
matrix that some of them I have chose

00:17:17,770 --> 00:17:22,990
and the CPU matrix are collected by

00:17:20,290 --> 00:17:26,470
Prometheus these metrics are cumulative

00:17:22,990 --> 00:17:28,870
metrics in some cases for errors and

00:17:26,470 --> 00:17:31,480
cumulative matrix like this it may not

00:17:28,870 --> 00:17:34,630
address but for these kind of metrics it

00:17:31,480 --> 00:17:37,240
may be better for using rate of change

00:17:34,630 --> 00:17:40,780
as a metric for comparison rather than

00:17:37,240 --> 00:17:42,790
the metric itself right so then you know

00:17:40,780 --> 00:17:45,970
how much exactly at individual time

00:17:42,790 --> 00:17:49,030
period the data is changing to compare

00:17:45,970 --> 00:17:50,080
them better in some cases you may want

00:17:49,030 --> 00:17:53,679
to use

00:17:50,080 --> 00:17:55,840
percentile data collection say if you're

00:17:53,679 --> 00:17:59,260
comparing latencies you really don't

00:17:55,840 --> 00:18:02,919
care some changes your SLA is 300 your

00:17:59,260 --> 00:18:07,019
system is at 100 milliseconds now if you

00:18:02,919 --> 00:18:10,269
could say my 90 percentile data if it is

00:18:07,019 --> 00:18:14,049
different by more than 20% then I want

00:18:10,269 --> 00:18:15,880
to be failing it even with the current

00:18:14,049 --> 00:18:18,039
default implementation you take the 90

00:18:15,880 --> 00:18:20,559
percentile data and compare that may

00:18:18,039 --> 00:18:23,830
give you a better visibility into your

00:18:20,559 --> 00:18:26,769
system performance and how the

00:18:23,830 --> 00:18:29,980
developers use these metrics is slightly

00:18:26,769 --> 00:18:32,590
different and how the operations people

00:18:29,980 --> 00:18:35,380
like to see these metrics what we have

00:18:32,590 --> 00:18:37,960
seen so for this cannery for the it

00:18:35,380 --> 00:18:40,539
works best with the operations kind of

00:18:37,960 --> 00:18:43,149
metrics rather than the developers where

00:18:40,539 --> 00:18:46,630
you take 400 metrics or thousand metrics

00:18:43,149 --> 00:18:48,429
and try to see all of them at Netflix

00:18:46,630 --> 00:18:51,580
they have huge amount of traffic for

00:18:48,429 --> 00:18:53,950
them 1% of the traffic is like more than

00:18:51,580 --> 00:18:57,039
anybody can others others can handle so

00:18:53,950 --> 00:18:59,799
for smaller people the running this

00:18:57,039 --> 00:19:03,820
canary analysis with that small amount

00:18:59,799 --> 00:19:05,889
of data may also not give rightly so so

00:19:03,820 --> 00:19:07,630
you have to make sure the traffic that

00:19:05,889 --> 00:19:09,340
you are seeing is representative of your

00:19:07,630 --> 00:19:12,279
cannery you have to compute some

00:19:09,340 --> 00:19:14,830
confidence scores based on them to make

00:19:12,279 --> 00:19:17,409
sure your cannery is actually giving you

00:19:14,830 --> 00:19:20,080
the result that you expected for the

00:19:17,409 --> 00:19:24,149
time period right and the other thing we

00:19:20,080 --> 00:19:27,840
have seen is for most of the services

00:19:24,149 --> 00:19:30,880
the matrix collection is not very good

00:19:27,840 --> 00:19:32,169
if you have the gateways in front which

00:19:30,880 --> 00:19:34,450
are collecting all the latency is

00:19:32,169 --> 00:19:37,000
throughputs for example it's tier does

00:19:34,450 --> 00:19:39,700
Netflix has their own gateway API which

00:19:37,000 --> 00:19:42,659
provides all the data it gives much

00:19:39,700 --> 00:19:44,799
better it's also so you should consider

00:19:42,659 --> 00:19:46,889
having some kind of application

00:19:44,799 --> 00:19:50,289
performance monitoring metrics are

00:19:46,889 --> 00:19:53,919
gateways way which can give you that

00:19:50,289 --> 00:19:57,309
code inside for the KPIs for all the

00:19:53,919 --> 00:19:59,620
interfaces having combined data for all

00:19:57,309 --> 00:20:02,020
interfaces together is one thing but

00:19:59,620 --> 00:20:03,789
knowing what how individual interface is

00:20:02,020 --> 00:20:06,159
working gives it better

00:20:03,789 --> 00:20:14,979
agnostic information ability to fix them

00:20:06,159 --> 00:20:18,039
quickly thank ya in conclusion the

00:20:14,979 --> 00:20:20,229
Cantor is awesome most people who use it

00:20:18,039 --> 00:20:22,299
really love it but there are some

00:20:20,229 --> 00:20:24,399
improvements that you can do primarily I

00:20:22,299 --> 00:20:29,139
think there is some context information

00:20:24,399 --> 00:20:31,899
that can be passed that can extend the

00:20:29,139 --> 00:20:36,029
computation our analysis much better and

00:20:31,899 --> 00:20:36,029

YouTube URL: https://www.youtube.com/watch?v=66RJlBy84ug


