Title: Gopinath Rebala   Naran Patel - Lessons from Deploying to OpenShift at Cisco
Publication date: 2018-12-13
Playlist: Spinnaker Summit 2018
Description: 
	
Captions: 
	00:00:01,270 --> 00:00:05,380
[Music]

00:00:09,820 --> 00:00:13,259
[Music]

00:00:16,190 --> 00:00:22,529
and my name is Narayan Patel I'm an

00:00:19,830 --> 00:00:24,330
architect at Cisco and I'm going to be

00:00:22,529 --> 00:00:29,490
doing doing this presentation with Gopi

00:00:24,330 --> 00:00:30,960
Rapala who's a CTO of oopps MX so that's

00:00:29,490 --> 00:00:34,110
us too so I'm going to skip over that

00:00:30,960 --> 00:00:35,489
and this is what gender is gonna be so

00:00:34,110 --> 00:00:37,770
I'm gonna talk about Cisco environment

00:00:35,489 --> 00:00:40,770
some of the challenges and anti patterns

00:00:37,770 --> 00:00:44,820
that we've faced in our original CD 1.0

00:00:40,770 --> 00:00:49,140
and some of the goals of what we want

00:00:44,820 --> 00:00:51,059
for CD 2.0 what made us choose spinnaker

00:00:49,140 --> 00:00:54,329
some of the journey and the challenges

00:00:51,059 --> 00:00:56,460
we've experienced so far some of the

00:00:54,329 --> 00:00:57,899
lessons learned some of the results that

00:00:56,460 --> 00:01:00,780
we've achieved so far so just to do a

00:00:57,899 --> 00:01:02,910
level set we are about to go GA we

00:01:00,780 --> 00:01:04,260
haven't gone GA completely but we are

00:01:02,910 --> 00:01:08,250
leading up to that and this is like

00:01:04,260 --> 00:01:10,290
learnings from nine months or so of work

00:01:08,250 --> 00:01:12,659
on spinnaker leading up to going to GA

00:01:10,290 --> 00:01:14,520
and so this is what we've learned so far

00:01:12,659 --> 00:01:17,810
but there's a lot more results and

00:01:14,520 --> 00:01:20,460
lessons to be learned after we go GA and

00:01:17,810 --> 00:01:23,659
some of the next steps for us we'll

00:01:20,460 --> 00:01:23,659
start to talk about some of that

00:01:25,470 --> 00:01:35,290
so this is our CD 1.0 pipeline and we

00:01:31,120 --> 00:01:38,170
have a lot of mutable tools in that

00:01:35,290 --> 00:01:41,620
pipeline there and that worked really

00:01:38,170 --> 00:01:43,030
great for us in CD 1.0 when

00:01:41,620 --> 00:01:44,740
infrastructure was managed by

00:01:43,030 --> 00:01:48,670
configuration management and you were

00:01:44,740 --> 00:01:52,140
throwing binaries and artifacts into VMs

00:01:48,670 --> 00:01:56,500
that was great but with the arrival of

00:01:52,140 --> 00:01:58,390
kubernetes and containers some of this

00:01:56,500 --> 00:02:00,160
posed some challenges of how to operate

00:01:58,390 --> 00:02:03,100
and so this pipeline which served us

00:02:00,160 --> 00:02:05,470
really well for a long time and provided

00:02:03,100 --> 00:02:07,960
this tremendous value started to have

00:02:05,470 --> 00:02:09,820
some issues right a couple of things

00:02:07,960 --> 00:02:12,040
I've described down below in terms of

00:02:09,820 --> 00:02:13,810
prescriptive pipelines and high ceremony

00:02:12,040 --> 00:02:16,720
there's just some of the conditions I've

00:02:13,810 --> 00:02:19,150
sort of summarized in this little blob

00:02:16,720 --> 00:02:20,980
on top is well you were very

00:02:19,150 --> 00:02:22,480
prescriptive in our pipeline patterns we

00:02:20,980 --> 00:02:24,430
sort of yes we talked to a lot of

00:02:22,480 --> 00:02:26,620
developers and yes we built some

00:02:24,430 --> 00:02:29,650
pipeline patterns in or created those

00:02:26,620 --> 00:02:32,530
templates around them but self-service

00:02:29,650 --> 00:02:34,360
was challenging and modifying templates

00:02:32,530 --> 00:02:36,640
was difficult and so you needed a lot of

00:02:34,360 --> 00:02:41,050
understanding and knowledge on how to

00:02:36,640 --> 00:02:42,370
change those processes to really make it

00:02:41,050 --> 00:02:45,610
useful to you or adapt them to your

00:02:42,370 --> 00:02:47,560
processes and so that was a bit of a

00:02:45,610 --> 00:02:49,330
problem for us so we couldn't scale to

00:02:47,560 --> 00:02:53,500
support that much self service and so

00:02:49,330 --> 00:02:56,590
much programmability so we had low or

00:02:53,500 --> 00:02:59,770
poor self service and the

00:02:56,590 --> 00:03:01,480
programmability of the trying to think

00:02:59,770 --> 00:03:03,940
about things like pipeline this code

00:03:01,480 --> 00:03:05,770
wasn't really the technique technically

00:03:03,940 --> 00:03:07,980
and so we couldn't hand that over to

00:03:05,770 --> 00:03:10,000
development teams and it made for

00:03:07,980 --> 00:03:11,709
friction so that's some of the

00:03:10,000 --> 00:03:15,220
challenges that I talked about there in

00:03:11,709 --> 00:03:16,450
terms of non-intuitive ui/ux friction

00:03:15,220 --> 00:03:19,870
and there's a whole love-hate

00:03:16,450 --> 00:03:21,940
relationship some people liked it and a

00:03:19,870 --> 00:03:23,680
lot of people actually didn't so we were

00:03:21,940 --> 00:03:26,260
trying to solve that problem with what

00:03:23,680 --> 00:03:27,700
we're trying to do in the future look

00:03:26,260 --> 00:03:29,530
well on mutable infrastructure that's

00:03:27,700 --> 00:03:32,470
great look but doesn't work so well on

00:03:29,530 --> 00:03:34,810
immutable and we did a hacky hacky

00:03:32,470 --> 00:03:35,590
solution to try to introduce Kuban et's

00:03:34,810 --> 00:03:38,230
and

00:03:35,590 --> 00:03:39,940
openshift into the environment but it

00:03:38,230 --> 00:03:42,310
didn't work very well and I knew that

00:03:39,940 --> 00:03:44,950
that hacky solution was gonna not gonna

00:03:42,310 --> 00:03:46,450
last so it gave us some time some

00:03:44,950 --> 00:03:49,300
breathing room to think about what does

00:03:46,450 --> 00:03:52,000
the future look like what we did want

00:03:49,300 --> 00:03:55,810
was you know API first but even though

00:03:52,000 --> 00:03:57,459
we had some API first it was challenging

00:03:55,810 --> 00:03:59,470
in terms of resource managing and

00:03:57,459 --> 00:04:02,470
provisioning and things like that just

00:03:59,470 --> 00:04:06,030
managing an ancient infrastructure which

00:04:02,470 --> 00:04:08,950
is what urbancode is built on was

00:04:06,030 --> 00:04:11,350
difficult or difficult for support

00:04:08,950 --> 00:04:13,120
operations to maintain so that wasn't

00:04:11,350 --> 00:04:15,570
really great and so I think we wanted to

00:04:13,120 --> 00:04:17,769
shift and pivot towards agent lessness

00:04:15,570 --> 00:04:20,859
and some of that is what we're looking

00:04:17,769 --> 00:04:23,260
at in the future as well the other

00:04:20,859 --> 00:04:25,390
challenges were as people are shifting

00:04:23,260 --> 00:04:28,060
from and pivoting from continuous

00:04:25,390 --> 00:04:30,130
delivery to continuous deployment how

00:04:28,060 --> 00:04:31,960
can we reduce the amount of ceremony and

00:04:30,130 --> 00:04:35,320
increase the amount of velocity of

00:04:31,960 --> 00:04:36,850
change and do that in such a way is that

00:04:35,320 --> 00:04:37,720
we can scale that out so those some of

00:04:36,850 --> 00:04:42,850
the other things that we were thinking

00:04:37,720 --> 00:04:44,320
about it's why spinnaker well for us I

00:04:42,850 --> 00:04:45,520
think everyone recognizes that multi

00:04:44,320 --> 00:04:47,800
clouds a big deal it's not just a

00:04:45,520 --> 00:04:50,229
buzzword people are actually doing dev

00:04:47,800 --> 00:04:52,000
tests in cloud but they're also thinking

00:04:50,229 --> 00:04:55,479
about hybrid hybridization of their

00:04:52,000 --> 00:04:57,900
workloads and if that's not right now

00:04:55,479 --> 00:05:01,120
that's going to be there very soon

00:04:57,900 --> 00:05:03,039
deployment strategies I got told by

00:05:01,120 --> 00:05:05,860
several users that can you do blue green

00:05:03,039 --> 00:05:07,510
and right now for us that's a cobbled

00:05:05,860 --> 00:05:09,729
together script to do that it wasn't in

00:05:07,510 --> 00:05:11,050
an imperative first-class operation in a

00:05:09,729 --> 00:05:12,910
deployment tool so that was kind of

00:05:11,050 --> 00:05:15,940
important because people were asking for

00:05:12,910 --> 00:05:18,280
that zero downtime for business is

00:05:15,940 --> 00:05:19,390
important and so a lot of deployment

00:05:18,280 --> 00:05:21,870
strategies coming out of the box of

00:05:19,390 --> 00:05:24,010
spinnaker was in interesting for us and

00:05:21,870 --> 00:05:29,440
helped us achieve some of those goals

00:05:24,010 --> 00:05:30,729
right so if an application is

00:05:29,440 --> 00:05:32,710
distributed and let's deploy anywhere

00:05:30,729 --> 00:05:35,710
that's table stakes again and leads back

00:05:32,710 --> 00:05:36,970
to the multi cloud ability and then some

00:05:35,710 --> 00:05:40,510
things that were really interesting or

00:05:36,970 --> 00:05:43,060
future facing were these runtime

00:05:40,510 --> 00:05:45,220
analytics and then actions or actionable

00:05:43,060 --> 00:05:46,419
behaviors off some of those runtime

00:05:45,220 --> 00:05:48,580
analytics so that's kind of an

00:05:46,419 --> 00:05:49,480
interesting thing not just fire and

00:05:48,580 --> 00:05:52,570
forget

00:05:49,480 --> 00:05:55,030
but fire and observe and make corrective

00:05:52,570 --> 00:05:59,350
actions there was some of the design

00:05:55,030 --> 00:06:03,880
patents we were seeking and then the

00:05:59,350 --> 00:06:05,460
whole developer experience on what we

00:06:03,880 --> 00:06:07,900
built on top of urban code was just

00:06:05,460 --> 00:06:09,910
wasn't gonna fly with a lot of the

00:06:07,900 --> 00:06:12,220
developers and we talked to some leading

00:06:09,910 --> 00:06:13,750
developing teams and they just found

00:06:12,220 --> 00:06:15,730
that the experience they were having

00:06:13,750 --> 00:06:20,080
wasn't the type of experience that they

00:06:15,730 --> 00:06:22,300
wanted right and pipeline is curved

00:06:20,080 --> 00:06:25,330
declarative everything that's kind of

00:06:22,300 --> 00:06:28,660
the not only is it infrastructure but

00:06:25,330 --> 00:06:30,790
it's also pipelines it's also how you

00:06:28,660 --> 00:06:31,990
deal with configuration management so

00:06:30,790 --> 00:06:33,910
that is kind of the imperative

00:06:31,990 --> 00:06:35,170
everything needs to be programmable and

00:06:33,910 --> 00:06:40,860
every need everything needs to be

00:06:35,170 --> 00:06:43,630
exposed as such and these are some

00:06:40,860 --> 00:06:47,230
non-functional requirements I'm I'm not

00:06:43,630 --> 00:06:51,640
really going to talk about these a lot

00:06:47,230 --> 00:06:53,860
I think branching first was an important

00:06:51,640 --> 00:06:55,120
aspect to deliver different types of

00:06:53,860 --> 00:06:56,350
artifacts and different pipelines and

00:06:55,120 --> 00:06:59,010
this this is another pattern of

00:06:56,350 --> 00:07:01,240
spinnaker that makes that really easy

00:06:59,010 --> 00:07:02,890
dealing with state and stateless is

00:07:01,240 --> 00:07:07,260
another thing that's kind of easier with

00:07:02,890 --> 00:07:11,020
spinnaker because it can treat v2 method

00:07:07,260 --> 00:07:14,260
let's say baked binaries or binary

00:07:11,020 --> 00:07:16,120
artifacts alongside v2 manifests

00:07:14,260 --> 00:07:17,890
kubernetes workloads is both first-class

00:07:16,120 --> 00:07:19,660
operations so if you have stateful

00:07:17,890 --> 00:07:22,360
workloads as well as stateless workloads

00:07:19,660 --> 00:07:24,250
it can deal with both of those as a

00:07:22,360 --> 00:07:26,230
collection of pipelines as part as

00:07:24,250 --> 00:07:27,730
associated with an application so that

00:07:26,230 --> 00:07:31,570
was kind of attractive that we could

00:07:27,730 --> 00:07:33,310
deal with State stateless has pipelines

00:07:31,570 --> 00:07:35,920
and a lot of abstraction there could be

00:07:33,310 --> 00:07:39,430
leveraged and then finally the

00:07:35,920 --> 00:07:43,120
extensibility of community of spinnaker

00:07:39,430 --> 00:07:45,070
was really amazingly advantageous so

00:07:43,120 --> 00:07:47,850
that we could vault on some of the chaos

00:07:45,070 --> 00:07:51,450
engineering reliability engineering

00:07:47,850 --> 00:07:55,450
leverage the new analytics they're

00:07:51,450 --> 00:07:58,660
pushing into all the events that are

00:07:55,450 --> 00:08:00,970
coming out of spinnaker and using that

00:07:58,660 --> 00:08:02,870
information to either do automated

00:08:00,970 --> 00:08:04,910
canary analysis or other

00:08:02,870 --> 00:08:09,440
the ball analytics that was kind of very

00:08:04,910 --> 00:08:12,320
interesting for us as well this is what

00:08:09,440 --> 00:08:14,420
our 2.0 pipeline kind of shapes itself

00:08:12,320 --> 00:08:17,350
up to be a couple of things have changed

00:08:14,420 --> 00:08:21,770
there you'll see that there is a

00:08:17,350 --> 00:08:23,690
essentially a repo there quai which is

00:08:21,770 --> 00:08:26,620
essentially an image Reaper for

00:08:23,690 --> 00:08:30,080
kubernetes images and we're using that

00:08:26,620 --> 00:08:31,640
from core whereas as a repository

00:08:30,080 --> 00:08:34,580
instead of artifactory now we could use

00:08:31,640 --> 00:08:36,260
audio factory but quaking with Claire

00:08:34,580 --> 00:08:37,850
and a few of the features built in and

00:08:36,260 --> 00:08:39,320
it's allows for automated security

00:08:37,850 --> 00:08:42,380
scanning of images and so that was an

00:08:39,320 --> 00:08:44,090
attraction we may change our minds and

00:08:42,380 --> 00:08:46,820
switch over to having parallel pipelines

00:08:44,090 --> 00:08:49,760
but that's just something as apparently

00:08:46,820 --> 00:08:52,760
as some choices that we have here now we

00:08:49,760 --> 00:08:56,000
displaced yeah the code you deploy with

00:08:52,760 --> 00:08:57,470
spinnaker and then we if you notice the

00:08:56,000 --> 00:08:59,360
release is not there anymore so that's

00:08:57,470 --> 00:09:01,550
in kind of interesting saying when I

00:08:59,360 --> 00:09:04,660
talk to our release management

00:09:01,550 --> 00:09:06,800
organization we are trying to leverage

00:09:04,660 --> 00:09:09,080
spinnaker now for releasing which is

00:09:06,800 --> 00:09:10,640
curiosity because it's more of a

00:09:09,080 --> 00:09:13,340
continuous deployment continuous

00:09:10,640 --> 00:09:15,170
delivery tool so what about releasing so

00:09:13,340 --> 00:09:18,500
that we still find a fashion what that

00:09:15,170 --> 00:09:19,790
means and how to simplify releasing and

00:09:18,500 --> 00:09:21,620
if you look at some DevOps patterns that

00:09:19,790 --> 00:09:23,900
they took about you know future Flags

00:09:21,620 --> 00:09:25,280
and you talk about how did you dark

00:09:23,900 --> 00:09:28,430
releasing there's a lot of other

00:09:25,280 --> 00:09:31,220
techniques that you can use to maybe

00:09:28,430 --> 00:09:32,870
make release really simple and a trivial

00:09:31,220 --> 00:09:35,450
act activity that you don't need any

00:09:32,870 --> 00:09:36,980
heavy weight release tooling so that's

00:09:35,450 --> 00:09:38,900
kind of what we're exploring there and

00:09:36,980 --> 00:09:40,040
then finally the verification thing is

00:09:38,900 --> 00:09:42,260
something really future facing

00:09:40,040 --> 00:09:44,960
exploratory for us to look at cancer and

00:09:42,260 --> 00:09:48,200
tap into that maybe look at chaos

00:09:44,960 --> 00:09:50,030
toolkit as a mechanism of doing chaos

00:09:48,200 --> 00:09:51,890
engineering and and gremlin and then

00:09:50,030 --> 00:09:54,500
play off those two to see if they can

00:09:51,890 --> 00:09:58,910
help on any of that that we have down

00:09:54,500 --> 00:10:00,920
further down in roadmap the top bar over

00:09:58,910 --> 00:10:06,590
there is CSTR which is essentially

00:10:00,920 --> 00:10:09,140
continuous software deployment is really

00:10:06,590 --> 00:10:10,730
about continuous security right so

00:10:09,140 --> 00:10:14,780
baking in security all the way through

00:10:10,730 --> 00:10:16,400
the pipeline and not only looking at

00:10:14,780 --> 00:10:17,270
like threat analysis right at the

00:10:16,400 --> 00:10:20,030
beginning when you

00:10:17,270 --> 00:10:23,690
helping your product but also scanning

00:10:20,030 --> 00:10:28,900
your source code looking and firing off

00:10:23,690 --> 00:10:31,820
different types of scans for source and

00:10:28,900 --> 00:10:33,790
libraries and then looking at your

00:10:31,820 --> 00:10:35,800
repository for any runtime

00:10:33,790 --> 00:10:40,040
vulnerabilities and then finally

00:10:35,800 --> 00:10:42,350
anything that pops up that actual

00:10:40,040 --> 00:10:46,130
scanning of the runtime states of

00:10:42,350 --> 00:10:48,380
containers or images actually deployed

00:10:46,130 --> 00:10:50,150
in say of a virtual virtual machine and

00:10:48,380 --> 00:10:52,220
looking for any vulnerabilities there so

00:10:50,150 --> 00:10:58,220
that's like a full spectrum continuous

00:10:52,220 --> 00:11:00,830
security via on top so what kicked this

00:10:58,220 --> 00:11:03,770
off well the the whole transformation

00:11:00,830 --> 00:11:05,480
between 1 mm and 200 was we took a

00:11:03,770 --> 00:11:07,520
strong look at CN CF and the whole

00:11:05,480 --> 00:11:09,410
quadrant on CI CD and we started to dig

00:11:07,520 --> 00:11:11,660
into all these different tools out there

00:11:09,410 --> 00:11:14,690
a couple of the more recent one Brigade

00:11:11,660 --> 00:11:16,700
and Argonaut there but I've paid some

00:11:14,690 --> 00:11:17,840
attention to more recently but we

00:11:16,700 --> 00:11:21,280
continue to look at that there's

00:11:17,840 --> 00:11:23,540
different patterns in there like git ops

00:11:21,280 --> 00:11:25,430
for gitlab is really something that's

00:11:23,540 --> 00:11:27,350
really grown up more recently and is

00:11:25,430 --> 00:11:29,300
still very attractive for us and we may

00:11:27,350 --> 00:11:31,790
still look into that for certain types

00:11:29,300 --> 00:11:34,040
of developer experience but out of the

00:11:31,790 --> 00:11:37,040
rest of them the only the strongest

00:11:34,040 --> 00:11:38,720
candidate for us seem like spinnaker

00:11:37,040 --> 00:11:41,840
compared to all the others the others

00:11:38,720 --> 00:11:45,380
were either had one or two cloud

00:11:41,840 --> 00:11:47,330
providers support not the ten or so that

00:11:45,380 --> 00:11:50,440
spinnaker supports but they also were

00:11:47,330 --> 00:11:54,820
not quite advanced in other features so

00:11:50,440 --> 00:11:54,820
right now we feel that it's the most

00:11:55,240 --> 00:11:59,960
candid highest functional candidate that

00:11:58,010 --> 00:12:02,390
we have out of CD tools out there from

00:11:59,960 --> 00:12:03,860
the open source lens not from the

00:12:02,390 --> 00:12:05,980
commercial lens there are some

00:12:03,860 --> 00:12:10,070
commercial tools that are pretty good

00:12:05,980 --> 00:12:14,900
code fresh comes to mind but int and go

00:12:10,070 --> 00:12:16,490
from thought works but spinnaker format

00:12:14,900 --> 00:12:19,070
open source sense was one of the most

00:12:16,490 --> 00:12:20,630
powerful and we wanted to try and to

00:12:19,070 --> 00:12:22,520
reduce some of the cost of operations of

00:12:20,630 --> 00:12:24,080
CD because we don't want a penalty of if

00:12:22,520 --> 00:12:27,200
you follow best practice and do more

00:12:24,080 --> 00:12:28,820
deployment you should be penalized so we

00:12:27,200 --> 00:12:30,590
wanted to it was an attraction to say

00:12:28,820 --> 00:12:32,390
that if you do more deployments

00:12:30,590 --> 00:12:34,010
it doesn't cost you any more to do that

00:12:32,390 --> 00:12:36,410
so that was one of the other

00:12:34,010 --> 00:12:37,760
distractions is that we can scale up and

00:12:36,410 --> 00:12:40,520
scale out and you can do more

00:12:37,760 --> 00:12:41,750
deployments maybe 10,000 a day and it

00:12:40,520 --> 00:12:45,320
doesn't cost you any more right

00:12:41,750 --> 00:12:47,480
other than the bandwidth I suppose and

00:12:45,320 --> 00:12:50,810
so we did a POC I did a POC last year

00:12:47,480 --> 00:12:52,670
around October time frame and the exact

00:12:50,810 --> 00:12:55,550
loved it so they told me when can you

00:12:52,670 --> 00:12:58,580
have it ready so now I had the challenge

00:12:55,550 --> 00:13:01,130
of like okay they liked it how can I

00:12:58,580 --> 00:13:05,630
make this real right so that was the

00:13:01,130 --> 00:13:06,830
beginning of the journey and these were

00:13:05,630 --> 00:13:09,680
some of the considerations on that

00:13:06,830 --> 00:13:12,110
journey was okay so now I have a mandate

00:13:09,680 --> 00:13:13,670
to go ahead and make this real but I

00:13:12,110 --> 00:13:14,960
know I can't do it by myself there's a

00:13:13,670 --> 00:13:18,260
lot of knowledge that needs to be

00:13:14,960 --> 00:13:21,470
learned here okay so now who out there

00:13:18,260 --> 00:13:24,170
has knowledge about this stuff and so

00:13:21,470 --> 00:13:25,400
one of the group's was Optimax and the

00:13:24,170 --> 00:13:28,820
other group was armory so I went down

00:13:25,400 --> 00:13:30,470
reached out read about spinnaker and

00:13:28,820 --> 00:13:32,740
notice there's his little paper in there

00:13:30,470 --> 00:13:35,210
called DST spec which was a manifest v2

00:13:32,740 --> 00:13:37,430
spec before he actually materialized and

00:13:35,210 --> 00:13:39,350
actually was anything and so I started

00:13:37,430 --> 00:13:41,600
to subscribe to that was very interested

00:13:39,350 --> 00:13:43,400
in that but at that time army wasn't

00:13:41,600 --> 00:13:44,630
really supporting that as part of their

00:13:43,400 --> 00:13:46,340
release and it was still being worked on

00:13:44,630 --> 00:13:48,080
but that was what I wanted to actually

00:13:46,340 --> 00:13:50,510
launch with a v2 provider for

00:13:48,080 --> 00:13:52,400
communities manifest driven deployments

00:13:50,510 --> 00:13:53,690
because I felt that that would provide a

00:13:52,400 --> 00:13:58,310
first-class

00:13:53,690 --> 00:14:01,160
communities deployment and tightly bind

00:13:58,310 --> 00:14:03,890
that to the Jenkins experience and allow

00:14:01,160 --> 00:14:05,300
both programmers program ability from

00:14:03,890 --> 00:14:07,820
Jenkins as well as the spinnaker

00:14:05,300 --> 00:14:11,360
perspective and that was kind of where

00:14:07,820 --> 00:14:13,370
we wanted to try to launch with Arbor II

00:14:11,360 --> 00:14:14,990
wasn't providing that but officer Mike

00:14:13,370 --> 00:14:19,580
said we'll provide you support for the

00:14:14,990 --> 00:14:21,530
latest stable open-source version and so

00:14:19,580 --> 00:14:23,870
I said okay that sounds good

00:14:21,530 --> 00:14:26,090
why don't you help us build that and

00:14:23,870 --> 00:14:28,700
make that and so we've been working with

00:14:26,090 --> 00:14:31,490
the officer most guys for a little while

00:14:28,700 --> 00:14:32,840
it's a little plug for them and they've

00:14:31,490 --> 00:14:34,910
been helping us put the pipeline's

00:14:32,840 --> 00:14:37,220
together and and from a product

00:14:34,910 --> 00:14:39,050
standpoint make spinnaker work with open

00:14:37,220 --> 00:14:41,330
chef now I didn't just work and it

00:14:39,050 --> 00:14:42,350
needed some configuration to make it

00:14:41,330 --> 00:14:44,989
work

00:14:42,350 --> 00:14:49,059
some of the

00:14:44,989 --> 00:14:51,889
challenges there where the OpenShift has

00:14:49,059 --> 00:14:53,269
some configuration on top and some

00:14:51,889 --> 00:14:55,729
modules on top in terms of security

00:14:53,269 --> 00:14:58,429
management and stuff and when spinnaker

00:14:55,729 --> 00:15:00,139
actually talks to it and you tightened

00:14:58,429 --> 00:15:01,849
up all of the permissions on the

00:15:00,139 --> 00:15:04,669
security model inside of OpenShift

00:15:01,849 --> 00:15:06,139
it buffs so you have to figure out okay

00:15:04,669 --> 00:15:07,459
so what is it complaining about what is

00:15:06,139 --> 00:15:09,199
the security permissions complaining

00:15:07,459 --> 00:15:11,779
about and so we wasn't it it was a

00:15:09,199 --> 00:15:13,669
non-trivial exercise to figure out how

00:15:11,779 --> 00:15:16,459
do I actually make spinnaker to work

00:15:13,669 --> 00:15:17,869
with OpenShift by figuring out what are

00:15:16,459 --> 00:15:20,599
the security permissions are allowed for

00:15:17,869 --> 00:15:23,389
project per namespace and how do I

00:15:20,599 --> 00:15:24,529
operate that at scale so that was some

00:15:23,389 --> 00:15:26,359
of the challenges there and we had to

00:15:24,529 --> 00:15:29,899
figure out what are the permission

00:15:26,359 --> 00:15:33,079
structures that we can emit we can bind

00:15:29,899 --> 00:15:35,899
to and to allow spinnaker

00:15:33,079 --> 00:15:38,689
to Holly odd and its account services to

00:15:35,899 --> 00:15:39,979
operate and then from there we went and

00:15:38,689 --> 00:15:45,739
started to actually dig into the

00:15:39,979 --> 00:15:47,539
application side some of the deployment

00:15:45,739 --> 00:15:51,259
infrastructure that we're going with is

00:15:47,539 --> 00:15:53,659
we're deploying on appreciate 3.9 we

00:15:51,259 --> 00:15:55,729
built spinnaker in such a way as that

00:15:53,659 --> 00:15:58,279
we're got a primary instance on a che

00:15:55,729 --> 00:15:59,959
instance spinnaker is not any clustering

00:15:58,279 --> 00:16:02,689
has got any fancy so we've just done

00:15:59,959 --> 00:16:04,669
some active passive setup and that comes

00:16:02,689 --> 00:16:06,019
with its own caveat and maybe guppy can

00:16:04,669 --> 00:16:07,909
go into a little bit of that it is

00:16:06,019 --> 00:16:09,649
non-trivial it is challenging because

00:16:07,909 --> 00:16:11,599
partial state is stored inside of Redis

00:16:09,649 --> 00:16:14,989
and the rest of it is in many Oh which

00:16:11,599 --> 00:16:16,369
is an s3 store and there are some

00:16:14,989 --> 00:16:18,109
challenges in there because if things

00:16:16,369 --> 00:16:20,839
break then you lose runtime state in

00:16:18,109 --> 00:16:23,929
Redis and it's not as simple as just

00:16:20,839 --> 00:16:25,459
fetching you the data back from Mineo

00:16:23,929 --> 00:16:28,279
and you're there and ready to run you

00:16:25,459 --> 00:16:29,239
actually lose runtime State so again

00:16:28,279 --> 00:16:30,889
that's something that we're still

00:16:29,239 --> 00:16:32,689
continuing to explore and to make sure

00:16:30,889 --> 00:16:36,739
that we don't lose anything and we can

00:16:32,689 --> 00:16:38,329
come up clean in cleanly we did some

00:16:36,739 --> 00:16:39,619
fail back and failover testing and that

00:16:38,329 --> 00:16:41,229
sort of worked quite well under

00:16:39,619 --> 00:16:44,629
controlled conditions but like I said

00:16:41,229 --> 00:16:46,699
you will lose some estate information in

00:16:44,629 --> 00:16:47,869
in Redis which you do need to kind of

00:16:46,699 --> 00:16:51,470
think a little bit more strongly about

00:16:47,869 --> 00:16:54,049
how to how to figure that out and then

00:16:51,470 --> 00:16:56,760
we were looking at when we install

00:16:54,049 --> 00:16:59,170
spinnaker we realized that

00:16:56,760 --> 00:17:01,440
this is a non-trivial exercise because

00:16:59,170 --> 00:17:04,839
the documentation is not that great and

00:17:01,440 --> 00:17:06,940
we found that we needed to script some

00:17:04,839 --> 00:17:08,950
of it so we ended up scripting how to do

00:17:06,940 --> 00:17:10,780
Hallie odd ended up scripting how to do

00:17:08,950 --> 00:17:12,790
installation spinnaker and all its micro

00:17:10,780 --> 00:17:15,910
services and then all the secrets and

00:17:12,790 --> 00:17:17,740
the config maps and and we ended up kind

00:17:15,910 --> 00:17:19,720
of automating a lot of it and so we

00:17:17,740 --> 00:17:21,310
realized that if we just wrap that whole

00:17:19,720 --> 00:17:24,610
thing and all those scripts together and

00:17:21,310 --> 00:17:26,560
just put some command line tool around

00:17:24,610 --> 00:17:28,329
it we can actually kind of install

00:17:26,560 --> 00:17:34,710
spinnaker or on-the-fly wherever we want

00:17:28,329 --> 00:17:34,710
and so we treat that as our ability to

00:17:35,220 --> 00:17:40,840
do spinnaker as a service and on-demand

00:17:38,170 --> 00:17:42,730
wherever we want it where we point to in

00:17:40,840 --> 00:17:45,790
terms of openshift or or or kubernetes

00:17:42,730 --> 00:17:47,170
cluster we can just run this script and

00:17:45,790 --> 00:17:49,900
it installs benek and it's working it's

00:17:47,170 --> 00:17:54,100
setup and it's kind of cool so that

00:17:49,900 --> 00:17:57,130
allows us to scale out instances when we

00:17:54,100 --> 00:17:59,020
want maybe it's not a big deal it's just

00:17:57,130 --> 00:18:01,720
a script we can even just get hey guys

00:17:59,020 --> 00:18:03,880
have fun and people could use that it's

00:18:01,720 --> 00:18:05,200
again it's not a big deal it's it's just

00:18:03,880 --> 00:18:08,020
cobble together best practice on

00:18:05,200 --> 00:18:10,990
spinnaker management and I'm sure that

00:18:08,020 --> 00:18:12,550
goki's wrote the script so copy if he

00:18:10,990 --> 00:18:13,600
feels comfortable and just throwing it

00:18:12,550 --> 00:18:15,640
out there I don't know if he wants to

00:18:13,600 --> 00:18:16,750
keep it like a an onus that stuff we

00:18:15,640 --> 00:18:19,570
wanted to keep for our professional

00:18:16,750 --> 00:18:20,770
services it's up to him but it wasn't it

00:18:19,570 --> 00:18:22,720
wasn't a huge deal it was a lot of

00:18:20,770 --> 00:18:25,080
learning that we put into it which is

00:18:22,720 --> 00:18:25,080
kind of nice

00:18:25,680 --> 00:18:29,910
copy you want to talk a little bit about

00:18:27,550 --> 00:18:29,910
this

00:18:34,010 --> 00:18:38,460
thanks Aaron it's a nohrin was talking

00:18:36,810 --> 00:18:40,230
about high availability deployment for

00:18:38,460 --> 00:18:43,860
the spinnaker and what the challenges

00:18:40,230 --> 00:18:45,300
are so as we progress through it in the

00:18:43,860 --> 00:18:47,040
enterprise we had to integrate with a

00:18:45,300 --> 00:18:50,250
bunch of the services that are already

00:18:47,040 --> 00:18:52,020
there in the Cisco so we went through

00:18:50,250 --> 00:18:53,250
all of that here there were some

00:18:52,020 --> 00:18:56,070
challenges there because of the

00:18:53,250 --> 00:18:59,160
documentation issues huge organization

00:18:56,070 --> 00:19:00,570
Jenkins runs thousand plus jobs the

00:18:59,160 --> 00:19:02,580
default configurations don't support

00:19:00,570 --> 00:19:05,190
those kind of things for example we went

00:19:02,580 --> 00:19:09,660
through all of that but the deployment

00:19:05,190 --> 00:19:12,810
itself is one huge cluster with service

00:19:09,660 --> 00:19:14,550
accounts for different departments that

00:19:12,810 --> 00:19:17,150
are pointing to that cluster deployment

00:19:14,550 --> 00:19:20,940
you know the spinnaker setup we have a

00:19:17,150 --> 00:19:23,640
active-passive spinnaker itself can run

00:19:20,940 --> 00:19:26,190
across of multiple availabilities or

00:19:23,640 --> 00:19:29,520
regions but the way we are deployed

00:19:26,190 --> 00:19:33,450
because of the databases readies and

00:19:29,520 --> 00:19:36,390
Mineo we set up the replications for the

00:19:33,450 --> 00:19:38,520
databases and active passive mode and

00:19:36,390 --> 00:19:41,610
similarly the spinnaker itself runs in

00:19:38,520 --> 00:19:44,760
active passive mode so we had the issues

00:19:41,610 --> 00:19:46,800
where the whole region went down and we

00:19:44,760 --> 00:19:48,720
had to bring up the secondary and then

00:19:46,800 --> 00:19:52,740
once the region comes back up we can

00:19:48,720 --> 00:19:54,720
pull it back in the way the switch also

00:19:52,740 --> 00:19:58,380
happens is there is a vanity URLs for

00:19:54,720 --> 00:20:02,010
the global that we can set to replicated

00:19:58,380 --> 00:20:04,380
cluster once the primary goes down and

00:20:02,010 --> 00:20:06,870
we can start using it but the challenges

00:20:04,380 --> 00:20:09,600
here are it's not a zero downtime

00:20:06,870 --> 00:20:12,540
because of the wave active passive setup

00:20:09,600 --> 00:20:14,910
today there are new things that are

00:20:12,540 --> 00:20:18,450
coming which is not there yet in the

00:20:14,910 --> 00:20:20,850
production where the radius itself can

00:20:18,450 --> 00:20:23,610
be in individual zones you can have

00:20:20,850 --> 00:20:25,470
Redis in active passive right a master

00:20:23,610 --> 00:20:27,660
slave configuration and then replicate

00:20:25,470 --> 00:20:30,870
it to the next but if the region itself

00:20:27,660 --> 00:20:33,780
goes down that does not help so the red

00:20:30,870 --> 00:20:35,330
is right now what is being done is break

00:20:33,780 --> 00:20:38,700
up the Redis into two different parts

00:20:35,330 --> 00:20:42,280
one goes through SQL Server which can be

00:20:38,700 --> 00:20:44,559
replicated without loss of data and then

00:20:42,280 --> 00:20:46,720
when you switch back you don't lose the

00:20:44,559 --> 00:20:48,429
state information of the pipeline so

00:20:46,720 --> 00:20:51,820
those things are not done yet right now

00:20:48,429 --> 00:20:53,620
it's a active passive mode in simple

00:20:51,820 --> 00:20:56,950
replication with Redis and menu and

00:20:53,620 --> 00:20:59,620
switch of the regions if the one of them

00:20:56,950 --> 00:21:01,809
fails yeah I think just to add to that

00:20:59,620 --> 00:21:04,030
that's active work in terms of state

00:21:01,809 --> 00:21:05,500
recovery in some of the micro services

00:21:04,030 --> 00:21:09,130
respecting that and backing it up and

00:21:05,500 --> 00:21:11,559
just into sequel and this is just little

00:21:09,130 --> 00:21:14,700
weaknesses that we found and the other

00:21:11,559 --> 00:21:17,890
weaknesses we found is cloud drivers

00:21:14,700 --> 00:21:19,690
resource hog it's a real dog for

00:21:17,890 --> 00:21:21,850
resources and the more accounts you

00:21:19,690 --> 00:21:24,580
write on it just really tags on to time

00:21:21,850 --> 00:21:26,110
in terms of coming up and so you have to

00:21:24,580 --> 00:21:27,610
do a counterbalance between the amount

00:21:26,110 --> 00:21:29,530
of accounts that you put into cloud

00:21:27,610 --> 00:21:32,380
driver and the resources that it

00:21:29,530 --> 00:21:34,750
consumes versus the number of spin

00:21:32,380 --> 00:21:37,299
occurrences and the clients you put into

00:21:34,750 --> 00:21:40,690
them and it's a fine balance between the

00:21:37,299 --> 00:21:43,960
two and that's I think somewhat and that

00:21:40,690 --> 00:21:45,909
needs some work and the other is not

00:21:43,960 --> 00:21:47,650
putting all your eggs in one basket

00:21:45,909 --> 00:21:49,809
I think distributing some of your

00:21:47,650 --> 00:21:52,419
clients and your lines of businesses and

00:21:49,809 --> 00:21:56,350
different spinnaker instances allows you

00:21:52,419 --> 00:21:58,270
not only to scale and support and reduce

00:21:56,350 --> 00:22:00,909
the risk to each of those operating

00:21:58,270 --> 00:22:02,740
lines of business but also allows you to

00:22:00,909 --> 00:22:04,840
manage some of the scalability concerns

00:22:02,740 --> 00:22:06,370
and performance concerns so you do have

00:22:04,840 --> 00:22:08,230
to kind of weigh that up and measure it

00:22:06,370 --> 00:22:13,720
up for yourselves we're doing some scale

00:22:08,230 --> 00:22:15,970
testing right now just throwing accounts

00:22:13,720 --> 00:22:18,280
into the service bringing it up and just

00:22:15,970 --> 00:22:20,080
monitoring how it behaves how long it

00:22:18,280 --> 00:22:22,390
takes to come up and doing some timing

00:22:20,080 --> 00:22:25,210
tests around that and also running

00:22:22,390 --> 00:22:26,650
pipeline jobs at scale programmatically

00:22:25,210 --> 00:22:28,120
to see how that behaves as well so

00:22:26,650 --> 00:22:31,270
there's different types of scale testing

00:22:28,120 --> 00:22:36,039
that we do I strongly urge that if you

00:22:31,270 --> 00:22:37,720
have an environment where you think that

00:22:36,039 --> 00:22:39,520
the one instance is going to scale or if

00:22:37,720 --> 00:22:42,419
you think as tenants is going to scale

00:22:39,520 --> 00:22:45,340
do the scale tests you'll realize that

00:22:42,419 --> 00:22:46,870
whether it's your Holly odd number of

00:22:45,340 --> 00:22:48,940
accounts or a number of those that are

00:22:46,870 --> 00:22:52,270
mapped to a number of spinnaker

00:22:48,940 --> 00:22:55,330
instances is if you have not done some

00:22:52,270 --> 00:22:57,610
measure of that and some sizing of that

00:22:55,330 --> 00:22:58,660
you might want to file and that's some

00:22:57,610 --> 00:23:00,250
of the things that we want to make sure

00:22:58,660 --> 00:23:03,100
we have a good handle on so as we

00:23:00,250 --> 00:23:06,640
operate in scale we know what the number

00:23:03,100 --> 00:23:08,980
of tendencies that we have in terms of

00:23:06,640 --> 00:23:11,230
namespaces and projects per instance and

00:23:08,980 --> 00:23:13,300
how that operates and also the number of

00:23:11,230 --> 00:23:14,410
accounts that we have pointed to

00:23:13,300 --> 00:23:16,330
different clusters and a number of

00:23:14,410 --> 00:23:17,950
instances of spinnaker itself so that

00:23:16,330 --> 00:23:19,090
that's kind of the balancing act you

00:23:17,950 --> 00:23:20,110
have to do but the scale testing

00:23:19,090 --> 00:23:23,320
hopefully will give us some good numbers

00:23:20,110 --> 00:23:24,460
to size that out I'm not talking about

00:23:23,320 --> 00:23:27,220
vertical I'm talking about horizontal

00:23:24,460 --> 00:23:29,110
scaling as well so the cloud driver

00:23:27,220 --> 00:23:32,350
itself you can help multiple instances

00:23:29,110 --> 00:23:34,900
running there are there is a huge amount

00:23:32,350 --> 00:23:37,330
of traffic between the cloud driver and

00:23:34,900 --> 00:23:39,580
Redis because of the caching and the

00:23:37,330 --> 00:23:42,280
frequency at which it does you have some

00:23:39,580 --> 00:23:44,170
parameters that you can tune with like

00:23:42,280 --> 00:23:45,640
having a number of paddle threads that

00:23:44,170 --> 00:23:48,700
are running in individual cloud driver

00:23:45,640 --> 00:23:50,110
instances multiple plow drivers no but

00:23:48,700 --> 00:23:51,940
those are the things that you need to

00:23:50,110 --> 00:23:56,350
watch out like nothing was saying you

00:23:51,940 --> 00:23:57,490
need to measure those and I'm just gonna

00:23:56,350 --> 00:23:59,980
go through this real quick and hand over

00:23:57,490 --> 00:24:02,080
again a couple of things that just to

00:23:59,980 --> 00:24:04,660
call out here we did the enterprise

00:24:02,080 --> 00:24:07,660
integrations you can see that pretty

00:24:04,660 --> 00:24:09,130
common staff installed and upgrades are

00:24:07,660 --> 00:24:11,290
scripted automation we did that because

00:24:09,130 --> 00:24:14,020
I like I said you know because the

00:24:11,290 --> 00:24:16,090
project changes so rapidly we needed to

00:24:14,020 --> 00:24:18,250
have a sandbox where you could do some

00:24:16,090 --> 00:24:20,890
sanity checking and then dev stage prod

00:24:18,250 --> 00:24:24,070
instances of spinnaker and then you know

00:24:20,890 --> 00:24:25,480
staging baked out with a che and that to

00:24:24,070 --> 00:24:28,210
be tested in the production and all of

00:24:25,480 --> 00:24:29,470
that that means that you need to have a

00:24:28,210 --> 00:24:30,610
significant amount of spinnaker

00:24:29,470 --> 00:24:33,130
environments to make sure your life

00:24:30,610 --> 00:24:34,960
cycle in spinnaker itself the project is

00:24:33,130 --> 00:24:37,660
evolving very very rapidly it's

00:24:34,960 --> 00:24:41,530
something like a couple of releases

00:24:37,660 --> 00:24:43,450
every two or three weeks so what we do

00:24:41,530 --> 00:24:45,730
is we throw it into sanity checking and

00:24:43,450 --> 00:24:47,230
run some tests against it just to see if

00:24:45,730 --> 00:24:49,420
all the stuff that we put into pipelines

00:24:47,230 --> 00:24:50,800
and stuff works before we start

00:24:49,420 --> 00:24:53,740
promoting it out and that's something

00:24:50,800 --> 00:24:54,940
that we've run afoul with with just

00:24:53,740 --> 00:24:58,630
getting a little too eager of getting

00:24:54,940 --> 00:25:00,700
the new version in I would suggest that

00:24:58,630 --> 00:25:02,200
you have some sort of life cycling of

00:25:00,700 --> 00:25:03,730
spinnaker itself and that you're

00:25:02,200 --> 00:25:06,130
validating and testing your pipelines

00:25:03,730 --> 00:25:08,320
that it's all working because it's

00:25:06,130 --> 00:25:09,659
somewhat brittle still some things that

00:25:08,320 --> 00:25:11,820
we're working in a previous

00:25:09,659 --> 00:25:12,779
don't work in the next release and you

00:25:11,820 --> 00:25:13,829
don't want to run afoul of that

00:25:12,779 --> 00:25:15,629
especially you've got a lot of clients

00:25:13,829 --> 00:25:17,399
on there you want to kind of make sure

00:25:15,629 --> 00:25:25,739
that the products working as it should

00:25:17,399 --> 00:25:27,899
right the other problem that security

00:25:25,739 --> 00:25:31,349
guys decided that OpenShift needs to be

00:25:27,899 --> 00:25:33,570
set up is they force revalidation the

00:25:31,349 --> 00:25:35,969
invalidation of all tokens that you use

00:25:33,570 --> 00:25:39,359
to access quai every 24 hours

00:25:35,969 --> 00:25:41,190
so that means spinnaker itself can't

00:25:39,359 --> 00:25:43,289
operate against quiet all of a sudden so

00:25:41,190 --> 00:25:45,839
that kind of causes us problems when

00:25:43,289 --> 00:25:47,729
we've got like a let's say a thousand

00:25:45,839 --> 00:25:49,649
tenants all of a sudden all thousand

00:25:47,729 --> 00:25:51,450
can't operate so we had to set up a

00:25:49,649 --> 00:25:54,959
regen token service we built ourselves

00:25:51,450 --> 00:25:56,579
just to inject the regen tokens into the

00:25:54,959 --> 00:25:58,289
pipeline so we can always continue to

00:25:56,579 --> 00:26:00,269
operate and so we know we need to have

00:25:58,289 --> 00:26:03,929
you know these these these things

00:26:00,269 --> 00:26:06,209
inserted but we built a way of work

00:26:03,929 --> 00:26:08,190
around around that security premise I

00:26:06,209 --> 00:26:11,940
don't think it's ideal but it's a way of

00:26:08,190 --> 00:26:15,349
us working around it and it avoids this

00:26:11,940 --> 00:26:18,450
sort of friction with the user community

00:26:15,349 --> 00:26:20,820
finally the whole halyard spinnaker

00:26:18,450 --> 00:26:23,639
wrapper facade api's is all stab at

00:26:20,820 --> 00:26:28,109
doing Enterprise one-click pipeline

00:26:23,639 --> 00:26:29,879
invocation and so I think arm we talked

00:26:28,109 --> 00:26:31,979
about you know one-click provisioning of

00:26:29,879 --> 00:26:33,690
pipelines that's kind of a stab at doing

00:26:31,979 --> 00:26:36,389
that we created a facade API across the

00:26:33,690 --> 00:26:40,320
spinnaker API api's and we exposed to

00:26:36,389 --> 00:26:43,099
our provisioning services and a CLI the

00:26:40,320 --> 00:26:45,509
ability to just craft your pipeline and

00:26:43,099 --> 00:26:47,039
the facade API take care of that work

00:26:45,509 --> 00:26:48,450
there's an event queue and there's some

00:26:47,039 --> 00:26:51,059
funky stuff that happens between it so

00:26:48,450 --> 00:26:52,409
it tries to make sure that it completes

00:26:51,059 --> 00:26:54,479
all of the provisioning services

00:26:52,409 --> 00:26:55,979
otherwise it fails and somebody acts

00:26:54,479 --> 00:26:58,139
upon it and we'll you know we'll think

00:26:55,979 --> 00:27:00,529
about how to do better paid behaviors

00:26:58,139 --> 00:27:00,529
around that

00:27:02,190 --> 00:27:09,240
yeah and we built compliance Sox process

00:27:07,440 --> 00:27:11,880
which is an as this process into the

00:27:09,240 --> 00:27:14,490
pipeline and we do have some Sox

00:27:11,880 --> 00:27:16,530
colleague in here or Havas and it's

00:27:14,490 --> 00:27:18,240
pretty much the same process that we do

00:27:16,530 --> 00:27:20,730
on our previous pipelines but we've

00:27:18,240 --> 00:27:23,430
baked it into the spinnaker pipeline and

00:27:20,730 --> 00:27:25,140
it requires some approvals and such and

00:27:23,430 --> 00:27:27,390
it captures some of that data and the

00:27:25,140 --> 00:27:29,130
event either going through echo will be

00:27:27,390 --> 00:27:32,070
sent over to some analytics that we have

00:27:29,130 --> 00:27:35,190
and we'll be using that to essentially

00:27:32,070 --> 00:27:36,990
provide audit auditable data but also

00:27:35,190 --> 00:27:38,280
the runtime data to say the upper-right

00:27:36,990 --> 00:27:40,850
approvals happened at the right time

00:27:38,280 --> 00:27:40,850
with the right people

00:27:40,890 --> 00:27:45,000
that's all I think I wanted to talk

00:27:42,840 --> 00:27:47,150
about that we'll talk about this one

00:27:45,000 --> 00:27:47,150
together

00:27:51,570 --> 00:27:59,380
so here so the expectation was that

00:27:56,610 --> 00:28:01,870
because we support kubernetes with the

00:27:59,380 --> 00:28:03,880
spinnaker you point spinnaker to the

00:28:01,870 --> 00:28:07,450
open shipped cluster which is built on

00:28:03,880 --> 00:28:09,760
kubernetes base should just work but we

00:28:07,450 --> 00:28:12,970
found some of the issues that make it

00:28:09,760 --> 00:28:14,920
difficult in the initial goal the

00:28:12,970 --> 00:28:18,250
biggest one was the security

00:28:14,920 --> 00:28:21,430
considerations in OpenShift

00:28:18,250 --> 00:28:24,070
it it expects anonymous user in each of

00:28:21,430 --> 00:28:25,540
the containers and so initially there's

00:28:24,070 --> 00:28:28,570
a few months ago when we were starting

00:28:25,540 --> 00:28:30,400
it off the spinnaker itself was using

00:28:28,570 --> 00:28:33,420
route for some of the containers and

00:28:30,400 --> 00:28:36,220
then that was changed to non route and

00:28:33,420 --> 00:28:38,670
even that is not sufficient because some

00:28:36,220 --> 00:28:42,190
of the users like the spinnaker user

00:28:38,670 --> 00:28:45,070
were expected because of the environment

00:28:42,190 --> 00:28:49,180
variables and how it uses it so we took

00:28:45,070 --> 00:28:51,030
that and and the second thing is because

00:28:49,180 --> 00:28:54,640
of the security constraints you cannot

00:28:51,030 --> 00:28:57,160
install something from say public domain

00:28:54,640 --> 00:28:58,720
it needs to be approved and it needs to

00:28:57,160 --> 00:29:02,920
go through some checks so that are there

00:28:58,720 --> 00:29:05,290
within the krei of Cisco so we built the

00:29:02,920 --> 00:29:08,320
wrappers around that will change the

00:29:05,290 --> 00:29:12,400
user to a non an anonymous user for the

00:29:08,320 --> 00:29:15,550
containers for this the releases and we

00:29:12,400 --> 00:29:17,470
deploy it through the Cisco way so those

00:29:15,550 --> 00:29:21,100
were the automation part that we have

00:29:17,470 --> 00:29:24,160
done for whenever there is a release you

00:29:21,100 --> 00:29:26,950
just run the script it will go do its

00:29:24,160 --> 00:29:28,780
magic generates the config file applies

00:29:26,950 --> 00:29:30,820
that to halyard you can done he'll

00:29:28,780 --> 00:29:34,240
deploy and that deploys the whole

00:29:30,820 --> 00:29:36,460
cluster for the new release and in

00:29:34,240 --> 00:29:39,120
single sign-on is another issue that

00:29:36,460 --> 00:29:42,540
came through for the open shift

00:29:39,120 --> 00:29:44,230
cisco has this ability of doing

00:29:42,540 --> 00:29:48,220
two-factor authentication

00:29:44,230 --> 00:29:50,350
that's SSL endpoint so but then if you

00:29:48,220 --> 00:29:52,570
do that this spinnaker itself cannot

00:29:50,350 --> 00:29:54,970
accept that so we had to make changes

00:29:52,570 --> 00:29:56,980
there to have the authentication

00:29:54,970 --> 00:29:58,660
directly done SSL termination but

00:29:56,980 --> 00:30:01,870
authentication done in spinnaker but we

00:29:58,660 --> 00:30:03,630
are going to implement the two-factor

00:30:01,870 --> 00:30:05,580
authentication with Sam OH

00:30:03,630 --> 00:30:07,770
spinnaker directly that part is coming

00:30:05,580 --> 00:30:10,260
right then there were a few other things

00:30:07,770 --> 00:30:11,730
like because openshift supports its own

00:30:10,260 --> 00:30:15,590
constructs like route and deployment

00:30:11,730 --> 00:30:17,910
config they were not working initially

00:30:15,590 --> 00:30:20,370
with the spinnaker releases we worked

00:30:17,910 --> 00:30:28,920
with the community now those are all

00:30:20,370 --> 00:30:30,810
supported in the scaling of the

00:30:28,920 --> 00:30:34,370
spinnaker was what neuron was talking

00:30:30,810 --> 00:30:36,450
about large number of namespaces

00:30:34,370 --> 00:30:38,430
particularly with the communities v2

00:30:36,450 --> 00:30:40,950
because of the caching mechanism and

00:30:38,430 --> 00:30:42,690
going to all the checks for all

00:30:40,950 --> 00:30:45,960
different kinds for permissions before

00:30:42,690 --> 00:30:48,450
it caches that takes some time and we

00:30:45,960 --> 00:30:50,340
need to make sure the way we deploy and

00:30:48,450 --> 00:30:52,590
allocate time number of threads and all

00:30:50,340 --> 00:30:57,540
of that corresponds to what you expect

00:30:52,590 --> 00:31:00,030
within that and the monitoring spinnaker

00:30:57,540 --> 00:31:01,620
spinnaker has this prometheus just add a

00:31:00,030 --> 00:31:04,950
little bit to the cloud driver restart

00:31:01,620 --> 00:31:08,490
that can be take 10-15 minutes depending

00:31:04,950 --> 00:31:11,610
and it's it's number accounts scales it

00:31:08,490 --> 00:31:14,040
takes a long time so that means that

00:31:11,610 --> 00:31:15,870
cloud drive is unavailable right when

00:31:14,040 --> 00:31:18,420
it's trying to come up it's unavailable

00:31:15,870 --> 00:31:20,670
so that's a problem that obviously we

00:31:18,420 --> 00:31:22,950
have to figure out and and make sure

00:31:20,670 --> 00:31:25,110
that we can sustain cloud driver even if

00:31:22,950 --> 00:31:27,480
we're making account changes and that

00:31:25,110 --> 00:31:28,740
problem has not been solved so we're

00:31:27,480 --> 00:31:30,630
still thinking about how to solve that

00:31:28,740 --> 00:31:31,710
maybe you have two of them running and

00:31:30,630 --> 00:31:32,820
you stage one and you bring the other

00:31:31,710 --> 00:31:34,800
one up while the other ones still

00:31:32,820 --> 00:31:36,570
working on the older cans and then while

00:31:34,800 --> 00:31:38,190
and then when your menu wants over it

00:31:36,570 --> 00:31:41,390
switches over with blue green we're

00:31:38,190 --> 00:31:41,390
still figuring out how to make that work

00:31:42,440 --> 00:31:47,610
so essentially go with the blue green

00:31:45,120 --> 00:31:49,830
when you restart a cloud driver the

00:31:47,610 --> 00:31:51,510
existing cloud driver with accounts that

00:31:49,830 --> 00:31:52,800
it's running with continues to run and

00:31:51,510 --> 00:31:55,050
with the new accounts when you bring up

00:31:52,800 --> 00:31:57,360
with new one it takes some time so

00:31:55,050 --> 00:32:00,840
essentially whenever there is a new

00:31:57,360 --> 00:32:02,910
account being on-boarded it takes that

00:32:00,840 --> 00:32:05,430
much amount of time for them to see the

00:32:02,910 --> 00:32:09,450
changes that are coming up right and

00:32:05,430 --> 00:32:11,370
monitoring is again with Prometheus

00:32:09,450 --> 00:32:14,100
we're here also the trick is because we

00:32:11,370 --> 00:32:16,590
have active passive clusters we can now

00:32:14,100 --> 00:32:17,040
use the monitoring within the cluster as

00:32:16,590 --> 00:32:18,810
well as

00:32:17,040 --> 00:32:21,420
across the clusters to identify if there

00:32:18,810 --> 00:32:22,830
are the whole region goes down then we

00:32:21,420 --> 00:32:28,170
have the monitoring from the second one

00:32:22,830 --> 00:32:31,940
that can identify that our back issues

00:32:28,170 --> 00:32:36,810
are one of the hardest ones spinnaker

00:32:31,940 --> 00:32:38,660
has two types of security with the

00:32:36,810 --> 00:32:42,180
accounts themselves has some security

00:32:38,660 --> 00:32:44,400
built in with readwrite access and then

00:32:42,180 --> 00:32:46,830
there is a application level readwrite

00:32:44,400 --> 00:32:49,080
access for the users and the third one

00:32:46,830 --> 00:32:50,550
is about service accounts for managed

00:32:49,080 --> 00:32:52,590
service accounts for running the

00:32:50,550 --> 00:32:54,330
pipeline's so when the trigger comes in

00:32:52,590 --> 00:32:57,000
because there is no authentication

00:32:54,330 --> 00:33:00,510
that's happening at the trigger time we

00:32:57,000 --> 00:33:03,030
can set up which account that it uses to

00:33:00,510 --> 00:33:05,070
run the pipeline so that has some side

00:33:03,030 --> 00:33:07,470
effects that are unintended it was not

00:33:05,070 --> 00:33:11,520
really designed for the security but

00:33:07,470 --> 00:33:12,420
more in terms of usage so those are some

00:33:11,520 --> 00:33:14,040
of the things that we are working

00:33:12,420 --> 00:33:18,030
through and trying to figure out what's

00:33:14,040 --> 00:33:20,670
the right thing to do for the moment we

00:33:18,030 --> 00:33:23,820
have that service accounts managed

00:33:20,670 --> 00:33:26,190
service accounts we are looking at admin

00:33:23,820 --> 00:33:28,830
account as a workaround it allows us to

00:33:26,190 --> 00:33:32,630
update those accounts whenever changes

00:33:28,830 --> 00:33:32,630
while it is being sent a service account

00:33:32,990 --> 00:33:39,300
Sox compliance today it's a manual

00:33:36,600 --> 00:33:40,980
judgment let's say the account this

00:33:39,300 --> 00:33:44,430
pipeline is triggered by account one

00:33:40,980 --> 00:33:47,910
then you can have a manual judgment

00:33:44,430 --> 00:33:50,820
that's set to have a privilege

00:33:47,910 --> 00:33:52,530
escalation so only certain groups of

00:33:50,820 --> 00:33:54,870
people who have the privilege to

00:33:52,530 --> 00:33:56,720
escalate it and escalate and that's the

00:33:54,870 --> 00:33:59,760
context it would it will run the

00:33:56,720 --> 00:34:01,980
deployment with and so then you can

00:33:59,760 --> 00:34:06,030
control how the deployment goes through

00:34:01,980 --> 00:34:08,070
with the privileges this is application

00:34:06,030 --> 00:34:09,960
onboarding this is the one-click deploy

00:34:08,070 --> 00:34:11,820
that nuran was talking about there was

00:34:09,960 --> 00:34:14,640
this facade API with the integrations

00:34:11,820 --> 00:34:16,350
with existing deployments we have the

00:34:14,640 --> 00:34:20,340
configuration now you can create a

00:34:16,350 --> 00:34:22,140
pipeline with user input single click

00:34:20,340 --> 00:34:25,290
that creates a pipeline in spinnaker

00:34:22,140 --> 00:34:27,570
that allows you to deploy straight to

00:34:25,290 --> 00:34:30,240
the deployment clusters you can have one

00:34:27,570 --> 00:34:30,899
or more clusters because we are creating

00:34:30,240 --> 00:34:34,559
the beginner

00:34:30,899 --> 00:34:38,220
our pipelines that allow to configure

00:34:34,559 --> 00:34:40,109
however you want just to add a little

00:34:38,220 --> 00:34:43,200
bit to the beginner and professional

00:34:40,109 --> 00:34:45,510
advance what does that mean about 80

00:34:43,200 --> 00:34:48,149
percent of our our folks really aren't

00:34:45,510 --> 00:34:50,639
DevOps engineers and really don't give a

00:34:48,149 --> 00:34:51,950
crap about DevOps when it comes to just

00:34:50,639 --> 00:34:54,299
getting their work out for the business

00:34:51,950 --> 00:34:56,970
they just want a pipeline that works and

00:34:54,299 --> 00:34:58,799
so that beginner pipeline is just fully

00:34:56,970 --> 00:35:00,869
baked it's not very complicated its

00:34:58,799 --> 00:35:03,180
straightforward its baked in socks if

00:35:00,869 --> 00:35:05,490
necessary and it just gets them going

00:35:03,180 --> 00:35:07,079
and that's a one click experience the

00:35:05,490 --> 00:35:08,220
professional and the advanced is some

00:35:07,079 --> 00:35:09,299
things that design patterns that were

00:35:08,220 --> 00:35:11,760
still working on what does that pipeline

00:35:09,299 --> 00:35:13,380
look like for now I think it's mostly

00:35:11,760 --> 00:35:15,839
going to be a lot of documentation on

00:35:13,380 --> 00:35:17,220
our part to provide those guidance and

00:35:15,839 --> 00:35:19,190
saying this is what the best practice is

00:35:17,220 --> 00:35:22,349
community as well as what we've learned

00:35:19,190 --> 00:35:25,170
but we're working with certain advanced

00:35:22,349 --> 00:35:27,630
users to figure out how to codify that

00:35:25,170 --> 00:35:29,609
into pipeline templates they can use

00:35:27,630 --> 00:35:31,619
time and time again for their particular

00:35:29,609 --> 00:35:33,809
applications but also to evolve that and

00:35:31,619 --> 00:35:35,670
so I think a community thing that really

00:35:33,809 --> 00:35:37,020
is something that not being looked at

00:35:35,670 --> 00:35:39,750
and not addressed I had talked to a few

00:35:37,020 --> 00:35:42,119
folks about some of that so there's a

00:35:39,750 --> 00:35:45,450
lot of thought process in maybe

00:35:42,119 --> 00:35:47,400
promoting some of that to be open

00:35:45,450 --> 00:35:48,750
sourced and just provide some pipelines

00:35:47,400 --> 00:35:50,010
that people can use for best practices

00:35:48,750 --> 00:35:53,940
around how how they can get all these

00:35:50,010 --> 00:35:56,190
things hooked up and working and managed

00:35:53,940 --> 00:35:59,460
by planes if you're familiar with it or

00:35:56,190 --> 00:36:01,440
the templates that are either stored in

00:35:59,460 --> 00:36:04,079
the gate or in the spinnaker itself

00:36:01,440 --> 00:36:05,940
that construct the pipeline and which

00:36:04,079 --> 00:36:08,400
you can run when you go apply the

00:36:05,940 --> 00:36:10,230
changes to the templates you can apply

00:36:08,400 --> 00:36:13,829
that to the spinnaker pipelines and

00:36:10,230 --> 00:36:14,849
those gets reflected right so anyway

00:36:13,829 --> 00:36:18,000
those get locked

00:36:14,849 --> 00:36:20,220
if Enterprise wants to manage their

00:36:18,000 --> 00:36:22,730
locked pipelines there's one way you can

00:36:20,220 --> 00:36:25,020
do is have have it in the gate that's

00:36:22,730 --> 00:36:27,480
secured and from there you apply these

00:36:25,020 --> 00:36:29,130
pipelines and those pipelines cannot be

00:36:27,480 --> 00:36:32,700
changed by the users who actually

00:36:29,130 --> 00:36:35,760
execute them well it's a workaround not

00:36:32,700 --> 00:36:37,460
exactly the secure thing but that can be

00:36:35,760 --> 00:36:44,829
used

00:36:37,460 --> 00:36:47,890
and in the summary of the lessons said

00:36:44,829 --> 00:36:50,780
Auerbach is one of the big issues you

00:36:47,890 --> 00:36:52,910
clearly need to automate the spinnaker

00:36:50,780 --> 00:36:54,619
deployments there are multiple releases

00:36:52,910 --> 00:36:57,319
that are coming in really fast a lot of

00:36:54,619 --> 00:37:00,050
new features being added bug fixes that

00:36:57,319 --> 00:37:02,000
were done to big community now you need

00:37:00,050 --> 00:37:05,930
to make sure you have your own process

00:37:02,000 --> 00:37:11,000
to deploy in your test before promoting

00:37:05,930 --> 00:37:13,910
it to production there are some issues

00:37:11,000 --> 00:37:15,650
if you have one large account with the

00:37:13,910 --> 00:37:18,740
service account that's controlling

00:37:15,650 --> 00:37:23,150
multiple deployments there are issues

00:37:18,740 --> 00:37:25,700
with the performance like no one was

00:37:23,150 --> 00:37:26,990
talking about that you have to worry

00:37:25,700 --> 00:37:28,579
about and there are a lot of

00:37:26,990 --> 00:37:30,980
improvements coming in that area but

00:37:28,579 --> 00:37:34,910
there's still working progress not to

00:37:30,980 --> 00:37:36,740
look forward to and really needed the

00:37:34,910 --> 00:37:39,920
audit dashboard is of another piece

00:37:36,740 --> 00:37:42,170
right now cisco has a audit dashboard

00:37:39,920 --> 00:37:44,809
for the current CD under that similar

00:37:42,170 --> 00:37:46,430
thing needs to be extended to the

00:37:44,809 --> 00:37:48,349
deployments that going with spinnaker

00:37:46,430 --> 00:37:51,079
you need to know how many you need to be

00:37:48,349 --> 00:37:52,640
able to measure what is the improvement

00:37:51,079 --> 00:37:54,740
where the improvements need to come

00:37:52,640 --> 00:37:58,069
where are the inefficiencies so that's a

00:37:54,740 --> 00:38:00,319
critical thing that you have to do the

00:37:58,069 --> 00:38:03,470
pipeline management super admin account

00:38:00,319 --> 00:38:05,869
would be one of the space they work

00:38:03,470 --> 00:38:07,819
around so this all back needs to be

00:38:05,869 --> 00:38:10,069
really thought through for real

00:38:07,819 --> 00:38:12,440
enterprises where we have multiple

00:38:10,069 --> 00:38:16,069
requirements it's it's not a purely

00:38:12,440 --> 00:38:18,710
self-service kind of a model right and

00:38:16,069 --> 00:38:22,250
centralized logging is a very critical

00:38:18,710 --> 00:38:23,869
of for production stuff cisco has I

00:38:22,250 --> 00:38:26,799
think elasticsearch paste central

00:38:23,869 --> 00:38:30,650
logging that takes all the data in that

00:38:26,799 --> 00:38:34,599
needs to be really scaled and set up I

00:38:30,650 --> 00:38:37,010
think we wrapped basically flow D and

00:38:34,599 --> 00:38:40,280
forded it to the centralized login so

00:38:37,010 --> 00:38:42,079
everyone has access to their logging

00:38:40,280 --> 00:38:43,369
services now not just for file services

00:38:42,079 --> 00:38:45,440
will elastic but now you've got the flow

00:38:43,369 --> 00:38:47,270
and D logs for the ephemeral workloads

00:38:45,440 --> 00:38:48,530
as well you just can't point it to a

00:38:47,270 --> 00:38:48,839
file obviously that's not going to work

00:38:48,530 --> 00:38:50,969
in

00:38:48,839 --> 00:38:53,670
ephemeral environment so the persistence

00:38:50,969 --> 00:38:55,650
of runtime to runtime instances of those

00:38:53,670 --> 00:38:56,759
workloads has to be forwarded or

00:38:55,650 --> 00:38:58,589
captured and then aligned and then

00:38:56,759 --> 00:38:59,969
visualized so that people can see where

00:38:58,589 --> 00:39:02,700
the failure happens because it fails it

00:38:59,969 --> 00:39:05,269
con what happened it's gone I mean so

00:39:02,700 --> 00:39:07,349
all of that has to be connected and

00:39:05,269 --> 00:39:08,819
allowing teams to do their debugging

00:39:07,349 --> 00:39:11,819
when something crashes and it's not

00:39:08,819 --> 00:39:13,769
unusual to see crashes crashes happen

00:39:11,819 --> 00:39:17,729
quite frequently so you don't lose that

00:39:13,769 --> 00:39:19,650
data right and spinnaker is tested at

00:39:17,729 --> 00:39:21,930
scale and Netflix has been using it for

00:39:19,650 --> 00:39:24,239
some time now we know it runs at scale

00:39:21,930 --> 00:39:26,069
but it's a quite feature-rich

00:39:24,239 --> 00:39:27,749
but there are a lot of hidden features

00:39:26,069 --> 00:39:30,809
that you need to figure out to get the

00:39:27,749 --> 00:39:34,160
scale of the Netflix and so the docks is

00:39:30,809 --> 00:39:34,160
one other place I think it can improve

00:39:35,690 --> 00:39:40,890
yeah I think so

00:39:38,009 --> 00:39:43,259
we're going to be going ga literally in

00:39:40,890 --> 00:39:44,999
less than 30 days and so that's gonna be

00:39:43,259 --> 00:39:47,339
an interesting proposition by itself so

00:39:44,999 --> 00:39:50,160
we are pulling here and I figure out can

00:39:47,339 --> 00:39:51,749
we really make this happen and what

00:39:50,160 --> 00:39:54,809
we're here so that's kind of interesting

00:39:51,749 --> 00:39:56,700
in itself we do have some scale testing

00:39:54,809 --> 00:39:58,859
to complete like I said earlier so

00:39:56,700 --> 00:40:00,210
that's some of the fine-tuning that

00:39:58,859 --> 00:40:03,539
needs to come out of that we're still

00:40:00,210 --> 00:40:06,359
working on the one clay provisioning

00:40:03,539 --> 00:40:08,369
services we're actually actively working

00:40:06,359 --> 00:40:10,319
on completing that we're hopeful that

00:40:08,369 --> 00:40:13,140
we'll meet the target date for that to

00:40:10,319 --> 00:40:15,960
roll it out it may shift they're all out

00:40:13,140 --> 00:40:19,019
by a week or so but that's kind of our

00:40:15,960 --> 00:40:20,729
target there they're going to grow it

00:40:19,019 --> 00:40:22,619
we're not just gonna throw everybody on

00:40:20,729 --> 00:40:24,749
it in one grow we're going to scale it

00:40:22,619 --> 00:40:27,239
out with a community of users to start

00:40:24,749 --> 00:40:29,369
with and then increase that size as we

00:40:27,239 --> 00:40:31,650
keep build up confidence and we start to

00:40:29,369 --> 00:40:34,349
configure the scale and such and then

00:40:31,650 --> 00:40:36,299
eventually hopefully we get our 1,500

00:40:34,349 --> 00:40:38,779
apps on there maybe more because there's

00:40:36,299 --> 00:40:40,859
a lot more refactoring going on and

00:40:38,779 --> 00:40:43,650
there's a lot more apps still being

00:40:40,859 --> 00:40:45,479
added so but that's kind of a our

00:40:43,650 --> 00:40:46,529
estimate right now number of apps that

00:40:45,479 --> 00:40:48,630
we have it could be a little bit more

00:40:46,529 --> 00:40:50,460
could be maybe a little bit less

00:40:48,630 --> 00:40:51,420
hopefully if people retire apps but that

00:40:50,460 --> 00:40:55,170
seems to be really hard proposition

00:40:51,420 --> 00:40:57,749
apparently we support we're gonna

00:40:55,170 --> 00:41:00,869
support 5,000 developers mostly these

00:40:57,749 --> 00:41:02,550
are IT developers but we do have quite a

00:41:00,869 --> 00:41:06,240
bit of interest from engineering

00:41:02,550 --> 00:41:08,040
IT that's has 25,000 plus developers so

00:41:06,240 --> 00:41:10,590
I'll be interesting to see if some of

00:41:08,040 --> 00:41:12,860
them start to use it we have some

00:41:10,590 --> 00:41:16,680
consolidated services between us now so

00:41:12,860 --> 00:41:19,590
it's going to be I'm hopeful that they

00:41:16,680 --> 00:41:22,530
will use this environment as well but

00:41:19,590 --> 00:41:24,480
we'll see how that goes a couple of

00:41:22,530 --> 00:41:26,730
fixes that were looking for I just put

00:41:24,480 --> 00:41:30,960
them out here in terms of actually we

00:41:26,730 --> 00:41:32,820
submitted a fix for in Fiat for a role

00:41:30,960 --> 00:41:34,410
for assignment of security was looking

00:41:32,820 --> 00:41:37,380
up LDAP actually should be looking

00:41:34,410 --> 00:41:38,850
looking up a Fiat an account itself when

00:41:37,380 --> 00:41:40,800
he wasn't returning right response so we

00:41:38,850 --> 00:41:43,440
found that bug and we submitted a fix

00:41:40,800 --> 00:41:46,200
and it got approved so apparently does

00:41:43,440 --> 00:41:49,860
work if you find a bug and get it

00:41:46,200 --> 00:41:51,540
approved by somebody the other problem

00:41:49,860 --> 00:41:52,740
was caching sync errors in Fiat and

00:41:51,540 --> 00:41:54,390
we're still working on a fix while were

00:41:52,740 --> 00:41:57,300
looking for a fix for that and then

00:41:54,390 --> 00:42:00,750
long-term stability I feel for the

00:41:57,300 --> 00:42:02,730
project is still not there it's still

00:42:00,750 --> 00:42:05,490
got bugs so the way we're going to

00:42:02,730 --> 00:42:07,110
manage that is going to be we're going

00:42:05,490 --> 00:42:11,790
to slow down a little bit on the amount

00:42:07,110 --> 00:42:13,050
of Spinnaker's that we upgrade to unless

00:42:11,790 --> 00:42:15,270
it's really necessary so we're going to

00:42:13,050 --> 00:42:17,040
slow down a little bit the other thing

00:42:15,270 --> 00:42:18,960
is went between versions of spinnaker as

00:42:17,040 --> 00:42:21,690
we upgrade we're gonna do a lot more

00:42:18,960 --> 00:42:24,300
testing so that's kind of something that

00:42:21,690 --> 00:42:26,840
we have to put on ourselves to control

00:42:24,300 --> 00:42:26,840
some of the chaos

00:42:27,720 --> 00:42:32,460
there's a few things that we have in the

00:42:29,369 --> 00:42:34,890
future we want to do canary deployments

00:42:32,460 --> 00:42:37,020
with ACA and run time and run time

00:42:34,890 --> 00:42:39,180
statistical metrics and really that

00:42:37,020 --> 00:42:42,359
involves hooking up to a lot of runtime

00:42:39,180 --> 00:42:46,099
data and being able to really leverage

00:42:42,359 --> 00:42:48,450
the next generation of ACA encanta and

00:42:46,099 --> 00:42:51,359
that's really read me nicely into the

00:42:48,450 --> 00:42:53,549
second point here is that there's a lot

00:42:51,359 --> 00:42:55,440
of data sources we're not tapping into a

00:42:53,549 --> 00:42:57,660
half of them probably not tapping into a

00:42:55,440 --> 00:43:00,569
lot of them and so we really need to do

00:42:57,660 --> 00:43:03,089
that and the benefit of that is to

00:43:00,569 --> 00:43:05,670
reduce the the time to recovery from

00:43:03,089 --> 00:43:08,190
incidents and to generally reduce

00:43:05,670 --> 00:43:11,910
incidents but the other side product of

00:43:08,190 --> 00:43:15,059
that is that depending on Georg's that

00:43:11,910 --> 00:43:17,309
you use some of them can result in false

00:43:15,059 --> 00:43:18,660
positive reduction as well so that's an

00:43:17,309 --> 00:43:21,180
interesting thing that we need to tap on

00:43:18,660 --> 00:43:22,770
it's really really early days I think

00:43:21,180 --> 00:43:25,289
when it comes to judges and comparing

00:43:22,770 --> 00:43:27,420
judges against each other and the data

00:43:25,289 --> 00:43:29,780
that they gather and what they can infer

00:43:27,420 --> 00:43:33,690
out of that data so we're exploring that

00:43:29,780 --> 00:43:36,240
and then some things that got interested

00:43:33,690 --> 00:43:38,880
in in terms of judges that I talked to

00:43:36,240 --> 00:43:41,099
ops mx about is the different approaches

00:43:38,880 --> 00:43:43,680
right statistical an algorithmic

00:43:41,099 --> 00:43:45,779
reasoning these neural net data and how

00:43:43,680 --> 00:43:47,190
do you leverage the two and how can they

00:43:45,779 --> 00:43:48,660
both solve the same problem and how does

00:43:47,190 --> 00:43:50,549
one solve the problem better than the

00:43:48,660 --> 00:43:52,099
other so this is still we're scratching

00:43:50,549 --> 00:43:56,309
the surface there to see how people are

00:43:52,099 --> 00:43:58,170
evolving that in terms of kind to judge

00:43:56,309 --> 00:44:02,130
it so there's going to be a lot of I

00:43:58,170 --> 00:44:03,960
think innovation happening in that space

00:44:02,130 --> 00:44:05,730
and a lot of people going after you know

00:44:03,960 --> 00:44:11,069
making sense out of the chaos of that

00:44:05,730 --> 00:44:13,829
data finally we're looking at

00:44:11,069 --> 00:44:15,480
introducing cows engineering which is I

00:44:13,829 --> 00:44:16,980
think in our interpretation probably not

00:44:15,480 --> 00:44:19,349
as much chaos than it is reliability

00:44:16,980 --> 00:44:20,760
engineering but it's something that

00:44:19,349 --> 00:44:23,339
we're exploring and not just from a

00:44:20,760 --> 00:44:25,349
software sense but more holistically

00:44:23,339 --> 00:44:27,029
from an infrastructure and application

00:44:25,349 --> 00:44:28,789
sense so we're trying to figure out how

00:44:27,029 --> 00:44:31,740
does that work I think pioneers like

00:44:28,789 --> 00:44:34,650
Netflix are inspirations for us and

00:44:31,740 --> 00:44:38,700
we're using a little bit more modern

00:44:34,650 --> 00:44:40,839
developed software now which is acute to

00:44:38,700 --> 00:44:42,489
a cow's toolkit as well as gremlin

00:44:40,839 --> 00:44:44,140
Netflix's OSS we're going to compare all

00:44:42,489 --> 00:44:46,329
of those contrasts and see which ones we

00:44:44,140 --> 00:44:50,259
can leverage to solve which kinds of

00:44:46,329 --> 00:44:51,339
problems and finally there's a couple of

00:44:50,259 --> 00:44:53,829
other points here

00:44:51,339 --> 00:44:56,619
integration with STL I think that's

00:44:53,829 --> 00:44:59,739
really necessary because as everyone

00:44:56,619 --> 00:45:01,690
knows all of these containers are really

00:44:59,739 --> 00:45:03,309
micro services and there are micro

00:45:01,690 --> 00:45:05,019
service dependencies between each other

00:45:03,309 --> 00:45:06,039
that's a lot of networking how do you

00:45:05,019 --> 00:45:08,259
manage all that and how do you manage

00:45:06,039 --> 00:45:11,529
that scale so obviously service mesh is

00:45:08,259 --> 00:45:13,269
helping solve and reduce the amount of

00:45:11,529 --> 00:45:15,819
complexity but also add a lot of value

00:45:13,269 --> 00:45:18,099
in making that happen and making it much

00:45:15,819 --> 00:45:19,660
more programmable - and conducive to the

00:45:18,099 --> 00:45:21,880
programmability of spinnaker pipelines

00:45:19,660 --> 00:45:23,920
so that you can set those patterns in

00:45:21,880 --> 00:45:26,499
where you want to flex let's say blue

00:45:23,920 --> 00:45:28,180
green or canary how much you want to

00:45:26,499 --> 00:45:30,130
flow that traffic based on what results

00:45:28,180 --> 00:45:32,890
you're getting back and things like that

00:45:30,130 --> 00:45:34,630
and manage that at not just a individual

00:45:32,890 --> 00:45:36,630
micro service level but across micro

00:45:34,630 --> 00:45:40,180
services and across dependencies right

00:45:36,630 --> 00:45:42,729
and then integrating - CD analytics

00:45:40,180 --> 00:45:44,920
that's kind of a homegrown thing every

00:45:42,729 --> 00:45:48,160
event that comes out of anywhere in the

00:45:44,920 --> 00:45:50,950
pipeline or across CI CD creates an

00:45:48,160 --> 00:45:53,079
event we correlate aggregate we get lots

00:45:50,950 --> 00:45:56,430
of rich data out of that and it's no

00:45:53,079 --> 00:45:59,049
different for using spinnaker and and

00:45:56,430 --> 00:46:00,160
open ships so we're going to do the same

00:45:59,049 --> 00:46:02,079
same we're going to grab all that data

00:46:00,160 --> 00:46:05,349
and be able to correlate and get good

00:46:02,079 --> 00:46:08,099
user value out of that and then got we

00:46:05,349 --> 00:46:08,099
talked about a sorcerer

00:46:08,980 --> 00:46:11,040

YouTube URL: https://www.youtube.com/watch?v=LKrSWryMNKg


