Title: Libcamera: Making complex cameras easy! - Umang Jain
Publication date: 2020-11-15
Playlist: Linux App Summit 2020 Talks
Description: 
	A complex camera support library for Linux, Android, and ChromeOS.

Cameras are complex devices that need heavy hardware image processing operations. Control of the processing is based on advanced algorithms that must run on a programmable processor. This has traditionally been implemented in a dedicated MCU in the camera, but in embedded devices algorithms have been moved to the main CPU to save cost. Blurring the boundary between camera devices and Linux often left the user with no other option than a vendor-specific closed-source solution.

To address this problem the V4L2 community is collaborating with industry leaders to develop a camera stack that will be open-source-friendly while still protecting vendor core IP. Libcamera is under active development and interested vendors have the opportunity to contribute and provide feedback to ensure we cover all use cases before the API is finalised.
Captions: 
	00:00:01,599 --> 00:00:06,399
uh thanks

00:00:03,360 --> 00:00:09,760
uh so let's begin uh i am

00:00:06,399 --> 00:00:11,599
a monk uh i am a journalist open source

00:00:09,760 --> 00:00:17,920
software developer

00:00:11,599 --> 00:00:17,920
for a couple of years now uh recently uh

00:00:18,640 --> 00:00:24,480
i am working on a project called lip

00:00:21,920 --> 00:00:24,480
camera

00:00:24,560 --> 00:00:33,119
i don't think i have camera right now

00:00:29,119 --> 00:00:33,119
that's ironic uh

00:00:33,920 --> 00:00:38,719
yeah i i don't have a webcam right now

00:00:38,879 --> 00:00:43,440
sorry it's it's i thought it could go

00:00:42,000 --> 00:00:46,160
with presentation and

00:00:43,440 --> 00:00:46,160
audio only

00:00:49,440 --> 00:00:53,680
yeah so is that okay

00:00:56,160 --> 00:00:59,840
okay so

00:01:00,160 --> 00:01:06,400
uh okay sure

00:01:03,199 --> 00:01:09,760
thanks uh so let's begin uh

00:01:06,400 --> 00:01:13,360
so i'm uh let's uh uh

00:01:09,760 --> 00:01:16,880
talk about the uh like video capture

00:01:13,360 --> 00:01:21,119
uh linux media uh domain

00:01:16,880 --> 00:01:24,159
for for life what happens is like uh

00:01:21,119 --> 00:01:26,640
like a while ago like

00:01:24,159 --> 00:01:28,640
15 years ago there what the linux media

00:01:26,640 --> 00:01:31,840
and the video capture domain was

00:01:28,640 --> 00:01:33,280
uh quite simple you would have a camera

00:01:31,840 --> 00:01:37,040
sensor at the top

00:01:33,280 --> 00:01:40,159
uh and there would be a

00:01:37,040 --> 00:01:42,479
interface csi2 or even parallel and

00:01:40,159 --> 00:01:45,200
you would that would get exposed through

00:01:42,479 --> 00:01:46,880
a video node so

00:01:45,200 --> 00:01:49,439
writing applications user space

00:01:46,880 --> 00:01:52,960
applications was pretty easy

00:01:49,439 --> 00:01:55,600
you would have only one place for

00:01:52,960 --> 00:01:56,079
control one place to look for frames and

00:01:55,600 --> 00:02:00,320
just

00:01:56,079 --> 00:02:03,520
display to your output uh window

00:02:00,320 --> 00:02:04,079
uh so this was uh basically a very

00:02:03,520 --> 00:02:07,360
simple

00:02:04,079 --> 00:02:11,520
and uh it rare like

00:02:07,360 --> 00:02:14,800
it worked well for a while but then

00:02:11,520 --> 00:02:16,400
uh things get complicated yeah so

00:02:14,800 --> 00:02:19,520
complexity increased

00:02:16,400 --> 00:02:20,879
with the image signal processors being

00:02:19,520 --> 00:02:24,080
introduced

00:02:20,879 --> 00:02:24,879
so let's talk a bit brief about what are

00:02:24,080 --> 00:02:26,959
isps

00:02:24,879 --> 00:02:28,160
or emit signal processors they are

00:02:26,959 --> 00:02:30,319
system peripherals

00:02:28,160 --> 00:02:32,480
that means they are operating at very

00:02:30,319 --> 00:02:35,120
high frequency

00:02:32,480 --> 00:02:37,200
uh that operate on a digital images so

00:02:35,120 --> 00:02:40,160
basically the raw

00:02:37,200 --> 00:02:40,640
data captured by the sensor is then

00:02:40,160 --> 00:02:46,160
pushed

00:02:40,640 --> 00:02:46,160
down to isps and they do some stuff

00:02:46,319 --> 00:02:50,000
that we are going to talk so basically

00:02:48,640 --> 00:02:52,480
dma resizing

00:02:50,000 --> 00:02:53,360
scaling cropping or pixel format

00:02:52,480 --> 00:02:55,840
conversation

00:02:53,360 --> 00:02:56,879
conversion are some of the things that

00:02:55,840 --> 00:03:01,120
they would do

00:02:56,879 --> 00:03:03,599
uh these are the basic ones that

00:03:01,120 --> 00:03:04,560
basically were found in many but there

00:03:03,599 --> 00:03:07,599
are other

00:03:04,560 --> 00:03:10,319
isps so isps are basically

00:03:07,599 --> 00:03:12,000
a group of building blocks that have

00:03:10,319 --> 00:03:14,800
some specific operations

00:03:12,000 --> 00:03:16,959
on the raw data that been captured so

00:03:14,800 --> 00:03:18,400
imagine a pipeline or simply a g

00:03:16,959 --> 00:03:20,239
streamer pipeline you would have

00:03:18,400 --> 00:03:21,200
elements and the data would flow through

00:03:20,239 --> 00:03:24,400
them

00:03:21,200 --> 00:03:26,239
uh so image uh signal processors were

00:03:24,400 --> 00:03:27,680
then but they are basically system

00:03:26,239 --> 00:03:31,120
peripherals so they were

00:03:27,680 --> 00:03:36,080
uh like embedded on the uh soc

00:03:31,120 --> 00:03:38,879
itself so uh in order to

00:03:36,080 --> 00:03:39,680
manage the data flow through these

00:03:38,879 --> 00:03:43,680
peripherals

00:03:39,680 --> 00:03:46,879
kernel was kernel exposed a new api

00:03:43,680 --> 00:03:50,560
named media controller uh before that to

00:03:46,879 --> 00:03:53,360
capture uh like the video frames and all

00:03:50,560 --> 00:03:54,480
the there was already an api called v4l

00:03:53,360 --> 00:03:58,480
video for linux

00:03:54,480 --> 00:04:02,799
and v4 l2 uh so that part was sorted but

00:03:58,480 --> 00:04:05,040
the introduction of isps uh

00:04:02,799 --> 00:04:06,159
led to a need to introduce a new api

00:04:05,040 --> 00:04:09,760
called media con

00:04:06,159 --> 00:04:13,680
media controller in the kernel uh

00:04:09,760 --> 00:04:17,440
so looking at high level what exactly

00:04:13,680 --> 00:04:19,840
has happened i cannot see my

00:04:17,440 --> 00:04:19,840
slide

00:04:25,759 --> 00:04:32,960
okay so yeah the hardware topology

00:04:29,120 --> 00:04:35,680
uh got complicated like you can see here

00:04:32,960 --> 00:04:36,080
uh you would have some sensors the red

00:04:35,680 --> 00:04:39,360
uh

00:04:36,080 --> 00:04:42,160
boxes are the sensors like two uh

00:04:39,360 --> 00:04:43,360
sensors and this flash maybe the isps

00:04:42,160 --> 00:04:46,400
building blocks are

00:04:43,360 --> 00:04:50,479
denoted in green so you would have some

00:04:46,400 --> 00:04:53,840
sub divs or some something uh resizer

00:04:50,479 --> 00:04:55,919
and uh the blue boxes are the api so

00:04:53,840 --> 00:04:57,440
mind you this are the like the video

00:04:55,919 --> 00:05:00,560
notes uh they

00:04:57,440 --> 00:05:03,919
are also configured or they are also

00:05:00,560 --> 00:05:07,280
interfaced with an api maybe before

00:05:03,919 --> 00:05:10,560
and the the uh

00:05:07,280 --> 00:05:13,680
isps were controlled using something

00:05:10,560 --> 00:05:14,400
we discuss is media controller so two

00:05:13,680 --> 00:05:18,639
different

00:05:14,400 --> 00:05:20,960
apis to manage uh the video capture

00:05:18,639 --> 00:05:20,960
here

00:05:22,560 --> 00:05:26,479
okay so looking at very high level for

00:05:24,960 --> 00:05:29,199
an camera application

00:05:26,479 --> 00:05:30,160
earlier it was just v4l2 one place to

00:05:29,199 --> 00:05:33,120
look for frames

00:05:30,160 --> 00:05:33,680
one place to control them and now with

00:05:33,120 --> 00:05:36,160
the

00:05:33,680 --> 00:05:37,440
introduction of complex isps you would

00:05:36,160 --> 00:05:39,440
have v4l2

00:05:37,440 --> 00:05:41,680
you would the camera application would

00:05:39,440 --> 00:05:42,880
also need to know about media controller

00:05:41,680 --> 00:05:45,520
like how

00:05:42,880 --> 00:05:45,919
uh media will flow through through uh

00:05:45,520 --> 00:05:49,199
the

00:05:45,919 --> 00:05:52,560
peripherals uh sub-div so

00:05:49,199 --> 00:05:55,840
it became a very complex task

00:05:52,560 --> 00:05:56,800
to write a camera application without

00:05:55,840 --> 00:06:00,080
the knowledge

00:05:56,800 --> 00:06:03,280
of like uh hardware uh

00:06:00,080 --> 00:06:06,319
uh complexity you are handling and uh

00:06:03,280 --> 00:06:08,800
being very tied to a hardware

00:06:06,319 --> 00:06:10,000
uh is something which does not scale in

00:06:08,800 --> 00:06:13,440
the long run

00:06:10,000 --> 00:06:14,479
so uh this went for a while in embedded

00:06:13,440 --> 00:06:17,199
and like

00:06:14,479 --> 00:06:18,479
you have seen uh like the mobiles and

00:06:17,199 --> 00:06:22,240
the cell phones had

00:06:18,479 --> 00:06:25,600
cameras which are uh which which

00:06:22,240 --> 00:06:28,639
use basically this uh this frame

00:06:25,600 --> 00:06:30,000
framework or like uh practice more or

00:06:28,639 --> 00:06:33,759
less to say

00:06:30,000 --> 00:06:36,960
uh but uh since last couple of years

00:06:33,759 --> 00:06:38,720
those cameras are slowly uh coming to

00:06:36,960 --> 00:06:40,400
uh the personal computing world the

00:06:38,720 --> 00:06:43,919
laptops and a

00:06:40,400 --> 00:06:47,199
few other uh like uvc

00:06:43,919 --> 00:06:50,479
devices and all so we need to

00:06:47,199 --> 00:06:53,120
address a problem here uh we need a like

00:06:50,479 --> 00:06:54,000
uh something which can abstract all this

00:06:53,120 --> 00:06:57,520
complexity

00:06:54,000 --> 00:06:59,440
and let application developers write

00:06:57,520 --> 00:07:00,639
application in such a way that they are

00:06:59,440 --> 00:07:03,840
portable they

00:07:00,639 --> 00:07:05,120
run uh basically depict the main

00:07:03,840 --> 00:07:07,360
business logic

00:07:05,120 --> 00:07:08,160
of the application and being able to

00:07:07,360 --> 00:07:10,800
like

00:07:08,160 --> 00:07:11,440
uh run on different uh on and not care

00:07:10,800 --> 00:07:14,840
about the

00:07:11,440 --> 00:07:18,080
platform on there which are running

00:07:14,840 --> 00:07:19,039
so this is the problem statement uh as

00:07:18,080 --> 00:07:20,800
of now uh

00:07:19,039 --> 00:07:23,360
applications are requested to know a lot

00:07:20,800 --> 00:07:26,880
of details of underlying hardware

00:07:23,360 --> 00:07:28,240
and uh capturing frames uh meaning like

00:07:26,880 --> 00:07:31,280
you have to

00:07:28,240 --> 00:07:33,440
uh really know about the what

00:07:31,280 --> 00:07:35,680
peripherals you have on the hardware and

00:07:33,440 --> 00:07:37,440
configuring it before the application

00:07:35,680 --> 00:07:40,479
can even use it

00:07:37,440 --> 00:07:41,680
uh and yeah uh the media graph that i

00:07:40,479 --> 00:07:45,199
showed you earlier

00:07:41,680 --> 00:07:47,280
is from like 10 years back so

00:07:45,199 --> 00:07:49,280
it was already complex 10 years back and

00:07:47,280 --> 00:07:52,080
uh modern laptops that are shipping with

00:07:49,280 --> 00:07:54,720
powerful isps like intel ipo 3 uh

00:07:52,080 --> 00:07:55,840
i rather not show the media graph here

00:07:54,720 --> 00:07:59,680
because it's

00:07:55,840 --> 00:08:02,879
very complex and i just don't want to uh

00:07:59,680 --> 00:08:04,720
you can look it up online uh maybe let

00:08:02,879 --> 00:08:06,960
us know

00:08:04,720 --> 00:08:07,919
and worry worry uh the details would be

00:08:06,960 --> 00:08:10,960
worried about the

00:08:07,919 --> 00:08:14,800
flip camera developers

00:08:10,960 --> 00:08:17,599
uh so yeah this is a

00:08:14,800 --> 00:08:19,680
reply on a mailing list web camera not

00:08:17,599 --> 00:08:22,879
recognized by a dell attitude

00:08:19,680 --> 00:08:26,400
uh this specific model because it was

00:08:22,879 --> 00:08:29,039
shipped with an ipo 3 camera

00:08:26,400 --> 00:08:29,680
the reply was laptops i will just read

00:08:29,039 --> 00:08:32,000
it out

00:08:29,680 --> 00:08:32,719
embeds one of these new complex cameras

00:08:32,000 --> 00:08:35,680
from intel

00:08:32,719 --> 00:08:37,279
they require ipo3 driver though unlike

00:08:35,680 --> 00:08:39,919
traditional webcam you need

00:08:37,279 --> 00:08:42,320
special user user space to use it there

00:08:39,919 --> 00:08:44,000
is no embedded firmware to manage focus

00:08:42,320 --> 00:08:47,279
white balance etc

00:08:44,000 --> 00:08:49,200
user space code need to read the stats

00:08:47,279 --> 00:08:49,920
and manage that as of now there is a no

00:08:49,200 --> 00:08:52,320
good

00:08:49,920 --> 00:08:53,600
plan on how to support this as your user

00:08:52,320 --> 00:08:57,360
space

00:08:53,600 --> 00:08:59,360
so i i hope you have uh pretty much uh

00:08:57,360 --> 00:09:02,640
understood what what the what is the

00:08:59,360 --> 00:09:02,640
problem we are dealing with here

00:09:02,800 --> 00:09:06,480
uh so yeah uh that that was the

00:09:05,279 --> 00:09:08,959
motivation

00:09:06,480 --> 00:09:10,000
or the background for which the lip

00:09:08,959 --> 00:09:13,600
camera has been

00:09:10,000 --> 00:09:16,160
started uh it

00:09:13,600 --> 00:09:16,800
is being actively developed by linux

00:09:16,160 --> 00:09:20,390
media

00:09:16,800 --> 00:09:21,920
folks uh and yeah some

00:09:20,390 --> 00:09:24,640
[Music]

00:09:21,920 --> 00:09:25,360
other consulting firms as well uh very

00:09:24,640 --> 00:09:28,720
specific

00:09:25,360 --> 00:09:30,880
to related to the needs so

00:09:28,720 --> 00:09:33,200
let's get into that lip camera is a

00:09:30,880 --> 00:09:35,120
complete use-based camera stack

00:09:33,200 --> 00:09:37,279
it abstracts away all the complexities

00:09:35,120 --> 00:09:39,600
as we discussed about v4l2 media

00:09:37,279 --> 00:09:42,560
controller hardware topology

00:09:39,600 --> 00:09:43,519
everything uh it aims to be compatible

00:09:42,560 --> 00:09:47,680
with already

00:09:43,519 --> 00:09:49,040
written media applications uh v4d2 based

00:09:47,680 --> 00:09:52,080
application

00:09:49,040 --> 00:09:53,440
and aims to like provide a layer so that

00:09:52,080 --> 00:09:57,920
we can

00:09:53,440 --> 00:09:57,920
it can be used on android and chrome os

00:09:58,399 --> 00:10:01,600
already we had a good amount of

00:10:00,480 --> 00:10:04,800
documentation

00:10:01,600 --> 00:10:07,360
we have application developer and

00:10:04,800 --> 00:10:10,079
pipeline handle that we will discuss

00:10:07,360 --> 00:10:10,880
and sap a couple of sample applications

00:10:10,079 --> 00:10:14,240
that we

00:10:10,880 --> 00:10:17,440
use for testing and basic dog fooding

00:10:14,240 --> 00:10:19,519
so you can just try them out and see for

00:10:17,440 --> 00:10:23,120
yourself

00:10:19,519 --> 00:10:24,240
uh now let's uh okay we are mail based

00:10:23,120 --> 00:10:26,720
development i know

00:10:24,240 --> 00:10:29,519
uh mailing lists first patchwork

00:10:26,720 --> 00:10:33,519
basically i think uh that's the

00:10:29,519 --> 00:10:36,880
uh workflow the linux media door zoom in

00:10:33,519 --> 00:10:37,279
were comfortable so they started with

00:10:36,880 --> 00:10:40,640
that

00:10:37,279 --> 00:10:43,519
we use my son and ninja and it's quite

00:10:40,640 --> 00:10:44,640
like it might sound complex but uh as of

00:10:43,519 --> 00:10:47,839
uh this talk goes

00:10:44,640 --> 00:10:49,920
you will find uh it's it's not a very

00:10:47,839 --> 00:10:52,399
like i come from a background where i

00:10:49,920 --> 00:10:52,720
have haven't done much linux development

00:10:52,399 --> 00:10:55,760
uh

00:10:52,720 --> 00:10:58,720
mostly i was working in user space but

00:10:55,760 --> 00:10:59,279
uh the community and people are very

00:10:58,720 --> 00:11:02,720
friendly

00:10:59,279 --> 00:11:05,600
very newcomers friendly so i think

00:11:02,720 --> 00:11:07,839
if you plan to contribute please check

00:11:05,600 --> 00:11:11,360
check it out

00:11:07,839 --> 00:11:13,200
uh let's talk about uh

00:11:11,360 --> 00:11:15,040
complex cameras debate there are a

00:11:13,200 --> 00:11:18,079
couple of uh if you want to get

00:11:15,040 --> 00:11:19,839
more into the problem space

00:11:18,079 --> 00:11:21,600
specifically the problem space so why

00:11:19,839 --> 00:11:23,600
embedded cameras are difficult

00:11:21,600 --> 00:11:26,240
and like complex cameras on linux these

00:11:23,600 --> 00:11:29,279
are the three talks i would recommend

00:11:26,240 --> 00:11:32,000
you can check them out uh simply

00:11:29,279 --> 00:11:32,800
searching for them on the youtube uh

00:11:32,000 --> 00:11:34,640
they are

00:11:32,800 --> 00:11:36,240
a personal favorite of mine and

00:11:34,640 --> 00:11:40,240
basically help this

00:11:36,240 --> 00:11:40,240
talk that i'm delivering right now

00:11:41,200 --> 00:11:43,839
okay

00:11:50,800 --> 00:11:58,320
okay so here is the entire camera stack

00:11:55,040 --> 00:12:00,399
a bird's eye view so you can see that

00:11:58,320 --> 00:12:01,760
kernel space already has like a media

00:12:00,399 --> 00:12:04,800
device video device

00:12:01,760 --> 00:12:06,880
uh and v42 sub dev the lip camera will

00:12:04,800 --> 00:12:10,160
interact and abstract all of this

00:12:06,880 --> 00:12:12,880
for applications uh we

00:12:10,160 --> 00:12:14,399
would have uh we will we have a v4r2

00:12:12,880 --> 00:12:16,720
compatibility layer so

00:12:14,399 --> 00:12:18,959
existing application can work on it we

00:12:16,720 --> 00:12:22,959
also have g streamer element

00:12:18,959 --> 00:12:23,279
that it can use we as of now don't have

00:12:22,959 --> 00:12:26,480
like

00:12:23,279 --> 00:12:28,000
language bindings but there is a i think

00:12:26,480 --> 00:12:30,399
a discussion going on and

00:12:28,000 --> 00:12:31,839
we would start with python so basically

00:12:30,399 --> 00:12:35,680
just to mention lip camera

00:12:31,839 --> 00:12:39,040
is being developed in c plus plus uh

00:12:35,680 --> 00:12:43,200
yeah uh so i think uh uh

00:12:39,040 --> 00:12:43,920
for now c plus plus uh would be a strong

00:12:43,200 --> 00:12:46,480
uh

00:12:43,920 --> 00:12:47,680
association uh if there is any

00:12:46,480 --> 00:12:49,920
application you want to

00:12:47,680 --> 00:12:51,120
any application wants to use it uh but

00:12:49,920 --> 00:12:52,880
yeah shortly

00:12:51,120 --> 00:12:55,040
you should look out there is a plan

00:12:52,880 --> 00:12:58,800
already planned for language

00:12:55,040 --> 00:13:02,160
bindings and we also have a android

00:12:58,800 --> 00:13:05,680
uh camera ha a hardware extraction layer

00:13:02,160 --> 00:13:08,079
which is uh which sort of decently works

00:13:05,680 --> 00:13:12,240
on the chromium os as well

00:13:08,079 --> 00:13:16,000
uh so this is the bird's eye view

00:13:12,240 --> 00:13:17,279
for for uh lip camera and now i think we

00:13:16,000 --> 00:13:20,399
will go into

00:13:17,279 --> 00:13:24,320
a lip camera our architecture

00:13:20,399 --> 00:13:26,480
so at the top is the public api uh

00:13:24,320 --> 00:13:27,839
which will uh which the applications

00:13:26,480 --> 00:13:30,079
will interact

00:13:27,839 --> 00:13:32,480
at the core lift camera has a device

00:13:30,079 --> 00:13:34,800
manager which will

00:13:32,480 --> 00:13:36,720
start and enumerate it will find all the

00:13:34,800 --> 00:13:39,680
camera video capture devices

00:13:36,720 --> 00:13:41,839
attached to your systems and expose uh

00:13:39,680 --> 00:13:45,360
camera device objects

00:13:41,839 --> 00:13:46,240
uh that you can use uh we have state

00:13:45,360 --> 00:13:49,839
machines

00:13:46,240 --> 00:13:50,560
so basically to track what is the status

00:13:49,839 --> 00:13:53,120
of the camera

00:13:50,560 --> 00:13:53,920
it's running it's stopped or it's in

00:13:53,120 --> 00:13:56,959
configure

00:13:53,920 --> 00:13:58,160
state or something like that uh we have

00:13:56,959 --> 00:14:01,040
streams what

00:13:58,160 --> 00:14:02,320
streams are supported by the camera what

00:14:01,040 --> 00:14:05,839
role do you want to

00:14:02,320 --> 00:14:07,680
like you want to use for a video

00:14:05,839 --> 00:14:09,120
video capture or you want to use for a

00:14:07,680 --> 00:14:12,160
still capture

00:14:09,120 --> 00:14:16,240
so uh depending on that uh the

00:14:12,160 --> 00:14:19,360
the uh device or the camera device will

00:14:16,240 --> 00:14:23,040
give you uh best suited streams uh

00:14:19,360 --> 00:14:25,199
and at which uh an associated resolution

00:14:23,040 --> 00:14:26,240
and you of course have access control so

00:14:25,199 --> 00:14:29,519
that uh

00:14:26,240 --> 00:14:30,720
no two applications simultaneously asks

00:14:29,519 --> 00:14:34,000
for

00:14:30,720 --> 00:14:34,000
uh the camera

00:14:34,079 --> 00:14:40,959
at the same time so this part is

00:14:37,680 --> 00:14:42,320
a device agnostic uh this is uh

00:14:40,959 --> 00:14:44,560
this has nothing to do with the

00:14:42,320 --> 00:14:45,839
underlying hardware and all the device

00:14:44,560 --> 00:14:48,959
specific stuff

00:14:45,839 --> 00:14:52,880
goes into a pipeline handler which will

00:14:48,959 --> 00:14:56,160
uh do all the things uh video notes

00:14:52,880 --> 00:14:59,040
media controller stuff and

00:14:56,160 --> 00:14:59,519
set up pipeline set up the flow in which

00:14:59,040 --> 00:15:01,839
the

00:14:59,519 --> 00:15:03,519
data data flow was intended to be

00:15:01,839 --> 00:15:05,519
because you have different right

00:15:03,519 --> 00:15:07,839
rockchip would have a different pipeline

00:15:05,519 --> 00:15:08,560
handler and rather than a raspberry pi

00:15:07,839 --> 00:15:11,360
one

00:15:08,560 --> 00:15:13,199
so you will have a raspberry pi pi

00:15:11,360 --> 00:15:14,720
pipeline handler and you have we'll have

00:15:13,199 --> 00:15:16,639
a different

00:15:14,720 --> 00:15:17,760
rockchip pipeline handler so all the

00:15:16,639 --> 00:15:21,760
diff or

00:15:17,760 --> 00:15:25,199
device specific stuff goes here

00:15:21,760 --> 00:15:26,000
and the device manager is smart enough

00:15:25,199 --> 00:15:28,480
to figure out what

00:15:26,000 --> 00:15:29,600
the platform is and use the appropriate

00:15:28,480 --> 00:15:32,720
pipeline handler

00:15:29,600 --> 00:15:35,680
and mind you like pipeline handlers are

00:15:32,720 --> 00:15:37,279
a bit complex in a way like uh camera

00:15:35,680 --> 00:15:38,480
objects can be different but they can

00:15:37,279 --> 00:15:42,720
use the same

00:15:38,480 --> 00:15:46,079
uh isp on the hardware so

00:15:42,720 --> 00:15:49,440
uh no two cameras uh

00:15:46,079 --> 00:15:51,440
like uh one will gain exclusive use of

00:15:49,440 --> 00:15:55,279
the pipeline handlers

00:15:51,440 --> 00:15:57,600
uh another thing is uh image processing

00:15:55,279 --> 00:15:58,800
algorithms which is also very device

00:15:57,600 --> 00:16:02,240
specific

00:15:58,800 --> 00:16:03,120
and this is shown in a blue kind of box

00:16:02,240 --> 00:16:07,199
which is

00:16:03,120 --> 00:16:09,279
which shows the sandboxing because

00:16:07,199 --> 00:16:11,199
image processing algorithms or three

00:16:09,279 --> 00:16:14,880
years as we talk

00:16:11,199 --> 00:16:18,560
are very vendor specific and

00:16:14,880 --> 00:16:22,079
vendors might might

00:16:18,560 --> 00:16:25,519
need to protect that core ip

00:16:22,079 --> 00:16:28,320
so lip camera already has uh

00:16:25,519 --> 00:16:29,680
has been developed with that uh frame uh

00:16:28,320 --> 00:16:34,079
in mind

00:16:29,680 --> 00:16:37,920
uh so we are lgbl lip cameras lgpl

00:16:34,079 --> 00:16:38,399
so that we don't tie into some binary

00:16:37,920 --> 00:16:41,440
blob

00:16:38,399 --> 00:16:44,720
uh in the future

00:16:41,440 --> 00:16:47,519
uh so it has been designed in such a way

00:16:44,720 --> 00:16:48,399
uh and you have some uh helpers and

00:16:47,519 --> 00:16:51,040
support graph

00:16:48,399 --> 00:16:52,399
buffer allocators pipeline runners and

00:16:51,040 --> 00:16:55,519
debugging and login which

00:16:52,399 --> 00:16:57,519
are i think uh if you

00:16:55,519 --> 00:16:59,120
plan to develop these it will become

00:16:57,519 --> 00:17:02,000
obvious if you read

00:16:59,120 --> 00:17:02,000
the documentation

00:17:02,880 --> 00:17:08,240
uh uh yeah so platform supported by lip

00:17:07,120 --> 00:17:12,319
camera as of now

00:17:08,240 --> 00:17:15,520
we have uh uvc uh like your usb webcams

00:17:12,319 --> 00:17:18,240
ipo3 is supported rockchip vmc

00:17:15,520 --> 00:17:19,760
which is a test driver and we do a lot

00:17:18,240 --> 00:17:23,199
of testing

00:17:19,760 --> 00:17:26,160
uh like for uh not have not

00:17:23,199 --> 00:17:27,280
uh if we don't have some hardware or

00:17:26,160 --> 00:17:30,799
something

00:17:27,280 --> 00:17:34,160
uh and uh

00:17:30,799 --> 00:17:36,720
for raspberry pi uh we also have

00:17:34,160 --> 00:17:37,520
uh working with raspberry pi folks uh

00:17:36,720 --> 00:17:41,039
for

00:17:37,520 --> 00:17:46,480
the uh for the support

00:17:41,039 --> 00:17:49,280
uh in lip camera uh

00:17:46,480 --> 00:17:49,919
flip camera api so let's talk about uh

00:17:49,280 --> 00:17:53,360
something

00:17:49,919 --> 00:17:55,919
uh which is the core uh

00:17:53,360 --> 00:17:58,080
of this talk uh i want to just give an

00:17:55,919 --> 00:17:59,840
overview how the api and how would uh

00:17:58,080 --> 00:18:01,919
application would interact with lip

00:17:59,840 --> 00:18:05,039
camera so

00:18:01,919 --> 00:18:07,280
basically five things uh we have camera

00:18:05,039 --> 00:18:09,600
manager we talked about a little bit

00:18:07,280 --> 00:18:11,280
which will do the camera emulation which

00:18:09,600 --> 00:18:12,400
will find all the devices attached to

00:18:11,280 --> 00:18:15,679
your system

00:18:12,400 --> 00:18:18,000
then we have camera configuration uh

00:18:15,679 --> 00:18:19,120
which will just set up the camera

00:18:18,000 --> 00:18:22,160
prepare it for

00:18:19,120 --> 00:18:23,120
for the intended use we have config

00:18:22,160 --> 00:18:25,919
validation

00:18:23,120 --> 00:18:26,559
of like if the application has specific

00:18:25,919 --> 00:18:29,280
requests

00:18:26,559 --> 00:18:31,520
suppose an application wants to capture

00:18:29,280 --> 00:18:34,080
a specific format

00:18:31,520 --> 00:18:35,280
or a specific structure at specific

00:18:34,080 --> 00:18:37,440
resolution

00:18:35,280 --> 00:18:39,360
the application can request it through

00:18:37,440 --> 00:18:41,520
the configuration and

00:18:39,360 --> 00:18:43,039
it will be sent back to the camera for

00:18:41,520 --> 00:18:45,440
that validation

00:18:43,039 --> 00:18:46,480
after that process happens it's just

00:18:45,440 --> 00:18:49,760
allocating same

00:18:46,480 --> 00:18:52,960
some buffers for the data being written

00:18:49,760 --> 00:18:56,160
and finally we have the frame capture

00:18:52,960 --> 00:18:58,559
so let's try to map it out a bit in into

00:18:56,160 --> 00:18:58,559
the code

00:19:05,840 --> 00:19:10,480
camera enumeration camera manager we

00:19:08,640 --> 00:19:11,919
have we make a new camera manager we

00:19:10,480 --> 00:19:14,640
start the camera manager

00:19:11,919 --> 00:19:16,640
which will like set up pipelines set up

00:19:14,640 --> 00:19:19,919
or find all the devices

00:19:16,640 --> 00:19:23,440
uh and make camera objects

00:19:19,919 --> 00:19:26,640
and you can you can retrieve the camera

00:19:23,440 --> 00:19:29,120
from camera managers with the cameras

00:19:26,640 --> 00:19:31,120
api we just iterate over them and we

00:19:29,120 --> 00:19:39,840
just print an id

00:19:31,120 --> 00:19:39,840
so a camera animation

00:19:40,960 --> 00:19:44,640
uh let's talk about camera configuration

00:19:43,280 --> 00:19:46,640
after we have uh

00:19:44,640 --> 00:19:48,080
got the cameras we select the first

00:19:46,640 --> 00:19:51,120
camera we have so

00:19:48,080 --> 00:19:52,880
zero is the first camera suppose uh we

00:19:51,120 --> 00:19:54,880
get a pointer to it

00:19:52,880 --> 00:19:56,160
we acquire a camera so this is an

00:19:54,880 --> 00:19:59,360
exclusive lock once

00:19:56,160 --> 00:20:00,000
a camera has been acquired no other

00:19:59,360 --> 00:20:03,280
application

00:20:00,000 --> 00:20:06,640
will be granted access to that camera uh

00:20:03,280 --> 00:20:09,679
for the time until it is released

00:20:06,640 --> 00:20:13,039
uh so after the camera has been acquired

00:20:09,679 --> 00:20:14,960
it is just um uh uh we would generate a

00:20:13,039 --> 00:20:15,280
configuration and for the configuration

00:20:14,960 --> 00:20:18,080
we

00:20:15,280 --> 00:20:18,720
specify a stream role stream rule is

00:20:18,080 --> 00:20:21,679
basically

00:20:18,720 --> 00:20:23,600
is what's the intent of the use uh so

00:20:21,679 --> 00:20:26,720
basically you can

00:20:23,600 --> 00:20:27,679
uh tell it's a still capture or it's a

00:20:26,720 --> 00:20:31,200
raw capture

00:20:27,679 --> 00:20:33,039
or it's a video capture or something

00:20:31,200 --> 00:20:35,440
else

00:20:33,039 --> 00:20:37,120
so accordingly uh the camera will

00:20:35,440 --> 00:20:41,440
generate a configuration

00:20:37,120 --> 00:20:41,440
uh and store it in config

00:20:43,520 --> 00:20:46,559
uh now comes the validation part so

00:20:46,080 --> 00:20:49,280
after

00:20:46,559 --> 00:20:50,159
a configuration has been uh camera

00:20:49,280 --> 00:20:53,280
configuration

00:20:50,159 --> 00:20:54,640
has been uh stored so

00:20:53,280 --> 00:20:56,960
what it contains is a stream

00:20:54,640 --> 00:20:57,679
configuration so stream configuration is

00:20:56,960 --> 00:21:00,960
nothing but

00:20:57,679 --> 00:21:03,520
a specific uh configuration for

00:21:00,960 --> 00:21:05,360
each stream like you can ask for

00:21:03,520 --> 00:21:07,360
multiple stream roles or

00:21:05,360 --> 00:21:09,840
other stream those so each will have a

00:21:07,360 --> 00:21:13,520
specific stream configuration

00:21:09,840 --> 00:21:15,280
and uh you can uh suppose uh this is the

00:21:13,520 --> 00:21:16,400
stream configuration the camera has

00:21:15,280 --> 00:21:19,039
given you

00:21:16,400 --> 00:21:20,720
and default still capture configuration

00:21:19,039 --> 00:21:23,760
so this is the default one so if

00:21:20,720 --> 00:21:26,960
if i print this out you it will tell me

00:21:23,760 --> 00:21:30,000
it will capture at uh 1280

00:21:26,960 --> 00:21:33,600
or 720 p uh

00:21:30,000 --> 00:21:36,400
resolution with the format being mjpeg

00:21:33,600 --> 00:21:38,080
and uh uh let's say i'm not satisfied

00:21:36,400 --> 00:21:41,039
with this configuration so

00:21:38,080 --> 00:21:41,440
i can uh i as an application developer

00:21:41,039 --> 00:21:45,039
can

00:21:41,440 --> 00:21:47,760
write uh let's see uh i will give

00:21:45,039 --> 00:21:49,360
uh i want to capture at width 640 and

00:21:47,760 --> 00:21:52,640
height 480

00:21:49,360 --> 00:21:54,880
so i will just uh try to amend these two

00:21:52,640 --> 00:21:56,480
parameters and again i will try to

00:21:54,880 --> 00:22:00,400
validate the conflict

00:21:56,480 --> 00:22:02,320
so what happens here is if if uh

00:22:00,400 --> 00:22:04,720
if the camera can provide this

00:22:02,320 --> 00:22:04,960
resolution it will just simply validate

00:22:04,720 --> 00:22:08,159
it

00:22:04,960 --> 00:22:10,799
if it doesn't uh it

00:22:08,159 --> 00:22:11,440
will give the nearest uh configuration

00:22:10,799 --> 00:22:13,840
so suppose

00:22:11,440 --> 00:22:16,400
if this is not supported here then a

00:22:13,840 --> 00:22:19,520
lower one is supported for suppose uh

00:22:16,400 --> 00:22:20,960
320 into 180 so it will just try to

00:22:19,520 --> 00:22:24,320
amend this and give you

00:22:20,960 --> 00:22:26,559
320 and 180 or similarly or if you go

00:22:24,320 --> 00:22:29,440
higher it will try to get it but

00:22:26,559 --> 00:22:32,080
if it doesn't have it will just keep it

00:22:29,440 --> 00:22:32,080
as default

00:22:36,559 --> 00:22:42,000
sorry after the configuration

00:22:40,080 --> 00:22:43,600
phase has happened we will just allocate

00:22:42,000 --> 00:22:47,200
some buffers

00:22:43,600 --> 00:22:49,360
so you can use your own allocator all

00:22:47,200 --> 00:22:51,440
lip cameras provides one for you

00:22:49,360 --> 00:22:54,400
it's a frame buffer allocator it will

00:22:51,440 --> 00:22:56,159
iterate over the stream configuration

00:22:54,400 --> 00:22:57,840
you can like a camera can ask for

00:22:56,159 --> 00:23:00,880
multiple streams uh as

00:22:57,840 --> 00:23:01,760
we talked about so basically uh i can

00:23:00,880 --> 00:23:05,200
ask for

00:23:01,760 --> 00:23:08,799
a stream where i want to look

00:23:05,200 --> 00:23:11,440
look at the camera is just streaming

00:23:08,799 --> 00:23:13,840
all the frames but i want at a click of

00:23:11,440 --> 00:23:16,880
a button i want a frame to be saved to

00:23:13,840 --> 00:23:19,520
a to a disk so camera can ask for

00:23:16,880 --> 00:23:20,960
like something like np12 and mjpeg so

00:23:19,520 --> 00:23:23,760
nv12 will

00:23:20,960 --> 00:23:25,520
just keep the stream going on in my

00:23:23,760 --> 00:23:27,919
application window and when i hit

00:23:25,520 --> 00:23:29,280
like capture uh it will just use the

00:23:27,919 --> 00:23:31,440
mjpeg stream

00:23:29,280 --> 00:23:32,720
and capture that frame in m jpeg and

00:23:31,440 --> 00:23:35,039
save it to the disk

00:23:32,720 --> 00:23:35,919
so you know in a way like application

00:23:35,039 --> 00:23:39,200
can ask

00:23:35,919 --> 00:23:41,520
multiple from the camera itself so for

00:23:39,200 --> 00:23:44,960
each stream you have to allocate

00:23:41,520 --> 00:23:46,960
buffers uh so it will we will iterate

00:23:44,960 --> 00:23:49,039
from the configuration we would iterate

00:23:46,960 --> 00:23:52,400
on each stream configuration and

00:23:49,039 --> 00:23:55,360
allocate buffers uh

00:23:52,400 --> 00:23:56,320
it simply allocates uh like required

00:23:55,360 --> 00:23:59,520
number of buffers

00:23:56,320 --> 00:24:02,960
it thinks it can but i am sure you can

00:23:59,520 --> 00:24:03,440
specify your own uh set of requirements

00:24:02,960 --> 00:24:06,720
as well

00:24:03,440 --> 00:24:06,720
for the buffer allocation

00:24:08,320 --> 00:24:11,440
uh now comes the frame capture part so

00:24:11,039 --> 00:24:14,960
after

00:24:11,440 --> 00:24:18,080
allocating buffers you uh you can create

00:24:14,960 --> 00:24:20,640
a request to the camera uh

00:24:18,080 --> 00:24:21,360
where request is at least one stream

00:24:20,640 --> 00:24:23,679
like

00:24:21,360 --> 00:24:25,760
one stream from the stream configuration

00:24:23,679 --> 00:24:27,440
and the frame buffer you have got uh

00:24:25,760 --> 00:24:29,679
like from the previous slide

00:24:27,440 --> 00:24:31,520
so request is nothing but one stream one

00:24:29,679 --> 00:24:32,799
buffer and you just skew it to the

00:24:31,520 --> 00:24:36,400
camera

00:24:32,799 --> 00:24:37,200
after after the request are queued to

00:24:36,400 --> 00:24:40,240
the camera you

00:24:37,200 --> 00:24:44,000
just run camera start and it will start

00:24:40,240 --> 00:24:46,720
uh writing data to those buffers

00:24:44,000 --> 00:24:47,120
and after uh like where how do you know

00:24:46,720 --> 00:24:49,200
like

00:24:47,120 --> 00:24:51,520
when the buffer is full because you will

00:24:49,200 --> 00:24:53,679
know when the camera has

00:24:51,520 --> 00:24:55,120
uh emitted the request completed signal

00:24:53,679 --> 00:24:59,039
and thereafter in the

00:24:55,120 --> 00:25:00,720
signal handler you can just go and uh

00:24:59,039 --> 00:25:03,440
take out the buffers from the request

00:25:00,720 --> 00:25:07,760
object and simply you can

00:25:03,440 --> 00:25:10,400
just do like your frame capture is

00:25:07,760 --> 00:25:10,400
then complete

00:25:11,360 --> 00:25:15,919
uh lib camera sample applications we

00:25:13,840 --> 00:25:18,320
have we use a cam utility which

00:25:15,919 --> 00:25:19,039
is a swiss knife it's a testing tool

00:25:18,320 --> 00:25:20,720
it's

00:25:19,039 --> 00:25:22,480
but it's uh it has got all the

00:25:20,720 --> 00:25:25,919
configuration options

00:25:22,480 --> 00:25:28,799
we have qcam qt based queue

00:25:25,919 --> 00:25:31,120
gui application we also have simple cam

00:25:28,799 --> 00:25:33,120
if you just want to read

00:25:31,120 --> 00:25:34,799
like the minimal reference code as we

00:25:33,120 --> 00:25:36,960
did just right now

00:25:34,799 --> 00:25:37,840
so you can just look at the simple cam

00:25:36,960 --> 00:25:41,120
uh and try

00:25:37,840 --> 00:25:42,159
running it and reading it's over

00:25:41,120 --> 00:25:45,120
commented

00:25:42,159 --> 00:25:46,080
so you will have a good grasp on how to

00:25:45,120 --> 00:25:49,279
write a

00:25:46,080 --> 00:25:50,640
application with lip camera there is

00:25:49,279 --> 00:25:52,559
decent documentation

00:25:50,640 --> 00:25:57,840
and app developers guide in the tree

00:25:52,559 --> 00:25:57,840
itself uh you can also look into that

00:25:59,679 --> 00:26:04,520
so yeah please join our live camera is a

00:26:01,679 --> 00:26:08,400
young project it started around

00:26:04,520 --> 00:26:08,799
2018 maybe yeah i'm not trying but yeah

00:26:08,400 --> 00:26:13,039
somewhere

00:26:08,799 --> 00:26:14,080
around 2018 uh docs patches link uh we

00:26:13,039 --> 00:26:17,840
have of

00:26:14,080 --> 00:26:20,240
uh irc channel lift camera on free node

00:26:17,840 --> 00:26:22,080
and we welcome inputs from anyone

00:26:20,240 --> 00:26:25,520
working with cameras

00:26:22,080 --> 00:26:28,400
i think that's all from me and i guess i

00:26:25,520 --> 00:26:28,400
can take questions

00:26:36,840 --> 00:26:39,840
now

00:26:41,919 --> 00:26:48,000
hi thank you for your talk um we have

00:26:45,039 --> 00:26:50,240
a few questions from for you you can

00:26:48,000 --> 00:26:54,480
check those at the shared note

00:26:50,240 --> 00:26:54,480
uh section here in the big blue button

00:27:01,600 --> 00:27:07,919
yeah i see the questions uh will it be

00:27:04,640 --> 00:27:09,200
possible to use ipo cameras from v4l to

00:27:07,919 --> 00:27:13,120
then

00:27:09,200 --> 00:27:17,679
uh yes i think so it can be used

00:27:13,120 --> 00:27:17,679
um but uh

00:27:18,320 --> 00:27:25,120
i i uh v4 l2 you will have also have to

00:27:22,480 --> 00:27:25,520
tackle the media controller api from the

00:27:25,120 --> 00:27:29,840
uh

00:27:25,520 --> 00:27:29,840
kernel itself and

00:27:31,520 --> 00:27:34,880
is it to be done with fallback devices

00:27:33,760 --> 00:27:36,799
i'm not sure

00:27:34,880 --> 00:27:38,880
i understand what you mean by fallback

00:27:36,799 --> 00:27:40,799
devices

00:27:38,880 --> 00:27:42,240
uh doesn't interact with tools like

00:27:40,799 --> 00:27:46,399
gstreamer yes we have

00:27:42,240 --> 00:27:51,039
our element g streamer element

00:27:46,399 --> 00:27:52,960
uh and i think there's good support

00:27:51,039 --> 00:27:56,320
uh because it was written by g streamer

00:27:52,960 --> 00:27:58,799
developers so and pipe fire by fire i

00:27:56,320 --> 00:28:02,240
think there is some work in progress

00:27:58,799 --> 00:28:05,120
going on

00:28:02,240 --> 00:28:06,159
regarding pipefire so basically uh as

00:28:05,120 --> 00:28:09,120
far as i know

00:28:06,159 --> 00:28:09,840
pipefire likes to ask the system

00:28:09,120 --> 00:28:13,360
resources

00:28:09,840 --> 00:28:15,840
upfront uh but uh lip camera what it

00:28:13,360 --> 00:28:16,559
does it's allocate resources on the fly

00:28:15,840 --> 00:28:20,080
so there

00:28:16,559 --> 00:28:23,360
is like a some bit of mismatch

00:28:20,080 --> 00:28:24,159
uh that we don't have or like a right

00:28:23,360 --> 00:28:28,960
robust

00:28:24,159 --> 00:28:30,640
support as of now but i think uh

00:28:28,960 --> 00:28:32,480
so us there was a discussion on the

00:28:30,640 --> 00:28:37,360
mailing list as far as i know so

00:28:32,480 --> 00:28:39,520
it's still um i think

00:28:37,360 --> 00:28:41,039
some people will bash their heads on it

00:28:39,520 --> 00:28:44,640
as well

00:28:41,039 --> 00:28:48,080
uh will chromium firefox support this

00:28:44,640 --> 00:28:51,679
uh i hope so chromium

00:28:48,080 --> 00:28:54,960
we are working with chromium developers

00:28:51,679 --> 00:28:58,320
uh for chromium os so that's the first

00:28:54,960 --> 00:29:01,679
uh um

00:28:58,320 --> 00:29:04,720
parts to make it work there uh

00:29:01,679 --> 00:29:07,760
and i hope uh if if you have like

00:29:04,720 --> 00:29:11,120
in the chromium os there is like a it

00:29:07,760 --> 00:29:13,919
goes into as a shared library so if you

00:29:11,120 --> 00:29:14,799
just replace it with with what chromium

00:29:13,919 --> 00:29:17,039
oil ships the

00:29:14,799 --> 00:29:19,120
browser the native camera app will start

00:29:17,039 --> 00:29:22,880
using the lip camera

00:29:19,120 --> 00:29:23,840
so yeah i'm not sure of firefox size i

00:29:22,880 --> 00:29:27,520
have not been

00:29:23,840 --> 00:29:27,520
uh actively

00:29:27,840 --> 00:29:38,240

YouTube URL: https://www.youtube.com/watch?v=Vm66MPVwec4


