Title: Responsible AI in Banking - Ranadip Chatterjee & Christos Aniftos, Google
Publication date: 2020-12-22
Playlist: FINOS Open Source Strategy Forum 2020
Description: 
	Responsible AI in Banking - Ranadip Chatterjee & Christos Aniftos, Google
Captions: 
	00:00:07,759 --> 00:00:11,360
hello everyone

00:00:09,120 --> 00:00:13,200
welcome to this talk on responsible ai

00:00:11,360 --> 00:00:15,440
in banking

00:00:13,200 --> 00:00:17,440
artificial intelligence or ai has

00:00:15,440 --> 00:00:19,520
remarkably improved our ability to

00:00:17,440 --> 00:00:21,119
predict outcomes much more reliably than

00:00:19,520 --> 00:00:22,800
ever before

00:00:21,119 --> 00:00:25,840
the progress and availability of these

00:00:22,800 --> 00:00:27,519
tools in a simple and scalable way

00:00:25,840 --> 00:00:28,880
have meant that businesses can have far

00:00:27,519 --> 00:00:30,960
deeper insights and

00:00:28,880 --> 00:00:33,280
look forward capabilities than say 10 to

00:00:30,960 --> 00:00:34,480
15 years back

00:00:33,280 --> 00:00:36,399
used in the right ways these

00:00:34,480 --> 00:00:38,480
capabilities can enable businesses

00:00:36,399 --> 00:00:40,960
to provide far more relevant offers and

00:00:38,480 --> 00:00:42,640
better experience to their customers

00:00:40,960 --> 00:00:44,640
this has enabled businesses to improve

00:00:42,640 --> 00:00:46,079
their revenues improve nps course of

00:00:44,640 --> 00:00:48,559
their products and services

00:00:46,079 --> 00:00:51,680
and generally establish a more trusted

00:00:48,559 --> 00:00:54,079
relationship with their customers

00:00:51,680 --> 00:00:55,680
however as with all great powers comes

00:00:54,079 --> 00:00:57,600
greater responsibilities

00:00:55,680 --> 00:00:58,800
we need to be mindful of the dangers and

00:00:57,600 --> 00:01:01,680
the pitfalls which

00:00:58,800 --> 00:01:03,760
we may come by if we are not careful

00:01:01,680 --> 00:01:06,080
many advanced machine learning models

00:01:03,760 --> 00:01:07,200
are not as transparent and easy to

00:01:06,080 --> 00:01:09,280
understand

00:01:07,200 --> 00:01:10,880
they can encapsulate a lot of complex

00:01:09,280 --> 00:01:12,240
logic

00:01:10,880 --> 00:01:14,799
and between the crevices of these

00:01:12,240 --> 00:01:15,840
complexities can lie uh dangerous biases

00:01:14,799 --> 00:01:17,600
and bugs

00:01:15,840 --> 00:01:19,040
they can hide seemingly innocuous but

00:01:17,600 --> 00:01:22,960
potentially illegal and

00:01:19,040 --> 00:01:24,720
unethical reasoning in order to be

00:01:22,960 --> 00:01:26,240
responsible users of this powerful

00:01:24,720 --> 00:01:27,840
paradigm called ai

00:01:26,240 --> 00:01:30,560
we need to be on the top of and in

00:01:27,840 --> 00:01:33,280
control of these risks

00:01:30,560 --> 00:01:34,640
the good news is that in recent years

00:01:33,280 --> 00:01:36,400
there has been a number of different

00:01:34,640 --> 00:01:39,360
tools and techniques which have

00:01:36,400 --> 00:01:41,200
come by and these can enable us to

00:01:39,360 --> 00:01:42,240
control and mitigate this risk all the

00:01:41,200 --> 00:01:44,159
while we can

00:01:42,240 --> 00:01:46,320
focus on improving revenue and continue

00:01:44,159 --> 00:01:48,000
to get our customers love

00:01:46,320 --> 00:01:50,240
so in today's talk we will be exploring

00:01:48,000 --> 00:01:53,439
some of these tools and where and how we

00:01:50,240 --> 00:01:57,119
can use them to stay safe

00:01:53,439 --> 00:01:59,200
so with that let's introduce ourselves

00:01:57,119 --> 00:02:01,360
i am ranadev chatterjee i'm a data

00:01:59,200 --> 00:02:03,119
analyst specialist working google cloud

00:02:01,360 --> 00:02:06,719
i'm based in london and i mainly work

00:02:03,119 --> 00:02:06,719
with financial services customers

00:02:07,119 --> 00:02:11,440
and then christos a machine learning

00:02:09,280 --> 00:02:14,720
specialist working for google cloud

00:02:11,440 --> 00:02:14,720
also based in london

00:02:16,560 --> 00:02:19,760
let's look at a story to guide us

00:02:17,920 --> 00:02:21,840
through this talk

00:02:19,760 --> 00:02:23,680
this is a work of pure fiction but any

00:02:21,840 --> 00:02:25,040
resemblance to the real life

00:02:23,680 --> 00:02:27,760
is intentional and not merely

00:02:25,040 --> 00:02:30,879
coincidental

00:02:27,760 --> 00:02:32,560
so our two friends jess and nick no they

00:02:30,879 --> 00:02:33,200
are not a couple this is not a romantic

00:02:32,560 --> 00:02:36,879
story

00:02:33,200 --> 00:02:39,680
um let's see what happens next but

00:02:36,879 --> 00:02:41,360
uh uh let's consider our two friends

00:02:39,680 --> 00:02:43,280
jess and nick

00:02:41,360 --> 00:02:45,040
two young professionals they don't know

00:02:43,280 --> 00:02:46,720
each other and they are both dreaming

00:02:45,040 --> 00:02:50,239
about buying their first homes

00:02:46,720 --> 00:02:51,760
and getting on the property ladder

00:02:50,239 --> 00:02:53,760
so they don't know too much about

00:02:51,760 --> 00:02:55,840
mortgages and credits

00:02:53,760 --> 00:02:57,360
and though they have had a few years of

00:02:55,840 --> 00:02:58,159
pretty steady relationship with their

00:02:57,360 --> 00:03:01,599
banks

00:02:58,159 --> 00:03:01,599
mainly through current accounts and some

00:03:02,840 --> 00:03:06,959
deposits

00:03:04,080 --> 00:03:08,400
so here on the top on this slide is jess

00:03:06,959 --> 00:03:10,720
no she's not always upset

00:03:08,400 --> 00:03:12,000
it's just me being lazy and not finding

00:03:10,720 --> 00:03:15,840
a smiling picture of her

00:03:12,000 --> 00:03:18,080
so she's fine so just has been working

00:03:15,840 --> 00:03:21,440
for the last three years and has had a

00:03:18,080 --> 00:03:22,400
pretty stable job she banks with kansai

00:03:21,440 --> 00:03:24,239
bank

00:03:22,400 --> 00:03:26,000
and she has had a steady relationship

00:03:24,239 --> 00:03:27,599
with the bank for all of this time

00:03:26,000 --> 00:03:30,080
mainly through her current account and

00:03:27,599 --> 00:03:33,360
some savings

00:03:30,080 --> 00:03:34,799
and lately she has uh seen this new

00:03:33,360 --> 00:03:38,400
apartment block come up

00:03:34,799 --> 00:03:39,920
close by and uh she is she fancies a two

00:03:38,400 --> 00:03:41,360
better there and she's looking to get

00:03:39,920 --> 00:03:44,959
onto the property ladder

00:03:41,360 --> 00:03:47,040
uh being a first-time buyer uh and uh

00:03:44,959 --> 00:03:48,959
not knowing much about mortgages she

00:03:47,040 --> 00:03:52,159
just uh approaches her

00:03:48,959 --> 00:03:54,959
um a normal everyday bank accounts event

00:03:52,159 --> 00:03:54,959
for the mortgage

00:03:55,439 --> 00:04:00,159
and down here is nick so here on the

00:03:58,720 --> 00:04:01,120
other hand is a little bit more

00:04:00,159 --> 00:04:03,519
adventurous

00:04:01,120 --> 00:04:06,159
so he he likes the idea of being

00:04:03,519 --> 00:04:09,360
independent and having his own business

00:04:06,159 --> 00:04:11,280
so he works contracts for the money and

00:04:09,360 --> 00:04:12,080
is saving and also slowly building up

00:04:11,280 --> 00:04:14,319
his business

00:04:12,080 --> 00:04:15,599
uh mainly working in between contracts

00:04:14,319 --> 00:04:18,400
and uh

00:04:15,599 --> 00:04:19,280
additional money that he's getting so he

00:04:18,400 --> 00:04:21,280
has also been

00:04:19,280 --> 00:04:22,960
uh working for the last four or five

00:04:21,280 --> 00:04:24,479
years and has been lucky to get uh

00:04:22,960 --> 00:04:27,759
regular work

00:04:24,479 --> 00:04:29,600
and he banks with telugu back and again

00:04:27,759 --> 00:04:30,880
all this was the last four five years he

00:04:29,600 --> 00:04:32,880
has had a steady relationship with

00:04:30,880 --> 00:04:36,320
telugu bank

00:04:32,880 --> 00:04:39,440
so coincidentally nick also decides to

00:04:36,320 --> 00:04:41,440
get onto the property ladder and he's

00:04:39,440 --> 00:04:43,120
also attracted by this nice apartment

00:04:41,440 --> 00:04:47,040
block that's coming up

00:04:43,120 --> 00:04:49,440
and he also plans to buy a flat there

00:04:47,040 --> 00:04:51,360
so he's slightly more savvy than jess

00:04:49,440 --> 00:04:52,000
about finances being in business and all

00:04:51,360 --> 00:04:54,240
that

00:04:52,000 --> 00:04:56,240
but he's very busy and he doesn't have

00:04:54,240 --> 00:04:57,520
time so he just goes to his standard

00:04:56,240 --> 00:05:00,800
bank telu bank

00:04:57,520 --> 00:05:02,160
and requests for mortgage now both

00:05:00,800 --> 00:05:03,919
constant telu bank use

00:05:02,160 --> 00:05:06,080
instant mortgage account processes using

00:05:03,919 --> 00:05:11,360
ai engines to encapsulate their mortgage

00:05:06,080 --> 00:05:13,199
approval process

00:05:11,360 --> 00:05:15,759
so as in every nice story here comes the

00:05:13,199 --> 00:05:18,400
twist jesus mortgage application gets

00:05:15,759 --> 00:05:20,080
rejected by cancer bank

00:05:18,400 --> 00:05:21,759
and true to their name they haven't

00:05:20,080 --> 00:05:22,320
provided a reason they said they can't

00:05:21,759 --> 00:05:25,120
say

00:05:22,320 --> 00:05:28,320
that reason for the rejection it's

00:05:25,120 --> 00:05:30,639
against their company policies

00:05:28,320 --> 00:05:32,479
so jesse is left wondering why she

00:05:30,639 --> 00:05:34,400
doesn't know what she can do to

00:05:32,479 --> 00:05:35,840
get that mortgage and she's really

00:05:34,400 --> 00:05:37,520
disappointed that she

00:05:35,840 --> 00:05:40,000
cannot get onto the property ladder and

00:05:37,520 --> 00:05:42,000
she cannot buy her dream home

00:05:40,000 --> 00:05:43,440
neither does she like her bank anymore

00:05:42,000 --> 00:05:47,280
because of the

00:05:43,440 --> 00:05:47,280
unhelpful attitude that they have shown

00:05:47,759 --> 00:05:51,039
now looks can be deceptive

00:05:51,199 --> 00:05:55,759
even though we see here nick is smiling

00:05:52,800 --> 00:05:57,520
but his mortgage has got rejected too

00:05:55,759 --> 00:06:00,400
but he has some reasons for being a

00:05:57,520 --> 00:06:03,520
little bit happy uh happier than jess

00:06:00,400 --> 00:06:06,080
because his bank has told him uh the key

00:06:03,520 --> 00:06:07,759
factors that affected the decision like

00:06:06,080 --> 00:06:09,919
his credit score is too low

00:06:07,759 --> 00:06:11,440
his monthly outgoings are too high for

00:06:09,919 --> 00:06:13,759
his income

00:06:11,440 --> 00:06:16,960
and maybe the period left in his current

00:06:13,759 --> 00:06:16,960
contract is too short

00:06:17,520 --> 00:06:20,880
and what's more the edu bank has told

00:06:20,240 --> 00:06:23,759
nick

00:06:20,880 --> 00:06:27,199
how he can improve his chances of

00:06:23,759 --> 00:06:30,240
qualifying for that elusive mortgage

00:06:27,199 --> 00:06:32,240
so now he can plan his uh

00:06:30,240 --> 00:06:34,240
next steps he can prioritize what he

00:06:32,240 --> 00:06:36,319
wants to do and he knows exactly what

00:06:34,240 --> 00:06:38,479
sort of steps he might take in order to

00:06:36,319 --> 00:06:40,720
go on to the property ladder and own his

00:06:38,479 --> 00:06:43,520
dream home

00:06:40,720 --> 00:06:44,319
now let's imagine councilman takes on

00:06:43,520 --> 00:06:47,919
board

00:06:44,319 --> 00:06:50,080
jesus feedback and realizes that they

00:06:47,919 --> 00:06:51,840
are losing their customers trust and

00:06:50,080 --> 00:06:52,800
customers are not happy and going to

00:06:51,840 --> 00:06:56,400
their

00:06:52,800 --> 00:06:58,160
competitor telu bank so they quickly uh

00:06:56,400 --> 00:06:58,880
crank up some transparency features in

00:06:58,160 --> 00:07:01,280
haste

00:06:58,880 --> 00:07:02,000
without due consideration of the risks

00:07:01,280 --> 00:07:05,360
so what can go

00:07:02,000 --> 00:07:06,960
wrong well problems or weaknesses in

00:07:05,360 --> 00:07:08,639
their models can manifest in many

00:07:06,960 --> 00:07:10,000
damaging ways

00:07:08,639 --> 00:07:11,440
maybe they had some issues with the

00:07:10,000 --> 00:07:12,080
input data that was used to train the

00:07:11,440 --> 00:07:13,520
model

00:07:12,080 --> 00:07:16,400
and now the model is biased against

00:07:13,520 --> 00:07:18,560
women for example now

00:07:16,400 --> 00:07:19,599
was it intentional of the bank to do

00:07:18,560 --> 00:07:22,639
this

00:07:19,599 --> 00:07:22,639
is it even ethical

00:07:23,680 --> 00:07:27,599
there can be other unintended behavior

00:07:25,440 --> 00:07:29,680
as well if we are not careful

00:07:27,599 --> 00:07:31,520
for example the model might say that

00:07:29,680 --> 00:07:34,080
jess's income is too low

00:07:31,520 --> 00:07:35,120
now that might be the result of skewness

00:07:34,080 --> 00:07:37,120
in data maybe

00:07:35,120 --> 00:07:38,240
the data that was used to train this

00:07:37,120 --> 00:07:40,000
model

00:07:38,240 --> 00:07:42,000
had a whole lot of data coming from new

00:07:40,000 --> 00:07:43,680
york because there might be more

00:07:42,000 --> 00:07:45,840
customers based in new york for this

00:07:43,680 --> 00:07:47,759
particular bank

00:07:45,840 --> 00:07:49,360
now what the model has learned here is

00:07:47,759 --> 00:07:52,080
that the average uh

00:07:49,360 --> 00:07:53,360
salary drawn by new yorker is the

00:07:52,080 --> 00:07:56,560
standard salary

00:07:53,360 --> 00:07:58,080
and for for even smaller towns

00:07:56,560 --> 00:08:00,240
and so when jess applies for the

00:07:58,080 --> 00:08:02,000
mortgage even though her salary might be

00:08:00,240 --> 00:08:03,280
quite fine for this apartment that she

00:08:02,000 --> 00:08:05,360
is looking for

00:08:03,280 --> 00:08:07,360
the model has wrongly rejected her

00:08:05,360 --> 00:08:08,879
application

00:08:07,360 --> 00:08:10,800
and there could be other things as well

00:08:08,879 --> 00:08:12,639
like it might be discriminating based on

00:08:10,800 --> 00:08:14,560
physical disabilities which may be

00:08:12,639 --> 00:08:16,800
completely unintended and might even be

00:08:14,560 --> 00:08:18,240
illegal in some jurisdictions

00:08:16,800 --> 00:08:20,080
it might be considering completely

00:08:18,240 --> 00:08:22,160
absurd factors like whether somebody is

00:08:20,080 --> 00:08:24,400
a coffee drinker say for example

00:08:22,160 --> 00:08:26,319
and this might be the reason because

00:08:24,400 --> 00:08:26,800
absurd data has not been removed from

00:08:26,319 --> 00:08:28,400
the

00:08:26,800 --> 00:08:30,960
training data and due to some

00:08:28,400 --> 00:08:32,800
coincidental patterns in this data

00:08:30,960 --> 00:08:36,399
the the machine has actually picked up

00:08:32,800 --> 00:08:37,919
that as one of the significant factors

00:08:36,399 --> 00:08:40,080
so in order to ensure that such

00:08:37,919 --> 00:08:42,159
unintended behavior is not passed on

00:08:40,080 --> 00:08:43,760
to the ai models a robust machine

00:08:42,159 --> 00:08:44,720
learning and model life cycle needs to

00:08:43,760 --> 00:08:45,920
be established

00:08:44,720 --> 00:08:48,000
with the right software and

00:08:45,920 --> 00:08:50,000
organizational checks in place

00:08:48,000 --> 00:08:52,480
to ensure consistent and intended

00:08:50,000 --> 00:08:52,480
results

00:08:52,720 --> 00:08:58,399
internal processes uh in ai such as ai

00:08:56,320 --> 00:09:00,959
project governance for example

00:08:58,399 --> 00:09:02,720
can establish an ethics approval process

00:09:00,959 --> 00:09:06,160
where when there is a new

00:09:02,720 --> 00:09:07,920
idea for using ai and then data

00:09:06,160 --> 00:09:09,519
scientists analysts and managers they

00:09:07,920 --> 00:09:10,560
need to be educated on the concepts of

00:09:09,519 --> 00:09:12,959
ethical ai

00:09:10,560 --> 00:09:15,120
risks of biases and bugs and potential

00:09:12,959 --> 00:09:18,480
negative outcomes that can come out of

00:09:15,120 --> 00:09:20,000
not being careful additionally

00:09:18,480 --> 00:09:21,760
we need to put in a framework in place

00:09:20,000 --> 00:09:23,440
that ensures that all the right controls

00:09:21,760 --> 00:09:24,560
and checks are in place when a model is

00:09:23,440 --> 00:09:26,160
built

00:09:24,560 --> 00:09:28,399
for this framework to work well in a

00:09:26,160 --> 00:09:30,000
scalable way we need to leverage tooling

00:09:28,399 --> 00:09:32,880
and techniques

00:09:30,000 --> 00:09:33,440
hence we need to invest in tooling at

00:09:32,880 --> 00:09:35,200
google

00:09:33,440 --> 00:09:37,360
we innovate and create tools that can

00:09:35,200 --> 00:09:38,640
help understand and validate data and ml

00:09:37,360 --> 00:09:40,399
models

00:09:38,640 --> 00:09:42,000
we open source these tools as we want to

00:09:40,399 --> 00:09:43,279
enable the ai community to build

00:09:42,000 --> 00:09:46,080
products that are ethical

00:09:43,279 --> 00:09:47,920
and responsible we open source tools for

00:09:46,080 --> 00:09:49,040
data exploration model analysis

00:09:47,920 --> 00:09:52,000
explainability

00:09:49,040 --> 00:09:53,600
and reporting in the rest of the talk we

00:09:52,000 --> 00:09:55,440
will take a look through some of these

00:09:53,600 --> 00:09:58,720
tools and techniques that can be used

00:09:55,440 --> 00:10:00,800
to adhere to responsible ai principles

00:09:58,720 --> 00:10:03,360
as example of principles that can guide

00:10:00,800 --> 00:10:06,240
the use of ai in a responsible manner

00:10:03,360 --> 00:10:07,920
here we show google's ai principles this

00:10:06,240 --> 00:10:12,240
can be accessed online by going to

00:10:07,920 --> 00:10:13,920
ai.google forward slash principles

00:10:12,240 --> 00:10:16,480
they are a set of objectives against

00:10:13,920 --> 00:10:18,959
which we assess our ai applications

00:10:16,480 --> 00:10:20,320
for example ai applications should be

00:10:18,959 --> 00:10:23,920
socially beneficial

00:10:20,320 --> 00:10:26,240
and avoid creating unfair bias

00:10:23,920 --> 00:10:27,200
they should be built and tested for

00:10:26,240 --> 00:10:28,720
safety

00:10:27,200 --> 00:10:30,959
and accountability should lie with

00:10:28,720 --> 00:10:32,480
humans

00:10:30,959 --> 00:10:34,320
on the other hand they should not be

00:10:32,480 --> 00:10:34,880
used in applications that are likely to

00:10:34,320 --> 00:10:36,800
cause

00:10:34,880 --> 00:10:38,880
overall harm or that violates

00:10:36,800 --> 00:10:40,720
internationally accepted norms and human

00:10:38,880 --> 00:10:42,959
rights

00:10:40,720 --> 00:10:45,120
every organization that uses ai should

00:10:42,959 --> 00:10:46,640
create their own set of principles based

00:10:45,120 --> 00:10:49,600
on their ethics and beliefs

00:10:46,640 --> 00:10:49,600
which they should honor

00:10:49,680 --> 00:10:52,720
with that i hand over to my co-speaker

00:10:52,079 --> 00:10:54,000
christos

00:10:52,720 --> 00:10:57,360
to take us to the rest of the

00:10:54,000 --> 00:10:58,640
presentation thank you randy

00:10:57,360 --> 00:11:01,279
let's see how we can leverage

00:10:58,640 --> 00:11:03,040
responsible ai in a machine learning

00:11:01,279 --> 00:11:05,600
life cycle

00:11:03,040 --> 00:11:07,760
a typical machine learning life cycle

00:11:05,600 --> 00:11:11,440
consists of several steps

00:11:07,760 --> 00:11:13,279
that take care of data ingestion

00:11:11,440 --> 00:11:14,880
data analysis training of the machine

00:11:13,279 --> 00:11:15,839
learning model deploying the machine

00:11:14,880 --> 00:11:19,360
learning model

00:11:15,839 --> 00:11:21,600
and then access the model

00:11:19,360 --> 00:11:22,720
given the previous example of a loan

00:11:21,600 --> 00:11:26,320
application

00:11:22,720 --> 00:11:28,880
then we can first of all gather previous

00:11:26,320 --> 00:11:30,640
loan applications data and the outcomes

00:11:28,880 --> 00:11:34,079
so if the loan was approved

00:11:30,640 --> 00:11:37,120
or not we can do data analysis

00:11:34,079 --> 00:11:39,839
and feature engineering then we train

00:11:37,120 --> 00:11:40,880
the loan approval model and we evaluate

00:11:39,839 --> 00:11:44,640
that the model

00:11:40,880 --> 00:11:45,839
is accurate enough before we put into

00:11:44,640 --> 00:11:47,519
production

00:11:45,839 --> 00:11:49,120
then we deploy a machinery model into

00:11:47,519 --> 00:11:51,680
production and then

00:11:49,120 --> 00:11:52,959
after that when there is a new loan

00:11:51,680 --> 00:11:56,079
application we can

00:11:52,959 --> 00:11:58,639
send the application details to

00:11:56,079 --> 00:12:00,639
an api for example and get back a

00:11:58,639 --> 00:12:03,360
prediction that says

00:12:00,639 --> 00:12:04,639
if an individual should be approved or

00:12:03,360 --> 00:12:07,040
declined

00:12:04,639 --> 00:12:07,040
alone

00:12:08,240 --> 00:12:11,839
with that in mind let's revisit the

00:12:09,760 --> 00:12:13,839
scenario of bias

00:12:11,839 --> 00:12:15,839
how could we ensure that we do not

00:12:13,839 --> 00:12:17,839
introduce bias in our data

00:12:15,839 --> 00:12:20,160
responsible ai expands beyond

00:12:17,839 --> 00:12:22,160
explanations or suggestions

00:12:20,160 --> 00:12:23,279
in this scenario we can see that the

00:12:22,160 --> 00:12:26,079
model is biasing

00:12:23,279 --> 00:12:28,000
based on gender why is gender so

00:12:26,079 --> 00:12:29,839
important for a loan approval

00:12:28,000 --> 00:12:31,519
one should wonder why gender is even

00:12:29,839 --> 00:12:34,560
part of the equation

00:12:31,519 --> 00:12:36,880
do we discriminate you need to ensure

00:12:34,560 --> 00:12:38,480
that ai models perform in an ethical and

00:12:36,880 --> 00:12:40,560
responsible manner

00:12:38,480 --> 00:12:41,519
of course you do not need to do that

00:12:40,560 --> 00:12:44,079
simply because

00:12:41,519 --> 00:12:45,760
the end user can see the explanations

00:12:44,079 --> 00:12:47,440
provided by the model

00:12:45,760 --> 00:12:49,760
you need to create a fair environment

00:12:47,440 --> 00:12:53,839
for your customers regardless if they

00:12:49,760 --> 00:12:53,839
know how the decisions are made or not

00:12:54,079 --> 00:12:59,519
biases can exist in data for example

00:12:57,760 --> 00:13:01,440
selection bias is when a selection of

00:12:59,519 --> 00:13:03,440
data points happen without proper

00:13:01,440 --> 00:13:04,800
randomization

00:13:03,440 --> 00:13:06,480
let's now go back to our loan

00:13:04,800 --> 00:13:08,480
application use case

00:13:06,480 --> 00:13:11,040
imagine that we're training our machine

00:13:08,480 --> 00:13:14,240
learning model using loan applications

00:13:11,040 --> 00:13:16,399
from a pool of new york applicants only

00:13:14,240 --> 00:13:18,079
this might result in misrepresentation

00:13:16,399 --> 00:13:21,279
of applicants in other cities

00:13:18,079 --> 00:13:23,120
as our ai model will not know much about

00:13:21,279 --> 00:13:25,600
those people

00:13:23,120 --> 00:13:27,200
another example is when historic data

00:13:25,600 --> 00:13:29,360
include marginalized groups

00:13:27,200 --> 00:13:31,680
that were treated unfairly in the past

00:13:29,360 --> 00:13:34,480
and had their loans declined

00:13:31,680 --> 00:13:36,720
by the use of such data the ai model

00:13:34,480 --> 00:13:38,240
will naively learn to discriminate those

00:13:36,720 --> 00:13:41,519
groups

00:13:38,240 --> 00:13:44,720
so to sum up biased data

00:13:41,519 --> 00:13:49,279
introduced an ai algorithm we produced

00:13:44,720 --> 00:13:51,279
a biased machine learning model

00:13:49,279 --> 00:13:52,880
of course another issue that can be

00:13:51,279 --> 00:13:56,240
introduced is the one

00:13:52,880 --> 00:13:57,839
of unintended treatments when we are

00:13:56,240 --> 00:14:00,240
analyzing our data

00:13:57,839 --> 00:14:02,079
and creating features we can use tools

00:14:00,240 --> 00:14:05,839
that can help us better understand

00:14:02,079 --> 00:14:08,399
our data for example facets

00:14:05,839 --> 00:14:10,880
facet is a tool that we use in order to

00:14:08,399 --> 00:14:13,199
slice and dice our data

00:14:10,880 --> 00:14:16,079
notice that this can be used before we

00:14:13,199 --> 00:14:18,240
build our machine learning models you

00:14:16,079 --> 00:14:20,079
can also use it when you want to analyze

00:14:18,240 --> 00:14:22,560
your data without building machine

00:14:20,079 --> 00:14:23,760
learning simply load your data and

00:14:22,560 --> 00:14:25,839
explore

00:14:23,760 --> 00:14:26,800
what you can see in this animation is

00:14:25,839 --> 00:14:29,360
how easy it

00:14:26,800 --> 00:14:31,760
is using facets to explore different age

00:14:29,360 --> 00:14:33,600
groups from your data

00:14:31,760 --> 00:14:35,600
you can visualize ages in different

00:14:33,600 --> 00:14:38,160
buckets color code based on

00:14:35,600 --> 00:14:40,079
relationship status and split based on

00:14:38,160 --> 00:14:42,639
martial status

00:14:40,079 --> 00:14:45,040
with this approach you can easily tell

00:14:42,639 --> 00:14:47,199
if there is a group missing

00:14:45,040 --> 00:14:48,399
what if you have no data for people

00:14:47,199 --> 00:14:51,600
between ages

00:14:48,399 --> 00:14:53,680
6 and 70 years old an age that a lot of

00:14:51,600 --> 00:14:55,760
people retire

00:14:53,680 --> 00:14:57,199
what would your model assume for this

00:14:55,760 --> 00:15:00,240
age group

00:14:57,199 --> 00:15:02,880
would it be accurate enough lastly

00:15:00,240 --> 00:15:03,440
facets is a tool which you can use for

00:15:02,880 --> 00:15:06,560
both

00:15:03,440 --> 00:15:07,760
structure and unstructured data so you

00:15:06,560 --> 00:15:10,000
can visually explore

00:15:07,760 --> 00:15:12,560
images and text viewers might

00:15:10,000 --> 00:15:14,560
discriminate indirectly like the fact

00:15:12,560 --> 00:15:15,760
that our customer receives a disability

00:15:14,560 --> 00:15:18,240
allowance

00:15:15,760 --> 00:15:18,880
the reasons may vary whether there is

00:15:18,240 --> 00:15:21,040
bias

00:15:18,880 --> 00:15:22,560
in our dataset or an underrepresented

00:15:21,040 --> 00:15:25,760
demographic group

00:15:22,560 --> 00:15:26,959
the problem is still there while we

00:15:25,760 --> 00:15:29,440
train our model

00:15:26,959 --> 00:15:30,639
we need to ensure that it is performing

00:15:29,440 --> 00:15:33,120
well overall

00:15:30,639 --> 00:15:34,399
but also for different slices of the

00:15:33,120 --> 00:15:37,120
data

00:15:34,399 --> 00:15:39,040
we need to be sure that it's treating

00:15:37,120 --> 00:15:42,399
all groups fairly

00:15:39,040 --> 00:15:45,199
and for that we need fairness indicators

00:15:42,399 --> 00:15:47,120
furnace indicators allow you to explore

00:15:45,199 --> 00:15:48,720
how your model performs with different

00:15:47,120 --> 00:15:50,639
groups of data

00:15:48,720 --> 00:15:52,480
in these examples we see the false

00:15:50,639 --> 00:15:53,680
negative rate for three different

00:15:52,480 --> 00:15:57,680
ethnicities

00:15:53,680 --> 00:16:01,040
a b and c assuming that these data

00:15:57,680 --> 00:16:04,079
are for our loan application use case

00:16:01,040 --> 00:16:06,800
what this chart tells us is that our ai

00:16:04,079 --> 00:16:08,160
falsely declines loan applications of

00:16:06,800 --> 00:16:11,199
ethnicity c

00:16:08,160 --> 00:16:13,360
way more often than other ethnicities

00:16:11,199 --> 00:16:16,160
the same we can check for age groups

00:16:13,360 --> 00:16:17,839
genders disabilities and so on

00:16:16,160 --> 00:16:20,160
not always the results would be

00:16:17,839 --> 00:16:21,120
unreasonable some attributes might be

00:16:20,160 --> 00:16:23,759
relevant

00:16:21,120 --> 00:16:25,920
it is reasonable to reject very big

00:16:23,759 --> 00:16:26,560
loans of individuals with very low

00:16:25,920 --> 00:16:29,360
income

00:16:26,560 --> 00:16:31,440
because those might be of higher risk

00:16:29,360 --> 00:16:33,279
but how about ethnicity

00:16:31,440 --> 00:16:35,440
we need to do more investigation in

00:16:33,279 --> 00:16:40,000
order to understand the reasons

00:16:35,440 --> 00:16:40,000
and if unfair treatment is introduced

00:16:40,320 --> 00:16:44,639
another concept we can use to better

00:16:42,880 --> 00:16:47,360
understand our models

00:16:44,639 --> 00:16:49,360
is sustainability explainability is the

00:16:47,360 --> 00:16:50,000
process of understanding how and why a

00:16:49,360 --> 00:16:53,040
machine learning

00:16:50,000 --> 00:16:53,680
model is making predictions and it

00:16:53,040 --> 00:16:56,320
happens

00:16:53,680 --> 00:16:58,720
during modeling and prediction phase of

00:16:56,320 --> 00:17:01,519
the machine learning life cycle

00:16:58,720 --> 00:17:02,079
explanability is a concept that you can

00:17:01,519 --> 00:17:04,880
apply

00:17:02,079 --> 00:17:07,400
with different modeling techniques and

00:17:04,880 --> 00:17:08,640
it is also applicable when you are using

00:17:07,400 --> 00:17:11,919
state-of-the-art

00:17:08,640 --> 00:17:14,319
deep neural networks as mentioned

00:17:11,919 --> 00:17:16,480
explainability is a tool which you can

00:17:14,319 --> 00:17:19,679
use during model training

00:17:16,480 --> 00:17:21,919
as well as during prediction time

00:17:19,679 --> 00:17:24,160
that is when the model is deployed in

00:17:21,919 --> 00:17:26,079
production

00:17:24,160 --> 00:17:27,439
so back to the example of our coffin

00:17:26,079 --> 00:17:29,120
drinker

00:17:27,439 --> 00:17:30,480
yes maybe this attribute shouldn't be

00:17:29,120 --> 00:17:32,880
part of the model

00:17:30,480 --> 00:17:33,600
but for the purpose of this presentation

00:17:32,880 --> 00:17:36,320
assume

00:17:33,600 --> 00:17:40,240
that this was not filter out and then

00:17:36,320 --> 00:17:40,240
made it into the model training step

00:17:40,720 --> 00:17:45,360
using explainable ai tools you can

00:17:43,520 --> 00:17:48,000
quantify how much of an impact

00:17:45,360 --> 00:17:49,520
each feature has for a particular

00:17:48,000 --> 00:17:51,840
prediction

00:17:49,520 --> 00:17:53,919
when looking for each predictions

00:17:51,840 --> 00:17:55,679
individually we are referring to local

00:17:53,919 --> 00:17:58,000
explanability

00:17:55,679 --> 00:17:59,280
if we then aggregate all the predictions

00:17:58,000 --> 00:18:01,520
together

00:17:59,280 --> 00:18:02,960
and average the impact of the features

00:18:01,520 --> 00:18:06,000
we get what we called

00:18:02,960 --> 00:18:08,160
global experiment building in the first

00:18:06,000 --> 00:18:09,919
example here you can see

00:18:08,160 --> 00:18:12,160
that the loan was declined mainly

00:18:09,919 --> 00:18:15,520
because individual applied

00:18:12,160 --> 00:18:18,480
drinks coffee capturing that early

00:18:15,520 --> 00:18:19,600
we can understand why and fix such

00:18:18,480 --> 00:18:22,000
defects

00:18:19,600 --> 00:18:23,120
additionally by serving explanations to

00:18:22,000 --> 00:18:25,200
the customer

00:18:23,120 --> 00:18:28,320
you give them the right to dispute any

00:18:25,200 --> 00:18:31,520
decision and escalate to humans in order

00:18:28,320 --> 00:18:33,679
for their application to be revised

00:18:31,520 --> 00:18:35,760
in the second example we can see that

00:18:33,679 --> 00:18:38,640
another loan was rejected

00:18:35,760 --> 00:18:39,360
this time because of gender the reasons

00:18:38,640 --> 00:18:42,559
may vary

00:18:39,360 --> 00:18:43,039
as i said earlier not enough data or

00:18:42,559 --> 00:18:46,400
maybe

00:18:43,039 --> 00:18:46,880
biased in the data maybe the aggregation

00:18:46,400 --> 00:18:49,919
was

00:18:46,880 --> 00:18:53,919
problematic either way capturing these

00:18:49,919 --> 00:18:53,919
allow us to investigate further

00:18:54,480 --> 00:19:01,760
another important asset in your toolkit

00:18:57,919 --> 00:19:04,679
is the word if2 this is another

00:19:01,760 --> 00:19:06,400
open source tool that with the help of

00:19:04,679 --> 00:19:09,039
explanations

00:19:06,400 --> 00:19:10,799
allows you to explore data and their

00:19:09,039 --> 00:19:13,679
predictions

00:19:10,799 --> 00:19:14,559
compare with previous model versions and

00:19:13,679 --> 00:19:18,400
finally

00:19:14,559 --> 00:19:20,960
test different what-if scenarios

00:19:18,400 --> 00:19:23,600
looking at an individual whose loan

00:19:20,960 --> 00:19:25,760
application was declined

00:19:23,600 --> 00:19:26,880
you can check different scenarios for

00:19:25,760 --> 00:19:30,960
example what

00:19:26,880 --> 00:19:34,160
if their age was 50 instead of 38

00:19:30,960 --> 00:19:38,000
how does this changes the prediction

00:19:34,160 --> 00:19:40,240
would they now be approved for the loan

00:19:38,000 --> 00:19:43,120
the word if tool helps you answer all

00:19:40,240 --> 00:19:43,120
those questions

00:19:43,760 --> 00:19:47,880
and finally the last piece of the puzzle

00:19:46,480 --> 00:19:50,080
is to be able to

00:19:47,880 --> 00:19:51,039
retrospectively evaluate your model

00:19:50,080 --> 00:19:53,679
performance

00:19:51,039 --> 00:19:54,960
after it is deployed to production in

00:19:53,679 --> 00:19:58,559
order to ensure

00:19:54,960 --> 00:20:00,160
it is behaving additionally

00:19:58,559 --> 00:20:02,320
you need to lock predictions and

00:20:00,160 --> 00:20:03,039
explanations in order to be able to

00:20:02,320 --> 00:20:06,000
debug

00:20:03,039 --> 00:20:09,280
and report and for this you can use

00:20:06,000 --> 00:20:09,280
continuous evaluation

00:20:10,559 --> 00:20:14,720
continuous evaluation is more of an

00:20:12,880 --> 00:20:17,760
architecture decision

00:20:14,720 --> 00:20:18,720
than an open source tool having said

00:20:17,760 --> 00:20:22,720
that

00:20:18,720 --> 00:20:24,799
google cloud has a ready-made solution

00:20:22,720 --> 00:20:26,240
that you can use when you deploy your

00:20:24,799 --> 00:20:29,039
models

00:20:26,240 --> 00:20:30,400
continuous valuation automatically logs

00:20:29,039 --> 00:20:33,520
all predicted

00:20:30,400 --> 00:20:36,159
attributes for a machine learning model

00:20:33,520 --> 00:20:39,280
and allows you to complement data with

00:20:36,159 --> 00:20:42,000
the truth at a later stage

00:20:39,280 --> 00:20:42,480
either by using human labelers or by

00:20:42,000 --> 00:20:45,520
having

00:20:42,480 --> 00:20:47,760
feedback loop from a given platform

00:20:45,520 --> 00:20:49,520
for example if you're automating loan

00:20:47,760 --> 00:20:51,520
application processing you should block

00:20:49,520 --> 00:20:53,840
a hundred percent of the predictions

00:20:51,520 --> 00:20:56,000
along with their explanations

00:20:53,840 --> 00:20:57,600
you can then loop back the customers

00:20:56,000 --> 00:21:01,440
that disputed the ais

00:20:57,600 --> 00:21:03,840
decision and want the dispute

00:21:01,440 --> 00:21:05,840
so we now know how responsible ai fits

00:21:03,840 --> 00:21:07,840
the machine learning lifecycle

00:21:05,840 --> 00:21:09,120
during this lifecycle there are multiple

00:21:07,840 --> 00:21:11,600
steps we

00:21:09,120 --> 00:21:12,400
explore data we analyze data we train

00:21:11,600 --> 00:21:15,200
models

00:21:12,400 --> 00:21:16,640
we push models into production we have

00:21:15,200 --> 00:21:19,440
tools that we can leverage

00:21:16,640 --> 00:21:21,200
during the whole process those tools can

00:21:19,440 --> 00:21:24,640
help us understand

00:21:21,200 --> 00:21:25,360
our data our model and how the models

00:21:24,640 --> 00:21:27,200
perform

00:21:25,360 --> 00:21:29,440
how accurate they are and if they

00:21:27,200 --> 00:21:32,000
discriminate between different slides

00:21:29,440 --> 00:21:34,960
of the data and with that in mind let's

00:21:32,000 --> 00:21:34,960
get back to running

00:21:35,760 --> 00:21:40,720
hello again so let's wrap up the story

00:21:39,360 --> 00:21:43,200
so going back to the story let's see

00:21:40,720 --> 00:21:45,600
what happened to jess and nick

00:21:43,200 --> 00:21:47,039
so it so happened that jess and nick

00:21:45,600 --> 00:21:48,320
bumped into each other on one of their

00:21:47,039 --> 00:21:49,440
visit to the estate

00:21:48,320 --> 00:21:51,760
where they were looking to buy the

00:21:49,440 --> 00:21:54,640
apartments and nick

00:21:51,760 --> 00:21:55,840
smart guy he struck up a conversation

00:21:54,640 --> 00:21:57,679
with jess

00:21:55,840 --> 00:21:59,360
and then they both started chatting and

00:21:57,679 --> 00:22:01,679
went for a coffee

00:21:59,360 --> 00:22:04,480
and during their coffee nick told jess

00:22:01,679 --> 00:22:07,440
about his experience with telu bank

00:22:04,480 --> 00:22:07,840
and that gave jess a direction now just

00:22:07,440 --> 00:22:09,440
knew

00:22:07,840 --> 00:22:11,200
that there was somebody out there who

00:22:09,440 --> 00:22:13,120
can help her

00:22:11,200 --> 00:22:14,880
so just now went to telu bank and

00:22:13,120 --> 00:22:16,640
applied for a mod gauge and got some

00:22:14,880 --> 00:22:18,240
reasons of how she can actually make

00:22:16,640 --> 00:22:20,799
things work better

00:22:18,240 --> 00:22:22,159
and eventually uh they worked hard uh

00:22:20,799 --> 00:22:25,120
towards getting their mortgage and

00:22:22,159 --> 00:22:27,600
eventually got onto the property ladder

00:22:25,120 --> 00:22:29,280
and that made her smile but again uh

00:22:27,600 --> 00:22:30,320
being lazy i couldn't find a smiling

00:22:29,280 --> 00:22:33,919
picture of her

00:22:30,320 --> 00:22:35,600
so that's why she still looks glum here

00:22:33,919 --> 00:22:37,039
and telu bank was actually able to

00:22:35,600 --> 00:22:38,880
expand their business

00:22:37,039 --> 00:22:40,159
by getting custom getting getting a

00:22:38,880 --> 00:22:43,520
customer from

00:22:40,159 --> 00:22:46,320
uh kansas bank just in this case

00:22:43,520 --> 00:22:48,000
and also by increasing trust on their

00:22:46,320 --> 00:22:51,120
own brand by their own customer

00:22:48,000 --> 00:22:51,679
nick in this case as for what happened

00:22:51,120 --> 00:22:54,799
next

00:22:51,679 --> 00:22:57,360
we leave it up to the audience to think

00:22:54,799 --> 00:22:59,120
about how you want to end the story

00:22:57,360 --> 00:23:00,559
thank you very much for being with us

00:22:59,120 --> 00:23:01,840
and look forward to seeing you somewhere

00:23:00,559 --> 00:23:09,840
sometimes again

00:23:01,840 --> 00:23:09,840
thank you

00:23:19,039 --> 00:23:21,120

YouTube URL: https://www.youtube.com/watch?v=-2f3y7SynvE


