Title: The Art and Tech of Generating Secure & Authentic Synthetic Data
Publication date: 2020-11-19
Playlist: Open Source Strategy Forum 2020
Description: 
	The Art and Tech of Generating Secure & Authentic Synthetic Data - Andrew Carr, Scott Logic & Paul Groves, Citi
Captions: 
	00:00:02,879 --> 00:00:06,399
great

00:00:03,360 --> 00:00:06,879
i think we are live now so um hello

00:00:06,399 --> 00:00:08,800
everybody

00:00:06,879 --> 00:00:10,240
my name is paul groves i'm the lead

00:00:08,800 --> 00:00:10,960
architect for client boarding over at

00:00:10,240 --> 00:00:13,200
city group

00:00:10,960 --> 00:00:14,799
and uh we also got andrew carr on here

00:00:13,200 --> 00:00:17,359
uh andrew

00:00:14,799 --> 00:00:21,039
hello so i'm uh head of consultancy uh

00:00:17,359 --> 00:00:21,039
for the bristol office in scotlogic

00:00:21,439 --> 00:00:25,279
cool okay uh so we're gonna talk about

00:00:23,359 --> 00:00:27,519
synthetic data generation today

00:00:25,279 --> 00:00:29,039
um won't go to it's quite a broad

00:00:27,519 --> 00:00:29,599
subject it's quite deep so we're gonna

00:00:29,039 --> 00:00:31,519
kind of

00:00:29,599 --> 00:00:32,960
go over it quite lightly today uh but if

00:00:31,519 --> 00:00:33,360
there's any questions we'd love to hear

00:00:32,960 --> 00:00:36,239
them

00:00:33,360 --> 00:00:37,680
um you can also contact me at uh there

00:00:36,239 --> 00:00:39,360
are contact details on here if you wanna

00:00:37,680 --> 00:00:42,559
kind of learn a little bit more

00:00:39,360 --> 00:00:44,960
so um let's get going so

00:00:42,559 --> 00:00:46,640
there's uh within philos there's two

00:00:44,960 --> 00:00:47,840
synthetic data generation projects that

00:00:46,640 --> 00:00:51,199
are live there right now

00:00:47,840 --> 00:00:55,360
um data hub and uh data helix

00:00:51,199 --> 00:00:57,440
so data hub came out of silly group and

00:00:55,360 --> 00:00:59,359
what we produced was a set of python

00:00:57,440 --> 00:01:01,520
libraries that were

00:00:59,359 --> 00:01:03,120
helpful to doing synthetic data

00:01:01,520 --> 00:01:05,040
production so

00:01:03,120 --> 00:01:07,040
it kind of supported two use cases one

00:01:05,040 --> 00:01:08,479
way you could hand write rules

00:01:07,040 --> 00:01:10,080
kind of features and then you could go

00:01:08,479 --> 00:01:12,799
and generate some data

00:01:10,080 --> 00:01:13,200
or there was we've got facilities where

00:01:12,799 --> 00:01:15,439
we can

00:01:13,200 --> 00:01:16,320
analyze existing product existing data

00:01:15,439 --> 00:01:18,479
sets

00:01:16,320 --> 00:01:19,920
kind of make a statistical model out of

00:01:18,479 --> 00:01:23,280
that data set and then use

00:01:19,920 --> 00:01:25,759
that to produce then synthetic data and

00:01:23,280 --> 00:01:27,200
uh we've also got data helix so i'll

00:01:25,759 --> 00:01:28,560
throw over to you andrew to quickly say

00:01:27,200 --> 00:01:30,560
something about that

00:01:28,560 --> 00:01:31,600
yeah so data helix is slightly different

00:01:30,560 --> 00:01:34,079
than it was a

00:01:31,600 --> 00:01:35,840
uh synthetic data generator designed to

00:01:34,079 --> 00:01:36,880
generate large volumes of data really

00:01:35,840 --> 00:01:38,799
quickly so

00:01:36,880 --> 00:01:40,720
we tried to do it where um i guess

00:01:38,799 --> 00:01:42,079
similar to the modes that paul talks

00:01:40,720 --> 00:01:43,759
about with the data hub

00:01:42,079 --> 00:01:45,280
where you can throw it at data and

00:01:43,759 --> 00:01:47,680
analyze data and then

00:01:45,280 --> 00:01:49,920
generate it well we described our own uh

00:01:47,680 --> 00:01:50,720
data language to describe the rules of

00:01:49,920 --> 00:01:52,560
the data

00:01:50,720 --> 00:01:54,320
such that someone who wasn't necessarily

00:01:52,560 --> 00:01:55,040
a developer could write down all the

00:01:54,320 --> 00:01:57,200
rules and

00:01:55,040 --> 00:01:59,680
generate data very very quickly so i

00:01:57,200 --> 00:02:01,439
guess the first use case was really for

00:01:59,680 --> 00:02:02,719
testers who wanted to do load testing on

00:02:01,439 --> 00:02:06,000
the system and

00:02:02,719 --> 00:02:07,200
generate that data rapidly over to you

00:02:06,000 --> 00:02:09,360
paul

00:02:07,200 --> 00:02:11,280
cool great actually more data healing

00:02:09,360 --> 00:02:14,560
stuff

00:02:11,280 --> 00:02:16,879
natural screenshot there i apologize so

00:02:14,560 --> 00:02:18,080
um yeah so i guess if you look on the

00:02:16,879 --> 00:02:21,280
left hand side

00:02:18,080 --> 00:02:22,000
you can see sample rules that describe

00:02:21,280 --> 00:02:23,920
the data so

00:02:22,000 --> 00:02:25,440
you can describe uh the types of the

00:02:23,920 --> 00:02:28,080
columns you can describe

00:02:25,440 --> 00:02:28,480
certain rule sets you can say that this

00:02:28,080 --> 00:02:30,640
string

00:02:28,480 --> 00:02:33,360
flows this regular expression you can

00:02:30,640 --> 00:02:35,040
put conditions between the the data

00:02:33,360 --> 00:02:36,720
and this if you go to this finos

00:02:35,040 --> 00:02:39,760
playground you can actually

00:02:36,720 --> 00:02:41,360
live edit a profile and then press run

00:02:39,760 --> 00:02:43,519
and it will generate some data based on

00:02:41,360 --> 00:02:44,879
that profile thus you can have a really

00:02:43,519 --> 00:02:48,000
quick turnaround

00:02:44,879 --> 00:02:50,879
to generate some quite realistic data

00:02:48,000 --> 00:02:51,519
quite rapidly and an example is is

00:02:50,879 --> 00:02:53,599
pretty

00:02:51,519 --> 00:02:55,440
um simple but it shows you a bunch of

00:02:53,599 --> 00:02:56,879
rules that will generate that data in

00:02:55,440 --> 00:03:00,800
the right-hand side

00:02:56,879 --> 00:03:03,120
uh next slide piece paul cool

00:03:00,800 --> 00:03:04,560
okay so synthetic data yeah what is it

00:03:03,120 --> 00:03:05,280
it's there's a lot of talk about it

00:03:04,560 --> 00:03:07,440
these days

00:03:05,280 --> 00:03:09,200
and simply anything where you can

00:03:07,440 --> 00:03:11,280
algorithmically generate data

00:03:09,200 --> 00:03:12,640
that's what synthetic data is so there's

00:03:11,280 --> 00:03:13,599
a lot as we've probably touched before

00:03:12,640 --> 00:03:16,560
there's a lot of

00:03:13,599 --> 00:03:17,200
um ways of doing this typically we're

00:03:16,560 --> 00:03:19,360
looking

00:03:17,200 --> 00:03:20,720
in financial institutions towards

00:03:19,360 --> 00:03:23,440
synthetic data

00:03:20,720 --> 00:03:25,680
because um we're looking around data

00:03:23,440 --> 00:03:28,799
privacy so how can we populate our

00:03:25,680 --> 00:03:32,000
test data systems with realistic looking

00:03:28,799 --> 00:03:33,200
data but that it um that has full

00:03:32,000 --> 00:03:35,360
privacy on there

00:03:33,200 --> 00:03:36,879
um so i think a lot of people we've come

00:03:35,360 --> 00:03:38,480
down this

00:03:36,879 --> 00:03:39,760
data redaction route and then we've

00:03:38,480 --> 00:03:41,760
obviously discovered issues there

00:03:39,760 --> 00:03:43,120
particularly around re-identification

00:03:41,760 --> 00:03:44,959
and then we've also many of us gone down

00:03:43,120 --> 00:03:47,680
like the full anonymization

00:03:44,959 --> 00:03:48,640
path and often we found the results were

00:03:47,680 --> 00:03:50,080
not particularly

00:03:48,640 --> 00:03:52,319
weren't particularly happy with the the

00:03:50,080 --> 00:03:53,920
results like for those anonymizers to

00:03:52,319 --> 00:03:54,239
fully anonymize we've often ended up

00:03:53,920 --> 00:03:56,159
with

00:03:54,239 --> 00:03:58,319
just trash data at the end of it that

00:03:56,159 --> 00:03:59,120
has no use within really using the test

00:03:58,319 --> 00:03:59,920
system

00:03:59,120 --> 00:04:02,159
so what we're trying to do with

00:03:59,920 --> 00:04:03,439
synthetic systems is try and produce

00:04:02,159 --> 00:04:05,040
realistic data

00:04:03,439 --> 00:04:06,640
that has the characteristics of the real

00:04:05,040 --> 00:04:08,400
data but there's

00:04:06,640 --> 00:04:10,080
uh absolutely no way that we can breach

00:04:08,400 --> 00:04:10,959
privacy no way we could accidentally

00:04:10,080 --> 00:04:14,319
recreate

00:04:10,959 --> 00:04:16,160
real people synthetically um

00:04:14,319 --> 00:04:18,320
so it's not a new thing it's been around

00:04:16,160 --> 00:04:18,880
a long time uh some of the history of

00:04:18,320 --> 00:04:21,359
this is

00:04:18,880 --> 00:04:22,240
um a lot of the work in synthetic data

00:04:21,359 --> 00:04:25,040
that we can't

00:04:22,240 --> 00:04:26,080
see now is uh pioneered in the 90s by

00:04:25,040 --> 00:04:29,040
the u.s centers

00:04:26,080 --> 00:04:29,440
brewer where what they wanted to do was

00:04:29,040 --> 00:04:32,000
share

00:04:29,440 --> 00:04:33,520
out the data sets without revealing any

00:04:32,000 --> 00:04:34,560
of the actual real census data because

00:04:33,520 --> 00:04:35,680
it's quite confidential you have

00:04:34,560 --> 00:04:37,520
people's salaries

00:04:35,680 --> 00:04:39,919
race religion lots of things that people

00:04:37,520 --> 00:04:44,160
wouldn't maybe want to put out there

00:04:39,919 --> 00:04:45,840
so um what they were doing was

00:04:44,160 --> 00:04:47,520
also as issues of incomplete data as

00:04:45,840 --> 00:04:49,360
well so what they wanted to do was kind

00:04:47,520 --> 00:04:49,919
of statistically populate missing data

00:04:49,360 --> 00:04:52,560
with

00:04:49,919 --> 00:04:54,000
with realistic values and so they spent

00:04:52,560 --> 00:04:56,800
a lot of effort doing this

00:04:54,000 --> 00:04:58,720
um in a slightly more fun way um if you

00:04:56,800 --> 00:05:00,639
go to the opposite side of things of

00:04:58,720 --> 00:05:02,479
trying to recreate kind of believable

00:05:00,639 --> 00:05:04,479
worlds based off rules

00:05:02,479 --> 00:05:06,000
um anybody probably around about my age

00:05:04,479 --> 00:05:07,919
or andrew's age uh

00:05:06,000 --> 00:05:09,440
who used to play games on the zx

00:05:07,919 --> 00:05:11,440
spectrums and bbc micros

00:05:09,440 --> 00:05:12,880
probably remember this game elite and

00:05:11,440 --> 00:05:14,400
this again was a form of synthetic

00:05:12,880 --> 00:05:15,120
generation it was more procedural

00:05:14,400 --> 00:05:17,680
generation

00:05:15,120 --> 00:05:18,320
which was how can you create a life-like

00:05:17,680 --> 00:05:20,800
galaxy

00:05:18,320 --> 00:05:23,199
that you can go around trading do things

00:05:20,800 --> 00:05:25,199
and keep it consistently generating um

00:05:23,199 --> 00:05:26,960
and so that was a really quite clever

00:05:25,199 --> 00:05:28,720
algorithm algorithms

00:05:26,960 --> 00:05:30,160
they generated back then and that was

00:05:28,720 --> 00:05:31,680
kind of also like the

00:05:30,160 --> 00:05:33,360
genesis of i guess of that kind of

00:05:31,680 --> 00:05:35,600
procedural generation of

00:05:33,360 --> 00:05:36,880
kind of world creation so completely

00:05:35,600 --> 00:05:39,919
different way that you can

00:05:36,880 --> 00:05:42,479
use these tools and it goes way back

00:05:39,919 --> 00:05:42,960
there's nothing new uh as we touched on

00:05:42,479 --> 00:05:44,720
there's

00:05:42,960 --> 00:05:46,240
two kind of big use cases we're seeing

00:05:44,720 --> 00:05:46,800
out there in financial services right

00:05:46,240 --> 00:05:49,600
now

00:05:46,800 --> 00:05:51,280
there's the whole gdpr all the laws we

00:05:49,600 --> 00:05:53,039
have and regulations around protecting

00:05:51,280 --> 00:05:55,440
pii data

00:05:53,039 --> 00:05:57,360
the problems of that anonymization of

00:05:55,440 --> 00:05:58,560
and re-identification that a lot of us

00:05:57,360 --> 00:05:59,840
have found

00:05:58,560 --> 00:06:02,160
then on the opposite side you have kind

00:05:59,840 --> 00:06:03,759
of machine learning so

00:06:02,160 --> 00:06:05,280
why you might not use synthetic data

00:06:03,759 --> 00:06:07,280
well you definitely wouldn't use intense

00:06:05,280 --> 00:06:09,840
data to train your ml

00:06:07,280 --> 00:06:11,120
uh or your ai particularly in the data

00:06:09,840 --> 00:06:14,479
engineering aspects of

00:06:11,120 --> 00:06:16,000
building an ai or ml pipeline is um

00:06:14,479 --> 00:06:17,600
your developers might not be allowed the

00:06:16,000 --> 00:06:19,600
real data um

00:06:17,600 --> 00:06:21,360
again to get it so you need kind of

00:06:19,600 --> 00:06:24,639
standing data sets that look

00:06:21,360 --> 00:06:26,319
vaguely realistic that you can use in

00:06:24,639 --> 00:06:28,000
your development systems

00:06:26,319 --> 00:06:29,520
i mean you have other other things where

00:06:28,000 --> 00:06:31,120
you might have a team of people that are

00:06:29,520 --> 00:06:34,160
working on the

00:06:31,120 --> 00:06:34,720
say say tagging data uh actually working

00:06:34,160 --> 00:06:36,160
on the real

00:06:34,720 --> 00:06:38,240
production data set and it's not

00:06:36,160 --> 00:06:40,160
available yet so while you're doing the

00:06:38,240 --> 00:06:41,440
work in terms of your data engineering

00:06:40,160 --> 00:06:42,960
you might need some kind of standing

00:06:41,440 --> 00:06:43,520
data set for the real works kind of

00:06:42,960 --> 00:06:45,600
going on

00:06:43,520 --> 00:06:46,639
to you know get the data that you need

00:06:45,600 --> 00:06:48,000
so there's kind of two different use

00:06:46,639 --> 00:06:52,080
cases kind of seeing a lot around

00:06:48,000 --> 00:06:53,440
here um so yes three we've got three

00:06:52,080 --> 00:06:55,280
main approaches production which is

00:06:53,440 --> 00:06:57,120
simply removing sensitive information

00:06:55,280 --> 00:06:58,560
you have the risk of re-identification

00:06:57,120 --> 00:06:59,919
they have anonymization which is much

00:06:58,560 --> 00:07:01,599
further process where we ensure

00:06:59,919 --> 00:07:02,800
re-identification cannot happen

00:07:01,599 --> 00:07:04,960
there's a bunch of tooling out there

00:07:02,800 --> 00:07:07,440
that can help you that or we go to

00:07:04,960 --> 00:07:08,479
synthesis where we again you've got

00:07:07,440 --> 00:07:10,160
those two words where you do it

00:07:08,479 --> 00:07:11,840
procedurally where you handcraft your

00:07:10,160 --> 00:07:14,240
rules and your procedure generate

00:07:11,840 --> 00:07:16,639
or you analyze production data observe

00:07:14,240 --> 00:07:18,160
the patterns and generate from there

00:07:16,639 --> 00:07:19,919
um and that's kind of where we're

00:07:18,160 --> 00:07:20,240
roughly at between data helix and data

00:07:19,919 --> 00:07:22,319
hub

00:07:20,240 --> 00:07:23,599
uh data's kind of morning leading to the

00:07:22,319 --> 00:07:26,400
analysis side

00:07:23,599 --> 00:07:27,280
and uh yeah i think we've got data helix

00:07:26,400 --> 00:07:31,360
which is much more

00:07:27,280 --> 00:07:33,759
kind of the procedural side um

00:07:31,360 --> 00:07:34,720
yeah so um andrew do i join a handout to

00:07:33,759 --> 00:07:38,080
you now on this one

00:07:34,720 --> 00:07:40,880
or uh i don't mind

00:07:38,080 --> 00:07:43,440
i think yeah i think this one is your

00:07:40,880 --> 00:07:46,720
slide but you can i can talk to you sean

00:07:43,440 --> 00:07:49,440
no you go for it okay so um

00:07:46,720 --> 00:07:50,240
i guess uh there's there's lots of

00:07:49,440 --> 00:07:53,039
problems with

00:07:50,240 --> 00:07:55,199
uh redaction i i think the challenge of

00:07:53,039 --> 00:07:56,879
redaction is when you start to

00:07:55,199 --> 00:07:59,039
use redaction to get to the point where

00:07:56,879 --> 00:08:02,240
you can't do the re-identification

00:07:59,039 --> 00:08:04,560
um is you have to remove so much as to

00:08:02,240 --> 00:08:05,520
the sometimes the data becomes unusable

00:08:04,560 --> 00:08:07,680
and not

00:08:05,520 --> 00:08:09,039
useful for the task at hand so you end

00:08:07,680 --> 00:08:10,479
up with just a slosh of data that

00:08:09,039 --> 00:08:11,120
doesn't actually represent the original

00:08:10,479 --> 00:08:13,440
data

00:08:11,120 --> 00:08:14,160
in any form whatsoever so there are real

00:08:13,440 --> 00:08:16,160
troubles

00:08:14,160 --> 00:08:17,360
uh challenges of reduction also the

00:08:16,160 --> 00:08:19,440
other problem with redaction

00:08:17,360 --> 00:08:21,039
is it does take a long time to do and

00:08:19,440 --> 00:08:22,960
then you have to get to the point where

00:08:21,039 --> 00:08:25,759
as paul says you have to verify that you

00:08:22,960 --> 00:08:28,000
can't then re-identify the individuals

00:08:25,759 --> 00:08:30,639
in the original data so paul if you go

00:08:28,000 --> 00:08:30,639
to the next slide

00:08:30,720 --> 00:08:33,839
do you want to talk about differential

00:08:32,320 --> 00:08:37,519
privacy

00:08:33,839 --> 00:08:37,519
yeah so different privacy so

00:08:37,760 --> 00:08:41,440
what we tend to talk about there is uh

00:08:39,599 --> 00:08:43,760
when we talk about differential privacy

00:08:41,440 --> 00:08:46,000
is the point where you're basically

00:08:43,760 --> 00:08:47,440
creating a statistical model of the data

00:08:46,000 --> 00:08:49,680
and out of that statistical model the

00:08:47,440 --> 00:08:51,440
data you should be general about the

00:08:49,680 --> 00:08:53,279
data that should have the properties of

00:08:51,440 --> 00:08:54,959
it the distributions any constraints

00:08:53,279 --> 00:08:56,160
found in there essentially the rule sets

00:08:54,959 --> 00:08:59,200
that data

00:08:56,160 --> 00:09:01,519
um but you must be able

00:08:59,200 --> 00:09:02,959
in that data set be able to re-identify

00:09:01,519 --> 00:09:05,279
an actual individual again

00:09:02,959 --> 00:09:08,080
so you know if we looked at this example

00:09:05,279 --> 00:09:09,600
back here of the hr data where um

00:09:08,080 --> 00:09:12,000
you know you could simply

00:09:09,600 --> 00:09:13,600
cross-reference if you redacted people's

00:09:12,000 --> 00:09:15,600
uh names out you could simply

00:09:13,600 --> 00:09:17,760
cross-reference it with like a nature or

00:09:15,600 --> 00:09:19,360
phone book and then if you hadn't

00:09:17,760 --> 00:09:20,880
removed things like salary information

00:09:19,360 --> 00:09:22,320
all the rest of it you'd quickly work

00:09:20,880 --> 00:09:23,519
out whatever salaries were or other

00:09:22,320 --> 00:09:24,800
confidential things you didn't want to

00:09:23,519 --> 00:09:27,839
find out

00:09:24,800 --> 00:09:29,200
um so it's yeah quite critical

00:09:27,839 --> 00:09:30,560
differential privacy is quite critical

00:09:29,200 --> 00:09:32,080
to synthetic data generation

00:09:30,560 --> 00:09:35,040
particularly when we're doing it

00:09:32,080 --> 00:09:36,320
in the analysis of existing data sets so

00:09:35,040 --> 00:09:36,959
if you're looking at typical synthetic

00:09:36,320 --> 00:09:38,880
data flow

00:09:36,959 --> 00:09:40,000
where you're doing the analysis stage

00:09:38,880 --> 00:09:42,320
you'll often start with

00:09:40,000 --> 00:09:43,600
your production data so in your

00:09:42,320 --> 00:09:44,399
production environment this is our

00:09:43,600 --> 00:09:45,839
boundary

00:09:44,399 --> 00:09:47,920
we have another boundary which are

00:09:45,839 --> 00:09:49,920
non-production environment you start by

00:09:47,920 --> 00:09:50,959
querying your production data you'll

00:09:49,920 --> 00:09:54,080
certainly remove

00:09:50,959 --> 00:09:55,839
any pii action easily identify

00:09:54,080 --> 00:09:57,519
pi attributes out of there don't name

00:09:55,839 --> 00:09:58,959
social connect social groups numbers

00:09:57,519 --> 00:10:00,959
addresses all those good things

00:09:58,959 --> 00:10:02,720
you don't want those in your data set at

00:10:00,959 --> 00:10:04,800
all

00:10:02,720 --> 00:10:06,320
you will then do your analysis on it so

00:10:04,800 --> 00:10:07,440
to find out where these constraints

00:10:06,320 --> 00:10:09,120
distributions and other

00:10:07,440 --> 00:10:10,800
interesting properties are and produce

00:10:09,120 --> 00:10:12,320
this kind of dp data file this

00:10:10,800 --> 00:10:13,440
differential privacy data file that's a

00:10:12,320 --> 00:10:15,279
statistical model

00:10:13,440 --> 00:10:16,959
and that should be then safe to transfer

00:10:15,279 --> 00:10:18,160
to a non-production environment

00:10:16,959 --> 00:10:19,920
and then you're into your synthetic

00:10:18,160 --> 00:10:20,560
generation that's your kind of analysis

00:10:19,920 --> 00:10:22,399
mode

00:10:20,560 --> 00:10:24,000
then you've got your generation mode

00:10:22,399 --> 00:10:26,240
which is where you take this

00:10:24,000 --> 00:10:27,440
statistical model you put into some kind

00:10:26,240 --> 00:10:29,120
of thing that can produce

00:10:27,440 --> 00:10:30,560
data out of it that looks like the

00:10:29,120 --> 00:10:31,839
original data set

00:10:30,560 --> 00:10:34,160
and when you've done that you might then

00:10:31,839 --> 00:10:35,839
choose to enhance it so as you remember

00:10:34,160 --> 00:10:37,040
we've redacted all the pi attributes out

00:10:35,839 --> 00:10:38,000
of it we've removed people's names

00:10:37,040 --> 00:10:40,160
addresses so

00:10:38,000 --> 00:10:41,519
now let's add back fake names and

00:10:40,160 --> 00:10:43,360
addresses back in there

00:10:41,519 --> 00:10:47,040
and now you've kind of created this

00:10:43,360 --> 00:10:48,880
virtual life like um

00:10:47,040 --> 00:10:50,959
representation of the original data set

00:10:48,880 --> 00:10:51,760
but everything it refers to can't

00:10:50,959 --> 00:10:54,720
possibly have

00:10:51,760 --> 00:10:54,720
existed in real life

00:10:54,959 --> 00:10:58,079
you've got to be a little bit careful in

00:10:56,240 --> 00:10:59,120
this space particularly with your data

00:10:58,079 --> 00:11:00,640
analysis

00:10:59,120 --> 00:11:02,560
there's lots of different approaches to

00:11:00,640 --> 00:11:06,000
doing this this analysis produced

00:11:02,560 --> 00:11:07,040
the the dp data file what you tend to

00:11:06,000 --> 00:11:08,000
find out is you've got to be very

00:11:07,040 --> 00:11:10,160
careful of

00:11:08,000 --> 00:11:11,519
um anyone who knows anything about like

00:11:10,160 --> 00:11:12,880
being near machine learning

00:11:11,519 --> 00:11:14,399
understands the cursive like hyper

00:11:12,880 --> 00:11:15,519
dimensionality where you have so many

00:11:14,399 --> 00:11:16,880
dimensions the data

00:11:15,519 --> 00:11:18,640
that actually everything resolves back

00:11:16,880 --> 00:11:20,480
to one record and one record only

00:11:18,640 --> 00:11:22,480
and if you do that quite often it's

00:11:20,480 --> 00:11:24,000
quite hard so when you're doing analysis

00:11:22,480 --> 00:11:25,680
you have to be quite careful of what

00:11:24,000 --> 00:11:27,519
dimension data dimensions you're

00:11:25,680 --> 00:11:30,560
actually interested in and remove the

00:11:27,519 --> 00:11:31,760
ones you're not that aren't important

00:11:30,560 --> 00:11:33,440
versus i guess now we've got the

00:11:31,760 --> 00:11:34,240
procedural generation which is quite

00:11:33,440 --> 00:11:35,920
simply

00:11:34,240 --> 00:11:38,000
you offer some rules you produce some

00:11:35,920 --> 00:11:38,640
data do something with it put into your

00:11:38,000 --> 00:11:40,800
database

00:11:38,640 --> 00:11:42,000
um now that could be a lot more involved

00:11:40,800 --> 00:11:43,920
because the developer has to sit there

00:11:42,000 --> 00:11:46,720
and hand craft the setup rules

00:11:43,920 --> 00:11:47,680
this is really useful approaches where

00:11:46,720 --> 00:11:50,240
you're

00:11:47,680 --> 00:11:51,839
um you might not have any data like it's

00:11:50,240 --> 00:11:53,120
a brand new system you've got no data so

00:11:51,839 --> 00:11:54,079
you just need to start generating

00:11:53,120 --> 00:11:56,880
something for your

00:11:54,079 --> 00:11:59,040
test system to start working with um so

00:11:56,880 --> 00:12:01,360
that's that's those kind of scenarios

00:11:59,040 --> 00:12:02,639
or you need a lot of data very quickly

00:12:01,360 --> 00:12:05,920
um and it's got to be

00:12:02,639 --> 00:12:08,839
you know relatively simple so

00:12:05,920 --> 00:12:10,560
um yeah i'll hand back over to you

00:12:08,839 --> 00:12:12,079
andrew cool so

00:12:10,560 --> 00:12:13,519
if we take a step back so obviously

00:12:12,079 --> 00:12:14,720
we've highlighted that there's different

00:12:13,519 --> 00:12:17,360
approaches to

00:12:14,720 --> 00:12:19,519
generating synthetic data the question

00:12:17,360 --> 00:12:20,959
is when do you use which approach and i

00:12:19,519 --> 00:12:23,040
guess i'm going to chat to you

00:12:20,959 --> 00:12:24,000
a bit more about the rules-based

00:12:23,040 --> 00:12:26,399
approach where you

00:12:24,000 --> 00:12:28,480
generate synthetic data from a bunch of

00:12:26,399 --> 00:12:30,720
rules and when's that is useful so

00:12:28,480 --> 00:12:31,760
i guess if you if you pull all the

00:12:30,720 --> 00:12:34,079
different use cases

00:12:31,760 --> 00:12:35,200
of uh why do you want test data you can

00:12:34,079 --> 00:12:36,639
pull them back

00:12:35,200 --> 00:12:38,800
and this is a bit of a generalization

00:12:36,639 --> 00:12:40,639
but it often holds true

00:12:38,800 --> 00:12:42,240
sometimes you want low volume highly

00:12:40,639 --> 00:12:44,160
accurate data and that's

00:12:42,240 --> 00:12:46,639
typically to test functionality in the

00:12:44,160 --> 00:12:47,680
system and for that you need the data to

00:12:46,639 --> 00:12:49,839
absolutely be

00:12:47,680 --> 00:12:51,440
accurate otherwise it might not trigger

00:12:49,839 --> 00:12:52,720
the correct functionality in in the

00:12:51,440 --> 00:12:54,560
system

00:12:52,720 --> 00:12:56,320
sometimes you want high volume

00:12:54,560 --> 00:12:57,600
reasonably shaped data

00:12:56,320 --> 00:12:59,519
and it's really you know reasonably

00:12:57,600 --> 00:13:00,959
accurate data and that's often to test

00:12:59,519 --> 00:13:03,200
the load whether that's a

00:13:00,959 --> 00:13:04,800
you're doing uh you know can the system

00:13:03,200 --> 00:13:07,040
deal with this throughput

00:13:04,800 --> 00:13:08,079
can it deal with uh data and process at

00:13:07,040 --> 00:13:10,800
a certain speed

00:13:08,079 --> 00:13:12,480
and and can the system respond given a

00:13:10,800 --> 00:13:14,880
certain volume of data

00:13:12,480 --> 00:13:16,959
and with that that tends to be the use

00:13:14,880 --> 00:13:18,839
case that you will typically do rule

00:13:16,959 --> 00:13:22,399
space generation data

00:13:18,839 --> 00:13:24,079
um depending on the use case as you said

00:13:22,399 --> 00:13:26,000
uh you're considering should support the

00:13:24,079 --> 00:13:27,760
approach what i'm going to do is walk

00:13:26,000 --> 00:13:30,560
through an example of how a simple

00:13:27,760 --> 00:13:32,639
use case if you want volume data can get

00:13:30,560 --> 00:13:33,360
complex very quickly using a rules-based

00:13:32,639 --> 00:13:35,519
approach

00:13:33,360 --> 00:13:36,880
so i generally recommend if you're going

00:13:35,519 --> 00:13:38,880
to go for

00:13:36,880 --> 00:13:41,040
rules based approach use it when you

00:13:38,880 --> 00:13:42,560
want kind of large volume data

00:13:41,040 --> 00:13:44,399
and it just has to look reasonably

00:13:42,560 --> 00:13:48,000
realistic

00:13:44,399 --> 00:13:49,839
so if we go to the next slide okay

00:13:48,000 --> 00:13:51,360
so like i said what we're going to do is

00:13:49,839 --> 00:13:52,720
do a simple example

00:13:51,360 --> 00:13:55,440
and this is a financial services or

00:13:52,720 --> 00:13:57,519
capital markets example i guess

00:13:55,440 --> 00:14:00,480
imagine you want the simple test data of

00:13:57,519 --> 00:14:03,600
a trade id a stock id a stock name

00:14:00,480 --> 00:14:06,720
a price and a trading date time

00:14:03,600 --> 00:14:08,399
so if we go to the next slide if i use

00:14:06,720 --> 00:14:10,720
really simple rules and said actually

00:14:08,399 --> 00:14:12,800
you know what um the trade id is a

00:14:10,720 --> 00:14:14,240
an integer the stock id is a string the

00:14:12,800 --> 00:14:16,800
stock name is a string

00:14:14,240 --> 00:14:17,440
the price is a float and the trade date

00:14:16,800 --> 00:14:20,320
time

00:14:17,440 --> 00:14:21,600
uh is just a trade day now clearly uh i

00:14:20,320 --> 00:14:23,199
think even people who are outside of

00:14:21,600 --> 00:14:24,480
financial services we look at that and

00:14:23,199 --> 00:14:25,680
and see that that's clearly a

00:14:24,480 --> 00:14:28,240
nonsensical

00:14:25,680 --> 00:14:30,160
uh bit of data um it's valid according

00:14:28,240 --> 00:14:32,000
to rules that we just gave it but it's

00:14:30,160 --> 00:14:33,519
not really usable even for functional

00:14:32,000 --> 00:14:34,240
testing this probably wouldn't be very

00:14:33,519 --> 00:14:35,760
usable

00:14:34,240 --> 00:14:37,600
uh if you look at the price field it's

00:14:35,760 --> 00:14:39,600
not to two decimal places

00:14:37,600 --> 00:14:40,800
um you know it could easily break part

00:14:39,600 --> 00:14:43,680
of the system on

00:14:40,800 --> 00:14:45,680
in even basic checks and so if we go to

00:14:43,680 --> 00:14:47,440
the next slide

00:14:45,680 --> 00:14:49,600
if we try and tighten up some of these

00:14:47,440 --> 00:14:51,440
rules um we could try and generate a bit

00:14:49,600 --> 00:14:53,920
more realistic data as well as giving it

00:14:51,440 --> 00:14:55,680
the the types of each field we could

00:14:53,920 --> 00:14:57,519
give it rules about the field so

00:14:55,680 --> 00:14:59,440
we could say that the stock id should be

00:14:57,519 --> 00:15:00,800
taken from an enumeration

00:14:59,440 --> 00:15:02,800
we could say the stock name should be

00:15:00,800 --> 00:15:04,800
taken from enumeration and we should say

00:15:02,800 --> 00:15:07,360
maybe the price should float between

00:15:04,800 --> 00:15:08,880
you know two boundaries and maybe the

00:15:07,360 --> 00:15:10,079
trade date needs to be greater than one

00:15:08,880 --> 00:15:12,320
week ago but less

00:15:10,079 --> 00:15:14,160
today and then if we have a look to see

00:15:12,320 --> 00:15:17,440
what that would generate

00:15:14,160 --> 00:15:18,959
well the data looks much better it still

00:15:17,440 --> 00:15:20,800
has a lot of challenges in it

00:15:18,959 --> 00:15:22,079
clearly the stock id and the stock name

00:15:20,800 --> 00:15:24,320
don't match

00:15:22,079 --> 00:15:25,360
and the price still has issues because

00:15:24,320 --> 00:15:28,160
um there's

00:15:25,360 --> 00:15:30,000
multiple uh i guess significant figures

00:15:28,160 --> 00:15:31,519
after the the decimal point

00:15:30,000 --> 00:15:33,040
so it's getting a little bit more

00:15:31,519 --> 00:15:35,120
realistic and even with some

00:15:33,040 --> 00:15:36,639
simple rules we've got we've got much

00:15:35,120 --> 00:15:39,040
closer but again

00:15:36,639 --> 00:15:40,399
it's probably not usable for functional

00:15:39,040 --> 00:15:42,639
testing yet

00:15:40,399 --> 00:15:44,480
it's yeah probably not usable for volume

00:15:42,639 --> 00:15:47,759
testing yet it's definitely not

00:15:44,480 --> 00:15:50,240
usable for machine learning analysis

00:15:47,759 --> 00:15:51,839
so if we go to the next slide if we try

00:15:50,240 --> 00:15:52,720
and tighten those rules up a little bit

00:15:51,839 --> 00:15:54,959
more

00:15:52,720 --> 00:15:56,320
we basically put in a condition uh to

00:15:54,959 --> 00:15:59,120
line up the enumeration

00:15:56,320 --> 00:16:00,880
the stock id uh with the stock name and

00:15:59,120 --> 00:16:01,680
maybe give two decimal places for the

00:16:00,880 --> 00:16:04,320
float

00:16:01,680 --> 00:16:05,600
uh and for the the trade date time we'll

00:16:04,320 --> 00:16:08,800
keep the same so if we go

00:16:05,600 --> 00:16:11,040
to that the next slide

00:16:08,800 --> 00:16:12,720
so actually um we're starting to get

00:16:11,040 --> 00:16:14,240
data that looks a little bit more

00:16:12,720 --> 00:16:15,519
realistic i mean there's still some

00:16:14,240 --> 00:16:16,880
problems with the data

00:16:15,519 --> 00:16:19,040
but i imagine that this would probably

00:16:16,880 --> 00:16:20,560
be fine for volume testing

00:16:19,040 --> 00:16:22,560
but if you're trying to do functional

00:16:20,560 --> 00:16:23,360
testing clearly you can see in this

00:16:22,560 --> 00:16:26,639
example

00:16:23,360 --> 00:16:27,360
uh the the stock price of bt has varied

00:16:26,639 --> 00:16:29,519
wildly

00:16:27,360 --> 00:16:31,199
now that's unlikely to work if you're

00:16:29,519 --> 00:16:33,360
you're trying to get that into a system

00:16:31,199 --> 00:16:34,399
and you're using this the stock price

00:16:33,360 --> 00:16:35,040
like that because the system would

00:16:34,399 --> 00:16:37,040
clearly go

00:16:35,040 --> 00:16:38,399
well that stock price has jumped hugely

00:16:37,040 --> 00:16:40,240
but actually if you're doing volume

00:16:38,399 --> 00:16:41,360
testing maybe that's okay maybe the

00:16:40,240 --> 00:16:43,360
shape of the data

00:16:41,360 --> 00:16:45,040
is accurate enough for volume testing

00:16:43,360 --> 00:16:47,279
and as you can see even this really

00:16:45,040 --> 00:16:49,120
simple example with five columns

00:16:47,279 --> 00:16:50,880
you actually need to get a reasonable

00:16:49,120 --> 00:16:52,399
set of rules in place

00:16:50,880 --> 00:16:54,399
to start to get the data looking

00:16:52,399 --> 00:16:56,240
realistic and we worked

00:16:54,399 --> 00:16:57,839
with one particular client that had very

00:16:56,240 --> 00:17:00,480
large files

00:16:57,839 --> 00:17:02,639
and originally we were generating i

00:17:00,480 --> 00:17:06,000
think for 150 columns

00:17:02,639 --> 00:17:07,839
they ended up generating over 3000 rules

00:17:06,000 --> 00:17:09,439
to make the data look realistic enough

00:17:07,839 --> 00:17:11,360
to do her volume testing

00:17:09,439 --> 00:17:13,039
and even then it wasn't anywhere near

00:17:11,360 --> 00:17:14,720
realistic enough to do functionality

00:17:13,039 --> 00:17:15,839
testing so that kind of gives you a bit

00:17:14,720 --> 00:17:18,160
of a feel for

00:17:15,839 --> 00:17:19,600
how quickly uh using the rules based

00:17:18,160 --> 00:17:21,600
approach you can get to the point where

00:17:19,600 --> 00:17:23,990
you've just got too many rules to manage

00:17:21,600 --> 00:17:26,959
okay next slide

00:17:23,990 --> 00:17:30,080
[Music]

00:17:26,959 --> 00:17:32,080
yeah as i said you know with 150 columns

00:17:30,080 --> 00:17:33,919
we saw over 3000 rules

00:17:32,080 --> 00:17:35,280
uh really quickly and bear in mind this

00:17:33,919 --> 00:17:37,760
is a really simple

00:17:35,280 --> 00:17:38,559
case i've only looked at the challenge

00:17:37,760 --> 00:17:41,280
um where

00:17:38,559 --> 00:17:42,880
we uh have um simple cases where each

00:17:41,280 --> 00:17:44,400
row is independent of the azure

00:17:42,880 --> 00:17:46,000
if you were trying to do something like

00:17:44,400 --> 00:17:48,720
generate a realistic looking bank

00:17:46,000 --> 00:17:49,600
account the rules would be way more

00:17:48,720 --> 00:17:51,520
complicated

00:17:49,600 --> 00:17:52,720
you would have to do rules on uh how

00:17:51,520 --> 00:17:54,160
much money you're spending

00:17:52,720 --> 00:17:55,919
you would want the rent to come out at

00:17:54,160 --> 00:17:57,520
the same time every month and you might

00:17:55,919 --> 00:17:58,400
have dependencies between things you

00:17:57,520 --> 00:17:59,600
might go well

00:17:58,400 --> 00:18:00,640
it's getting near the end of the month

00:17:59,600 --> 00:18:01,679
the person hasn't got money in their

00:18:00,640 --> 00:18:03,760
bank account maybe they wouldn't

00:18:01,679 --> 00:18:08,559
withdraw 300 pounds cash

00:18:03,760 --> 00:18:08,559
next slide please um

00:18:08,960 --> 00:18:18,080
i think that should be yeah

00:18:15,520 --> 00:18:18,960
sorry i went the wrong way yeah sorry

00:18:18,080 --> 00:18:20,880
yeah so as we

00:18:18,960 --> 00:18:23,120
we talked about a realistic bank account

00:18:20,880 --> 00:18:25,440
salary coming in same day every month

00:18:23,120 --> 00:18:27,440
uh same outgoing such as rent etc

00:18:25,440 --> 00:18:29,120
outgoings hopefully less than incomings

00:18:27,440 --> 00:18:30,720
realistic amounts coffee at prep

00:18:29,120 --> 00:18:33,039
shouldn't be 300 pounds

00:18:30,720 --> 00:18:35,120
and also realistic number of events i

00:18:33,039 --> 00:18:37,520
you end up with a state system

00:18:35,120 --> 00:18:39,360
and rolling stats ie balance and when

00:18:37,520 --> 00:18:40,799
you get into that situation you quickly

00:18:39,360 --> 00:18:42,320
come to the conclusion that you need to

00:18:40,799 --> 00:18:44,720
start handwriting the code

00:18:42,320 --> 00:18:46,160
in fact if you want data to be as

00:18:44,720 --> 00:18:47,679
accurate as the application

00:18:46,160 --> 00:18:49,520
you probably end up getting to a

00:18:47,679 --> 00:18:51,600
situation where you have to write

00:18:49,520 --> 00:18:53,600
as much logic in the generation of the

00:18:51,600 --> 00:18:55,520
data as the business logic that you have

00:18:53,600 --> 00:18:59,200
in your application originally

00:18:55,520 --> 00:18:59,200
i think that's over to you now paul

00:19:02,960 --> 00:19:06,880
yeah so i guess some examples we've been

00:19:04,799 --> 00:19:08,960
looking at for ourselves you know

00:19:06,880 --> 00:19:11,120
providing realistic test data for our

00:19:08,960 --> 00:19:12,960
client onboarding platforms and

00:19:11,120 --> 00:19:14,160
they're quite complicated onboarding

00:19:12,960 --> 00:19:17,280
requests so

00:19:14,160 --> 00:19:19,360
um you're handling all the kyc um very

00:19:17,280 --> 00:19:20,720
complex complicated kind of multi-nested

00:19:19,360 --> 00:19:22,799
level bits of data

00:19:20,720 --> 00:19:25,200
um also looks like you're generating

00:19:22,799 --> 00:19:27,440
risk and pnl with realistic value so by

00:19:25,200 --> 00:19:29,600
analyzing the production you know p l

00:19:27,440 --> 00:19:30,480
data and then using that to make sure

00:19:29,600 --> 00:19:33,200
that

00:19:30,480 --> 00:19:34,320
uh things like antennas currencies

00:19:33,200 --> 00:19:36,240
curves and all the rest

00:19:34,320 --> 00:19:38,080
all line up properly in a realistic way

00:19:36,240 --> 00:19:39,360
and then using kind of almost similar

00:19:38,080 --> 00:19:41,280
values as well

00:19:39,360 --> 00:19:43,039
so and also we've uh been generating

00:19:41,280 --> 00:19:45,520
portfolios of trades so you know

00:19:43,039 --> 00:19:47,200
um desired characteristics a little bit

00:19:45,520 --> 00:19:50,240
like scenario based so we can generate

00:19:47,200 --> 00:19:51,760
a portfolio of interest rate swaps to

00:19:50,240 --> 00:19:53,440
and add different kind of

00:19:51,760 --> 00:19:54,000
characteristics into the generation off

00:19:53,440 --> 00:19:55,280
there

00:19:54,000 --> 00:19:56,799
uh other things we've looked at credit

00:19:55,280 --> 00:19:58,720
card payments between merchants and card

00:19:56,799 --> 00:20:00,400
holders again analyzing those data sets

00:19:58,720 --> 00:20:01,760
that's quite an interesting

00:20:00,400 --> 00:20:03,919
different kind of way you have to do the

00:20:01,760 --> 00:20:05,760
analysis um

00:20:03,919 --> 00:20:07,760
it's near refining it helps very

00:20:05,760 --> 00:20:08,960
much with is um

00:20:07,760 --> 00:20:10,480
easy exploratory relationships with

00:20:08,960 --> 00:20:12,159
vendors and cloud providers so before

00:20:10,480 --> 00:20:14,159
you often let anybody near

00:20:12,159 --> 00:20:15,200
anything of your data you have you have

00:20:14,159 --> 00:20:17,919
to get through

00:20:15,200 --> 00:20:20,240
signing contracts big ndas so if we

00:20:17,919 --> 00:20:23,120
start actually just sharing some

00:20:20,240 --> 00:20:23,679
purely fully public domain data sets

00:20:23,120 --> 00:20:26,960
between

00:20:23,679 --> 00:20:28,960
each other that are um

00:20:26,960 --> 00:20:30,000
structurally correct things become a lot

00:20:28,960 --> 00:20:31,280
easier very quickly

00:20:30,000 --> 00:20:33,280
in terms of that exploratory

00:20:31,280 --> 00:20:35,200
relationship um

00:20:33,280 --> 00:20:37,520
so i was hoping to demo this today but

00:20:35,200 --> 00:20:40,400
unfortunately my main desktop pc

00:20:37,520 --> 00:20:40,720
has died of death and blue screen so i'm

00:20:40,400 --> 00:20:41,840
gonna

00:20:40,720 --> 00:20:44,159
have to unfortunately walk you through

00:20:41,840 --> 00:20:45,840
this and not do a live demo so

00:20:44,159 --> 00:20:47,360
with data hub and i've actually like

00:20:45,840 --> 00:20:49,600
you've only got a few minutes anyway

00:20:47,360 --> 00:20:50,799
so simply to install data hub use right

00:20:49,600 --> 00:20:52,320
it's python based

00:20:50,799 --> 00:20:54,080
anyone who knows python you do pip

00:20:52,320 --> 00:20:56,480
install github core

00:20:54,080 --> 00:20:57,919
and you'll you'll bring down the library

00:20:56,480 --> 00:21:00,480
and then

00:20:57,919 --> 00:21:02,799
very simply if you uh were to handcraft

00:21:00,480 --> 00:21:04,559
some rules in a simulated data helix

00:21:02,799 --> 00:21:06,159
we could if we wanted to create say a

00:21:04,559 --> 00:21:06,799
set of accounts we could quickly do this

00:21:06,159 --> 00:21:08,960
where we'll say

00:21:06,799 --> 00:21:10,720
we want a region here's some data to

00:21:08,960 --> 00:21:11,679
choose from here's some weights for the

00:21:10,720 --> 00:21:13,919
data

00:21:11,679 --> 00:21:16,080
now we want a country um so there's so

00:21:13,919 --> 00:21:18,000
data has kind of inbuilt

00:21:16,080 --> 00:21:19,679
types for things like current countries

00:21:18,000 --> 00:21:21,520
currencies and those kind of things so

00:21:19,679 --> 00:21:23,600
it understands already what they are

00:21:21,520 --> 00:21:25,120
so we say look now give me a country and

00:21:23,600 --> 00:21:25,600
base the country based on the region

00:21:25,120 --> 00:21:27,120
field

00:21:25,600 --> 00:21:28,960
so it will select countries now

00:21:27,120 --> 00:21:30,799
appropriate to the region

00:21:28,960 --> 00:21:32,480
then we'll see what an industry so you

00:21:30,799 --> 00:21:35,520
know are you in

00:21:32,480 --> 00:21:37,679
retail um banking finance you know

00:21:35,520 --> 00:21:39,360
agriculture whatever and then generate a

00:21:37,679 --> 00:21:41,919
very specific industry code

00:21:39,360 --> 00:21:43,760
based off of that industry it sounds now

00:21:41,919 --> 00:21:44,159
generate a legal name for that kind of

00:21:43,760 --> 00:21:48,159
thing

00:21:44,159 --> 00:21:51,840
uh that this record so we'll call it um

00:21:48,159 --> 00:21:52,159
you know um abc mining company limited

00:21:51,840 --> 00:21:54,640
or

00:21:52,159 --> 00:21:55,840
whatever um and so there's a lot of work

00:21:54,640 --> 00:21:58,320
in here where we

00:21:55,840 --> 00:21:59,440
generate them appropriate names

00:21:58,320 --> 00:22:01,600
synthetically

00:21:59,440 --> 00:22:03,679
based on the industry in the country

00:22:01,600 --> 00:22:05,600
that that this thing's in

00:22:03,679 --> 00:22:07,280
um and then we generate ldi code or

00:22:05,600 --> 00:22:11,120
other things evpd whatever

00:22:07,280 --> 00:22:14,240
and use various functions so um

00:22:11,120 --> 00:22:17,679
it's all in python so um

00:22:14,240 --> 00:22:20,400
yeah and it's very easy to extend

00:22:17,679 --> 00:22:22,000
now if we were to look at the analysis

00:22:20,400 --> 00:22:23,120
what we can do

00:22:22,000 --> 00:22:24,880
is you've got two different functions

00:22:23,120 --> 00:22:26,320
here so this generate model function

00:22:24,880 --> 00:22:27,919
functions in the top

00:22:26,320 --> 00:22:29,840
that's what you'd run inside your kind

00:22:27,919 --> 00:22:31,039
of in your inside your production domain

00:22:29,840 --> 00:22:33,360
so you'll say

00:22:31,039 --> 00:22:34,960
look take this csv file or whatever

00:22:33,360 --> 00:22:36,720
input stream it is

00:22:34,960 --> 00:22:38,799
now create this thing called a model

00:22:36,720 --> 00:22:40,880
file.json so that's the output

00:22:38,799 --> 00:22:41,840
and then you give it essentially the

00:22:40,880 --> 00:22:44,480
classifiers

00:22:41,840 --> 00:22:46,640
and the continuous values also discrete

00:22:44,480 --> 00:22:48,640
values and continuous values you say

00:22:46,640 --> 00:22:50,080
look here's the region countries code

00:22:48,640 --> 00:22:50,960
industry code sick names that i want you

00:22:50,080 --> 00:22:53,200
to analyze

00:22:50,960 --> 00:22:55,280
and work out how they're distributed and

00:22:53,200 --> 00:22:58,799
then inside these

00:22:55,280 --> 00:23:00,480
this set of um classifier information

00:22:58,799 --> 00:23:02,640
these are like the continuous data

00:23:00,480 --> 00:23:05,039
values so assets under management

00:23:02,640 --> 00:23:05,840
estimated value um and then there's your

00:23:05,039 --> 00:23:07,919
bit

00:23:05,840 --> 00:23:09,120
we support like a plug-in model so this

00:23:07,919 --> 00:23:11,679
code's a little bit old

00:23:09,120 --> 00:23:12,960
so there's different analysis modules

00:23:11,679 --> 00:23:13,919
which are tailored towards different

00:23:12,960 --> 00:23:16,640
data sets

00:23:13,919 --> 00:23:18,000
and also there's support soon once i

00:23:16,640 --> 00:23:19,520
finish doing the pr

00:23:18,000 --> 00:23:21,039
and it's in there which will support

00:23:19,520 --> 00:23:23,919
kind of multi-table as well

00:23:21,039 --> 00:23:25,120
so there's a bunch of stuff in there and

00:23:23,919 --> 00:23:26,320
then what we can do

00:23:25,120 --> 00:23:28,320
here very quickly is we can then

00:23:26,320 --> 00:23:32,799
generate from that that model

00:23:28,320 --> 00:23:35,679
so we can now say uh generate from model

00:23:32,799 --> 00:23:36,960
um this is called a fast bucket model um

00:23:35,679 --> 00:23:38,960
so it's very very quick

00:23:36,960 --> 00:23:40,720
give it that model file.json which has

00:23:38,960 --> 00:23:42,640
got that different that kind of

00:23:40,720 --> 00:23:44,480
statistical model in there

00:23:42,640 --> 00:23:46,000
and now i'll go and generate and then we

00:23:44,480 --> 00:23:47,919
can also you can see when we talk about

00:23:46,000 --> 00:23:48,480
enhancing the data we can actually add

00:23:47,919 --> 00:23:50,559
back in

00:23:48,480 --> 00:23:52,400
things like a name and an lei code which

00:23:50,559 --> 00:23:53,679
work which we removed from the original

00:23:52,400 --> 00:23:55,520
data set so we can then

00:23:53,679 --> 00:23:56,799
add these extra attributes back onto it

00:23:55,520 --> 00:23:58,400
synthetically again

00:23:56,799 --> 00:24:00,080
so that's kind of briefly what kind of

00:23:58,400 --> 00:24:02,159
data does and sorry i couldn't do a live

00:24:00,080 --> 00:24:03,679
demo but um things went already wrong

00:24:02,159 --> 00:24:05,440
datehub is also incredibly easy to

00:24:03,679 --> 00:24:06,159
extend so if there's not a function in

00:24:05,440 --> 00:24:08,159
if you want

00:24:06,159 --> 00:24:10,480
with a couple of lines of python you can

00:24:08,159 --> 00:24:11,840
um you know extend it so

00:24:10,480 --> 00:24:13,200
you know here's here's one where now

00:24:11,840 --> 00:24:14,640
we're adding a little message in there

00:24:13,200 --> 00:24:17,120
and it's going to go hello

00:24:14,640 --> 00:24:18,320
whatever your name is um it just takes a

00:24:17,120 --> 00:24:21,679
couple lines of codes to

00:24:18,320 --> 00:24:22,640
to do that um so that's how you can

00:24:21,679 --> 00:24:24,320
extend data

00:24:22,640 --> 00:24:26,240
uh so if it's something in there you

00:24:24,320 --> 00:24:29,279
that doesn't you want extra

00:24:26,240 --> 00:24:31,520
um it's really easy

00:24:29,279 --> 00:24:32,320
right um so what's next for up and data

00:24:31,520 --> 00:24:33,840
helix so

00:24:32,320 --> 00:24:35,600
uh the two projects we're bringing them

00:24:33,840 --> 00:24:38,080
together um

00:24:35,600 --> 00:24:38,880
if ever we're also investigating in

00:24:38,080 --> 00:24:41,840
terms of the

00:24:38,880 --> 00:24:42,640
data specification how we integrate with

00:24:41,840 --> 00:24:45,120
the

00:24:42,640 --> 00:24:47,200
alloy legends uh contributions to finos

00:24:45,120 --> 00:24:49,679
which is great that's got a whole

00:24:47,200 --> 00:24:50,880
uml like markup language sorry

00:24:49,679 --> 00:24:52,159
functional language about it that

00:24:50,880 --> 00:24:53,840
describes data sets

00:24:52,159 --> 00:24:55,200
so look at how we can integrate those so

00:24:53,840 --> 00:24:55,840
we can actually start generating data

00:24:55,200 --> 00:24:59,200
sets from

00:24:55,840 --> 00:25:01,360
legend uh specifications um

00:24:59,200 --> 00:25:03,200
so in the next version of data hub we've

00:25:01,360 --> 00:25:05,600
got um

00:25:03,200 --> 00:25:06,880
some extra bits so david at the moment

00:25:05,600 --> 00:25:08,000
if we're doing an analysis of data sets

00:25:06,880 --> 00:25:10,159
all our models

00:25:08,000 --> 00:25:11,279
support classifiers with continuous

00:25:10,159 --> 00:25:12,640
there we haven't got anything that

00:25:11,279 --> 00:25:14,640
supports continuous values only so

00:25:12,640 --> 00:25:16,880
that's a bit of a heart enhancement

00:25:14,640 --> 00:25:18,640
integrating a ct gan so that's like a

00:25:16,880 --> 00:25:19,200
another big open source project that

00:25:18,640 --> 00:25:23,360
does

00:25:19,200 --> 00:25:24,240
um that uses gans to analyze data so

00:25:23,360 --> 00:25:26,080
integrating that

00:25:24,240 --> 00:25:28,640
and making it so it's seamless within

00:25:26,080 --> 00:25:31,520
the product and multi-table support so

00:25:28,640 --> 00:25:32,159
you just supply it you know a bunch of

00:25:31,520 --> 00:25:33,760
files

00:25:32,159 --> 00:25:35,279
and tell it what the foreign key primary

00:25:33,760 --> 00:25:36,960
key relationships are and then it'll be

00:25:35,279 --> 00:25:40,000
able to use that for its analysis

00:25:36,960 --> 00:25:41,840
and generate them as well um

00:25:40,000 --> 00:25:43,919
we're also building more foundry types

00:25:41,840 --> 00:25:45,360
understanding of q-tip sizes any eyes

00:25:43,919 --> 00:25:46,320
curves tenors and all those kind of

00:25:45,360 --> 00:25:48,320
things

00:25:46,320 --> 00:25:49,760
as well as things where in that data

00:25:48,320 --> 00:25:51,919
analysis

00:25:49,760 --> 00:25:52,799
at the moment you have to say what each

00:25:51,919 --> 00:25:54,080
is like

00:25:52,799 --> 00:25:55,440
you have to say look these are the

00:25:54,080 --> 00:25:56,080
columns i want so we're looking at

00:25:55,440 --> 00:25:57,440
building data

00:25:56,080 --> 00:25:59,520
type predictors in there so we can look

00:25:57,440 --> 00:26:00,000
at your data set and then go that looks

00:25:59,520 --> 00:26:01,520
like a q

00:26:00,000 --> 00:26:03,679
sip that looks like a currency that

00:26:01,520 --> 00:26:04,240
looks like a pii attribute it's a name

00:26:03,679 --> 00:26:06,559
or a

00:26:04,240 --> 00:26:08,000
currency you know something that's there

00:26:06,559 --> 00:26:09,760
so it just helped

00:26:08,000 --> 00:26:11,200
move things along and also we're looking

00:26:09,760 --> 00:26:13,200
at spark integration for

00:26:11,200 --> 00:26:14,960
really big data set generation so we'll

00:26:13,200 --> 00:26:16,960
we'll use pi spark

00:26:14,960 --> 00:26:18,080
to then you know generate actually on a

00:26:16,960 --> 00:26:19,279
cluster um

00:26:18,080 --> 00:26:20,640
[Music]

00:26:19,279 --> 00:26:21,840
and i think down the line this is

00:26:20,640 --> 00:26:23,039
probably going to be well into next year

00:26:21,840 --> 00:26:25,120
we're going to look at actually how we

00:26:23,039 --> 00:26:27,520
support agent-based modeling as well so

00:26:25,120 --> 00:26:29,279
if you're trying to use do simulation

00:26:27,520 --> 00:26:30,559
how we can then synthetically generate

00:26:29,279 --> 00:26:34,159
actors uh for you

00:26:30,559 --> 00:26:36,559
at the desired way so cool

00:26:34,159 --> 00:26:37,919
um yeah i guess if this sounds any

00:26:36,559 --> 00:26:40,400
interesting you know please reach out to

00:26:37,919 --> 00:26:41,840
us uh the details should be around uh

00:26:40,400 --> 00:26:44,400
that they're not on this deck i should

00:26:41,840 --> 00:26:45,919
put it on there um we're always looking

00:26:44,400 --> 00:26:47,200
for help so if you want to get involved

00:26:45,919 --> 00:26:49,279
we're looking for

00:26:47,200 --> 00:26:50,640
anybody who can put code in python

00:26:49,279 --> 00:26:52,080
particularly if you've got any kind of

00:26:50,640 --> 00:26:53,520
data science background as well that

00:26:52,080 --> 00:26:54,880
would be fantastic

00:26:53,520 --> 00:26:56,960
and if you want to help us particularly

00:26:54,880 --> 00:26:58,320
on the alloy or legend integration

00:26:56,960 --> 00:27:00,159
that would be really great to reach out

00:26:58,320 --> 00:27:03,360
to us as well but uh yeah

00:27:00,159 --> 00:27:04,240
the if you code in python and want to

00:27:03,360 --> 00:27:05,520
get involved

00:27:04,240 --> 00:27:07,760
please do even if you can't code in

00:27:05,520 --> 00:27:09,760
python uh we'll teach you on the way

00:27:07,760 --> 00:27:12,159
um yeah andrew you've got anything to

00:27:09,760 --> 00:27:15,279
finish up with

00:27:12,159 --> 00:27:18,960
uh no that was great paul

00:27:15,279 --> 00:27:20,320
cool awesome uh so that's that's it i

00:27:18,960 --> 00:27:23,120
think we maybe hopefully got a couple of

00:27:20,320 --> 00:27:23,120
minutes for questions

00:27:26,640 --> 00:27:30,799
which is your out head out see what we

00:27:32,840 --> 00:27:37,679
have

00:27:34,799 --> 00:27:39,679
course there's no questions in i guess

00:27:37,679 --> 00:27:41,520
we can probably um

00:27:39,679 --> 00:27:49,840
maybe give it one more minute and then

00:27:41,520 --> 00:27:49,840
uh wrap up

00:27:50,799 --> 00:28:03,840
to the awkward side in power

00:28:04,159 --> 00:28:07,520
cool great thank you everybody i'll put

00:28:05,520 --> 00:28:09,840
my contact details within the chat

00:28:07,520 --> 00:28:12,960
um you know please do reach out to us if

00:28:09,840 --> 00:28:15,520
you want to that'd be great

00:28:12,960 --> 00:28:19,919
thanks for coming everybody thanks for

00:28:15,520 --> 00:28:19,919

YouTube URL: https://www.youtube.com/watch?v=keNm0U3Wtu4


