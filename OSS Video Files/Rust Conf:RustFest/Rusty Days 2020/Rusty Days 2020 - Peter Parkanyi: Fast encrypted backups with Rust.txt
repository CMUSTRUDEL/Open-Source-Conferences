Title: Rusty Days 2020 - Peter Parkanyi: Fast encrypted backups with Rust
Publication date: 2020-08-02
Playlist: Rusty Days 2020
Description: 
	Agenda ► https://rusty-days.org/agenda
Playlist with all talks ► https://www.youtube.com/playlist?list=PLf3u8NhoEikhTC5radGrmmqdkOK-xMDoZ

Follow ►
Facebook: https://rusty-days.org/facebook
Twitch: https://rusty-days.org/twitch
Twitter: https://rusty-days.org/twitter

This video ►
Zerostash is a deduplicated and encrypted file storage format that is optimized for speed.

The talk will walk through the problem domain, the design decisions that were influenced directly by the need for speed for tools like this, and how to reduce synchronization latency in for remote or p2p sync.

The listeners will learn about how backup software generally works, and where the design tradeoffs lie when designing a storage layer. In addition, they get some insights into generic Rust optimization tricks and gotchas:

* Reducing the number of copies
* Slicing a slice will reduce performance
* LTO
* inlining
* reducing code size on the hot path
* threads and pipelining
* trusting the operating system
* using vectorization for the costliest things
Captions: 
	00:00:01,680 --> 00:00:06,720
hi everyone um

00:00:03,520 --> 00:00:07,839
welcome to the stream tonight and thank

00:00:06,720 --> 00:00:10,160
you for joining

00:00:07,839 --> 00:00:11,599
and uh thanks very much to the to the

00:00:10,160 --> 00:00:13,040
rusty days team

00:00:11,599 --> 00:00:15,759
uh for pulling this amazing event

00:00:13,040 --> 00:00:16,960
together it's it's really exciting to be

00:00:15,759 --> 00:00:18,480
part of it and it's really exciting to

00:00:16,960 --> 00:00:20,160
see so many people from so many

00:00:18,480 --> 00:00:25,039
different parts of the world

00:00:20,160 --> 00:00:25,039
on um on an online rust conference um

00:00:25,840 --> 00:00:29,760
a little bit about i'm tonight i'm going

00:00:27,920 --> 00:00:32,800
to talk about um

00:00:29,760 --> 00:00:33,360
encrypted backups and and how you um how

00:00:32,800 --> 00:00:36,320
you actually

00:00:33,360 --> 00:00:37,920
create encrypted backups using rust but

00:00:36,320 --> 00:00:40,640
before we step into the meat

00:00:37,920 --> 00:00:42,160
i'm just going to introduce myself i

00:00:40,640 --> 00:00:44,399
work in security software

00:00:42,160 --> 00:00:46,160
as a day job and i quote roster the day

00:00:44,399 --> 00:00:48,960
job

00:00:46,160 --> 00:00:49,520
at red sift i work on ingredient which

00:00:48,960 --> 00:00:53,280
is

00:00:49,520 --> 00:00:56,640
a hardware a cloud monitoring agent

00:00:53,280 --> 00:00:59,840
which runs rust in the linux kernel as

00:00:56,640 --> 00:00:59,840
ebpf modules

00:01:00,640 --> 00:01:03,760
it's been very very exciting and

00:01:02,480 --> 00:01:07,119
interesting how

00:01:03,760 --> 00:01:08,640
rust allowed us to actually lower the

00:01:07,119 --> 00:01:11,600
barrier to entry to something as

00:01:08,640 --> 00:01:11,600
technical and as

00:01:11,760 --> 00:01:15,040
in the grain so to say as the newest

00:01:14,080 --> 00:01:18,799
kernel

00:01:15,040 --> 00:01:20,960
um and actually the libraries that

00:01:18,799 --> 00:01:22,880
that we were able to build using rust

00:01:20,960 --> 00:01:25,360
are really really pleasant to use

00:01:22,880 --> 00:01:28,479
um as opposed to dc interfaces and and

00:01:25,360 --> 00:01:30,640
we can provide the complete tool chain

00:01:28,479 --> 00:01:32,159
um so we're using ingredient for

00:01:30,640 --> 00:01:35,600
monitoring

00:01:32,159 --> 00:01:38,960
um the the cloud

00:01:35,600 --> 00:01:43,200
data and cloud uh network traffic

00:01:38,960 --> 00:01:47,280
but today i will talk about a little bit

00:01:43,200 --> 00:01:47,280
different aspect of cloud protection

00:01:48,240 --> 00:01:52,799
and when i say cloud what i really mean

00:01:50,560 --> 00:01:54,880
is somebody else's computer

00:01:52,799 --> 00:01:56,240
and when i say cloud storage what i

00:01:54,880 --> 00:02:00,240
really mean is storing your holiday

00:01:56,240 --> 00:02:00,240
pictures on somebody else's computer

00:02:01,439 --> 00:02:05,439
um the problem is that really our only

00:02:04,159 --> 00:02:06,880
layer of protection

00:02:05,439 --> 00:02:08,959
in most of the cases especially if

00:02:06,880 --> 00:02:11,760
you're using software provided by the

00:02:08,959 --> 00:02:14,239
big five is privacy policies

00:02:11,760 --> 00:02:14,800
these are not generally super helpful in

00:02:14,239 --> 00:02:17,280
terms of

00:02:14,800 --> 00:02:17,840
protecting your privacy they are very

00:02:17,280 --> 00:02:23,120
often

00:02:17,840 --> 00:02:27,200
designed to be deliberately vague and

00:02:23,120 --> 00:02:30,239
we surely can do better

00:02:27,200 --> 00:02:30,879
and some of that better is uh encryption

00:02:30,239 --> 00:02:32,480
at rest

00:02:30,879 --> 00:02:35,519
if you go to a service provider's

00:02:32,480 --> 00:02:37,280
website they very often tell that

00:02:35,519 --> 00:02:38,800
they are they provide military grade

00:02:37,280 --> 00:02:40,319
encryption to your data and that is

00:02:38,800 --> 00:02:42,319
going that is what is going to keep it

00:02:40,319 --> 00:02:44,319
secure

00:02:42,319 --> 00:02:46,000
however encryption at rest is only

00:02:44,319 --> 00:02:47,760
really useful if the military literally

00:02:46,000 --> 00:02:49,920
breaks into the data center

00:02:47,760 --> 00:02:51,680
and steals the hard drives that store

00:02:49,920 --> 00:02:54,879
your data

00:02:51,680 --> 00:02:58,000
for any type of online attack or sort of

00:02:54,879 --> 00:02:59,920
going through the front door

00:02:58,000 --> 00:03:01,680
like the twitter hacks that we've that

00:02:59,920 --> 00:03:05,519
we've seen recently

00:03:01,680 --> 00:03:08,720
that type of encryption is not going to

00:03:05,519 --> 00:03:12,080
your data at all it's it's

00:03:08,720 --> 00:03:13,120
almost as if it wasn't there so the idea

00:03:12,080 --> 00:03:15,040
is that we

00:03:13,120 --> 00:03:16,640
have to enter we use end-to-end

00:03:15,040 --> 00:03:17,120
encryption and this is a buzzword that's

00:03:16,640 --> 00:03:22,720
been going

00:03:17,120 --> 00:03:25,840
around in the media quite a lot recently

00:03:22,720 --> 00:03:26,799
um the idea of end-to-end encryption is

00:03:25,840 --> 00:03:29,920
to encrypt

00:03:26,799 --> 00:03:31,280
your data on the client and make sure

00:03:29,920 --> 00:03:32,959
that only the client can

00:03:31,280 --> 00:03:36,480
decrypt that data and the server is

00:03:32,959 --> 00:03:38,400
completely unaware of what's in that

00:03:36,480 --> 00:03:40,080
now if you think about your holiday

00:03:38,400 --> 00:03:43,120
pictures this is obviously

00:03:40,080 --> 00:03:45,680
much more preferable to

00:03:43,120 --> 00:03:48,000
allowing any sort of systems

00:03:45,680 --> 00:03:50,480
administrator to even inadvertently

00:03:48,000 --> 00:03:51,680
take a look at your pictures um if you

00:03:50,480 --> 00:03:55,439
use end-to-end encryption

00:03:51,680 --> 00:03:58,879
you can be sure that it is only you

00:03:55,439 --> 00:04:01,120
or whoever you authorized um

00:03:58,879 --> 00:04:03,680
that will actually access that piece of

00:04:01,120 --> 00:04:03,680
information

00:04:04,319 --> 00:04:08,560
however when you're writing software for

00:04:06,480 --> 00:04:10,959
um

00:04:08,560 --> 00:04:13,200
for encrypting especially backups and

00:04:10,959 --> 00:04:14,640
photos and those types of files

00:04:13,200 --> 00:04:17,840
you kind of have to pick your battles

00:04:14,640 --> 00:04:21,680
wisely the

00:04:17,840 --> 00:04:25,120
the existing software that's out there

00:04:21,680 --> 00:04:27,040
they use normally they normally tune it

00:04:25,120 --> 00:04:30,240
towards the security side

00:04:27,040 --> 00:04:33,040
of um

00:04:30,240 --> 00:04:33,520
of the spectrum but i think there was a

00:04:33,040 --> 00:04:35,280
lot of

00:04:33,520 --> 00:04:37,600
development in the past sort of ten

00:04:35,280 --> 00:04:41,440
years in cryptography that

00:04:37,600 --> 00:04:44,000
um that demolished this dichotomy of

00:04:41,440 --> 00:04:46,560
of performance versus security so we can

00:04:44,000 --> 00:04:50,160
actually approach the problem in a way

00:04:46,560 --> 00:04:52,160
where we are both fast and

00:04:50,160 --> 00:04:53,840
we are both correct and this is where us

00:04:52,160 --> 00:04:57,680
comes into the picture it really helps

00:04:53,840 --> 00:05:01,120
us with the correct part

00:04:57,680 --> 00:05:04,560
so how do we actually performance

00:05:01,120 --> 00:05:06,560
uh just in general we have to minimize

00:05:04,560 --> 00:05:09,360
the latency maximize the throughput

00:05:06,560 --> 00:05:11,440
and and then profile and tweak and then

00:05:09,360 --> 00:05:13,039
rinse repeat

00:05:11,440 --> 00:05:15,600
what you're going to notice on the

00:05:13,039 --> 00:05:17,680
slides is that

00:05:15,600 --> 00:05:19,280
performance needs to be designed into a

00:05:17,680 --> 00:05:21,600
system

00:05:19,280 --> 00:05:23,840
before you actually start implementing

00:05:21,600 --> 00:05:25,600
something you need to think about

00:05:23,840 --> 00:05:26,880
how this is going that is going to be

00:05:25,600 --> 00:05:30,160
used and

00:05:26,880 --> 00:05:31,199
what sort of uh people are going to use

00:05:30,160 --> 00:05:33,440
it

00:05:31,199 --> 00:05:34,880
and then embed these assumptions into

00:05:33,440 --> 00:05:38,000
your design

00:05:34,880 --> 00:05:39,680
uh to provide the user experience that

00:05:38,000 --> 00:05:44,880
you're targeting

00:05:39,680 --> 00:05:44,880
with uh with the optimal scenario

00:05:46,560 --> 00:05:53,680
when i say latency what i really mean is

00:05:48,400 --> 00:05:55,440
the time to the first bit of response

00:05:53,680 --> 00:05:58,400
and you you can measure this in not a

00:05:55,440 --> 00:06:01,360
second or milliseconds

00:05:58,400 --> 00:06:02,319
you can when you're reading a file from

00:06:01,360 --> 00:06:03,680
a server

00:06:02,319 --> 00:06:05,680
for instance you're accessing your

00:06:03,680 --> 00:06:07,680
google drive or your icloud account

00:06:05,680 --> 00:06:09,520
you're sending a request to the service

00:06:07,680 --> 00:06:11,280
provider

00:06:09,520 --> 00:06:13,520
and the service provider will do a

00:06:11,280 --> 00:06:15,680
lookup on their site

00:06:13,520 --> 00:06:16,639
execute some sort of business logic and

00:06:15,680 --> 00:06:20,160
then return

00:06:16,639 --> 00:06:22,880
to you with your data now the latency

00:06:20,160 --> 00:06:24,720
is the first bit of response after this

00:06:22,880 --> 00:06:26,479
entire cycle has been done

00:06:24,720 --> 00:06:28,800
from the time that you finished sending

00:06:26,479 --> 00:06:32,560
your request

00:06:28,800 --> 00:06:33,759
um obviously in in a network scenario

00:06:32,560 --> 00:06:34,880
this is probably hundreds of

00:06:33,759 --> 00:06:37,280
milliseconds

00:06:34,880 --> 00:06:38,319
but when you're reading from a disk or

00:06:37,280 --> 00:06:41,039
an ssd

00:06:38,319 --> 00:06:42,479
that is going to be orders of magnitude

00:06:41,039 --> 00:06:46,000
different

00:06:42,479 --> 00:06:48,880
and lower even between spinning rust

00:06:46,000 --> 00:06:51,120
as in conventional hdds or ssds there

00:06:48,880 --> 00:06:53,919
can be huge differences

00:06:51,120 --> 00:06:55,520
really really interesting one is

00:06:53,919 --> 00:06:58,800
syscalls

00:06:55,520 --> 00:07:01,599
whenever you access the operating system

00:06:58,800 --> 00:07:02,000
you execute the syscall so typically

00:07:01,599 --> 00:07:03,840
opening

00:07:02,000 --> 00:07:06,240
a file or sending data through the

00:07:03,840 --> 00:07:09,520
network or reading or writing to a file

00:07:06,240 --> 00:07:09,520
are all system calls

00:07:10,160 --> 00:07:14,880
that involves some level of latency

00:07:13,199 --> 00:07:16,639
because of the way operating systems

00:07:14,880 --> 00:07:19,199
generally work

00:07:16,639 --> 00:07:20,720
and this can be significant if you're

00:07:19,199 --> 00:07:24,000
dealing with large amounts of data

00:07:20,720 --> 00:07:26,720
or large amounts of files

00:07:24,000 --> 00:07:28,160
throughput is the time to completion and

00:07:26,720 --> 00:07:29,840
we usually

00:07:28,160 --> 00:07:32,240
measure this in gigabytes per second or

00:07:29,840 --> 00:07:34,639
megabytes per second

00:07:32,240 --> 00:07:36,880
um this is a property of encryption

00:07:34,639 --> 00:07:40,720
algorithms or compression algorithms

00:07:36,880 --> 00:07:43,120
uh it is a property of your network link

00:07:40,720 --> 00:07:44,720
uh you buy you normally in europe you

00:07:43,120 --> 00:07:48,160
purchase

00:07:44,720 --> 00:07:52,720
your internet service based on

00:07:48,160 --> 00:07:56,080
the throughput that you will get

00:07:52,720 --> 00:07:58,319
in in an idea scenario and it is also

00:07:56,080 --> 00:08:00,240
a property of the disk not only the

00:07:58,319 --> 00:08:03,759
lookup speed is what matters but

00:08:00,240 --> 00:08:07,360
also the actual speed at which you

00:08:03,759 --> 00:08:07,360
extract data from from a desk

00:08:07,440 --> 00:08:15,759
um now that now that we have an idea

00:08:11,680 --> 00:08:17,680
about these sorts of terms

00:08:15,759 --> 00:08:19,680
i want to talk a little bit about zero

00:08:17,680 --> 00:08:22,479
stash

00:08:19,680 --> 00:08:23,440
and and what my aim was with designing

00:08:22,479 --> 00:08:26,800
this

00:08:23,440 --> 00:08:28,800
this piece of library so i wanted to

00:08:26,800 --> 00:08:29,280
hide all the metadata this is this is a

00:08:28,800 --> 00:08:31,520
really

00:08:29,280 --> 00:08:32,320
really interesting uh aspect of it i

00:08:31,520 --> 00:08:35,360
think

00:08:32,320 --> 00:08:37,200
because there's a lot of

00:08:35,360 --> 00:08:40,159
metadata that we store on our file

00:08:37,200 --> 00:08:40,640
systems and especially in backups they

00:08:40,159 --> 00:08:43,760
can

00:08:40,640 --> 00:08:43,760
expose a lot of stuff

00:08:45,040 --> 00:08:50,160
it is deduplicated so we save some space

00:08:48,160 --> 00:08:51,839
it's a nice to have it's not it wasn't

00:08:50,160 --> 00:08:55,360
really a big effort to implement it

00:08:51,839 --> 00:08:57,519
within the system but most importantly

00:08:55,360 --> 00:08:59,440
we can actually use this as an online

00:08:57,519 --> 00:09:02,480
file system

00:08:59,440 --> 00:09:04,959
that doesn't necessarily expose all of

00:09:02,480 --> 00:09:04,959
the data

00:09:05,200 --> 00:09:08,640
and he says this is really exciting

00:09:06,720 --> 00:09:10,320
because it also means that

00:09:08,640 --> 00:09:11,839
whenever a user logs into a cloud

00:09:10,320 --> 00:09:15,440
service we can also use

00:09:11,839 --> 00:09:16,560
the xero format as a key value store

00:09:15,440 --> 00:09:20,399
where we use their

00:09:16,560 --> 00:09:20,399
personally identifiable information

00:09:21,120 --> 00:09:24,640
and do this in a way that the server has

00:09:23,519 --> 00:09:27,519
no idea about

00:09:24,640 --> 00:09:28,720
whether does not necessarily need to

00:09:27,519 --> 00:09:32,560
have an idea

00:09:28,720 --> 00:09:34,959
um if the users

00:09:32,560 --> 00:09:38,640
are accessing their data or or which

00:09:34,959 --> 00:09:38,640
parts of the data they are accessing

00:09:39,760 --> 00:09:46,240
so in order to achieve uh sort of

00:09:42,959 --> 00:09:47,440
fast programs um the first step is to

00:09:46,240 --> 00:09:48,959
minimize latency

00:09:47,440 --> 00:09:51,600
a lot of backup software that are out

00:09:48,959 --> 00:09:54,080
there they are deduplicating your data

00:09:51,600 --> 00:09:57,920
by generating large numbers of files

00:09:54,080 --> 00:10:01,440
which is ideal from a lot of

00:09:57,920 --> 00:10:03,839
from a lot of aspects of the

00:10:01,440 --> 00:10:05,920
of the design space most importantly it

00:10:03,839 --> 00:10:08,800
reduces the complexity within the backup

00:10:05,920 --> 00:10:08,800
software itself

00:10:08,880 --> 00:10:14,800
however large numbers of small files

00:10:12,800 --> 00:10:16,959
means that you're accessing your files

00:10:14,800 --> 00:10:19,920
more frequently

00:10:16,959 --> 00:10:21,120
so what i thought would be a good idea

00:10:19,920 --> 00:10:24,320
is to pack

00:10:21,120 --> 00:10:27,279
uh all of these into relatively large

00:10:24,320 --> 00:10:28,240
uh objects uh and pack these objects

00:10:27,279 --> 00:10:31,519
densely

00:10:28,240 --> 00:10:33,279
so that we minimize the

00:10:31,519 --> 00:10:35,440
the access to the file system or the

00:10:33,279 --> 00:10:37,200
network whenever we're synchronizing or

00:10:35,440 --> 00:10:40,240
decrypting

00:10:37,200 --> 00:10:40,240
the data

00:10:41,920 --> 00:10:46,480
it is large enough to be efficient four

00:10:45,040 --> 00:10:50,399
megabyte happens to

00:10:46,480 --> 00:10:53,519
also kind of align with um

00:10:50,399 --> 00:10:56,959
access sizes of ssds

00:10:53,519 --> 00:10:57,600
and which gives us the really nice

00:10:56,959 --> 00:10:59,680
alignment

00:10:57,600 --> 00:11:01,760
and and actually a speed bump

00:10:59,680 --> 00:11:04,800
theoretically

00:11:01,760 --> 00:11:07,760
um but also it's it's uh

00:11:04,800 --> 00:11:08,560
it's a very versatile file size i feel

00:11:07,760 --> 00:11:10,399
um

00:11:08,560 --> 00:11:13,680
for different use cases you can increase

00:11:10,399 --> 00:11:15,920
that or this decrease this

00:11:13,680 --> 00:11:18,560
um but the key thing is that we only

00:11:15,920 --> 00:11:22,720
work on four megabyte uniform objects

00:11:18,560 --> 00:11:22,720
that that densely pack our data

00:11:24,000 --> 00:11:29,600
the raw structures that access this uh

00:11:27,279 --> 00:11:31,360
uh so object which is also represented

00:11:29,600 --> 00:11:33,519
as an object in zero stash

00:11:31,360 --> 00:11:35,279
uh looked like this uh there's a it's a

00:11:33,519 --> 00:11:39,279
generic thing because it's

00:11:35,279 --> 00:11:41,920
it um generally works on a file

00:11:39,279 --> 00:11:43,360
on a buffer and there doesn't need to be

00:11:41,920 --> 00:11:46,560
anything else

00:11:43,360 --> 00:11:49,680
um but a buffer

00:11:46,560 --> 00:11:50,720
it has a capacity it has a cursor and it

00:11:49,680 --> 00:11:54,399
has an id

00:11:50,720 --> 00:11:58,320
and the object id is um

00:11:54,399 --> 00:12:01,680
just 32 bytes of random

00:11:58,320 --> 00:12:02,639
um the capacity is interesting because

00:12:01,680 --> 00:12:06,800
we need to reserve

00:12:02,639 --> 00:12:09,760
some uh space at the end of the file

00:12:06,800 --> 00:12:10,320
uh for uh cryptographic tags and and a

00:12:09,760 --> 00:12:13,279
number of

00:12:10,320 --> 00:12:14,720
other accounting pieces and the cursor

00:12:13,279 --> 00:12:17,760
is

00:12:14,720 --> 00:12:23,519
something that um that i actually

00:12:17,760 --> 00:12:23,519
lifted over from the std libraries

00:12:23,680 --> 00:12:27,120
read write implementations

00:12:28,240 --> 00:12:32,880
but i did this for the for the sake of

00:12:30,240 --> 00:12:32,880
performance

00:12:33,839 --> 00:12:38,160
and the usual way of interacting with

00:12:35,920 --> 00:12:40,320
this object is is actually initializing

00:12:38,160 --> 00:12:44,000
it with the with the block buffer

00:12:40,320 --> 00:12:47,440
as the as the buffer

00:12:44,000 --> 00:12:47,440
and i talk about this later why

00:12:47,760 --> 00:12:52,800
step two choose the right primitives to

00:12:50,000 --> 00:12:54,959
maximize the throughput

00:12:52,800 --> 00:12:56,320
we're still in design space we're not

00:12:54,959 --> 00:12:59,040
we're just kind of playing around with

00:12:56,320 --> 00:13:01,839
the theoretical maximums

00:12:59,040 --> 00:13:04,839
so for indexing we need

00:13:01,839 --> 00:13:07,440
cryptographically strong

00:13:04,839 --> 00:13:09,040
primitives because

00:13:07,440 --> 00:13:10,480
the large numbers of files and because

00:13:09,040 --> 00:13:12,000
of the security properties that these

00:13:10,480 --> 00:13:14,240
provide

00:13:12,000 --> 00:13:15,519
so i went with the blake 2 which is not

00:13:14,240 --> 00:13:18,720
a standard

00:13:15,519 --> 00:13:21,279
a standardized hash function but

00:13:18,720 --> 00:13:21,839
it is um generally considered very

00:13:21,279 --> 00:13:25,440
strong

00:13:21,839 --> 00:13:27,040
and uh it can it can scale to very high

00:13:25,440 --> 00:13:30,079
performance especially with

00:13:27,040 --> 00:13:32,399
um efficient implementations

00:13:30,079 --> 00:13:35,120
as before um it's pretty much the same

00:13:32,399 --> 00:13:37,680
deal it's battle tested

00:13:35,120 --> 00:13:39,279
it doesn't come from any sort of large

00:13:37,680 --> 00:13:40,560
software vendor there's an open source

00:13:39,279 --> 00:13:43,760
implementation out there

00:13:40,560 --> 00:13:46,560
uh it's been used for ages it's a it's a

00:13:43,760 --> 00:13:50,240
trusty workhorse

00:13:46,560 --> 00:13:53,519
the of 20 poly construction is something

00:13:50,240 --> 00:13:57,839
from the

00:13:53,519 --> 00:13:59,360
house of daniel bernstein

00:13:57,839 --> 00:14:01,440
this is an authenticated encryption

00:13:59,360 --> 00:14:03,839
algorithm

00:14:01,440 --> 00:14:03,839
and

00:14:04,639 --> 00:14:08,240
the um the benefits of this is being

00:14:07,120 --> 00:14:11,600
really really fast

00:14:08,240 --> 00:14:13,600
and um also

00:14:11,600 --> 00:14:15,279
providing us with with what with the

00:14:13,600 --> 00:14:18,000
properties that we would normally expect

00:14:15,279 --> 00:14:20,240
from modern cryptographic primitives

00:14:18,000 --> 00:14:22,160
um and for deduplication i'm using c

00:14:20,240 --> 00:14:23,360
hash which does like 10 gigabytes per

00:14:22,160 --> 00:14:26,160
second

00:14:23,360 --> 00:14:27,600
um for hashing uh it is absolutely a

00:14:26,160 --> 00:14:30,800
non-cryptographic hash

00:14:27,600 --> 00:14:34,480
but it is it is generally very

00:14:30,800 --> 00:14:34,480
relatively hard and

00:14:34,560 --> 00:14:37,519
and really really fast

00:14:38,160 --> 00:14:41,199
now at this point we have some free

00:14:40,160 --> 00:14:44,399
optimizations

00:14:41,199 --> 00:14:45,279
um even though the standard library

00:14:44,399 --> 00:14:47,199
offers

00:14:45,279 --> 00:14:49,680
a lot of primitives for us to use

00:14:47,199 --> 00:14:54,480
especially for asynchronous programming

00:14:49,680 --> 00:14:57,680
um there are there are many many crates

00:14:54,480 --> 00:14:59,839
that offer basically free performance

00:14:57,680 --> 00:14:59,839
boost

00:15:00,639 --> 00:15:08,560
for channels between multiple processes

00:15:05,120 --> 00:15:10,160
the crossbeam channel offers quite a big

00:15:08,560 --> 00:15:14,000
speed up

00:15:10,160 --> 00:15:15,920
the crossbeam utils package uh crate

00:15:14,000 --> 00:15:17,040
um provides us with a with a threading

00:15:15,920 --> 00:15:20,480
implementation

00:15:17,040 --> 00:15:24,480
that is generally a bit more versatile

00:15:20,480 --> 00:15:28,079
than uh whatever is found in

00:15:24,480 --> 00:15:30,160
the standard library and uh the rv

00:15:28,079 --> 00:15:31,199
rw lock uh implementation in the

00:15:30,160 --> 00:15:33,839
standard library

00:15:31,199 --> 00:15:35,440
is um i don't wanna offend anyone but it

00:15:33,839 --> 00:15:36,720
doesn't have a great reputation in terms

00:15:35,440 --> 00:15:41,279
of performance

00:15:36,720 --> 00:15:44,560
uh so there are alternatives to like

00:15:41,279 --> 00:15:47,440
drop in alternatives to it that exist

00:15:44,560 --> 00:15:50,079
however for my use case i was better off

00:15:47,440 --> 00:15:53,440
using a parallel

00:15:50,079 --> 00:15:55,680
hash map library which is dash map

00:15:53,440 --> 00:15:57,519
and it's amazing it is really really

00:15:55,680 --> 00:16:00,800
fast it makes accessing

00:15:57,519 --> 00:16:01,839
um data from multiple threads really

00:16:00,800 --> 00:16:04,240
really easy

00:16:01,839 --> 00:16:06,399
and and provides a great api for doing

00:16:04,240 --> 00:16:09,759
so

00:16:06,399 --> 00:16:11,839
um i mentioned that blake 2 can

00:16:09,759 --> 00:16:12,800
actually achieve really high performance

00:16:11,839 --> 00:16:15,279
whenever

00:16:12,800 --> 00:16:17,920
you when you get a really efficient

00:16:15,279 --> 00:16:17,920
implementation

00:16:18,800 --> 00:16:26,000
and and

00:16:22,720 --> 00:16:27,120
that means that

00:16:26,000 --> 00:16:29,680
there is a really efficient

00:16:27,120 --> 00:16:32,000
implementation in rust um

00:16:29,680 --> 00:16:33,680
which is the s this is the cmd

00:16:32,000 --> 00:16:36,160
implementation

00:16:33,680 --> 00:16:37,440
as a bonus the rust argon 2 library also

00:16:36,160 --> 00:16:40,000
uses this

00:16:37,440 --> 00:16:41,519
as part of its argon 2 implementation so

00:16:40,000 --> 00:16:42,720
we're actually reducing the compile

00:16:41,519 --> 00:16:45,519
times

00:16:42,720 --> 00:16:46,639
while getting getting a really really

00:16:45,519 --> 00:16:49,680
nice

00:16:46,639 --> 00:16:52,720
black to speed

00:16:49,680 --> 00:16:55,040
lz4 is just a wrapper for the c library

00:16:52,720 --> 00:16:56,320
uh i kind of compared it to with with a

00:16:55,040 --> 00:16:59,759
couple of other crates

00:16:56,320 --> 00:17:05,039
like minis but

00:16:59,759 --> 00:17:06,640
um ld4 is just very versatile and very

00:17:05,039 --> 00:17:09,199
tunable

00:17:06,640 --> 00:17:10,160
um and c hash it's it's again a

00:17:09,199 --> 00:17:13,120
no-brainer

00:17:10,160 --> 00:17:14,319
great api great implementation really

00:17:13,120 --> 00:17:17,039
fast

00:17:14,319 --> 00:17:18,720
um and we're getting this all of these

00:17:17,039 --> 00:17:19,679
speed ups without actually having done

00:17:18,720 --> 00:17:22,799
any work

00:17:19,679 --> 00:17:24,400
um we're just using the right crates

00:17:22,799 --> 00:17:27,280
obviously the way that i learned that

00:17:24,400 --> 00:17:30,480
these are fast involved a lot of

00:17:27,280 --> 00:17:32,160
profiler driven development and

00:17:30,480 --> 00:17:34,320
and kind of like trying out everything

00:17:32,160 --> 00:17:35,919
that's out there um

00:17:34,320 --> 00:17:37,520
looking at at how complex the

00:17:35,919 --> 00:17:40,960
dependencies are and and

00:17:37,520 --> 00:17:44,799
try to vet them a little bit

00:17:40,960 --> 00:17:47,360
but i think um the bottom line is that

00:17:44,799 --> 00:17:49,280
there are lots of great crates out there

00:17:47,360 --> 00:17:51,760
that we can appreciate and that that

00:17:49,280 --> 00:17:55,120
actually bring in free optimizations

00:17:51,760 --> 00:17:55,120
if we're just using them

00:17:57,520 --> 00:18:04,000
now um

00:18:01,520 --> 00:18:05,360
we have kind of achieved a space where

00:18:04,000 --> 00:18:06,720
we're comfortable with the primitives

00:18:05,360 --> 00:18:09,840
that we're using

00:18:06,720 --> 00:18:14,559
and now

00:18:09,840 --> 00:18:16,720
we should figure out how to um

00:18:14,559 --> 00:18:18,480
design and implementation and the point

00:18:16,720 --> 00:18:18,960
is and one of the one of the great

00:18:18,480 --> 00:18:21,760
things

00:18:18,960 --> 00:18:22,799
about rust is that the implementation

00:18:21,760 --> 00:18:26,480
design can really

00:18:22,799 --> 00:18:29,200
follow principle engineering

00:18:26,480 --> 00:18:30,960
good programs copy fast program steal or

00:18:29,200 --> 00:18:33,280
borrow

00:18:30,960 --> 00:18:34,640
the point is we don't want to copy data

00:18:33,280 --> 00:18:37,760
a lot of times

00:18:34,640 --> 00:18:41,200
um and borrowing data actually makes

00:18:37,760 --> 00:18:42,080
accessing the same buffer very very

00:18:41,200 --> 00:18:45,039
efficient

00:18:42,080 --> 00:18:46,080
and also statically checked by the rust

00:18:45,039 --> 00:18:47,600
compiler

00:18:46,080 --> 00:18:50,240
which is often the root of error in

00:18:47,600 --> 00:18:50,240
other languages

00:18:50,960 --> 00:18:54,160
another principle that i followed is

00:18:52,720 --> 00:18:55,760
that you kind of have to trust the

00:18:54,160 --> 00:18:57,039
operating system and the compiler to

00:18:55,760 --> 00:19:00,240
know the right thing

00:18:57,039 --> 00:19:00,720
within reason they are really really

00:19:00,240 --> 00:19:03,280
smart

00:19:00,720 --> 00:19:04,960
generally speaking but they are also not

00:19:03,280 --> 00:19:07,120
always

00:19:04,960 --> 00:19:11,840
smart enough to figure out what you mean

00:19:07,120 --> 00:19:11,840
precisely as a developer

00:19:18,080 --> 00:19:21,200
there was a there was a question on

00:19:20,240 --> 00:19:24,559
twitch

00:19:21,200 --> 00:19:25,360
from frago daleta i hope i pronounced

00:19:24,559 --> 00:19:28,480
that right

00:19:25,360 --> 00:19:29,200
um which asked whether it would make

00:19:28,480 --> 00:19:32,799
sense

00:19:29,200 --> 00:19:36,240
to have the hash um

00:19:32,799 --> 00:19:38,000
be the id of the buffer i think um

00:19:36,240 --> 00:19:39,600
in terms of cryptographic construction i

00:19:38,000 --> 00:19:40,160
don't really want to go into the all

00:19:39,600 --> 00:19:44,160
sorts of

00:19:40,160 --> 00:19:46,799
all the security details that um

00:19:44,160 --> 00:19:49,919
that were chosen um i've documented

00:19:46,799 --> 00:19:53,280
these in the repository under

00:19:49,919 --> 00:19:54,799
uh on in a document um but generally

00:19:53,280 --> 00:19:59,280
there are a couple of

00:19:54,799 --> 00:19:59,280
trade-offs with the indexing mechanisms

00:19:59,760 --> 00:20:02,960
um that were that were actually like

00:20:01,600 --> 00:20:04,640
part of this design loop

00:20:02,960 --> 00:20:06,960
uh how can we how can we most

00:20:04,640 --> 00:20:08,799
efficiently index

00:20:06,960 --> 00:20:10,730
the objects themselves and then the data

00:20:08,799 --> 00:20:13,799
within the objects

00:20:10,730 --> 00:20:13,799
[Music]

00:20:13,840 --> 00:20:18,880
the bottom line is that the the way that

00:20:16,320 --> 00:20:23,280
we pack the objects themselves

00:20:18,880 --> 00:20:25,120
doesn't really lend them to hashing

00:20:23,280 --> 00:20:28,799
that easily and we get some security

00:20:25,120 --> 00:20:28,799
properties from from other places

00:20:30,640 --> 00:20:35,039
so the big picture of the program and

00:20:33,200 --> 00:20:37,440
and how we actually want to structure

00:20:35,039 --> 00:20:37,440
um

00:20:39,120 --> 00:20:44,159
compressing a bunch of files into

00:20:45,919 --> 00:20:52,799
into our objects it looks like this

00:20:49,520 --> 00:20:53,760
we open a file we unmap the file into

00:20:52,799 --> 00:20:56,559
memory

00:20:53,760 --> 00:20:58,080
which which basically creates a memory

00:20:56,559 --> 00:21:01,280
area

00:20:58,080 --> 00:21:04,559
that is equivalent in size

00:21:01,280 --> 00:21:08,240
to the file itself so we can just access

00:21:04,559 --> 00:21:08,799
that access that file as if it was a

00:21:08,240 --> 00:21:12,000
buffer

00:21:08,799 --> 00:21:15,039
in rust and then we go through this we

00:21:12,000 --> 00:21:18,640
run the duplication algorithm

00:21:15,039 --> 00:21:20,240
and then we check if we've already

00:21:18,640 --> 00:21:22,640
stored that

00:21:20,240 --> 00:21:24,880
piece of information in our index and if

00:21:22,640 --> 00:21:28,960
we haven't then store it

00:21:24,880 --> 00:21:32,559
and then just do some other bookkeeping

00:21:28,960 --> 00:21:32,559
and do this do this in a single thread

00:21:33,919 --> 00:21:38,159
now we've kind of like have a rough idea

00:21:36,640 --> 00:21:40,559
of the implementation

00:21:38,159 --> 00:21:41,919
um it's very very important to start

00:21:40,559 --> 00:21:45,200
profiling

00:21:41,919 --> 00:21:46,080
and i actually started profiling very

00:21:45,200 --> 00:21:48,159
early on

00:21:46,080 --> 00:21:50,159
in order to to figure out where the

00:21:48,159 --> 00:21:53,280
bottlenecks are

00:21:50,159 --> 00:21:57,120
perf it works greatly on linux you get

00:21:53,280 --> 00:22:00,640
really really detailed output and

00:21:57,120 --> 00:22:02,080
software like k cash grind um

00:22:00,640 --> 00:22:03,760
can actually load per files in a

00:22:02,080 --> 00:22:06,400
graphical environment but perf

00:22:03,760 --> 00:22:07,760
on the command line is also very

00:22:06,400 --> 00:22:08,960
powerful if you depend

00:22:07,760 --> 00:22:11,679
if you happen to be debugging on a

00:22:08,960 --> 00:22:12,720
server um but a lot of times i was just

00:22:11,679 --> 00:22:15,760
using

00:22:12,720 --> 00:22:17,200
os which um as you can see on the

00:22:15,760 --> 00:22:19,200
screenshot

00:22:17,200 --> 00:22:20,720
um and this is a release build that

00:22:19,200 --> 00:22:22,960
we're looking at

00:22:20,720 --> 00:22:24,240
actually resolves um all the symbols in

00:22:22,960 --> 00:22:27,440
the binaries

00:22:24,240 --> 00:22:30,480
uh and and we can start digging into

00:22:27,440 --> 00:22:31,600
uh the nitty-gritty details of of our

00:22:30,480 --> 00:22:34,559
execution

00:22:31,600 --> 00:22:35,760
and and runtime and i'll come back to

00:22:34,559 --> 00:22:38,840
the profiler

00:22:35,760 --> 00:22:41,840
um several times during during the

00:22:38,840 --> 00:22:41,840
presentation

00:22:42,880 --> 00:22:46,480
now that we have an idea about how much

00:22:45,120 --> 00:22:49,120
everything costs

00:22:46,480 --> 00:22:50,080
in real life we have an implementation

00:22:49,120 --> 00:22:53,039
we

00:22:50,080 --> 00:22:54,000
we know how to profile it we have pretty

00:22:53,039 --> 00:22:55,919
good primitives

00:22:54,000 --> 00:22:58,159
we've optimized our data structures so

00:22:55,919 --> 00:22:59,760
that that we reduce the the excess

00:22:58,159 --> 00:23:02,320
latency we can start

00:22:59,760 --> 00:23:02,880
actually tweaking things and this these

00:23:02,320 --> 00:23:04,880
things

00:23:02,880 --> 00:23:06,840
some of some of the things that i'm

00:23:04,880 --> 00:23:09,600
mentioning actually like make a lot of

00:23:06,840 --> 00:23:11,679
difference

00:23:09,600 --> 00:23:14,240
first and foremost one of the things

00:23:11,679 --> 00:23:16,080
that i

00:23:14,240 --> 00:23:18,080
i was trying to optimize for is reducing

00:23:16,080 --> 00:23:21,520
the number of copies

00:23:18,080 --> 00:23:24,480
this is this is super important

00:23:21,520 --> 00:23:26,320
four reasons i'm gonna go into later um

00:23:24,480 --> 00:23:28,640
slice access generates a boundary check

00:23:26,320 --> 00:23:30,960
these boundary checks can be very costly

00:23:28,640 --> 00:23:32,720
um link time optimization at the best

00:23:30,960 --> 00:23:36,320
case you can you can get around

00:23:32,720 --> 00:23:40,480
um 20 30 percent um

00:23:36,320 --> 00:23:42,799
worst case it probably equals out

00:23:40,480 --> 00:23:44,080
some gotcha is about inlining uh

00:23:42,799 --> 00:23:47,200
reducing size on the

00:23:44,080 --> 00:23:50,720
reducing code size in a hot pass

00:23:47,200 --> 00:23:52,720
pipelining and uh crypto hash libraries

00:23:50,720 --> 00:23:54,799
using cmd that i mentioned this is

00:23:52,720 --> 00:23:58,480
actually incredibly important because

00:23:54,799 --> 00:24:02,000
the cmd speed ups are significant

00:23:58,480 --> 00:24:04,720
i don't consider myself smart enough to

00:24:02,000 --> 00:24:06,960
write sim decode myself so i was mostly

00:24:04,720 --> 00:24:10,240
leveraging other people

00:24:06,960 --> 00:24:10,240
who have put in the great work

00:24:11,600 --> 00:24:15,039
now let's just go back to mf for a

00:24:12,960 --> 00:24:15,760
second because i think this is very

00:24:15,039 --> 00:24:17,760
important

00:24:15,760 --> 00:24:20,880
if we want to if we want to achieve high

00:24:17,760 --> 00:24:20,880
performance on

00:24:22,720 --> 00:24:25,760
basically any any sort of database like

00:24:25,200 --> 00:24:28,320
um

00:24:25,760 --> 00:24:28,320
application

00:24:28,960 --> 00:24:32,960
there's a new kid on the block called i

00:24:30,640 --> 00:24:35,600
o u ring

00:24:32,960 --> 00:24:36,880
which is which offers really exciting uh

00:24:35,600 --> 00:24:40,240
and interesting modes of

00:24:36,880 --> 00:24:42,480
async access um that

00:24:40,240 --> 00:24:43,919
that actually get really really good

00:24:42,480 --> 00:24:46,400
real life speed ups

00:24:43,919 --> 00:24:48,080
however at the moment is linux only so

00:24:46,400 --> 00:24:49,279
um

00:24:48,080 --> 00:24:51,039
and i kind of wanted this to be a

00:24:49,279 --> 00:24:53,120
multi-platform thing and developing on

00:24:51,039 --> 00:24:54,720
mac os i can't really rely on platform

00:24:53,120 --> 00:24:58,159
dependent stuff

00:24:54,720 --> 00:24:58,159
i think one of the great things about

00:24:59,600 --> 00:25:03,279
about rust is that a lot of uh the

00:25:02,240 --> 00:25:06,720
libraries

00:25:03,279 --> 00:25:06,720
that i'm using like my map

00:25:07,440 --> 00:25:11,919
they can do stuff that's similar

00:25:12,559 --> 00:25:18,480
uh to other operating systems native

00:25:15,840 --> 00:25:19,760
system calls so membab does some magic

00:25:18,480 --> 00:25:21,520
on windows

00:25:19,760 --> 00:25:23,039
that basically gives me the same

00:25:21,520 --> 00:25:25,279
properties as if it was

00:25:23,039 --> 00:25:27,120
a mapping natively in a posix unix

00:25:25,279 --> 00:25:30,159
system

00:25:27,120 --> 00:25:32,559
um it works everywhere um

00:25:30,159 --> 00:25:34,320
the the the fact that we're using a map

00:25:32,559 --> 00:25:37,360
reduces

00:25:34,320 --> 00:25:38,960
the memory this is called pressure quite

00:25:37,360 --> 00:25:41,360
significantly

00:25:38,960 --> 00:25:43,279
and um the way that this works is you

00:25:41,360 --> 00:25:44,159
start accessing data and if the data is

00:25:43,279 --> 00:25:46,799
not in memory

00:25:44,159 --> 00:25:48,000
the that that access will generate the

00:25:46,799 --> 00:25:50,159
page fault

00:25:48,000 --> 00:25:52,000
um and the operating system will go back

00:25:50,159 --> 00:25:54,799
to the disk ask the disk to get him the

00:25:52,000 --> 00:25:54,799
data and then

00:25:54,880 --> 00:25:58,000
the operating system will put that data

00:25:56,480 --> 00:25:59,200
into the memory for you completely

00:25:58,000 --> 00:26:01,919
transparently

00:25:59,200 --> 00:26:03,600
it's also it's in mechanism very similar

00:26:01,919 --> 00:26:07,360
to reading through a file

00:26:03,600 --> 00:26:11,360
but it's automatic and less predictable

00:26:07,360 --> 00:26:13,039
which is sort of a downside

00:26:11,360 --> 00:26:14,880
but the really powerful part of it is

00:26:13,039 --> 00:26:17,279
that you get a slice that you can pass

00:26:14,880 --> 00:26:17,279
around

00:26:18,000 --> 00:26:21,600
and you can design your entire data flow

00:26:20,000 --> 00:26:23,360
around this

00:26:21,600 --> 00:26:25,120
when you have a file you end up that

00:26:23,360 --> 00:26:27,520
file and then

00:26:25,120 --> 00:26:28,960
you just start working on slices and

00:26:27,520 --> 00:26:30,880
feed those slices into the crypto

00:26:28,960 --> 00:26:33,440
algorithm and you don't

00:26:30,880 --> 00:26:33,919
and compression and whatever whatnot and

00:26:33,440 --> 00:26:36,640
you don't

00:26:33,919 --> 00:26:38,320
really need to think about copying

00:26:36,640 --> 00:26:39,919
you're just borrowing that's from from

00:26:38,320 --> 00:26:40,640
that same memory structure that you're

00:26:39,919 --> 00:26:43,039
building

00:26:40,640 --> 00:26:45,200
uh that that you're um going to go

00:26:43,039 --> 00:26:48,960
through anyway

00:26:45,200 --> 00:26:52,480
um i've done some tests

00:26:48,960 --> 00:26:53,279
and and the the performance differences

00:26:52,480 --> 00:26:56,640
to

00:26:53,279 --> 00:26:59,679
uh reading a file

00:26:56,640 --> 00:27:00,960
um chunk by chunk is actually quite

00:26:59,679 --> 00:27:04,080
significant compared to

00:27:00,960 --> 00:27:04,080
to whatever map does

00:27:04,720 --> 00:27:08,559
and the power of rust comes in because

00:27:06,880 --> 00:27:11,039
because we can pass these burrows around

00:27:08,559 --> 00:27:11,039
safely

00:27:11,679 --> 00:27:16,880
um this is sort of a small picture but

00:27:14,720 --> 00:27:18,399
this is called pressure is quite an

00:27:16,880 --> 00:27:21,840
interesting one

00:27:18,399 --> 00:27:21,840
what you can see here is

00:27:22,080 --> 00:27:29,200
opening a file closing a file

00:27:26,080 --> 00:27:29,679
uh and mapping and monomapping the file

00:27:29,200 --> 00:27:32,720
as

00:27:29,679 --> 00:27:34,559
in undoing the map um

00:27:32,720 --> 00:27:37,360
is around 20 to 30 percent of the

00:27:34,559 --> 00:27:37,360
complete run time

00:27:39,039 --> 00:27:42,960
which is which is quite significant uh

00:27:41,440 --> 00:27:43,520
we're opening files for reading and

00:27:42,960 --> 00:27:46,720
writing

00:27:43,520 --> 00:27:50,159
when we're decompressing um

00:27:46,720 --> 00:27:54,799
we're mapping these files um and

00:27:50,159 --> 00:27:57,039
um there's there's also some um

00:27:54,799 --> 00:27:58,320
cisco's involved well native library

00:27:57,039 --> 00:28:00,640
calls involved

00:27:58,320 --> 00:28:04,240
um for for actually copying the data out

00:28:00,640 --> 00:28:04,240
and into into our memory space

00:28:04,559 --> 00:28:07,760
so minimizing this these open operations

00:28:07,039 --> 00:28:10,640
can can

00:28:07,760 --> 00:28:12,159
can be a huge win i remember testing at

00:28:10,640 --> 00:28:15,440
some point

00:28:12,159 --> 00:28:18,799
with a kernel module

00:28:15,440 --> 00:28:20,240
that uh increased the time to open the

00:28:18,799 --> 00:28:23,760
file

00:28:20,240 --> 00:28:24,240
uh to around 700 millisecond and at that

00:28:23,760 --> 00:28:27,120
point

00:28:24,240 --> 00:28:29,360
that is just ridiculously slow uh

00:28:27,120 --> 00:28:33,200
obviously here it's it's much better

00:28:29,360 --> 00:28:33,200
without without kernel modules but

00:28:34,320 --> 00:28:38,799
but this is where the profiler can tell

00:28:36,640 --> 00:28:45,200
us where exactly our program is

00:28:38,799 --> 00:28:48,399
is experiencing slowdowns

00:28:45,200 --> 00:28:51,679
how are you always gonna need to copy

00:28:48,399 --> 00:28:53,200
at some point i think the the really

00:28:51,679 --> 00:28:56,240
really

00:28:53,200 --> 00:28:59,120
um important part

00:28:56,240 --> 00:29:01,520
is to be able to tell when that copy

00:28:59,120 --> 00:29:01,520
happens

00:29:02,399 --> 00:29:06,880
and if you just pass around slices and

00:29:05,279 --> 00:29:10,240
are quite pragmatic and

00:29:06,880 --> 00:29:12,320
and principled

00:29:10,240 --> 00:29:14,000
around around how you manage this kind

00:29:12,320 --> 00:29:16,480
of data then

00:29:14,000 --> 00:29:17,840
rusts one of rust's greatest power is

00:29:16,480 --> 00:29:18,399
that you can actually reason about what

00:29:17,840 --> 00:29:20,799
happens

00:29:18,399 --> 00:29:22,720
at a low level in the memory uh so you

00:29:20,799 --> 00:29:25,200
can you get this very very fine grain

00:29:22,720 --> 00:29:25,200
control

00:29:25,440 --> 00:29:30,799
and you can precisely pinpoint when that

00:29:27,840 --> 00:29:30,799
copay is going to happen

00:29:31,360 --> 00:29:35,679
related to this is slicing a slice uh

00:29:34,159 --> 00:29:37,200
this is something that i ran into and i

00:29:35,679 --> 00:29:37,919
didn't really understand why things are

00:29:37,200 --> 00:29:41,279
slow

00:29:37,919 --> 00:29:42,559
um the point is i i saw that

00:29:41,279 --> 00:29:44,799
there was a function call and the

00:29:42,559 --> 00:29:47,440
function call goes into another one

00:29:44,799 --> 00:29:47,919
and and there was some some inexplicable

00:29:47,440 --> 00:29:51,200
uh

00:29:47,919 --> 00:29:53,600
slowdown there and what i discovered

00:29:51,200 --> 00:29:55,200
is that if you start slicing on a hot

00:29:53,600 --> 00:29:58,480
loop

00:29:55,200 --> 00:30:00,559
on the hot path then

00:29:58,480 --> 00:30:01,919
all the code that is generated by the

00:30:00,559 --> 00:30:05,200
slice access

00:30:01,919 --> 00:30:06,960
is going to be big enough to actually

00:30:05,200 --> 00:30:09,760
ruin the cache lines

00:30:06,960 --> 00:30:12,000
and expensive enough to ruin your

00:30:09,760 --> 00:30:16,960
performance

00:30:12,000 --> 00:30:16,960
so you want to avoid situations where

00:30:17,039 --> 00:30:21,520
you just keep looping around and and

00:30:19,679 --> 00:30:23,600
slicing into the same piece of data over

00:30:21,520 --> 00:30:26,000
and over again

00:30:23,600 --> 00:30:27,679
um especially if you're like reducing

00:30:26,000 --> 00:30:29,360
the the slice because then

00:30:27,679 --> 00:30:31,840
every single time you generate that

00:30:29,360 --> 00:30:34,840
boundary check with the panic code

00:30:31,840 --> 00:30:36,320
um which could be unwind or could be a

00:30:34,840 --> 00:30:39,840
board

00:30:36,320 --> 00:30:39,840
and that can get very expensive

00:30:40,320 --> 00:30:47,760
i mentioned cache lines so one of the

00:30:43,919 --> 00:30:50,159
tricks that is relatively difficult to

00:30:47,760 --> 00:30:53,520
reason about in rust

00:30:50,159 --> 00:30:57,120
is reducing the

00:30:53,520 --> 00:30:57,120
code size on the hot path

00:30:58,159 --> 00:31:01,840
inlining code will avoid function cause

00:31:00,159 --> 00:31:04,320
which is different type of cost

00:31:01,840 --> 00:31:06,000
but there's a trade-off that we need to

00:31:04,320 --> 00:31:09,360
really think about

00:31:06,000 --> 00:31:12,159
because inlining too much will

00:31:09,360 --> 00:31:15,120
be equally bad for performance than

00:31:12,159 --> 00:31:16,640
in-lining too little

00:31:15,120 --> 00:31:18,880
i think it really is a lot of

00:31:16,640 --> 00:31:20,080
experimentation to figure out what it is

00:31:18,880 --> 00:31:23,360
what is the sort of

00:31:20,080 --> 00:31:25,039
code that is worth in lining and the

00:31:23,360 --> 00:31:28,720
good thing about the inline macro

00:31:25,039 --> 00:31:34,720
is that it still allows the

00:31:28,720 --> 00:31:34,720
um the compiler to not do that for you

00:31:34,960 --> 00:31:38,000
there's an inline always macro which is

00:31:36,799 --> 00:31:39,519
a lot more dangerous

00:31:38,000 --> 00:31:47,200
because that will always in line that

00:31:39,519 --> 00:31:50,559
piece of code

00:31:47,200 --> 00:31:54,000
so the boundary check and the panic code

00:31:50,559 --> 00:31:54,000
are are big um

00:31:54,720 --> 00:32:01,840
there's a trick where you can reduce

00:31:57,039 --> 00:32:01,840
this by using an assert macro

00:32:02,159 --> 00:32:06,559
in which case you definitely want to

00:32:06,880 --> 00:32:10,320
because because the way the asset macro

00:32:08,720 --> 00:32:12,480
optimization works you definitely want

00:32:10,320 --> 00:32:13,120
to do all the dirty work in one lexical

00:32:12,480 --> 00:32:16,000
block

00:32:13,120 --> 00:32:18,799
or sort of one function and i think

00:32:16,000 --> 00:32:21,760
inlining doesn't work that well

00:32:18,799 --> 00:32:24,399
because my experience was that the

00:32:21,760 --> 00:32:27,519
boundary checks get

00:32:24,399 --> 00:32:30,640
generated into every single function

00:32:27,519 --> 00:32:30,640
even though they are in line

00:32:33,120 --> 00:32:37,360
so keeping keeping the data on the same

00:32:36,880 --> 00:32:40,720
thread

00:32:37,360 --> 00:32:40,720
avoids as a context switch

00:32:41,039 --> 00:32:45,600
which is which is kind of convenient in

00:32:43,519 --> 00:32:49,200
terms of pipelining our data

00:32:45,600 --> 00:32:52,880
and our instructions um in an optimal

00:32:49,200 --> 00:32:52,880
way for the cpu to execute

00:32:54,080 --> 00:32:57,519
on the picture you can see two different

00:32:56,399 --> 00:32:59,200
threads

00:32:57,519 --> 00:33:01,440
one of them is an encryption and the

00:32:59,200 --> 00:33:04,240
other one is a decryption

00:33:01,440 --> 00:33:08,080
thread the the top one you can see that

00:33:04,240 --> 00:33:11,200
cpi utilization just climbs up

00:33:08,080 --> 00:33:12,480
and this is because of all the page

00:33:11,200 --> 00:33:15,279
faults

00:33:12,480 --> 00:33:16,159
um and this is what the your i o latency

00:33:15,279 --> 00:33:19,519
looks like

00:33:16,159 --> 00:33:20,960
if you're if you're looking at it um

00:33:19,519 --> 00:33:24,720
the way the benchmark program is

00:33:20,960 --> 00:33:27,360
structured is that

00:33:24,720 --> 00:33:28,559
i read up a bunch of files um and

00:33:27,360 --> 00:33:30,559
generate the objects and then

00:33:28,559 --> 00:33:34,480
immediately afterwards

00:33:30,559 --> 00:33:35,919
i decrypt those objects and it shows

00:33:34,480 --> 00:33:39,519
very very nicely on the

00:33:35,919 --> 00:33:41,120
on the second thread that since all the

00:33:39,519 --> 00:33:43,919
data was already in the

00:33:41,120 --> 00:33:46,640
um the file system cache of the host

00:33:43,919 --> 00:33:49,679
operating system

00:33:46,640 --> 00:33:52,480
i could just go through them and and

00:33:49,679 --> 00:33:53,760
basically throughout all in this entire

00:33:52,480 --> 00:33:57,120
process there was

00:33:53,760 --> 00:33:59,519
about 100 you know like 80 90

00:33:57,120 --> 00:34:01,360
um cpu utilization which is completely

00:33:59,519 --> 00:34:02,799
reasonable

00:34:01,360 --> 00:34:05,039
uh there you didn't need any sort of

00:34:02,799 --> 00:34:07,200
ramp up time so it's really

00:34:05,039 --> 00:34:09,200
really interesting um how you cannot

00:34:07,200 --> 00:34:12,560
really predict page faults

00:34:09,200 --> 00:34:14,480
but then when your

00:34:12,560 --> 00:34:20,000
files are in the file system cache it

00:34:14,480 --> 00:34:23,679
just becomes ridiculously fast

00:34:20,000 --> 00:34:26,159
another thing that i used quite a lot in

00:34:23,679 --> 00:34:29,040
in the implementation of zero stash was

00:34:26,159 --> 00:34:33,280
arcing all the things

00:34:29,040 --> 00:34:35,679
um for those who are not familiar

00:34:33,280 --> 00:34:38,879
the ark is a is a reference counter that

00:34:35,679 --> 00:34:38,879
works in an atomic way

00:34:40,079 --> 00:34:46,839
it is super useful for keeping track of

00:34:43,679 --> 00:34:50,399
objects across threads

00:34:46,839 --> 00:34:53,280
and it can also result in pretty ugly

00:34:50,399 --> 00:34:53,280
type definitions

00:34:53,919 --> 00:34:58,320
what you can see here is the least

00:34:56,480 --> 00:35:02,240
recently used cache

00:34:58,320 --> 00:35:05,839
that i use on uh

00:35:02,240 --> 00:35:09,280
when when reading from uh a directory

00:35:05,839 --> 00:35:10,880
um and

00:35:09,280 --> 00:35:13,680
i think we we have to agree that this is

00:35:10,880 --> 00:35:17,599
pretty ugly uh but it also

00:35:13,680 --> 00:35:19,280
it also allows us to to control

00:35:17,599 --> 00:35:20,800
and sort of automatically garbage

00:35:19,280 --> 00:35:23,119
collect all the stuff

00:35:20,800 --> 00:35:26,560
that we don't need anymore at the time

00:35:23,119 --> 00:35:27,760
of not needing it anymore

00:35:26,560 --> 00:35:31,119
so there's a lot of convenience that

00:35:27,760 --> 00:35:32,240
comes with it um on the decryption side

00:35:31,119 --> 00:35:35,680
the the

00:35:32,240 --> 00:35:37,040
least recently used cash actually gave

00:35:35,680 --> 00:35:40,000
me a performance

00:35:37,040 --> 00:35:41,119
hit around a performance gain of around

00:35:40,000 --> 00:35:43,599
20 percent

00:35:41,119 --> 00:35:45,200
when i calibrated it correctly and it

00:35:43,599 --> 00:35:46,079
flat out crashed the program when i

00:35:45,200 --> 00:35:51,680
didn't

00:35:46,079 --> 00:35:51,680
um so there's there's that as well

00:35:52,000 --> 00:35:55,280
there are some other free optimizations

00:35:54,240 --> 00:35:59,839
i mentioned

00:35:55,280 --> 00:36:03,359
lto which is linkedin optimization

00:35:59,839 --> 00:36:05,680
the panic code abort

00:36:03,359 --> 00:36:07,440
is generally smaller than unwinding

00:36:05,680 --> 00:36:09,040
panics

00:36:07,440 --> 00:36:10,800
in a multi-threaded environment i

00:36:09,040 --> 00:36:11,440
actually prefer aborting because it

00:36:10,800 --> 00:36:13,040
means the

00:36:11,440 --> 00:36:15,040
entire program is going to be brought

00:36:13,040 --> 00:36:16,400
down instead of just killing that one

00:36:15,040 --> 00:36:19,359
thread

00:36:16,400 --> 00:36:19,359
which is quite useful

00:36:20,000 --> 00:36:23,520
the link time optimization and the and

00:36:22,240 --> 00:36:27,200
the optimization level

00:36:23,520 --> 00:36:31,119
three settings best case around 30

00:36:27,200 --> 00:36:34,560
performance gain um

00:36:31,119 --> 00:36:36,560
on on top of everything else

00:36:34,560 --> 00:36:37,599
which is which is definitely significant

00:36:36,560 --> 00:36:41,760
it reduces it

00:36:37,599 --> 00:36:44,800
reduces compile time

00:36:41,760 --> 00:36:46,400
quite significantly um

00:36:44,800 --> 00:36:48,560
but if you're only doing it in release

00:36:46,400 --> 00:36:49,200
mode then that that sort of compilation

00:36:48,560 --> 00:36:52,160
penalty is

00:36:49,200 --> 00:36:52,160
is definitely worth it

00:36:52,960 --> 00:36:58,079
um so one thing that i have not talked

00:36:54,880 --> 00:37:00,000
about today was async

00:36:58,079 --> 00:37:03,280
the reason is because i've never

00:37:00,000 --> 00:37:05,200
actually used async on this project

00:37:03,280 --> 00:37:06,960
um i kept thinking about how to

00:37:05,200 --> 00:37:10,800
incorporate async into

00:37:06,960 --> 00:37:12,400
this pipeline but i'm already getting

00:37:10,800 --> 00:37:15,520
almost a gigabyte of second

00:37:12,400 --> 00:37:15,520
on small files

00:37:15,599 --> 00:37:22,560
so do i really need it

00:37:18,640 --> 00:37:26,320
and the answer is kind of because

00:37:22,560 --> 00:37:29,440
this this mechanism works

00:37:26,320 --> 00:37:29,760
really really well on small files but it

00:37:29,440 --> 00:37:33,359
does

00:37:29,760 --> 00:37:36,720
lock large files onto a single thread

00:37:33,359 --> 00:37:38,480
which means if you're dealing with

00:37:36,720 --> 00:37:39,839
a couple of large files and a lot of

00:37:38,480 --> 00:37:41,119
lots of small ones

00:37:39,839 --> 00:37:42,720
and you're just going to block one

00:37:41,119 --> 00:37:44,480
thread and the other ones are just going

00:37:42,720 --> 00:37:47,119
to starve

00:37:44,480 --> 00:37:48,640
um so async would definitely be useful

00:37:47,119 --> 00:37:50,640
for

00:37:48,640 --> 00:37:52,720
breaking up the the workload and the

00:37:50,640 --> 00:37:57,200
pipeline so that we can schedule them

00:37:52,720 --> 00:38:00,000
across a number of threads dynamically

00:37:57,200 --> 00:38:01,280
and my expectation is that the the

00:38:00,000 --> 00:38:04,640
profiler

00:38:01,280 --> 00:38:08,160
um picture that i showed above

00:38:04,640 --> 00:38:10,320
about the ramp up of the the cpu use

00:38:08,160 --> 00:38:12,160
that would kind of flatten out because

00:38:10,320 --> 00:38:15,119
of of using async

00:38:12,160 --> 00:38:17,520
um i have yet to test this if if anybody

00:38:15,119 --> 00:38:20,240
is keen to play around with it then

00:38:17,520 --> 00:38:22,720
the con i would really really welcome

00:38:20,240 --> 00:38:26,640
the contributions

00:38:22,720 --> 00:38:30,720
um and

00:38:26,640 --> 00:38:33,839
um in general i think the async topic is

00:38:30,720 --> 00:38:33,839
super interesting

00:38:34,000 --> 00:38:38,160
the primitives are there the multiple

00:38:35,920 --> 00:38:41,760
the multi-threaded

00:38:38,160 --> 00:38:45,040
kind of architecture is there and

00:38:41,760 --> 00:38:46,240
i think right now the async ecosystem in

00:38:45,040 --> 00:38:48,560
rust is in a place

00:38:46,240 --> 00:38:49,760
where i would be very very happy and

00:38:48,560 --> 00:38:52,480
comfortable to

00:38:49,760 --> 00:38:53,520
to build on it it wasn't necessarily the

00:38:52,480 --> 00:38:55,599
case about

00:38:53,520 --> 00:38:58,640
a year and a half ago when i originally

00:38:55,599 --> 00:38:58,640
started the development

00:38:59,280 --> 00:39:03,920
apart from that i have absolutely like

00:39:01,839 --> 00:39:06,400
100 positive experience with the

00:39:03,920 --> 00:39:09,359
with the asic as an async user not an

00:39:06,400 --> 00:39:09,359
author of the libraries

00:39:10,320 --> 00:39:13,599
um this is everything that i brought for

00:39:11,839 --> 00:39:18,000
today and i will

00:39:13,599 --> 00:39:20,880
welcome any questions that

00:39:18,000 --> 00:39:21,520
that you might have and thank you for

00:39:20,880 --> 00:39:23,680
listening

00:39:21,520 --> 00:39:29,839
and i hope you enjoy you are enjoying

00:39:23,680 --> 00:39:29,839
rusty days and the hackathon as well

00:39:42,079 --> 00:39:47,280
i'm being told there's a tiny bit of a

00:39:54,839 --> 00:39:57,839
lag

00:40:15,280 --> 00:40:20,240
yeah so we are just going to wait a

00:40:16,560 --> 00:40:25,839
couple of minutes um if anybody has

00:40:20,240 --> 00:40:25,839
any sort of questions then please shoot

00:41:14,720 --> 00:41:18,400
so there's a there's a question about

00:41:16,400 --> 00:41:20,640
how we compare read and

00:41:18,400 --> 00:41:20,640
map

00:41:21,760 --> 00:41:27,839
well my my read implementation

00:41:25,839 --> 00:41:28,880
that i did literally just walked through

00:41:27,839 --> 00:41:31,599
the file

00:41:28,880 --> 00:41:33,040
uh bit by bit and then whatever came in

00:41:31,599 --> 00:41:35,839
it just fed it

00:41:33,040 --> 00:41:35,839
to

00:41:37,680 --> 00:41:40,960
and just fed it into

00:41:44,319 --> 00:41:50,640
the c hash hasher um

00:41:48,319 --> 00:41:50,640
which

00:41:51,760 --> 00:41:56,400
was so in terms of implementation it was

00:41:54,960 --> 00:42:00,000
sort of tedious

00:41:56,400 --> 00:42:02,560
because uh every single read can fail

00:42:00,000 --> 00:42:04,319
and every single read i would need to

00:42:02,560 --> 00:42:07,359
handle the error cases

00:42:04,319 --> 00:42:10,160
um and on top of that

00:42:07,359 --> 00:42:12,880
uh it just generated lots of lots of

00:42:10,160 --> 00:42:15,359
system calls

00:42:12,880 --> 00:42:16,240
one of the tricks that i probably did

00:42:15,359 --> 00:42:19,599
not

00:42:16,240 --> 00:42:19,599
mention is that

00:42:22,079 --> 00:42:26,880
there are not many allocations uh during

00:42:24,400 --> 00:42:28,560
the during the run time of the program

00:42:26,880 --> 00:42:31,119
there's not there's not a lot of cost to

00:42:28,560 --> 00:42:32,560
moloch for instance

00:42:31,119 --> 00:42:34,640
it is there but it is relatively

00:42:32,560 --> 00:42:36,319
insignificant a big win

00:42:34,640 --> 00:42:37,839
is reusing the same buffers that you

00:42:36,319 --> 00:42:40,240
would be using anyway and just dumping

00:42:37,839 --> 00:42:43,920
them to files

00:42:40,240 --> 00:42:45,359
resetting the resetting the the cursors

00:42:43,920 --> 00:42:47,280
and whatnot and then just dumping the

00:42:45,359 --> 00:42:49,440
entire thing into a file

00:42:47,280 --> 00:42:49,440
so

00:42:54,400 --> 00:42:57,760
yeah i'm really really there to win is

00:42:56,800 --> 00:43:00,240
that

00:42:57,760 --> 00:43:02,240
you're massively reducing the um the

00:43:00,240 --> 00:43:07,760
system called overhead

00:43:02,240 --> 00:43:10,880
between between molochs and

00:43:07,760 --> 00:43:10,880
maps and reads

00:43:11,119 --> 00:43:14,720
another question is uh object storage

00:43:13,119 --> 00:43:18,480
sounds like sounds like git

00:43:14,720 --> 00:43:20,000
and arc um they are the inspiration i

00:43:18,480 --> 00:43:21,520
wanted to do something that's open

00:43:20,000 --> 00:43:23,680
source and encrypted

00:43:21,520 --> 00:43:25,200
um a lot of the solutions out there and

00:43:23,680 --> 00:43:26,640
they kind of work similarly but you

00:43:25,200 --> 00:43:30,480
don't really know how

00:43:26,640 --> 00:43:33,920
um and the documentation on

00:43:30,480 --> 00:43:36,640
on the exact uh uh

00:43:33,920 --> 00:43:37,920
crypto that the user is very sparse um

00:43:36,640 --> 00:43:41,920
another problem that i had

00:43:37,920 --> 00:43:44,480
is that they were really really slow um

00:43:41,920 --> 00:43:46,240
and so if you use a look at something

00:43:44,480 --> 00:43:49,920
like boop

00:43:46,240 --> 00:43:51,920
which builds on git

00:43:49,920 --> 00:43:53,520
it generates a lot of small files is

00:43:51,920 --> 00:43:56,079
generally very very

00:43:53,520 --> 00:43:57,119
slow to sync i had the same issues with

00:43:56,079 --> 00:43:59,920
tahoe loves and

00:43:57,119 --> 00:43:59,920
and tar snap

00:44:00,160 --> 00:44:04,079
where they provide reasonable

00:44:02,480 --> 00:44:06,800
performance for putting stuff

00:44:04,079 --> 00:44:09,200
in but there are so many files that

00:44:06,800 --> 00:44:13,520
actually retrieving them

00:44:09,200 --> 00:44:13,520
is is taking an unreasonable amount of

00:44:20,839 --> 00:44:24,880
time

00:44:23,119 --> 00:44:27,280
um if you're unfamiliar with

00:44:24,880 --> 00:44:29,760
cryptography uh one of the books

00:44:27,280 --> 00:44:32,720
that i i went through and that i used uh

00:44:29,760 --> 00:44:36,640
quite a lot was jp amazon's

00:44:32,720 --> 00:44:38,000
um cryptography book published by no

00:44:36,640 --> 00:44:42,560
starch

00:44:38,000 --> 00:44:47,119
um the exact title kind of slips my mind

00:44:42,560 --> 00:44:50,000
um but it's a it's a really good

00:44:47,119 --> 00:44:50,560
it's a really good introduction i think

00:44:50,000 --> 00:44:51,920
and

00:44:50,560 --> 00:44:54,000
and that is definitely where i would

00:44:51,920 --> 00:44:56,720
start these days it goes through

00:44:54,000 --> 00:44:58,160
the historic things it goes through a

00:44:56,720 --> 00:45:00,720
lot of

00:44:58,160 --> 00:45:02,240
um algorithms that are not very favored

00:45:00,720 --> 00:45:03,200
today in like this

00:45:02,240 --> 00:45:05,839
and it just gives you a very good

00:45:03,200 --> 00:45:05,839
perspective

00:45:12,560 --> 00:45:17,359
uh yeah um there's a question about how

00:45:15,599 --> 00:45:21,440
big the performance

00:45:17,359 --> 00:45:21,440
improvement was by using inline

00:45:21,680 --> 00:45:27,119
the thing is i don't really know um

00:45:24,800 --> 00:45:29,280
i went through i went through a phase of

00:45:27,119 --> 00:45:31,599
starting to inline stuff

00:45:29,280 --> 00:45:34,079
and and then i started removing in lines

00:45:31,599 --> 00:45:36,480
and i didn't really

00:45:34,079 --> 00:45:38,240
didn't really see any huge difference

00:45:36,480 --> 00:45:39,200
and i think that was because the code

00:45:38,240 --> 00:45:42,720
was generally very

00:45:39,200 --> 00:45:46,160
optimizable for the compiler

00:45:42,720 --> 00:45:49,760
um some

00:45:46,160 --> 00:45:52,319
some things uh actually had

00:45:49,760 --> 00:45:54,640
like um a couple of percent impact when

00:45:52,319 --> 00:45:57,359
i was in lining on the hot path

00:45:54,640 --> 00:45:59,280
um very very simple stuff like sraf and

00:45:57,359 --> 00:46:02,480
um

00:45:59,280 --> 00:46:03,440
and uh other simple trade

00:46:02,480 --> 00:46:05,280
implementations

00:46:03,440 --> 00:46:08,000
i think the bottom line here is that you

00:46:05,280 --> 00:46:10,400
kind of have to play around and see

00:46:08,000 --> 00:46:15,839
um if it works or if the compiler does

00:46:10,400 --> 00:46:15,839
the right thing anyway

00:46:18,240 --> 00:46:21,760
there's a question about how do you

00:46:19,520 --> 00:46:23,680
protect encryption keys and

00:46:21,760 --> 00:46:26,319
manage them from being swapped or read

00:46:23,680 --> 00:46:28,480
straight from the memory so

00:46:26,319 --> 00:46:29,440
there is a is an amazing crate called

00:46:28,480 --> 00:46:31,680
secrecy

00:46:29,440 --> 00:46:33,119
which wipes the encryption keys from

00:46:31,680 --> 00:46:36,720
memory after being used

00:46:33,119 --> 00:46:37,119
and um i just had a discussion about

00:46:36,720 --> 00:46:41,119
this

00:46:37,119 --> 00:46:43,040
uh recently with someone in irc um

00:46:41,119 --> 00:46:44,480
a great thing about rust is that as a

00:46:43,040 --> 00:46:48,240
library author

00:46:44,480 --> 00:46:50,960
i can enforce that all the key material

00:46:48,240 --> 00:46:51,920
that i generate or derive or or

00:46:50,960 --> 00:46:57,599
otherwise

00:46:51,920 --> 00:47:00,240
return to the users of my library

00:46:57,599 --> 00:47:00,800
those keys will always be wiped from

00:47:00,240 --> 00:47:04,240
memory

00:47:00,800 --> 00:47:04,240
by the guarantees of of

00:47:04,400 --> 00:47:11,520
of what i can provide and

00:47:07,599 --> 00:47:14,640
and this is this is really really great

00:47:11,520 --> 00:47:18,000
another way that you can you can protect

00:47:14,640 --> 00:47:20,880
a key material is obviously memblocking

00:47:18,000 --> 00:47:22,079
a process into

00:47:20,880 --> 00:47:23,280
[Music]

00:47:22,079 --> 00:47:25,200
into the memory which means it never

00:47:23,280 --> 00:47:27,920
hits the swap space

00:47:25,200 --> 00:47:29,440
um i think this is very often used um

00:47:27,920 --> 00:47:31,119
other than that i think operating

00:47:29,440 --> 00:47:34,880
systems started to introduce

00:47:31,119 --> 00:47:37,440
memory encryption um schemes

00:47:34,880 --> 00:47:38,720
i don't specifically know the details of

00:47:37,440 --> 00:47:41,760
that

00:47:38,720 --> 00:47:46,160
um and how they work because uh

00:47:41,760 --> 00:47:46,160
they tend to be transparent um

00:47:46,800 --> 00:47:50,800
but there are no other special

00:47:48,480 --> 00:47:53,280
protections apart from

00:47:50,800 --> 00:48:07,839
um for the key material it's basically

00:47:53,280 --> 00:48:07,839
the role of the user to protect the keys

00:48:17,359 --> 00:48:20,319
there's a there's a comment about

00:48:18,559 --> 00:48:20,800
compression and encryption can leak some

00:48:20,319 --> 00:48:23,200
info

00:48:20,800 --> 00:48:24,800
on the compression ratio i think that

00:48:23,200 --> 00:48:29,119
threat vector is mitigated

00:48:24,800 --> 00:48:32,880
by the the simple fact that um

00:48:29,119 --> 00:48:35,690
the attacker cannot know the precise

00:48:32,880 --> 00:48:36,880
size of the data

00:48:35,690 --> 00:48:40,160
[Music]

00:48:36,880 --> 00:48:42,240
so it wouldn't be very applicable the

00:48:40,160 --> 00:48:44,319
the attackers can only observe four

00:48:42,240 --> 00:48:46,079
megabyte blobs of data

00:48:44,319 --> 00:48:47,760
that are completely opaque to them and

00:48:46,079 --> 00:48:48,800
they don't don't really contain any

00:48:47,760 --> 00:48:52,240
individually

00:48:48,800 --> 00:48:55,280
identifiable information um all of the

00:48:52,240 --> 00:48:59,280
the root the root of trust um

00:48:55,280 --> 00:49:01,280
in in this is uh entirely derived from

00:48:59,280 --> 00:49:02,960
the passphrase and the username

00:49:01,280 --> 00:49:17,839
that are that are fed into the

00:49:02,960 --> 00:49:17,839
encryption algorithm

00:49:21,599 --> 00:49:24,720
there's a question about what approach

00:49:23,119 --> 00:49:27,119
and library do i prefer for error

00:49:24,720 --> 00:49:27,119
handling

00:49:27,839 --> 00:49:33,200
i started off with failure and and that

00:49:31,119 --> 00:49:37,200
that was uh that was a failure

00:49:33,200 --> 00:49:37,760
um right now i'm using this error and

00:49:37,200 --> 00:49:40,079
anyhow

00:49:37,760 --> 00:49:41,680
consistently everywhere and i can highly

00:49:40,079 --> 00:49:43,359
recommend these

00:49:41,680 --> 00:49:45,440
um they're great they they're super

00:49:43,359 --> 00:49:46,960
convenient super clean

00:49:45,440 --> 00:49:48,720
uh don't come with any of the baggage

00:49:46,960 --> 00:49:52,240
that failer does

00:49:48,720 --> 00:49:55,359
and um and they are generally just very

00:49:52,240 --> 00:49:55,359
easy to use and understand

00:49:57,280 --> 00:50:01,280
um there are a couple of more crypto

00:49:58,800 --> 00:50:01,280
questions

00:50:01,520 --> 00:50:03,839
um

00:50:06,000 --> 00:50:10,800
how do you do regular backup

00:50:07,520 --> 00:50:10,800
verification um

00:50:10,839 --> 00:50:15,839
well one of the key key points of zero

00:50:14,079 --> 00:50:17,440
stash is that it separates the metadata

00:50:15,839 --> 00:50:18,960
from the data

00:50:17,440 --> 00:50:21,440
uh in which case you can keep your

00:50:18,960 --> 00:50:24,319
metadata actually in a separate space

00:50:21,440 --> 00:50:26,240
than your than your actual data and

00:50:24,319 --> 00:50:26,880
using the hashes you can you can go

00:50:26,240 --> 00:50:31,200
through them

00:50:26,880 --> 00:50:34,720
and uh and verify them um

00:50:31,200 --> 00:50:40,240
sort of extract them or or just even um

00:50:34,720 --> 00:50:41,760
get all the data bits and um

00:50:40,240 --> 00:50:43,440
based on the based on the hashes that

00:50:41,760 --> 00:50:46,800
are part of the uh

00:50:43,440 --> 00:50:50,000
the indexes um guarantee that

00:50:46,800 --> 00:50:52,559
that stuff is there and and not uh

00:50:50,000 --> 00:50:54,079
changed um so it's very it's really

00:50:52,559 --> 00:50:57,520
trivial to

00:50:54,079 --> 00:50:59,520
uh to detect um the

00:50:57,520 --> 00:51:01,200
whether the data was changed and and

00:50:59,520 --> 00:51:02,319
actually a couple of things are combined

00:51:01,200 --> 00:51:04,720
so that it is

00:51:02,319 --> 00:51:07,280
harder for a for an attacker to to

00:51:04,720 --> 00:51:10,960
change data

00:51:07,280 --> 00:51:12,240
but again i'm i if you're if you're

00:51:10,960 --> 00:51:15,440
interested i'm happy to

00:51:12,240 --> 00:51:18,640
take this take this up um

00:51:15,440 --> 00:51:21,280
and please reach out to me um

00:51:18,640 --> 00:51:23,839
on on email and happy to chat about

00:51:21,280 --> 00:51:23,839
stuff like this

00:51:33,040 --> 00:51:37,280
so how you synchronize keys between

00:51:34,880 --> 00:51:39,520
multiple devices

00:51:37,280 --> 00:51:40,400
it is not part of the threat model to

00:51:39,520 --> 00:51:44,000
solve this problem

00:51:40,400 --> 00:51:46,559
is basically your problem um

00:51:44,000 --> 00:51:47,680
or the or the user's problem and i

00:51:46,559 --> 00:51:50,880
really really like this

00:51:47,680 --> 00:51:55,200
because it means that suddenly

00:51:50,880 --> 00:51:57,440
the the storage and and the actual

00:51:55,200 --> 00:51:57,440
um

00:51:58,559 --> 00:52:02,720
the actual storage of data becomes

00:52:01,119 --> 00:52:05,280
completely disconnected from how you

00:52:02,720 --> 00:52:06,960
manage the keys to access that

00:52:05,280 --> 00:52:08,480
and i'm pretty sure there's a lot of

00:52:06,960 --> 00:52:10,720
research and there's a lot of

00:52:08,480 --> 00:52:11,839
very good and novel solutions for key

00:52:10,720 --> 00:52:15,119
distribution

00:52:11,839 --> 00:52:17,359
but i deliberately chose that chose not

00:52:15,119 --> 00:52:19,680
to include that in the design space

00:52:17,359 --> 00:52:21,119
because that's an entirely new challenge

00:52:19,680 --> 00:52:23,280
and

00:52:21,119 --> 00:52:25,040
i really really want to use this as a as

00:52:23,280 --> 00:52:28,400
a primitive

00:52:25,040 --> 00:52:29,359
that you can build up on this goes back

00:52:28,400 --> 00:52:31,599
to

00:52:29,359 --> 00:52:32,960
to one of the other questions about data

00:52:31,599 --> 00:52:36,000
verification

00:52:32,960 --> 00:52:38,559
the the model itself

00:52:36,000 --> 00:52:39,520
of what you store in these four megabyte

00:52:38,559 --> 00:52:42,800
blobs

00:52:39,520 --> 00:52:45,119
is completely up to you

00:52:42,800 --> 00:52:46,000
you can choose different data formats

00:52:45,119 --> 00:52:47,920
that you can

00:52:46,000 --> 00:52:49,599
you can put in there the fact that i'm

00:52:47,920 --> 00:52:52,880
using this for file encryption

00:52:49,599 --> 00:52:55,200
right now um is

00:52:52,880 --> 00:52:56,319
uh is something that i had a need for

00:52:55,200 --> 00:52:59,200
but ultimately

00:52:56,319 --> 00:53:00,880
uh it it's extensible and versatile

00:52:59,200 --> 00:53:02,400
enough that you can create your own

00:53:00,880 --> 00:53:06,079
indexing mechanisms

00:53:02,400 --> 00:53:10,000
and and build your own cryptographic um

00:53:06,079 --> 00:53:14,000
designs into a system that uses this

00:53:10,000 --> 00:53:29,839
storage layer so i think it's really

00:53:14,000 --> 00:53:29,839
good for composability

00:53:38,640 --> 00:53:42,079
there's a question about timing attacks

00:53:40,839 --> 00:53:46,079
when

00:53:42,079 --> 00:53:48,720
so what what happens when um

00:53:46,079 --> 00:53:50,240
somebody accesses uh the objects in

00:53:48,720 --> 00:53:51,760
quick succession

00:53:50,240 --> 00:53:53,440
uh meaning those likely belong to the

00:53:51,760 --> 00:53:55,280
same file so this is something that

00:53:53,440 --> 00:53:57,200
ingrain d can pick up

00:53:55,280 --> 00:53:58,720
so i'm working on the monitoring side

00:53:57,200 --> 00:54:00,079
and the detection side of this kind of

00:53:58,720 --> 00:54:02,960
stuff as well

00:54:00,079 --> 00:54:02,960
in another project

00:54:03,200 --> 00:54:10,000
it is completely completely possible

00:54:07,440 --> 00:54:11,839
to detect this kind of stuff and and use

00:54:10,000 --> 00:54:13,359
some sort of fancy statistical analysis

00:54:11,839 --> 00:54:16,160
to to actually start

00:54:13,359 --> 00:54:18,720
uh deriving this information if you are

00:54:16,160 --> 00:54:20,559
if you have compromised the server

00:54:18,720 --> 00:54:21,920
um the gut tray is that you don't know

00:54:20,559 --> 00:54:24,319
if somebody is trying to restore an

00:54:21,920 --> 00:54:26,559
entire backup or actually just

00:54:24,319 --> 00:54:28,400
and multiple files and you don't know

00:54:26,559 --> 00:54:32,240
which files they are accessing

00:54:28,400 --> 00:54:32,720
um and there are other vectors where you

00:54:32,240 --> 00:54:34,800
can

00:54:32,720 --> 00:54:36,400
you can actually observe how much data

00:54:34,800 --> 00:54:39,839
actually goes out on a

00:54:36,400 --> 00:54:39,839
network connection so

00:54:40,240 --> 00:54:44,960
um the the threat here is maybe

00:54:43,200 --> 00:54:47,520
identifying users i think

00:54:44,960 --> 00:54:48,000
i think that's possible um and i think

00:54:47,520 --> 00:54:49,760
that's

00:54:48,000 --> 00:54:52,960
that's very there's a very legitimate

00:54:49,760 --> 00:54:56,720
threat but it still

00:54:52,960 --> 00:55:01,280
um still protects the the user

00:54:56,720 --> 00:55:04,000
from um uh exposing the sensitive data

00:55:01,280 --> 00:55:05,280
and and so i think it's it composes

00:55:04,000 --> 00:55:06,880
really well again

00:55:05,280 --> 00:55:08,400
and you can you can deliberately slow

00:55:06,880 --> 00:55:10,319
down the server for instance so that an

00:55:08,400 --> 00:55:13,760
external observer cannot

00:55:10,319 --> 00:55:13,760
cannot detect these timing attacks

00:55:14,559 --> 00:55:17,920
um how does it handle encryption

00:55:16,720 --> 00:55:20,079
encrypting data smaller than four

00:55:17,920 --> 00:55:23,040
megabytes it will be just four megabytes

00:55:20,079 --> 00:55:24,000
um if you have if you have any any type

00:55:23,040 --> 00:55:25,280
of data it's gonna

00:55:24,000 --> 00:55:27,280
it's gonna you're gonna see that as

00:55:25,280 --> 00:55:30,400
multiples of four megabytes

00:55:27,280 --> 00:55:31,920
um which is which is why um

00:55:30,400 --> 00:55:33,359
distinguishing between files and

00:55:31,920 --> 00:55:36,880
different users if they are pulled

00:55:33,359 --> 00:55:36,880
together on the same server is sort of

00:55:46,839 --> 00:55:49,839
difficult

00:55:50,559 --> 00:55:55,359
so if there are no more questions

00:55:59,359 --> 00:56:05,920
yes so um i have a i have a role

00:56:03,520 --> 00:56:09,680
to give out a free ebook voucher and

00:56:05,920 --> 00:56:09,680
this is really exciting because um

00:56:10,559 --> 00:56:16,559
the best question wins the the ebooks

00:56:15,920 --> 00:56:18,079
and uh

00:56:16,559 --> 00:56:20,000
and i think one of the most interesting

00:56:18,079 --> 00:56:23,839
questions was

00:56:20,000 --> 00:56:23,839
um uh about

00:56:24,720 --> 00:56:31,280
crime and and the compression ratio by

00:56:28,160 --> 00:56:33,200
uh on twitch by henrik know i think

00:56:31,280 --> 00:56:36,400
that's that's very spot-on

00:56:33,200 --> 00:56:38,400
um and it and it's a good shout

00:56:36,400 --> 00:56:45,839
um so i i hope you're going to enjoy

00:56:38,400 --> 00:56:45,839
your ebook

00:56:47,839 --> 00:56:51,440
cool um i would like to thank everybody

00:56:49,839 --> 00:56:56,079
for for joining tonight

00:56:51,440 --> 00:56:56,079
and thank again for the organizers

00:56:56,839 --> 00:57:03,280
um

00:56:58,079 --> 00:57:03,280

YouTube URL: https://www.youtube.com/watch?v=rspSTNDap5A


