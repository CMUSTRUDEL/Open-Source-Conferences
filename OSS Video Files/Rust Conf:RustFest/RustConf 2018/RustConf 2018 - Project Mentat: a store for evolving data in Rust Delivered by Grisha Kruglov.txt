Title: RustConf 2018 - Project Mentat: a store for evolving data in Rust Delivered by Grisha Kruglov
Publication date: 2018-09-06
Playlist: RustConf 2018
Description: 
	RustConf 2018 - Project Mentat: a store for evolving data in Rust Delivered by Grisha Kruglov
Prepared by Emily Toop

Mozilla has a data storage problem. There is no unified strategy for storing new user data and moving it between devices, which has led to a proliferation of stores and strategies and a fragile mechanism for syncing that only handles a subset of data collected. Project Mentat was born to help resolve these issues - a structured data store that is designed to be replicated and synchronized and written in Rust to ensure security, safety and maximum portability between platforms.

This talk is about why we decided to "build" rather than "buy", how Mentat is designed to address the problems and requirements associated with data storage and syncing in an environment with trong client-side encryption, - as well as the challenges encountered and lessons learned while using Rust to create portable, performant, persistent, syncing, structured data storage.
Captions: 
	00:00:00,410 --> 00:00:16,309
[Music]

00:00:14,350 --> 00:00:18,260
that works okay

00:00:16,309 --> 00:00:21,320
yeah thanks everyone for coming my name

00:00:18,260 --> 00:00:23,119
is quisha Kruglov I work for Mozilla as

00:00:21,320 --> 00:00:26,270
an engineer and I'm here as a poor

00:00:23,119 --> 00:00:28,640
conduit for Emily slides she could make

00:00:26,270 --> 00:00:31,090
it at last moment so I'm here to talk

00:00:28,640 --> 00:00:35,720
about projects meant at which is a

00:00:31,090 --> 00:00:37,100
embedded rust or that we're using at

00:00:35,720 --> 00:00:39,620
Mozilla to solve some of our problems

00:00:37,100 --> 00:00:41,989
and I'll talk about what those problems

00:00:39,620 --> 00:00:45,130
are how we're trying to solve them and a

00:00:41,989 --> 00:00:50,120
bit a bit about that that team is

00:00:45,130 --> 00:00:52,100
working on that time so we're part of

00:00:50,120 --> 00:00:55,550
the browser architecture user data team

00:00:52,100 --> 00:00:58,129
and that's Emily to Nick Alexander

00:00:55,550 --> 00:01:01,670
myself and in the past richer Newman

00:00:58,129 --> 00:01:07,490
who's with us in spirit and in the front

00:01:01,670 --> 00:01:11,899
row and yeah and so the team's

00:01:07,490 --> 00:01:13,700
team's goals are to kind of figure out

00:01:11,899 --> 00:01:15,380
what's what what changes we need to make

00:01:13,700 --> 00:01:18,860
now to solve our three to five year

00:01:15,380 --> 00:01:23,810
goals and for Mozilla and for Firefox

00:01:18,860 --> 00:01:25,760
those are expanding Firefox and so like

00:01:23,810 --> 00:01:27,290
making the Firefox better creating user

00:01:25,760 --> 00:01:29,090
experiences and also going beyond

00:01:27,290 --> 00:01:32,360
Firefox building the applications to

00:01:29,090 --> 00:01:34,040
solve particularly user needs and a lot

00:01:32,360 --> 00:01:37,040
of this stuff Revolt like there's a lot

00:01:34,040 --> 00:01:40,909
of hurdles involved but one of the big

00:01:37,040 --> 00:01:42,890
things is user data right it's like okay

00:01:40,909 --> 00:01:44,810
that's our big moat essentially is we

00:01:42,890 --> 00:01:46,479
have a lot of valuable data and people

00:01:44,810 --> 00:01:48,979
would like to access it in different

00:01:46,479 --> 00:01:52,280
types of applications and our apps will

00:01:48,979 --> 00:01:53,180
like to use them and currently that's

00:01:52,280 --> 00:01:58,579
problematic

00:01:53,180 --> 00:02:03,259
we have for reasons that I'll kind of go

00:01:58,579 --> 00:02:05,509
through so part of the so one of the

00:02:03,259 --> 00:02:06,829
problems is storing storing the data so

00:02:05,509 --> 00:02:08,690
we store it like something like a

00:02:06,829 --> 00:02:10,009
browser stores a lot of it'll you will

00:02:08,690 --> 00:02:12,769
be surprised how many different things

00:02:10,009 --> 00:02:14,959
it stores some what about is about user

00:02:12,769 --> 00:02:17,150
behavior some of is some of it is about

00:02:14,959 --> 00:02:19,430
just like internals of the browser and a

00:02:17,150 --> 00:02:22,489
lot of it and so there are a lot of

00:02:19,430 --> 00:02:26,390
different teams involved in installing

00:02:22,489 --> 00:02:26,780
this stuff and it seems make their own

00:02:26,390 --> 00:02:28,940
this

00:02:26,780 --> 00:02:31,819
it's about data storage layers and

00:02:28,940 --> 00:02:34,130
oftentimes those decisions are driven

00:02:31,819 --> 00:02:36,560
more by immediate needs like how do we

00:02:34,130 --> 00:02:40,370
make this thing work for the cui how to

00:02:36,560 --> 00:02:42,140
make it how do we query it quickly you

00:02:40,370 --> 00:02:45,560
know how do we ship it tomorrow

00:02:42,140 --> 00:02:47,300
etc etc right and so and then since a

00:02:45,560 --> 00:02:49,480
lot of different teams may are making

00:02:47,300 --> 00:02:52,459
the decisions they're not necessarily

00:02:49,480 --> 00:02:56,480
well so they're making the decisions the

00:02:52,459 --> 00:02:58,069
end the outcomes very since you just

00:02:56,480 --> 00:02:59,300
have a lot of people and not everyone

00:02:58,069 --> 00:03:01,850
talks to each other and like there's

00:02:59,300 --> 00:03:04,700
some of the shared expertise when some

00:03:01,850 --> 00:03:06,320
of it is sort of like folk knowledge and

00:03:04,700 --> 00:03:08,480
seems might not be thinking about needs

00:03:06,320 --> 00:03:10,459
beyond their immediate needs so like if

00:03:08,480 --> 00:03:12,050
today and like in a month you don't need

00:03:10,459 --> 00:03:14,660
to share some data in between different

00:03:12,050 --> 00:03:16,940
clients you might not like bake that

00:03:14,660 --> 00:03:19,069
into your initial data schema and then

00:03:16,940 --> 00:03:20,540
you'll realize that - like when you will

00:03:19,069 --> 00:03:25,330
need that eventually it's gonna be

00:03:20,540 --> 00:03:27,980
problematic to you evolve right and so

00:03:25,330 --> 00:03:31,130
the decisions that people end up making

00:03:27,980 --> 00:03:33,290
around data storage needs well they

00:03:31,130 --> 00:03:35,329
often they start off as like well let's

00:03:33,290 --> 00:03:38,630
just do something simple if you like a

00:03:35,329 --> 00:03:40,549
JSON store or something and and that

00:03:38,630 --> 00:03:42,470
doesn't tend to scale all that well

00:03:40,549 --> 00:03:43,549
right it might solve your really

00:03:42,470 --> 00:03:45,950
immediate needs but it doesn't

00:03:43,549 --> 00:03:50,329
necessarily solve future needs and you

00:03:45,950 --> 00:03:54,350
know like building fast concurrent safe

00:03:50,329 --> 00:03:56,000
access to adjacent store that will you

00:03:54,350 --> 00:03:58,040
know what happened across many different

00:03:56,000 --> 00:04:01,010
components is it's gonna be troublesome

00:03:58,040 --> 00:04:03,260
and you're gonna end up essentially

00:04:01,010 --> 00:04:04,310
solving a lot of hard problems many many

00:04:03,260 --> 00:04:08,420
times because you have many different

00:04:04,310 --> 00:04:10,400
data stores and and then if you do pick

00:04:08,420 --> 00:04:18,530
like a more comprehensive solution to

00:04:10,400 --> 00:04:21,260
begin with you'll well you will sorry I

00:04:18,530 --> 00:04:24,710
don't know I don't own voice slides here

00:04:21,260 --> 00:04:26,419
but you'll you'll end up with like with

00:04:24,710 --> 00:04:29,720
a lot of will host of other problems

00:04:26,419 --> 00:04:32,240
right so like if you so for example like

00:04:29,720 --> 00:04:34,640
if you picked a sequel light store as

00:04:32,240 --> 00:04:37,280
your storage model you'll still need to

00:04:34,640 --> 00:04:39,229
handle a lot of migrations and here's

00:04:37,280 --> 00:04:39,630
your project evolves as your data needs

00:04:39,229 --> 00:04:42,360
of

00:04:39,630 --> 00:04:44,820
evolved that tends to become quite

00:04:42,360 --> 00:04:47,760
problematic as well when people don't

00:04:44,820 --> 00:04:49,440
necessarily think about think in a

00:04:47,760 --> 00:04:50,850
correct ways about those problems

00:04:49,440 --> 00:04:53,180
because it's it's it's a fairly

00:04:50,850 --> 00:04:55,500
specialized skill doing this stuff like

00:04:53,180 --> 00:04:59,640
building data stores that will sync and

00:04:55,500 --> 00:05:01,920
it will wolf well over time and another

00:04:59,640 --> 00:05:04,770
so that kind of ties into the second

00:05:01,920 --> 00:05:07,620
point is sharing good data and by

00:05:04,770 --> 00:05:09,150
sharing we mean sharing amongst mullick

00:05:07,620 --> 00:05:10,890
and as far as Firefox we mean

00:05:09,150 --> 00:05:12,750
specifically sharing it cause different

00:05:10,890 --> 00:05:15,210
instances of Firefox well and if you

00:05:12,750 --> 00:05:19,140
sure between different products that use

00:05:15,210 --> 00:05:22,050
Firefox data so we have strong privacy

00:05:19,140 --> 00:05:24,690
guarantees and it's part of like a big

00:05:22,050 --> 00:05:28,620
part of that is enter an encryption and

00:05:24,690 --> 00:05:31,320
which means that clients have to do all

00:05:28,620 --> 00:05:33,390
of the conflict resolution work server

00:05:31,320 --> 00:05:37,230
cannot be there like servers just to

00:05:33,390 --> 00:05:40,320
dump a blob store more or less and we

00:05:37,230 --> 00:05:42,990
have multiple clients and the set of

00:05:40,320 --> 00:05:44,700
clients is growing and would like it to

00:05:42,990 --> 00:05:46,710
grow right that's part of our three to

00:05:44,700 --> 00:05:48,000
five-year goals is that you know

00:05:46,710 --> 00:05:53,190
building more products that use this

00:05:48,000 --> 00:05:54,810
data right and then each client is they

00:05:53,190 --> 00:05:56,130
have their own data storage

00:05:54,810 --> 00:05:58,380
implementations are written in different

00:05:56,130 --> 00:06:02,420
languages you have JavaScript C Java

00:05:58,380 --> 00:06:05,900
Swift with sutter implementations and

00:06:02,420 --> 00:06:09,390
yeah and and and the clients tend to

00:06:05,900 --> 00:06:11,280
build data like that the teams that are

00:06:09,390 --> 00:06:14,790
building this stuff they tend to build

00:06:11,280 --> 00:06:16,230
data that's oriented around their

00:06:14,790 --> 00:06:19,470
immediate needs so like wearing this

00:06:16,230 --> 00:06:22,050
stuff like which isn't and the the

00:06:19,470 --> 00:06:23,520
schemas you'll you take for that are not

00:06:22,050 --> 00:06:25,890
necessarily the schemas you'll take if

00:06:23,520 --> 00:06:29,250
you want to optimize to optimize for

00:06:25,890 --> 00:06:31,050
syncing and so you run into problems

00:06:29,250 --> 00:06:32,940
like you can't do three we merges of

00:06:31,050 --> 00:06:36,830
data because you don't have historical

00:06:32,940 --> 00:06:41,820
view into how some the tables changed

00:06:36,830 --> 00:06:44,570
and yeah so here so let's let's I guess

00:06:41,820 --> 00:06:46,950
let's try to look at a concrete example

00:06:44,570 --> 00:06:48,479
of what that actually looks like in

00:06:46,950 --> 00:06:50,820
practice like here's a symbol like a

00:06:48,479 --> 00:06:51,350
really simplistic way to model a

00:06:50,820 --> 00:06:53,870
password

00:06:51,350 --> 00:06:55,610
storage layer so like it will have two

00:06:53,870 --> 00:06:57,670
clients we have a server in the middle

00:06:55,610 --> 00:07:00,350
which it just acts as a dump blob and

00:06:57,670 --> 00:07:02,930
the schema is very basic you there's a

00:07:00,350 --> 00:07:07,430
URL for that URL who have username and

00:07:02,930 --> 00:07:09,800
password and and there's a time step so

00:07:07,430 --> 00:07:14,600
there's some immediate problems as you

00:07:09,800 --> 00:07:17,750
start making changes here so say imagine

00:07:14,600 --> 00:07:21,050
client 1 makes a change to a URL maybe

00:07:17,750 --> 00:07:23,150
they've observed now that I think

00:07:21,050 --> 00:07:25,430
there's a change so they've observed the

00:07:23,150 --> 00:07:27,620
URL changed and they record one that the

00:07:25,430 --> 00:07:29,090
change happen and client 2 makes a

00:07:27,620 --> 00:07:33,260
change to the password so you'll see the

00:07:29,090 --> 00:07:38,810
password is no different and there's

00:07:33,260 --> 00:07:41,120
some animation yeah there you go yeah so

00:07:38,810 --> 00:07:44,900
like client 1 syncs the data is now on

00:07:41,120 --> 00:07:50,180
the server and client 2 will sink

00:07:44,900 --> 00:07:51,680
eventually and the data will now slowly

00:07:50,180 --> 00:07:54,290
yeah you'll notice that like we

00:07:51,680 --> 00:07:55,880
essentially get a blob JSON blob back

00:07:54,290 --> 00:07:59,060
right and now at this point we have to

00:07:55,880 --> 00:08:01,340
make a decision like we have to JSON

00:07:59,060 --> 00:08:03,260
blobs we and we have to somehow smush

00:08:01,340 --> 00:08:05,540
them together right we see that the URL

00:08:03,260 --> 00:08:07,460
change the password changed and this

00:08:05,540 --> 00:08:09,200
information is on the server already so

00:08:07,460 --> 00:08:10,580
other clients might have seen it so we

00:08:09,200 --> 00:08:13,610
don't have a ton of choice here we have

00:08:10,580 --> 00:08:15,800
to take what we see which is usually

00:08:13,610 --> 00:08:19,280
what happens since in like simplistic

00:08:15,800 --> 00:08:21,560
kind of syncing scheme flows like this

00:08:19,280 --> 00:08:25,070
right and so we end up on the client -

00:08:21,560 --> 00:08:27,320
we've just lost the password so like

00:08:25,070 --> 00:08:29,030
this is a lossy process we lost the

00:08:27,320 --> 00:08:30,680
password changed and we end up like with

00:08:29,030 --> 00:08:33,050
a state that we've never really observed

00:08:30,680 --> 00:08:37,539
and clients week has really no way to

00:08:33,050 --> 00:08:40,010
recover from this and so there ways to

00:08:37,539 --> 00:08:41,780
kind of fix that problem in an existing

00:08:40,010 --> 00:08:43,820
world but they tend to involve a lot of

00:08:41,780 --> 00:08:45,950
a lot of work essentially right like

00:08:43,820 --> 00:08:47,990
this we could track more states on each

00:08:45,950 --> 00:08:49,010
client but as I mentioned we have many

00:08:47,990 --> 00:08:50,630
clients and they all have different

00:08:49,010 --> 00:08:52,310
implementations of stores and it

00:08:50,630 --> 00:08:53,930
involves writing a lot of complicated

00:08:52,310 --> 00:08:56,810
code many times in different languages

00:08:53,930 --> 00:08:59,660
and trying to coordinate across teams to

00:08:56,810 --> 00:09:03,440
do that but there's this concept called

00:08:59,660 --> 00:09:05,540
so a bit like one of the lessons that we

00:09:03,440 --> 00:09:07,759
owe that people tend to learn

00:09:05,540 --> 00:09:09,620
as they write this stuff is it's it

00:09:07,759 --> 00:09:13,070
helps to separate the way you query

00:09:09,620 --> 00:09:15,740
stuff from the way you modify your data

00:09:13,070 --> 00:09:18,709
right and that's there's this idea of

00:09:15,740 --> 00:09:21,620
CQRS so that you essentially segregate

00:09:18,709 --> 00:09:23,149
separate query from command right so

00:09:21,620 --> 00:09:25,880
like you separate the way you modify

00:09:23,149 --> 00:09:27,980
data from you the way you query it and

00:09:25,880 --> 00:09:30,230
that was you address individual like

00:09:27,980 --> 00:09:33,410
needs specific to each side of that

00:09:30,230 --> 00:09:35,990
equation in a more coherent way and be

00:09:33,410 --> 00:09:37,910
very explicit about that separation so

00:09:35,990 --> 00:09:41,300
for example we'd like fast querying but

00:09:37,910 --> 00:09:43,670
we'll also like data that is syncable

00:09:41,300 --> 00:09:46,970
and those two are kind of at odds with

00:09:43,670 --> 00:09:48,949
each other and this kind of approach

00:09:46,970 --> 00:09:51,860
making this explicit lets us actually

00:09:48,949 --> 00:09:56,029
address the Boyd make some progress or

00:09:51,860 --> 00:09:59,360
the problem with the problem and so yeah

00:09:56,029 --> 00:10:01,639
so we get to try to access it and so we

00:09:59,360 --> 00:10:04,660
get to trying to build mentat and fix

00:10:01,639 --> 00:10:09,470
those problems that we've observed and

00:10:04,660 --> 00:10:11,510
we the team's made we went through what

00:10:09,470 --> 00:10:13,519
kind of this regular buyer built this

00:10:11,510 --> 00:10:16,279
decision like we're like we're looking

00:10:13,519 --> 00:10:19,339
for something that solves the problems

00:10:16,279 --> 00:10:22,069
like maybe has a maybe he's shaped in

00:10:19,339 --> 00:10:25,730
the crs style maybe his event or like

00:10:22,069 --> 00:10:29,060
log shaped has allows us to define

00:10:25,730 --> 00:10:30,829
strong schemas explicitly visibly that

00:10:29,060 --> 00:10:32,510
really helps with syncing data and

00:10:30,829 --> 00:10:34,970
there's always the schema in your data

00:10:32,510 --> 00:10:36,589
even if it's implicit except that you're

00:10:34,970 --> 00:10:40,300
just gonna like it's just a food gun

00:10:36,589 --> 00:10:42,319
waiting to fire if it's not explicit and

00:10:40,300 --> 00:10:46,130
yeah and then so we went through like

00:10:42,319 --> 00:10:50,600
this kind of a set of regular suspects

00:10:46,130 --> 00:10:52,670
and like the the point is that something

00:10:50,600 --> 00:10:54,050
will always have run into missing

00:10:52,670 --> 00:10:56,089
features right like it's not embeddable

00:10:54,050 --> 00:10:58,639
or doesn't have full-text indexing or we

00:10:56,089 --> 00:11:01,010
can't you know use it some many

00:10:58,639 --> 00:11:04,189
different platforms with a single

00:11:01,010 --> 00:11:07,370
implementation and so ideologically in

00:11:04,189 --> 00:11:09,740
the we've came across the atomic which

00:11:07,370 --> 00:11:13,490
is a database that exists in the closure

00:11:09,740 --> 00:11:17,040
world and it's transactional it has

00:11:13,490 --> 00:11:19,800
human data models in the sense that the

00:11:17,040 --> 00:11:22,080
like there well we have a strongly typed

00:11:19,800 --> 00:11:22,950
schema with it and we can mutate it for

00:11:22,080 --> 00:11:24,930
time easily

00:11:22,950 --> 00:11:27,030
we have transaction we have a log of

00:11:24,930 --> 00:11:29,430
everything that happens we have rich

00:11:27,030 --> 00:11:32,490
querying via the data log which is their

00:11:29,430 --> 00:11:34,830
querying language but yeah it's only but

00:11:32,490 --> 00:11:36,780
only in the spirit is it like a good

00:11:34,830 --> 00:11:39,150
good fit visits it well it actually is a

00:11:36,780 --> 00:11:44,220
server-side kind of a system it's not

00:11:39,150 --> 00:11:46,110
open source and yeah then we get to data

00:11:44,220 --> 00:11:48,330
script which exists in the same similar

00:11:46,110 --> 00:11:50,580
mindshare it's a closer script

00:11:48,330 --> 00:11:53,280
implementation of those ideas over the

00:11:50,580 --> 00:11:56,070
tommix ideas but again it more requires

00:11:53,280 --> 00:11:58,800
a JavaScript runtime so not really

00:11:56,070 --> 00:12:01,440
something we can necessarily deploy for

00:11:58,800 --> 00:12:03,690
real in in in the environments we care

00:12:01,440 --> 00:12:05,070
about and it exists in memory only and

00:12:03,690 --> 00:12:07,880
we really care about persistence so

00:12:05,070 --> 00:12:11,730
later and so we get to build your own

00:12:07,880 --> 00:12:14,730
and so like the which is what the rest

00:12:11,730 --> 00:12:18,060
of this kind of talk covers and the

00:12:14,730 --> 00:12:20,190
basic concept is for now anyway is to

00:12:18,060 --> 00:12:22,020
use something like sequel Lite or

00:12:20,190 --> 00:12:23,790
specifically psycho light underneath to

00:12:22,020 --> 00:12:26,900
store the data is you get everything

00:12:23,790 --> 00:12:28,920
from sequel lights it's a solid project

00:12:26,900 --> 00:12:33,930
you have a real it's a reliable

00:12:28,920 --> 00:12:36,150
relational store with FTS capable small

00:12:33,930 --> 00:12:38,280
memory footprint etc etc there's a long

00:12:36,150 --> 00:12:40,620
history behind it and then we'll start

00:12:38,280 --> 00:12:43,470
layering kind of the ideas we care about

00:12:40,620 --> 00:12:45,180
on top of sequel lights so we'll layer

00:12:43,470 --> 00:12:48,180
transaction log on top we'll have a

00:12:45,180 --> 00:12:51,660
meter ball strongly-typed schema and we

00:12:48,180 --> 00:12:54,000
have querying it and and that implies

00:12:51,660 --> 00:12:56,130
that we'll need to run search kind of

00:12:54,000 --> 00:12:58,020
compile our querying query language or

00:12:56,130 --> 00:13:01,650
like data log in this case into sequel

00:12:58,020 --> 00:13:04,110
in the end and so one of the first kind

00:13:01,650 --> 00:13:06,120
of prototypes and stubs of this is was

00:13:04,110 --> 00:13:08,370
written in CoffeeScript because at the

00:13:06,120 --> 00:13:10,560
time were prototyping a browser written

00:13:08,370 --> 00:13:13,440
in JavaScript and this like this was a

00:13:10,560 --> 00:13:16,920
good prototyping decision we ran into a

00:13:13,440 --> 00:13:19,740
bunch of problems i guessing channels

00:13:16,920 --> 00:13:23,910
etc like the transpiling process was

00:13:19,740 --> 00:13:26,460
slow and buggy and it's just an again

00:13:23,910 --> 00:13:28,600
like this required a JavaScript runtime

00:13:26,460 --> 00:13:30,760
which like it is

00:13:28,600 --> 00:13:32,410
there's a hard requirements if you're

00:13:30,760 --> 00:13:34,390
trying to embed this across and use this

00:13:32,410 --> 00:13:40,930
across like obvious Android applications

00:13:34,390 --> 00:13:43,570
and also in desktop etc and so we yeah

00:13:40,930 --> 00:13:45,520
so like rust is a natural next kind of a

00:13:43,570 --> 00:13:49,750
choice like the only real alternative to

00:13:45,520 --> 00:13:51,550
this is C++ but but like we get a lot of

00:13:49,750 --> 00:13:54,160
benefits from rust right like it's a

00:13:51,550 --> 00:13:56,980
modern expressive language with really

00:13:54,160 --> 00:13:59,350
nice algebraic algebraic data types that

00:13:56,980 --> 00:14:02,740
really kind of help manage complexity or

00:13:59,350 --> 00:14:05,920
something like this it's and we get

00:14:02,740 --> 00:14:07,990
predictable correct results once we sort

00:14:05,920 --> 00:14:11,980
of work through all of the problems

00:14:07,990 --> 00:14:14,380
right and we it's performance right so

00:14:11,980 --> 00:14:16,360
like there it's not all kind of roses

00:14:14,380 --> 00:14:18,490
it's the implementation took much longer

00:14:16,360 --> 00:14:20,680
to write and something done the initial

00:14:18,490 --> 00:14:23,770
prototype enclosure script and it's

00:14:20,680 --> 00:14:26,440
still a kind of an ongoing thing but we

00:14:23,770 --> 00:14:27,790
like we get like we we get a lot of

00:14:26,440 --> 00:14:30,400
things out of it right the in the

00:14:27,790 --> 00:14:31,690
trifecta that meant that cares the

00:14:30,400 --> 00:14:34,090
rostra effect that meant that cares

00:14:31,690 --> 00:14:38,490
about this kind of correctness combined

00:14:34,090 --> 00:14:41,770
with portability so cross-platform

00:14:38,490 --> 00:14:43,510
combine the performance so those sort of

00:14:41,770 --> 00:14:47,680
things that really make a difference

00:14:43,510 --> 00:14:52,120
here so and if we kind of peek under the

00:14:47,680 --> 00:14:54,430
hood of Mendte it's essentially it's

00:14:52,120 --> 00:14:57,490
like the core is the transaction log and

00:14:54,430 --> 00:14:59,290
this isn't quite what like if you if you

00:14:57,490 --> 00:15:02,050
were to open up an entire sequel I

00:14:59,290 --> 00:15:04,840
databases and this isn't an exact

00:15:02,050 --> 00:15:08,410
representation of its close enough it's

00:15:04,840 --> 00:15:10,120
a quad well it's a tapas store we have

00:15:08,410 --> 00:15:13,090
everything is an entity in the system

00:15:10,120 --> 00:15:16,300
including your schema definitions and

00:15:13,090 --> 00:15:19,210
entities are described by attributes we

00:15:16,300 --> 00:15:22,750
and then like the the to have a value

00:15:19,210 --> 00:15:24,940
right so like a URL so like a login URL

00:15:22,750 --> 00:15:27,370
will be an attribute of some entity and

00:15:24,940 --> 00:15:31,030
there'll be a value of like Ross con-com

00:15:27,370 --> 00:15:33,040
and those everything is grouped by

00:15:31,030 --> 00:15:35,350
transactions because we want atomic

00:15:33,040 --> 00:15:38,320
applications of data we kind of want to

00:15:35,350 --> 00:15:41,480
track when things happen and how and

00:15:38,320 --> 00:15:43,579
since it's a log and it's an append-only

00:15:41,480 --> 00:15:46,189
kind of vlog we need to know I for

00:15:43,579 --> 00:15:49,850
adding or retracting a piece of data so

00:15:46,189 --> 00:15:52,579
changing a URL will actually involve

00:15:49,850 --> 00:15:56,209
retracting the existing URL and then

00:15:52,579 --> 00:15:58,160
appending a new one and so that's what

00:15:56,209 --> 00:16:00,889
this looks like I'm like like under the

00:15:58,160 --> 00:16:02,989
hood and so the the thing that's missing

00:16:00,889 --> 00:16:05,779
here is the you know the values can be

00:16:02,989 --> 00:16:07,879
typed and we have a bunch of different

00:16:05,779 --> 00:16:11,089
types with support and you know that we

00:16:07,879 --> 00:16:12,919
can enforce that at schema level and

00:16:11,089 --> 00:16:17,019
then mentat will complain if you're

00:16:12,919 --> 00:16:19,819
trying to write wrong types into data

00:16:17,019 --> 00:16:23,119
yeah and so and let's try to and like

00:16:19,819 --> 00:16:25,399
this is an example of what the

00:16:23,119 --> 00:16:27,199
transaction table how data flows around

00:16:25,399 --> 00:16:30,529
right there what it actually looks like

00:16:27,199 --> 00:16:32,419
for real so for example like it's also

00:16:30,529 --> 00:16:34,579
simplistic but it's I think it

00:16:32,419 --> 00:16:36,859
illustrates the problem well enough so

00:16:34,579 --> 00:16:40,879
we have the same situation as before we

00:16:36,859 --> 00:16:42,649
have client 1 to blob the service still

00:16:40,879 --> 00:16:45,379
like a Dom server blob everything is

00:16:42,649 --> 00:16:48,109
still on to and encrypted and except now

00:16:45,379 --> 00:16:49,819
we have those transaction logs and so

00:16:48,109 --> 00:16:51,919
let's try start making changes all right

00:16:49,819 --> 00:16:54,109
so like me changing a password inclined

00:16:51,919 --> 00:16:57,139
to we're missing some records but this

00:16:54,109 --> 00:16:59,179
is good enough is essentially evolves

00:16:57,139 --> 00:17:01,069
appending a new password to the log and

00:16:59,179 --> 00:17:04,760
you'll notice that it's now it's in a

00:17:01,069 --> 00:17:07,639
different transaction and let's make a

00:17:04,760 --> 00:17:13,819
similar change in I'm client one will

00:17:07,639 --> 00:17:16,819
append a new new URL and there you go

00:17:13,819 --> 00:17:19,429
now we're syncing stuff we append like

00:17:16,819 --> 00:17:22,159
so log a server essentially has like an

00:17:19,429 --> 00:17:25,939
encrypted log which to into which we

00:17:22,159 --> 00:17:28,250
appended new records and so that's when

00:17:25,939 --> 00:17:29,840
we sync those records back

00:17:28,250 --> 00:17:34,789
we now have like you'll notice that we

00:17:29,840 --> 00:17:37,090
have conflicting IDs so it's almost an

00:17:34,789 --> 00:17:40,340
implementational detail since we chose

00:17:37,090 --> 00:17:43,039
integer you know the cool like

00:17:40,340 --> 00:17:45,139
transactions are presented as an integer

00:17:43,039 --> 00:17:47,929
but like we perform something akin to a

00:17:45,139 --> 00:17:50,210
git rebase where you playback will you

00:17:47,929 --> 00:17:52,159
rewind your current state back to our

00:17:50,210 --> 00:17:54,620
shared parents you play in remote

00:17:52,159 --> 00:17:57,110
changes and then

00:17:54,620 --> 00:17:59,630
your local changes on top and like

00:17:57,110 --> 00:18:02,750
that's one way to do this you could also

00:17:59,630 --> 00:18:04,880
represent this as a merge or depending

00:18:02,750 --> 00:18:07,910
on your needs or like the schema my

00:18:04,880 --> 00:18:09,320
different things might make sense but

00:18:07,910 --> 00:18:12,320
like if you're just doing a simple

00:18:09,320 --> 00:18:15,620
rebased well you end up with this nice

00:18:12,320 --> 00:18:16,850
linear log where you have like an exact

00:18:15,620 --> 00:18:18,440
record of everything that happened in

00:18:16,850 --> 00:18:21,170
the system you have the old password any

00:18:18,440 --> 00:18:25,070
passwords the URLs everything and then

00:18:21,170 --> 00:18:28,130
we sync back the log back to the first

00:18:25,070 --> 00:18:30,410
clients there you go

00:18:28,130 --> 00:18:32,900
and so now both clients they agree on

00:18:30,410 --> 00:18:36,500
the log they have a coherent view into

00:18:32,900 --> 00:18:37,820
the system and they have a nicely like

00:18:36,500 --> 00:18:39,350
they have a nice historically of

00:18:37,820 --> 00:18:42,080
everything happened and so like your

00:18:39,350 --> 00:18:44,330
conflict resolution algorithms like

00:18:42,080 --> 00:18:46,600
specific to the domain so the data

00:18:44,330 --> 00:18:52,460
models can make the right decisions

00:18:46,600 --> 00:18:54,679
which is nice so that's kind of flow

00:18:52,460 --> 00:18:57,320
right and then and then then we get back

00:18:54,679 --> 00:19:00,800
to kind of querying this data so like we

00:18:57,320 --> 00:19:02,360
talked about CRS and how it's important

00:19:00,800 --> 00:19:06,170
to kind of think about that separation

00:19:02,360 --> 00:19:07,850
of how you restore data and and how you

00:19:06,170 --> 00:19:09,830
modify the data and on how you read it

00:19:07,850 --> 00:19:12,170
back right and then those are quite

00:19:09,830 --> 00:19:14,000
different like if you were to read the

00:19:12,170 --> 00:19:17,020
transaction log away from the beginning

00:19:14,000 --> 00:19:18,830
it's it will be a terrible experience

00:19:17,020 --> 00:19:21,500
performance wise since you have to

00:19:18,830 --> 00:19:23,960
actually so like so we do that for you

00:19:21,500 --> 00:19:25,340
like we call that the datum stable and

00:19:23,960 --> 00:19:27,050
it's a it's a it's essentially a

00:19:25,340 --> 00:19:29,030
materialized view into the transaction

00:19:27,050 --> 00:19:32,390
like it's a snapshot of the transaction

00:19:29,030 --> 00:19:36,290
log as it is as of the last transaction

00:19:32,390 --> 00:19:38,570
and so so you notice it's missing the

00:19:36,290 --> 00:19:40,700
added field it sounds small it's not

00:19:38,570 --> 00:19:42,679
it's just the snapshot this is what it

00:19:40,700 --> 00:19:45,500
is now so it's an amount out internally

00:19:42,679 --> 00:19:51,050
keeps modifying this materialization as

00:19:45,500 --> 00:19:53,900
the video changes and yeah and then so

00:19:51,050 --> 00:19:55,760
you'll notice that so this is what the

00:19:53,900 --> 00:19:57,590
data table will look like and you'll

00:19:55,760 --> 00:20:00,320
notice that the attribute is now

00:19:57,590 --> 00:20:01,850
expanded like it's actually attributes

00:20:00,320 --> 00:20:04,280
are also part of the scheme and they

00:20:01,850 --> 00:20:05,900
they they're just another entity in the

00:20:04,280 --> 00:20:08,120
system you have entities discovering and

00:20:05,900 --> 00:20:12,500
this is kind of like an RDF like

00:20:08,120 --> 00:20:14,360
approach and yeah and then like when

00:20:12,500 --> 00:20:16,820
we're acquiring this stuff we expands I

00:20:14,360 --> 00:20:19,270
was into like from the keywords like

00:20:16,820 --> 00:20:23,240
login URL into like an actual entity and

00:20:19,270 --> 00:20:25,700
the datum stable will contain that I'm

00:20:23,240 --> 00:20:27,470
going but when you're querying this data

00:20:25,700 --> 00:20:29,990
you don't have to worry about stuff like

00:20:27,470 --> 00:20:32,480
this you can you describe the attributes

00:20:29,990 --> 00:20:34,520
you'd like and this is like a simple

00:20:32,480 --> 00:20:36,650
example of data log query that you would

00:20:34,520 --> 00:20:39,170
use to query this stuff you describe

00:20:36,650 --> 00:20:41,660
what you would like and you define your

00:20:39,170 --> 00:20:46,220
bindings like URL username password will

00:20:41,660 --> 00:20:48,620
be bound to login /url etc and you could

00:20:46,220 --> 00:20:51,530
back and then internally mentat will

00:20:48,620 --> 00:20:54,200
compile this down into my chip sequel

00:20:51,530 --> 00:20:57,170
and you'll notice that's it's a self

00:20:54,200 --> 00:20:58,640
joins the datums on adam's table so

00:20:57,170 --> 00:21:00,230
we're querying we're not querying the

00:20:58,640 --> 00:21:03,830
transaction log we're querying this

00:21:00,230 --> 00:21:06,020
internal materialized view of it it's a

00:21:03,830 --> 00:21:12,050
bit quicker it's not like it's still

00:21:06,020 --> 00:21:13,910
very slow or slow enough but it's yeah

00:21:12,050 --> 00:21:15,770
but like it's that's how it would sort

00:21:13,910 --> 00:21:18,440
of look like internally it's like you go

00:21:15,770 --> 00:21:20,060
from from from this into into this and

00:21:18,440 --> 00:21:22,460
you'll notice that like we're not doing

00:21:20,060 --> 00:21:24,950
anything really tricky here like we've

00:21:22,460 --> 00:21:27,020
resolved the attributes into their aunt

00:21:24,950 --> 00:21:29,450
IDs and we're joining on anti D so it's

00:21:27,020 --> 00:21:33,740
ensure we get the correct view of the

00:21:29,450 --> 00:21:34,970
data for each entity yeah and then you

00:21:33,740 --> 00:21:38,090
get diagnosed results and this is

00:21:34,970 --> 00:21:40,150
missing at the anti Z column but you

00:21:38,090 --> 00:21:44,720
could buy data from from the system and

00:21:40,150 --> 00:21:46,820
and then you do this at infinite like

00:21:44,720 --> 00:21:48,830
the the datum stable is just a simple

00:21:46,820 --> 00:21:50,720
it's an internal materialized to you

00:21:48,830 --> 00:21:53,720
it's one materialized to be you in the

00:21:50,720 --> 00:21:56,210
system but like the secure us lesson is

00:21:53,720 --> 00:21:58,550
the is that applications are usually

00:21:56,210 --> 00:22:01,370
well served by many many different views

00:21:58,550 --> 00:22:04,250
that define that like represent the data

00:22:01,370 --> 00:22:06,860
that the uise or whatever else would

00:22:04,250 --> 00:22:08,570
like to query in in your data store so

00:22:06,860 --> 00:22:11,030
you have a really normalized data store

00:22:08,570 --> 00:22:15,080
and you have the normalized views into

00:22:11,030 --> 00:22:17,750
that data store and so we have or will

00:22:15,080 --> 00:22:20,030
have anyway is a user-defined

00:22:17,750 --> 00:22:21,380
materialized views where you define like

00:22:20,030 --> 00:22:21,820
say you might like if you're in the

00:22:21,380 --> 00:22:23,530
browsing

00:22:21,820 --> 00:22:27,310
citation you might only care about the

00:22:23,530 --> 00:22:29,350
top 10 visited websites and your history

00:22:27,310 --> 00:22:30,790
might have tens of thousands of records

00:22:29,350 --> 00:22:32,860
but you only care about the 10 of them

00:22:30,790 --> 00:22:34,930
and you only want your view and when

00:22:32,860 --> 00:22:36,040
you're acquiring your view you like it

00:22:34,930 --> 00:22:39,070
will be really quick you'll just have

00:22:36,040 --> 00:22:41,860
ten records and many may maybe like 5 10

00:22:39,070 --> 00:22:44,320
columns or something so the Quarian will

00:22:41,860 --> 00:22:46,120
be really quick and internally mentat

00:22:44,320 --> 00:22:49,720
will use transaction listeners to

00:22:46,120 --> 00:22:52,960
monitor changes to the to its log and

00:22:49,720 --> 00:22:54,820
updates the views you've defined which

00:22:52,960 --> 00:22:56,860
is nice and like it's the same mechanism

00:22:54,820 --> 00:22:59,770
that it uses internally for its datums

00:22:56,860 --> 00:23:01,240
table for its atoms you and then you can

00:22:59,770 --> 00:23:03,520
define as many of those users you'd like

00:23:01,240 --> 00:23:06,820
as your application requires and there

00:23:03,520 --> 00:23:08,470
will be very domain specific for you and

00:23:06,820 --> 00:23:10,000
that's your kind of way to query data

00:23:08,470 --> 00:23:11,980
and but you're still when you're writing

00:23:10,000 --> 00:23:13,540
data you're not touching you your views

00:23:11,980 --> 00:23:19,300
obviously you're still writing into

00:23:13,540 --> 00:23:20,590
transaction log so right so like that's

00:23:19,300 --> 00:23:26,830
sort of like a peek into mental

00:23:20,590 --> 00:23:28,720
internals and it's the part it was

00:23:26,830 --> 00:23:31,090
really important that whatever we built

00:23:28,720 --> 00:23:33,550
will work in every environment we need

00:23:31,090 --> 00:23:35,580
and those environments involve many

00:23:33,550 --> 00:23:40,770
different mobile platforms

00:23:35,580 --> 00:23:45,010
well two mobile platforms one too many

00:23:40,770 --> 00:23:47,530
and as well as Firefox desktop itself

00:23:45,010 --> 00:23:51,040
and maybe other consumers in the future

00:23:47,530 --> 00:23:54,250
and so we have a public API which is

00:23:51,040 --> 00:23:57,360
wrapped in the FFI layer which lets you

00:23:54,250 --> 00:24:00,850
access it from from non Brust code and

00:23:57,360 --> 00:24:03,790
we built an iOS sdk in swift and an

00:24:00,850 --> 00:24:07,270
android sdk in java they're shallow is

00:24:03,790 --> 00:24:10,810
the case there the map pretty well -

00:24:07,270 --> 00:24:12,700
Mentats internals and and then

00:24:10,810 --> 00:24:14,590
essentially what you use this stuff

00:24:12,700 --> 00:24:16,720
without having to worry about FFI and

00:24:14,590 --> 00:24:19,060
many of those stuff just just as if

00:24:16,720 --> 00:24:22,330
you're riding like a nice native java

00:24:19,060 --> 00:24:24,580
application you can query and write data

00:24:22,330 --> 00:24:28,330
and you can define material s use things

00:24:24,580 --> 00:24:30,370
and you can you know invoke syncing and

00:24:28,330 --> 00:24:32,980
integrate with whatever is appropriate

00:24:30,370 --> 00:24:33,740
to your environment for scheduling stuff

00:24:32,980 --> 00:24:38,180
like this

00:24:33,740 --> 00:24:39,920
and soon we'll have SDKs and Kotlin cuz

00:24:38,180 --> 00:24:44,270
that's like the hot new thing apparently

00:24:39,920 --> 00:24:47,570
and annex become stuff for for well

00:24:44,270 --> 00:24:51,020
integration into Firefox proper because

00:24:47,570 --> 00:24:53,320
the plan is too well so right now we're

00:24:51,020 --> 00:24:56,480
still solving some of the hard problems

00:24:53,320 --> 00:24:58,220
so sinking is working progress we're

00:24:56,480 --> 00:25:01,220
still working like various merging

00:24:58,220 --> 00:25:04,790
algorithms we're working on forgetting

00:25:01,220 --> 00:25:07,820
data which is important from like post

00:25:04,790 --> 00:25:10,640
both privacy concerns like the right to

00:25:07,820 --> 00:25:12,980
forget and just the ability for people

00:25:10,640 --> 00:25:15,140
to erase history from their log that

00:25:12,980 --> 00:25:17,690
they don't like as well as just from

00:25:15,140 --> 00:25:19,310
engineering perspective like you have an

00:25:17,690 --> 00:25:21,170
infinite log and I really find that

00:25:19,310 --> 00:25:25,580
universe and it's just not gonna work

00:25:21,170 --> 00:25:27,410
forever and yeah we're still evolving

00:25:25,580 --> 00:25:29,300
our IP API a little bit as we're

00:25:27,410 --> 00:25:31,880
building our internal consumers that's

00:25:29,300 --> 00:25:33,950
shaping the API and writing the

00:25:31,880 --> 00:25:37,760
commutation and the next step is

00:25:33,950 --> 00:25:40,880
shipping this in Firefox log box which

00:25:37,760 --> 00:25:42,440
is a I standalone password manager that

00:25:40,880 --> 00:25:45,550
Mozilla's building that gives you access

00:25:42,440 --> 00:25:49,330
to all of your Firefox account passwords

00:25:45,550 --> 00:25:53,410
and so it will be backed by mentat and

00:25:49,330 --> 00:25:56,320
eventually syncing via meant as well and

00:25:53,410 --> 00:26:00,500
and in the future we have this

00:25:56,320 --> 00:26:02,930
internally process of building Android

00:26:00,500 --> 00:26:04,880
components that will help us build

00:26:02,930 --> 00:26:07,250
browsers better and we'll be wrapping

00:26:04,880 --> 00:26:10,640
mint out into an Android component so

00:26:07,250 --> 00:26:12,670
like it's more easily accessible for our

00:26:10,640 --> 00:26:14,510
internal teams and for anyone who's

00:26:12,670 --> 00:26:18,020
building something out books like a

00:26:14,510 --> 00:26:20,930
browser we'll be using it in new

00:26:18,020 --> 00:26:23,210
products that Mozilla is building to

00:26:20,930 --> 00:26:25,820
support storing new data and interacting

00:26:23,210 --> 00:26:27,830
with the existing sink ecosystem well

00:26:25,820 --> 00:26:29,480
build building new features inside the

00:26:27,830 --> 00:26:32,060
existing products which was historically

00:26:29,480 --> 00:26:33,650
quite difficult because involving data

00:26:32,060 --> 00:26:35,630
is really difficult in the existing

00:26:33,650 --> 00:26:40,100
system and will be much simpler in in

00:26:35,630 --> 00:26:42,980
this new world and eventually will start

00:26:40,100 --> 00:26:45,260
evolving the existing Firefox stores and

00:26:42,980 --> 00:26:45,950
building we have a vague transition plan

00:26:45,260 --> 00:26:47,809
and

00:26:45,950 --> 00:26:52,130
it's sort of coming to fruition with

00:26:47,809 --> 00:26:55,490
some of the efforts internally and the

00:26:52,130 --> 00:26:58,660
next is I guess you guys like perhaps

00:26:55,490 --> 00:27:01,640
other people have meant at shaped

00:26:58,660 --> 00:27:05,120
problems and would love to help you

00:27:01,640 --> 00:27:07,340
address them and get you involved in the

00:27:05,120 --> 00:27:09,050
development of this stuff so the links

00:27:07,340 --> 00:27:10,820
are it's everything is in standard

00:27:09,050 --> 00:27:13,270
places although the development happens

00:27:10,820 --> 00:27:16,010
to the github the commutation is there

00:27:13,270 --> 00:27:18,980
there's a wiki page has a bunch of model

00:27:16,010 --> 00:27:21,230
link examples and a lot of kind of a

00:27:18,980 --> 00:27:25,630
theory on syncing and data stores

00:27:21,230 --> 00:27:29,030
written down so please peruse that and

00:27:25,630 --> 00:27:32,570
yeah and then why finds myself or other

00:27:29,030 --> 00:27:35,780
people from the teams to ask additional

00:27:32,570 --> 00:27:39,490
questions okay thanks a lot

00:27:35,780 --> 00:27:42,589
[Applause]

00:27:39,490 --> 00:27:42,589
[Music]

00:27:43,470 --> 00:27:46,569
[Applause]

00:27:47,250 --> 00:27:54,940
[Music]

00:27:52,880 --> 00:27:54,940

YouTube URL: https://www.youtube.com/watch?v=bqG5OfGXI_E


