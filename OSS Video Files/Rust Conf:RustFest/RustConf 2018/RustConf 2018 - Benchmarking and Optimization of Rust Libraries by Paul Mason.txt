Title: RustConf 2018 - Benchmarking and Optimization of Rust Libraries by Paul Mason
Publication date: 2018-09-06
Playlist: RustConf 2018
Description: 
	RustConf 2018 - Benchmarking and Optimization of Rust Libraries by Paul Mason

As we develop the Rust eco-system we have a goal that "Rust should provide easy access to high quality crates". This means libraries must be both ergonomic and perform well. Rust provides various frameworks to help benchmark libraries however achieving performance past a certain point requires knowledge of some deep language constructs.

This talk explores a journey towards benchmarking various library functions consistently and fairly and consequently exploring strategies for optimizing performance.
Captions: 
	00:00:00,410 --> 00:00:17,520
[Music]

00:00:14,510 --> 00:00:22,170
hello can you run here me okay

00:00:17,520 --> 00:00:23,550
yep Co and so yeah as I mentioned I'm

00:00:22,170 --> 00:00:26,279
Paul talking about benchmarking and

00:00:23,550 --> 00:00:28,110
optimization of rust libraries and just

00:00:26,279 --> 00:00:31,050
as a little bit of intro about Who I am

00:00:28,110 --> 00:00:33,870
so I'm currently principal engineer at

00:00:31,050 --> 00:00:36,480
human interest human interest is a 401k

00:00:33,870 --> 00:00:38,250
processing company and in San Francisco

00:00:36,480 --> 00:00:43,860
you might be able to tell I'm not from

00:00:38,250 --> 00:00:45,510
there so I've got an accent and I be

00:00:43,860 --> 00:00:47,550
working on rest for a number of years

00:00:45,510 --> 00:00:50,640
and as a result home had to create a

00:00:47,550 --> 00:00:52,110
number of libraries and one such library

00:00:50,640 --> 00:00:54,000
that I'll be talking about in a lot of

00:00:52,110 --> 00:00:56,280
these examples as a rusty small library

00:00:54,000 --> 00:01:00,239
which is a fixed precision decimal

00:00:56,280 --> 00:01:02,760
number library written in rust so being

00:01:00,239 --> 00:01:04,409
told like my accents had to understand

00:01:02,760 --> 00:01:06,120
so I thought I would start off by giving

00:01:04,409 --> 00:01:09,900
a little bit of a 101 on the New Zealand

00:01:06,120 --> 00:01:13,320
accent so and essentially if you take

00:01:09,900 --> 00:01:14,909
the valves you take up the oh and then

00:01:13,320 --> 00:01:19,620
you move the sounds of the vowels over

00:01:14,909 --> 00:01:22,200
one that's the New Zealand accent so if

00:01:19,620 --> 00:01:26,040
I say the word pan you might hear this

00:01:22,200 --> 00:01:30,030
and I say pin you may be hearing that

00:01:26,040 --> 00:01:32,310
and likewise if I say pen sometimes you

00:01:30,030 --> 00:01:33,990
might be hearing there so if you're

00:01:32,310 --> 00:01:35,760
hearing the word and yellow then you're

00:01:33,990 --> 00:01:37,350
going to be good but if you're hearing

00:01:35,760 --> 00:01:39,660
the word on the right you may need to

00:01:37,350 --> 00:01:44,160
reverse engineer what I'm saying some

00:01:39,660 --> 00:01:47,010
other times and so on to the talk and so

00:01:44,160 --> 00:01:48,960
the rest ecosystem is growing and when I

00:01:47,010 --> 00:01:51,900
first put together these slides it was

00:01:48,960 --> 00:01:53,780
just under 17,000 this morning it was

00:01:51,900 --> 00:01:56,010
around seventeen thousand seven hundred

00:01:53,780 --> 00:02:00,330
it's very soon it's going to be eighteen

00:01:56,010 --> 00:02:02,670
thousand eighteen thousand crates and so

00:02:00,330 --> 00:02:04,820
with all those crates we we're starting

00:02:02,670 --> 00:02:07,470
to use them in our in our projects and

00:02:04,820 --> 00:02:09,330
we're implicitly relying on them and

00:02:07,470 --> 00:02:11,970
live downstream dependencies to really

00:02:09,330 --> 00:02:15,810
do the job correctly and securely as

00:02:11,970 --> 00:02:17,610
well as quickly and so as a as a case

00:02:15,810 --> 00:02:19,170
point really is if you're using a

00:02:17,610 --> 00:02:20,489
decimal number library you don't want

00:02:19,170 --> 00:02:23,219
that to be the the performance

00:02:20,489 --> 00:02:24,569
bottleneck of your system and you also

00:02:23,219 --> 00:02:26,400
don't want it to be the source of bugs

00:02:24,569 --> 00:02:30,250
as well

00:02:26,400 --> 00:02:31,810
and so to really be able to understand

00:02:30,250 --> 00:02:33,430
the performance of a system the first

00:02:31,810 --> 00:02:34,240
thing we really need to do is be able to

00:02:33,430 --> 00:02:37,180
measure it

00:02:34,240 --> 00:02:39,480
and really that the idea of this is so

00:02:37,180 --> 00:02:42,220
that you can understand whether you're

00:02:39,480 --> 00:02:46,860
making positive or negative impacts to

00:02:42,220 --> 00:02:49,720
your to your library and so just to

00:02:46,860 --> 00:02:50,980
really intro into this is that there's a

00:02:49,720 --> 00:02:53,170
couple of terminologies that you've

00:02:50,980 --> 00:02:55,810
probably heard around there micro/macro

00:02:53,170 --> 00:02:57,100
benchmarking so micro benchmarking is

00:02:55,810 --> 00:02:59,470
where you're measuring a very small unit

00:02:57,100 --> 00:03:01,150
of performance and macro benchmarking is

00:02:59,470 --> 00:03:04,840
where you're trying to simulate customer

00:03:01,150 --> 00:03:06,220
application workloads and so when we're

00:03:04,840 --> 00:03:08,769
looking at some of these libraries we

00:03:06,220 --> 00:03:11,050
may need to be considering both and

00:03:08,769 --> 00:03:15,040
we'll go into some of those some of that

00:03:11,050 --> 00:03:17,200
detail throughout this talk and so so

00:03:15,040 --> 00:03:18,700
just to begin with in order to benchmark

00:03:17,200 --> 00:03:21,250
we need to know some of the tools that

00:03:18,700 --> 00:03:23,019
are out there so and cargo bench is the

00:03:21,250 --> 00:03:24,700
most obvious one to start up start off

00:03:23,019 --> 00:03:27,790
with and the reason why is because it's

00:03:24,700 --> 00:03:30,220
included with cargo it leverages the

00:03:27,790 --> 00:03:33,010
test crate test crates internals and

00:03:30,220 --> 00:03:36,250
stable at the moment which means that it

00:03:33,010 --> 00:03:37,930
can only be run on lightly only but

00:03:36,250 --> 00:03:40,090
getting it up and running is relatively

00:03:37,930 --> 00:03:43,269
straightforward so essentially we need

00:03:40,090 --> 00:03:47,500
to include the the test feature and from

00:03:43,269 --> 00:03:49,989
there it exposes the bench attribute the

00:03:47,500 --> 00:03:53,079
bench attribute in the case what

00:03:49,989 --> 00:03:56,260
function should be called under and when

00:03:53,079 --> 00:03:59,230
the bench mark runs and within each of

00:03:56,260 --> 00:04:02,140
those functions you'll see that this and

00:03:59,230 --> 00:04:05,350
no function so everything inside there

00:04:02,140 --> 00:04:07,360
is what's being benchmarked and in this

00:04:05,350 --> 00:04:09,310
first example you'll see that the the

00:04:07,360 --> 00:04:12,310
sub functions being at impact in this

00:04:09,310 --> 00:04:13,750
particular example here and the results

00:04:12,310 --> 00:04:16,030
being passed through to the black box

00:04:13,750 --> 00:04:18,519
and function just immediately afterwards

00:04:16,030 --> 00:04:20,890
and the reason that's happening is

00:04:18,519 --> 00:04:22,270
because we need to make sure that the

00:04:20,890 --> 00:04:24,250
compilers not doing any sort of

00:04:22,270 --> 00:04:26,260
optimizations that means that we're not

00:04:24,250 --> 00:04:29,950
actually testing what we think we're

00:04:26,260 --> 00:04:32,710
testing within that edit function so

00:04:29,950 --> 00:04:33,820
running these results is pretty

00:04:32,710 --> 00:04:36,550
straightforward

00:04:33,820 --> 00:04:38,500
it's a tabular format there we've got

00:04:36,550 --> 00:04:38,980
the names of the tests on the left and

00:04:38,500 --> 00:04:40,180
we

00:04:38,980 --> 00:04:44,380
got the number of nanoseconds per

00:04:40,180 --> 00:04:45,940
iteration on the right and on the far

00:04:44,380 --> 00:04:48,760
right there you'll also see the variance

00:04:45,940 --> 00:04:51,190
between the top and the bottom tests and

00:04:48,760 --> 00:04:52,600
so over time you'll probably want to be

00:04:51,190 --> 00:04:55,360
able to compare these two make sure you

00:04:52,600 --> 00:04:58,000
are either doing things if things are

00:04:55,360 --> 00:04:59,740
improving or regressing and so this

00:04:58,000 --> 00:05:01,450
various ways of doing this and you could

00:04:59,740 --> 00:05:03,520
be using spreadsheets you could be using

00:05:01,450 --> 00:05:05,170
all sorts of archiving strategies but

00:05:03,520 --> 00:05:08,590
one tool that makes things a little bit

00:05:05,170 --> 00:05:10,750
easier as cargo bench comp and that's a

00:05:08,590 --> 00:05:13,690
cargo plugin which essentially if you

00:05:10,750 --> 00:05:15,190
pipe your beach results out to file you

00:05:13,690 --> 00:05:18,520
can pass those files through the bench

00:05:15,190 --> 00:05:20,860
comp and it will spit out a tabular form

00:05:18,520 --> 00:05:22,960
like so so the first thing you probably

00:05:20,860 --> 00:05:25,570
notice in this in this particular table

00:05:22,960 --> 00:05:27,130
is the red and the green the red in the

00:05:25,570 --> 00:05:29,680
case it's something bad happened a

00:05:27,130 --> 00:05:32,580
regression and the green indicates that

00:05:29,680 --> 00:05:35,080
something good happened so either this

00:05:32,580 --> 00:05:39,550
the same performance or an improvement

00:05:35,080 --> 00:05:41,950
in performance and so cargo is pretty

00:05:39,550 --> 00:05:43,510
its sorry carrier bench is included with

00:05:41,950 --> 00:05:46,240
cargo so it's pretty low effort to get

00:05:43,510 --> 00:05:48,580
set up it's very fast to compile and

00:05:46,240 --> 00:05:49,090
execute and you don't need any external

00:05:48,580 --> 00:05:54,100
crates

00:05:49,090 --> 00:05:55,600
within your cargo tamil file and you

00:05:54,100 --> 00:05:58,210
know with a good archiving strategy you

00:05:55,600 --> 00:06:01,660
could also compare results over from

00:05:58,210 --> 00:06:03,910
version 3 division 1 if you wish to and

00:06:01,660 --> 00:06:06,280
that the major downside though is that

00:06:03,910 --> 00:06:08,920
it's nightly only and performed the

00:06:06,280 --> 00:06:10,180
reason for that is that performance may

00:06:08,920 --> 00:06:12,610
be different and stable you may be

00:06:10,180 --> 00:06:16,150
testing against experimental compiler

00:06:12,610 --> 00:06:17,320
features or whatever else which means

00:06:16,150 --> 00:06:18,750
your results may be a little bit

00:06:17,320 --> 00:06:20,920
different

00:06:18,750 --> 00:06:24,610
cargo bench comp can be a little bit

00:06:20,920 --> 00:06:26,290
sensitive to thresholds so in that

00:06:24,610 --> 00:06:27,820
particular in the previous example there

00:06:26,290 --> 00:06:29,500
was green and red I was actually running

00:06:27,820 --> 00:06:33,300
that against the same code without

00:06:29,500 --> 00:06:35,830
making any changes and so essentially

00:06:33,300 --> 00:06:36,910
you can control the threshold but you've

00:06:35,830 --> 00:06:39,760
just got to be making sure you're

00:06:36,910 --> 00:06:41,530
comparing like for like tests so some of

00:06:39,760 --> 00:06:43,110
those tests were taking 2 nanoseconds if

00:06:41,530 --> 00:06:48,160
it goes to the 3 nanoseconds that's a

00:06:43,110 --> 00:06:49,780
50% increase and the other thing of of

00:06:48,160 --> 00:06:52,390
cargo bench is looping through sets of

00:06:49,780 --> 00:06:55,720
values can be a little bit tedious

00:06:52,390 --> 00:06:56,860
and so with a decimal number library you

00:06:55,720 --> 00:06:59,710
want to be able to test a range of

00:06:56,860 --> 00:07:02,260
values 7 divided by 3 is not the same as

00:06:59,710 --> 00:07:04,570
6 divided by 3 a very different

00:07:02,260 --> 00:07:07,090
calculation that actually happens under

00:07:04,570 --> 00:07:08,410
the scenes and you can do the sort of

00:07:07,090 --> 00:07:11,470
cargo bench it's just a matter of

00:07:08,410 --> 00:07:15,810
leveraging macros to be able to do all

00:07:11,470 --> 00:07:18,160
the the boilerplate code for you a

00:07:15,810 --> 00:07:21,850
second library which is out there which

00:07:18,160 --> 00:07:23,920
is also a viable to use as criterion

00:07:21,850 --> 00:07:26,710
arias and that's inspired by Haskell's

00:07:23,920 --> 00:07:28,960
criterion library and it's been written

00:07:26,710 --> 00:07:30,700
so that it runs on stable by default

00:07:28,960 --> 00:07:34,270
which means it also runs on beta and

00:07:30,700 --> 00:07:37,960
nightly and getting that up and running

00:07:34,270 --> 00:07:39,160
as is pretty straightforward as well

00:07:37,960 --> 00:07:41,980
that's a matter of including the

00:07:39,160 --> 00:07:43,630
criterion crate and then overriding the

00:07:41,980 --> 00:07:45,760
bench commands so that instead of

00:07:43,630 --> 00:07:49,080
invoking the default bench and harness

00:07:45,760 --> 00:07:52,720
and invokes the criterion bench Alice

00:07:49,080 --> 00:07:54,220
and so within the code relatively

00:07:52,720 --> 00:07:56,440
straightforward we've got the criterion

00:07:54,220 --> 00:07:59,140
main function which essentially is what

00:07:56,440 --> 00:08:02,080
is getting invoked by the harness as the

00:07:59,140 --> 00:08:04,000
criterion harness and instead of having

00:08:02,080 --> 00:08:06,310
the bench attribute we had criterion

00:08:04,000 --> 00:08:08,170
group so we had the bench attribute on

00:08:06,310 --> 00:08:11,160
each of the functions and still you list

00:08:08,170 --> 00:08:13,870
them in their criterion group macro and

00:08:11,160 --> 00:08:15,910
the actual met the actual function that

00:08:13,870 --> 00:08:17,650
gets called is relatively similar looks

00:08:15,910 --> 00:08:20,020
similar in the fact it's got an editor

00:08:17,650 --> 00:08:23,020
function as well as I'm passing the

00:08:20,020 --> 00:08:24,310
result to a black box and however the

00:08:23,020 --> 00:08:26,430
big difference there is it's wrapped

00:08:24,310 --> 00:08:30,640
around with a beach function and

00:08:26,430 --> 00:08:32,770
function and so what that is therefore

00:08:30,640 --> 00:08:34,960
is to name all the beaches so because

00:08:32,770 --> 00:08:36,610
you not able to leverage the attribute

00:08:34,960 --> 00:08:38,440
the beach attribute you've got to be

00:08:36,610 --> 00:08:41,680
able to name them via a string for it to

00:08:38,440 --> 00:08:43,180
work unstable one of the actual

00:08:41,680 --> 00:08:45,190
side-effects of this as well as they do

00:08:43,180 --> 00:08:47,190
have Beach function over inputs so you

00:08:45,190 --> 00:08:51,460
can actually pass multiple inputs to a

00:08:47,190 --> 00:08:54,070
benchmarking function also that the

00:08:51,460 --> 00:08:55,660
results serve verbose and so as you can

00:08:54,070 --> 00:08:58,900
see it's not a tabular format anymore

00:08:55,660 --> 00:09:00,310
but within each of those benchmarks it

00:08:58,900 --> 00:09:02,620
does give you a lot more information

00:09:00,310 --> 00:09:05,770
it's giving you their and the time the

00:09:02,620 --> 00:09:06,269
percentage change outliers statistical

00:09:05,770 --> 00:09:10,089
signal

00:09:06,269 --> 00:09:12,130
whether it regressed or not etc etc and

00:09:10,089 --> 00:09:14,589
so there's a lot more information there

00:09:12,130 --> 00:09:18,759
and in addition it spits out these

00:09:14,589 --> 00:09:20,740
graphs and I actually haven't used these

00:09:18,759 --> 00:09:22,240
graphs much and practice however I can

00:09:20,740 --> 00:09:24,250
imagine this would be a great thing to

00:09:22,240 --> 00:09:29,319
show your boss show that you're actually

00:09:24,250 --> 00:09:30,850
making an improvement there so criterion

00:09:29,319 --> 00:09:32,500
is relatively easy to set up and what I

00:09:30,850 --> 00:09:34,949
mean by that it's an easy migration from

00:09:32,500 --> 00:09:38,800
cargo bench the code was fairly similar

00:09:34,949 --> 00:09:40,959
and you know it has some way offs and

00:09:38,800 --> 00:09:43,209
which turn out to be kind of nice in

00:09:40,959 --> 00:09:44,800
some ways so bench function over inputs

00:09:43,209 --> 00:09:47,980
means you can pass multiple inputs to a

00:09:44,800 --> 00:09:49,480
a single benchmarking function and it

00:09:47,980 --> 00:09:52,630
does provide statistics out of the box

00:09:49,480 --> 00:09:56,290
which means you don't need a second plug

00:09:52,630 --> 00:09:58,149
in or whatever to manage there the major

00:09:56,290 --> 00:10:00,519
downside is it's that it's quite a bit

00:09:58,149 --> 00:10:03,940
slower than bench and it takes quite a

00:10:00,519 --> 00:10:06,670
while to - I guess warm up the tests and

00:10:03,940 --> 00:10:08,680
then run them and I guess it really

00:10:06,670 --> 00:10:10,089
depends on what you use cases but if

00:10:08,680 --> 00:10:12,370
you're wanting to run things quickly or

00:10:10,089 --> 00:10:15,160
do minor small changes then this can be

00:10:12,370 --> 00:10:19,029
a a little bit of a bottleneck for you

00:10:15,160 --> 00:10:21,069
and it does suffer some of the threshold

00:10:19,029 --> 00:10:24,100
issues between iterations and there is a

00:10:21,069 --> 00:10:26,139
check going on about that and one of the

00:10:24,100 --> 00:10:29,199
the forum's about introducing the

00:10:26,139 --> 00:10:31,300
ability to control threshold and but at

00:10:29,199 --> 00:10:33,550
the the previous example again showed

00:10:31,300 --> 00:10:37,209
regressions and nothing had changed in

00:10:33,550 --> 00:10:38,680
the code and the last thing which is

00:10:37,209 --> 00:10:40,029
more of just like it got sure is because

00:10:38,680 --> 00:10:41,529
you're naming your own benchmarking

00:10:40,029 --> 00:10:43,839
functions you've just got to be careful

00:10:41,529 --> 00:10:45,610
to not name them the same thing if you

00:10:43,839 --> 00:10:47,800
do then you get these weird subtle

00:10:45,610 --> 00:10:49,180
comparison errors and that can just

00:10:47,800 --> 00:10:53,230
really throw you off if you haven't

00:10:49,180 --> 00:10:54,550
realized what you've done so so before

00:10:53,230 --> 00:10:56,199
jumping into some of the practical

00:10:54,550 --> 00:10:57,250
things of performance and the other

00:10:56,199 --> 00:10:59,079
thing I just want to mention is just

00:10:57,250 --> 00:11:03,550
really understanding your application

00:10:59,079 --> 00:11:05,259
before running it under bench so you can

00:11:03,550 --> 00:11:07,060
use intrument ation to help understand

00:11:05,259 --> 00:11:08,500
this and the reason you might want to do

00:11:07,060 --> 00:11:11,790
this is to really understand what the

00:11:08,500 --> 00:11:15,519
internals of the application are doing

00:11:11,790 --> 00:11:16,930
before you I understand what the

00:11:15,519 --> 00:11:18,850
internals are doing so that you can

00:11:16,930 --> 00:11:19,760
really make sure that what you're

00:11:18,850 --> 00:11:22,760
testing

00:11:19,760 --> 00:11:27,590
against as what's expected from a normal

00:11:22,760 --> 00:11:29,000
application Ram and thus various tools

00:11:27,590 --> 00:11:31,640
to be able to do this but the whole idea

00:11:29,000 --> 00:11:33,260
here is that you understand what a both

00:11:31,640 --> 00:11:37,630
expensive calls but also high-end

00:11:33,260 --> 00:11:40,760
vacation calls so in an example for a

00:11:37,630 --> 00:11:42,860
decimal library for division for bigger

00:11:40,760 --> 00:11:44,840
numbers you might be calling a

00:11:42,860 --> 00:11:47,420
subtraction function maybe a thousand

00:11:44,840 --> 00:11:49,820
times internally which isn't exposed by

00:11:47,420 --> 00:11:51,590
the public API and so it's important

00:11:49,820 --> 00:11:56,270
that that particular function is tested

00:11:51,590 --> 00:11:57,650
under those sorts of loads so we'll go

00:11:56,270 --> 00:11:58,730
into some of the practical things and

00:11:57,650 --> 00:12:00,800
this one's going to see them a little

00:11:58,730 --> 00:12:03,200
bit of a cop-out because it's going back

00:12:00,800 --> 00:12:04,760
to the fundamentals but essentially some

00:12:03,200 --> 00:12:06,410
of the biggest ones you can get is

00:12:04,760 --> 00:12:09,170
really from re looking at your approach

00:12:06,410 --> 00:12:10,850
and these things such as early exit

00:12:09,170 --> 00:12:13,910
conditions these operational

00:12:10,850 --> 00:12:17,660
efficiencies using bitwise shift and C

00:12:13,910 --> 00:12:20,120
of dividing by a power of two these

00:12:17,660 --> 00:12:22,760
parallel operations you've got dynamic

00:12:20,120 --> 00:12:24,260
programming use of efficient types will

00:12:22,760 --> 00:12:26,240
jump into use of efficient types a

00:12:24,260 --> 00:12:29,000
little bit more in this talk and just go

00:12:26,240 --> 00:12:30,500
into that a little bit more but just

00:12:29,000 --> 00:12:33,580
there's a bit of an example we'll just

00:12:30,500 --> 00:12:36,950
talk about an Postgres write performance

00:12:33,580 --> 00:12:40,640
and so Postgres has a numeric data type

00:12:36,950 --> 00:12:42,890
and you're probably all aware of and to

00:12:40,640 --> 00:12:44,630
write out to the Postgres protocol you

00:12:42,890 --> 00:12:47,690
need to essentially break a number into

00:12:44,630 --> 00:12:48,890
groups of 10,000 and then write out the

00:12:47,690 --> 00:12:50,630
number of groups that you've broken into

00:12:48,890 --> 00:12:53,480
followed by the weight of the integer

00:12:50,630 --> 00:12:57,710
portion science scale and then followed

00:12:53,480 --> 00:13:01,280
by the groups of 10,000 so if we were to

00:12:57,710 --> 00:13:03,020
write out the number 3.14 then

00:13:01,280 --> 00:13:05,630
essentially we need to break it into

00:13:03,020 --> 00:13:07,100
groups and so we group back him to the

00:13:05,630 --> 00:13:10,370
integer portion and the decimal portion

00:13:07,100 --> 00:13:12,610
and the integer portion we actually pad

00:13:10,370 --> 00:13:17,000
to the left with zeros to make it into a

00:13:12,610 --> 00:13:19,720
10,000 group and on the decimal portion

00:13:17,000 --> 00:13:24,890
we pad to the right to make it into a

00:13:19,720 --> 00:13:26,600
10000 group and so when we're writing it

00:13:24,890 --> 00:13:29,600
out we write out two groups in this case

00:13:26,600 --> 00:13:31,030
and the first ones integer portions of

00:13:29,600 --> 00:13:33,490
the weight 0

00:13:31,030 --> 00:13:35,200
and the scale in this case is two

00:13:33,490 --> 00:13:38,070
because there's only two decimal points

00:13:35,200 --> 00:13:41,470
that are relevant and the the 1400 group

00:13:38,070 --> 00:13:43,330
and so so that was you know relatively

00:13:41,470 --> 00:13:46,780
easy easy to explain from a base-10

00:13:43,330 --> 00:13:48,640
perspective you know if we had it in a

00:13:46,780 --> 00:13:50,710
string for example it might be quite

00:13:48,640 --> 00:13:52,510
easy to reason about how we might be

00:13:50,710 --> 00:13:55,090
able to implement this we essentially

00:13:52,510 --> 00:13:58,180
chunk it into groups of four and paired

00:13:55,090 --> 00:14:00,070
the zeroes and output the results so if

00:13:58,180 --> 00:14:02,770
we were to do that and rust we might do

00:14:00,070 --> 00:14:04,780
something like so where we convert it to

00:14:02,770 --> 00:14:07,120
a string we find out where to split the

00:14:04,780 --> 00:14:10,450
number and so that we've got an integer

00:14:07,120 --> 00:14:12,160
portion and fractional portion and we

00:14:10,450 --> 00:14:15,280
can then go through and chunk it by

00:14:12,160 --> 00:14:17,110
fours heading to lift for the integer

00:14:15,280 --> 00:14:19,980
portion and padding to the right for the

00:14:17,110 --> 00:14:23,620
decimal portion and then writing it out

00:14:19,980 --> 00:14:28,000
to the protocol with the the big endian

00:14:23,620 --> 00:14:30,730
format down the bottom and so if we were

00:14:28,000 --> 00:14:32,290
to do it this way then say we had 15

00:14:30,730 --> 00:14:35,080
samples that we're testing with it

00:14:32,290 --> 00:14:37,900
roughly takes around 15,000 nanoseconds

00:14:35,080 --> 00:14:40,000
per iteration so around about thousand

00:14:37,900 --> 00:14:43,030
seconds thousand nanoseconds per

00:14:40,000 --> 00:14:44,620
iteration for this particular example

00:14:43,030 --> 00:14:46,120
and of course I wouldn't be talking

00:14:44,620 --> 00:14:50,290
about this if you couldn't do it better

00:14:46,120 --> 00:14:52,510
so what have you didn't have to convert

00:14:50,290 --> 00:14:54,370
it to string well you don't and if you

00:14:52,510 --> 00:14:56,320
take a step back and think about the

00:14:54,370 --> 00:14:59,740
pure math approach about how to do this

00:14:56,320 --> 00:15:01,360
then you may think about how to scale up

00:14:59,740 --> 00:15:04,750
the number to the closest team thousand

00:15:01,360 --> 00:15:06,820
group keep dividing it by 10,000 while

00:15:04,750 --> 00:15:08,530
storing the remainder and keep going

00:15:06,820 --> 00:15:12,460
until you reach 0 and you've got your

00:15:08,530 --> 00:15:15,180
groups so we took the the 3.1 for

00:15:12,460 --> 00:15:18,760
example again and we scale it up to

00:15:15,180 --> 00:15:20,710
10,000 boundary which is 31,400 we

00:15:18,760 --> 00:15:23,920
divide it by 10,000 we get 3 with a

00:15:20,710 --> 00:15:26,500
remainder of 1400 and we divide 3 by

00:15:23,920 --> 00:15:28,420
10,000 with a remainder of 3 we've got

00:15:26,500 --> 00:15:30,280
our groups on the right there and that's

00:15:28,420 --> 00:15:34,510
without having to convert it to string

00:15:30,280 --> 00:15:36,820
first so implementing this and rust and

00:15:34,510 --> 00:15:39,160
we could do the following where we

00:15:36,820 --> 00:15:41,020
essentially figure out what we should be

00:15:39,160 --> 00:15:44,080
scaling and up to so the closest team

00:15:41,020 --> 00:15:44,740
thousand boundary I'm also using a

00:15:44,080 --> 00:15:47,220
couple of

00:15:44,740 --> 00:15:49,920
operational efficiencies here which is

00:15:47,220 --> 00:15:52,779
instead of using the modulus and divider

00:15:49,920 --> 00:15:53,500
functions or the rain durham divider

00:15:52,779 --> 00:15:55,510
functions

00:15:53,500 --> 00:15:58,510
Steve just taking the last two bits of

00:15:55,510 --> 00:16:03,240
the number and likewise also bitwise

00:15:58,510 --> 00:16:05,860
shifting over to Steve dividing it by 4

00:16:03,240 --> 00:16:08,560
so we've scaled up the number we then

00:16:05,860 --> 00:16:10,779
divide the number by team thousands

00:16:08,560 --> 00:16:15,160
during the group into array and finally

00:16:10,779 --> 00:16:16,839
we write it out to two Postgres so the

00:16:15,160 --> 00:16:19,060
performance of that is quite a bit

00:16:16,839 --> 00:16:22,690
faster it's 5,000 NS seconds versus

00:16:19,060 --> 00:16:25,180
15,000 nanoseconds and so we're getting

00:16:22,690 --> 00:16:27,310
a you know three times increased just

00:16:25,180 --> 00:16:29,230
from really looking at our approach the

00:16:27,310 --> 00:16:31,390
first one was easy to reason about but

00:16:29,230 --> 00:16:34,089
the second one of you take a math

00:16:31,390 --> 00:16:37,649
approach to it then you can get some

00:16:34,089 --> 00:16:40,690
clear clear winds just from doing that

00:16:37,649 --> 00:16:44,459
so the next one I want to talk about is

00:16:40,690 --> 00:16:47,680
the exercise slices performing better so

00:16:44,459 --> 00:16:50,380
if we have two identical functions like

00:16:47,680 --> 00:16:52,720
so where one of them takes exercise

00:16:50,380 --> 00:16:55,420
slice of three and the second one

00:16:52,720 --> 00:16:57,730
doesn't then the hypothesis is the first

00:16:55,420 --> 00:16:58,870
one runs faster and you're probably

00:16:57,730 --> 00:17:01,360
looking at this and thinking well

00:16:58,870 --> 00:17:02,890
obviously it runs faster pool there the

00:17:01,360 --> 00:17:06,370
second one does all these bounds cheeks

00:17:02,890 --> 00:17:09,280
which the first one doesn't do and you'd

00:17:06,370 --> 00:17:11,110
be right in this particular case so the

00:17:09,280 --> 00:17:13,510
the first one well that one of them

00:17:11,110 --> 00:17:15,730
takes two nanoseconds pin iteration

00:17:13,510 --> 00:17:19,030
where the the one where bounce cheeks

00:17:15,730 --> 00:17:22,600
takes three nanoseconds and within a

00:17:19,030 --> 00:17:25,059
loop we get 20 100 nanoseconds in 3700

00:17:22,600 --> 00:17:27,939
nanoseconds so it starts to broaden a

00:17:25,059 --> 00:17:28,960
little bit there but what if we didn't

00:17:27,939 --> 00:17:30,850
have those bounce cheeks

00:17:28,960 --> 00:17:33,250
what have we had this particular code

00:17:30,850 --> 00:17:34,840
here which is of course a little bit

00:17:33,250 --> 00:17:37,870
dangerous to have in your production and

00:17:34,840 --> 00:17:42,429
base but nonetheless how does it perform

00:17:37,870 --> 00:17:45,010
compared to a fixed sized slice well in

00:17:42,429 --> 00:17:47,559
a single iteration sense it's closest to

00:17:45,010 --> 00:17:49,150
nanoseconds per iteration but as we get

00:17:47,559 --> 00:17:51,790
into a loop we start to see a little bit

00:17:49,150 --> 00:17:54,790
of a little bit of difference there so

00:17:51,790 --> 00:17:57,170
we have 20 100 nanoseconds again versus

00:17:54,790 --> 00:17:59,570
27 hundred nanoseconds

00:17:57,170 --> 00:18:01,580
so what this is saying to us is that by

00:17:59,570 --> 00:18:04,400
giving the fixed size slice the compiler

00:18:01,580 --> 00:18:08,990
is able to make various assumptions or

00:18:04,400 --> 00:18:10,940
various I guess heuristics to be able to

00:18:08,990 --> 00:18:13,040
understand that they can it can make

00:18:10,940 --> 00:18:14,840
further optimizations that it's unable

00:18:13,040 --> 00:18:19,880
to do without having that fixed sized

00:18:14,840 --> 00:18:22,700
slice so fixed sized slices are indeed

00:18:19,880 --> 00:18:25,220
faster um

00:18:22,700 --> 00:18:28,640
so following on from their inlining can

00:18:25,220 --> 00:18:31,130
both improve and hinder and so with that

00:18:28,640 --> 00:18:33,680
previous example there say we just throw

00:18:31,130 --> 00:18:37,580
inline always on to the top what's going

00:18:33,680 --> 00:18:39,380
to happen well you said that things are

00:18:37,580 --> 00:18:41,990
going to improve substantially then

00:18:39,380 --> 00:18:44,120
you'll be right but interesting to note

00:18:41,990 --> 00:18:47,000
is that both of them behave exactly the

00:18:44,120 --> 00:18:48,620
same way now so within lighting both of

00:18:47,000 --> 00:18:50,240
them take 1,300 nanoseconds per

00:18:48,620 --> 00:18:52,850
iteration for the multiple iterations

00:18:50,240 --> 00:18:56,570
and one nanosecond

00:18:52,850 --> 00:18:58,460
for this the singular version so what

00:18:56,570 --> 00:19:01,790
that's really telling us is that the

00:18:58,460 --> 00:19:03,920
compiler is able to make various I guess

00:19:01,790 --> 00:19:06,380
conclusions by having the the code in

00:19:03,920 --> 00:19:08,000
line so it's able to optimize the the

00:19:06,380 --> 00:19:11,150
compiled code so that it even you know

00:19:08,000 --> 00:19:12,710
everything runs faster and inlining for

00:19:11,150 --> 00:19:15,410
the second example of the bounce cheeks

00:19:12,710 --> 00:19:17,120
well it knows that the size of the array

00:19:15,410 --> 00:19:18,530
that I'm passing through is 3 so it can

00:19:17,120 --> 00:19:23,600
basically remove all those bounce checks

00:19:18,530 --> 00:19:25,280
and make things faster as well and so so

00:19:23,600 --> 00:19:28,940
within lining that the common thing is

00:19:25,280 --> 00:19:30,770
is well that I often hear is I use

00:19:28,940 --> 00:19:34,160
matter than the compiler and to know

00:19:30,770 --> 00:19:35,690
when to in line and essentially I think

00:19:34,160 --> 00:19:37,400
if you're measuring things and you

00:19:35,690 --> 00:19:39,740
understand the impact of what you're

00:19:37,400 --> 00:19:44,690
doing then sometimes I say yes you can

00:19:39,740 --> 00:19:46,430
be smarter than the compiler and so with

00:19:44,690 --> 00:19:48,650
a library though I think the main thing

00:19:46,430 --> 00:19:50,870
to call out there is that just to be

00:19:48,650 --> 00:19:52,220
worried about the impact you're going to

00:19:50,870 --> 00:19:57,560
be having on your downstream components

00:19:52,220 --> 00:19:59,510
so although consuming applications so it

00:19:57,560 --> 00:20:01,130
will increase the binary size and

00:19:59,510 --> 00:20:03,980
sometimes you won't get the benefits you

00:20:01,130 --> 00:20:07,880
want now with with the increased binary

00:20:03,980 --> 00:20:10,780
size so my general rule was to be very

00:20:07,880 --> 00:20:13,220
wary of inlining public API functions

00:20:10,780 --> 00:20:17,710
going nuts with your internal stuff if

00:20:13,220 --> 00:20:20,840
you if you know what what the impact is

00:20:17,710 --> 00:20:23,630
so the fourth one is primitive types

00:20:20,840 --> 00:20:24,950
almost always better and so the first

00:20:23,630 --> 00:20:28,010
ones a little bit of a contrived example

00:20:24,950 --> 00:20:29,780
but bear with me and so every was

00:20:28,010 --> 00:20:31,940
representing a decimal number I might

00:20:29,780 --> 00:20:35,000
represent it as teamed about ten divided

00:20:31,940 --> 00:20:37,370
by ten to the power of E and so if I

00:20:35,000 --> 00:20:39,110
wanted to represent pi and two more

00:20:37,370 --> 00:20:41,179
precision then essentially I have a

00:20:39,110 --> 00:20:46,640
bigger integer portion and a bigger

00:20:41,179 --> 00:20:48,710
scale to help represent that and an

00:20:46,640 --> 00:20:51,230
obvious way of representing and this

00:20:48,710 --> 00:20:53,030
particular numbers with a big ant I mean

00:20:51,230 --> 00:20:56,990
that's just a single number could store

00:20:53,030 --> 00:21:00,080
the emotion and a scale we could store

00:20:56,990 --> 00:21:02,870
it as a an array of for you thirty twos

00:21:00,080 --> 00:21:05,630
and so have a ninety-six bit integer so

00:21:02,870 --> 00:21:08,360
we have a cap there and a fourth one to

00:21:05,630 --> 00:21:10,460
represent a scale and a sign or you know

00:21:08,360 --> 00:21:15,830
since rust 126 we could also use a

00:21:10,460 --> 00:21:18,669
128-bit integer so that's pretty cool so

00:21:15,830 --> 00:21:23,270
we'll take a look at big emphases u32

00:21:18,669 --> 00:21:27,049
the for the array of for MU thirty twos

00:21:23,270 --> 00:21:28,990
and as an operational example we'll try

00:21:27,049 --> 00:21:31,820
to add together two decimal numbers so

00:21:28,990 --> 00:21:33,610
adding to adding together two decimal

00:21:31,820 --> 00:21:35,809
numbers is relatively straightforward

00:21:33,610 --> 00:21:37,400
essentially you need to have the numbers

00:21:35,809 --> 00:21:39,980
at the same scale to be able to add them

00:21:37,400 --> 00:21:42,950
together so if I have two point five

00:21:39,980 --> 00:21:45,230
which is scale one plus three scale zero

00:21:42,950 --> 00:21:47,540
then I just need to scale up the the

00:21:45,230 --> 00:21:50,090
three to scale one to be able to add

00:21:47,540 --> 00:21:53,000
them together so 25 plus thirty it's

00:21:50,090 --> 00:21:57,470
easy you have fifty five scale one so

00:21:53,000 --> 00:21:59,270
five point five and so big it's a lot

00:21:57,470 --> 00:22:01,970
easier to reason about this it's one

00:21:59,270 --> 00:22:05,450
single number you need to scale up and

00:22:01,970 --> 00:22:07,100
if you have an array of you know three

00:22:05,450 --> 00:22:09,530
you thirty twos then you need to start

00:22:07,100 --> 00:22:11,450
thinking about words and how the

00:22:09,530 --> 00:22:13,940
overflow happens between binaries it's

00:22:11,450 --> 00:22:16,400
not just a simple addition anymore you

00:22:13,940 --> 00:22:21,080
need to essentially add the bits

00:22:16,400 --> 00:22:22,940
together one by one and so with a naive

00:22:21,080 --> 00:22:23,909
implementation of both these you can see

00:22:22,940 --> 00:22:27,299
that the

00:22:23,909 --> 00:22:30,079
the array version does actually behave a

00:22:27,299 --> 00:22:32,219
lot faster than the beginner version

00:22:30,079 --> 00:22:35,099
however that's not really what I want to

00:22:32,219 --> 00:22:36,929
go into in this particular part I really

00:22:35,099 --> 00:22:41,309
want to talk about exploiting fixed size

00:22:36,929 --> 00:22:43,529
primitives so by knowing that that array

00:22:41,309 --> 00:22:47,339
is 96 bits we can make a lot of

00:22:43,529 --> 00:22:49,440
assumptions about how we add together or

00:22:47,339 --> 00:22:52,859
do certain things with their particular

00:22:49,440 --> 00:22:55,979
number and so shifting on from addition

00:22:52,859 --> 00:22:58,829
going to division a naive implementation

00:22:55,979 --> 00:23:00,929
of division might look like so and I'm

00:22:58,829 --> 00:23:03,259
using 32-bit numbers here but

00:23:00,929 --> 00:23:06,719
essentially the concepts the same so

00:23:03,259 --> 00:23:08,419
this is a the two's complement version

00:23:06,719 --> 00:23:12,179
of division of you're not aware of it as

00:23:08,419 --> 00:23:14,369
as essentially you take the dividend and

00:23:12,179 --> 00:23:15,659
you keep - inger divisor every time

00:23:14,369 --> 00:23:19,499
you're successful you increase the

00:23:15,659 --> 00:23:23,759
quotient so as you can imagine that

00:23:19,499 --> 00:23:26,159
doesn't perform very well so for a

00:23:23,759 --> 00:23:28,679
smaller numbers you can get really good

00:23:26,159 --> 00:23:30,419
results 18 nanoseconds but as you get

00:23:28,679 --> 00:23:33,989
bigger than 90 million MSI

00:23:30,419 --> 00:23:37,859
considerations it's not acceptable in

00:23:33,989 --> 00:23:41,279
most cases probably so we know that the

00:23:37,859 --> 00:23:42,599
the size of the type is 32 bits so with

00:23:41,279 --> 00:23:44,579
that we can also make various

00:23:42,599 --> 00:23:48,989
assumptions about how that two's

00:23:44,579 --> 00:23:50,969
complement and division works so instead

00:23:48,989 --> 00:23:53,159
of looping through in number of times

00:23:50,969 --> 00:23:55,619
depending on the size of the number we

00:23:53,159 --> 00:23:58,949
can limit our loop through only 32 times

00:23:55,619 --> 00:24:00,929
and a syn and basically exploit the fact

00:23:58,949 --> 00:24:03,029
that it's a binary number so we can

00:24:00,929 --> 00:24:05,699
exploit the fact that when things carry

00:24:03,029 --> 00:24:08,719
over we can they disappear from the

00:24:05,699 --> 00:24:11,399
number when we should bit shift left and

00:24:08,719 --> 00:24:14,459
we can carry them over with various

00:24:11,399 --> 00:24:18,089
tests that we need to I won't go into

00:24:14,459 --> 00:24:21,149
this myth here but essentially the idea

00:24:18,089 --> 00:24:23,849
of it here is that we are now only

00:24:21,149 --> 00:24:27,499
looping 32 times so we get around about

00:24:23,849 --> 00:24:31,469
45 or 42 to 46 nanoseconds per iteration

00:24:27,499 --> 00:24:34,169
for this division and for all all of

00:24:31,469 --> 00:24:35,969
those particular numbers and I do want

00:24:34,169 --> 00:24:37,480
to call out here is that the hundred is

00:24:35,969 --> 00:24:39,580
actually slower in this case

00:24:37,480 --> 00:24:43,510
we do have 46 nanoseconds per iteration

00:24:39,580 --> 00:24:45,700
over the 18 we had before but it's a

00:24:43,510 --> 00:24:48,580
reasonable trade-off considering that we

00:24:45,700 --> 00:24:52,900
now have a very consistent performance

00:24:48,580 --> 00:24:55,120
across the board so the other thing I

00:24:52,900 --> 00:24:56,559
just want to pull out here is this is

00:24:55,120 --> 00:24:58,390
another example why you should be

00:24:56,559 --> 00:25:00,429
testing across a range of inputs if I

00:24:58,390 --> 00:25:03,850
just have one test around for a hundred

00:25:00,429 --> 00:25:06,010
or even 200 or what a thousand then it's

00:25:03,850 --> 00:25:08,530
not going to be incredibly bad

00:25:06,010 --> 00:25:09,790
performance but as I start to get to the

00:25:08,530 --> 00:25:14,799
bigger numbers that starts to get

00:25:09,790 --> 00:25:16,690
horrible so the fifth thing I wanted to

00:25:14,799 --> 00:25:21,130
talk about is copy borrow semantics in

00:25:16,690 --> 00:25:24,640
this ones and essentially when we first

00:25:21,130 --> 00:25:26,140
start getting into rust well I'm sure a

00:25:24,640 --> 00:25:28,299
lot of us are battled with the borrowed

00:25:26,140 --> 00:25:30,700
chicken before and we've done things

00:25:28,299 --> 00:25:34,990
like this to get around it and obviously

00:25:30,700 --> 00:25:36,160
that's a warning sign because cloning to

00:25:34,990 --> 00:25:38,350
get around the borrowed checker isn't

00:25:36,160 --> 00:25:42,720
the way forward it's just the way

00:25:38,350 --> 00:25:44,799
forward temporarily or whatever else but

00:25:42,720 --> 00:25:46,210
essentially if you're avoiding the

00:25:44,799 --> 00:25:49,929
borrowed checker it's probably a bad

00:25:46,210 --> 00:25:52,150
sign and the reason being is copying or

00:25:49,929 --> 00:25:55,720
cloning a large struct we all know that

00:25:52,150 --> 00:25:57,640
that can be expensive but essentially it

00:25:55,720 --> 00:26:00,190
can also be expensive if it doesn't fit

00:25:57,640 --> 00:26:02,020
on the stack so we need to be

00:26:00,190 --> 00:26:04,570
considering the size of the data that

00:26:02,020 --> 00:26:09,040
we're really copying in these particular

00:26:04,570 --> 00:26:11,440
cases so as an example we'll take a look

00:26:09,040 --> 00:26:14,290
at the when we had before which is the

00:26:11,440 --> 00:26:16,510
fixed size slice and so we've got the

00:26:14,290 --> 00:26:19,030
fix a slice of three there and then on

00:26:16,510 --> 00:26:21,070
the bottom one there the copy we don't

00:26:19,030 --> 00:26:25,570
have the the borrow we copy the array

00:26:21,070 --> 00:26:27,070
instead of borrowing it and so if we

00:26:25,570 --> 00:26:29,559
were to look at the performance of this

00:26:27,070 --> 00:26:31,690
then we can see that for a single

00:26:29,559 --> 00:26:34,000
iteration it looks fine to nanoseconds

00:26:31,690 --> 00:26:35,500
each but once we get into a bigger loops

00:26:34,000 --> 00:26:37,929
then we start to see a little bit of a

00:26:35,500 --> 00:26:39,640
variance and to be honest this this

00:26:37,929 --> 00:26:41,290
particular benchmark is an interesting

00:26:39,640 --> 00:26:45,160
one because it varies substantially

00:26:41,290 --> 00:26:47,130
between runs it really depends on how

00:26:45,160 --> 00:26:49,780
the process is working at the time but

00:26:47,130 --> 00:26:50,950
essentially this one has a roughly

00:26:49,780 --> 00:26:52,149
around 2,400

00:26:50,950 --> 00:26:56,080
seconds versus twenty nine hundred

00:26:52,149 --> 00:26:59,559
nanoseconds so copying in this size just

00:26:56,080 --> 00:27:01,419
96 bits as absolutely slower than just

00:26:59,559 --> 00:27:04,630
borrowing those 96 bits in this

00:27:01,419 --> 00:27:05,980
particular case again if it can fit on

00:27:04,630 --> 00:27:08,799
the stack it's fast but if it doesn't

00:27:05,980 --> 00:27:13,240
then it potentially could be a bit

00:27:08,799 --> 00:27:15,279
slower um so what about unsafe

00:27:13,240 --> 00:27:21,010
I mean unsafe is a great way to improve

00:27:15,279 --> 00:27:23,889
performance right so as library authors

00:27:21,010 --> 00:27:27,070
I think that well the definition of

00:27:23,889 --> 00:27:27,970
unsafe really for wooden rust from my

00:27:27,070 --> 00:27:30,010
understanding is you're basically

00:27:27,970 --> 00:27:32,260
telling the compiler hey I know better

00:27:30,010 --> 00:27:36,309
than you I know what I'm doing

00:27:32,260 --> 00:27:38,880
trust me and well that's fine when I'm

00:27:36,309 --> 00:27:42,850
writing the code you know I trust myself

00:27:38,880 --> 00:27:46,210
but you know of course I cause a lot of

00:27:42,850 --> 00:27:48,250
bugs as well but essentially the the

00:27:46,210 --> 00:27:50,799
community doesn't necessarily trust me

00:27:48,250 --> 00:27:53,200
like I trust myself so having unsafe

00:27:50,799 --> 00:27:55,210
within your code is something that if

00:27:53,200 --> 00:27:58,330
you can avoid it as possible then then

00:27:55,210 --> 00:28:00,250
you know you should be avoiding it um

00:27:58,330 --> 00:28:02,139
and I have done a little bit of

00:28:00,250 --> 00:28:05,049
experimentation with in the library and

00:28:02,139 --> 00:28:06,340
I have found that and the cases that

00:28:05,049 --> 00:28:08,440
I've been looking at where I've thought

00:28:06,340 --> 00:28:11,080
hey I just had me moved that would be a

00:28:08,440 --> 00:28:12,370
lot faster I've actually found that

00:28:11,080 --> 00:28:16,600
there hasn't been any noticeable

00:28:12,370 --> 00:28:18,399
difference and I think that's kind of

00:28:16,600 --> 00:28:22,779
interesting I think that's something

00:28:18,399 --> 00:28:24,250
that as as you know within everyone here

00:28:22,779 --> 00:28:26,799
if you were measuring your performance

00:28:24,250 --> 00:28:28,389
and you see that there's a huge and

00:28:26,799 --> 00:28:30,220
performance increase then you can make

00:28:28,389 --> 00:28:33,279
that trade-off only if it's absolutely

00:28:30,220 --> 00:28:34,539
necessary and so I think there

00:28:33,279 --> 00:28:36,100
originally I was jumping to the

00:28:34,539 --> 00:28:38,919
conclusion that unsafe was always going

00:28:36,100 --> 00:28:40,960
to be better and in terms of performance

00:28:38,919 --> 00:28:46,409
it wasn't necessarily the case and so

00:28:40,960 --> 00:28:48,700
I'd probably be interesting to challenge

00:28:46,409 --> 00:28:51,059
challenge yourself by just measuring

00:28:48,700 --> 00:28:51,059
your results

00:28:51,540 --> 00:28:58,020
so just as some closing thoughts as that

00:28:55,380 --> 00:29:00,420
um you know as library authors we have

00:28:58,020 --> 00:29:03,060
an implicit responsibility consider and

00:29:00,420 --> 00:29:06,360
performance as small details do matter

00:29:03,060 --> 00:29:08,010
and it's really important that you

00:29:06,360 --> 00:29:10,290
understand how your applications working

00:29:08,010 --> 00:29:11,910
under load or under normal circumstances

00:29:10,290 --> 00:29:14,940
in order to really benchmark it

00:29:11,910 --> 00:29:16,710
effectively it's important that you're

00:29:14,940 --> 00:29:18,210
testing across a range of inputs would

00:29:16,710 --> 00:29:20,730
be a shame of you just were testing

00:29:18,210 --> 00:29:22,920
against dividing by 100 before and the

00:29:20,730 --> 00:29:25,050
billion was turning into 19 million

00:29:22,920 --> 00:29:26,400
nanoseconds so it's important that

00:29:25,050 --> 00:29:31,560
you're really considering a whole

00:29:26,400 --> 00:29:33,630
variety of of benchmark tests and the

00:29:31,560 --> 00:29:35,190
main purpose of metering is really so

00:29:33,630 --> 00:29:37,670
that you have insights so you can make

00:29:35,190 --> 00:29:40,680
effective decisions going forward so I

00:29:37,670 --> 00:29:43,200
you know all of this has really been a

00:29:40,680 --> 00:29:44,730
result of experimentation so really

00:29:43,200 --> 00:29:45,930
understanding what's there knowing that

00:29:44,730 --> 00:29:49,050
you want to make the improvement and

00:29:45,930 --> 00:29:51,150
then absolutely testing something and I

00:29:49,050 --> 00:29:55,710
guess testing a hypothesis and seeing

00:29:51,150 --> 00:29:57,570
that actually worked and so all in all

00:29:55,710 --> 00:29:59,400
this community is awesome and you guys

00:29:57,570 --> 00:30:01,740
are great for coming out to the russ

00:29:59,400 --> 00:30:06,840
conf and we can keep making it awesome

00:30:01,740 --> 00:30:08,850
by really working together and so thank

00:30:06,840 --> 00:30:10,560
you for listening and if you do have any

00:30:08,850 --> 00:30:12,780
questions and you can come and see me in

00:30:10,560 --> 00:30:14,400
the break but I did also want to just

00:30:12,780 --> 00:30:17,070
say a special thanks to all those people

00:30:14,400 --> 00:30:19,810
that helped me build these libraries you

00:30:17,070 --> 00:30:30,869
guys are awesome so thank you

00:30:19,810 --> 00:30:30,869
[Applause]

00:30:31,540 --> 00:30:39,220
[Music]

00:30:37,159 --> 00:30:39,220

YouTube URL: https://www.youtube.com/watch?v=d2ZQ9-4ZJmQ


