Title: RustFest Paris 2018:  Building Reliable Infrastructure in Rust by Tyler Neely
Publication date: 2018-05-28
Playlist: RustFest Paris 2018
Description: 
	Tyler Neely can help us to test
if our code is really the best
he is sharing techniques
to test with some tweaks
so our biases can lay to rest

After years of getting whooped by bugs at scale at various North American infrastructure companies, Tyler moved to Berlin where he spends his days reading papers, finding bugs in complex systems, and building Sled - a modern embedded database for the Rust ecosystem. He believes on-call people should sleep as long as they want.      The wild success of testing tools like Jepsen is a wake-up call that we’re approaching systems engineering from a fundamentally bug-prone perspective. Why don’t we find these devastating bugs on our laptops before opening pull requests? Rust’s compiler gives us wonderful guarantees about memory safety, but as soon as we open files or sockets, all hell seems to break loose.      This talk will show you how to apply techniques from the distributed systems and database worlds in a way that maximizes the number of bugs found per cpu cycle, and reduce the amount of bias that we hardcode into our tests.

(Limerick by @llogiq)

https://paris.rustfest.eu/sessions/building-reliable-infrastructure-in-rust
Captions: 
	00:00:04,759 --> 00:00:12,830
Tyler Neely can help you to test if your

00:00:09,660 --> 00:00:12,830
coat is really the best

00:00:19,000 --> 00:00:22,920
[Applause]

00:00:42,200 --> 00:00:53,789
library thing so another name for this

00:00:51,660 --> 00:00:56,600
clock could be the clear expression of

00:00:53,789 --> 00:01:00,260
beliefs or to

00:00:56,600 --> 00:01:03,079
so Who am I I kind of started as like an

00:01:00,260 --> 00:01:05,660
SRE facing a lot of bugs and production

00:01:03,079 --> 00:01:07,130
at social media companies and then it

00:01:05,660 --> 00:01:08,540
worked for like about infrastructure

00:01:07,130 --> 00:01:10,880
companies and then like serverless

00:01:08,540 --> 00:01:13,220
company seemed like a bunch of like

00:01:10,880 --> 00:01:15,500
weird infrastructure things then I got

00:01:13,220 --> 00:01:17,240
super burn it out and I moved to Berlin

00:01:15,500 --> 00:01:19,640
and just got lazy and to start working

00:01:17,240 --> 00:01:21,860
on personal projects kind of culminating

00:01:19,640 --> 00:01:23,630
and it projects all the swed there's

00:01:21,860 --> 00:01:25,880
like a database construction kit and

00:01:23,630 --> 00:01:27,920
some testing things so it's like fill

00:01:25,880 --> 00:01:29,539
the database in rust it's like a

00:01:27,920 --> 00:01:31,430
collection of modular components like a

00:01:29,539 --> 00:01:33,680
page cache they can just take and

00:01:31,430 --> 00:01:35,600
basically build fairly high performance

00:01:33,680 --> 00:01:37,340
things with very little effort and I

00:01:35,600 --> 00:01:38,810
felt like a pw tree and I got the

00:01:37,340 --> 00:01:40,640
housing lines of rest on top of this so

00:01:38,810 --> 00:01:42,320
even those really complex things without

00:01:40,640 --> 00:01:45,920
very much effort on top of the page

00:01:42,320 --> 00:01:48,229
cache anyway today I worked on it with

00:01:45,920 --> 00:01:50,690
the source point which aims to better

00:01:48,229 --> 00:01:54,310
fund and empower free software and you

00:01:50,690 --> 00:01:54,310
might know me as a space jams

00:01:55,270 --> 00:02:00,140
anyway so what I'm going to because we

00:01:57,500 --> 00:02:02,960
got say ourselves the things we create

00:02:00,140 --> 00:02:05,570
and the context that we exist in and

00:02:02,960 --> 00:02:08,540
also mechanically confronting our

00:02:05,570 --> 00:02:10,300
assumptions and basically trying to test

00:02:08,540 --> 00:02:13,220
things that are networks these sockets

00:02:10,300 --> 00:02:15,800
and then just like random miscellaneous

00:02:13,220 --> 00:02:17,210
tips on architecture maybe something is

00:02:15,800 --> 00:02:18,980
driven fault injection if we get to it

00:02:17,210 --> 00:02:21,520
it's basically ways it like really

00:02:18,980 --> 00:02:23,990
bringing out the bugs from your systems

00:02:21,520 --> 00:02:26,450
things that I'm not going to cover so

00:02:23,990 --> 00:02:29,540
reliable infrastructure many people need

00:02:26,450 --> 00:02:31,610
things like metrics introspection time

00:02:29,540 --> 00:02:32,930
series databases it has to be planning

00:02:31,610 --> 00:02:34,580
and these things are crucial for

00:02:32,930 --> 00:02:35,660
actually running the levels that's where

00:02:34,580 --> 00:02:37,940
it but I think that they're covered very

00:02:35,660 --> 00:02:39,980
well particularly like to direct your

00:02:37,940 --> 00:02:42,800
attention to duties in plugins use one

00:02:39,980 --> 00:02:44,940
by Brendan Gregg you might know because

00:02:42,800 --> 00:02:46,890
there's like the flame graph guy

00:02:44,940 --> 00:02:49,970
wonderful book systems performance

00:02:46,890 --> 00:02:53,970
monitoring particularly chapter 2

00:02:49,970 --> 00:02:56,180
analogy is outside because because our

00:02:53,970 --> 00:02:58,950
ebook is great for particularly like

00:02:56,180 --> 00:03:01,650
building things away that is

00:02:58,950 --> 00:03:03,840
introspective oil and also sort of like

00:03:01,650 --> 00:03:04,710
the social aspects of running teams that

00:03:03,840 --> 00:03:06,240
have to deal with reliable

00:03:04,710 --> 00:03:08,490
infrastructure this looks great for it

00:03:06,240 --> 00:03:10,230
and of course learn to cut my design and

00:03:08,490 --> 00:03:11,990
data intensive application is like

00:03:10,230 --> 00:03:14,670
really good for work and like

00:03:11,990 --> 00:03:17,550
understanding material databases and

00:03:14,670 --> 00:03:19,470
distributed systems correctness and

00:03:17,550 --> 00:03:21,540
things like that ok so let's go check

00:03:19,470 --> 00:03:23,190
out those books they're really good for

00:03:21,540 --> 00:03:26,070
those kind of things but we are going to

00:03:23,190 --> 00:03:27,690
be talking more about efficient ways of

00:03:26,070 --> 00:03:29,010
getting bugs out of our systems because

00:03:27,690 --> 00:03:32,700
I think that this is a topic that has

00:03:29,010 --> 00:03:35,280
not been covered very well so this is

00:03:32,700 --> 00:03:37,850
your brain everything we know is kind of

00:03:35,280 --> 00:03:40,620
wrong because our perception is so fuzzy

00:03:37,850 --> 00:03:42,420
and then like so everything that gets

00:03:40,620 --> 00:03:45,720
into our brains is like kind of wrong

00:03:42,420 --> 00:03:47,340
based on our local like experiences and

00:03:45,720 --> 00:03:48,450
then when we try to make things it's

00:03:47,340 --> 00:03:50,910
kind of like running those assumptions

00:03:48,450 --> 00:03:52,590
in Reverse and basically the things we

00:03:50,910 --> 00:03:56,670
create kind of reflect these biases

00:03:52,590 --> 00:03:58,770
symmetrically and also we tend not to

00:03:56,670 --> 00:04:00,930
ask our beliefs to pay rent and what I

00:03:58,770 --> 00:04:02,459
mean by this is basically asking you

00:04:00,930 --> 00:04:04,440
know what do these beliefs kind of

00:04:02,459 --> 00:04:06,570
predict should happen and also what do

00:04:04,440 --> 00:04:08,760
these beliefs kind of make us think

00:04:06,570 --> 00:04:11,220
should be less likely if beliefs don't

00:04:08,760 --> 00:04:13,080
constrain any possible realities then

00:04:11,220 --> 00:04:14,430
they they don't really help us guide

00:04:13,080 --> 00:04:16,709
decisions they could be useful in other

00:04:14,430 --> 00:04:18,000
ways but um to the extent that we're

00:04:16,709 --> 00:04:19,950
trying to make reliable care this is

00:04:18,000 --> 00:04:21,570
important and we don't do cache

00:04:19,950 --> 00:04:23,640
invalidation when we've realized that

00:04:21,570 --> 00:04:25,020
things are wrong that we believe and

00:04:23,640 --> 00:04:27,300
also we kind of stacked beliefs on top

00:04:25,020 --> 00:04:28,770
of each other in ways that can like make

00:04:27,300 --> 00:04:30,360
these like teetering towers of beliefs

00:04:28,770 --> 00:04:31,650
that like you've ripped out a Jenga cube

00:04:30,360 --> 00:04:34,110
and like you would you would hope it

00:04:31,650 --> 00:04:36,150
would like you know tumble to the ground

00:04:34,110 --> 00:04:37,380
but instead of just days floating there

00:04:36,150 --> 00:04:40,050
in the air and we continue to base

00:04:37,380 --> 00:04:41,040
decisions on it not so useful anyway I'd

00:04:40,050 --> 00:04:43,710
love to keep talking about this like

00:04:41,040 --> 00:04:45,630
brain stuff but let's kind of bridges

00:04:43,710 --> 00:04:47,160
into code if you want to learn more

00:04:45,630 --> 00:04:49,680
about that I recommend checking out

00:04:47,160 --> 00:04:51,240
rationality from AI to zombies but

00:04:49,680 --> 00:04:53,100
really I think that reliable

00:04:51,240 --> 00:04:54,570
infrastructure kind of boils down to

00:04:53,100 --> 00:04:55,370
confronting assumptions so these things

00:04:54,570 --> 00:04:58,880
are kind of nice

00:04:55,370 --> 00:05:01,190
talk about Andres okay so given the fact

00:04:58,880 --> 00:05:04,639
that our code kind of represents the

00:05:01,190 --> 00:05:06,680
culmination of our biases and like the

00:05:04,639 --> 00:05:10,070
things that we think with some error in

00:05:06,680 --> 00:05:12,080
them when we write tests they're also

00:05:10,070 --> 00:05:13,970
symmetrically affected by these biases

00:05:12,080 --> 00:05:18,110
and this can be problematic because when

00:05:13,970 --> 00:05:20,090
we write tests they often basically

00:05:18,110 --> 00:05:22,370
don't look for things that we've already

00:05:20,090 --> 00:05:24,740
thought about and this is pretty

00:05:22,370 --> 00:05:26,419
problematic because I mean how often

00:05:24,740 --> 00:05:28,340
have you found a bug in a system in

00:05:26,419 --> 00:05:31,340
production or just like running your

00:05:28,340 --> 00:05:32,660
code and you just realize like oh I you

00:05:31,340 --> 00:05:35,750
know I thought I had like great test

00:05:32,660 --> 00:05:37,310
coverage I should have caught this but

00:05:35,750 --> 00:05:38,330
like my tests just didn't cover it it

00:05:37,310 --> 00:05:40,490
turns out that like if you're just

00:05:38,330 --> 00:05:43,699
writing like unit tests even if you have

00:05:40,490 --> 00:05:45,650
like 100% line and branch coverage

00:05:43,699 --> 00:05:47,660
that's only one dimension of the entire

00:05:45,650 --> 00:05:49,190
space of your program there's also like

00:05:47,660 --> 00:05:50,990
all the different values of all the

00:05:49,190 --> 00:05:53,479
variables throughout it that are just

00:05:50,990 --> 00:05:56,240
totally unaddressed just relying on

00:05:53,479 --> 00:05:58,370
unlike a bunch of unit tests makes your

00:05:56,240 --> 00:06:00,110
code very subject to was called the

00:05:58,370 --> 00:06:03,680
pesticide paradox where your code

00:06:00,110 --> 00:06:04,970
becomes immune to your tests but that

00:06:03,680 --> 00:06:07,520
doesn't actually make mean that it's

00:06:04,970 --> 00:06:10,160
like all that useful for other things so

00:06:07,520 --> 00:06:12,889
of how can we like what should we do if

00:06:10,160 --> 00:06:15,160
like our tests that we write tend not to

00:06:12,889 --> 00:06:17,870
be like as effective as they could be

00:06:15,160 --> 00:06:20,599
don't write them just don't write tests

00:06:17,870 --> 00:06:22,130
come on like testing is boring I know I

00:06:20,599 --> 00:06:25,580
don't really enjoy writing tests

00:06:22,130 --> 00:06:27,770
manually but we can we can do a lot

00:06:25,580 --> 00:06:30,139
better by writing what we expect and

00:06:27,770 --> 00:06:31,789
then mechanically generating the tests

00:06:30,139 --> 00:06:33,260
and we can basically have the Machine

00:06:31,789 --> 00:06:36,919
create more tests than we would have

00:06:33,260 --> 00:06:39,440
like many lifetimes to write by hand and

00:06:36,919 --> 00:06:41,570
if we can do this then we can get a lot

00:06:39,440 --> 00:06:43,940
of mileage out of things we should make

00:06:41,570 --> 00:06:45,349
our beliefs explicit and the beliefs

00:06:43,940 --> 00:06:48,680
that are present in our code should pay

00:06:45,349 --> 00:06:50,750
rent and I would like to introduce you

00:06:48,680 --> 00:06:53,449
to property testing which is a wonderful

00:06:50,750 --> 00:06:55,430
way of doing this so there's kind of a

00:06:53,449 --> 00:06:58,280
newt a new crate and the rest ecosystem

00:06:55,430 --> 00:07:00,670
called prop tests where you basically

00:06:58,280 --> 00:07:02,110
write these macros and

00:07:00,670 --> 00:07:06,190
you know this looks a lot like a normal

00:07:02,110 --> 00:07:08,590
test except you can specify these

00:07:06,190 --> 00:07:12,310
generators and basically provide

00:07:08,590 --> 00:07:14,290
variables into your test and the

00:07:12,310 --> 00:07:16,180
generators will provide specific

00:07:14,290 --> 00:07:18,910
instances of these these different

00:07:16,180 --> 00:07:21,400
inputs so if you have not been subjected

00:07:18,910 --> 00:07:23,050
to the cruel realities of modern

00:07:21,400 --> 00:07:24,910
computing machinery you might assume

00:07:23,050 --> 00:07:26,680
that this could be correct like

00:07:24,910 --> 00:07:28,480
multiplying something by five and then

00:07:26,680 --> 00:07:30,130
dividing it by five you might expect

00:07:28,480 --> 00:07:33,220
that to you know equal what you put in

00:07:30,130 --> 00:07:34,150
in the first place people who have not

00:07:33,220 --> 00:07:36,070
been so lucky

00:07:34,150 --> 00:07:38,140
or like subjected to the cruel whims of

00:07:36,070 --> 00:07:40,960
the machine might guess what's going to

00:07:38,140 --> 00:07:43,030
happen we've run cargo tests the prop

00:07:40,960 --> 00:07:46,150
test library is able to identify a

00:07:43,030 --> 00:07:47,290
specific very large number that when

00:07:46,150 --> 00:07:49,420
multiplied by five

00:07:47,290 --> 00:07:52,150
well like basically flag the overflow

00:07:49,420 --> 00:07:54,700
flag or the overflow register on our

00:07:52,150 --> 00:07:56,830
CPUs and rust checks for this when not

00:07:54,700 --> 00:07:59,340
running in release mode and it will

00:07:56,830 --> 00:07:59,340
cause a panic

00:07:59,520 --> 00:08:04,330
yeah prop test pays a lot of attention

00:08:01,780 --> 00:08:06,040
to the edge cases but also really like

00:08:04,330 --> 00:08:07,810
this is a really cool thing because it

00:08:06,040 --> 00:08:09,040
also basically just wrote a regression

00:08:07,810 --> 00:08:11,230
test for us

00:08:09,040 --> 00:08:13,740
so prop tests just created this file and

00:08:11,230 --> 00:08:16,210
prop test regressions and it basically

00:08:13,740 --> 00:08:18,250
shows the random number generator seed

00:08:16,210 --> 00:08:22,150
that it used to generate the specific

00:08:18,250 --> 00:08:23,890
failing input for our test and anytime

00:08:22,150 --> 00:08:25,090
it runs a new test it will basically go

00:08:23,890 --> 00:08:28,300
through all of the things in this

00:08:25,090 --> 00:08:31,360
regressions file and like basically make

00:08:28,300 --> 00:08:33,970
sure that it tries those first and if we

00:08:31,360 --> 00:08:36,160
have in past that yet it will just keep

00:08:33,970 --> 00:08:37,660
deterministically replaying it so prop

00:08:36,160 --> 00:08:40,090
test is nice because it gives us so not

00:08:37,660 --> 00:08:42,340
some non determinism in checking random

00:08:40,090 --> 00:08:44,560
values but also we get deterministic

00:08:42,340 --> 00:08:46,270
replay of our bugs that it does find so

00:08:44,560 --> 00:08:48,160
it's a really wonderful way of just you

00:08:46,270 --> 00:08:49,630
know coming up with tests for us we just

00:08:48,160 --> 00:08:52,660
say what we expect and then it does the

00:08:49,630 --> 00:08:54,390
rest you can also do this for things

00:08:52,660 --> 00:08:57,640
that involve compression or like

00:08:54,390 --> 00:08:59,770
serialization basically things that you

00:08:57,640 --> 00:09:01,350
expected like do a round trip of some

00:08:59,770 --> 00:09:05,230
sort and retain their original identity

00:09:01,350 --> 00:09:06,610
and it's like quite commonly used in

00:09:05,230 --> 00:09:09,220
like if you're writing like a JSON

00:09:06,610 --> 00:09:10,780
deserialize ER or something then like

00:09:09,220 --> 00:09:12,990
that this is a pretty straightforward

00:09:10,780 --> 00:09:15,360
thing to use

00:09:12,990 --> 00:09:17,850
and you can basically provide more

00:09:15,360 --> 00:09:19,410
interesting patterns as well

00:09:17,850 --> 00:09:21,089
you can basically give it like reg X's

00:09:19,410 --> 00:09:24,019
and it will generate text that that

00:09:21,089 --> 00:09:26,490
satisfies them it's a it's really cool

00:09:24,019 --> 00:09:30,600
you can also provide your own generators

00:09:26,490 --> 00:09:32,399
for instance and in bottles crate with

00:09:30,600 --> 00:09:34,560
immutable data structures there's a

00:09:32,399 --> 00:09:36,990
whole like like collection of

00:09:34,560 --> 00:09:38,700
interesting prop test macros so if

00:09:36,990 --> 00:09:41,550
you're curious about looking at more

00:09:38,700 --> 00:09:45,360
examples of practiced check out mr s

00:09:41,550 --> 00:09:46,589
there's tons of examples there also if

00:09:45,360 --> 00:09:48,779
you have a system with configuration

00:09:46,589 --> 00:09:50,579
that the user can change you better

00:09:48,779 --> 00:09:53,459
expect your users to configure your

00:09:50,579 --> 00:09:55,890
system in ways that like maybe you don't

00:09:53,459 --> 00:09:57,930
expect so my friend Yash is basically

00:09:55,890 --> 00:10:00,779
doing a rest port of the DAT protocol

00:09:57,930 --> 00:10:02,850
and this is a library called spar spit

00:10:00,779 --> 00:10:05,070
field that's a part of it and one day we

00:10:02,850 --> 00:10:06,779
were just hanging out at a cafe and and

00:10:05,070 --> 00:10:09,060
said oh do you hear about the prop test

00:10:06,779 --> 00:10:10,589
library and it's like yeah let's try it

00:10:09,060 --> 00:10:12,480
out so this was actually the the first

00:10:10,589 --> 00:10:13,890
thing that we wrote together to kind of

00:10:12,480 --> 00:10:15,690
play with prop test and it just like

00:10:13,890 --> 00:10:18,449
immediately caused the code to blow up

00:10:15,690 --> 00:10:21,209
and it's like really not so much testing

00:10:18,449 --> 00:10:22,440
but like you know you might expect users

00:10:21,209 --> 00:10:24,000
to configure things in ways that we

00:10:22,440 --> 00:10:26,399
didn't expect specifically what this is

00:10:24,000 --> 00:10:29,310
doing is its configuring this library

00:10:26,399 --> 00:10:31,279
with a particular page size and then

00:10:29,310 --> 00:10:34,410
it's like actually using one of the

00:10:31,279 --> 00:10:36,420
methods on the library so it's like

00:10:34,410 --> 00:10:37,560
without very much effort put into

00:10:36,420 --> 00:10:39,810
testing you get really interesting

00:10:37,560 --> 00:10:42,329
results so how do we apply this to more

00:10:39,810 --> 00:10:45,810
complex things allow me to introduce you

00:10:42,329 --> 00:10:47,510
to model-based testing model that this

00:10:45,810 --> 00:10:50,670
is like a really powerful technique

00:10:47,510 --> 00:10:52,890
basically what you do is you build a

00:10:50,670 --> 00:10:54,329
simplified model of the system like if

00:10:52,890 --> 00:10:55,740
you're building a database maybe you can

00:10:54,329 --> 00:10:57,360
just use a hash map for that and

00:10:55,740 --> 00:10:59,339
basically the point of the model is just

00:10:57,360 --> 00:11:02,430
to encode your like expectations about

00:10:59,339 --> 00:11:03,630
how the system should behave the simpler

00:11:02,430 --> 00:11:06,060
it is the better because it's also like

00:11:03,630 --> 00:11:08,250
a cognitive aid once you have that

00:11:06,060 --> 00:11:10,649
simplified model of the system you'll

00:11:08,250 --> 00:11:13,500
basically use a library to generate a

00:11:10,649 --> 00:11:15,720
random sequence of operations that apply

00:11:13,500 --> 00:11:18,300
both to the implementation and the model

00:11:15,720 --> 00:11:20,040
and if their behavior ever diverges then

00:11:18,300 --> 00:11:21,839
you know that you either have a problem

00:11:20,040 --> 00:11:23,990
with the model the implementation or

00:11:21,839 --> 00:11:28,430
both

00:11:23,990 --> 00:11:29,960
we found a problem and you know if you

00:11:28,430 --> 00:11:32,060
build something like this on top of prop

00:11:29,960 --> 00:11:33,280
test or another popular library you

00:11:32,060 --> 00:11:35,180
might have heard of called quick check

00:11:33,280 --> 00:11:35,920
you can basically just like.he

00:11:35,180 --> 00:11:39,080
pre-running

00:11:35,920 --> 00:11:40,970
this long sequence of operations which

00:11:39,080 --> 00:11:43,280
it might initially be quite large like a

00:11:40,970 --> 00:11:44,780
hundred operations and who wants to like

00:11:43,280 --> 00:11:46,670
actually like figure out which

00:11:44,780 --> 00:11:48,980
particular subsequence of those

00:11:46,670 --> 00:11:50,450
operations led to the failure so these

00:11:48,980 --> 00:11:52,340
libraries are wonderful because they

00:11:50,450 --> 00:11:54,890
will randomly pick operations to drop

00:11:52,340 --> 00:11:56,930
out of that sequence rerun the test and

00:11:54,890 --> 00:11:59,110
if it continues to fail basically keep

00:11:56,930 --> 00:12:02,690
dropping elements out of that operation

00:11:59,110 --> 00:12:05,690
sequence so it basically is able to

00:12:02,690 --> 00:12:08,060
shrink all these like random operations

00:12:05,690 --> 00:12:10,580
into the specific subsequence that

00:12:08,060 --> 00:12:13,340
triggers your failure for an example

00:12:10,580 --> 00:12:15,020
let's start off by building a tree just

00:12:13,340 --> 00:12:17,120
like a simple tree with an optional root

00:12:15,020 --> 00:12:18,980
and that's not actually implement the

00:12:17,120 --> 00:12:23,210
the methods let's just like have them do

00:12:18,980 --> 00:12:25,280
nothing on our tree so this is a little

00:12:23,210 --> 00:12:27,920
library that I wrote to make model based

00:12:25,280 --> 00:12:29,990
test fit on my slides for this talk but

00:12:27,920 --> 00:12:31,220
it turns out that it's actually pretty

00:12:29,990 --> 00:12:32,810
good at significantly reducing the

00:12:31,220 --> 00:12:36,260
boilerplate required to do this kind of

00:12:32,810 --> 00:12:38,690
testing so we have this tree that we're

00:12:36,260 --> 00:12:40,160
building as implementation and let's

00:12:38,690 --> 00:12:42,560
just use like a beech tree map as our

00:12:40,160 --> 00:12:44,990
model and basically what this macro says

00:12:42,560 --> 00:12:48,080
is we we have two operations that we're

00:12:44,990 --> 00:12:50,960
defining set and get and along with

00:12:48,080 --> 00:12:52,910
their associated generators and we're

00:12:50,960 --> 00:12:54,740
generating a key and a value for sets

00:12:52,910 --> 00:12:56,600
that we insert into both the

00:12:54,740 --> 00:12:58,460
implementation and the model and then

00:12:56,600 --> 00:13:02,330
when we try to get a randomly generated

00:12:58,460 --> 00:13:05,960
key out of these structures we expect

00:13:02,330 --> 00:13:08,390
the values to be the same when we run it

00:13:05,960 --> 00:13:11,810
it basically generates like a long

00:13:08,390 --> 00:13:13,970
sequence of of operations and this is

00:13:11,810 --> 00:13:17,150
like actually amazing because it just

00:13:13,970 --> 00:13:19,760
found two specific operations if you set

00:13:17,150 --> 00:13:22,310
two to a value and then you try to get

00:13:19,760 --> 00:13:23,720
two then the operations diverged because

00:13:22,310 --> 00:13:26,240
remember we didn't actually implement

00:13:23,720 --> 00:13:28,070
there our tree we just kind of like had

00:13:26,240 --> 00:13:30,680
to do nothing and return none for

00:13:28,070 --> 00:13:32,540
everything for the gets but what

00:13:30,680 --> 00:13:34,610
actually happened under the hood was

00:13:32,540 --> 00:13:36,160
that this generated like like a hundred

00:13:34,610 --> 00:13:37,900
operations and then

00:13:36,160 --> 00:13:39,280
when it found a failure it kind of

00:13:37,900 --> 00:13:41,080
boiled it down into something that's

00:13:39,280 --> 00:13:43,630
super understandable so this is great

00:13:41,080 --> 00:13:44,890
for like actually trying to like like

00:13:43,630 --> 00:13:46,480
figure out what could have happened

00:13:44,890 --> 00:13:49,060
because we don't just get like this

00:13:46,480 --> 00:13:50,320
crazy like fuzzing input like what if

00:13:49,060 --> 00:13:52,060
you've ever used fuzzers before

00:13:50,320 --> 00:13:53,500
sometimes it can be really difficult to

00:13:52,060 --> 00:13:55,300
figure out what was the actual thing

00:13:53,500 --> 00:13:57,100
that went wrong but this lets our tests

00:13:55,300 --> 00:14:02,500
tell us stories that we can understand

00:13:57,100 --> 00:14:03,880
as humans so we can also do more complex

00:14:02,500 --> 00:14:06,550
things like imagine we were building a

00:14:03,880 --> 00:14:08,170
database you could do like a restart

00:14:06,550 --> 00:14:09,850
just by like dropping the thing having a

00:14:08,170 --> 00:14:11,920
closed its file descriptors and then

00:14:09,850 --> 00:14:14,470
open it again and basically this could

00:14:11,920 --> 00:14:16,570
check for like things like is the data

00:14:14,470 --> 00:14:20,020
still in the database that I expected to

00:14:16,570 --> 00:14:21,700
be in the database okay a slight

00:14:20,020 --> 00:14:23,800
diversion into a really cool property

00:14:21,700 --> 00:14:26,710
that many systems we would like to have

00:14:23,800 --> 00:14:28,450
is called linearize ability you might

00:14:26,710 --> 00:14:29,620
have heard of it it's something like a

00:14:28,450 --> 00:14:31,150
lot of like just like distributed

00:14:29,620 --> 00:14:33,970
systems people love like talking about

00:14:31,150 --> 00:14:35,530
like throwing throwing out there but

00:14:33,970 --> 00:14:37,810
most of them don't actually understand

00:14:35,530 --> 00:14:40,240
what it means and basically means that

00:14:37,810 --> 00:14:43,210
all of our operations happen at one

00:14:40,240 --> 00:14:46,390
particular time and and it has to be at

00:14:43,210 --> 00:14:48,280
some point after it starts and before it

00:14:46,390 --> 00:14:50,500
finishes like if you basically send a

00:14:48,280 --> 00:14:52,270
request to a distributed or any database

00:14:50,500 --> 00:14:54,430
or even just like call database an

00:14:52,270 --> 00:14:57,820
embedded database library to set a key

00:14:54,430 --> 00:15:00,940
that that key should be set after you

00:14:57,820 --> 00:15:03,430
call the the set and at some point

00:15:00,940 --> 00:15:06,580
before it actually returns to you it

00:15:03,430 --> 00:15:08,770
sounds obvious but many things don't

00:15:06,580 --> 00:15:10,660
actually act this way but this is a

00:15:08,770 --> 00:15:13,000
really nice property to have and it can

00:15:10,660 --> 00:15:15,580
also be tested in totally a blackbox way

00:15:13,000 --> 00:15:17,140
by just looking at particular operations

00:15:15,580 --> 00:15:18,850
that you might issue in a concurrent way

00:15:17,140 --> 00:15:20,890
from multiple threads or multiple

00:15:18,850 --> 00:15:23,860
servers and then look at the return

00:15:20,890 --> 00:15:25,540
values and then just like after you have

00:15:23,860 --> 00:15:27,880
all the operations that happened and all

00:15:25,540 --> 00:15:29,830
of the return values try to find some

00:15:27,880 --> 00:15:31,750
permutation of those operations and

00:15:29,830 --> 00:15:33,640
return values that could have been done

00:15:31,750 --> 00:15:35,980
by a single thread or a single client

00:15:33,640 --> 00:15:38,830
sequentially and if you can't find that

00:15:35,980 --> 00:15:40,570
then it's not linearizable so I wrote

00:15:38,830 --> 00:15:42,760
this little macro also in the model

00:15:40,570 --> 00:15:44,890
library that can do this for arbitrary

00:15:42,760 --> 00:15:46,770
concurrent data structures in this case

00:15:44,890 --> 00:15:49,540
it's just like using an atomic you size

00:15:46,770 --> 00:15:49,970
so basically imagine like multiple

00:15:49,540 --> 00:15:51,980
threads

00:15:49,970 --> 00:15:53,480
trying to do this buggy ad so atomic you

00:15:51,980 --> 00:15:55,519
size is interesting because you can

00:15:53,480 --> 00:15:58,629
basically have multiple threads change a

00:15:55,519 --> 00:16:00,769
counter or or rather au size value

00:15:58,629 --> 00:16:03,350
without taking out of mutex or anything

00:16:00,769 --> 00:16:05,779
and it relies on atomic operations of

00:16:03,350 --> 00:16:08,810
our CPUs to actually guarantee atomicity

00:16:05,779 --> 00:16:11,449
however if two threads basically get to

00:16:08,810 --> 00:16:15,079
the line where we load the value like

00:16:11,449 --> 00:16:17,089
let current equal I load then two

00:16:15,079 --> 00:16:18,920
threads could basically read like four

00:16:17,089 --> 00:16:21,050
for instance and if one of those threads

00:16:18,920 --> 00:16:22,910
let's say that both of those threads are

00:16:21,050 --> 00:16:25,129
just trying to add one to it if these

00:16:22,910 --> 00:16:26,899
were happening at atomically then we

00:16:25,129 --> 00:16:29,209
would end up with six like plus one plus

00:16:26,899 --> 00:16:31,069
one however if both threads read four

00:16:29,209 --> 00:16:33,740
and then add one to it they'll both try

00:16:31,069 --> 00:16:36,740
to then store five so we just lost a

00:16:33,740 --> 00:16:39,410
right so this is able to basically run

00:16:36,740 --> 00:16:41,509
out these operations concurrently look

00:16:39,410 --> 00:16:43,040
at the return values and then just find

00:16:41,509 --> 00:16:45,050
bugs and your concurrent data structures

00:16:43,040 --> 00:16:46,699
with and look how the little code that

00:16:45,050 --> 00:16:48,920
is like like you think of like

00:16:46,699 --> 00:16:52,009
concurrency testing and like usually

00:16:48,920 --> 00:16:54,769
it's it's like a monstrous amount of

00:16:52,009 --> 00:16:56,000
effort but we can really start to have

00:16:54,769 --> 00:16:58,730
reduced the amount of effort that goes

00:16:56,000 --> 00:17:00,649
into these things and I'd love to keep

00:16:58,730 --> 00:17:02,720
talking about model testing but it's

00:17:00,649 --> 00:17:04,309
time to get like even more torturous but

00:17:02,720 --> 00:17:06,770
these are some really great papers by

00:17:04,309 --> 00:17:09,589
one of the pioneers in model testing

00:17:06,770 --> 00:17:13,039
John Hughes and he's the creator of

00:17:09,589 --> 00:17:14,449
quick check and yeah I highly recommend

00:17:13,039 --> 00:17:15,740
checking out these papers if this is

00:17:14,449 --> 00:17:17,990
something you're interested in they're

00:17:15,740 --> 00:17:22,130
um they're quite accessible and they

00:17:17,990 --> 00:17:23,240
don't use a lot of academic jargon cool

00:17:22,130 --> 00:17:27,140
so what about things that actually do

00:17:23,240 --> 00:17:31,490
i/o like things that use files things

00:17:27,140 --> 00:17:33,230
that use sockets well like we can do

00:17:31,490 --> 00:17:35,120
fault injection for that we have an

00:17:33,230 --> 00:17:36,740
issue where when we deploy things to

00:17:35,120 --> 00:17:38,570
production on possibly like thousands of

00:17:36,740 --> 00:17:41,090
servers or even just give things out to

00:17:38,570 --> 00:17:42,620
a bunch of users they often encounter

00:17:41,090 --> 00:17:43,820
far more problems with the issue then we

00:17:42,620 --> 00:17:46,490
were able to detect when we were doing

00:17:43,820 --> 00:17:47,990
testing on our laptops so our laptops

00:17:46,490 --> 00:17:50,409
tend to be these like serene places

00:17:47,990 --> 00:17:52,460
where not very many things go wrong and

00:17:50,409 --> 00:17:53,870
basically when we build things that work

00:17:52,460 --> 00:17:55,100
well on our laptops that actually

00:17:53,870 --> 00:17:57,169
doesn't guarantee very much about how

00:17:55,100 --> 00:17:58,610
they're going to behave in the world so

00:17:57,169 --> 00:18:00,470
the solution is to basically

00:17:58,610 --> 00:18:00,920
intentionally mess stuff up as we're

00:18:00,470 --> 00:18:03,560
running these

00:18:00,920 --> 00:18:05,660
tests quick aside we can we can mess up

00:18:03,560 --> 00:18:08,030
so many things but like it probably

00:18:05,660 --> 00:18:10,040
would make sense to focus our attention

00:18:08,030 --> 00:18:11,660
real quick so there was a wonderful

00:18:10,040 --> 00:18:14,480
paper that came out of the University of

00:18:11,660 --> 00:18:16,430
Toronto in 2014 called simple testing

00:18:14,480 --> 00:18:18,290
can prevent can prevent most critical

00:18:16,430 --> 00:18:21,380
failures and what they found was that

00:18:18,290 --> 00:18:25,100
like 92% of all critical failures have

00:18:21,380 --> 00:18:27,710
some like like trace of consideration in

00:18:25,100 --> 00:18:29,420
the code like if for instance in rust if

00:18:27,710 --> 00:18:31,040
like if you're doing like a match and

00:18:29,420 --> 00:18:32,690
like there's some match arm that's like

00:18:31,040 --> 00:18:34,490
you know this thing is like an error

00:18:32,690 --> 00:18:35,780
then like maybe you like do a log

00:18:34,490 --> 00:18:39,260
statement about it but don't actually

00:18:35,780 --> 00:18:41,570
fix it things like this where like

00:18:39,260 --> 00:18:43,970
there's like and in almost all critical

00:18:41,570 --> 00:18:45,770
bugs that bring systems down like we

00:18:43,970 --> 00:18:48,020
begin to think about the issue but we

00:18:45,770 --> 00:18:50,720
don't really finish it furthermore in 58

00:18:48,020 --> 00:18:52,430
percent of those cases they could have

00:18:50,720 --> 00:18:54,740
easily been like this could have easily

00:18:52,430 --> 00:18:56,660
been fixed if we just like actually

00:18:54,740 --> 00:18:58,220
trigger those failures and tests so we

00:18:56,660 --> 00:18:59,870
actually don't really need to go too

00:18:58,220 --> 00:19:01,760
overboard with these things we just need

00:18:59,870 --> 00:19:05,360
to actually exercise our testing code

00:19:01,760 --> 00:19:07,010
when we think of things a lot of code

00:19:05,360 --> 00:19:08,480
ends up just looking like this we're

00:19:07,010 --> 00:19:10,670
like you know if there's an error

00:19:08,480 --> 00:19:12,770
somewhere maybe we log it maybe we just

00:19:10,670 --> 00:19:14,360
have a to do or maybe we bring down the

00:19:12,770 --> 00:19:16,250
whole system and I'm not against

00:19:14,360 --> 00:19:17,570
panicking at all like I'm very much a

00:19:16,250 --> 00:19:19,700
fan of like the Erlang let it crash

00:19:17,570 --> 00:19:22,340
philosophy and when you can't guarantee

00:19:19,700 --> 00:19:24,860
safe execution of a system of crashing

00:19:22,340 --> 00:19:26,890
is usually better or very frequently

00:19:24,860 --> 00:19:28,910
better than not continuing at all

00:19:26,890 --> 00:19:31,010
however there's another thing which is

00:19:28,910 --> 00:19:32,960
like unavailability amplification where

00:19:31,010 --> 00:19:35,300
something bad happens and then like you

00:19:32,960 --> 00:19:36,920
do something even worse in response and

00:19:35,300 --> 00:19:39,740
that might not be the best way to handle

00:19:36,920 --> 00:19:42,380
this problem so there's a wonderful

00:19:39,740 --> 00:19:45,290
wonderful crate that a pink cap put out

00:19:42,380 --> 00:19:48,410
called fail and fail is inspired by

00:19:45,290 --> 00:19:49,880
FreeBSD fail points which they used for

00:19:48,410 --> 00:19:52,760
testing their kernel and it basically

00:19:49,880 --> 00:19:55,970
allows you to trigger externally a

00:19:52,760 --> 00:19:58,730
particular particular like return

00:19:55,970 --> 00:20:01,880
statement or it can also cause like a

00:19:58,730 --> 00:20:03,890
thread sleep or scheduler yield and

00:20:01,880 --> 00:20:05,900
basically what you do is in some test

00:20:03,890 --> 00:20:08,060
you basically say hey I'd like to turn

00:20:05,900 --> 00:20:10,490
that fail point on and then when we run

00:20:08,060 --> 00:20:12,750
the code it will basically trigger that

00:20:10,490 --> 00:20:14,670
that error to be returned

00:20:12,750 --> 00:20:18,870
and then we'll basically be able to

00:20:14,670 --> 00:20:20,400
exercise our error-handling logic one

00:20:18,870 --> 00:20:21,870
little gotcha is if you're using

00:20:20,400 --> 00:20:23,700
something like quick check or prop test

00:20:21,870 --> 00:20:25,200
in combination with this they'll often

00:20:23,700 --> 00:20:28,680
be using multiple threads in the same

00:20:25,200 --> 00:20:30,570
process and the fail create has like a

00:20:28,680 --> 00:20:32,580
global registry of which fail points are

00:20:30,570 --> 00:20:34,320
enabled so just like rapid mutex around

00:20:32,580 --> 00:20:38,640
it or something so that they don't

00:20:34,320 --> 00:20:41,160
conflict advanced technique is yet

00:20:38,640 --> 00:20:44,300
combining failed tests or fail points

00:20:41,160 --> 00:20:47,850
with generative testing property tests

00:20:44,300 --> 00:20:51,510
basically it can be kind of a pain to

00:20:47,850 --> 00:20:53,700
like for every possible piece of of

00:20:51,510 --> 00:20:54,840
error handling logic to basically like

00:20:53,700 --> 00:20:56,910
manually trigger that and the test that

00:20:54,840 --> 00:20:58,290
we write but if we just write one test

00:20:56,910 --> 00:21:01,080
like this it'll get around to triggering

00:20:58,290 --> 00:21:03,540
all of them and like depending on how

00:21:01,080 --> 00:21:05,580
much we're able to basically specify our

00:21:03,540 --> 00:21:07,020
expectations about general failures this

00:21:05,580 --> 00:21:09,570
can dramatically reduce the amount of

00:21:07,020 --> 00:21:12,150
effort that goes into it here's an

00:21:09,570 --> 00:21:14,640
example of one test for the sled project

00:21:12,150 --> 00:21:16,890
and I would have never written this test

00:21:14,640 --> 00:21:19,110
it's basically sets a key it deletes the

00:21:16,890 --> 00:21:20,730
same key it triggers one failed point

00:21:19,110 --> 00:21:21,990
and it just goes down this list of

00:21:20,730 --> 00:21:23,640
things I would have just never written

00:21:21,990 --> 00:21:24,900
this test but by having this kind of

00:21:23,640 --> 00:21:25,680
infrastructure that just like creates

00:21:24,900 --> 00:21:27,900
tests for me

00:21:25,680 --> 00:21:29,820
it creates bugs that are like maniacal

00:21:27,900 --> 00:21:32,750
and it's also deterministically

00:21:29,820 --> 00:21:35,010
replayable so it's not so hard to debug

00:21:32,750 --> 00:21:36,990
cool and to learn more about this or

00:21:35,010 --> 00:21:38,310
like working with files rather if you'd

00:21:36,990 --> 00:21:40,590
like to go deeper

00:21:38,310 --> 00:21:43,380
there was another paper that came out in

00:21:40,590 --> 00:21:46,830
2014 which is like a great year and like

00:21:43,380 --> 00:21:48,540
reliability and testing and this one is

00:21:46,830 --> 00:21:51,630
basically about this tool called Alice

00:21:48,540 --> 00:21:54,390
where they're able to basically record

00:21:51,630 --> 00:21:56,910
using a modified s trace of the disk

00:21:54,390 --> 00:21:59,670
operations that commonly use databases

00:21:56,910 --> 00:22:01,170
are using and then based on models of

00:21:59,670 --> 00:22:03,840
different file systems it will replay

00:22:01,170 --> 00:22:05,550
those those operations in ways that

00:22:03,840 --> 00:22:08,160
could have realistically happened on

00:22:05,550 --> 00:22:09,870
different common file systems and then

00:22:08,160 --> 00:22:11,940
just start them up again and see if

00:22:09,870 --> 00:22:13,830
there's any any strange behavior and

00:22:11,940 --> 00:22:15,480
they broke like every database they

00:22:13,830 --> 00:22:16,620
broke like sequel Lite which like

00:22:15,480 --> 00:22:18,150
everyone thinks of as like this

00:22:16,620 --> 00:22:21,390
incredibly well tested database and it

00:22:18,150 --> 00:22:23,550
is but even sequel Lite fell to this

00:22:21,390 --> 00:22:25,020
incredible testing tool so check out

00:22:23,550 --> 00:22:25,980
that paper if you're interested in going

00:22:25,020 --> 00:22:28,490
deeper on like

00:22:25,980 --> 00:22:31,169
particularly like like spy all testing

00:22:28,490 --> 00:22:33,600
cool what about like network sockets and

00:22:31,169 --> 00:22:39,179
just things that end up talking with

00:22:33,600 --> 00:22:42,650
each other yeah using them so one option

00:22:39,179 --> 00:22:45,260
is Jepsen which you might have heard of

00:22:42,650 --> 00:22:47,520
and this is another really cool tool

00:22:45,260 --> 00:22:50,040
basically it's like another one of these

00:22:47,520 --> 00:22:52,049
tools that I'm like pretty much every

00:22:50,040 --> 00:22:55,320
system that it gets turned loose against

00:22:52,049 --> 00:22:56,669
tends to fall it's it's famous for like

00:22:55,320 --> 00:23:00,330
you know bringing down like Redis and

00:22:56,669 --> 00:23:03,090
MongoDB and basically what it does is

00:23:00,330 --> 00:23:05,160
will spin up a cluster and then run some

00:23:03,090 --> 00:23:07,110
workload against that cluster and then

00:23:05,160 --> 00:23:08,220
start partitioning the nodes from each

00:23:07,110 --> 00:23:10,380
other so that they can't talk to each

00:23:08,220 --> 00:23:12,780
other and then after running the

00:23:10,380 --> 00:23:14,400
workload it will look at a trace of the

00:23:12,780 --> 00:23:16,590
like the return values that the

00:23:14,400 --> 00:23:18,330
different clients observed and it will

00:23:16,590 --> 00:23:20,309
like basically do linearize ability

00:23:18,330 --> 00:23:21,960
testing and see if like if this like

00:23:20,309 --> 00:23:24,419
should be allowed or not and it has just

00:23:21,960 --> 00:23:30,090
found so many bugs it's really wonderful

00:23:24,419 --> 00:23:31,740
however it's like it also can be kind of

00:23:30,090 --> 00:23:33,330
expensive to get set up

00:23:31,740 --> 00:23:35,160
it can take like a month it's actually

00:23:33,330 --> 00:23:37,169
like implement it a nice way for a

00:23:35,160 --> 00:23:38,820
particular system and it's like it ends

00:23:37,169 --> 00:23:40,559
up being like so expensive to use that

00:23:38,820 --> 00:23:42,299
like many companies that end up doing it

00:23:40,559 --> 00:23:44,910
end up writing like blog posts about

00:23:42,299 --> 00:23:47,520
like yeah we finally got Jepsen working

00:23:44,910 --> 00:23:49,380
and it's like it's a lot of work and

00:23:47,520 --> 00:23:53,400
also it takes like five minutes per run

00:23:49,380 --> 00:23:55,440
to to work but it is like very nice and

00:23:53,400 --> 00:23:57,929
nothing else fully replaces it because

00:23:55,440 --> 00:24:00,179
it is completely black box which means

00:23:57,929 --> 00:24:01,860
like it will catch like like bugs that

00:24:00,179 --> 00:24:04,830
happen anywhere in the system and that's

00:24:01,860 --> 00:24:06,090
it is quite a nice property and it's if

00:24:04,830 --> 00:24:09,030
you if you can spend that kind of energy

00:24:06,090 --> 00:24:12,929
engineering time on it and it's a cool

00:24:09,030 --> 00:24:15,530
thing to have another option Toa plus so

00:24:12,929 --> 00:24:18,870
Toa plus was created by Leslie Lamport

00:24:15,530 --> 00:24:22,470
he's the person who created like latex

00:24:18,870 --> 00:24:24,690
and Paxos and vector clocks so he's kind

00:24:22,470 --> 00:24:28,650
of like the patron saint of distributed

00:24:24,690 --> 00:24:30,660
systems and basically what this what CoA

00:24:28,650 --> 00:24:33,270
Plus lets you do is describe algorithms

00:24:30,660 --> 00:24:35,549
and also invariants that should hold for

00:24:33,270 --> 00:24:36,260
different kind of interleavings of

00:24:35,549 --> 00:24:37,730
different

00:24:36,260 --> 00:24:39,410
different processes that are running

00:24:37,730 --> 00:24:41,270
through these algorithms and it will

00:24:39,410 --> 00:24:44,870
find violations of those invariants and

00:24:41,270 --> 00:24:47,290
it's very effective at doing this it's

00:24:44,870 --> 00:24:49,730
also intended as like a learning tool

00:24:47,290 --> 00:24:52,100
where like just by using it and learning

00:24:49,730 --> 00:24:53,450
how to like actually write Toa Plus you

00:24:52,100 --> 00:24:55,760
kind of like dramatically improve your

00:24:53,450 --> 00:24:58,970
ability to reason about correct systems

00:24:55,760 --> 00:25:00,620
so I highly recommend learning this also

00:24:58,970 --> 00:25:02,390
it has like a wonderful video course

00:25:00,620 --> 00:25:04,580
where he's like wearing like different

00:25:02,390 --> 00:25:06,290
fuzzy hats and things and like it's

00:25:04,580 --> 00:25:09,799
worth watching just for the hats but the

00:25:06,290 --> 00:25:12,890
content is also incredible and also a

00:25:09,799 --> 00:25:14,809
Hallel has a site learn Toa comm which

00:25:12,890 --> 00:25:18,049
is wonderful for getting into it as well

00:25:14,809 --> 00:25:19,910
so it's a really cool tool but it has

00:25:18,049 --> 00:25:21,770
this like it is another language and

00:25:19,910 --> 00:25:23,000
then there's this question of like okay

00:25:21,770 --> 00:25:24,260
we described our algorithm in this

00:25:23,000 --> 00:25:26,840
language and then we have this

00:25:24,260 --> 00:25:28,820
implementation and like like there's is

00:25:26,840 --> 00:25:30,169
there a gap like is my implementation

00:25:28,820 --> 00:25:32,419
actually doing what I expect

00:25:30,169 --> 00:25:36,010
sometimes that that's a that's a

00:25:32,419 --> 00:25:39,110
challenge cool and add the option that

00:25:36,010 --> 00:25:41,960
I'm going to go farther into is network

00:25:39,110 --> 00:25:43,820
simulation and that's where we just kind

00:25:41,960 --> 00:25:45,980
of like start off building our system in

00:25:43,820 --> 00:25:50,419
a way that is very amenable to fast

00:25:45,980 --> 00:25:51,860
testing in a deterministic way and it

00:25:50,419 --> 00:25:56,480
can be like just like extremely

00:25:51,860 --> 00:25:57,799
efficient like yeah basically can run

00:25:56,480 --> 00:26:01,730
like thousands of tests per second it's

00:25:57,799 --> 00:26:03,020
it's incredible also like one issue with

00:26:01,730 --> 00:26:05,480
fault injection in general is like

00:26:03,020 --> 00:26:07,390
sometimes it can be like a question

00:26:05,480 --> 00:26:10,280
about like which things do you actually

00:26:07,390 --> 00:26:11,830
break like you know you can break so

00:26:10,280 --> 00:26:14,000
many things so how do you focus it

00:26:11,830 --> 00:26:16,309
lineage driven fault injection I'll get

00:26:14,000 --> 00:26:18,679
into in a second is one way to do that

00:26:16,309 --> 00:26:20,059
and it's very it works very well with

00:26:18,679 --> 00:26:22,280
something that you build from the

00:26:20,059 --> 00:26:25,309
beginning to be to basically run on a

00:26:22,280 --> 00:26:26,660
simulator it's I've been building if

00:26:25,309 --> 00:26:28,370
like distributed systems on top of

00:26:26,660 --> 00:26:30,650
simulators for like about like the last

00:26:28,370 --> 00:26:33,559
year and it's I just have to say that

00:26:30,650 --> 00:26:36,020
like I have never caught so many bugs so

00:26:33,559 --> 00:26:38,299
early with like so much ease as when I

00:26:36,020 --> 00:26:40,070
started doing this it's something that

00:26:38,299 --> 00:26:42,590
kind of sounds like it has a high cost

00:26:40,070 --> 00:26:44,750
initially but once you try it you're

00:26:42,590 --> 00:26:46,909
just instantly hooked and and like you

00:26:44,750 --> 00:26:48,450
never like you never feel safe writing

00:26:46,909 --> 00:26:50,490
distributed systems code what

00:26:48,450 --> 00:26:52,680
- simulator again in the future you just

00:26:50,490 --> 00:26:54,450
find so many bugs that you're totally

00:26:52,680 --> 00:26:55,800
like you would have never you would have

00:26:54,450 --> 00:26:58,500
never thought to check for it it's

00:26:55,800 --> 00:27:00,870
incredible so I'll just kind of like

00:26:58,500 --> 00:27:02,450
give you kind of like a skeleton view of

00:27:00,870 --> 00:27:04,710
like how you might implement a simulator

00:27:02,450 --> 00:27:08,850
one way to do it is by basically having

00:27:04,710 --> 00:27:11,550
a trait receive that on basically at a

00:27:08,850 --> 00:27:13,650
given time you you have like some node

00:27:11,550 --> 00:27:16,320
and it receives a message from a peer

00:27:13,650 --> 00:27:20,450
and you're basically given a message at

00:27:16,320 --> 00:27:23,160
that time from that peer and in order to

00:27:20,450 --> 00:27:24,750
unbale you just respond with a vector of

00:27:23,160 --> 00:27:26,850
outgoing messages in response to that

00:27:24,750 --> 00:27:29,070
and by having this deterministic mapping

00:27:26,850 --> 00:27:30,510
between inputs and outputs we can

00:27:29,070 --> 00:27:34,050
basically start running our clusters in

00:27:30,510 --> 00:27:36,210
accelerated time can generate a cluster

00:27:34,050 --> 00:27:38,370
also using something like quick check or

00:27:36,210 --> 00:27:40,620
or prop test where we generate a random

00:27:38,370 --> 00:27:42,060
set of partitions which are basically

00:27:40,620 --> 00:27:44,400
pairs of nodes that can't communicate

00:27:42,060 --> 00:27:47,070
with each other at particular times and

00:27:44,400 --> 00:27:49,470
then we have like a priority queue

00:27:47,070 --> 00:27:51,390
implemented as a binary heap of all of

00:27:49,470 --> 00:27:54,900
like the messages that are in flight in

00:27:51,390 --> 00:27:57,180
the in the network as well as like the

00:27:54,900 --> 00:27:59,100
the responses that clients get that we

00:27:57,180 --> 00:28:04,500
can basically perform invariant checks

00:27:59,100 --> 00:28:07,500
on after the fact so basically for every

00:28:04,500 --> 00:28:10,110
message in the in-flight priority queue

00:28:07,500 --> 00:28:12,510
we just pop it off we deliver it to the

00:28:10,110 --> 00:28:15,330
destination at the time that we decided

00:28:12,510 --> 00:28:17,820
it should be then we we basically

00:28:15,330 --> 00:28:20,340
deterministically like determine how

00:28:17,820 --> 00:28:23,280
long it should run or rather how long it

00:28:20,340 --> 00:28:25,200
will take to get to its destination then

00:28:23,280 --> 00:28:27,030
we check is that allowed based on the

00:28:25,200 --> 00:28:30,840
partitions that we we just came up with

00:28:27,030 --> 00:28:32,160
if so skip it if not we basically put it

00:28:30,840 --> 00:28:34,260
back into the priority queue that we

00:28:32,160 --> 00:28:35,220
continue to iterate over and then when

00:28:34,260 --> 00:28:37,590
there's nothing left in the priority

00:28:35,220 --> 00:28:39,210
queue we know that basically our our

00:28:37,590 --> 00:28:41,600
cluster is quiet and now we can run our

00:28:39,210 --> 00:28:45,000
invariant checks on the client responses

00:28:41,600 --> 00:28:46,740
so if this sounds nice but you know it's

00:28:45,000 --> 00:28:48,180
like a whole cluster in a box and that

00:28:46,740 --> 00:28:50,580
sounds really complex how do you choose

00:28:48,180 --> 00:28:52,380
like efficiently which things to add to

00:28:50,580 --> 00:28:53,460
mess with and that's where something

00:28:52,380 --> 00:28:56,850
called lineage driven fault injection

00:28:53,460 --> 00:28:59,360
comes in basically it just looks at the

00:28:56,850 --> 00:29:02,780
things that go right and and

00:28:59,360 --> 00:29:06,020
deterministically like pics different

00:29:02,780 --> 00:29:07,460
permutations of them to mess up you

00:29:06,020 --> 00:29:10,429
start with the very last thing so

00:29:07,460 --> 00:29:11,990
imagine like a chain of messages like

00:29:10,429 --> 00:29:13,790
you're like passing a secret long from

00:29:11,990 --> 00:29:15,620
one person to another and then you just

00:29:13,790 --> 00:29:17,600
basically pick like the last person who

00:29:15,620 --> 00:29:19,760
sent it and just like nope nope you do

00:29:17,600 --> 00:29:23,179
not send it and just like work your way

00:29:19,760 --> 00:29:25,130
backwards and then see what happens

00:29:23,179 --> 00:29:26,929
so Peter Alvaro one of the creators of

00:29:25,130 --> 00:29:29,150
lineage driven fault injection has a

00:29:26,929 --> 00:29:30,770
nice quote which is fault tolerance is

00:29:29,150 --> 00:29:33,770
redundancy and space and time so

00:29:30,770 --> 00:29:35,660
basically if that message being dropped

00:29:33,770 --> 00:29:38,059
does not affect the overall correctness

00:29:35,660 --> 00:29:41,030
of the system like if it is retried then

00:29:38,059 --> 00:29:42,440
we're still good and when we're building

00:29:41,030 --> 00:29:43,910
things that are simulator friendly to

00:29:42,440 --> 00:29:46,940
begin with it basically makes this

00:29:43,910 --> 00:29:48,700
extremely easy to do and I'm working on

00:29:46,940 --> 00:29:51,710
a crate for this right now

00:29:48,700 --> 00:29:52,730
cool we want our stuff to be

00:29:51,710 --> 00:29:55,040
deterministic though if it's going to

00:29:52,730 --> 00:29:56,750
work well in a simulator so for that we

00:29:55,040 --> 00:29:59,030
need to control our clocks random number

00:29:56,750 --> 00:30:01,760
generators and also our like the way

00:29:59,030 --> 00:30:04,040
that our threads are scheduled basically

00:30:01,760 --> 00:30:05,720
you can control threads using Linux real

00:30:04,040 --> 00:30:08,480
time priorities as well as like P trace

00:30:05,720 --> 00:30:10,490
and other things files can be wrapped in

00:30:08,480 --> 00:30:12,110
a mutation log that basically just

00:30:10,490 --> 00:30:13,490
measured like keeps track of what

00:30:12,110 --> 00:30:15,169
threads are doing what writes at what

00:30:13,490 --> 00:30:17,090
time and then when synchronization

00:30:15,169 --> 00:30:18,470
happens and then like if you want to

00:30:17,090 --> 00:30:20,600
basically simulate some kind of crash

00:30:18,470 --> 00:30:22,760
you basically just like you know flip

00:30:20,600 --> 00:30:24,140
the flag from the test and then just

00:30:22,760 --> 00:30:25,790
like allowing no more rights or sinks

00:30:24,140 --> 00:30:27,679
and then when you like restart the

00:30:25,790 --> 00:30:29,419
system just you know deterministically

00:30:27,679 --> 00:30:31,610
choose some subset of that data that was

00:30:29,419 --> 00:30:32,360
written since the last thing to drop and

00:30:31,610 --> 00:30:34,880
you can check out the crate

00:30:32,360 --> 00:30:36,860
deterministic for like deterministic

00:30:34,880 --> 00:30:39,200
versions of clocks or NGS

00:30:36,860 --> 00:30:41,090
and also using linux real-time as

00:30:39,200 --> 00:30:44,080
priorities and i'm working on the file

00:30:41,090 --> 00:30:46,309
thing also miscellaneous things

00:30:44,080 --> 00:30:49,970
generally isolate business logic from

00:30:46,309 --> 00:30:52,000
i/o concerns and control flow logic this

00:30:49,970 --> 00:30:55,070
is something I noticed a lot of people

00:30:52,000 --> 00:30:58,100
who are writing things using futures and

00:30:55,070 --> 00:31:03,530
asynchronous code kind of violating the

00:30:58,100 --> 00:31:05,299
idea of basically like we we would do

00:31:03,530 --> 00:31:07,940
well to the extent that we set like like

00:31:05,299 --> 00:31:09,980
separate concerns we can take advantage

00:31:07,940 --> 00:31:12,200
of all the performance benefits of

00:31:09,980 --> 00:31:13,090
asynchronous code without basically

00:31:12,200 --> 00:31:15,370
mixing over

00:31:13,090 --> 00:31:17,020
it's logic into it and and there's I

00:31:15,370 --> 00:31:19,570
mean this is not true in every case but

00:31:17,020 --> 00:31:20,620
in most cases it is and I think this is

00:31:19,570 --> 00:31:23,080
something that we should strive for for

00:31:20,620 --> 00:31:25,090
understandability also use the certs and

00:31:23,080 --> 00:31:28,480
debug sorts everywhere when basically

00:31:25,090 --> 00:31:30,310
testing our our code and random ways

00:31:28,480 --> 00:31:33,700
having lots of these asserts will

00:31:30,310 --> 00:31:35,980
basically check lots of assumptions use

00:31:33,700 --> 00:31:37,840
them use debug assert if you're

00:31:35,980 --> 00:31:40,090
concerned about performance implications

00:31:37,840 --> 00:31:42,280
because it gets compiled away and try to

00:31:40,090 --> 00:31:43,630
use expect instead of unwrap to give the

00:31:42,280 --> 00:31:45,040
poor people who have to deal with the

00:31:43,630 --> 00:31:47,740
panics that are inevitable with calling

00:31:45,040 --> 00:31:49,840
unwrap a little bit of information to

00:31:47,740 --> 00:31:51,750
help them when it happens and also when

00:31:49,840 --> 00:31:54,130
you propagate errors try to include

00:31:51,750 --> 00:31:56,230
context so for instance using the

00:31:54,130 --> 00:31:57,160
failure crate can be nice for this cool

00:31:56,230 --> 00:31:59,820
go break systems

00:31:57,160 --> 00:31:59,820
thank you

00:32:01,100 --> 00:32:04,230

YouTube URL: https://www.youtube.com/watch?v=hMJEPWcSD8w


