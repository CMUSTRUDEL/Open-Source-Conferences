Title: RustFest Paris 2018 -  Immutable Data Structures and why You want them by Bodil Stokke
Publication date: 2018-05-26
Playlist: RustFest Paris 2018
Description: 
	An applause for Bodil Stokke please
with immutable structures at ease
though her twitter explains
she is asking for brains
she'll only fill them with ideas

There’s a discrepancy between the careful attention to mutability and immutability in Rust itself and the data structures available in the standard library. The only way to update a Vec with an immutable ref is to clone it first, which could get expensive. But what else can you do?  Turns out there’s a number of data structures out there that make it cheap and easy to do immutable copies and updates. Some are so simple it’s ridiculous, some are anything but, and we’re going to dive into some of the more useful ones, how they work, why you should care, and how to best implement them in Rust.

(Limerick by @llogiq)

https://paris.rustfest.eu/sessions/immutable-data-structures
Captions: 
	00:00:06,859 --> 00:00:11,840
and a place for bodies Tucker please

00:00:16,350 --> 00:00:23,289
with rust data structures at ease the

00:00:20,950 --> 00:00:31,630
hatate explains he is asking for brains

00:00:23,289 --> 00:00:38,010
she will only fill them with IDs good

00:00:31,630 --> 00:00:38,010
morning I'm sort of awake how about you

00:00:38,460 --> 00:00:48,820
it's just me or is the sound good now

00:00:42,120 --> 00:00:51,640
excellent okay hi I'm Bodhi and I've

00:00:48,820 --> 00:00:55,000
been writing this library for immutable

00:00:51,640 --> 00:00:56,920
data structures in rust called immutable

00:00:55,000 --> 00:01:04,570
does Horace is the domain name it's just

00:00:56,920 --> 00:01:07,380
in on cargo on Christ at i/o and I'd

00:01:04,570 --> 00:01:10,930
like to basically run you through them I

00:01:07,380 --> 00:01:13,330
expected this talk to be to have a lot

00:01:10,930 --> 00:01:16,060
of code and a lot of fancy examples and

00:01:13,330 --> 00:01:18,340
live coding and I wrote it on it turns

00:01:16,060 --> 00:01:21,369
out it's mostly diagrams about how

00:01:18,340 --> 00:01:24,700
amazing data structures are so prepare

00:01:21,369 --> 00:01:28,149
for some graph theory I guess first of

00:01:24,700 --> 00:01:34,119
all this is dawn dawn is going to be a

00:01:28,149 --> 00:01:36,999
background for today Don is a relatively

00:01:34,119 --> 00:01:39,219
famous computer scientist and this is

00:01:36,999 --> 00:01:40,899
one of his most exciting his most

00:01:39,219 --> 00:01:42,880
favorite subjects so he's very excited

00:01:40,899 --> 00:01:44,530
for you to learn about data structures

00:01:42,880 --> 00:01:46,499
today it's gonna be there in the

00:01:44,530 --> 00:01:49,210
background all the time cheering you on

00:01:46,499 --> 00:01:50,979
if I get too complicated you should

00:01:49,210 --> 00:01:59,369
absolutely feel free to interrupt me and

00:01:50,979 --> 00:02:02,560
ask me to clarify so let's get started

00:01:59,369 --> 00:02:03,429
what is the data structure let's start

00:02:02,560 --> 00:02:08,289
with the like the fundamental

00:02:03,429 --> 00:02:12,670
definitions here anybody care to offer

00:02:08,289 --> 00:02:14,440
an opinion no I said in the morning for

00:02:12,670 --> 00:02:16,090
that I'm just gonna give you the the

00:02:14,440 --> 00:02:17,950
thing I got when I asked Google what is

00:02:16,090 --> 00:02:20,050
the data structure a way of organizing

00:02:17,950 --> 00:02:22,720
data so that it can be accessed and

00:02:20,050 --> 00:02:25,680
modified efficiently which is just sort

00:02:22,720 --> 00:02:29,730
of a fancy generic way of saying a list

00:02:25,680 --> 00:02:32,050
or a map or a key value store or

00:02:29,730 --> 00:02:34,720
keystore without the values which will

00:02:32,050 --> 00:02:36,190
be asset and and various other things

00:02:34,720 --> 00:02:39,330
that you don't see quite as much in

00:02:36,190 --> 00:02:45,880
standard library it's like graphs and

00:02:39,330 --> 00:02:48,880
matrices and that sort of thing and this

00:02:45,880 --> 00:02:51,940
that word immutable that I was using in

00:02:48,880 --> 00:02:54,990
the title of this talk so we need to

00:02:51,940 --> 00:02:57,790
know about mutable versus immutable and

00:02:54,990 --> 00:02:59,410
this is the idea that something that is

00:02:57,790 --> 00:03:03,040
mutable that means it's changeable

00:02:59,410 --> 00:03:06,250
essentially a good example of a mutable

00:03:03,040 --> 00:03:09,070
data structure or a mutable value is a

00:03:06,250 --> 00:03:10,600
vac where it's an immutable value would

00:03:09,070 --> 00:03:12,490
be something like a number because you

00:03:10,600 --> 00:03:13,810
can't really change a number I mean if

00:03:12,490 --> 00:03:15,730
you got a variable with a number in it

00:03:13,810 --> 00:03:17,320
you can change what number is than the

00:03:15,730 --> 00:03:19,510
variable but you can't take the number

00:03:17,320 --> 00:03:23,500
four and make it be the number five from

00:03:19,510 --> 00:03:25,660
now on for instance but with a vac if

00:03:23,500 --> 00:03:27,310
you change the back.the it's something

00:03:25,660 --> 00:03:30,460
else now essentially if you add

00:03:27,310 --> 00:03:33,270
something to the end of it then the vac

00:03:30,460 --> 00:03:37,480
has kind of a new value inside it that

00:03:33,270 --> 00:03:40,480
makes it mutable and then there's

00:03:37,480 --> 00:03:43,240
persistent data structures that's sort

00:03:40,480 --> 00:03:45,880
of the technical term for something that

00:03:43,240 --> 00:03:47,890
isn't mutable and it's exactly that a

00:03:45,880 --> 00:03:50,020
data structure that persists is current

00:03:47,890 --> 00:03:52,450
state won't changed which basically

00:03:50,020 --> 00:03:54,640
means if you change it you don't really

00:03:52,450 --> 00:03:57,130
change it you just get a new value back

00:03:54,640 --> 00:03:58,750
it's like two plus two you don't change

00:03:57,130 --> 00:04:03,790
the number two by adding two to it you

00:03:58,750 --> 00:04:05,800
get the number four back so we also need

00:04:03,790 --> 00:04:08,739
to talk about complexity we need to have

00:04:05,800 --> 00:04:11,440
some sort of a vocabulary for being able

00:04:08,739 --> 00:04:14,320
to talk about the efficiency of

00:04:11,440 --> 00:04:16,720
operations on on data structures like

00:04:14,320 --> 00:04:19,540
say adding an element to the back of a

00:04:16,720 --> 00:04:22,450
list so I'm going to introduce you to

00:04:19,540 --> 00:04:23,230
Big O notation by going to keep it to

00:04:22,450 --> 00:04:26,290
the basics

00:04:23,230 --> 00:04:29,740
they worry too much I'm only going to

00:04:26,290 --> 00:04:31,510
talk about the pieces of Big O notation

00:04:29,740 --> 00:04:34,210
that you tend to see most and when

00:04:31,510 --> 00:04:36,730
talking about data structures and the

00:04:34,210 --> 00:04:39,130
simplest one by far is what we will call

00:04:36,730 --> 00:04:42,580
constant time operations we write that

00:04:39,130 --> 00:04:43,240
as oh one so the Big O notation comes

00:04:42,580 --> 00:04:45,509
from the big

00:04:43,240 --> 00:04:48,430
Oh in front of the parentheses here and

00:04:45,509 --> 00:04:50,380
sort of them what kind of big o-notation

00:04:48,430 --> 00:04:55,150
we're talking about it is what is inside

00:04:50,380 --> 00:04:57,490
the parentheses and this means that for

00:04:55,150 --> 00:05:01,020
a given operation if it runs in constant

00:04:57,490 --> 00:05:05,590
time you need the same amount of

00:05:01,020 --> 00:05:09,270
operations to perform it as a regardless

00:05:05,590 --> 00:05:12,729
of how large the data structure is

00:05:09,270 --> 00:05:14,110
whereas with linear time that's

00:05:12,729 --> 00:05:17,680
basically walking through the entire

00:05:14,110 --> 00:05:20,860
data structure element by element it's

00:05:17,680 --> 00:05:22,990
proportional to the the size of the data

00:05:20,860 --> 00:05:25,800
structure or the length of the list or

00:05:22,990 --> 00:05:29,830
whatever you you like to call it

00:05:25,800 --> 00:05:33,130
then there's logarithmic time that's a

00:05:29,830 --> 00:05:35,800
log n but where the number of operations

00:05:33,130 --> 00:05:37,780
you have to perform is logarithmic to

00:05:35,800 --> 00:05:39,849
the south of the data structure and this

00:05:37,780 --> 00:05:41,710
is what you would see if you say if

00:05:39,849 --> 00:05:42,509
you're walking down a single branch of a

00:05:41,710 --> 00:05:45,610
tree

00:05:42,509 --> 00:05:48,340
it's there's not as good as linear time

00:05:45,610 --> 00:05:49,960
oh sorry it's not as good as constant

00:05:48,340 --> 00:05:55,389
time but it's a look better than linear

00:05:49,960 --> 00:05:56,380
time by far usually so basically these

00:05:55,389 --> 00:05:58,570
are the three we need to pay attention

00:05:56,380 --> 00:06:01,810
to and they're ordered by how good they

00:05:58,570 --> 00:06:03,969
are or rather how fast they are because

00:06:01,810 --> 00:06:06,190
the time is best the great 'fuck time is

00:06:03,969 --> 00:06:09,219
still pretty good linear time is not

00:06:06,190 --> 00:06:11,729
right we tend to to want to not have to

00:06:09,219 --> 00:06:14,469
use operations that require linear time

00:06:11,729 --> 00:06:16,750
there's also you might see this one

00:06:14,469 --> 00:06:21,580
linear time slow rhythmic time oh and

00:06:16,750 --> 00:06:23,080
again this is it should be the

00:06:21,580 --> 00:06:27,430
worst-case performance for something

00:06:23,080 --> 00:06:29,889
like a sort operation some sort

00:06:27,430 --> 00:06:32,259
operations front to to polynomial time

00:06:29,889 --> 00:06:33,699
oh and squared but if you see that

00:06:32,259 --> 00:06:37,120
you're using a very bad sorting

00:06:33,699 --> 00:06:39,219
algorithm the best ones would would

00:06:37,120 --> 00:06:43,719
perform in linear time in the very best

00:06:39,219 --> 00:06:44,800
case and in n log n time but we're not

00:06:43,719 --> 00:06:47,919
going to be seeing any animal again

00:06:44,800 --> 00:06:50,680
today there's also this idea of a

00:06:47,919 --> 00:06:52,570
motorisation which means basically that

00:06:50,680 --> 00:06:55,449
the cost of an operation can be spread

00:06:52,570 --> 00:06:57,599
out over several operations and

00:06:55,449 --> 00:07:01,990
I'm going to illustrate this by example

00:06:57,599 --> 00:07:03,580
this is an array it's about the simplest

00:07:01,990 --> 00:07:05,439
data structure you can think of

00:07:03,580 --> 00:07:08,639
it's just basically a chunk of memory

00:07:05,439 --> 00:07:14,830
that you've allocated and you've put

00:07:08,639 --> 00:07:17,319
your elements in sequence inside it in

00:07:14,830 --> 00:07:19,659
rust you might have used the vector data

00:07:17,319 --> 00:07:22,839
structure it's about the most basic data

00:07:19,659 --> 00:07:25,150
structure in rust the vak is kind of

00:07:22,839 --> 00:07:27,400
like an array except it's got the added

00:07:25,150 --> 00:07:29,800
optimization that if you look at the

00:07:27,400 --> 00:07:35,199
array what would be the cost of adding

00:07:29,800 --> 00:07:36,819
something at the end oh and somebody

00:07:35,199 --> 00:07:38,589
said that's quite correct because what

00:07:36,819 --> 00:07:41,889
you have to do in this case because it's

00:07:38,589 --> 00:07:44,289
completely it's allocated to the extent

00:07:41,889 --> 00:07:45,999
of it is you basically have to allocate

00:07:44,289 --> 00:07:48,580
a new section of memory copy this and

00:07:45,999 --> 00:07:49,830
then add your element at the end that's

00:07:48,580 --> 00:07:53,349
linear time

00:07:49,830 --> 00:07:55,419
so the vac has this optimization where

00:07:53,349 --> 00:07:57,520
it pre allocates some memory that it

00:07:55,419 --> 00:07:58,990
thinks you're probably going to use and

00:07:57,520 --> 00:08:02,229
then it keeps track of the action size

00:07:58,990 --> 00:08:05,620
of your of your your vector and the the

00:08:02,229 --> 00:08:07,479
capacity of it so what will be the cost

00:08:05,620 --> 00:08:13,419
of adding an element at the back of this

00:08:07,479 --> 00:08:17,439
vector constant time linear constant

00:08:13,419 --> 00:08:21,610
time oh one if you do that four times

00:08:17,439 --> 00:08:23,830
however you run out of space and the

00:08:21,610 --> 00:08:26,949
cost at that point that would be linear

00:08:23,830 --> 00:08:29,169
time that will be o n so basically what

00:08:26,949 --> 00:08:32,169
we've done here is is with amortized the

00:08:29,169 --> 00:08:35,139
cost of pushing to the end of it by pre

00:08:32,169 --> 00:08:37,479
allocating some memory so that for most

00:08:35,139 --> 00:08:41,380
operations like this it's going to be a

00:08:37,479 --> 00:08:43,389
constant time but sometimes it's going

00:08:41,380 --> 00:08:47,380
to be a lot more expensive and that's a

00:08:43,389 --> 00:08:49,500
motorisation I'm going to introduce you

00:08:47,380 --> 00:08:54,430
to your first persistent data structure

00:08:49,500 --> 00:08:57,069
there's no classic this was invented

00:08:54,430 --> 00:09:00,519
back in the 50s along with a language

00:08:57,069 --> 00:09:02,940
you might have heard of called Lisp what

00:09:00,519 --> 00:09:04,980
you're saying here is a cons cell

00:09:02,940 --> 00:09:08,910
it's basically just a chunk of memory

00:09:04,980 --> 00:09:13,370
that contains two values like an array

00:09:08,910 --> 00:09:16,590
of size two but it's structured so that

00:09:13,370 --> 00:09:19,890
the left-hand side the the first element

00:09:16,590 --> 00:09:23,330
contains a value and the right-hand side

00:09:19,890 --> 00:09:28,500
contains a pointer to another console or

00:09:23,330 --> 00:09:32,460
possibly an empty value which means

00:09:28,500 --> 00:09:35,580
there is no more to this list there are

00:09:32,460 --> 00:09:39,720
no further elements and so you can use

00:09:35,580 --> 00:09:44,280
this to construct basically what is a

00:09:39,720 --> 00:09:47,460
very unbalanced binary tree but it also

00:09:44,280 --> 00:09:49,380
happens to be a list so that in this

00:09:47,460 --> 00:09:52,800
case we got a list with two elements

00:09:49,380 --> 00:09:55,170
Mike and Robert and so you see the first

00:09:52,800 --> 00:09:59,400
console that contains the value of Mike

00:09:55,170 --> 00:10:01,890
and it points to the next console which

00:09:59,400 --> 00:10:03,900
is kind of another list on its own which

00:10:01,890 --> 00:10:05,190
contains the value Robert and an empty

00:10:03,900 --> 00:10:14,360
pointer which means we're done with the

00:10:05,190 --> 00:10:17,300
list and so the clever bit here is that

00:10:14,360 --> 00:10:20,010
appending to the front of the list is

00:10:17,300 --> 00:10:22,470
actually a constant time operation it's

00:10:20,010 --> 00:10:26,100
blindingly fast because what you do is

00:10:22,470 --> 00:10:27,630
basically you create a new list with the

00:10:26,100 --> 00:10:29,990
value that you want to put up front and

00:10:27,630 --> 00:10:32,760
a pointer to this list

00:10:29,990 --> 00:10:36,180
it's called kunsing and it looks like

00:10:32,760 --> 00:10:38,790
this so now we've got Joe in front of

00:10:36,180 --> 00:10:41,220
Mike and Roberts in the nest by

00:10:38,790 --> 00:10:43,260
consoling him to the front of it and

00:10:41,220 --> 00:10:48,390
you'll notice that if you disregard

00:10:43,260 --> 00:10:49,920
Joe's console this is still just the

00:10:48,390 --> 00:10:52,830
lists with Mike and Robert in it we

00:10:49,920 --> 00:10:54,720
haven't changed anything inside the Mike

00:10:52,830 --> 00:10:56,790
and Robert list we've just sort of

00:10:54,720 --> 00:10:59,130
created a new list which contains Joe

00:10:56,790 --> 00:11:01,710
and then the micro robert list so that

00:10:59,130 --> 00:11:03,600
goes to Mike and Robert now but we are

00:11:01,710 --> 00:11:04,920
sharing structure with the Mike and

00:11:03,600 --> 00:11:06,870
Robert list you could have capture

00:11:04,920 --> 00:11:10,050
reference to the microbe list as well

00:11:06,870 --> 00:11:12,839
and now you've got two lists Jo Mike and

00:11:10,050 --> 00:11:14,730
Robert and Mike and Robert and they are

00:11:12,839 --> 00:11:15,510
sharing most of their structure most of

00:11:14,730 --> 00:11:17,910
the memory

00:11:15,510 --> 00:11:23,070
and it wasn't really fast adding to the

00:11:17,910 --> 00:11:24,920
front back you can't do that okay this

00:11:23,070 --> 00:11:28,699
is my favorite part

00:11:24,920 --> 00:11:31,740
so for historical reasons the cons now

00:11:28,699 --> 00:11:33,930
the names of the two elements inside the

00:11:31,740 --> 00:11:39,589
console are called the car and the

00:11:33,930 --> 00:11:44,279
cutter this might not seem too obvious

00:11:39,589 --> 00:11:48,449
to you but it comes from back in the day

00:11:44,279 --> 00:11:52,490
on the IBM 704 mainframe on which list

00:11:48,449 --> 00:11:54,810
was originally implemented what these

00:11:52,490 --> 00:11:57,350
these are actually abbreviations they

00:11:54,810 --> 00:12:01,230
mean constants of address register and

00:11:57,350 --> 00:12:06,810
contents of decrement register so now it

00:12:01,230 --> 00:12:09,449
makes sense yes so yeah this machine had

00:12:06,810 --> 00:12:11,339
five registers in total I guess one of

00:12:09,449 --> 00:12:13,740
them was the address register and I

00:12:11,339 --> 00:12:15,899
think it had three decrement registers

00:12:13,740 --> 00:12:18,089
which were sort of officers into that

00:12:15,899 --> 00:12:19,740
but they were just using it using them

00:12:18,089 --> 00:12:20,880
to hold like the current the value of

00:12:19,740 --> 00:12:25,010
the current console that you were

00:12:20,880 --> 00:12:28,709
looking at so so these names stuck and

00:12:25,010 --> 00:12:30,410
they're a bit confusing to be fair but I

00:12:28,709 --> 00:12:33,089
love them because they actually compose

00:12:30,410 --> 00:12:37,529
this is the thing that they did back in

00:12:33,089 --> 00:12:42,540
back in back in the day when Lisp was a

00:12:37,529 --> 00:12:45,209
big deal so you had the cauda which is

00:12:42,540 --> 00:12:47,069
the core of the cutter so the core

00:12:45,209 --> 00:12:48,690
basically I have this works now is the

00:12:47,069 --> 00:12:51,380
core is the first element of the list

00:12:48,690 --> 00:12:54,180
and the cutter is the rest of the list

00:12:51,380 --> 00:12:56,550
as you remember so the core of the

00:12:54,180 --> 00:12:58,050
khajit would be the second element you

00:12:56,550 --> 00:12:59,910
take the cutter first and then you get

00:12:58,050 --> 00:13:06,240
the core of that and that is the second

00:12:59,910 --> 00:13:11,459
element of the list like but we mike and

00:13:06,240 --> 00:13:12,480
then you have the Kidada the core of the

00:13:11,459 --> 00:13:16,800
country of the cutter the third element

00:13:12,480 --> 00:13:20,310
and the cutter the quadrille decoder

00:13:16,800 --> 00:13:23,579
which is everything but the first and

00:13:20,310 --> 00:13:26,970
second elements of the list and I may

00:13:23,579 --> 00:13:28,980
have made this up but the car is the car

00:13:26,970 --> 00:13:29,430
of the car which is the first element of

00:13:28,980 --> 00:13:30,750
the first

00:13:29,430 --> 00:13:35,160
and assuming the first element is

00:13:30,750 --> 00:13:38,610
another list they had fun back in the

00:13:35,160 --> 00:13:39,810
day but in most sensible languages

00:13:38,610 --> 00:13:40,970
nowaday which has called them the head

00:13:39,810 --> 00:13:43,560
in the tail

00:13:40,970 --> 00:13:47,750
bonus point incidentally can you name

00:13:43,560 --> 00:13:54,750
this Pokemon crostini you are very good

00:13:47,750 --> 00:13:57,240
I'm so impressed about this one Suda we

00:13:54,750 --> 00:14:00,020
do very good this is actually the second

00:13:57,240 --> 00:14:03,420
generation Pokemon I have to look it up

00:14:00,020 --> 00:14:06,320
I'm poking my champion of the original

00:14:03,420 --> 00:14:14,640
game but the others I'm too old for that

00:14:06,320 --> 00:14:16,290
anyway let's talk about trees so this is

00:14:14,640 --> 00:14:20,160
this is a lookup tree this is a binary

00:14:16,290 --> 00:14:24,600
tree that we use to look up values in an

00:14:20,160 --> 00:14:28,050
ordered sequence numbers have ordering

00:14:24,600 --> 00:14:30,450
we agree on this I hope so if we're

00:14:28,050 --> 00:14:32,910
going to look up the element 3 in in a

00:14:30,450 --> 00:14:34,709
list that looks like this how would we

00:14:32,910 --> 00:14:38,640
go about it we have a pointer to that to

00:14:34,709 --> 00:14:39,990
the top of the tree that's what we got

00:14:38,640 --> 00:14:41,550
and we know that we're looking up the

00:14:39,990 --> 00:14:45,209
number 3 and we know that the keys are

00:14:41,550 --> 00:14:47,400
ordered so we start out before is free

00:14:45,209 --> 00:14:50,610
larger than 4 or is it smaller than 4

00:14:47,400 --> 00:14:53,430
it's smaller so we go to the left with

00:14:50,610 --> 00:14:56,610
finally - it's free larger than 2 or

00:14:53,430 --> 00:14:59,550
smaller than 2 it's larger so we go to

00:14:56,610 --> 00:15:01,560
the right and we find the 3 and 3

00:14:59,550 --> 00:15:06,540
happens to be equal to 3 so we found our

00:15:01,560 --> 00:15:09,570
note so 3 is indeed in this set that's

00:15:06,540 --> 00:15:11,070
the look of operation and this is where

00:15:09,570 --> 00:15:15,360
it gets clever because we also want to

00:15:11,070 --> 00:15:17,579
be able to update this suppose that this

00:15:15,360 --> 00:15:20,490
is a map not just a set suppose as a

00:15:17,579 --> 00:15:23,820
value stored in the 3 notes along with

00:15:20,490 --> 00:15:25,680
the key 3 so we want to be able to

00:15:23,820 --> 00:15:27,300
update this but we want to be able to

00:15:25,680 --> 00:15:30,839
have the same effect as with the

00:15:27,300 --> 00:15:32,730
constant list we want - well we wanted

00:15:30,839 --> 00:15:35,160
to be a persistent data structure and we

00:15:32,730 --> 00:15:37,589
want that structure and sharing thing so

00:15:35,160 --> 00:15:42,270
what we do then is we are going just

00:15:37,589 --> 00:15:43,740
start to have to copy things now but

00:15:42,270 --> 00:15:46,260
we don't have to copy the entire thing

00:15:43,740 --> 00:15:47,700
we have to find the path than to the

00:15:46,260 --> 00:15:50,279
node that we are interested in changing

00:15:47,700 --> 00:15:53,640
and then we only copy the nodes along

00:15:50,279 --> 00:15:55,290
that path so we have to make a new route

00:15:53,640 --> 00:15:57,480
of the tree but the right-hand side of

00:15:55,290 --> 00:15:59,970
that can be appointed to the the old

00:15:57,480 --> 00:16:01,380
subtree and we have to go with the two

00:15:59,970 --> 00:16:03,120
but we don't have to cope with the one

00:16:01,380 --> 00:16:06,089
and then we get to the three we make our

00:16:03,120 --> 00:16:09,330
changes after we copied it and then we

00:16:06,089 --> 00:16:13,110
have a new tree which is like more than

00:16:09,330 --> 00:16:15,300
half the same as the previous tree so

00:16:13,110 --> 00:16:17,279
that's basically I think that the

00:16:15,300 --> 00:16:18,390
general rule for persistent data

00:16:17,279 --> 00:16:20,279
structures if they're going to be

00:16:18,390 --> 00:16:25,800
efficient at all is try and make them

00:16:20,279 --> 00:16:27,930
into a tree and after thinking about

00:16:25,800 --> 00:16:32,339
optimizing it and such we get is

00:16:27,930 --> 00:16:33,959
something like a bee tree which is this

00:16:32,339 --> 00:16:37,529
is basically the same as that binary

00:16:33,959 --> 00:16:39,360
tree except it's no longer binary the

00:16:37,529 --> 00:16:43,740
bee tree in in my current implementation

00:16:39,360 --> 00:16:49,709
is I think up to 32 or 64 elements per

00:16:43,740 --> 00:16:54,240
level per node and that means that the

00:16:49,709 --> 00:16:58,500
log n to get down to to a leaf becomes

00:16:54,240 --> 00:17:00,000
considerably shorter just because there

00:16:58,500 --> 00:17:01,170
are going to be fewer nodes because

00:17:00,000 --> 00:17:03,360
you've got to fit more space into them

00:17:01,170 --> 00:17:06,449
so it gets slightly more expensive to

00:17:03,360 --> 00:17:07,620
copy them but you save so much on most

00:17:06,449 --> 00:17:11,790
operations that it doesn't really matter

00:17:07,620 --> 00:17:14,459
and this is how order lists ordered maps

00:17:11,790 --> 00:17:17,670
sorry I've done in in the standard

00:17:14,459 --> 00:17:21,360
library and along with being persistent

00:17:17,670 --> 00:17:24,480
I did it in exactly the same way so

00:17:21,360 --> 00:17:28,800
let's talk about trees and this is my

00:17:24,480 --> 00:17:30,390
this is this annoys me so much Lisbeth's

00:17:28,800 --> 00:17:34,770
in the audience recognize one of these

00:17:30,390 --> 00:17:38,370
I'm sure John McCarthy is the fellow

00:17:34,770 --> 00:17:39,300
with a UNIX bed he invented Lisp but

00:17:38,370 --> 00:17:40,710
we're not here to talk about John

00:17:39,300 --> 00:17:43,320
McCarthy today we're here to talk about

00:17:40,710 --> 00:17:48,660
the guy to the right of him in the tan

00:17:43,320 --> 00:17:50,760
jacket that is edward fredkin now so

00:17:48,660 --> 00:17:53,970
there's this data structure which is

00:17:50,760 --> 00:17:54,419
called trees TR II's he did not invent

00:17:53,970 --> 00:17:55,910
it

00:17:54,419 --> 00:17:58,370
that was some Frenchman

00:17:55,910 --> 00:18:02,870
as earlier his name I cannot remember

00:17:58,370 --> 00:18:05,930
but he coined the name for it he was a

00:18:02,870 --> 00:18:06,770
colleague of the inventor of trees but

00:18:05,930 --> 00:18:10,070
they couldn't come up with a good name

00:18:06,770 --> 00:18:11,750
so he thought well basically were using

00:18:10,070 --> 00:18:17,000
this structure for retrieval so let's

00:18:11,750 --> 00:18:20,390
shorten retrieval down to tree and the

00:18:17,000 --> 00:18:23,720
thing is a tree to your ie

00:18:20,390 --> 00:18:27,710
tree is a prefix or a text-based search

00:18:23,720 --> 00:18:31,070
tree which means a tree is a specialized

00:18:27,710 --> 00:18:31,460
form of a tree which is not confusing at

00:18:31,070 --> 00:18:33,650
all

00:18:31,460 --> 00:18:40,520
he decided yes you have to pronounce a

00:18:33,650 --> 00:18:43,280
tree because obviously and yeah naming

00:18:40,520 --> 00:18:45,410
is hard it's like that the guy who

00:18:43,280 --> 00:18:46,820
invented gifts who decided though it was

00:18:45,410 --> 00:18:50,240
supposed to be pronounced jiff which is

00:18:46,820 --> 00:18:58,730
ridiculous oh and that reminds me it's

00:18:50,240 --> 00:19:00,110
pronounced sad anyway so this is all

00:18:58,730 --> 00:19:01,970
ridiculous to me so I'm just going to

00:19:00,110 --> 00:19:07,700
call them radix trees from now on to

00:19:01,970 --> 00:19:11,440
avoid any kind of confusion this is sort

00:19:07,700 --> 00:19:14,320
of the idea behind them that you sort of

00:19:11,440 --> 00:19:18,620
split up the key into its its

00:19:14,320 --> 00:19:22,100
subcomponents and and use that as a

00:19:18,620 --> 00:19:25,700
search path through the actual search

00:19:22,100 --> 00:19:28,400
tree this is a diagram I just got off

00:19:25,700 --> 00:19:32,300
Wikipedia that seems to explain it

00:19:28,400 --> 00:19:36,830
succinctly basically we're using strings

00:19:32,300 --> 00:19:41,240
here as keith to look at Bally's so if

00:19:36,830 --> 00:19:42,860
you want to look up chat you see the

00:19:41,240 --> 00:19:44,690
number 4 attached to the 10th that

00:19:42,860 --> 00:19:47,240
basically you split up the words head

00:19:44,690 --> 00:19:49,220
into its into his component letters and

00:19:47,240 --> 00:19:51,260
you start with the T we got a connection

00:19:49,220 --> 00:19:53,270
for the T there we go down to the e and

00:19:51,260 --> 00:19:58,360
we get down to the D there and we made

00:19:53,270 --> 00:20:01,100
Ted and that's 4 which is really clever

00:19:58,360 --> 00:20:05,320
but then there's this guy called Phil

00:20:01,100 --> 00:20:07,820
Bagwell and now we're at about the

00:20:05,320 --> 00:20:10,380
mid-2000s

00:20:07,820 --> 00:20:12,840
he actually took this thing seriously

00:20:10,380 --> 00:20:15,540
and decided to make some very very

00:20:12,840 --> 00:20:18,510
efficient data structures based on the

00:20:15,540 --> 00:20:20,880
idea of radix trees and so he came up

00:20:18,510 --> 00:20:23,730
with this thing this is my

00:20:20,880 --> 00:20:27,030
implementation for a hash map in the

00:20:23,730 --> 00:20:29,040
image of library incidentally so he's

00:20:27,030 --> 00:20:30,720
basically using the same trick as with

00:20:29,040 --> 00:20:32,970
the strings previously but he's using

00:20:30,720 --> 00:20:35,160
the hash map and it's using some very

00:20:32,970 --> 00:20:38,730
clever bit bits operations I'm not going

00:20:35,160 --> 00:20:41,610
to try to explain to to make this tree

00:20:38,730 --> 00:20:44,220
cleverly sparse but it's so basically

00:20:41,610 --> 00:20:47,790
the same idea and it's basically a tree

00:20:44,220 --> 00:20:53,640
so it's still persistent and it's still

00:20:47,790 --> 00:20:55,160
really quite efficient and then finally

00:20:53,640 --> 00:20:58,080
this fellow called rich Hickey

00:20:55,160 --> 00:21:00,510
he made a language called closure I

00:20:58,080 --> 00:21:03,720
think possibly the first Lisp that is

00:21:00,510 --> 00:21:05,880
the words first and rest instead of core

00:21:03,720 --> 00:21:11,970
encoder for which I will never forgive

00:21:05,880 --> 00:21:14,190
him but he took this hash map and I kind

00:21:11,970 --> 00:21:15,570
of popularized it I think closure was

00:21:14,190 --> 00:21:17,700
the first language were we started

00:21:15,570 --> 00:21:21,060
thinking of data structures as really

00:21:17,700 --> 00:21:25,950
essential to the language I took bag was

00:21:21,060 --> 00:21:27,660
hash map and he also carried the idea

00:21:25,950 --> 00:21:29,220
forward a little bit and made this thing

00:21:27,660 --> 00:21:35,040
called what he called the position

00:21:29,220 --> 00:21:39,330
vector which is very similar but instead

00:21:35,040 --> 00:21:43,280
of the hash as the radix that the search

00:21:39,330 --> 00:21:46,200
path he just uses the the index this is

00:21:43,280 --> 00:21:49,170
basically the same data structure as a

00:21:46,200 --> 00:21:51,690
Veck except a bit more clammer it works

00:21:49,170 --> 00:21:54,020
kind of the same way so you get really

00:21:51,690 --> 00:21:57,090
fast index lookup but o log N and

00:21:54,020 --> 00:22:00,240
because of the the size of each node

00:21:57,090 --> 00:22:09,480
that is a very high look so it's usually

00:22:00,240 --> 00:22:13,110
extremely fast and say we got a data

00:22:09,480 --> 00:22:16,710
structure that has very efficient lookup

00:22:13,110 --> 00:22:18,540
it's got very efficient append or pop

00:22:16,710 --> 00:22:24,450
from the back

00:22:18,540 --> 00:22:25,860
as well and with some trickery which is

00:22:24,450 --> 00:22:28,200
a hack that that rich Hickey didn't

00:22:25,860 --> 00:22:29,910
actually ease enclosure burn which you

00:22:28,200 --> 00:22:32,730
will find in things like immutable Jas

00:22:29,910 --> 00:22:36,870
and in my implementation you can also

00:22:32,730 --> 00:22:38,040
get efficient ads to the front but one

00:22:36,870 --> 00:22:41,580
thing left I'm going to be slow is

00:22:38,040 --> 00:22:44,850
concatenation and so basically this is

00:22:41,580 --> 00:22:46,260
annoying because there are data

00:22:44,850 --> 00:22:48,960
structures where you can get very

00:22:46,260 --> 00:22:52,050
efficient concatenation but you won't

00:22:48,960 --> 00:22:53,760
get efficient index lookup for this and

00:22:52,050 --> 00:23:00,330
now we've got that vector which has

00:22:53,760 --> 00:23:02,220
efficient indexing and which is really

00:23:00,330 --> 00:23:03,180
slow at concatenation so why can't we

00:23:02,220 --> 00:23:04,080
just have a data structure that's

00:23:03,180 --> 00:23:07,890
perfect

00:23:04,080 --> 00:23:09,750
and so his fill bag will again basically

00:23:07,890 --> 00:23:12,600
the the last thing he gave us who sadly

00:23:09,750 --> 00:23:15,570
passed away in 2012 was this thing

00:23:12,600 --> 00:23:17,670
called relaxed radix balance trees which

00:23:15,570 --> 00:23:21,390
is a further development on hickeys

00:23:17,670 --> 00:23:24,480
vector but which allows a more relaxed

00:23:21,390 --> 00:23:25,350
structure to the tree and I wasn't going

00:23:24,480 --> 00:23:26,970
to try and explain how that works

00:23:25,350 --> 00:23:29,940
especially because I'm actually running

00:23:26,970 --> 00:23:32,250
out of time it's a clever hack that

00:23:29,940 --> 00:23:36,420
involves size tables were necessary

00:23:32,250 --> 00:23:40,820
which means that how the tree looks is

00:23:36,420 --> 00:23:42,510
less important than in in the vector so

00:23:40,820 --> 00:23:44,370
concatenation is something you can just

00:23:42,510 --> 00:23:47,310
do by basically joining two trees

00:23:44,370 --> 00:23:50,550
together root social I'm oversimplifying

00:23:47,310 --> 00:23:53,130
but yeah so this is not actually in my

00:23:50,550 --> 00:23:57,390
library yet because I had to take time

00:23:53,130 --> 00:23:58,620
off to write this talk for one thing but

00:23:57,390 --> 00:24:01,290
I'm really excited about the potential

00:23:58,620 --> 00:24:03,000
for this basically it's it's all organic

00:24:01,290 --> 00:24:06,420
cross the board and it should be really

00:24:03,000 --> 00:24:08,190
efficient but why why why do we even

00:24:06,420 --> 00:24:12,150
want to have these these data structures

00:24:08,190 --> 00:24:14,820
why are they useful well so the classic

00:24:12,150 --> 00:24:15,210
argument the the Haskell defense as I

00:24:14,820 --> 00:24:17,490
call it

00:24:15,210 --> 00:24:19,920
it's a mutable values make it easier to

00:24:17,490 --> 00:24:22,200
reason about your program in fact and

00:24:19,920 --> 00:24:23,910
this is this is true in fact in Haskell

00:24:22,200 --> 00:24:25,440
it makes it so easy to reason about your

00:24:23,910 --> 00:24:27,840
program that they had should use things

00:24:25,440 --> 00:24:31,010
like monad transformers and proof onto

00:24:27,840 --> 00:24:31,010
updates just to make it hard again

00:24:31,440 --> 00:24:36,820
but the thing is so the idea is is if

00:24:35,050 --> 00:24:38,830
values don't change then it's a lot

00:24:36,820 --> 00:24:41,650
easier to track what's going on but rust

00:24:38,830 --> 00:24:44,110
has this too so that's not really a good

00:24:41,650 --> 00:24:46,960
argument I mean rust is actually able to

00:24:44,110 --> 00:24:49,380
track your how your mutable data

00:24:46,960 --> 00:24:54,100
structures change in a way that sort of

00:24:49,380 --> 00:24:56,559
eliminates this argument almost and the

00:24:54,100 --> 00:24:58,240
same with Fred safety because obviously

00:24:56,559 --> 00:24:59,770
for value never changes you don't have

00:24:58,240 --> 00:25:02,200
to worry about somebody else changing it

00:24:59,770 --> 00:25:06,280
in a different threat but rust kind of

00:25:02,200 --> 00:25:08,860
manages this too so here's an argument

00:25:06,280 --> 00:25:10,720
pad section is still sort of valid the

00:25:08,860 --> 00:25:12,370
idea of evolving state like say if you

00:25:10,720 --> 00:25:14,490
have a recursive algorithm that needs a

00:25:12,370 --> 00:25:16,750
backtrack if you're using recursive

00:25:14,490 --> 00:25:18,460
sorry if you using position data

00:25:16,750 --> 00:25:20,470
structures you don't really need to

00:25:18,460 --> 00:25:22,540
worry about how to backtrack yeah which

00:25:20,470 --> 00:25:23,770
is yeah you go back to the previous

00:25:22,540 --> 00:25:27,490
value like that you happen to have

00:25:23,770 --> 00:25:29,140
stored likewise with stateful apps like

00:25:27,490 --> 00:25:34,120
with Redux

00:25:29,140 --> 00:25:35,260
or Elm than the entire state can be

00:25:34,120 --> 00:25:37,570
stored in a persistent data structure

00:25:35,260 --> 00:25:40,360
and you can just roll back to previous

00:25:37,570 --> 00:25:41,950
state so keep snapshots around or like

00:25:40,360 --> 00:25:44,110
have a slider that will get you through

00:25:41,950 --> 00:25:46,300
the entire state history of the

00:25:44,110 --> 00:25:48,790
application state we're just really cool

00:25:46,300 --> 00:25:49,870
if you're writing you eyes but I think

00:25:48,790 --> 00:25:54,490
the core argument is they are actually

00:25:49,870 --> 00:25:56,080
faster this is a bold claim probably who

00:25:54,490 --> 00:25:58,059
wouldn't think cloning is always a

00:25:56,080 --> 00:26:01,809
constant time because basically just

00:25:58,059 --> 00:26:05,290
copping a pointer and increasing a

00:26:01,809 --> 00:26:07,500
reference counter but claim is maybe not

00:26:05,290 --> 00:26:10,900
the most exciting operation you can do I

00:26:07,500 --> 00:26:13,809
want to touch upon vac which is actually

00:26:10,900 --> 00:26:16,179
a pretty cool little data structure for

00:26:13,809 --> 00:26:20,590
a simplicity I mean it's got poor big-oh

00:26:16,179 --> 00:26:23,740
performance but in the end it's really

00:26:20,590 --> 00:26:26,800
really fast if it's small if it fits

00:26:23,740 --> 00:26:28,450
inside your CPU cache is completely

00:26:26,800 --> 00:26:31,630
unbeatable it's ridiculous

00:26:28,450 --> 00:26:33,910
like honestly I ran benchmarks with cons

00:26:31,630 --> 00:26:36,220
list versus just literally cloning a

00:26:33,910 --> 00:26:37,480
vector every time I changed it and the

00:26:36,220 --> 00:26:39,010
closet is how to get off to like a

00:26:37,480 --> 00:26:43,190
couple of hundred elements before it's

00:26:39,010 --> 00:26:46,530
actually faster which is ridiculous

00:26:43,190 --> 00:26:48,480
but the thing is with with chunking

00:26:46,530 --> 00:26:50,520
techniques which I'm not going to

00:26:48,480 --> 00:26:51,810
explain but I'm going to show you the

00:26:50,520 --> 00:26:56,730
name of a paper about it if you're

00:26:51,810 --> 00:27:00,030
interested it's that we can we can

00:26:56,730 --> 00:27:02,070
basically take these benefits from the

00:27:00,030 --> 00:27:04,800
efficiency of very small backs and and

00:27:02,070 --> 00:27:10,380
sort of borrow of them for things like

00:27:04,800 --> 00:27:13,110
the RR be back to what we come back to

00:27:10,380 --> 00:27:14,820
though every time it's that mutable data

00:27:13,110 --> 00:27:17,060
structures are always going to be faster

00:27:14,820 --> 00:27:19,680
than immutable data structures and

00:27:17,060 --> 00:27:22,740
kosher addresses this by with it with

00:27:19,680 --> 00:27:25,500
the idea of transient and Haskell has

00:27:22,740 --> 00:27:27,840
the STM owner similarly I managed to get

00:27:25,500 --> 00:27:29,580
the M word and I'm very proud of myself

00:27:27,840 --> 00:27:31,740
which is basically the idea about a

00:27:29,580 --> 00:27:34,860
persistent data structure can be mutable

00:27:31,740 --> 00:27:38,070
as long as nobody else sees it so inside

00:27:34,860 --> 00:27:39,990
a function this allows you to to mutate

00:27:38,070 --> 00:27:42,030
it as much as you want until you return

00:27:39,990 --> 00:27:45,060
it and somebody else actually sees it

00:27:42,030 --> 00:27:46,710
then it stops being mutable but this is

00:27:45,060 --> 00:27:50,630
rust and it turns out we've got this

00:27:46,710 --> 00:27:55,910
amazing function called make mute inside

00:27:50,630 --> 00:27:58,680
the arc reference counter thing which

00:27:55,910 --> 00:28:00,060
because this is a low-level that we're

00:27:58,680 --> 00:28:03,960
actually tracking reference counting

00:28:00,060 --> 00:28:07,650
ourselves and so we know whether way the

00:28:03,960 --> 00:28:11,370
the sole owner of a data structure so we

00:28:07,650 --> 00:28:16,140
can use this this basically looks at the

00:28:11,370 --> 00:28:17,910
reference count and if it's at one it

00:28:16,140 --> 00:28:19,650
just gives you a mutable reference and

00:28:17,910 --> 00:28:20,850
if it's more than that it copies it

00:28:19,650 --> 00:28:22,170
first they give it a mutable reference

00:28:20,850 --> 00:28:23,550
to that so basically I'm just

00:28:22,170 --> 00:28:25,380
implementing all my data structures as

00:28:23,550 --> 00:28:28,560
mutable and this thing will just

00:28:25,380 --> 00:28:30,780
magically make them immutable for me

00:28:28,560 --> 00:28:32,940
without having to do any work at all on

00:28:30,780 --> 00:28:39,630
this I had to put this bit in there

00:28:32,940 --> 00:28:41,850
sorry so basically we have mutable data

00:28:39,630 --> 00:28:45,660
structures with immutable guarantees and

00:28:41,850 --> 00:28:48,390
they perform like it and so I'm going to

00:28:45,660 --> 00:28:51,570
have to pick up some pace here because I

00:28:48,390 --> 00:28:54,150
just ran out of time so our a B vectors

00:28:51,570 --> 00:28:56,950
do complex things in a smarter way than

00:28:54,150 --> 00:28:58,600
back and we're talking we

00:28:56,950 --> 00:29:01,710
get a similar performance out of our

00:28:58,600 --> 00:29:05,019
aura be vectors asked with BEC ideally

00:29:01,710 --> 00:29:07,230
and let small slices because then it's

00:29:05,019 --> 00:29:09,789
just the the chunking head or the tail

00:29:07,230 --> 00:29:12,880
it literally kind of is just a vac or

00:29:09,789 --> 00:29:15,940
two backs at worst the memory footprint

00:29:12,880 --> 00:29:18,610
is only slightly worse than rack but vac

00:29:15,940 --> 00:29:20,289
will always be better and likewise with

00:29:18,610 --> 00:29:21,909
Maps the implementation is pretty

00:29:20,289 --> 00:29:25,510
similar to the mutable bits

00:29:21,909 --> 00:29:27,250
it's just with an added may commute if I

00:29:25,510 --> 00:29:29,850
done my job right anyway and I'm still

00:29:27,250 --> 00:29:31,990
working on it but we'll get that I hope

00:29:29,850 --> 00:29:33,789
so with a slightly worse memory

00:29:31,990 --> 00:29:34,620
footprint but hey that's the price to

00:29:33,789 --> 00:29:38,710
pay

00:29:34,620 --> 00:29:40,600
I'm gonna skip over this bit because I

00:29:38,710 --> 00:29:42,880
did run out of time I want to point out

00:29:40,600 --> 00:29:45,669
this thing though this is my guiding

00:29:42,880 --> 00:29:47,470
principle when writing this library that

00:29:45,669 --> 00:29:53,950
neighbors can easily bury with bad

00:29:47,470 --> 00:29:56,610
documentation so I spent I spend as much

00:29:53,950 --> 00:29:58,870
time as I I can actually writing

00:29:56,610 --> 00:30:02,169
documentation for this thing trying to

00:29:58,870 --> 00:30:05,080
explain my thinking this I wanna skip

00:30:02,169 --> 00:30:07,510
and say thank you very much don't don't

00:30:05,080 --> 00:30:09,070
applaud yet I want to first of all I

00:30:07,510 --> 00:30:12,240
want to draw attention to my hero's

00:30:09,070 --> 00:30:14,740
Belka and Strelka famous cosmonauts and

00:30:12,240 --> 00:30:18,010
this is the bit that you should be

00:30:14,740 --> 00:30:21,389
applauding Nobuko Strelka but my sources

00:30:18,010 --> 00:30:21,389
thank you very much

00:30:27,260 --> 00:30:29,320

YouTube URL: https://www.youtube.com/watch?v=Gfe-JKn7G0I


