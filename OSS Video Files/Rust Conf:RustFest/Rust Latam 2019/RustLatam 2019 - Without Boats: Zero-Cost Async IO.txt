Title: RustLatam 2019 - Without Boats: Zero-Cost Async IO
Publication date: 2019-04-21
Playlist: Rust Latam 2019
Description: 
	Boats is a member of the language design, library, and cargo teams of the Rust Project. They are Senior Research Engineer working on Rust for Mozilla Research. Contributing to Rust since 2014, they've done design work for significant language extensions like generic associated types and constant generics. For the last year, Boats has been focused on adding async/await syntax for non-blocking I/O to Rust.

Follow us on Twitter: https://twitter.com/rustlatamconf
Captions: 
	00:00:07,589 --> 00:00:16,090
hey everyone thanks for having me yeah

00:00:12,160 --> 00:00:20,320
I'm my name is without boats as in yeah

00:00:16,090 --> 00:00:21,970
see about this you can most people call

00:00:20,320 --> 00:00:27,789
me boats which is actually even more

00:00:21,970 --> 00:00:30,939
confusing I am researcher at Mozilla I

00:00:27,789 --> 00:00:32,140
work on rust my full-time job it's

00:00:30,939 --> 00:00:38,110
pretty cool

00:00:32,140 --> 00:00:40,750
I think so this talk is going to be

00:00:38,110 --> 00:00:43,239
about sort of its feature that I've been

00:00:40,750 --> 00:00:45,340
working on for about the last year and a

00:00:43,239 --> 00:00:48,670
half and before me other people were

00:00:45,340 --> 00:00:50,590
working on fervor it's I mean honestly

00:00:48,670 --> 00:00:54,550
since the very beginning of rust before

00:00:50,590 --> 00:00:56,379
run play now but before that I just

00:00:54,550 --> 00:00:57,760
wanted to thank the organizers for

00:00:56,379 --> 00:01:03,280
having me and for all of their work in

00:00:57,760 --> 00:01:04,300
putting this conference on I think I may

00:01:03,280 --> 00:01:07,300
be someone's already said pointed this

00:01:04,300 --> 00:01:09,040
out but I believe this is the first rust

00:01:07,300 --> 00:01:11,350
conference outside of the United States

00:01:09,040 --> 00:01:13,270
or Europe and so as someone who works in

00:01:11,350 --> 00:01:14,860
rust I'm really like excited and glad to

00:01:13,270 --> 00:01:16,120
see our global community like thriving

00:01:14,860 --> 00:01:17,920
and growing and it's really cool to see

00:01:16,120 --> 00:01:22,150
all the conferences that are happening

00:01:17,920 --> 00:01:26,500
this year come on to the technical stuff

00:01:22,150 --> 00:01:30,610
so the feature that I've been working on

00:01:26,500 --> 00:01:32,440
is this thing called async/await it's

00:01:30,610 --> 00:01:34,150
sort of going to be probably the the

00:01:32,440 --> 00:01:36,430
biggest thing that we do in the language

00:01:34,150 --> 00:01:39,580
this year we're planning to ship it

00:01:36,430 --> 00:01:40,750
sometime in the next few months and it's

00:01:39,580 --> 00:01:41,860
the solution to this problem that we've

00:01:40,750 --> 00:01:44,590
been struggling with for really long

00:01:41,860 --> 00:01:48,370
time which is how can we have a zero

00:01:44,590 --> 00:01:53,350
cost abstraction for asynchronous i/o in

00:01:48,370 --> 00:01:55,060
rust so I'm going to explain what zero

00:01:53,350 --> 00:01:57,040
cost abstraction means in a moment but

00:01:55,060 --> 00:02:03,070
first just to kind of give an overview

00:01:57,040 --> 00:02:04,840
of the feature so async/await

00:02:03,070 --> 00:02:07,360
it's just these two new keywords that

00:02:04,840 --> 00:02:11,740
we're adding to the language a sink and

00:02:07,360 --> 00:02:14,590
a weight and so a sink is this modifier

00:02:11,740 --> 00:02:16,660
that can be applied to like function

00:02:14,590 --> 00:02:17,920
we're now the function instead of when

00:02:16,660 --> 00:02:19,390
you call it runs all the way through and

00:02:17,920 --> 00:02:21,610
returns instead of returns immediately

00:02:19,390 --> 00:02:23,080
and returns this future that will

00:02:21,610 --> 00:02:25,959
eventually result in whatever the

00:02:23,080 --> 00:02:28,690
function would return and inside of an

00:02:25,959 --> 00:02:30,730
async function you can take the await

00:02:28,690 --> 00:02:32,440
operator and apply it to other features

00:02:30,730 --> 00:02:34,600
which will pause the function until

00:02:32,440 --> 00:02:35,560
those features are ready and so it's

00:02:34,600 --> 00:02:37,540
this way of handling asynchronous

00:02:35,560 --> 00:02:40,270
concurrent operations using these

00:02:37,540 --> 00:02:43,840
annotations that makes them much easier

00:02:40,270 --> 00:02:46,540
to write so you're just a little code

00:02:43,840 --> 00:02:51,150
sample just to sort of highlight and

00:02:46,540 --> 00:02:54,040
explain the future this is in like

00:02:51,150 --> 00:02:56,980
basically just the adapter on like a

00:02:54,040 --> 00:02:59,680
like a kind of ORM type of thing it's

00:02:56,980 --> 00:03:02,470
handwritten where you have this get user

00:02:59,680 --> 00:03:04,180
method which takes a string for a

00:03:02,470 --> 00:03:06,340
username and then returns this like user

00:03:04,180 --> 00:03:09,489
domain object by querying the database

00:03:06,340 --> 00:03:11,320
for the record for that user and it does

00:03:09,489 --> 00:03:12,970
that using async IO which means that

00:03:11,320 --> 00:03:15,400
it's an async function instead of just a

00:03:12,970 --> 00:03:18,280
normal function and so when you call it

00:03:15,400 --> 00:03:20,410
you can await it and then just to walk

00:03:18,280 --> 00:03:22,900
through the the body of this this method

00:03:20,410 --> 00:03:26,890
you just the first thing is it creates

00:03:22,900 --> 00:03:28,690
the sequel query interpolating the user

00:03:26,890 --> 00:03:32,530
name into you know select from users

00:03:28,690 --> 00:03:34,180
table and then we query the database and

00:03:32,530 --> 00:03:37,600
this is where we're actually performing

00:03:34,180 --> 00:03:40,060
some i/o so query also returns a future

00:03:37,600 --> 00:03:42,160
because it's doing this async i/o and so

00:03:40,060 --> 00:03:43,989
when you query the database you just add

00:03:42,160 --> 00:03:45,910
this await in order to wait for the

00:03:43,989 --> 00:03:48,209
response and then once you get the

00:03:45,910 --> 00:03:50,890
response you can parse a user out of it

00:03:48,209 --> 00:03:54,040
this user domain object which is you

00:03:50,890 --> 00:03:55,269
know part of your application when so

00:03:54,040 --> 00:03:56,950
this method is just sort of like a toy

00:03:55,269 --> 00:04:00,700
example for the talk but I wanted to

00:03:56,950 --> 00:04:02,049
highlight in it is that the only

00:04:00,700 --> 00:04:03,820
difference really between this and using

00:04:02,049 --> 00:04:05,350
blocking i/o or these little annotations

00:04:03,820 --> 00:04:06,700
where you just mark the functions as

00:04:05,350 --> 00:04:09,730
being hey sync and when you call them

00:04:06,700 --> 00:04:12,510
you add this away and so it's you know

00:04:09,730 --> 00:04:14,560
relatively little overhead forgetting

00:04:12,510 --> 00:04:17,500
using non-blocking i/o instead of

00:04:14,560 --> 00:04:19,510
blocking i/o and in particular and rust

00:04:17,500 --> 00:04:21,340
the really great thing about our

00:04:19,510 --> 00:04:24,729
implementation that it makes me really

00:04:21,340 --> 00:04:26,050
excited about it is that our async await

00:04:24,729 --> 00:04:34,990
and futures are

00:04:26,050 --> 00:04:37,120
zero cost abstraction and so zero cost

00:04:34,990 --> 00:04:38,440
attractions are sort of utterly defining

00:04:37,120 --> 00:04:40,000
feature of rust it's one of the things

00:04:38,440 --> 00:04:43,330
that differentiates us from a lot of

00:04:40,000 --> 00:04:46,090
other languages is that we really care

00:04:43,330 --> 00:04:49,629
about when we add new features that they

00:04:46,090 --> 00:04:53,560
are zero cost we didn't actually come up

00:04:49,629 --> 00:04:54,759
with the idea it's a big thing in C++

00:04:53,560 --> 00:04:56,740
also and so I think the best explanation

00:04:54,759 --> 00:04:58,960
is this quote from be honest true strep

00:04:56,740 --> 00:05:00,550
which is that a zero cost attraction

00:04:58,960 --> 00:05:02,979
means that when you don't use it you

00:05:00,550 --> 00:05:04,750
don't pay for it and further when you do

00:05:02,979 --> 00:05:09,669
use it you couldn't hand coded any

00:05:04,750 --> 00:05:11,319
better and so there's these two aspects

00:05:09,669 --> 00:05:13,479
to a zero cost abstraction which is that

00:05:11,319 --> 00:05:15,669
the first is that the feature can't

00:05:13,479 --> 00:05:17,500
effect can't add costs to people who

00:05:15,669 --> 00:05:18,669
aren't using the feature so we can't add

00:05:17,500 --> 00:05:20,949
this global cost that will slow down

00:05:18,669 --> 00:05:24,789
every program and or been able to in

00:05:20,949 --> 00:05:28,419
order to enable this feature and the

00:05:24,789 --> 00:05:31,539
second is that when you do use the

00:05:28,419 --> 00:05:32,830
feature it can't be slower than if you

00:05:31,539 --> 00:05:33,909
didn't use it and then you feel like oh

00:05:32,830 --> 00:05:35,650
well I would like to use this really

00:05:33,909 --> 00:05:36,880
nice feature that makes it easier but it

00:05:35,650 --> 00:05:38,469
will make my program slow and so I'll

00:05:36,880 --> 00:05:42,250
just like write this thing by hand it'll

00:05:38,469 --> 00:05:43,960
be a much bigger pain and so I'm gonna

00:05:42,250 --> 00:05:45,819
kind of walk through the history of how

00:05:43,960 --> 00:05:48,659
we try to solve async Iowa and rust and

00:05:45,819 --> 00:05:51,639
some of the steps along the way we hit

00:05:48,659 --> 00:05:59,860
had features that failed the zero cost

00:05:51,639 --> 00:06:01,389
test upon both both principles so the

00:05:59,860 --> 00:06:08,650
specific problem that we're trying to

00:06:01,389 --> 00:06:11,020
solve is async i/o and so normally IO is

00:06:08,650 --> 00:06:13,750
blocking so when you use IO you'll block

00:06:11,020 --> 00:06:15,580
thread and that will stop your program

00:06:13,750 --> 00:06:19,870
and then have to be rescheduled by the

00:06:15,580 --> 00:06:21,310
OS and the problem with blocking i/o is

00:06:19,870 --> 00:06:22,750
just doesn't really scale when you have

00:06:21,310 --> 00:06:25,029
trying to serve a lot of connections

00:06:22,750 --> 00:06:26,560
from the same program and so for these

00:06:25,029 --> 00:06:28,810
kinds of really high scale network

00:06:26,560 --> 00:06:34,300
services you really need some form of

00:06:28,810 --> 00:06:36,370
non blocking or asynchronous IO and rust

00:06:34,300 --> 00:06:37,810
in particular is supposed to be designed

00:06:36,370 --> 00:06:38,650
for languages that have these really

00:06:37,810 --> 00:06:40,270
high performance report

00:06:38,650 --> 00:06:42,490
Armin's you know it's a systems foreign

00:06:40,270 --> 00:06:43,870
language for people who really care

00:06:42,490 --> 00:06:45,160
about the computing resources they're

00:06:43,870 --> 00:06:47,320
using and so for us to really be

00:06:45,160 --> 00:06:48,729
successful in the network space we

00:06:47,320 --> 00:06:55,360
really need some sort of solution to

00:06:48,729 --> 00:06:57,850
this asynchronous i/o problem but the

00:06:55,360 --> 00:06:59,530
big problem with async is that the way

00:06:57,850 --> 00:07:02,020
it works is that when you call the i/o

00:06:59,530 --> 00:07:04,509
you know system call it just returns

00:07:02,020 --> 00:07:06,340
immediately and then eventually you can

00:07:04,509 --> 00:07:08,800
continue doing other work but it's your

00:07:06,340 --> 00:07:13,570
programs responsibility for figuring out

00:07:08,800 --> 00:07:15,460
how to like schedule calling back to the

00:07:13,570 --> 00:07:18,010
tasks that you were at the pause on when

00:07:15,460 --> 00:07:19,660
you're doing the asynchronous i/o and so

00:07:18,010 --> 00:07:21,130
this makes you know writing an async on

00:07:19,660 --> 00:07:23,139
your program much more complex than

00:07:21,130 --> 00:07:25,120
writing one of these is blocking i/o and

00:07:23,139 --> 00:07:26,560
so a lot of languages that are trying to

00:07:25,120 --> 00:07:28,449
target these like scalable network

00:07:26,560 --> 00:07:30,400
services have been trying to come up

00:07:28,449 --> 00:07:32,500
with solutions for this problem that

00:07:30,400 --> 00:07:33,789
like take it make it not the end users

00:07:32,500 --> 00:07:36,910
problem but a part of the language or a

00:07:33,789 --> 00:07:39,400
part of the libraries and so the first

00:07:36,910 --> 00:07:40,660
solution that rust started with was the

00:07:39,400 --> 00:07:43,500
city of green threads which have been

00:07:40,660 --> 00:07:46,419
successful in a lot of languages and so

00:07:43,500 --> 00:07:47,919
green threads basically looked like

00:07:46,419 --> 00:07:50,380
blocking i/o they look like spawning

00:07:47,919 --> 00:07:52,060
threads and then just blocking on i/o

00:07:50,380 --> 00:07:53,199
and everything looks exactly the same as

00:07:52,060 --> 00:07:55,300
if you were using the native OS

00:07:53,199 --> 00:07:58,360
primitives but they've been designed as

00:07:55,300 --> 00:07:59,800
part of the language runtime to be

00:07:58,360 --> 00:08:02,260
optimized for this use case of having

00:07:59,800 --> 00:08:04,000
these network services which are crying

00:08:02,260 --> 00:08:06,729
responding you know thousands tens of

00:08:04,000 --> 00:08:10,840
thousands maybe millions of green

00:08:06,729 --> 00:08:11,860
threads at the same time a language I

00:08:10,840 --> 00:08:13,240
think the right now that is like having

00:08:11,860 --> 00:08:15,010
a lot of success with this model is go

00:08:13,240 --> 00:08:16,870
where they're called go routines and so

00:08:15,010 --> 00:08:18,099
it's very normal for a go program to you

00:08:16,870 --> 00:08:20,229
have tens of thousands of these running

00:08:18,099 --> 00:08:24,340
at the same time because they're very

00:08:20,229 --> 00:08:26,530
cheap to spawn unlike OS threats and so

00:08:24,340 --> 00:08:30,280
just the advantage of green threads is

00:08:26,530 --> 00:08:32,440
that the memory overhead when you spot

00:08:30,280 --> 00:08:34,419
an OS thread is much higher because you

00:08:32,440 --> 00:08:36,190
create this huge stack for each OS

00:08:34,419 --> 00:08:37,180
thread whereas green threads the way

00:08:36,190 --> 00:08:39,190
they normally work is that you will

00:08:37,180 --> 00:08:40,839
spawn a thread that starts with a very

00:08:39,190 --> 00:08:42,820
small stack that can grow over time and

00:08:40,839 --> 00:08:45,400
so spawning a bunch of new threads that

00:08:42,820 --> 00:08:48,550
aren't using a lot of memory yet is no

00:08:45,400 --> 00:08:49,810
much cheaper and also a problem with

00:08:48,550 --> 00:08:51,850
using like the operating system

00:08:49,810 --> 00:08:52,540
primitives is that you depend on the

00:08:51,850 --> 00:08:54,759
operating system

00:08:52,540 --> 00:08:57,850
scheduling which means that you have to

00:08:54,759 --> 00:08:59,410
switch from your programs memory space

00:08:57,850 --> 00:09:02,259
into the kernel space and the context

00:08:59,410 --> 00:09:03,579
switching adds a lot of overhead if you

00:09:02,259 --> 00:09:04,720
once you start having you know tens of

00:09:03,579 --> 00:09:07,360
thousands of threads that are all being

00:09:04,720 --> 00:09:09,790
skipped like switched between really

00:09:07,360 --> 00:09:11,829
quickly and so by keeping that

00:09:09,790 --> 00:09:13,420
scheduling in the same program you'll

00:09:11,829 --> 00:09:15,519
avoid these contexts which is really

00:09:13,420 --> 00:09:17,079
reduces the overhead and so green

00:09:15,519 --> 00:09:20,230
threading is a pretty good model that

00:09:17,079 --> 00:09:20,620
works for a lot of languages both go in

00:09:20,230 --> 00:09:24,250
Java

00:09:20,620 --> 00:09:25,959
I believe used to smaadahl and rust had

00:09:24,250 --> 00:09:28,690
it for a long time but removed it

00:09:25,959 --> 00:09:29,980
shortly before Mulino and the reason

00:09:28,690 --> 00:09:32,170
that we moved to this that ultimately

00:09:29,980 --> 00:09:36,519
was not a zero cost abstraction

00:09:32,170 --> 00:09:39,310
specifically because of the the first

00:09:36,519 --> 00:09:40,870
issue that I talked about where it was

00:09:39,310 --> 00:09:43,089
imposing costs on people who didn't need

00:09:40,870 --> 00:09:44,829
it so if you just wanted to write a rust

00:09:43,089 --> 00:09:46,089
program that didn't need to use screen

00:09:44,829 --> 00:09:47,350
prints that wasn't a network service you

00:09:46,089 --> 00:09:49,149
still had to have this language runtime

00:09:47,350 --> 00:09:53,110
that was responsible for scheduling all

00:09:49,149 --> 00:09:54,579
of your green threads and so this is

00:09:53,110 --> 00:09:56,740
especially a problem for people who were

00:09:54,579 --> 00:09:59,130
trying to embed rust inside of like a

00:09:56,740 --> 00:10:01,120
larger C application it's one of the

00:09:59,130 --> 00:10:03,579
ways that we've seen a lot of success in

00:10:01,120 --> 00:10:05,139
people adopting rust is that they have

00:10:03,579 --> 00:10:07,420
some big C program and they want to

00:10:05,139 --> 00:10:09,250
start using rust and so they start

00:10:07,420 --> 00:10:10,389
integrating a bit of rust into their

00:10:09,250 --> 00:10:14,339
probe into their program it's just

00:10:10,389 --> 00:10:14,339
writing one section of the code in rust

00:10:14,550 --> 00:10:19,000
but the problem is that if you have to

00:10:16,750 --> 00:10:21,339
set up this runtime in order to call the

00:10:19,000 --> 00:10:23,139
rust then that it's too expensive to

00:10:21,339 --> 00:10:24,220
just have a small part of your program

00:10:23,139 --> 00:10:25,510
in rust because you have to set up the

00:10:24,220 --> 00:10:29,139
runtime before you can call the rust

00:10:25,510 --> 00:10:30,459
functions and so for 1.0 we removed

00:10:29,139 --> 00:10:31,810
green threads from the language we

00:10:30,459 --> 00:10:33,370
removed this Lingus runtime and we now

00:10:31,810 --> 00:10:35,110
have you know a runtime that is

00:10:33,370 --> 00:10:36,910
essentially the same as c and so it

00:10:35,110 --> 00:10:38,439
makes it very easy to call between rust

00:10:36,910 --> 00:10:40,870
in c and it's very cheap which is one of

00:10:38,439 --> 00:10:45,370
the key things that makes rust really

00:10:40,870 --> 00:10:47,139
successful and having removed green

00:10:45,370 --> 00:10:50,949
threads we still needed some sort of

00:10:47,139 --> 00:10:52,449
solution to async i/o but we what we

00:10:50,949 --> 00:10:53,860
realized was they need to be a library

00:10:52,449 --> 00:10:58,089
based solution we needed some sort of

00:10:53,860 --> 00:10:59,319
with providing a good abstraction for a

00:10:58,089 --> 00:11:00,459
single you know it's not a part of the

00:10:59,319 --> 00:11:02,019
language it was not a part of this

00:11:00,459 --> 00:11:03,160
runtime that came with every program it

00:11:02,019 --> 00:11:06,630
was just this library that you could opt

00:11:03,160 --> 00:11:06,630
into and use when you needed it

00:11:06,740 --> 00:11:11,720
the most successful library solution in

00:11:09,990 --> 00:11:13,890
general is this concept called futures

00:11:11,720 --> 00:11:20,460
and it's also called promises and

00:11:13,890 --> 00:11:23,220
JavaScript so the idea of the future is

00:11:20,460 --> 00:11:25,770
that it's this it represents a value

00:11:23,220 --> 00:11:27,330
that may not have evaluated yet and so

00:11:25,770 --> 00:11:29,850
you can manipulate it before you

00:11:27,330 --> 00:11:31,290
actually have for the future it's

00:11:29,850 --> 00:11:33,270
actually resolved eventually Rose off to

00:11:31,290 --> 00:11:34,470
something but you can start running

00:11:33,270 --> 00:11:37,440
things with it before it's actually

00:11:34,470 --> 00:11:38,580
resolved and there's not a lot of like

00:11:37,440 --> 00:11:41,520
work done on futures in a lot of

00:11:38,580 --> 00:11:43,310
different languages and they are a great

00:11:41,520 --> 00:11:45,030
way for supporting a lot of like

00:11:43,310 --> 00:11:46,530
combinators and especially this

00:11:45,030 --> 00:11:49,020
async/await syntax that makes it much

00:11:46,530 --> 00:11:51,570
more ergonomic to like build on top of

00:11:49,020 --> 00:11:56,280
this concurrency primitive and so

00:11:51,570 --> 00:11:58,140
futures can represent a lot of different

00:11:56,280 --> 00:12:00,420
things so they sync IO is kind of the

00:11:58,140 --> 00:12:01,980
the biggest most prominent one where you

00:12:00,420 --> 00:12:03,690
know you maybe make a network request

00:12:01,980 --> 00:12:05,460
and you immediately get a future back

00:12:03,690 --> 00:12:07,560
which once the network request is

00:12:05,460 --> 00:12:09,930
finished will resolve into whatever that

00:12:07,560 --> 00:12:11,220
never coasters are turning but you can

00:12:09,930 --> 00:12:13,620
also represent things like timeouts

00:12:11,220 --> 00:12:15,480
where a timeout is just a future that

00:12:13,620 --> 00:12:17,700
will resolve once that amount of time

00:12:15,480 --> 00:12:19,050
has passed and even things that aren't

00:12:17,700 --> 00:12:22,440
doing in the IO or anything like that

00:12:19,050 --> 00:12:24,180
were just CPU intensive work you can run

00:12:22,440 --> 00:12:25,440
that alone like a thread pool and then

00:12:24,180 --> 00:12:27,120
just get a future that you hold on to

00:12:25,440 --> 00:12:30,650
that once the thread pool is finished

00:12:27,120 --> 00:12:34,470
doing that work the future will resolve

00:12:30,650 --> 00:12:35,580
the problem with futures was that the

00:12:34,470 --> 00:12:37,500
way that they've been represented in

00:12:35,580 --> 00:12:40,470
most languages is this callback based

00:12:37,500 --> 00:12:43,710
approach where you have this feature and

00:12:40,470 --> 00:12:46,470
you can schedule a callback to run once

00:12:43,710 --> 00:12:48,540
the future resolves and so the future is

00:12:46,470 --> 00:12:49,980
responsible for figuring out when it

00:12:48,540 --> 00:12:52,140
resolves and then when it resolves it

00:12:49,980 --> 00:12:53,280
runs whatever your callback was and all

00:12:52,140 --> 00:12:57,540
these distractions are built on top of

00:12:53,280 --> 00:13:00,060
this model and this just really didn't

00:12:57,540 --> 00:13:02,540
work for us because there's a lot of

00:13:00,060 --> 00:13:07,110
people experiment with it a lot and

00:13:02,540 --> 00:13:08,610
found that I just was forcing way too

00:13:07,110 --> 00:13:10,320
many allocations essentially every

00:13:08,610 --> 00:13:12,210
callback that you tried to schedule had

00:13:10,320 --> 00:13:14,730
to get its own separate like crate

00:13:12,210 --> 00:13:15,930
object heap allocation and so there were

00:13:14,730 --> 00:13:17,670
these allocations everywhere these

00:13:15,930 --> 00:13:19,980
dynamic dispatches and

00:13:17,670 --> 00:13:21,630
this like approach failed the zero cost

00:13:19,980 --> 00:13:28,530
abstraction on the second principle

00:13:21,630 --> 00:13:30,030
where now you were it was not affecting

00:13:28,530 --> 00:13:31,950
people who work using it but if you did

00:13:30,030 --> 00:13:33,030
use it it would just be way slower than

00:13:31,950 --> 00:13:35,010
if you just had an end written something

00:13:33,030 --> 00:13:36,600
yourself and so why would you use it

00:13:35,010 --> 00:13:40,650
because if you wrote the thing yourself

00:13:36,600 --> 00:13:45,300
would be much faster but always hope

00:13:40,650 --> 00:13:51,770
it's not lost sorry I also have a bit of

00:13:45,300 --> 00:14:00,600
a cold this really great alternative

00:13:51,770 --> 00:14:02,910
abstraction that was pull based yes we

00:14:00,600 --> 00:14:06,720
write this model I really want to give

00:14:02,910 --> 00:14:11,030
credit to Alex who's here and Aaron

00:14:06,720 --> 00:14:13,440
Turin who came up with this idea where

00:14:11,030 --> 00:14:15,750
instead of futures scheduling a callback

00:14:13,440 --> 00:14:17,010
there instead you pull them and so

00:14:15,750 --> 00:14:18,360
there's this other component of the

00:14:17,010 --> 00:14:20,310
program called an executor which is

00:14:18,360 --> 00:14:22,440
responsible for actually running the

00:14:20,310 --> 00:14:24,540
futures and so the executor does is it

00:14:22,440 --> 00:14:26,520
post the future and the future either

00:14:24,540 --> 00:14:28,410
returns pending that it's not ready yet

00:14:26,520 --> 00:14:33,090
or once it is ready it you know returns

00:14:28,410 --> 00:14:36,630
ready and this model has a lot of

00:14:33,090 --> 00:14:38,580
advantages one advantage is that you can

00:14:36,630 --> 00:14:40,290
just cancel a futures very simply

00:14:38,580 --> 00:14:42,210
because all you do to cancel them is you

00:14:40,290 --> 00:14:43,530
stop holding them whereas with this

00:14:42,210 --> 00:14:44,940
callback based approach it was really

00:14:43,530 --> 00:14:48,650
difficult once you scheduled some work

00:14:44,940 --> 00:14:48,650
to cancel that work and have it stopped

00:14:49,170 --> 00:14:53,880
[Music]

00:14:50,780 --> 00:14:55,140
it also really enabled us to have this

00:14:53,880 --> 00:14:56,940
really clean abstraction boundary

00:14:55,140 --> 00:14:58,920
between different like parts of the

00:14:56,940 --> 00:15:01,320
program so most sort of futures

00:14:58,920 --> 00:15:03,240
libraries come with an event loop and

00:15:01,320 --> 00:15:04,470
that's just the your futures are

00:15:03,240 --> 00:15:06,270
scheduled across this event loop with

00:15:04,470 --> 00:15:07,380
these this way of doing i/o and you

00:15:06,270 --> 00:15:10,800
really don't have any control over it

00:15:07,380 --> 00:15:12,480
but in rust we have this really clean

00:15:10,800 --> 00:15:14,190
boundary between the executor which

00:15:12,480 --> 00:15:15,750
schedules your futures the reactor which

00:15:14,190 --> 00:15:17,960
handles all the i/o and then your actual

00:15:15,750 --> 00:15:20,010
code and so the end user can decide

00:15:17,960 --> 00:15:21,420
which executor they want to use which

00:15:20,010 --> 00:15:23,250
reactor they want to use giving them the

00:15:21,420 --> 00:15:25,470
kind of control that is really important

00:15:23,250 --> 00:15:26,790
in a systems language but the real

00:15:25,470 --> 00:15:28,680
advantage the most important thing about

00:15:26,790 --> 00:15:29,300
this model is that it enabled us to have

00:15:28,680 --> 00:15:31,910
this real

00:15:29,300 --> 00:15:33,290
perfect zero cost a way of implementing

00:15:31,910 --> 00:15:37,340
futures where they're each represented

00:15:33,290 --> 00:15:38,630
is this kind of state machine and so the

00:15:37,340 --> 00:15:40,310
way this works is that when the futures

00:15:38,630 --> 00:15:42,830
that you code that you write gets

00:15:40,310 --> 00:15:44,390
compiled down to it's actually compiled

00:15:42,830 --> 00:15:46,400
into native code where this is the sign

00:15:44,390 --> 00:15:49,220
of like state machine where it has one

00:15:46,400 --> 00:15:52,250
variant for each pause point for each

00:15:49,220 --> 00:15:53,780
i/o event essentially and each variant

00:15:52,250 --> 00:15:58,220
then has the state that it needs to

00:15:53,780 --> 00:15:59,990
resume from that I appoint and that is

00:15:58,220 --> 00:16:02,600
represented as this essentially like an

00:15:59,990 --> 00:16:04,820
enum where it's just one structure where

00:16:02,600 --> 00:16:07,070
it's the variant discriminant and then a

00:16:04,820 --> 00:16:10,850
union of all of the states that it could

00:16:07,070 --> 00:16:12,650
possibly need and so this is an attempt

00:16:10,850 --> 00:16:16,100
to visually represent that abstractly

00:16:12,650 --> 00:16:17,780
where this is a this state machine has

00:16:16,100 --> 00:16:19,790
you know you perform qio events and so

00:16:17,780 --> 00:16:21,670
it has these different states and each

00:16:19,790 --> 00:16:23,810
state it has this the amount of like

00:16:21,670 --> 00:16:26,830
space it needs to store everything you

00:16:23,810 --> 00:16:29,600
will need to restore front to that state

00:16:26,830 --> 00:16:31,580
and the entire future is just a single

00:16:29,600 --> 00:16:34,700
heap allocation that's that size where

00:16:31,580 --> 00:16:39,980
you just allocate that state machine to

00:16:34,700 --> 00:16:41,810
in to one place in the heap and it's

00:16:39,980 --> 00:16:43,040
just no additional overhead so you don't

00:16:41,810 --> 00:16:44,630
have these like all these boxed

00:16:43,040 --> 00:16:47,390
callbacks and things like that you just

00:16:44,630 --> 00:16:52,030
have this like perfect really truly zero

00:16:47,390 --> 00:16:54,470
cost model so I feel like that is

00:16:52,030 --> 00:16:58,220
usually a bit confusing to people so I

00:16:54,470 --> 00:17:02,650
tried to sit to my best keynote visually

00:16:58,220 --> 00:17:05,990
represent what's going on which is that

00:17:02,650 --> 00:17:07,130
the so you spawn a future and that puts

00:17:05,990 --> 00:17:09,470
the future in the heap in this one

00:17:07,130 --> 00:17:10,940
location and then if there's a handle to

00:17:09,470 --> 00:17:13,010
it that's you started in the executor

00:17:10,940 --> 00:17:14,150
the executor pulls the future until

00:17:13,010 --> 00:17:17,950
eventually the future needs to perform

00:17:14,150 --> 00:17:20,959
some sort of i/o in which case the

00:17:17,950 --> 00:17:22,940
feature gets handed off to the reactor

00:17:20,959 --> 00:17:24,980
and the reactor which is handling the

00:17:22,940 --> 00:17:26,839
i/o registers that the future is waiting

00:17:24,980 --> 00:17:28,400
on this particular i/o event and then

00:17:26,839 --> 00:17:30,440
eventually when that i/o event happens

00:17:28,400 --> 00:17:32,330
the reactor will wake up the future

00:17:30,440 --> 00:17:35,000
using the Waker argument that you passed

00:17:32,330 --> 00:17:37,250
in when you pulled it and still waking

00:17:35,000 --> 00:17:39,700
the future up passes it back to the

00:17:37,250 --> 00:17:39,700
executor

00:17:40,160 --> 00:17:44,660
and then the executor will pull it again

00:17:42,800 --> 00:17:45,890
and it'll just go back and forth like

00:17:44,660 --> 00:17:48,490
this until eventually the future

00:17:45,890 --> 00:17:50,480
resolves and so then when the future

00:17:48,490 --> 00:17:52,400
finally resolved in evaluates to its

00:17:50,480 --> 00:17:54,020
final result the executor knows that

00:17:52,400 --> 00:17:55,610
it's done and then it drops the handle

00:17:54,020 --> 00:17:58,160
and drops the future and the whole thing

00:17:55,610 --> 00:18:01,700
is finished and so it forms this sort of

00:17:58,160 --> 00:18:04,250
cycle where you pull the future wait for

00:18:01,700 --> 00:18:06,080
IO waken up again pull it again on and

00:18:04,250 --> 00:18:10,460
on in a loop until eventually the whole

00:18:06,080 --> 00:18:13,270
thing is finished and this model ended

00:18:10,460 --> 00:18:15,710
up being quite fast this is the sort of

00:18:13,270 --> 00:18:18,430
the benchmark that was posted in the

00:18:15,710 --> 00:18:22,610
first post about futures where

00:18:18,430 --> 00:18:24,650
benchmarked features against a lot of

00:18:22,610 --> 00:18:28,730
different implementations from other

00:18:24,650 --> 00:18:32,630
languages higher is better and features

00:18:28,730 --> 00:18:33,980
is the one on the far left so we had

00:18:32,630 --> 00:18:36,260
this really great zero cost abstraction

00:18:33,980 --> 00:18:39,560
that was you know competitive with the

00:18:36,260 --> 00:18:43,240
fastest kinds of implementations of

00:18:39,560 --> 00:18:45,200
async IO in a lot of other languages but

00:18:43,240 --> 00:18:46,160
of course the problem is that you don't

00:18:45,200 --> 00:18:47,030
want to write these state machines by

00:18:46,160 --> 00:18:48,680
hand right you have your whole entire

00:18:47,030 --> 00:18:51,230
application state as a state machine is

00:18:48,680 --> 00:18:52,430
like not very pleasant to write but

00:18:51,230 --> 00:18:53,690
that's where the future abstraction is

00:18:52,430 --> 00:19:00,770
really helpful is that we can build

00:18:53,690 --> 00:19:03,050
these other ApS on top of it and so the

00:19:00,770 --> 00:19:04,790
first solution that we had was this idea

00:19:03,050 --> 00:19:07,700
of futures combinators where you can

00:19:04,790 --> 00:19:09,620
build up the state machines but applying

00:19:07,700 --> 00:19:10,730
all of these methods to the future sort

00:19:09,620 --> 00:19:14,000
of similar to the way that iterator

00:19:10,730 --> 00:19:17,570
adapters like filtering map work and so

00:19:14,000 --> 00:19:19,670
this function it just what it does is it

00:19:17,570 --> 00:19:21,800
requests rustling on org and then

00:19:19,670 --> 00:19:27,560
converts that the response to a string

00:19:21,800 --> 00:19:29,480
and so instead of returning just a

00:19:27,560 --> 00:19:30,650
string and returns a future of a string

00:19:29,480 --> 00:19:33,680
because it's going to be an async

00:19:30,650 --> 00:19:36,170
function and it has these futures in the

00:19:33,680 --> 00:19:37,370
body that it's going to be calling in

00:19:36,170 --> 00:19:40,010
those are going to actually be the parts

00:19:37,370 --> 00:19:41,450
that do some i/o and then they're all

00:19:40,010 --> 00:19:44,540
sort of combined together using these

00:19:41,450 --> 00:19:46,130
combinators like and then in map and we

00:19:44,540 --> 00:19:48,560
built all these combinators like man

00:19:46,130 --> 00:19:50,920
then map filter map error like all kinds

00:19:48,560 --> 00:19:50,920
of different things

00:19:52,240 --> 00:19:57,910
and this works it has you know some

00:19:55,630 --> 00:19:59,530
downsides especially these like nested

00:19:57,910 --> 00:20:02,140
callbacks which can be really difficult

00:19:59,530 --> 00:20:04,920
to read sometimes and so because you

00:20:02,140 --> 00:20:07,750
know it has his down sights we also

00:20:04,920 --> 00:20:10,150
start at it tried to implement an async

00:20:07,750 --> 00:20:11,800
await implementation and so the first

00:20:10,150 --> 00:20:13,510
version of async await was not part of

00:20:11,800 --> 00:20:15,490
the language instead it was this library

00:20:13,510 --> 00:20:19,390
that provided this through like a syntax

00:20:15,490 --> 00:20:21,970
plugin and this is doing the same thing

00:20:19,390 --> 00:20:23,410
that the previous function did it just

00:20:21,970 --> 00:20:26,740
fetches rustling it turns it to a string

00:20:23,410 --> 00:20:29,290
but it does so using a single agent so

00:20:26,740 --> 00:20:30,790
it's much more like straight-line looks

00:20:29,290 --> 00:20:32,710
much more like the way normal blocking

00:20:30,790 --> 00:20:35,170
i/o works we're just like in the example

00:20:32,710 --> 00:20:37,390
that showed originally the only real

00:20:35,170 --> 00:20:38,890
difference is the annotations and so the

00:20:37,390 --> 00:20:40,690
async annotation you know turns this

00:20:38,890 --> 00:20:42,790
function into a future instead of just

00:20:40,690 --> 00:20:47,740
returning immediately and then the await

00:20:42,790 --> 00:20:49,059
annotations are wait on these on the

00:20:47,740 --> 00:20:55,330
futures that you actually construct

00:20:49,059 --> 00:20:59,320
inside of the function and a weight

00:20:55,330 --> 00:21:03,760
under this Paul model these sugars to

00:20:59,320 --> 00:21:06,100
this sort of loop where what you do is

00:21:03,760 --> 00:21:07,720
you just pull in a loop and over time

00:21:06,100 --> 00:21:09,660
you get pending back you yield all the

00:21:07,720 --> 00:21:11,980
way back up to the executor that your

00:21:09,660 --> 00:21:13,660
pending and so then it waits until it

00:21:11,980 --> 00:21:14,950
gets woken up again and then when

00:21:13,660 --> 00:21:16,480
finally the future that you're awaiting

00:21:14,950 --> 00:21:18,100
finishes it

00:21:16,480 --> 00:21:19,420
you know finishes with the value and you

00:21:18,100 --> 00:21:23,800
break out of the loop with the value and

00:21:19,420 --> 00:21:31,000
that's what these await expressions

00:21:23,800 --> 00:21:33,850
evaluate to so this seemed like a really

00:21:31,000 --> 00:21:37,540
good solution you know you have this

00:21:33,850 --> 00:21:39,160
async await notation which is compiling

00:21:37,540 --> 00:21:42,910
down to these really awesome zero-cost

00:21:39,160 --> 00:21:46,110
features and so sort of released futures

00:21:42,910 --> 00:21:51,280
into the wild and got feedback and

00:21:46,110 --> 00:21:53,429
that's where we ran into problems that

00:21:51,280 --> 00:21:56,950
essentially anyone who tried to use

00:21:53,429 --> 00:21:59,320
futures quickly ran into very confusing

00:21:56,950 --> 00:22:00,610
error messages where we've just kind of

00:21:59,320 --> 00:22:01,900
complained about how your feature isn't

00:22:00,610 --> 00:22:04,980
static or it doesn't implement this

00:22:01,900 --> 00:22:06,510
trait and it would be sort of this bath

00:22:04,980 --> 00:22:08,549
thing you didn't really understand and

00:22:06,510 --> 00:22:09,720
the compiler would like to make helpful

00:22:08,549 --> 00:22:11,880
suggestions which you would just follow

00:22:09,720 --> 00:22:13,710
until eventually compiled and C would be

00:22:11,880 --> 00:22:15,360
like annotating closures would move and

00:22:13,710 --> 00:22:17,160
you would put things into reference

00:22:15,360 --> 00:22:18,179
counted pointers and clone things and

00:22:17,160 --> 00:22:19,919
this and that and it all felt like you

00:22:18,179 --> 00:22:20,910
were adding all this overhead to the

00:22:19,919 --> 00:22:22,080
thing that you didn't didn't seem

00:22:20,910 --> 00:22:24,090
necessary didn't understand why you had

00:22:22,080 --> 00:22:25,860
to do it and also when you were down

00:22:24,090 --> 00:22:27,120
your code ended up looking like soup and

00:22:25,860 --> 00:22:28,410
so tons of people were bouncing off of

00:22:27,120 --> 00:22:31,320
futures and it didn't help that the

00:22:28,410 --> 00:22:33,690
Combinator's produce these really huge

00:22:31,320 --> 00:22:35,190
types where your entire terminal would

00:22:33,690 --> 00:22:37,320
be filled up with like the type of one

00:22:35,190 --> 00:22:38,549
of your Combinator chains or just be

00:22:37,320 --> 00:22:40,200
like you know an and then a van and then

00:22:38,549 --> 00:22:43,290
of a map bearer of a TCP stream and so

00:22:40,200 --> 00:22:44,610
on and you know you have to dig through

00:22:43,290 --> 00:22:46,230
this to try to figure out what the

00:22:44,610 --> 00:22:50,490
actual error that you encountered was

00:22:46,230 --> 00:22:53,220
and I found this quote on reddit which I

00:22:50,490 --> 00:22:55,380
think really beautifully sums up all of

00:22:53,220 --> 00:22:56,880
the complaints about features oh it's

00:22:55,380 --> 00:22:58,580
just that you know when using futures

00:22:56,880 --> 00:23:00,809
the error messages are inscrutable

00:22:58,580 --> 00:23:02,309
having to use ref cell or clone

00:23:00,809 --> 00:23:03,720
everything for each feature leads to

00:23:02,309 --> 00:23:05,250
over company to code and it makes me

00:23:03,720 --> 00:23:08,370
wish that rust just had garbage

00:23:05,250 --> 00:23:12,390
collection was just yeah not great

00:23:08,370 --> 00:23:16,650
feedback so looking at the situation

00:23:12,390 --> 00:23:18,390
maybe a year year and a half ago it was

00:23:16,650 --> 00:23:21,419
clear that there were sort of two

00:23:18,390 --> 00:23:22,679
problems that needed to be done to make

00:23:21,419 --> 00:23:25,140
like needed to be solved in order to

00:23:22,679 --> 00:23:26,970
make features more usable for people and

00:23:25,140 --> 00:23:28,980
the first was we need a better error

00:23:26,970 --> 00:23:30,570
messages and so the easiest way to do

00:23:28,980 --> 00:23:32,309
that is to build the syntax into the

00:23:30,570 --> 00:23:33,900
language and then they can hook into all

00:23:32,309 --> 00:23:36,179
of our Diagnostics and error handle

00:23:33,900 --> 00:23:37,429
aramis you know support so that you can

00:23:36,179 --> 00:23:41,010
have really good error messages for

00:23:37,429 --> 00:23:42,390
async/await but the second was that most

00:23:41,010 --> 00:23:44,790
of these errors people are running into

00:23:42,390 --> 00:23:46,650
were actually then bouncing off a

00:23:44,790 --> 00:23:50,490
certain obscure problem which is called

00:23:46,650 --> 00:23:51,840
the borrowing problem where there was

00:23:50,490 --> 00:23:53,790
this fundamental limitations in the way

00:23:51,840 --> 00:23:55,230
that futures was designed that made it

00:23:53,790 --> 00:23:58,110
so something really common pattern was

00:23:55,230 --> 00:24:00,240
not possible to express and that problem

00:23:58,110 --> 00:24:02,460
was that you can't in the original sign

00:24:00,240 --> 00:24:04,799
of futures you could not borrow across

00:24:02,460 --> 00:24:05,940
an awake point so if you were to await

00:24:04,799 --> 00:24:07,350
something you couldn't have any

00:24:05,940 --> 00:24:09,750
references that were alive at that time

00:24:07,350 --> 00:24:10,860
and so when people were having these

00:24:09,750 --> 00:24:12,660
problems that they were bouncing off of

00:24:10,860 --> 00:24:13,740
what they were actually ultimately what

00:24:12,660 --> 00:24:14,130
they were doing was they were trying to

00:24:13,740 --> 00:24:16,169
borrow

00:24:14,130 --> 00:24:17,360
while they were awaiting and they

00:24:16,169 --> 00:24:18,950
couldn't do that

00:24:17,360 --> 00:24:20,930
and so if we could just make it so that

00:24:18,950 --> 00:24:22,370
was allowed then most of these errors

00:24:20,930 --> 00:24:23,630
would go away and everything be much

00:24:22,370 --> 00:24:25,070
easier to use and you could just kind of

00:24:23,630 --> 00:24:32,150
write normal rest code with a sink and a

00:24:25,070 --> 00:24:33,740
late and it would all work and this

00:24:32,150 --> 00:24:35,300
kinds of borrows three weights are

00:24:33,740 --> 00:24:37,550
extremely common because just the

00:24:35,300 --> 00:24:42,050
natural API surface of rust is to have

00:24:37,550 --> 00:24:44,540
references in the API and so but the

00:24:42,050 --> 00:24:46,130
problem with futures is that when you

00:24:44,540 --> 00:24:48,740
actually compile the future which has to

00:24:46,130 --> 00:24:50,030
restore all that state when you have

00:24:48,740 --> 00:24:51,920
some references to something else it's

00:24:50,030 --> 00:24:53,420
in the same stack frame what you end up

00:24:51,920 --> 00:24:55,940
getting is the sort of self referential

00:24:53,420 --> 00:24:59,060
future and so here's the some code from

00:24:55,940 --> 00:25:00,890
the original like get user method where

00:24:59,060 --> 00:25:03,860
we have this sequel string and then when

00:25:00,890 --> 00:25:06,470
we call query with it we use pass a

00:25:03,860 --> 00:25:12,170
reference to the sequel string and so

00:25:06,470 --> 00:25:13,460
the problem here is that this reference

00:25:12,170 --> 00:25:14,840
to the sequel string is a reference to

00:25:13,460 --> 00:25:17,420
something else that's being stored in

00:25:14,840 --> 00:25:18,800
the same future state and so it becomes

00:25:17,420 --> 00:25:20,270
the sort of stuff referential struct

00:25:18,800 --> 00:25:22,160
where you have these are the fields of

00:25:20,270 --> 00:25:24,170
the future in theory if it were you know

00:25:22,160 --> 00:25:26,150
a real struct you would have you know

00:25:24,170 --> 00:25:28,700
the database handle that you were in the

00:25:26,150 --> 00:25:32,060
self aspect of it but I would also have

00:25:28,700 --> 00:25:33,950
the sequel string and the reference to

00:25:32,060 --> 00:25:36,170
the sequel string which is ultimately a

00:25:33,950 --> 00:25:39,590
reference pointing back to a field of

00:25:36,170 --> 00:25:40,580
the same struct and some fresh potential

00:25:39,590 --> 00:25:42,470
structs are sort of a really hard

00:25:40,580 --> 00:25:45,680
problem that we don't have a general

00:25:42,470 --> 00:25:47,240
solution for and the reason that we

00:25:45,680 --> 00:25:51,110
can't allow you to have referenced same

00:25:47,240 --> 00:25:54,170
structs though when you when you move

00:25:51,110 --> 00:25:55,490
that struct then what happens is that we

00:25:54,170 --> 00:25:57,290
make a new copy of the struct in the

00:25:55,490 --> 00:25:59,060
location that you're moving it to and

00:25:57,290 --> 00:26:01,280
when the old copy becomes invalidated

00:25:59,060 --> 00:26:03,530
but when you make that copy the

00:26:01,280 --> 00:26:06,860
reference that was self referential is

00:26:03,530 --> 00:26:09,950
still pointing to the old copy and

00:26:06,860 --> 00:26:11,420
that's becomes a dangling pointer and

00:26:09,950 --> 00:26:13,670
it's the kind of memory issues that rust

00:26:11,420 --> 00:26:14,840
has to prevent so we can't have suffer

00:26:13,670 --> 00:26:17,620
official structs because if you move

00:26:14,840 --> 00:26:20,060
them around then they become invalidated

00:26:17,620 --> 00:26:25,010
but we made this like really frustrating

00:26:20,060 --> 00:26:26,510
in the futures case was that we actually

00:26:25,010 --> 00:26:29,060
don't really need to move these futures

00:26:26,510 --> 00:26:30,200
around so if you remember the the model

00:26:29,060 --> 00:26:30,710
where the futures in the heap and a

00:26:30,200 --> 00:26:31,700
handle

00:26:30,710 --> 00:26:35,299
- it is getting passed back and forth

00:26:31,700 --> 00:26:37,279
between the reactor and the executor the

00:26:35,299 --> 00:26:39,620
future itself never actually moves and

00:26:37,279 --> 00:26:41,630
so it's totally fine for the future to

00:26:39,620 --> 00:26:43,580
contain self-references as long as you

00:26:41,630 --> 00:26:45,919
never move it and you don't need to move

00:26:43,580 --> 00:26:47,600
it so we really needed to solve this

00:26:45,919 --> 00:26:49,460
problem with some way to express in the

00:26:47,600 --> 00:26:51,049
API futures that while you're pulling it

00:26:49,460 --> 00:26:52,580
you're not allowed to move it around and

00:26:51,049 --> 00:26:58,029
then if we just could express that

00:26:52,580 --> 00:26:58,029
somehow then we could we could allow

00:26:58,510 --> 00:27:01,970
these kinds of self references in the

00:27:00,710 --> 00:27:04,130
body of the future and then we could

00:27:01,970 --> 00:27:05,779
just have these really these references

00:27:04,130 --> 00:27:08,330
in your racing functions and everything

00:27:05,779 --> 00:27:10,399
would work and so we were working on

00:27:08,330 --> 00:27:18,020
this problem and ultimately we came out

00:27:10,399 --> 00:27:19,610
with this new API called pin and so pin

00:27:18,020 --> 00:27:21,590
is a sort of adapt her around other

00:27:19,610 --> 00:27:23,179
pointer types where they become this

00:27:21,590 --> 00:27:25,309
pinned reference is there's some normal

00:27:23,179 --> 00:27:26,750
reference and a pinned reference in

00:27:25,309 --> 00:27:29,390
addition to whatever other guarantees it

00:27:26,750 --> 00:27:31,490
has it guarantees that the reference

00:27:29,390 --> 00:27:32,720
will never the value but the reference

00:27:31,490 --> 00:27:34,429
is playing - will never be moved again

00:27:32,720 --> 00:27:36,230
and so guarantees that it's going to

00:27:34,429 --> 00:27:40,130
stay in the same place until eventually

00:27:36,230 --> 00:27:41,690
it gets the allocated and so if you have

00:27:40,130 --> 00:27:43,520
something in your API which says that it

00:27:41,690 --> 00:27:44,630
has to come be taken by pin then you

00:27:43,520 --> 00:27:45,740
know that it will never removed again

00:27:44,630 --> 00:27:50,270
and you can have these kinds of self

00:27:45,740 --> 00:27:52,370
referential structs and so we changed

00:27:50,270 --> 00:27:54,409
the way the futures work so that now

00:27:52,370 --> 00:27:56,779
this is just being a boxed future it's

00:27:54,409 --> 00:27:58,850
the Box future behind a pin so we know

00:27:56,779 --> 00:28:01,190
that wherever we boxed it up and put it

00:27:58,850 --> 00:28:04,010
in the heap it's guaranteed now but I

00:28:01,190 --> 00:28:07,039
part of the pin API that it will never

00:28:04,010 --> 00:28:08,390
move again and then you know when you

00:28:07,039 --> 00:28:10,250
pull the future instead of just passing

00:28:08,390 --> 00:28:12,529
a normal reference to it we pass the pin

00:28:10,250 --> 00:28:15,220
reference to it and so the future knows

00:28:12,529 --> 00:28:17,360
that it won't that it can't be moved and

00:28:15,220 --> 00:28:19,909
the trick here that makes this all work

00:28:17,360 --> 00:28:21,590
is that you can only get an unpin

00:28:19,909 --> 00:28:23,149
reference out of a pin reference in

00:28:21,590 --> 00:28:25,340
unsafe code we make it's an unsafe

00:28:23,149 --> 00:28:27,909
function to be able to do that and so

00:28:25,340 --> 00:28:30,110
the API looks roughly like this where

00:28:27,909 --> 00:28:32,659
you have pin which is just you know a

00:28:30,110 --> 00:28:35,029
wrapper around another around a pointer

00:28:32,659 --> 00:28:36,919
type it doesn't any runtime overhead or

00:28:35,029 --> 00:28:43,090
anything it's just like demarcates it is

00:28:36,919 --> 00:28:45,790
being pinned and then a pin box

00:28:43,090 --> 00:28:46,630
be converted into a pin reference but

00:28:45,790 --> 00:28:48,160
the only way to cover two pinned

00:28:46,630 --> 00:28:55,420
reference into an unpin reference is to

00:28:48,160 --> 00:28:56,950
use an unsafe function and so what we

00:28:55,420 --> 00:28:59,620
did was then we just changed the futures

00:28:56,950 --> 00:29:00,850
API so that we instead of taking a

00:28:59,620 --> 00:29:06,370
normal reference it takes a pinned

00:29:00,850 --> 00:29:08,260
reference and otherwise the API is the

00:29:06,370 --> 00:29:09,580
same as it was before and this is

00:29:08,260 --> 00:29:14,200
essentially the API that we're going to

00:29:09,580 --> 00:29:16,450
going to be stabilizing and so with that

00:29:14,200 --> 00:29:19,120
change this code from the first example

00:29:16,450 --> 00:29:20,860
just works the way that it's written and

00:29:19,120 --> 00:29:22,270
so you can just write code exactly the

00:29:20,860 --> 00:29:24,760
way we would write it with blocking i/o

00:29:22,270 --> 00:29:28,090
add these async and await annotations

00:29:24,760 --> 00:29:29,680
and then what you get is this you know

00:29:28,090 --> 00:29:34,570
async idea with this really awesome zero

00:29:29,680 --> 00:29:35,950
cost abstraction where it's basically is

00:29:34,570 --> 00:29:41,860
cheapest if you hand-wrote the state

00:29:35,950 --> 00:29:43,180
machine yourself by hand so the

00:29:41,860 --> 00:29:45,760
situation today

00:29:43,180 --> 00:29:48,670
pinning was stabilized in the last

00:29:45,760 --> 00:29:50,740
release about a month ago we're in the

00:29:48,670 --> 00:29:54,220
process of stabilizing the future API so

00:29:50,740 --> 00:29:57,910
probably in 1/35 maybe it will slip in

00:29:54,220 --> 00:30:00,160
b1 36 which is know in about two or

00:29:57,910 --> 00:30:01,480
three months basically and then we're

00:30:00,160 --> 00:30:04,000
hoping sometime this year we'll have a

00:30:01,480 --> 00:30:05,400
single Wade state but hopefully by the

00:30:04,000 --> 00:30:07,660
end of summer even we're going to have

00:30:05,400 --> 00:30:11,170
it is stabilized and so that people will

00:30:07,660 --> 00:30:13,810
be able to write non-blocking i/o

00:30:11,170 --> 00:30:15,220
network services using this syntax that

00:30:13,810 --> 00:30:20,020
makes it very similar to writing with

00:30:15,220 --> 00:30:22,720
blocking i/o looking beyond that

00:30:20,020 --> 00:30:25,600
stabilization we're also already

00:30:22,720 --> 00:30:27,880
starting to work on these sort of more

00:30:25,600 --> 00:30:31,420
long-term features like streams I think

00:30:27,880 --> 00:30:33,010
is probably the next big one where it's

00:30:31,420 --> 00:30:34,390
an async

00:30:33,010 --> 00:30:37,090
let's so a feature is just you know one

00:30:34,390 --> 00:30:39,520
value but a stream is many values being

00:30:37,090 --> 00:30:40,840
yield a synchronism being yielded is

00:30:39,520 --> 00:30:43,180
synchronously it's essentially like an

00:30:40,840 --> 00:30:44,890
asynchronous iterator and so you'll be

00:30:43,180 --> 00:30:46,300
able to like loop asynchronously over a

00:30:44,890 --> 00:30:49,330
stream and things like that and it's

00:30:46,300 --> 00:30:50,560
very important for like a lot of use

00:30:49,330 --> 00:30:54,190
cases where you have like you know

00:30:50,560 --> 00:30:56,150
streaming HTTP web sockets in speed to

00:30:54,190 --> 00:30:58,430
push request that kind of thing

00:30:56,150 --> 00:31:00,140
instead of having a networking like our

00:30:58,430 --> 00:31:01,040
PC model where you you know make a

00:31:00,140 --> 00:31:03,080
network request and get a single

00:31:01,040 --> 00:31:06,100
response you have streams of responses

00:31:03,080 --> 00:31:08,450
and requests going back and forth

00:31:06,100 --> 00:31:11,140
there's also today a limitation that

00:31:08,450 --> 00:31:13,100
async offend can't be used in traits

00:31:11,140 --> 00:31:14,420
there's a lot of work being done in the

00:31:13,100 --> 00:31:17,660
compiler to make it so that it would be

00:31:14,420 --> 00:31:19,730
able to support that and looking out

00:31:17,660 --> 00:31:23,030
even beyond these features sometimes we

00:31:19,730 --> 00:31:24,470
want to have generators where for

00:31:23,030 --> 00:31:27,080
similar to generators in like Python or

00:31:24,470 --> 00:31:28,370
JavaScript where instead of just having

00:31:27,080 --> 00:31:30,260
functions to return you can also have

00:31:28,370 --> 00:31:31,550
functions that yield and so then you can

00:31:30,260 --> 00:31:33,470
resume them again after the yield and

00:31:31,550 --> 00:31:35,000
you can use these straight functions as

00:31:33,470 --> 00:31:36,980
a way of writing iterators and streams

00:31:35,000 --> 00:31:38,240
similar to how an async function lets

00:31:36,980 --> 00:31:43,400
you write a function it's actually a

00:31:38,240 --> 00:31:48,290
future but I guess just reserve

00:31:43,400 --> 00:31:49,730
recapping the real critical insights

00:31:48,290 --> 00:31:51,680
that led to this sort of zero cost is

00:31:49,730 --> 00:31:53,930
Takaya model where that first was this

00:31:51,680 --> 00:31:55,070
pole based version of futures where we

00:31:53,930 --> 00:31:57,370
hope to compile these features into

00:31:55,070 --> 00:32:00,170
these really tight state machines and

00:31:57,370 --> 00:32:02,330
then secondly that this way of doing

00:32:00,170 --> 00:32:03,560
async await syntax where we're able to

00:32:02,330 --> 00:32:07,910
have references across the weight points

00:32:03,560 --> 00:32:11,020
because of pinning supposed to say thank

00:32:07,910 --> 00:32:11,020
you I don't know how it became an ex

00:32:20,000 --> 00:32:22,480
[Music]

00:32:21,180 --> 00:32:25,529
[Applause]

00:32:22,480 --> 00:32:25,529

YouTube URL: https://www.youtube.com/watch?v=skos4B5x7qE


