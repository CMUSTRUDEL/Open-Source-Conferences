Title: RustFest Zürich 2017 - Tokio: How we hit 88mph by Alex Crichton
Publication date: 2017-10-21
Playlist: RustFest Zürich 2017
Description: 
	Async I/O has forever been a hot topic of discussion in Rust, but over the past year we’ve seen some significant advances in this domain with the futures crate an the Tokio project. We’ll start off by taking a look at where we are today with the async I/O ecosystem in Rust, highlighting a number of the features we’ve added in both the libraries and the language over the past year. We’ll then take a deep dive into Tokio itself, seeing how it capitalizes on some of Rust’s greatest strengths by going Back to Futures and gets our DeLorean up to 88mph.

About Alex Crichton:
Alex is a member of the Rust Core Team who has worked at Mozilla on Rust for the past four years. He is also a member of the Tokio Core Team, one of the primary authors of Cargo, helps maintain the standard library, and likes to ensure that engine of Rust never stops.
Captions: 
	00:00:12,030 --> 00:00:19,439
the Back to the Future soundtrack greets

00:00:14,490 --> 00:00:21,900
us on day 2 of Rasmus durig today we are

00:00:19,439 --> 00:00:24,270
starting with a keynote by Alex Crichton

00:00:21,900 --> 00:00:27,050
followed by some announcements of

00:00:24,270 --> 00:00:30,450
workshops and the workshops themselves

00:00:27,050 --> 00:00:34,230
ok so I prepared all night for this

00:00:30,450 --> 00:00:37,530
introduction and and that Alex in I

00:00:34,230 --> 00:00:38,489
think it was May 2016 when he was

00:00:37,530 --> 00:00:42,030
traveling Europe

00:00:38,489 --> 00:00:44,160
yep and stop by in Cologne and we sat

00:00:42,030 --> 00:00:47,519
down one evening and I was encouraged

00:00:44,160 --> 00:00:50,820
discussed some parts of his visions for

00:00:47,519 --> 00:00:53,429
rusts future and if I remember correctly

00:00:50,820 --> 00:00:55,140
so we had a lot of drinks so I'm not

00:00:53,429 --> 00:00:56,819
sure it was actually what we talked

00:00:55,140 --> 00:01:00,629
about but I imagine it was something

00:00:56,819 --> 00:01:02,699
like his grand secret vision of like

00:01:00,629 --> 00:01:09,000
taking over the Ross project and

00:01:02,699 --> 00:01:10,860
speeding apps coming a I singularity but

00:01:09,000 --> 00:01:15,170
I don't think that's the kind of futures

00:01:10,860 --> 00:01:18,899
he is going to talk about now anyway so

00:01:15,170 --> 00:01:21,509
it's it's movie your movie related what

00:01:18,899 --> 00:01:26,009
he is going to talk about so of course

00:01:21,509 --> 00:01:32,479
to ask him what is the best indie time

00:01:26,009 --> 00:01:32,479
travel movie and why is it primer

00:01:33,090 --> 00:01:44,950
Alex griping everyone Thank You Pasco

00:01:43,000 --> 00:01:46,750
and actually it was primer and he had

00:01:44,950 --> 00:01:48,700
that question before we said that anyway

00:01:46,750 --> 00:01:50,830
all right so today I would like to talk

00:01:48,700 --> 00:01:52,570
to you about Tokyo and how we hit 88

00:01:50,830 --> 00:01:54,159
miles per hour now I heard some

00:01:52,570 --> 00:01:55,299
questions that not everyone understands

00:01:54,159 --> 00:02:04,060
this so I decided to make it a little

00:01:55,299 --> 00:02:05,710
more European friendly okay sorry I

00:02:04,060 --> 00:02:07,750
should say non American friendly but any

00:02:05,710 --> 00:02:09,280
case my name is Alex I'm member of the

00:02:07,750 --> 00:02:11,380
core team I've been working on rest for

00:02:09,280 --> 00:02:13,090
about four years out of Mozilla now and

00:02:11,380 --> 00:02:14,739
today I'd like to like tell you talk to

00:02:13,090 --> 00:02:16,720
you about Tokyo and asynchronous i/o

00:02:14,739 --> 00:02:18,190
framework and when I say 88 miles per

00:02:16,720 --> 00:02:20,470
hour what I'm actually referring to is

00:02:18,190 --> 00:02:23,019
this movie called back to the future now

00:02:20,470 --> 00:02:25,060
this is an iconic classic of American

00:02:23,019 --> 00:02:27,130
cinema back to the future where the

00:02:25,060 --> 00:02:30,160
defining feature of this movie is this

00:02:27,130 --> 00:02:32,440
magic a scientific DeLorean powered by

00:02:30,160 --> 00:02:34,600
the flux capacitor where when it reaches

00:02:32,440 --> 00:02:36,970
88 miles per hour you'll see sparks fly

00:02:34,600 --> 00:02:38,709
and it travels forwards and backwards in

00:02:36,970 --> 00:02:40,450
time and it's an amazing movie everyone

00:02:38,709 --> 00:02:42,060
should go watch it I'll be hosting it

00:02:40,450 --> 00:02:44,890
afterward not I don't actually have it

00:02:42,060 --> 00:02:46,150
so when I talk about I want to talk

00:02:44,890 --> 00:02:47,470
about back to the future i mean i'm

00:02:46,150 --> 00:02:49,299
using this movie because it has the word

00:02:47,470 --> 00:02:51,670
future in it but also it implies this

00:02:49,299 --> 00:02:53,440
insane level of speed and so when i talk

00:02:51,670 --> 00:02:55,720
about this what I mean is that Tokyo

00:02:53,440 --> 00:02:57,549
itself is an insanely fast asynchronous

00:02:55,720 --> 00:02:59,019
i/o framework so this is kind of the

00:02:57,549 --> 00:03:00,730
canonical chart that we like to show

00:02:59,019 --> 00:03:02,890
which actually introduced Tokyo and

00:03:00,730 --> 00:03:04,690
futures to the rest community we're on

00:03:02,890 --> 00:03:06,250
this far left on the far left you have

00:03:04,690 --> 00:03:08,170
this very tall graph which is the rust

00:03:06,250 --> 00:03:10,000
thing showing that we have this insanely

00:03:08,170 --> 00:03:11,880
high request per second even compared to

00:03:10,000 --> 00:03:13,780
a bunch of other frameworks and so

00:03:11,880 --> 00:03:17,109
almost people tend to have a reaction

00:03:13,780 --> 00:03:19,630
looks like this Marty McFly and Doc I'm

00:03:17,109 --> 00:03:21,100
gonna I I will tone back the back to the

00:03:19,630 --> 00:03:24,280
future references eventually but not yet

00:03:21,100 --> 00:03:26,620
so to explain this we typically say that

00:03:24,280 --> 00:03:28,420
rust has zero cost futures that's kind

00:03:26,620 --> 00:03:30,489
of the foundation by which all of this

00:03:28,420 --> 00:03:32,290
is built the zero cost future aspects

00:03:30,489 --> 00:03:33,819
but while you're hearing about this

00:03:32,290 --> 00:03:35,290
you're like wait hang on I'd like you to

00:03:33,819 --> 00:03:36,760
explain a little bit more before you say

00:03:35,290 --> 00:03:38,440
that we're gonna say all but mio is low

00:03:36,760 --> 00:03:40,660
level you have this meal library it's

00:03:38,440 --> 00:03:42,700
great does all this a society like great

00:03:40,660 --> 00:03:44,200
what's me oh well we also have traits

00:03:42,700 --> 00:03:46,180
it's a future of a tree you can do

00:03:44,200 --> 00:03:46,750
whatever you want we have this Tokyo

00:03:46,180 --> 00:03:48,790
frame

00:03:46,750 --> 00:03:50,320
layers and all these possible entry

00:03:48,790 --> 00:03:51,910
points for you and we have lightweight

00:03:50,320 --> 00:03:53,650
tasks that are kind of like green

00:03:51,910 --> 00:03:54,790
threading and it ends up feeling a

00:03:53,650 --> 00:03:57,040
little bit like this when we're just

00:03:54,790 --> 00:03:58,480
kind of shouting all this at you and if

00:03:57,040 --> 00:04:00,220
you don't recognize this I would highly

00:03:58,480 --> 00:04:03,220
recommend you watch the talks from Russ

00:04:00,220 --> 00:04:04,930
comp in 2016 it was excellent but so

00:04:03,220 --> 00:04:07,209
today I want to give you the equivalent

00:04:04,930 --> 00:04:08,650
of a sports Almanac and you might be

00:04:07,209 --> 00:04:10,480
thinking that's that's insane what are

00:04:08,650 --> 00:04:12,880
you talking about here but back to the

00:04:10,480 --> 00:04:15,160
future - that's right there's actually

00:04:12,880 --> 00:04:17,230
three movies but in the second movie the

00:04:15,160 --> 00:04:20,919
plot of this movie was that the evil

00:04:17,230 --> 00:04:23,620
Biff Biff just sounds evil the evil Biff

00:04:20,919 --> 00:04:25,720
takes a sports Almanac back in time so I

00:04:23,620 --> 00:04:27,760
think his dad at that time and Gabe King

00:04:25,720 --> 00:04:29,440
gives us to him and then using the

00:04:27,760 --> 00:04:31,810
sports Almanac he's able to correctly

00:04:29,440 --> 00:04:33,790
predict every single horse race or every

00:04:31,810 --> 00:04:35,080
single race or sports event and

00:04:33,790 --> 00:04:36,850
basically get super rich from gambling

00:04:35,080 --> 00:04:38,410
and all that so I'm not actually going

00:04:36,850 --> 00:04:40,060
to talk much about sports here but I'd

00:04:38,410 --> 00:04:42,340
like to give you the Tokyo Almanac

00:04:40,060 --> 00:04:44,380
instead all the only valid until 2018

00:04:42,340 --> 00:04:46,210
but so I would like to give you a bit of

00:04:44,380 --> 00:04:47,860
an idea today about kind of the

00:04:46,210 --> 00:04:49,780
internals of Tokyo and kind of the

00:04:47,860 --> 00:04:51,700
internals of futures and give you a

00:04:49,780 --> 00:04:53,860
better idea about what I actually mean

00:04:51,700 --> 00:04:56,020
by zero costs how we actually achieve

00:04:53,860 --> 00:04:58,860
these insane levels of speed that we see

00:04:56,020 --> 00:05:01,570
on futures and that we see in Tokyo so

00:04:58,860 --> 00:05:03,970
to start off I like to give you a bit of

00:05:01,570 --> 00:05:05,530
an idea about what I mean by async IO

00:05:03,970 --> 00:05:07,270
and can I give you a bit of an

00:05:05,530 --> 00:05:08,500
introduction to Tokyo itself in case

00:05:07,270 --> 00:05:10,030
you're not super familiar with it which

00:05:08,500 --> 00:05:13,330
I'm sure there's a few of you at least

00:05:10,030 --> 00:05:14,740
so to start off asynchronous IO is

00:05:13,330 --> 00:05:16,630
typically contrasted with what is

00:05:14,740 --> 00:05:18,070
typically the first thing you reach in

00:05:16,630 --> 00:05:20,470
foreign programming which is synchronous

00:05:18,070 --> 00:05:22,330
i/o so in synchronous i/o what typically

00:05:20,470 --> 00:05:23,919
do is you'll have a TCP socket and

00:05:22,330 --> 00:05:26,140
you'll say I want to read some data off

00:05:23,919 --> 00:05:27,760
of this into this buffer and then after

00:05:26,140 --> 00:05:29,440
some amount of time the kernel will come

00:05:27,760 --> 00:05:31,990
back and say alright you got 4 bytes and

00:05:29,440 --> 00:05:34,419
the key thing here is that you're the

00:05:31,990 --> 00:05:36,520
calling context this current thread is

00:05:34,419 --> 00:05:38,710
blocked it can do nothing else until

00:05:36,520 --> 00:05:41,290
this call returns so it can do nothing

00:05:38,710 --> 00:05:43,570
useful while you're waiting for a TCP

00:05:41,290 --> 00:05:45,190
read or kind of bytes to come in and I

00:05:43,570 --> 00:05:46,840
can take a very long time sometimes you

00:05:45,190 --> 00:05:48,280
could have some connections boarding at

00:05:46,840 --> 00:05:49,450
megabytes per second other connections

00:05:48,280 --> 00:05:51,100
weren't them running at megabits or

00:05:49,450 --> 00:05:53,530
kilobytes per second it's it's kind of

00:05:51,100 --> 00:05:55,570
very variable there so the defining

00:05:53,530 --> 00:05:57,669
aspect of a synced IO is that the kernel

00:05:55,570 --> 00:06:00,220
immediately says nope this is going to

00:05:57,669 --> 00:06:00,590
block so all of these operations like

00:06:00,220 --> 00:06:02,000
when you

00:06:00,590 --> 00:06:03,980
we didn't do a buffer the colonel will

00:06:02,000 --> 00:06:05,540
immediately tell you I do not have bites

00:06:03,980 --> 00:06:06,530
you're gonna have to figure out one to

00:06:05,540 --> 00:06:08,570
call me again later

00:06:06,530 --> 00:06:10,790
so specifically what's happening here is

00:06:08,570 --> 00:06:12,639
that every single IO operation in the

00:06:10,790 --> 00:06:15,230
icing or cider world never blocks

00:06:12,639 --> 00:06:16,790
everything immediately returns and just

00:06:15,230 --> 00:06:19,940
immediately takes no time at all and

00:06:16,790 --> 00:06:21,889
then later you will receive a batch set

00:06:19,940 --> 00:06:23,060
of notification saying these objects are

00:06:21,889 --> 00:06:24,590
ready for reading these objects are

00:06:23,060 --> 00:06:27,560
ready for writing kind of various events

00:06:24,590 --> 00:06:28,820
coming out of the colonel and so you are

00:06:27,560 --> 00:06:30,919
then responsible for actually

00:06:28,820 --> 00:06:32,120
dispatching these events you have to

00:06:30,919 --> 00:06:33,680
then say all right well I am

00:06:32,120 --> 00:06:34,639
interpreting these these giant lists

00:06:33,680 --> 00:06:36,770
from the colonel and I'm going to figure

00:06:34,639 --> 00:06:38,900
out where all that goes what that ends

00:06:36,770 --> 00:06:40,880
up looking like is actually a very

00:06:38,900 --> 00:06:41,930
difficult world to work with so

00:06:40,880 --> 00:06:43,630
typically you're a pretty reasonable

00:06:41,930 --> 00:06:45,770
person you just want to grab the

00:06:43,630 --> 00:06:47,479
contents of the rustling homepage and

00:06:45,770 --> 00:06:49,820
just want to render that your browser

00:06:47,479 --> 00:06:51,229
your servo your whatever but as a result

00:06:49,820 --> 00:06:52,910
of this question or results of this

00:06:51,229 --> 00:06:54,710
requests the only thing we can do is all

00:06:52,910 --> 00:06:56,330
file descriptor five is ready and that's

00:06:54,710 --> 00:06:57,710
not actually very helpful we can't okay

00:06:56,330 --> 00:06:59,840
well I don't really know what file

00:06:57,710 --> 00:07:01,880
descriptor five is connected to where

00:06:59,840 --> 00:07:03,919
does the TLS in there so kind of this

00:07:01,880 --> 00:07:05,419
ends up being a very difficult system to

00:07:03,919 --> 00:07:07,400
work with this kind of asynchronous i/o

00:07:05,419 --> 00:07:09,200
world is very unwieldy it's not

00:07:07,400 --> 00:07:11,300
composable and it's very difficult to

00:07:09,200 --> 00:07:14,120
get right and so to solve this problem

00:07:11,300 --> 00:07:17,660
this is where futures come into play so

00:07:14,120 --> 00:07:19,370
futures are a sentinel for a value which

00:07:17,660 --> 00:07:21,650
will then become available at a later

00:07:19,370 --> 00:07:23,000
point in time and more clearly what's

00:07:21,650 --> 00:07:25,250
happening here is that a future is a

00:07:23,000 --> 00:07:27,260
proxy for an object which will kind of

00:07:25,250 --> 00:07:29,389
like you eventually can pull it out but

00:07:27,260 --> 00:07:31,700
it's not immediately ready but it's kind

00:07:29,389 --> 00:07:33,350
of the embodiment of object or objects

00:07:31,700 --> 00:07:35,300
orientation in the asynchronous i/o

00:07:33,350 --> 00:07:37,550
world where you have this one object

00:07:35,300 --> 00:07:39,979
which encapsulates all of its internal

00:07:37,550 --> 00:07:41,510
state and it's kind of all of opaque box

00:07:39,979 --> 00:07:43,250
all you know is that you can pull out a

00:07:41,510 --> 00:07:44,450
particular type from it and it's just

00:07:43,250 --> 00:07:46,430
happening asynchronously in the

00:07:44,450 --> 00:07:47,840
background and the other key thing about

00:07:46,430 --> 00:07:49,460
features kind of like with

00:07:47,840 --> 00:07:50,690
object-oriented programming is that you

00:07:49,460 --> 00:07:52,639
can actually start composing these

00:07:50,690 --> 00:07:54,590
together so you can say once this

00:07:52,639 --> 00:07:56,539
feature has completed I can now run this

00:07:54,590 --> 00:07:58,280
future or I can change a future of a

00:07:56,539 --> 00:07:59,870
string to a future of an integer by just

00:07:58,280 --> 00:08:01,490
parsing it and kind of all these other

00:07:59,870 --> 00:08:03,950
various operations you can do internally

00:08:01,490 --> 00:08:05,810
just by kind of creating and mapping and

00:08:03,950 --> 00:08:08,360
dealing with all these features that are

00:08:05,810 --> 00:08:10,250
themselves objects so an example of this

00:08:08,360 --> 00:08:12,140
is this previous example we had of kind

00:08:10,250 --> 00:08:14,540
of grabbing the contents of the rustling

00:08:12,140 --> 00:08:16,490
homepage well now when you ask this

00:08:14,540 --> 00:08:18,590
instead of saying fob escape the five is

00:08:16,490 --> 00:08:20,660
ready you'll get this response oh no all

00:08:18,590 --> 00:08:23,510
right here is a future of a vector of

00:08:20,660 --> 00:08:25,340
bytes and this internally encapsulate

00:08:23,510 --> 00:08:27,050
everything necessary to actually deal

00:08:25,340 --> 00:08:28,610
with this so for example this is going

00:08:27,050 --> 00:08:30,170
to make a TCP connection well it's first

00:08:28,610 --> 00:08:31,640
it's gonna resolve rustling door it's

00:08:30,170 --> 00:08:33,080
gonna make a TCP connection to one of

00:08:31,640 --> 00:08:35,090
those sites it's gonna negotiate TLS

00:08:33,080 --> 00:08:36,890
it's gonna parse the HTTP protocol it's

00:08:35,090 --> 00:08:38,990
gonna deal with the request response all

00:08:36,890 --> 00:08:40,580
of that is encapsulated in just this one

00:08:38,990 --> 00:08:42,650
future and you don't have to worry about

00:08:40,580 --> 00:08:44,600
any of the internal states so kind of

00:08:42,650 --> 00:08:46,550
all that is built for you and you know

00:08:44,600 --> 00:08:48,170
there's much there's far fewer kind of

00:08:46,550 --> 00:08:50,120
correctness worries it's much easier to

00:08:48,170 --> 00:08:51,980
get futures programming correct that

00:08:50,120 --> 00:08:53,410
needs to deal with just juggling file

00:08:51,980 --> 00:08:56,060
descriptors around all around the place

00:08:53,410 --> 00:08:57,380
and to give you another example of what

00:08:56,060 --> 00:08:58,970
I mean by futures and some examples of

00:08:57,380 --> 00:09:00,410
what you can do with it this is a small

00:08:58,970 --> 00:09:02,570
example what we're gonna spawn off some

00:09:00,410 --> 00:09:05,660
work so we'll stay here we're gonna on

00:09:02,570 --> 00:09:07,340
some thread pools spawn the 115 op G

00:09:05,660 --> 00:09:09,500
numbers some asynchronous computation

00:09:07,340 --> 00:09:11,750
and the key thing here is this function

00:09:09,500 --> 00:09:14,360
will immediately return and this local

00:09:11,750 --> 00:09:16,430
variable result is going to be a proxy

00:09:14,360 --> 00:09:18,620
for the actual value of the hundred

00:09:16,430 --> 00:09:20,120
Fibonacci number so in the meantime we

00:09:18,620 --> 00:09:21,320
can do whatever we can grab some coffee

00:09:20,120 --> 00:09:22,760
you can try and wake up because it's a

00:09:21,320 --> 00:09:24,950
little early in the morning we can then

00:09:22,760 --> 00:09:26,420
come out and say all right eventually I

00:09:24,950 --> 00:09:28,130
actually need the value of this feature

00:09:26,420 --> 00:09:29,870
so you can wait on it you can wait for

00:09:28,130 --> 00:09:31,190
it to be resolved and I'll perform some

00:09:29,870 --> 00:09:32,930
synchronization with the actual thread

00:09:31,190 --> 00:09:34,400
pool itself and then eventually this

00:09:32,930 --> 00:09:36,410
result down here at the bottom will

00:09:34,400 --> 00:09:38,600
actually be the hundredth Fibonacci

00:09:36,410 --> 00:09:40,640
number and you have this resolved value

00:09:38,600 --> 00:09:43,130
of the future and so the key thing here

00:09:40,640 --> 00:09:45,080
is that is asynchronous whenever you

00:09:43,130 --> 00:09:46,430
have a future the the computation the

00:09:45,080 --> 00:09:48,110
result of that computation is somehow

00:09:46,430 --> 00:09:50,450
being computed in the background at a

00:09:48,110 --> 00:09:53,360
quote unquote sense and you can do other

00:09:50,450 --> 00:09:55,280
work in the meantime as a result now so

00:09:53,360 --> 00:09:58,070
moving up to Tokyo I like to say that

00:09:55,280 --> 00:10:00,500
Tokyo is the fusion of the Meo library

00:09:58,070 --> 00:10:01,850
and futures now you don't have to worry

00:10:00,500 --> 00:10:03,740
so much about what actually mio

00:10:01,850 --> 00:10:06,920
particularly is but it suffice to say

00:10:03,740 --> 00:10:08,690
that it's cross-platform async IO and so

00:10:06,920 --> 00:10:10,880
dealing with async IO is actually

00:10:08,690 --> 00:10:12,530
entirely different on Linux and OS X and

00:10:10,880 --> 00:10:14,390
Windows and dealing with all of these

00:10:12,530 --> 00:10:14,960
details all the time is very very

00:10:14,390 --> 00:10:16,880
difficult

00:10:14,960 --> 00:10:19,070
so what mio is doing is basically just

00:10:16,880 --> 00:10:20,900
giving you a cross-platform uniform

00:10:19,070 --> 00:10:23,090
interface to asynchronous i/o on the

00:10:20,900 --> 00:10:25,910
actual system so what anyone says me oh

00:10:23,090 --> 00:10:27,820
all I really mean is that non-blocking

00:10:25,910 --> 00:10:29,380
i/o if things return immediately

00:10:27,820 --> 00:10:31,390
and then there's some way later to get a

00:10:29,380 --> 00:10:33,310
batch set of notification saying this is

00:10:31,390 --> 00:10:34,630
everything that just happens and then

00:10:33,310 --> 00:10:36,670
features on the other hand with Tokyo

00:10:34,630 --> 00:10:38,290
basically just mean that you can build

00:10:36,670 --> 00:10:40,240
up these features with AI objects

00:10:38,290 --> 00:10:42,340
internally so you can say I can build up

00:10:40,240 --> 00:10:43,660
TCP sockets and I can have suspect it

00:10:42,340 --> 00:10:47,610
can be part of the logic of how to

00:10:43,660 --> 00:10:50,140
resolve my future so Tokyo is

00:10:47,610 --> 00:10:53,020
essentially futures powered by IO this

00:10:50,140 --> 00:10:55,810
is TCP UDP UNIX sockets name pipes all

00:10:53,020 --> 00:10:57,310
that good stuff Tokyo because it is

00:10:55,810 --> 00:10:59,770
built on top of me who ends up working

00:10:57,310 --> 00:11:01,240
across all major platforms and then

00:10:59,770 --> 00:11:02,890
finally if you if you're familiar with a

00:11:01,240 --> 00:11:04,360
string of sleeo in general toki was kind

00:11:02,890 --> 00:11:05,980
of your event loop Toki was the one

00:11:04,360 --> 00:11:07,750
that's actually dispatching these events

00:11:05,980 --> 00:11:09,370
so he's the one that is responsible for

00:11:07,750 --> 00:11:10,780
waking up these features and we'll get

00:11:09,370 --> 00:11:14,620
into all that a little bit more in

00:11:10,780 --> 00:11:15,820
detail later and I also think Toki was

00:11:14,620 --> 00:11:17,440
kind of a cool name and a fun city to

00:11:15,820 --> 00:11:19,780
visit highly recommend everyone visit

00:11:17,440 --> 00:11:21,490
Tokyo it's a lot of fun but to give you

00:11:19,780 --> 00:11:23,710
a bit of an idea of where futures is

00:11:21,490 --> 00:11:25,570
where features are today so in the

00:11:23,710 --> 00:11:27,460
futures crate we have a trait for a

00:11:25,570 --> 00:11:29,620
future which is one value coming out at

00:11:27,460 --> 00:11:31,270
a particular time we just have a stream

00:11:29,620 --> 00:11:32,350
trait for many many values coming over

00:11:31,270 --> 00:11:34,780
time you can think of this as an

00:11:32,350 --> 00:11:37,180
asynchronous iterator just items with

00:11:34,780 --> 00:11:39,100
very long pauses between them we also

00:11:37,180 --> 00:11:41,260
have a sink where streams are kind of

00:11:39,100 --> 00:11:43,210
given items were given to you whereas

00:11:41,260 --> 00:11:45,460
with a sink you push items in there and

00:11:43,210 --> 00:11:47,350
then we also have a bunch of in memory

00:11:45,460 --> 00:11:49,150
we have kind of a very large toolkit

00:11:47,350 --> 00:11:50,920
around dealing with features today so we

00:11:49,150 --> 00:11:52,720
have one-shot channels for in-memory

00:11:50,920 --> 00:11:55,420
computations like that Fibonacci number

00:11:52,720 --> 00:11:56,830
we saw earlier we have NTSC streams very

00:11:55,420 --> 00:11:59,350
similar to the standard library of just

00:11:56,830 --> 00:12:02,230
in-memory thread-safe channels dealing

00:11:59,350 --> 00:12:03,820
with items over time and then finally

00:12:02,230 --> 00:12:05,710
you'll find a lot of integration with

00:12:03,820 --> 00:12:07,540
modern crates such as rayon where you

00:12:05,710 --> 00:12:09,100
can actually just spawn some work into a

00:12:07,540 --> 00:12:10,630
rayon thread pool and get a feature out

00:12:09,100 --> 00:12:11,710
of that and then whenever you block on

00:12:10,630 --> 00:12:13,540
that future it'll kind of do the right

00:12:11,710 --> 00:12:15,910
thing of doing the rayon work-stealing

00:12:13,540 --> 00:12:18,130
using either cores ends up being super

00:12:15,910 --> 00:12:19,510
fast but so the other thing I wanted to

00:12:18,130 --> 00:12:21,580
talk about with features today is we

00:12:19,510 --> 00:12:23,140
actually do have async await syntax and

00:12:21,580 --> 00:12:25,450
some of you who are familiar with

00:12:23,140 --> 00:12:27,100
JavaScript or C sharp or Python working

00:12:25,450 --> 00:12:28,570
in the asynchronous worlds there you'll

00:12:27,100 --> 00:12:30,580
remember that you'll probably know that

00:12:28,570 --> 00:12:32,710
this kind of syntax is critical for

00:12:30,580 --> 00:12:34,840
white for writing large applications and

00:12:32,710 --> 00:12:37,000
so this is only available in the nightly

00:12:34,840 --> 00:12:38,620
Channel today it's very pretty recent at

00:12:37,000 --> 00:12:40,660
this point but some of the highlights

00:12:38,620 --> 00:12:41,650
are the you can activate this by having

00:12:40,660 --> 00:12:43,660
this async attribute

00:12:41,650 --> 00:12:46,360
which says that this function is

00:12:43,660 --> 00:12:48,070
actually going to return a future so

00:12:46,360 --> 00:12:49,300
despite saying the return value as a

00:12:48,070 --> 00:12:51,100
result this is actually going to

00:12:49,300 --> 00:12:53,200
construct some future and then return it

00:12:51,100 --> 00:12:55,000
whenever you invoke it you can then use

00:12:53,200 --> 00:12:57,130
the weight macro to say I like to

00:12:55,000 --> 00:12:59,170
actually block on this value of the

00:12:57,130 --> 00:13:00,790
future so this is a hyper asynchronous

00:12:59,170 --> 00:13:02,980
client which gives you a future result

00:13:00,790 --> 00:13:04,570
but this will actually block the thread

00:13:02,980 --> 00:13:05,440
it's just going to block the future so

00:13:04,570 --> 00:13:06,970
this is still an asynchronous

00:13:05,440 --> 00:13:08,890
computation and it's able to just kind

00:13:06,970 --> 00:13:10,870
of write code in a very synchronous

00:13:08,890 --> 00:13:13,540
looking style well end up just building

00:13:10,870 --> 00:13:15,130
a giant asynchronous feature if you've

00:13:13,540 --> 00:13:16,450
worked with Combinator's and rust if you

00:13:15,130 --> 00:13:18,250
kind of work the futures before you'll

00:13:16,450 --> 00:13:19,960
notice that early returns are insanely

00:13:18,250 --> 00:13:21,610
hard and they're very easy to do this is

00:13:19,960 --> 00:13:23,140
gonna wait so this is kind of a great

00:13:21,610 --> 00:13:25,180
feature having early returns about

00:13:23,140 --> 00:13:26,589
okay's or errors and again just kind of

00:13:25,180 --> 00:13:28,000
adds to the very synchronous feeling of

00:13:26,589 --> 00:13:30,940
code kind of what you would expect from

00:13:28,000 --> 00:13:32,830
normal rust as you write it today and

00:13:30,940 --> 00:13:34,630
then finally we also have asynchronous

00:13:32,830 --> 00:13:36,310
for loops where we have this stream

00:13:34,630 --> 00:13:37,930
trait to kind of values coming out over

00:13:36,310 --> 00:13:40,120
time so this is saying that the the

00:13:37,930 --> 00:13:41,560
actual body of this HTTP request is

00:13:40,120 --> 00:13:43,420
taking a long time to come to us so what

00:13:41,560 --> 00:13:44,920
kind of process each chunk and then this

00:13:43,420 --> 00:13:47,620
is all just building up one giant

00:13:44,920 --> 00:13:49,480
feature externally to work with so I

00:13:47,620 --> 00:13:50,650
just don't talk a little bit about where

00:13:49,480 --> 00:13:52,839
Tokyo is today

00:13:50,650 --> 00:13:54,790
Tokyo is currently split up into a few

00:13:52,839 --> 00:13:56,080
crates I won't go into too much detail

00:13:54,790 --> 00:13:57,910
about these we have took you a core

00:13:56,080 --> 00:13:59,709
awesome higher-level proto and service

00:13:57,910 --> 00:14:01,390
but if you're interested in kind of the

00:13:59,709 --> 00:14:03,310
details here I highly recommend you

00:14:01,390 --> 00:14:05,170
start with the current RFC and kind of

00:14:03,310 --> 00:14:06,430
reorganizing some of these crates I just

00:14:05,170 --> 00:14:09,220
think it's number three now I've had to

00:14:06,430 --> 00:14:11,320
close that by accident but it's spice to

00:14:09,220 --> 00:14:12,790
say that in any case today we took you

00:14:11,320 --> 00:14:14,529
has a very large amount of iterations

00:14:12,790 --> 00:14:16,240
with other objects in the community so

00:14:14,529 --> 00:14:18,040
in addition to the networking types of

00:14:16,240 --> 00:14:18,760
TCP and UDP you'll have unix-like that's

00:14:18,040 --> 00:14:22,089
named pipes

00:14:18,760 --> 00:14:24,640
signals protocols such as HTTP - coming

00:14:22,089 --> 00:14:26,529
soon we've seen more and more protocols

00:14:24,640 --> 00:14:28,570
more and more I of primitives getting

00:14:26,529 --> 00:14:30,640
bound and took you everyday so you end

00:14:28,570 --> 00:14:31,660
up having a very large suite of objects

00:14:30,640 --> 00:14:33,550
to choose from kind of what you would

00:14:31,660 --> 00:14:35,950
expect out of an event loop library and

00:14:33,550 --> 00:14:37,390
also we've seen Tokyo deployed with

00:14:35,950 --> 00:14:39,250
great success to a lot of companies so

00:14:37,390 --> 00:14:41,160
far and we're super excited to see where

00:14:39,250 --> 00:14:44,440
everyone takes it from there

00:14:41,160 --> 00:14:47,290
sorry that's a little bit about Tokyo

00:14:44,440 --> 00:14:48,970
and futures so it's a bit of an

00:14:47,290 --> 00:14:50,589
introduction so now now they're kind of

00:14:48,970 --> 00:14:53,860
on the same page I want to dive a little

00:14:50,589 --> 00:14:55,270
bit more into why the future tree is so

00:14:53,860 --> 00:14:56,950
fast and so

00:14:55,270 --> 00:14:57,850
we're gonna get to this concept of tasks

00:14:56,950 --> 00:15:00,610
that have actually mention that later

00:14:57,850 --> 00:15:02,680
but specifically let's start out by

00:15:00,610 --> 00:15:04,900
writing a future let's define a future

00:15:02,680 --> 00:15:06,190
let's start from let's circumscribe so

00:15:04,900 --> 00:15:08,170
the first thing that we might do is

00:15:06,190 --> 00:15:09,820
write down as struts so we'll say we'll

00:15:08,170 --> 00:15:10,990
have a struct of a future with some type

00:15:09,820 --> 00:15:12,700
that it can resolve to because it's

00:15:10,990 --> 00:15:14,800
generic and I don't have some sort of

00:15:12,700 --> 00:15:16,540
invitation for this but right off the

00:15:14,800 --> 00:15:19,180
bat there's already a first problem the

00:15:16,540 --> 00:15:21,160
fact that this is a struct this means

00:15:19,180 --> 00:15:22,480
that there is one implementation of the

00:15:21,160 --> 00:15:24,580
future that we're going to be giving you

00:15:22,480 --> 00:15:25,840
but that actually might not always be

00:15:24,580 --> 00:15:27,370
correct that could be a thread safe

00:15:25,840 --> 00:15:29,230
future and you may not want to pay for

00:15:27,370 --> 00:15:30,880
that level of thread safety it could be

00:15:29,230 --> 00:15:33,580
an entree say future and you want that

00:15:30,880 --> 00:15:35,860
level of thread safety so this ends up

00:15:33,580 --> 00:15:37,540
being very inflexible where you by

00:15:35,860 --> 00:15:39,010
having only one definition we can't

00:15:37,540 --> 00:15:41,080
necessarily cater to everyone's needs

00:15:39,010 --> 00:15:43,750
but turns out rust does have a feature

00:15:41,080 --> 00:15:45,460
for this called trace so traits allow

00:15:43,750 --> 00:15:46,930
you to have the most specialized

00:15:45,460 --> 00:15:48,880
implementation for a future that you

00:15:46,930 --> 00:15:50,080
possibly need so your case of if you

00:15:48,880 --> 00:15:51,280
need thread safe you can use a thread

00:15:50,080 --> 00:15:52,570
safe future if you don't need thread

00:15:51,280 --> 00:15:53,830
safe you can use a non for a safe future

00:15:52,570 --> 00:15:55,420
and it kind of they can still

00:15:53,830 --> 00:15:56,770
interoperate together because they're

00:15:55,420 --> 00:15:57,340
still implementing the same fundamental

00:15:56,770 --> 00:15:59,190
tree

00:15:57,340 --> 00:16:01,780
I'm this we have an associated item

00:15:59,190 --> 00:16:03,100
what's actually coming out but another

00:16:01,780 --> 00:16:04,150
problem is we have to actually fill the

00:16:03,100 --> 00:16:06,340
soon we need to have some sort of

00:16:04,150 --> 00:16:08,260
implementation here and so as I was

00:16:06,340 --> 00:16:09,700
saying earlier a feature is a sentinel

00:16:08,260 --> 00:16:11,860
for a value which is going to become

00:16:09,700 --> 00:16:14,680
available at some point in time and so

00:16:11,860 --> 00:16:16,450
when we think about this it's kind of a

00:16:14,680 --> 00:16:17,710
future is an asynchronous computation

00:16:16,450 --> 00:16:19,660
eventually it's going to be run

00:16:17,710 --> 00:16:21,010
adventure it's going to be completed so

00:16:19,660 --> 00:16:23,140
why not let's have some sort of callback

00:16:21,010 --> 00:16:24,970
let's say that when this feature is

00:16:23,140 --> 00:16:26,710
resolved when this feature finishes

00:16:24,970 --> 00:16:28,570
completing itself it's going to invoke

00:16:26,710 --> 00:16:29,740
this callback with the actual value and

00:16:28,570 --> 00:16:31,570
that way you can then do further

00:16:29,740 --> 00:16:33,850
processing and you can hook into how

00:16:31,570 --> 00:16:35,920
this feature is being completed it turns

00:16:33,850 --> 00:16:37,750
out in most systems that implement

00:16:35,920 --> 00:16:38,680
features today this is actually how it's

00:16:37,750 --> 00:16:40,810
implemented you have some sort of

00:16:38,680 --> 00:16:42,940
callback based system where when the

00:16:40,810 --> 00:16:44,170
futures are done you run a callback and

00:16:42,940 --> 00:16:46,300
then that might go and further in

00:16:44,170 --> 00:16:48,190
schedule some more callbacks so I want

00:16:46,300 --> 00:16:49,570
to dive into a lot of details here about

00:16:48,190 --> 00:16:51,520
we have we actually went down this road

00:16:49,570 --> 00:16:53,350
quite a long ways before we ended up

00:16:51,520 --> 00:16:55,000
where we currently are today and so the

00:16:53,350 --> 00:16:57,850
first thing you'll notice is this

00:16:55,000 --> 00:17:00,310
bracket F and is fair self and so this

00:16:57,850 --> 00:17:02,650
crucially means that this tree cannot be

00:17:00,310 --> 00:17:04,209
compatible with virtual dispatch is not

00:17:02,650 --> 00:17:05,949
what we call object safe that came to

00:17:04,209 --> 00:17:07,570
turn into it straight objects now

00:17:05,949 --> 00:17:08,720
doesn't matter so much about the details

00:17:07,570 --> 00:17:10,159
of why

00:17:08,720 --> 00:17:12,049
but it suffice to say that you can't

00:17:10,159 --> 00:17:14,150
erase the type you can't have virtual

00:17:12,049 --> 00:17:16,370
dispatch you can only kind of have one

00:17:14,150 --> 00:17:17,750
at a time and I'm gonna give you an

00:17:16,370 --> 00:17:19,730
example of why that's actually a problem

00:17:17,750 --> 00:17:21,500
so let's say you're just writing a

00:17:19,730 --> 00:17:23,240
function which is gonna take a key it's

00:17:21,500 --> 00:17:25,610
gonna have some sort of cache to

00:17:23,240 --> 00:17:26,929
immediately immediate return values and

00:17:25,610 --> 00:17:29,360
otherwise have some sort of slow

00:17:26,929 --> 00:17:31,010
computation so we'll notice here that

00:17:29,360 --> 00:17:32,690
we'll look up my cache if it's ready to

00:17:31,010 --> 00:17:33,350
go we'll return a feature setting up

00:17:32,690 --> 00:17:34,909
this is done

00:17:33,350 --> 00:17:36,470
and then if it's not done we'll go do

00:17:34,909 --> 00:17:38,020
the actual slow computation that'll fill

00:17:36,470 --> 00:17:39,799
in the cache and all that good stuff so

00:17:38,020 --> 00:17:41,750
the first thing we'll notice is that

00:17:39,799 --> 00:17:42,919
this actually doesn't compile this is

00:17:41,750 --> 00:17:44,570
these are two branches of an if

00:17:42,919 --> 00:17:46,250
statement where rust will require that

00:17:44,570 --> 00:17:47,750
these are the exact same type and these

00:17:46,250 --> 00:17:49,370
are two different types an immediately

00:17:47,750 --> 00:17:50,630
resolved feature and then a delay

00:17:49,370 --> 00:17:52,940
feature that will take a little bit

00:17:50,630 --> 00:17:54,049
longer to actually process later on so

00:17:52,940 --> 00:17:55,370
if we try and solve this there's

00:17:54,049 --> 00:17:56,870
actually a relatively easy local

00:17:55,370 --> 00:17:58,880
solution we're gonna pack this in an

00:17:56,870 --> 00:18:00,500
either you know or we can say that the

00:17:58,880 --> 00:18:02,059
left-hand side is returning the Avery

00:18:00,500 --> 00:18:03,770
the a variant the right hand side is

00:18:02,059 --> 00:18:05,600
returning the B variant and then this

00:18:03,770 --> 00:18:07,340
just assumes that both if you have an

00:18:05,600 --> 00:18:08,539
either of a B that wants future if

00:18:07,340 --> 00:18:10,250
either in one of those as a future and

00:18:08,539 --> 00:18:12,200
then just kind of does that and this

00:18:10,250 --> 00:18:13,340
works great enough for two cases but

00:18:12,200 --> 00:18:14,929
then it starts being a problem one so

00:18:13,340 --> 00:18:17,210
you get even more cases so what if we

00:18:14,929 --> 00:18:18,620
have more conditions where if it's less

00:18:17,210 --> 00:18:20,659
than four you do one thing it's better

00:18:18,620 --> 00:18:22,460
than five do another thing and we might

00:18:20,659 --> 00:18:24,830
get this problem what happens we have 27

00:18:22,460 --> 00:18:26,419
cases a a the a little a actually not

00:18:24,830 --> 00:18:28,070
sure what the conventions are there but

00:18:26,419 --> 00:18:29,570
so it suffice it to say that this isn't

00:18:28,070 --> 00:18:31,700
going to cut it we can't have just an

00:18:29,570 --> 00:18:33,200
enum we can't statically say that this

00:18:31,700 --> 00:18:35,120
is the number of branches that we're

00:18:33,200 --> 00:18:37,700
going to be taking what we really need

00:18:35,120 --> 00:18:40,159
here is type erasure we need to return

00:18:37,700 --> 00:18:41,900
these trade objects so this box of

00:18:40,159 --> 00:18:43,880
future these creating these boxes of

00:18:41,900 --> 00:18:46,130
what's actually being returned so this

00:18:43,880 --> 00:18:47,570
is a critical feature of features and

00:18:46,130 --> 00:18:49,159
traits which is that at some point you

00:18:47,570 --> 00:18:50,570
have to be able to erase the type and

00:18:49,159 --> 00:18:52,549
you have to able to say that I don't

00:18:50,570 --> 00:18:54,200
know what where this feature came from

00:18:52,549 --> 00:18:56,720
but it's still a feature you can still

00:18:54,200 --> 00:18:59,179
use it as a future so having this

00:18:56,720 --> 00:19:01,190
ability for for for virtual dispatch

00:18:59,179 --> 00:19:02,630
ends up being a crucial feature that

00:19:01,190 --> 00:19:04,940
we're going to need out of the futures

00:19:02,630 --> 00:19:06,380
trade so we come back here to our

00:19:04,940 --> 00:19:07,909
definition and we'll take a look at this

00:19:06,380 --> 00:19:09,470
bracket elfin this self and we'll say

00:19:07,909 --> 00:19:11,299
all right so these are not compatible

00:19:09,470 --> 00:19:12,919
with futures these are not gonna work

00:19:11,299 --> 00:19:14,900
out I'm not gonna go in the details as

00:19:12,919 --> 00:19:16,580
to why they're so it's only talk in and

00:19:14,900 --> 00:19:18,470
of itself but this is an alternate

00:19:16,580 --> 00:19:20,990
signature which actually is object safe

00:19:18,470 --> 00:19:22,160
or we have this an mute self and this

00:19:20,990 --> 00:19:27,230
box at FN once

00:19:22,160 --> 00:19:29,060
now this is this isn't I lost over a few

00:19:27,230 --> 00:19:31,280
details here but the suffice to say that

00:19:29,060 --> 00:19:33,140
the the drawback of this approach is

00:19:31,280 --> 00:19:35,330
that this closure is allocated on the

00:19:33,140 --> 00:19:37,160
heap so this could actually be a

00:19:35,330 --> 00:19:38,930
relatively expensive operation

00:19:37,160 --> 00:19:40,820
and I want to explore that specifically

00:19:38,930 --> 00:19:45,590
and kind of why that is such an

00:19:40,820 --> 00:19:46,910
expensive operation so to explain that

00:19:45,590 --> 00:19:48,980
here I want to talk about kind of how we

00:19:46,910 --> 00:19:50,510
envision servers to be written nowadays

00:19:48,980 --> 00:19:52,220
with Tokyo and kind of with features

00:19:50,510 --> 00:19:54,110
kind of what the style for that would be

00:19:52,220 --> 00:19:55,550
and this is very heavily inspired by

00:19:54,110 --> 00:19:57,890
finagle and Scala if you're familiar

00:19:55,550 --> 00:20:00,020
with that where the fundamental idea is

00:19:57,890 --> 00:20:02,510
that your entire server is a function

00:20:00,020 --> 00:20:04,670
from a request to a future of a response

00:20:02,510 --> 00:20:05,900
which means that everything you've

00:20:04,670 --> 00:20:07,910
written in your server is entirely

00:20:05,900 --> 00:20:10,160
asynchronous it's all entirely built up

00:20:07,910 --> 00:20:11,960
in this one future and it's just all and

00:20:10,160 --> 00:20:13,460
captured in that one thing and then the

00:20:11,960 --> 00:20:14,780
the framework is what takes this and

00:20:13,460 --> 00:20:16,640
then starts processing that and dealing

00:20:14,780 --> 00:20:18,770
with decoding it and writing but not and

00:20:16,640 --> 00:20:20,930
so you might have a server which for

00:20:18,770 --> 00:20:22,340
example it receives a request load some

00:20:20,930 --> 00:20:24,410
information from a database to some

00:20:22,340 --> 00:20:26,030
remote API calls done some more database

00:20:24,410 --> 00:20:28,190
whatnot and finally renders a response

00:20:26,030 --> 00:20:29,840
and internally we can notice that these

00:20:28,190 --> 00:20:31,820
are actually all creating futures in the

00:20:29,840 --> 00:20:33,050
middle so loading some rows from a

00:20:31,820 --> 00:20:34,550
database might actually take some time

00:20:33,050 --> 00:20:35,690
doing an API call might take it might

00:20:34,550 --> 00:20:37,700
take some time and so we're gonna

00:20:35,690 --> 00:20:39,020
encapsulate all these with futures and

00:20:37,700 --> 00:20:41,750
then we're going to use those to build

00:20:39,020 --> 00:20:43,070
up a final future so if we kind of look

00:20:41,750 --> 00:20:44,270
at this a little bit graphically we have

00:20:43,070 --> 00:20:45,650
all these states that we're gonna go

00:20:44,270 --> 00:20:47,360
through the first state is we have a

00:20:45,650 --> 00:20:48,770
request and then we're waiting on a

00:20:47,360 --> 00:20:51,440
database query then we're waiting on an

00:20:48,770 --> 00:20:52,430
API query so on and so forth and what's

00:20:51,440 --> 00:20:54,560
actually happening here is we're gonna

00:20:52,430 --> 00:20:57,050
box all this up we're gonna put this all

00:20:54,560 --> 00:20:58,580
into one giant future and this is what

00:20:57,050 --> 00:21:00,140
we're going to return from our server so

00:20:58,580 --> 00:21:02,150
our server is then responsible for

00:21:00,140 --> 00:21:03,830
returning this one future with all of

00:21:02,150 --> 00:21:05,390
the Steep encapsulated internally for

00:21:03,830 --> 00:21:08,210
how you're actually processing this and

00:21:05,390 --> 00:21:09,800
so with our trait we have our scheduled

00:21:08,210 --> 00:21:11,750
function saying when this future is done

00:21:09,800 --> 00:21:13,610
I like you're gonna run this callback so

00:21:11,750 --> 00:21:14,990
to actually progress between these

00:21:13,610 --> 00:21:17,090
states we're gonna have these calls to

00:21:14,990 --> 00:21:18,770
schedule we're gonna say when this

00:21:17,090 --> 00:21:20,540
loading of the database is done I'd like

00:21:18,770 --> 00:21:22,190
you to schedule a callback which then

00:21:20,540 --> 00:21:23,450
fires off some more computations and

00:21:22,190 --> 00:21:25,550
then runs and actually goes and fetches

00:21:23,450 --> 00:21:27,380
the API queries and then when that's

00:21:25,550 --> 00:21:28,730
done I'd like you to schedule another

00:21:27,380 --> 00:21:30,980
callback to start loading some other

00:21:28,730 --> 00:21:32,690
database rows so we're on so forth and

00:21:30,980 --> 00:21:35,180
the critical thing we're noticing here

00:21:32,690 --> 00:21:35,630
is that every single state transition

00:21:35,180 --> 00:21:37,310
this

00:21:35,630 --> 00:21:38,870
future is making is actually going to

00:21:37,310 --> 00:21:40,220
call to schedule that's how we're

00:21:38,870 --> 00:21:42,560
progressing between these states we're

00:21:40,220 --> 00:21:43,910
saying that every time we make a state

00:21:42,560 --> 00:21:45,380
transition here we're scheduling a call

00:21:43,910 --> 00:21:48,260
back saying when that feature is done

00:21:45,380 --> 00:21:49,700
we'd like to now run another feature and

00:21:48,260 --> 00:21:53,540
when we start scaling this up

00:21:49,700 --> 00:21:55,220
we noticed that server the because of

00:21:53,540 --> 00:21:57,470
the server is in the server response is

00:21:55,220 --> 00:21:59,030
entirely a future that feature is tends

00:21:57,470 --> 00:22:01,010
to be composed of many other features as

00:21:59,030 --> 00:22:02,990
we just saw and then they themselves as

00:22:01,010 --> 00:22:04,370
we saw originally fetching an API

00:22:02,990 --> 00:22:05,990
request fetching something from github

00:22:04,370 --> 00:22:07,910
com that's actually gonna take a lot of

00:22:05,990 --> 00:22:09,890
TLS negotiation a lot of internals there

00:22:07,910 --> 00:22:11,870
so that entirely is made up with many

00:22:09,890 --> 00:22:14,090
many other features so we have this

00:22:11,870 --> 00:22:15,770
massive tree of futures which is goes

00:22:14,090 --> 00:22:17,540
far beyond what we actually wrote down

00:22:15,770 --> 00:22:20,270
because everything is internally made of

00:22:17,540 --> 00:22:21,950
futures and as a result over this entire

00:22:20,270 --> 00:22:23,840
request we have many many many state

00:22:21,950 --> 00:22:25,850
transitions this this this concept of

00:22:23,840 --> 00:22:27,680
state transition is almost happening

00:22:25,850 --> 00:22:29,930
every time bytes come in off the network

00:22:27,680 --> 00:22:31,940
which could be very very frequent very

00:22:29,930 --> 00:22:34,220
very rapid and the critical thing here

00:22:31,940 --> 00:22:36,350
is that if every single state transition

00:22:34,220 --> 00:22:38,690
actually allocates a callback it's

00:22:36,350 --> 00:22:40,670
incredibly expensive now for this kind

00:22:38,690 --> 00:22:42,260
of one generally only allocated five

00:22:40,670 --> 00:22:43,640
callbacks that would be fine but what we

00:22:42,260 --> 00:22:44,990
wanted to do is we want to push the

00:22:43,640 --> 00:22:47,180
boundaries of futures we want to make

00:22:44,990 --> 00:22:48,470
sure that you can use futures everywhere

00:22:47,180 --> 00:22:50,450
up and down the stack with kind of a

00:22:48,470 --> 00:22:52,340
uniform interface and that requires us

00:22:50,450 --> 00:22:54,290
to get this cost down even further and

00:22:52,340 --> 00:22:56,870
this allocation of callbacks is just not

00:22:54,290 --> 00:22:58,640
gonna cut it for us but it's not just

00:22:56,870 --> 00:23:00,470
costs it's not just runtime cost it's

00:22:58,640 --> 00:23:00,890
also the actual API cost of having a

00:23:00,470 --> 00:23:02,810
callback

00:23:00,890 --> 00:23:05,180
so we'll notice here that we have this

00:23:02,810 --> 00:23:07,190
box of FN once but we didn't say

00:23:05,180 --> 00:23:09,050
anything about thread safe to you so

00:23:07,190 --> 00:23:11,000
rust has this trait called send which

00:23:09,050 --> 00:23:12,830
says that this value can be sent across

00:23:11,000 --> 00:23:14,000
other threads it has sync saying that

00:23:12,830 --> 00:23:16,430
you can actually invoke this closure

00:23:14,000 --> 00:23:17,450
across many threads concurrently and we

00:23:16,430 --> 00:23:19,430
didn't say anything about that

00:23:17,450 --> 00:23:21,200
so this strict definition says that you

00:23:19,430 --> 00:23:23,600
can actually only run completion

00:23:21,200 --> 00:23:25,280
callbacks on the thread you initially

00:23:23,600 --> 00:23:27,170
had it on now that's not actually

00:23:25,280 --> 00:23:28,340
compatible if you have two threads

00:23:27,170 --> 00:23:30,410
computing a value and kind of want to

00:23:28,340 --> 00:23:32,090
fire one from one of the other but then

00:23:30,410 --> 00:23:33,290
the problem is that if we put in a send

00:23:32,090 --> 00:23:35,990
out here and we've required and we

00:23:33,290 --> 00:23:38,450
enabled that use case were then having

00:23:35,990 --> 00:23:40,130
we're then costing the other use case of

00:23:38,450 --> 00:23:42,680
I don't need the thread safe futures and

00:23:40,130 --> 00:23:44,690
I need the extra speed from not having

00:23:42,680 --> 00:23:45,980
this level of synchronization so the

00:23:44,690 --> 00:23:47,720
problem here is we're faced with an

00:23:45,980 --> 00:23:49,029
uncomfortable and impossible question of

00:23:47,720 --> 00:23:52,719
what do we actually do what

00:23:49,029 --> 00:23:54,609
we actually assign this callback so the

00:23:52,719 --> 00:23:56,679
drawbacks are not just that this is

00:23:54,609 --> 00:23:58,149
incredibly expensive because it ends up

00:23:56,679 --> 00:24:00,249
being very expensive the farther you

00:23:58,149 --> 00:24:02,139
push features but this thread safety

00:24:00,249 --> 00:24:03,669
aspect is really going to require some

00:24:02,139 --> 00:24:05,829
gymnastics if we're gonna try and solve

00:24:03,669 --> 00:24:07,389
it this is either going to require

00:24:05,829 --> 00:24:08,919
synchronization where it's not necessary

00:24:07,389 --> 00:24:10,929
or it's going to preclude

00:24:08,919 --> 00:24:12,729
synchronization to even exist where it

00:24:10,929 --> 00:24:15,639
actually needs it needs to be necessary

00:24:12,729 --> 00:24:18,009
and then we actually experimented with a

00:24:15,639 --> 00:24:19,509
couple of variants of thread safe and

00:24:18,009 --> 00:24:21,609
non thread safe future traits where you

00:24:19,509 --> 00:24:23,859
have kind of this parallel hierarchy but

00:24:21,609 --> 00:24:25,479
it ends up being very very difficult to

00:24:23,859 --> 00:24:27,699
use and essentially impossible to make

00:24:25,479 --> 00:24:29,709
sense of so it's suffice to say that

00:24:27,699 --> 00:24:31,989
callbacks are not going to cut it for us

00:24:29,709 --> 00:24:33,279
this ends up we've at this point we're

00:24:31,989 --> 00:24:35,199
not gonna be able to use callbacks this

00:24:33,279 --> 00:24:38,079
traditional way of blending features is

00:24:35,199 --> 00:24:39,249
not going to work so let's recap some of

00:24:38,079 --> 00:24:42,099
the constraints that we've seen so far

00:24:39,249 --> 00:24:43,599
number one we need to be a tree we have

00:24:42,099 --> 00:24:45,339
to allow these very specialized

00:24:43,599 --> 00:24:46,959
implementations we can't assume that

00:24:45,339 --> 00:24:49,179
anyone is going to be sufficient for

00:24:46,959 --> 00:24:51,099
everyone this trait itself though has to

00:24:49,179 --> 00:24:52,749
also enable virtual dispatch we can't

00:24:51,099 --> 00:24:54,429
compromise on that there might be cases

00:24:52,749 --> 00:24:55,989
where we don't know what kind of feature

00:24:54,429 --> 00:24:57,819
we're going to be returning and so we

00:24:55,989 --> 00:24:59,289
have to be able to erase that type and

00:24:57,819 --> 00:25:01,269
have some level of virtual dispatch

00:24:59,289 --> 00:25:02,739
theorem state transitions are happening

00:25:01,269 --> 00:25:04,599
all over the place

00:25:02,739 --> 00:25:05,919
we can't allocate all the time we can't

00:25:04,599 --> 00:25:07,959
make sure these are very expensive these

00:25:05,919 --> 00:25:09,969
this we need to optimize for as many

00:25:07,959 --> 00:25:12,129
state transitions to happen and have

00:25:09,969 --> 00:25:13,779
them be a very cheap operation and then

00:25:12,129 --> 00:25:15,609
finally we have to enable these thread

00:25:13,779 --> 00:25:17,109
safe cases you have to we can't force

00:25:15,609 --> 00:25:18,969
you to either be thread safe or not

00:25:17,109 --> 00:25:20,649
thread safe and everyone be in one world

00:25:18,969 --> 00:25:22,179
or the other we have this fundamental

00:25:20,649 --> 00:25:24,159
divide where there are legitimate

00:25:22,179 --> 00:25:26,109
reasons to be in one world or the other

00:25:24,159 --> 00:25:28,419
and simultaneously use those in the same

00:25:26,109 --> 00:25:31,209
application and we need one interface to

00:25:28,419 --> 00:25:33,269
kind of work across everything so to

00:25:31,209 --> 00:25:35,769
solve this I'm gonna take a bit of a

00:25:33,269 --> 00:25:37,539
larger look at what this server design

00:25:35,769 --> 00:25:39,339
is looking like so we had this diagram

00:25:37,539 --> 00:25:41,349
before of all these state transitions of

00:25:39,339 --> 00:25:42,939
our one request we have our big feature

00:25:41,349 --> 00:25:44,889
which internally is made up of little

00:25:42,939 --> 00:25:47,019
features and so let's zoom out a bit

00:25:44,889 --> 00:25:48,579
where we're not just processing this one

00:25:47,019 --> 00:25:50,829
feature what is the framework actually

00:25:48,579 --> 00:25:53,049
doing that is then getting this feature

00:25:50,829 --> 00:25:54,699
of a response and what it's doing is

00:25:53,049 --> 00:25:55,869
it's adding all of its own layers saying

00:25:54,699 --> 00:25:57,940
that at the very beginning it's

00:25:55,869 --> 00:25:59,679
literally reading bytes from a TCP

00:25:57,940 --> 00:26:02,559
socket it might be decrypting them doing

00:25:59,679 --> 00:26:04,570
TLS it could then be decoding some

00:26:02,559 --> 00:26:06,429
to be protocol one or two or whatnot and

00:26:04,570 --> 00:26:07,509
then once it finally has the result it's

00:26:06,429 --> 00:26:10,149
gonna do the opposite of all that it's

00:26:07,509 --> 00:26:11,289
gonna actually encode it in HTTP encrypt

00:26:10,149 --> 00:26:14,230
some bytes and then write it back out to

00:26:11,289 --> 00:26:17,049
the TCP socket and so all of this is

00:26:14,230 --> 00:26:19,179
kind of one connected client and it

00:26:17,049 --> 00:26:21,309
turns out this ends up being a very nice

00:26:19,179 --> 00:26:23,679
unit of isolation kind of unit of

00:26:21,309 --> 00:26:25,450
concurrency unit to talk about and so we

00:26:23,679 --> 00:26:27,999
ended up giving this a name called tasks

00:26:25,450 --> 00:26:30,580
where a task in this case is one

00:26:27,999 --> 00:26:31,929
connected TCP client and one Kani one

00:26:30,580 --> 00:26:34,179
client that kind of is a unit of

00:26:31,929 --> 00:26:36,340
concurrency that encapsulates everything

00:26:34,179 --> 00:26:38,440
that's happening here and then we can

00:26:36,340 --> 00:26:41,919
zoom out even further and show that a

00:26:38,440 --> 00:26:43,600
server is made up of many many tasks so

00:26:41,919 --> 00:26:45,369
every connected client on a server is

00:26:43,600 --> 00:26:46,779
going to be one independent task but

00:26:45,369 --> 00:26:48,669
each of these tasks are going to be

00:26:46,779 --> 00:26:50,740
independent from one another and each of

00:26:48,669 --> 00:26:52,299
these tacks of clinic have run within

00:26:50,740 --> 00:26:53,649
their own unit of concurrency but I'm

00:26:52,299 --> 00:26:55,809
kind of interoperate with everyone else

00:26:53,649 --> 00:26:58,240
but kind of a boundary for channels of

00:26:55,809 --> 00:27:00,700
communication for futures being spawned

00:26:58,240 --> 00:27:02,559
it's kind of no one task has futures

00:27:00,700 --> 00:27:04,869
that necessarily related to other tasks

00:27:02,559 --> 00:27:06,190
and this is kind of just a canonical

00:27:04,869 --> 00:27:08,230
architecture that we've seen in many

00:27:06,190 --> 00:27:10,629
asynchronous servers and so if we took a

00:27:08,230 --> 00:27:13,720
look at this we can actually do is try

00:27:10,629 --> 00:27:15,129
and kind of model a set of futures in

00:27:13,720 --> 00:27:18,159
that kind of a runtime system around

00:27:15,129 --> 00:27:21,129
this so specifically we have the a task

00:27:18,159 --> 00:27:22,990
is composed of many many features which

00:27:21,129 --> 00:27:24,999
are they themselves composed of many

00:27:22,990 --> 00:27:27,100
many other features internally but

00:27:24,999 --> 00:27:28,809
everything about those features they

00:27:27,100 --> 00:27:30,820
have no need to cross this task they're

00:27:28,809 --> 00:27:33,549
typically always balanced as one client

00:27:30,820 --> 00:27:35,440
as one TCP socket so every single one of

00:27:33,549 --> 00:27:37,720
these features can be concrete Lee named

00:27:35,440 --> 00:27:40,419
or connected to this one task for its

00:27:37,720 --> 00:27:42,249
entire lifetime now while that task is

00:27:40,419 --> 00:27:43,840
alive it might have many features which

00:27:42,249 --> 00:27:45,159
are active so sometimes it's waiting on

00:27:43,840 --> 00:27:47,110
the database sometimes it's waiting on

00:27:45,159 --> 00:27:49,240
the API requests but all those features

00:27:47,110 --> 00:27:52,119
end up being connected to the same task

00:27:49,240 --> 00:27:53,769
and this task as a kind of very nice

00:27:52,119 --> 00:27:55,590
unit of concurrency and ends up being

00:27:53,769 --> 00:27:57,519
very similar to a green threaded system

00:27:55,590 --> 00:27:59,529
especially if you combine this with

00:27:57,519 --> 00:28:01,509
async and await you'll notice that you

00:27:59,529 --> 00:28:03,129
actually have very synchronous looking

00:28:01,509 --> 00:28:04,929
code and then you end up Scott's calling

00:28:03,129 --> 00:28:06,249
spawn to spawn new tasks and it actually

00:28:04,929 --> 00:28:07,869
looks very similar to like green

00:28:06,249 --> 00:28:09,399
fighting like system but it kind of has

00:28:07,869 --> 00:28:12,190
all the extra power that you get with

00:28:09,399 --> 00:28:15,760
features and with the ability to operate

00:28:12,190 --> 00:28:18,520
in in in a synchronous fashion

00:28:15,760 --> 00:28:20,110
so given all that the constant this kind

00:28:18,520 --> 00:28:21,610
of we might have this idea of tasks in

00:28:20,110 --> 00:28:23,380
here we have this kind of concrete idea

00:28:21,610 --> 00:28:24,580
of tasks following features around and

00:28:23,380 --> 00:28:27,310
features they're always following a task

00:28:24,580 --> 00:28:28,510
let's try and redefine in our treat so

00:28:27,310 --> 00:28:30,220
right now we still only have a tree we

00:28:28,510 --> 00:28:31,990
ever type item and the next thing we can

00:28:30,220 --> 00:28:34,270
think of is so earlier we were saying

00:28:31,990 --> 00:28:36,220
when are you done please do this when

00:28:34,270 --> 00:28:37,570
this is done and now we can say well

00:28:36,220 --> 00:28:39,430
let's look they are we there yet

00:28:37,570 --> 00:28:41,650
approach will say are you done yet and

00:28:39,430 --> 00:28:42,760
then are if you are you're gonna give me

00:28:41,650 --> 00:28:44,830
a value and if you're not you're not

00:28:42,760 --> 00:28:46,810
gonna give me value so this is kind of

00:28:44,830 --> 00:28:48,370
the next road that we ended up going

00:28:46,810 --> 00:28:50,170
down it's trying to actually implement

00:28:48,370 --> 00:28:51,310
features and we say all right well so

00:28:50,170 --> 00:28:53,140
this is still a trait so we're gonna

00:28:51,310 --> 00:28:54,190
solve that problem of trait and like

00:28:53,140 --> 00:28:56,320
having a treat and having the most

00:28:54,190 --> 00:28:58,600
specialized implementation and the good

00:28:56,320 --> 00:29:00,460
thing is that this signature is object

00:28:58,600 --> 00:29:02,200
safe and this this signature

00:29:00,460 --> 00:29:03,520
automatically does allow for actual

00:29:02,200 --> 00:29:05,800
dispatch and I'm working on the details

00:29:03,520 --> 00:29:07,540
as to why but it suffice to say that no

00:29:05,800 --> 00:29:09,460
generics here know about all yourself

00:29:07,540 --> 00:29:12,160
it's just it will be compatible with

00:29:09,460 --> 00:29:14,650
trade objects and type erasure and so

00:29:12,160 --> 00:29:16,390
what we're gonna say here is that you're

00:29:14,650 --> 00:29:18,550
gonna ask a future periodically are you

00:29:16,390 --> 00:29:19,990
ready yet it's gonna return none saying

00:29:18,550 --> 00:29:21,610
nope I'm not ready yet you're gonna have

00:29:19,990 --> 00:29:23,560
to come back at a later time or it'll

00:29:21,610 --> 00:29:25,990
return some so yep I'm done here's the

00:29:23,560 --> 00:29:28,090
value and then the only problem here is

00:29:25,990 --> 00:29:30,340
saying well okay if you're not ready at

00:29:28,090 --> 00:29:31,900
how do I actually come back to this and

00:29:30,340 --> 00:29:33,460
you'll notice this is very similar to

00:29:31,900 --> 00:29:34,900
the asynchronous i/o we saw at the very

00:29:33,460 --> 00:29:36,670
beginning of what the kernel is doing

00:29:34,900 --> 00:29:38,290
where you will try and read some bytes

00:29:36,670 --> 00:29:39,970
on the kernel immediately says nope I'm

00:29:38,290 --> 00:29:41,740
not done and then you have to figure out

00:29:39,970 --> 00:29:44,590
when to come back and try and read those

00:29:41,740 --> 00:29:47,800
bytes again and so we've seen earlier

00:29:44,590 --> 00:29:50,230
that futures are owned by one task so

00:29:47,800 --> 00:29:52,030
the entire lifetime of a future is going

00:29:50,230 --> 00:29:54,250
to be owned by a particular task and it

00:29:52,030 --> 00:29:56,890
knows what to notify them and so the

00:29:54,250 --> 00:29:58,630
task is the one that has to come back

00:29:56,890 --> 00:30:01,540
and actually know to pull this feature

00:29:58,630 --> 00:30:03,700
so when we see none what we need to do

00:30:01,540 --> 00:30:05,860
is make sure that the task is notified

00:30:03,700 --> 00:30:07,720
to come repol this feature and look at

00:30:05,860 --> 00:30:09,310
the future again and concretely that

00:30:07,720 --> 00:30:11,470
means that there's an implicit protocol

00:30:09,310 --> 00:30:12,010
happening here saying that if you see

00:30:11,470 --> 00:30:14,620
none

00:30:12,010 --> 00:30:17,290
then implicitly and automatically your

00:30:14,620 --> 00:30:18,820
ambient task is scheduled to receive a

00:30:17,290 --> 00:30:20,610
notification that you were then ready

00:30:18,820 --> 00:30:22,750
and able to make more forward progress

00:30:20,610 --> 00:30:24,190
so it's kind of a lot of work so I want

00:30:22,750 --> 00:30:25,690
to kind of dive into a bit of a detail

00:30:24,190 --> 00:30:28,000
let's kind of implement a simple

00:30:25,690 --> 00:30:29,320
time-out this is just a a feature that

00:30:28,000 --> 00:30:31,149
will resolve

00:30:29,320 --> 00:30:33,820
at some point in the future or at some

00:30:31,149 --> 00:30:35,380
point later in time and so the first

00:30:33,820 --> 00:30:36,970
thing will fill out some struck fields

00:30:35,380 --> 00:30:39,039
we have our moments which we're actually

00:30:36,970 --> 00:30:42,130
going to fire at so this is just kind of

00:30:39,039 --> 00:30:43,960
when our future will become resolved and

00:30:42,130 --> 00:30:45,669
then we have some auxilary library data

00:30:43,960 --> 00:30:47,470
structures so we have a timer here which

00:30:45,669 --> 00:30:49,450
has this one function which allows us to

00:30:47,470 --> 00:30:49,960
run a closure at some particular point

00:30:49,450 --> 00:30:52,389
in time

00:30:49,960 --> 00:30:53,830
now the DMM tation details are not too

00:30:52,389 --> 00:30:56,679
too important this is mostly just how

00:30:53,830 --> 00:30:57,940
we're going to implement our future so

00:30:56,679 --> 00:31:00,130
we'll start off by saying it will

00:30:57,940 --> 00:31:01,389
feature for timeout our associative type

00:31:00,130 --> 00:31:02,590
is this going to be a unit because we're

00:31:01,389 --> 00:31:03,759
not actually gonna have any values here

00:31:02,590 --> 00:31:05,559
when the futures done it's going to say

00:31:03,759 --> 00:31:07,600
I'm done that's pretty much it and then

00:31:05,559 --> 00:31:08,679
we have our poll function so the first

00:31:07,600 --> 00:31:10,509
thing we're gonna do our and our poll

00:31:08,679 --> 00:31:12,519
function to say all right well if the

00:31:10,509 --> 00:31:14,409
timeout has elapsed then we are done we

00:31:12,519 --> 00:31:16,330
are can now return sum we can never turn

00:31:14,409 --> 00:31:17,740
this back out because the time has

00:31:16,330 --> 00:31:19,269
passed for this actual future to be

00:31:17,740 --> 00:31:21,490
resolved you have correctly pulled me at

00:31:19,269 --> 00:31:23,889
the right time but the more interesting

00:31:21,490 --> 00:31:25,360
part is in this none case and the real

00:31:23,889 --> 00:31:27,190
thing to note here is these calls to

00:31:25,360 --> 00:31:29,500
task current and it's calls to task

00:31:27,190 --> 00:31:31,600
notify so what's happening here is the

00:31:29,500 --> 00:31:34,210
when we're not ready we're gonna return

00:31:31,600 --> 00:31:36,190
none and our implicit protocol means

00:31:34,210 --> 00:31:37,990
that we need to notify our task when we

00:31:36,190 --> 00:31:39,669
otherwise would be done so the

00:31:37,990 --> 00:31:41,559
definition for when this future is going

00:31:39,669 --> 00:31:44,169
to be ready is at this point in time

00:31:41,559 --> 00:31:46,299
we're now ready and so we're using this

00:31:44,169 --> 00:31:48,309
auxilary function on our timer kind of

00:31:46,299 --> 00:31:50,440
inside of our struct to schedule a

00:31:48,309 --> 00:31:51,669
callback to be invoked at some point or

00:31:50,440 --> 00:31:53,919
this callback is going to actually just

00:31:51,669 --> 00:31:56,169
notify the task so here this task

00:31:53,919 --> 00:31:59,110
current is built into the futures crate

00:31:56,169 --> 00:32:00,490
this is kind of a paradigm brought forth

00:31:59,110 --> 00:32:02,529
in features how you actually build

00:32:00,490 --> 00:32:04,299
features you'll pull that out and then

00:32:02,529 --> 00:32:06,610
when you're ready go call dot notify and

00:32:04,299 --> 00:32:07,960
then I'll then queue up that task to

00:32:06,610 --> 00:32:09,309
come around and pull this feature again

00:32:07,960 --> 00:32:11,080
and realize it actually has been

00:32:09,309 --> 00:32:15,100
resolved and it's able to make for and

00:32:11,080 --> 00:32:17,289
it's able to make further progress all

00:32:15,100 --> 00:32:18,909
right let's take a look at this design

00:32:17,289 --> 00:32:21,100
and kind of how it matches up with the

00:32:18,909 --> 00:32:23,019
constraints that we've had so far so

00:32:21,100 --> 00:32:25,539
first up we have our constraints of a

00:32:23,019 --> 00:32:27,419
trait and virtual dispatch and as I was

00:32:25,539 --> 00:32:30,100
saying this pull based solution it does

00:32:27,419 --> 00:32:31,990
obviously is a tree and then it suffice

00:32:30,100 --> 00:32:33,580
to say that it does work with virtual

00:32:31,990 --> 00:32:36,129
dispatch and we argue normal outright

00:32:33,580 --> 00:32:37,389
objects from this so the next aspect is

00:32:36,129 --> 00:32:39,610
we wanted to make sure that these state

00:32:37,389 --> 00:32:41,379
transitions were cheap these all these

00:32:39,610 --> 00:32:43,000
state transitions were no no allocations

00:32:41,379 --> 00:32:45,160
internally it's all just happening

00:32:43,000 --> 00:32:46,750
very lightweight manner and so if we

00:32:45,160 --> 00:32:48,610
take a look at how the tasks are

00:32:46,750 --> 00:32:50,590
actually implemented then it turns out

00:32:48,610 --> 00:32:52,210
that when you spawn a future when you

00:32:50,590 --> 00:32:54,280
create a task when you can create this

00:32:52,210 --> 00:32:55,480
giant tree that's one allocation you're

00:32:54,280 --> 00:32:57,280
probably gonna have to have some sort of

00:32:55,480 --> 00:32:58,390
arc some sort of piece of chunk of

00:32:57,280 --> 00:33:00,820
memory to allocate for that one

00:32:58,390 --> 00:33:02,740
particular task but then acquiring a

00:33:00,820 --> 00:33:03,970
reference to the current task you don't

00:33:02,740 --> 00:33:05,770
have to create a new one you're just

00:33:03,970 --> 00:33:08,260
referencing the ambient tasks that

00:33:05,770 --> 00:33:10,240
you're always part of and so acquiring

00:33:08,260 --> 00:33:11,740
the current task tends to just be in a

00:33:10,240 --> 00:33:12,610
breakfast counts got a bump a reference

00:33:11,740 --> 00:33:14,200
count Tamaki

00:33:12,610 --> 00:33:17,260
I tell my increment all that good stuff

00:33:14,200 --> 00:33:18,820
and the notification as well there's no

00:33:17,260 --> 00:33:20,230
extra allocations than needed there all

00:33:18,820 --> 00:33:22,420
we're gonna do is put ourselves into

00:33:20,230 --> 00:33:24,040
some form of a readiness cue so our

00:33:22,420 --> 00:33:25,450
tasks is this going to be put back into

00:33:24,040 --> 00:33:27,220
some queue that already has a note

00:33:25,450 --> 00:33:28,510
allocated for it and we can say this is

00:33:27,220 --> 00:33:30,400
ready to go so eventually it'll get

00:33:28,510 --> 00:33:33,310
processed and and kumkum come back to

00:33:30,400 --> 00:33:34,480
that so this straight about cheap we can

00:33:33,310 --> 00:33:36,550
say we've solved that as well

00:33:34,480 --> 00:33:39,100
this aspect of tasks I can dive more

00:33:36,550 --> 00:33:41,230
into the into the details later today

00:33:39,100 --> 00:33:42,970
but it suffice to say that there are no

00:33:41,230 --> 00:33:44,380
allocations here while these features

00:33:42,970 --> 00:33:46,270
are executing these two fundamental

00:33:44,380 --> 00:33:47,770
functions current and notify are

00:33:46,270 --> 00:33:50,560
basically this reference counts and

00:33:47,770 --> 00:33:51,670
queuing operations now the final thing

00:33:50,560 --> 00:33:53,020
that we needed was we wanted to make

00:33:51,670 --> 00:33:54,820
sure that these futures were thread safe

00:33:53,020 --> 00:33:56,680
we're kind of not necessarily thread

00:33:54,820 --> 00:33:59,260
safe but compatible with different modes

00:33:56,680 --> 00:34:00,670
of working with threads and so it turns

00:33:59,260 --> 00:34:03,040
out that this fundamental primitive this

00:34:00,670 --> 00:34:04,840
task is indeed send able you can send

00:34:03,040 --> 00:34:06,940
this across threads you can use this

00:34:04,840 --> 00:34:08,560
across many threads concurrently and

00:34:06,940 --> 00:34:11,230
this ends up being a critical feature

00:34:08,560 --> 00:34:13,240
saying that this tasks not the feature

00:34:11,230 --> 00:34:15,250
itself as it's disconnected from the

00:34:13,240 --> 00:34:17,440
future is able to be sent across many

00:34:15,250 --> 00:34:19,360
threads and this means that the future

00:34:17,440 --> 00:34:20,770
trait which didn't mention callbacks

00:34:19,360 --> 00:34:23,230
didn't mention closures didn't mention

00:34:20,770 --> 00:34:25,510
send or sync allows you to either write

00:34:23,230 --> 00:34:26,889
a thread safe feature or a non thread

00:34:25,510 --> 00:34:29,169
safe future in kind of whatever way you

00:34:26,889 --> 00:34:30,460
see fit so it ends up a lie it allows

00:34:29,169 --> 00:34:32,379
you to kind of bring on the cost

00:34:30,460 --> 00:34:34,330
synchronization if you need it or shed

00:34:32,379 --> 00:34:36,100
them if you don't need it so it ends up

00:34:34,330 --> 00:34:37,450
we do end up solving this thread safe

00:34:36,100 --> 00:34:38,770
constraint where we end up having this

00:34:37,450 --> 00:34:40,720
seamless interoperation

00:34:38,770 --> 00:34:42,790
like in normal rust between thread safe

00:34:40,720 --> 00:34:44,830
code and non threat safe code where if

00:34:42,790 --> 00:34:46,300
you use a non thread safe feature across

00:34:44,830 --> 00:34:47,350
threads then the compiler will give you

00:34:46,300 --> 00:34:49,740
an error saying you can't do that

00:34:47,350 --> 00:34:51,610
whereas otherwise you can end up using

00:34:49,740 --> 00:34:54,610
channels like you do today and well

00:34:51,610 --> 00:34:56,020
it'll all just nice in the file but all

00:34:54,610 --> 00:34:56,589
right so that's a little bit about the

00:34:56,020 --> 00:34:58,450
task

00:34:56,589 --> 00:35:00,309
of futures and kind of how we end up

00:34:58,450 --> 00:35:02,440
empowering these very very cheap state

00:35:00,309 --> 00:35:03,700
transitions and end up actually solving

00:35:02,440 --> 00:35:04,900
the constraints of working in many

00:35:03,700 --> 00:35:06,670
different environments especially

00:35:04,900 --> 00:35:09,009
related to threads I want to talk now

00:35:06,670 --> 00:35:10,180
about Tokyo and its relation to tasks

00:35:09,009 --> 00:35:13,509
and how we actually work with the

00:35:10,180 --> 00:35:15,489
futures there and so in Tokyo it is

00:35:13,509 --> 00:35:18,249
critical to understand that literally

00:35:15,489 --> 00:35:20,019
everything is a future the entire way up

00:35:18,249 --> 00:35:21,849
and down that stack I was showing you

00:35:20,019 --> 00:35:23,920
this diagram of a task where every

00:35:21,849 --> 00:35:26,259
single unit like even decrypting SSL

00:35:23,920 --> 00:35:28,059
reading bytes writing bytes all of that

00:35:26,259 --> 00:35:30,489
was built around this task model and all

00:35:28,059 --> 00:35:32,499
this futures model so you're seeing a

00:35:30,489 --> 00:35:34,930
uniform model of futures all the way up

00:35:32,499 --> 00:35:36,910
and down for these entire IO stacks for

00:35:34,930 --> 00:35:38,440
from from the top to the bottom but it

00:35:36,910 --> 00:35:39,999
means that every single along the way

00:35:38,440 --> 00:35:41,710
all of these constructed features

00:35:39,999 --> 00:35:43,239
internally will eventually wait for some

00:35:41,710 --> 00:35:45,099
IO them ie to wait for some bytes to

00:35:43,239 --> 00:35:48,069
become readable wait for some bytes to

00:35:45,099 --> 00:35:49,569
become writable and so Tokyo's job is to

00:35:48,069 --> 00:35:52,059
take these events that were receiving

00:35:49,569 --> 00:35:53,769
from the kernel and then route them to

00:35:52,059 --> 00:35:55,809
the actual tasks they're waiting on them

00:35:53,769 --> 00:35:57,940
so have a task that is gonna be waiting

00:35:55,809 --> 00:35:59,469
to read some bytes and we need to know

00:35:57,940 --> 00:36:02,680
when to actually wake up and notify that

00:35:59,469 --> 00:36:05,979
task to move forward so before this was

00:36:02,680 --> 00:36:07,059
the a service IO interface we got we

00:36:05,979 --> 00:36:09,069
were trying to read some bytes and we're

00:36:07,059 --> 00:36:10,630
gonna immediately see that here's some

00:36:09,069 --> 00:36:12,880
bytes ready to go or this is gonna be

00:36:10,630 --> 00:36:14,229
woodblock well what we're gonna do here

00:36:12,880 --> 00:36:16,779
is we're gonna kind of likely do the

00:36:14,229 --> 00:36:18,940
futures layer on an implicit protocol

00:36:16,779 --> 00:36:21,789
here where what's happening is that all

00:36:18,940 --> 00:36:23,309
i/o in Tokyo like I sync I will return

00:36:21,789 --> 00:36:25,960
immediately none of it will ever block

00:36:23,309 --> 00:36:28,420
but this written this notification of

00:36:25,960 --> 00:36:30,759
woodblock is an implicitly saying that

00:36:28,420 --> 00:36:33,430
your task is now ready to receive a

00:36:30,759 --> 00:36:34,989
notification when you are readable so

00:36:33,430 --> 00:36:36,609
like why the future if you're not ready

00:36:34,989 --> 00:36:37,809
yet you will you will not have the value

00:36:36,609 --> 00:36:40,450
and you're scheduled to receive a

00:36:37,809 --> 00:36:41,859
notification with i/o if it's not ready

00:36:40,450 --> 00:36:43,569
yet you know you're going to receive a

00:36:41,859 --> 00:36:45,309
notification when you do become readable

00:36:43,569 --> 00:36:46,869
when you do become writable or you're

00:36:45,309 --> 00:36:48,069
gonna finish immediately and it's going

00:36:46,869 --> 00:36:51,160
to actually be submitted to the kernel

00:36:48,069 --> 00:36:53,140
so this allows us to build up these two

00:36:51,160 --> 00:36:55,089
extension traits called async read and

00:36:53,140 --> 00:36:57,099
async right and you'll notice that these

00:36:55,089 --> 00:36:58,869
inherit from the standard read and write

00:36:57,099 --> 00:37:00,579
traits but what they're doing is they're

00:36:58,869 --> 00:37:02,170
layering on these contracts so anything

00:37:00,579 --> 00:37:04,809
that implements the async read trade is

00:37:02,170 --> 00:37:05,920
not walking so it will never block the

00:37:04,809 --> 00:37:07,719
current thread will always return

00:37:05,920 --> 00:37:09,760
immediately and it also has this

00:37:07,719 --> 00:37:11,770
implicit contract saying that

00:37:09,760 --> 00:37:13,600
never return woodblock I'm going to

00:37:11,770 --> 00:37:15,520
schedule the current future to receive a

00:37:13,600 --> 00:37:17,020
notification and then write is very

00:37:15,520 --> 00:37:18,610
similar we're right it will receive a

00:37:17,020 --> 00:37:20,830
notification to it returns woodblock and

00:37:18,610 --> 00:37:22,300
then we also add this shutdown function

00:37:20,830 --> 00:37:24,400
for graceful shutdowns where typically

00:37:22,300 --> 00:37:25,690
this is handled we had drop but in this

00:37:24,400 --> 00:37:26,800
case we might need to block for some

00:37:25,690 --> 00:37:29,440
period of time so this is kind of

00:37:26,800 --> 00:37:31,240
necessary for that end of things and so

00:37:29,440 --> 00:37:33,340
these are mostly just marker traits

00:37:31,240 --> 00:37:35,230
saying that this is an actual compatible

00:37:33,340 --> 00:37:36,430
IO object but I'm going to show you how

00:37:35,230 --> 00:37:38,890
one of these might actually be

00:37:36,430 --> 00:37:41,260
implemented so you'll find this in the

00:37:38,890 --> 00:37:43,290
Tokyo library of this Pola vented type

00:37:41,260 --> 00:37:45,670
for this is transforming any

00:37:43,290 --> 00:37:48,100
asynchronous i/o object into a Tokyo

00:37:45,670 --> 00:37:49,330
asynchronous i/o object and the first

00:37:48,100 --> 00:37:51,910
thing we'll notice here is this pole

00:37:49,330 --> 00:37:54,250
read and so this is kind of a convention

00:37:51,910 --> 00:37:56,230
in Tokyo where any function prefixed by

00:37:54,250 --> 00:37:58,720
pole is interacting with the task system

00:37:56,230 --> 00:38:00,910
so if this object we know for a fact

00:37:58,720 --> 00:38:02,260
it's not readable we're a media League

00:38:00,910 --> 00:38:04,720
owing to return woodblock without doing

00:38:02,260 --> 00:38:06,880
any i/o and we're gonna this implicitly

00:38:04,720 --> 00:38:09,400
internally will schedule our tasks

00:38:06,880 --> 00:38:11,410
notified so we know that because we are

00:38:09,400 --> 00:38:13,120
returning woodblock we know that our

00:38:11,410 --> 00:38:14,620
task is already scheduled to be notified

00:38:13,120 --> 00:38:15,970
so we don't actually need to do anything

00:38:14,620 --> 00:38:17,380
else we can this kind of continue to

00:38:15,970 --> 00:38:20,650
return woodblock and move out from there

00:38:17,380 --> 00:38:22,360
but if our object actually says that it

00:38:20,650 --> 00:38:23,650
is ready we're going to perform the read

00:38:22,360 --> 00:38:25,960
operation and then take a look at the

00:38:23,650 --> 00:38:28,300
result that happens afterwards so if the

00:38:25,960 --> 00:38:29,920
result from the actual eye operation

00:38:28,300 --> 00:38:32,170
that we submitted to the colonel says

00:38:29,920 --> 00:38:33,670
woodblock then now it's our

00:38:32,170 --> 00:38:35,170
responsibility we have done no

00:38:33,670 --> 00:38:36,730
interaction with the task system yet so

00:38:35,170 --> 00:38:39,130
we have to make sure we block our task

00:38:36,730 --> 00:38:40,540
and so this function called need read is

00:38:39,130 --> 00:38:43,210
a function on the pole event to type

00:38:40,540 --> 00:38:45,400
itself and it's going to say schedule

00:38:43,210 --> 00:38:48,400
and notification when this object is

00:38:45,400 --> 00:38:49,720
readable for the current task and so you

00:38:48,400 --> 00:38:52,690
might be able to start seeing this where

00:38:49,720 --> 00:38:54,880
this pole evented object knows the TCP

00:38:52,690 --> 00:38:56,440
socket that has internally and then so

00:38:54,880 --> 00:38:58,210
we now we know the task that we're

00:38:56,440 --> 00:39:00,190
connecting with and we know we need it

00:38:58,210 --> 00:39:01,810
to be readable so you can kind of see

00:39:00,190 --> 00:39:03,010
now how when the colonel says that

00:39:01,810 --> 00:39:05,320
follows four four five is ready for

00:39:03,010 --> 00:39:06,700
reading tokyo has all everything it

00:39:05,320 --> 00:39:09,790
needs to connect that up and say well

00:39:06,700 --> 00:39:11,620
now that test means to go wake up so

00:39:09,790 --> 00:39:13,540
we're actually translating these is kind

00:39:11,620 --> 00:39:16,210
of very obscure events coming from the

00:39:13,540 --> 00:39:18,220
kernel to precisely this future that

00:39:16,210 --> 00:39:19,750
task they can now explicitly make

00:39:18,220 --> 00:39:22,630
progress and start and start working on

00:39:19,750 --> 00:39:24,759
this object so the event loop

00:39:22,630 --> 00:39:26,859
is the one that's actually responsible

00:39:24,759 --> 00:39:28,299
for blocking the current thread it's the

00:39:26,859 --> 00:39:29,950
one that's dispatching all these events

00:39:28,299 --> 00:39:31,539
that we received from the kernel it's

00:39:29,950 --> 00:39:33,700
kind of one sitting there and looping

00:39:31,539 --> 00:39:35,109
and you can kind of see how with all

00:39:33,700 --> 00:39:36,609
this information we now know precisely

00:39:35,109 --> 00:39:38,019
were to actually dispatch these events

00:39:36,609 --> 00:39:39,490
we know precisely what features to wake

00:39:38,019 --> 00:39:40,960
up and you no longer have to worry about

00:39:39,490 --> 00:39:42,190
correctly routing notifications

00:39:40,960 --> 00:39:44,019
correctly making sure the system is

00:39:42,190 --> 00:39:46,420
actually making progress and so

00:39:44,019 --> 00:39:48,400
effectively Tokyo is now translating

00:39:46,420 --> 00:39:52,000
these i/o notifications into actually

00:39:48,400 --> 00:39:55,210
task notifications and mning features to

00:39:52,000 --> 00:39:57,369
progress forward and so alright that was

00:39:55,210 --> 00:39:59,049
a bit of a whirlwind tour of features

00:39:57,369 --> 00:40:01,210
themselves Toki with the lower layers

00:39:59,049 --> 00:40:03,640
and kind of a bit of an idea of how

00:40:01,210 --> 00:40:05,380
Tokyo is ends up being so fast by having

00:40:03,640 --> 00:40:07,690
reducing these costs from these

00:40:05,380 --> 00:40:09,490
classical callback based systems so I

00:40:07,690 --> 00:40:11,140
think I have a couple minutes for

00:40:09,490 --> 00:40:13,480
questions and so this these are the

00:40:11,140 --> 00:40:14,859
links for Tokyo itself the project on

00:40:13,480 --> 00:40:16,630
github and the features create itself

00:40:14,859 --> 00:40:18,609
and you can also also go those and I

00:40:16,630 --> 00:40:20,589
think I'll be in the the networking room

00:40:18,609 --> 00:40:23,559
today if you have any toady took your

00:40:20,589 --> 00:40:25,059
questions with Andrew back there so feel

00:40:23,559 --> 00:40:27,030
free to drop by and otherwise thank you

00:40:25,059 --> 00:40:30,479
thank you here

00:40:27,030 --> 00:40:30,479
[Applause]

00:40:38,260 --> 00:40:56,810
thank you Alex I saw a hand go up over

00:40:42,080 --> 00:40:59,540
there so with a sink read and a sink

00:40:56,810 --> 00:41:03,440
right specifically those inherit from

00:40:59,540 --> 00:41:05,300
the standard read and write trades if

00:41:03,440 --> 00:41:07,520
you have a case where you have a read

00:41:05,300 --> 00:41:09,710
implementation that assumes that you're

00:41:07,520 --> 00:41:11,540
in the context of an executing task so

00:41:09,710 --> 00:41:14,300
if you actually call read on that

00:41:11,540 --> 00:41:16,990
outside of a task you're going to panic

00:41:14,300 --> 00:41:21,800
how do you how do you deal with that

00:41:16,990 --> 00:41:23,570
right so this is where it is the having

00:41:21,800 --> 00:41:24,860
a current task is something that is

00:41:23,570 --> 00:41:26,630
currently thread-local in the futures

00:41:24,860 --> 00:41:28,400
crate and if you do not have a current

00:41:26,630 --> 00:41:30,830
task and you otherwise try to try to

00:41:28,400 --> 00:41:32,300
acquire it so if we just if I can go

00:41:30,830 --> 00:41:34,670
back and find that yes so if you call

00:41:32,300 --> 00:41:36,500
task current and you're not actually

00:41:34,670 --> 00:41:38,240
inside of the context of a test and that

00:41:36,500 --> 00:41:39,860
will panic and so that means that these

00:41:38,240 --> 00:41:41,390
are these operations like this this bear

00:41:39,860 --> 00:41:43,670
read tree this bear imitation will

00:41:41,390 --> 00:41:45,290
indeed panic and so currently it's

00:41:43,670 --> 00:41:47,150
mostly set up where that ends up

00:41:45,290 --> 00:41:49,580
happening very rarely most of the time

00:41:47,150 --> 00:41:51,740
these are very especially IO is embedded

00:41:49,580 --> 00:41:53,810
very very deep inside of futures but

00:41:51,740 --> 00:41:55,280
otherwise a panic is it runs like an

00:41:53,810 --> 00:41:56,540
actual programmer error it ends up

00:41:55,280 --> 00:41:57,830
showing up very very quickly

00:41:56,540 --> 00:41:59,150
so this is something that we've kind of

00:41:57,830 --> 00:42:00,950
struggled with in the past to make sure

00:41:59,150 --> 00:42:03,950
to kind of make sure that there is a

00:42:00,950 --> 00:42:05,690
very clear demarcation but the benefit

00:42:03,950 --> 00:42:07,400
of reusing the standard read and write

00:42:05,690 --> 00:42:09,710
traits kind of reusing everything that

00:42:07,400 --> 00:42:11,150
currently exists it ends up being much

00:42:09,710 --> 00:42:12,650
greater than kind of what we would have

00:42:11,150 --> 00:42:14,600
getting well what we would otherwise get

00:42:12,650 --> 00:42:17,150
from a static distinction of this is a

00:42:14,600 --> 00:42:19,100
only Tokio readable trait and this is

00:42:17,150 --> 00:42:20,750
the standard readable trade an example

00:42:19,100 --> 00:42:23,390
there's a lot of the compression crates

00:42:20,750 --> 00:42:24,470
so like the fleet gzip compression doing

00:42:23,390 --> 00:42:26,030
that in a certain fashion there was

00:42:24,470 --> 00:42:28,010
already a crate for that it already

00:42:26,030 --> 00:42:29,960
worked with standard i/o or standard

00:42:28,010 --> 00:42:32,030
reading standard right and also already

00:42:29,960 --> 00:42:33,920
worked with non-blocking objects so

00:42:32,030 --> 00:42:35,750
plugging in Tokyo was and it was just

00:42:33,920 --> 00:42:37,070
actually just adding the marker trade

00:42:35,750 --> 00:42:41,440
async read then it was basically done

00:42:37,070 --> 00:42:41,440
from there does that make sense yeah

00:42:49,300 --> 00:42:55,250
hi I wanted to ask what's the roadmap

00:42:52,099 --> 00:42:57,589
for async IO with file systems rather

00:42:55,250 --> 00:42:58,790
than network sockets it's an excellent

00:42:57,589 --> 00:43:01,849
question and the answer is there's no

00:42:58,790 --> 00:43:03,079
roadmap the dealing with asynchronous

00:43:01,849 --> 00:43:04,730
file systems ends up being very

00:43:03,079 --> 00:43:06,260
difficult where it's like kind of a

00:43:04,730 --> 00:43:08,180
sinker to some Windows but apparently

00:43:06,260 --> 00:43:09,680
not really I don't know a lot about the

00:43:08,180 --> 00:43:12,470
details there but I think that's

00:43:09,680 --> 00:43:14,660
definitely on UNIX there's basically no

00:43:12,470 --> 00:43:16,550
portable interface for asynchronous i/o

00:43:14,660 --> 00:43:18,559
so right now for file system operations

00:43:16,550 --> 00:43:19,760
you tend to just have to fork out to a

00:43:18,559 --> 00:43:21,319
thread pool you have some thread pool

00:43:19,760 --> 00:43:23,059
actually performing blocking operations

00:43:21,319 --> 00:43:25,579
and then you have some sort of future of

00:43:23,059 --> 00:43:27,200
doing that result and so in with futures

00:43:25,579 --> 00:43:28,819
it ends up being very ergonomic and very

00:43:27,200 --> 00:43:30,260
easy to spawn futures on thread pools

00:43:28,819 --> 00:43:31,760
and then continue to work with them and

00:43:30,260 --> 00:43:33,260
you're just using question mark syntax

00:43:31,760 --> 00:43:35,750
the whole time with a with i/o errors

00:43:33,260 --> 00:43:38,030
and those kinds of objects so it ends up

00:43:35,750 --> 00:43:40,369
just being that because it's ergonomic

00:43:38,030 --> 00:43:42,020
enough to kind of spin that up and spawn

00:43:40,369 --> 00:43:43,970
off that work and just get the results

00:43:42,020 --> 00:43:45,770
back out in an asynchronous fashion that

00:43:43,970 --> 00:43:47,359
it's the thread pool is the way to go

00:43:45,770 --> 00:43:49,520
right now and I don't think there's as

00:43:47,359 --> 00:43:50,990
much if the kernel gives us the ability

00:43:49,520 --> 00:43:52,339
to do better we do better but for now we

00:43:50,990 --> 00:43:56,720
don't have we don't have much of an

00:43:52,339 --> 00:43:59,270
option well have a lot of questions on

00:43:56,720 --> 00:44:01,880
the right hand side so people on the

00:43:59,270 --> 00:44:04,839
left guys in there try to think of some

00:44:01,880 --> 00:44:07,490
questions to make me walk a bit

00:44:04,839 --> 00:44:09,319
do you have an embedded story or a no

00:44:07,490 --> 00:44:12,440
STDs story

00:44:09,319 --> 00:44:13,460
yes actually so the Tokyo crate doesn't

00:44:12,440 --> 00:44:15,770
really work with embedded because it

00:44:13,460 --> 00:44:17,270
kind of assumes Linux OSX windows kind

00:44:15,770 --> 00:44:18,890
of stuff but futures on the other hand

00:44:17,270 --> 00:44:21,410
actually is compatible with embedded

00:44:18,890 --> 00:44:23,420
systems in the sense that there is a no

00:44:21,410 --> 00:44:25,460
stood version of the futures crate and

00:44:23,420 --> 00:44:26,809
it actually still gives you at least so

00:44:25,460 --> 00:44:28,520
yeah it gives you the task model it

00:44:26,809 --> 00:44:30,530
gives you the task kind of a test

00:44:28,520 --> 00:44:32,119
current tasks notify everything there is

00:44:30,530 --> 00:44:34,250
built like you strip out some features

00:44:32,119 --> 00:44:35,869
features there are like you can't have a

00:44:34,250 --> 00:44:37,880
buffered stream you can't have the

00:44:35,869 --> 00:44:39,349
couple of allocating combinators but the

00:44:37,880 --> 00:44:41,119
bare-bones the future trait it's all

00:44:39,349 --> 00:44:43,430
compatible with that system and the way

00:44:41,119 --> 00:44:44,869
that that works is that essentially I

00:44:43,430 --> 00:44:46,670
was saying earlier that when you first

00:44:44,869 --> 00:44:48,980
create a task you have to allocate an

00:44:46,670 --> 00:44:50,630
arc and we basically add a trait for

00:44:48,980 --> 00:44:52,730
that saying it's it's an unsafe version

00:44:50,630 --> 00:44:54,589
of this trait or it's some allocated

00:44:52,730 --> 00:44:56,030
pointer that we we you tell us how to

00:44:54,589 --> 00:44:58,849
reference count it how to drop it and

00:44:56,030 --> 00:45:00,859
then we end up doing all that and so you

00:44:58,849 --> 00:45:02,089
can like what you end up can do is you

00:45:00,859 --> 00:45:02,420
can construct a system where everything

00:45:02,089 --> 00:45:04,069
instead

00:45:02,420 --> 00:45:06,319
allocated in there literally are no

00:45:04,069 --> 00:45:07,700
runtime allocations and ends up just

00:45:06,319 --> 00:45:09,349
working with features we haven't

00:45:07,700 --> 00:45:10,910
actually seen features used in the

00:45:09,349 --> 00:45:13,099
embedded context yet but it's

00:45:10,910 --> 00:45:14,750
essentially we want we always wanted to

00:45:13,099 --> 00:45:26,890
have it empowered to work at that layer

00:45:14,750 --> 00:45:26,890
cool thanks we're almost at the center

00:45:27,400 --> 00:45:36,530
so my question is this as I seen your

00:45:33,589 --> 00:45:39,890
timer example you use current task

00:45:36,530 --> 00:45:44,990
context to reschedule it

00:45:39,890 --> 00:45:47,420
then if task is the assumed the single

00:45:44,990 --> 00:45:50,869
entry control point why not pass it to

00:45:47,420 --> 00:45:54,940
Paul function explicitly otherwise it

00:45:50,869 --> 00:45:58,099
seems like non-trivial implicit

00:45:54,940 --> 00:46:00,170
dependency like if you want to

00:45:58,099 --> 00:46:03,170
reschedule you'll need to know that

00:46:00,170 --> 00:46:08,780
there is such thing as tasks in some

00:46:03,170 --> 00:46:10,130
module and stuff there it's true so the

00:46:08,780 --> 00:46:12,319
question is mostly why don't we pass

00:46:10,130 --> 00:46:16,640
tasks explicitly why why why is this a

00:46:12,319 --> 00:46:18,049
thread local variable mostly yes okay so

00:46:16,640 --> 00:46:19,910
that's a very good question and we

00:46:18,049 --> 00:46:21,910
definitely add that a lot so the

00:46:19,910 --> 00:46:24,349
decision here was that so on one hand

00:46:21,910 --> 00:46:25,910
every single poll function every single

00:46:24,349 --> 00:46:27,559
every single function and features is

00:46:25,910 --> 00:46:29,720
sort of parametric over a task so we

00:46:27,559 --> 00:46:31,849
could have the entire system pass pass

00:46:29,720 --> 00:46:36,890
tasks everywhere but on one hand that is

00:46:31,849 --> 00:46:39,530
a little a little unorganized ends up

00:46:36,890 --> 00:46:40,849
coming back to this i/o objects where we

00:46:39,530 --> 00:46:43,339
actually we want this Interop

00:46:40,849 --> 00:46:45,020
interoperation with the existing IO echo

00:46:43,339 --> 00:46:46,910
system kind of everything that already

00:46:45,020 --> 00:46:49,369
is compatible with async IO should still

00:46:46,910 --> 00:46:52,099
be compatible with with Tokyo itself and

00:46:49,369 --> 00:46:54,740
so this reach rate we're not actually

00:46:52,099 --> 00:46:56,839
defining the signature but there's no

00:46:54,740 --> 00:46:58,849
way to pass in a task here and there's

00:46:56,839 --> 00:47:00,770
no way to pass in a task to the actual

00:46:58,849 --> 00:47:02,119
like you can't bind the task to the poll

00:47:00,770 --> 00:47:04,190
event at object because you're creating

00:47:02,119 --> 00:47:06,470
features before they're bound to tasks

00:47:04,190 --> 00:47:08,089
and so the feature itself creates the

00:47:06,470 --> 00:47:10,730
poll evented before there's even a task

00:47:08,089 --> 00:47:12,859
in existence so this is an example

00:47:10,730 --> 00:47:14,420
actually which is not actually possible

00:47:12,859 --> 00:47:15,830
to implement in that kind of fashion

00:47:14,420 --> 00:47:18,050
where this is going to work

00:47:15,830 --> 00:47:20,450
are some sort of thread-local state

00:47:18,050 --> 00:47:22,340
passing going on there and so this is

00:47:20,450 --> 00:47:23,840
kind of one major motivating example but

00:47:22,340 --> 00:47:26,120
kind of the other aspect which is it's

00:47:23,840 --> 00:47:27,410
already everywhere it's already on every

00:47:26,120 --> 00:47:28,820
single function call and so it ends up

00:47:27,410 --> 00:47:30,950
just being a design decision where it's

00:47:28,820 --> 00:47:32,840
it's more ergonomic it's already

00:47:30,950 --> 00:47:34,810
happening regardless it doesn't have any

00:47:32,840 --> 00:47:37,760
runtime impact as far as we can tell and

00:47:34,810 --> 00:47:40,190
ends up making implementations cleaner

00:47:37,760 --> 00:47:42,110
Morgan AMA can in a sense and also

00:47:40,190 --> 00:47:44,210
enables this sort of reusing the i/o

00:47:42,110 --> 00:47:46,220
traits reusing that existing ecosystem

00:47:44,210 --> 00:47:55,370
and being still being able to pass a

00:47:46,220 --> 00:47:58,250
test out in there and so I understand

00:47:55,370 --> 00:48:01,340
I think timer might require tasks to

00:47:58,250 --> 00:48:07,370
reschedule and like I also get might

00:48:01,340 --> 00:48:10,580
require something else right we could do

00:48:07,370 --> 00:48:11,930
that it's kind of its kind of six to one

00:48:10,580 --> 00:48:13,100
half dozen really oh the other at that

00:48:11,930 --> 00:48:14,330
point where you you could have two

00:48:13,100 --> 00:48:15,890
systems for doing it but then you gotta

00:48:14,330 --> 00:48:18,770
learn two systems it is a little cleaner

00:48:15,890 --> 00:48:20,480
and it's I think a lot of it a lot of

00:48:18,770 --> 00:48:22,910
this does boil down to and that there's

00:48:20,480 --> 00:48:24,950
we we have not found a technical reason

00:48:22,910 --> 00:48:27,080
the past tasks around and so the current

00:48:24,950 --> 00:48:28,220
system we feel is kind of better for

00:48:27,080 --> 00:48:29,510
writing features better for using

00:48:28,220 --> 00:48:32,600
features and better with interoperating

00:48:29,510 --> 00:48:35,090
and in the presence of a lack of a

00:48:32,600 --> 00:48:36,470
technical argument we tend to just we we

00:48:35,090 --> 00:48:40,520
decided to stay the course of what we

00:48:36,470 --> 00:48:47,510
currently are okay now for one question

00:48:40,520 --> 00:48:49,990
on the left side anyone no more

00:48:47,510 --> 00:48:49,990
questions Oh

00:48:53,170 --> 00:49:04,210
thank you hi so um I mostly played with

00:49:01,359 --> 00:49:06,220
the Tokyo level and I was wondering if

00:49:04,210 --> 00:49:09,480
there is a way at the lower levels it's

00:49:06,220 --> 00:49:15,279
not exposed by Tokyo IO to prevent

00:49:09,480 --> 00:49:19,900
getting foals when there's not enough

00:49:15,279 --> 00:49:23,559
bytes in buffer maybe so for example I'm

00:49:19,900 --> 00:49:26,980
reading messages and I know I need at

00:49:23,559 --> 00:49:29,079
most at least 30 bytes can I prevent

00:49:26,980 --> 00:49:32,319
those contacts which is for the first 29

00:49:29,079 --> 00:49:35,109
bytes or is it not sensible to prevent

00:49:32,319 --> 00:49:37,569
that and by context which is you mean

00:49:35,109 --> 00:49:39,279
like you you pull out the current task

00:49:37,569 --> 00:49:40,480
and then you schedule yourself to get

00:49:39,279 --> 00:49:42,130
waited because you only got one byte at

00:49:40,480 --> 00:49:43,269
a time and you're kind of coming back no

00:49:42,130 --> 00:49:45,369
right now there's there's no way to do

00:49:43,269 --> 00:49:46,930
that it's it's one of those where most

00:49:45,369 --> 00:49:48,549
of the time if you end up having a

00:49:46,930 --> 00:49:49,720
blocking operation where you're not able

00:49:48,549 --> 00:49:51,250
to resolve it at that point in time

00:49:49,720 --> 00:49:53,349
you're already very much on the slow

00:49:51,250 --> 00:49:54,760
path so the fast path is where you don't

00:49:53,349 --> 00:49:56,019
even touch the task system you're just

00:49:54,760 --> 00:49:57,670
ready and you just keep going and the

00:49:56,019 --> 00:49:59,079
slow path is where alright I'm already

00:49:57,670 --> 00:50:00,369
gonna wait for multiple milliseconds to

00:49:59,079 --> 00:50:02,859
wait for those bytes to actually come in

00:50:00,369 --> 00:50:04,539
and so by that point it there there is

00:50:02,859 --> 00:50:05,769
no way to actually I mean you could busy

00:50:04,539 --> 00:50:07,750
wait you could sit there in the future

00:50:05,769 --> 00:50:08,829
and spin for five milliseconds waiting

00:50:07,750 --> 00:50:10,900
for the value to come available you're

00:50:08,829 --> 00:50:12,279
not quite a sync at that point but it's

00:50:10,900 --> 00:50:13,539
kind of might be a sick enough for that

00:50:12,279 --> 00:50:14,950
for that particular use case but in

00:50:13,539 --> 00:50:16,809
general there's no way to avoid that

00:50:14,950 --> 00:50:19,150
you'll have to you are forced to then

00:50:16,809 --> 00:50:20,859
get the task put it somewhere and then

00:50:19,150 --> 00:50:22,450
go through the whole machinery of load

00:50:20,859 --> 00:50:26,619
balancing and whatnot but there's no way

00:50:22,450 --> 00:50:31,109
to ask the kernel to say only signal the

00:50:26,619 --> 00:50:31,109
event on the file descriptor if you have

00:50:31,769 --> 00:50:39,630
known as far as far as I know no okay

00:50:37,509 --> 00:50:44,409
thanks Alex thank you

00:50:39,630 --> 00:50:44,409

YouTube URL: https://www.youtube.com/watch?v=4QZ0-vIIFug


