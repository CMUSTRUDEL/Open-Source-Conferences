Title: RustFest Zürich 2017 - Fearless concurrency in your microcontroller by Jorge Aparicio
Publication date: 2017-10-21
Playlist: RustFest Zürich 2017
Description: 
	Fast, efficient, safe: pick three.

Embedded systems are highly concurrent; they must respond to several different external stimuli within tight time constraints while maintaining a low power consumption. At the core of these systems we usually find microcontrollers, low end Systems on a Chip (SoCs) with just about enough resources to fulfill their tasks: tens of MHz of CPU frequency and a few KBs of RAM are usual.

In this talk we’ll explore how to do efficient multitasking on these systems using zero cost, memory safe abstractions.

About Jorge Aparicio:
Jorge Aparicio has been a Rustacean since Rust 0.9 (early 2014) and since that time he has many several contributions to the compiler, the standard libraries and the crate ecosystem. With his background in Mechatronics Jorge has been tackling, for more than one year now, the task of making Rust easy to use for embedded development with great success. He’s the author and maintainer of several crates and tools core to the ARM Cortex-M ecosystem.
Captions: 
	00:00:12,760 --> 00:00:14,760
Thanks for the introduction

00:00:16,620 --> 00:00:19,600
First you can find these slides at that

00:00:19,600 --> 00:00:23,600
Github link if you want to look at them in more detail.

00:00:23,600 --> 00:00:27,160
There are some links here, and there if you want to check them later

00:00:28,300 --> 00:00:32,020
My name is Jorge Aparicio. Also known as japaric on github

00:00:33,780 --> 00:00:37,780
Right now I'm a master student at Luleå University of Technology,

00:00:38,480 --> 00:00:43,560
and I'm working with professor Per Lindgren and we do a research on real-time systems

00:00:43,900 --> 00:00:46,660
and we are using Rust for our research

00:00:47,580 --> 00:00:51,380
Today, I will talk about concurrency in microcontrollers

00:00:53,860 --> 00:00:59,249
So the agenda for this talk is to go through micro-controllers basics and then cover

00:00:59,920 --> 00:01:06,239
cooperative multitasking and then go into preemption as an alternative for doing multitasking and

00:01:07,330 --> 00:01:11,939
We'll talk about the problems that arise from using preemption as a multitasking mechanism

00:01:11,939 --> 00:01:16,109
And then we'll talk about locks as a way to solve those problems

00:01:16,500 --> 00:01:20,840
Then I'll present a fearless concurrency framework that we have been developing

00:01:21,480 --> 00:01:23,900
and I conclude on some future work in this space

00:01:27,160 --> 00:01:29,160
First microcontrollers

00:01:30,820 --> 00:01:37,109
So we have these single core devices with a very small amount of RAM and

00:01:38,079 --> 00:01:40,079
[low] processing power

00:01:40,869 --> 00:01:44,188
So why would you want to use a microcontroller in your application?

00:01:44,829 --> 00:01:47,759
The main reason is that you want to do I/O with the world

00:01:48,039 --> 00:01:50,879
So when you are working with the general purpose computers

00:01:50,880 --> 00:01:55,920
I/O means files, sockets and data bases and when you're working with microcontrollers

00:01:55,929 --> 00:01:59,219
I/O means reading sensors, controlling motors

00:02:02,679 --> 00:02:04,509
Some of you

00:02:04,509 --> 00:02:09,869
may know that you can use single board computers like the Raspberry PI for this kind of I/O

00:02:10,210 --> 00:02:17,129
so why would you pick a microcontroller instead of a Raspberry Pi, which is more powerful and runs an

00:02:17,680 --> 00:02:19,680
operating system like Linux

00:02:20,230 --> 00:02:23,250
So within those reason we have that microcontrollers are cheaper

00:02:23,890 --> 00:02:25,570
Which is good for

00:02:25,570 --> 00:02:27,070
business

00:02:27,070 --> 00:02:29,070
They are simpler systems

00:02:29,349 --> 00:02:33,339
So they are simple enough that you can program them from scratch

00:02:34,549 --> 00:02:38,019
They also have lower power consumption. Which is good for battery life

00:02:40,099 --> 00:02:46,809
Most importantly you can have full control over how tasks get scheduled on this system if you're not using an operating system and

00:02:47,540 --> 00:02:52,150
This is important if you have timing requirements in your application

00:02:54,500 --> 00:03:01,329
In this talk I will be talking about bare metal system when there is no underlying OS that's when you get full control over

00:03:01,969 --> 00:03:03,969
scheduling of tasks and

00:03:04,669 --> 00:03:07,869
This is a minimal microcontroller program

00:03:08,540 --> 00:03:10,540
using the QuickStart framework

00:03:11,269 --> 00:03:13,269
It looks no different from any other

00:03:13,519 --> 00:03:14,780
Rust program

00:03:14,780 --> 00:03:20,649
We have this no_std attribute at the top, which means that the standard library is not available in this program

00:03:20,750 --> 00:03:22,809
Then we have some crates that will care of

00:03:23,510 --> 00:03:25,099
booting the device

00:03:25,099 --> 00:03:28,749
then you have a standard main function and

00:03:32,569 --> 00:03:35,858
A important thing to note here is that on bare metal systems

00:03:36,290 --> 00:03:40,540
You can only run one program at a time and this program must never end so

00:03:40,699 --> 00:03:45,459
In this case when the main function returns it will put your microcontroller to sleep

00:03:46,970 --> 00:03:48,970
This QuickStart framework gives you

00:03:50,870 --> 00:03:52,870
This common

00:03:54,290 --> 00:04:00,069
Level of support across different devices and currently it supports Cortex-M and MSP430 microcontrollers

00:04:00,560 --> 00:04:04,810
And someone is already working on importing this to RISC-V microcontrollers

00:04:06,620 --> 00:04:08,859
Next how we do I/O on a microcontroller

00:04:10,340 --> 00:04:13,500
Basically we have to just write or read memory

00:04:15,700 --> 00:04:18,640
Especially the region of memory called peripheral memory

00:04:19,560 --> 00:04:22,400
so this program does two

00:04:22,600 --> 00:04:27,660
write operations, and the first one will turn an LED on and the second one will turn it off

00:04:29,020 --> 00:04:31,440
This approach to I/O is called memory mapped I/O

00:04:35,840 --> 00:04:39,900
Let's look at three common peripherals that I use in some examples in this talk

00:04:41,360 --> 00:04:45,190
The first one is called general purpose input output

00:04:46,370 --> 00:04:52,600
So this peripheral lets you send digital signals through the microcontroller pins and with proper

00:04:53,330 --> 00:04:56,350
electronics you can use that to turn things on and off and

00:04:57,050 --> 00:05:03,850
the input part of this peripheral lets you read some external binary state like

00:05:04,490 --> 00:05:06,490
"is this button pressed or not?"

00:05:06,950 --> 00:05:12,879
This talk I'll use this high-level LED abstraction which give us an API to turn it on or off

00:05:14,810 --> 00:05:17,350
Another peripheral I'll be using are timers

00:05:18,770 --> 00:05:23,680
Timers are useful to generate periodic tasks and also to measure the duration of external events

00:05:24,590 --> 00:05:28,899
and in this program we use the timer as a periodic alarm and

00:05:29,960 --> 00:05:33,609
And we'll use this alarm to blink an LED

00:05:36,860 --> 00:05:41,920
So we use this `bwait` method which is a blocking method we will wait until the

00:05:42,830 --> 00:05:47,080
Alarm goes off and we just study it to generate the delays in this program

00:05:50,210 --> 00:05:52,660
How does this `bwait` method work?

00:05:53,600 --> 00:05:55,600
so this timer

00:05:56,300 --> 00:06:02,530
You can read its status by reading the status register, this status register is a

00:06:03,350 --> 00:06:06,790
32 bit of memory, peripheral memory, and

00:06:08,210 --> 00:06:16,120
When the alarm goes off one of the bits of this status register will be changed to `1` so what we do in this method is

00:06:16,790 --> 00:06:18,790
continuously poll in the state of

00:06:19,280 --> 00:06:24,070
The register until the bit is set to `1`. That indicates that the alarm has gone off

00:06:27,020 --> 00:06:28,940
This approach

00:06:28,940 --> 00:06:31,570
Is called busy waiting because the processor will be

00:06:32,480 --> 00:06:34,480
continuously polling a register.

00:06:34,820 --> 00:06:36,969
It's a wasteful approach to

00:06:37,640 --> 00:06:40,420
I/O but it gives us the delay we want

00:06:41,900 --> 00:06:43,900
another peripheral we use is

00:06:44,690 --> 00:06:50,769
Called serial which stands for serial port communication and serial port communication is this interface that allows you

00:06:51,080 --> 00:06:53,080
to exchange data between two endpoints

00:06:54,020 --> 00:06:55,040
at any given time

00:06:55,040 --> 00:06:58,380
Each end point can send data to the other side.

00:07:00,500 --> 00:07:08,500
This program here, will start by sending a greeting to the other endpoint, and then we will wait for some input

00:07:10,190 --> 00:07:13,749
Every byte it receives it will send it back to the

00:07:14,390 --> 00:07:20,409
The other side so basically it's kind of a... it will echo back all the received data

00:07:21,770 --> 00:07:23,770
Here as well all the methods are blocking

00:07:26,960 --> 00:07:28,989
Now we can move on to concurrency

00:07:30,620 --> 00:07:37,720
Let's say that we want to run these two previous programs at the same time so we want to create a new program that runs

00:07:40,010 --> 00:07:45,789
The two previous tasks concurrently we can use an approach which is called cooperative multitasking

00:07:47,420 --> 00:07:49,420
Using generators

00:07:50,960 --> 00:07:55,180
So here's the method for reading a byte from the interface

00:07:56,360 --> 00:08:00,820
From the serial interface using generators, so it looks similar to the

00:08:01,700 --> 00:08:04,180
`bwait` I showed you before but instead of

00:08:04,820 --> 00:08:06,500
continuously polling the

00:08:06,500 --> 00:08:11,080
Status register in this case what this method will do is yield control back to the caller

00:08:11,630 --> 00:08:13,929
while the condition is is not met and

00:08:14,450 --> 00:08:17,920
Then it will return the byte when it becomes available

00:08:20,600 --> 00:08:22,070
So

00:08:22,070 --> 00:08:24,610
using this generator "raise" API we can

00:08:25,340 --> 00:08:28,509
Write the task as infinite generators

00:08:29,420 --> 00:08:33,440
The first task is this echo program from before

00:08:33,520 --> 00:08:39,900
The logic looks exactly the same we'll read one byte and then send it back. I will use the generator API

00:08:40,720 --> 00:08:43,680
And we use the `await!` macro

00:08:45,290 --> 00:08:47,589
To drive this generator to completion

00:08:48,620 --> 00:08:51,190
The important thing here is that the `await!` macro doesn't block

00:08:51,860 --> 00:08:57,550
Until the operation is complete but instead it will yield control to the caller when you cannot make any more progress

00:08:59,960 --> 00:09:02,799
And the other task is the LED blinking task

00:09:03,680 --> 00:09:09,609
Here I have changed slightly the logic so you can see that generators can capture variables allocated on stack

00:09:11,660 --> 00:09:17,290
The `on` variable will track the state of the LED and we'll use that for turning on or off and

00:09:18,080 --> 00:09:20,080
to generate the delay we'll use

00:09:21,110 --> 00:09:22,580
a generator

00:09:22,580 --> 00:09:26,109
a version of the `await` method with the `await!` macro

00:09:28,910 --> 00:09:33,100
With those two tasks we can put them together in a program and

00:09:34,970 --> 00:09:40,089
To execute them concurrently we have this infinite loop that will resume the generators

00:09:40,760 --> 00:09:46,119
One after the other what you will do is that each processor will execute each task

00:09:47,150 --> 00:09:54,609
Until he cannot make any more progress on that task and it will switch to the other task and resume its operation

00:09:55,730 --> 00:09:59,380
so effectively it runs the two programs from before concurrently

00:10:01,610 --> 00:10:02,830
Note that this program

00:10:02,830 --> 00:10:05,679
still has busy waiting when the processor cannot

00:10:06,110 --> 00:10:11,200
Make progress on any of the tasks it will still continuously poll the status register

00:10:11,900 --> 00:10:13,959
which burns CPU cycles

00:10:17,570 --> 00:10:22,929
Now imagine this scenario you need to execute two periodic tasks concurrently like in the previous example

00:10:23,779 --> 00:10:27,309
But this time let's say that task 1 needs to be executed

00:10:27,920 --> 00:10:31,510
every 10 milliseconds and takes 2 milliseconds to complete and

00:10:32,089 --> 00:10:38,589
The second task needs to be run every 1 milliseconds and takes 100 microseconds to complete

00:10:41,240 --> 00:10:45,190
So can these timing constraint be satisfying using cooperative multitasking

00:10:52,730 --> 00:10:56,200
If we analyze this problem and say that

00:10:56,990 --> 00:10:58,990
task 1 is executed first

00:10:59,450 --> 00:11:03,819
And then 1 millisecond passes while we're executing that tasks

00:11:04,520 --> 00:11:06,759
We'll get a request to execute the second task

00:11:07,820 --> 00:11:15,760
But since we are using cooperative multitasking if task 1 never yields control back to the caller we'll continue its execution for another millisecond that

00:11:15,980 --> 00:11:19,839
Means that in those 2 milliseconds we didn't execute the task 2

00:11:20,480 --> 00:11:23,950
Which had to be run at least twice in that amount of time

00:11:24,830 --> 00:11:28,569
so task 2 missed its deadline twice

00:11:29,330 --> 00:11:34,629
In this case and if this were our real-time application

00:11:35,540 --> 00:11:41,529
That could mean a system failure because in real-time systems you cannot miss a single deadline

00:11:42,950 --> 00:11:48,369
So in general using cooperative multitasking we cannot always meet the timing constraints

00:11:49,670 --> 00:11:54,070
Instead we need task prioritization in this example if we had

00:11:54,760 --> 00:11:58,460
task prioritization, we could give tasks 2 a higher priority and

00:11:59,000 --> 00:12:05,980
That means that the processor could have a switch from executing task 1 to execute task 1 which have higher priority

00:12:06,440 --> 00:12:09,660
Once it is done with that, then it can resume execution of task 1

00:12:10,520 --> 00:12:13,780
Basically, we are saying here that task 2 can preempt the first task

00:12:17,120 --> 00:12:22,210
Micro-controllers provide a hardware mechanism for preemption which are interrupts

00:12:22,520 --> 00:12:26,979
And basically interrupts are a callback mechanism provided by the hardware

00:12:28,430 --> 00:12:30,430
So how do they work?

00:12:32,620 --> 00:12:35,720
So each in interrupt is triggered by a different event,

00:12:36,340 --> 00:12:41,400
External event, and you can register an interrupt handler for each interrupt

00:12:41,540 --> 00:12:43,540
and this interrupt handler is basically just a function

00:12:44,180 --> 00:12:49,120
In this program we register an interrupt for the `EXTI0` interrupt

00:12:50,510 --> 00:12:57,609
We register this handler function to deal with that interrupt and this interrupt is triggered when the user press a button

00:12:58,220 --> 00:12:59,839
so in this case

00:12:59,839 --> 00:13:02,529
The microcontroller will usually be executed in the main function

00:13:03,080 --> 00:13:04,899
but at some time

00:13:04,899 --> 00:13:10,688
at some point the user will press the button and when that happens the handler will call our interrupt handler

00:13:11,749 --> 00:13:14,769
Once the processor is done executing that interrupt handler

00:13:14,769 --> 00:13:18,849
We will resume the execution of the main function so what we can say here is that

00:13:19,339 --> 00:13:21,789
The interrupt handler can preempt the main function

00:13:22,220 --> 00:13:27,790
Another way to see this is that the interrupts have a higher priority than the main function

00:13:29,929 --> 00:13:33,039
We can port one of the previous examples I gave

00:13:33,980 --> 00:13:35,540
the echo

00:13:35,540 --> 00:13:36,920
program

00:13:36,920 --> 00:13:39,729
And in this case we can move all the logic

00:13:40,369 --> 00:13:42,369
into an interrupt handler

00:13:42,410 --> 00:13:47,019
And we can set the interrupt to trigger every time new data is available

00:13:49,420 --> 00:13:55,300
In this case there is nothing to do in the main loop since all the logic will be handled in the interrupt handler

00:13:55,460 --> 00:13:58,180
So in the main loop we can set the microcontroller to sleep

00:13:59,600 --> 00:14:02,520
which save energy so

00:14:04,730 --> 00:14:09,099
This program has no busy waiting and is more energy efficient

00:14:11,990 --> 00:14:19,329
So when you're working on interrupts at some point you will want to share memory between the main function and the interrupt handler,

00:14:20,120 --> 00:14:22,120
or have some means of communication

00:14:23,300 --> 00:14:26,900
And actually the only way to do that is to have a

00:14:26,900 --> 00:14:29,500
statically allocated variable

00:14:29,860 --> 00:14:33,920
and probably the first thing you will try is to use this static built variable to

00:14:34,519 --> 00:14:36,499
share memory between them

00:14:36,499 --> 00:14:38,919
And the problem with this variables is that

00:14:39,829 --> 00:14:45,369
Access to them is unsynchronized, and if you do that you will run into data races and race conditions

00:14:47,360 --> 00:14:51,669
So how can we do this memory sharing in a memory safe way?

00:14:52,429 --> 00:14:55,899
One way is to use locks to synchronize the operations

00:14:57,170 --> 00:14:59,979
so looking again the previous program we

00:15:00,829 --> 00:15:08,198
have the main function and the interrupt handler, both modify this shared data variable and

00:15:09,170 --> 00:15:17,019
The problem with this program is that if the main function is modifying the data variable and it gets preempted by the interrupt handler

00:15:17,400 --> 00:15:22,100
Then the interrupt handler might observe that the data variable is is in some

00:15:22,680 --> 00:15:25,190
inconsistent state or it might even find

00:15:25,800 --> 00:15:27,800
corrupted data

00:15:30,020 --> 00:15:37,660
So to solve this problem and this data race what we have to do is synchronize these two operations on the shared memory

00:15:39,200 --> 00:15:40,760
The synchronization

00:15:40,770 --> 00:15:46,970
For synchronizing these two operations its just enough that one happens before or after the other

00:15:47,940 --> 00:15:53,690
And the other order is not important as long as both operation doesn't happen midway of the other [operation]

00:15:55,140 --> 00:15:56,460
and

00:15:56,460 --> 00:15:58,230
We can do that

00:15:58,260 --> 00:16:01,840
By disabling the interrupts in the main functions

00:16:03,640 --> 00:16:10,160
And when we do that, while the main function is modifying the data variable the interrupt handler cannot preempt it

00:16:10,160 --> 00:16:11,460
that means that

00:16:12,870 --> 00:16:14,480
our

00:16:14,490 --> 00:16:17,900
operation on the shared memory will only happen either

00:16:18,600 --> 00:16:21,589
before or after the operation in the main function and

00:16:24,180 --> 00:16:29,210
This give us the synchronization to eliminate that data race and this program is no memory safe

00:16:31,770 --> 00:16:33,180
Note that

00:16:33,180 --> 00:16:40,080
in contrast with mutexes which we use in standard Rust programs, in this case the,

00:16:42,640 --> 00:16:49,660
the interrupt handler doesn't need to lock the data doesn't need to disable interrupts because it cannot be preempted by any other

00:16:50,220 --> 00:16:52,220
interrupt handler

00:16:52,880 --> 00:16:56,840
Now what would happen if we had another interrupt handler to the previous program and

00:16:59,140 --> 00:17:06,000
Let's say that main and the two interrupts are contending for the data. Is this program memory safe?

00:17:07,760 --> 00:17:10,040
And the answer is, it depends

00:17:11,610 --> 00:17:13,610
It depends on the architecture

00:17:14,220 --> 00:17:16,220
If you are running this on a

00:17:16,800 --> 00:17:18,540
msp430 microcontroller

00:17:18,540 --> 00:17:20,040
then

00:17:20,040 --> 00:17:25,190
in that architecture, interrupts are disabled when you are executing an interrupt

00:17:25,350 --> 00:17:30,050
That means that if you are executing one of these interrupt handlers, then it cannot get preempted

00:17:30,660 --> 00:17:37,499
Which means there is no data race on the operation that is executed in the interrupt handler so in that case it's memory safe

00:17:38,710 --> 00:17:42,360
But if instead you were targeting a Cortex-M microcontroller

00:17:43,120 --> 00:17:48,239
this architecture lets you assign priorities to the interrupt handlers and

00:17:48,970 --> 00:17:53,250
interrupts handlers with higher priority can preempt lower priority interrupts

00:17:53,500 --> 00:18:00,119
And in that case we cannot answer this question without knowing. What's the exact priorities of both interrupts

00:18:04,060 --> 00:18:07,799
So now lets say that we are working with Cortex-M microcontrollers

00:18:07,800 --> 00:18:13,050
And we have these three interrupts contending for the data, but this time we know the priority of each one

00:18:14,200 --> 00:18:16,800
And this version of the program is memory safe

00:18:18,400 --> 00:18:20,400
Note that only the two lower

00:18:20,920 --> 00:18:28,100
Priority interrupts need to lock the data before accessing it because they can be preempted by the highest priority interrupt

00:18:28,560 --> 00:18:34,580
And the highest priority interrupt doesn't need any lock to access the data since it cannot be preempted by anything else

00:18:36,900 --> 00:18:42,440
Now let's tweak that example a little bit. Again three interrupts with different priorities

00:18:43,150 --> 00:18:45,150
And this time only the two

00:18:46,300 --> 00:18:48,300
priorities with the lowest...

00:18:49,330 --> 00:18:55,470
[Only] the two interrupts with the lowest priorities access the data, but the highest priority interrupt doesn't access the data

00:18:56,290 --> 00:18:58,290
so this program is memory safe because

00:18:58,930 --> 00:19:01,680
The lower priority interrupt is blocking

00:19:03,660 --> 00:19:05,660
The `EXTI1`

00:19:05,680 --> 00:19:12,980
Interrupt handler from preemption. (We must know that a race can happen here.) But if we are using this [rough] lock

00:19:13,840 --> 00:19:17,900
This operation will also block the highest priority interrupt from running

00:19:18,120 --> 00:19:22,340
But in this case that interrupt doesn't need to be blocked because it doesn't access the data

00:19:24,040 --> 00:19:29,720
Can we improve this situation if we lock higher priority tasks from running?

00:19:30,580 --> 00:19:36,330
That is not good from a scalability point of view because higher priority interrupts are supposed to run

00:19:37,120 --> 00:19:39,720
Because they have higher priority, in that

00:19:39,720 --> 00:19:44,249
they are not supposed to be blocked by lower priority interrupts unless it is required for memory safety

00:19:45,880 --> 00:19:48,040
So we can use a different kind of lock

00:19:48,640 --> 00:19:51,480
And this is valid only for Cortex-M devices

00:19:52,020 --> 00:19:56,720
So instead of disabling all the interrupts we can raise the interrupt priority

00:19:57,369 --> 00:20:00,419
Temporarily just to block some of the interrupts

00:20:01,749 --> 00:20:03,749
And these are the actual

00:20:04,840 --> 00:20:10,289
Operations that need to be done, and they only work for Cortex-M3+ devices interrupts

00:20:11,889 --> 00:20:15,659
If we use now this different lock in the previous program and

00:20:16,980 --> 00:20:23,840
we raise the interrupts - we raise the priority to 2 and the lowest priority interrupt will get...

00:20:25,000 --> 00:20:27,000
require a

00:20:27,100 --> 00:20:31,440
synchronization troubled data race, but this time the `EXTI2`

00:20:32,139 --> 00:20:35,008
Interrupt won't be blocked by the lowest priority interrupt

00:20:38,769 --> 00:20:41,159
But in general how can we pick this

00:20:42,159 --> 00:20:43,749
temporal erase

00:20:43,749 --> 00:20:50,069
Priority and this is a problem that has been studied by the real-time research community since the 80s

00:20:50,379 --> 00:20:54,569
And an answer to that is the immediate ceiling priority protocol

00:20:55,960 --> 00:20:57,960
so in this

00:20:57,969 --> 00:21:02,039
Scheduling policy this raised priority value is called

00:21:02,710 --> 00:21:04,710
ceiling priority and

00:21:06,279 --> 00:21:11,549
Each resource which means a shared variable is assigned this priority ceiling

00:21:12,190 --> 00:21:17,099
Which is a priority equal to the highest priority of any task which might lock the resource?

00:21:17,619 --> 00:21:23,249
so we basically have to take the maximum value among all the priorities of the interrupts that access the

00:21:23,859 --> 00:21:25,839
variable

00:21:25,839 --> 00:21:28,739
And this scheduling policy has an extra nice,

00:21:30,070 --> 00:21:36,359
property which is nice which guarantees deadlock free execution if you use it use it correctly

00:21:39,339 --> 00:21:42,569
Now we have seen how to use a lock

00:21:43,210 --> 00:21:45,210
to prevent data races

00:21:45,849 --> 00:21:47,968
But even if you follow these guidelines

00:21:49,690 --> 00:21:55,559
Doing so by hand is error-prone and also all the programs have a bit of unsafe code in them

00:21:56,690 --> 00:22:04,120
Instead we'd like to write just safe Rust code and have the compiler enforce that memory safety for us

00:22:05,720 --> 00:22:11,860
And that's well where we have the real-time for the masses framework, which is Duke as RTFM

00:22:14,450 --> 00:22:22,120
This is actually a port of the "Real-Time for The Masses" language to the Rust language. This language was atdeveloped

00:22:23,660 --> 00:22:26,139
Luleå University of Technology and

00:22:27,920 --> 00:22:30,550
It has some really nice properties

00:22:32,780 --> 00:22:34,780
So in this framework

00:22:34,880 --> 00:22:40,030
the concurrency model is that you have tasks and resources and

00:22:41,060 --> 00:22:44,649
Each task in this model maps to a single interrupt

00:22:45,710 --> 00:22:49,420
Which means that you can assign priorities to tasks and

00:22:51,140 --> 00:22:57,339
By using interrupts you can have the hardware scheduled a task for you, which means you don't have any

00:22:58,280 --> 00:23:02,829
bookkeeping in your software so basically there is no code for the scheduler

00:23:04,460 --> 00:23:05,780
And

00:23:05,780 --> 00:23:11,979
[a] resource in this model is a zero cost mechanism to share memory. It is basically the locks we saw before and

00:23:13,160 --> 00:23:19,389
the framework uses this ICPP scheduling policy which guarantees deadlock freedom and

00:23:19,970 --> 00:23:22,060
All the ceilings which are required by this

00:23:22,730 --> 00:23:24,410
policy are

00:23:24,410 --> 00:23:26,840
automatically computed by the framework and

00:23:28,520 --> 00:23:31,420
Since this model uses tasks which are interrupts

00:23:33,320 --> 00:23:36,140
[it favors] writing event-driven

00:23:37,000 --> 00:23:38,860
preemptive multitasking

00:23:38,870 --> 00:23:42,520
But you can still do a cooperative multitasking as we saw the beginning

00:23:44,570 --> 00:23:50,530
The downside of all these nice properties is that the frame will require whole program analysis

00:23:50,990 --> 00:23:54,069
But as we'll see it is not much of a problem

00:23:54,860 --> 00:23:56,860
in the current implementation at least

00:23:58,400 --> 00:24:00,550
So let's see how a

00:24:01,220 --> 00:24:08,380
RTFM application looks like. All of them have this `app!` macro which is a specification of the application

00:24:09,220 --> 00:24:14,529
So the `app!` macro will have a declaration of all the resources and all the tasks in your application

00:24:15,289 --> 00:24:18,819
And the resources basically look like static variables

00:24:19,489 --> 00:24:21,049
and

00:24:21,049 --> 00:24:25,929
[at] each task entry what we'll do is bind an interrupt to a task and

00:24:26,509 --> 00:24:31,748
each one of these tasks will have a priority and a list of the resources he have access to

00:24:34,249 --> 00:24:40,959
In this particular example we have the resources and two tasks that run on different priorities

00:24:42,460 --> 00:24:44,460
And

00:24:44,560 --> 00:24:50,540
The `OWNED` resource is only accessed by one task and the `SHARED` resource is accessed by both tasks

00:24:53,140 --> 00:24:57,980
This `app!` macro is where we have this whole program analysis downside

00:25:00,019 --> 00:25:02,138
So thing is that this `app!` macro will

00:25:03,080 --> 00:25:05,529
Have to have all your tasks and resources

00:25:06,320 --> 00:25:10,840
Declared there and you can only have one instance of this macro in your application

00:25:13,159 --> 00:25:18,248
This basically means that you cannot split the declaration of tasks and resources across different crates.

00:25:20,509 --> 00:25:24,549
So this `app!` macro will expand into the main function

00:25:25,340 --> 00:25:27,609
So the user will have to supply

00:25:28,849 --> 00:25:32,619
These two init and idle functions instead of the main function

00:25:33,529 --> 00:25:40,539
So this init function will run first, we will take care of initialization, and it has access to all the peripherals

00:25:42,049 --> 00:25:44,528
And you will run with interrupts disabled

00:25:45,349 --> 00:25:47,349
and after,

00:25:47,929 --> 00:25:49,929
initialization have been completed,

00:25:50,629 --> 00:25:56,019
interrupts will be re-enabled and you have this idle function. This idle function is a never-ending

00:25:56,149 --> 00:25:59,049
function and you can do cooperative multitasking here

00:26:03,139 --> 00:26:10,839
And then the user write tasks as normal rust functions and the signatures you see here are generated by the

00:26:11,599 --> 00:26:13,599
framework

00:26:14,690 --> 00:26:20,200
This resources struct here is generated also by the framework and

00:26:21,570 --> 00:26:24,929
it enforces the resource access as is specified in the `app!` macro

00:26:25,360 --> 00:26:29,849
And the other thing that it does is minimizes locking operations so in this case

00:26:30,490 --> 00:26:35,759
We see that in the second task it cannot access the `OWNED` resource because in the specification

00:26:35,760 --> 00:26:38,560
We said that this task doesn't have access to that resource

00:26:39,600 --> 00:26:42,500
And it minimizes locking here

00:26:43,660 --> 00:26:49,060
as you can see the first task can access it's own resource without any kind of lock and

00:26:49,420 --> 00:26:52,500
The highest priority task which is the second one can access the `SHARED`

00:26:52,930 --> 00:26:59,310
Resource without any locking while the first task which has lower priority has to lock the resource to be able to access it

00:27:01,720 --> 00:27:05,699
So the RTFM framework uses locks as

00:27:09,610 --> 00:27:17,099
Some means to guarantee synchronization, but we also want to support other synchronization patterns

00:27:18,790 --> 00:27:26,790
For example you can also use Atomics for synchronization and we're working on letting you use those with RTFM

00:27:29,170 --> 00:27:33,029
Because right now if you use them you will have to lock the Atomic to be able to use, and

00:27:34,380 --> 00:27:37,760
and a new case that users have raised is that

00:27:38,440 --> 00:27:43,080
There is this common abstraction of a ring buffer, which has a single producer single consumer

00:27:43,660 --> 00:27:48,500
in this case you can kind of split your ring buffer into a producing a consumer and

00:27:49,450 --> 00:27:53,669
this data structure is interrupt safe and lock free and

00:27:54,160 --> 00:27:59,040
You can run the producer and the consumer on different tasks without any kind of blocking

00:27:59,080 --> 00:28:04,019
And we also working to get that working with RTFM without locking

00:28:06,700 --> 00:28:08,700
What's next in this

00:28:09,610 --> 00:28:11,610
Application space of real-time systems

00:28:12,160 --> 00:28:16,470
So RTFM gives you this preemptive multitasking that is very efficient

00:28:17,350 --> 00:28:21,659
But it's basically just a toolbox of concurrency primitives

00:28:23,200 --> 00:28:25,350
And the main way to do

00:28:26,530 --> 00:28:31,639
Communication between tasks is using shared memory, but shared memory can get harder to reason about

00:28:31,639 --> 00:28:33,120
when you have larger programs

00:28:34,070 --> 00:28:35,450
so

00:28:35,450 --> 00:28:41,710
The next extension to the real time for the masses framework are concurrent reactive objects

00:28:44,720 --> 00:28:46,720
Which kind of look like this

00:28:49,160 --> 00:28:51,080
So

00:28:51,080 --> 00:28:53,560
yeah, I guess you can see that very well, but

00:28:54,770 --> 00:28:56,770
In this case we have a different model

00:28:57,040 --> 00:28:59,409
We'll move to objects

00:28:59,900 --> 00:29:05,680
Instead of resources and we use message passing as a mean of communication between these objects

00:29:07,070 --> 00:29:14,949
So and in this example we have three objects and each one can pass information to the next one using message passing

00:29:16,820 --> 00:29:21,879
So we have both synchronous in a synchronous message in this framework and

00:29:22,340 --> 00:29:27,160
Asynchronous message will be posted to an a scheduler it will be executed later

00:29:28,310 --> 00:29:32,949
One other thing we have here is that we are adding timing semantics

00:29:33,710 --> 00:29:37,870
So you can specify the timing requirements of your application?

00:29:40,970 --> 00:29:44,110
So you can say how often an interrupt is triggered.

00:29:44,300 --> 00:29:50,440
And with that information the framework will take care of computing the priorities for you, so you don't have to specify them

00:29:53,240 --> 00:29:55,690
This version of RTFM is not yet

00:29:56,540 --> 00:29:58,540
Released we are still working on it

00:29:59,380 --> 00:30:02,460
So expect a blog post about that in the future

00:30:06,120 --> 00:30:07,560
Thank you!

00:30:07,560 --> 00:30:09,700
if you have any question, and if there is time

00:30:09,700 --> 00:30:15,580
[Applause]

00:30:16,360 --> 00:30:17,240

YouTube URL: https://www.youtube.com/watch?v=J4dZRrldMcI


