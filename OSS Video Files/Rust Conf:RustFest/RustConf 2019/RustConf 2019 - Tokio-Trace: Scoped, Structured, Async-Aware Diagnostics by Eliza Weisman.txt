Title: RustConf 2019 - Tokio-Trace: Scoped, Structured, Async-Aware Diagnostics by Eliza Weisman
Publication date: 2019-09-16
Playlist: RustConf 2019
Description: 
	RustConf 2019 - Tokio-Trace: Scoped, Structured, Async-Aware Diagnostics by Eliza Weisman

tokio-trace is a new set of Rust libraries that provide primitives for recording scoped, structured, and async-aware diagnostics. Unlike traditional logging, tokio-trace emits structured diagnostics that model the contextual and causal relationships between between events. tokio-trace was designed by the tokio project to solve problems with logging in asynchronous applications, but may be used in any Rust codebase. This talk presents the motivation and influences behind tokio-trace, introduces its core concepts, and demonstrates how it can be used.
Captions: 
	00:00:08,770 --> 00:00:15,680
[Music]

00:00:17,140 --> 00:00:23,119
hello Russ Khan how are we feeling

00:00:21,650 --> 00:00:26,420
tonight okay

00:00:23,119 --> 00:00:29,750
so I have a couple of Corrections that I

00:00:26,420 --> 00:00:31,520
need to make before we can continue some

00:00:29,750 --> 00:00:33,559
of you may have seen on the program that

00:00:31,520 --> 00:00:37,160
it says that this talk is about Tokyo

00:00:33,559 --> 00:00:39,920
Trace that's a lot this talk is not

00:00:37,160 --> 00:00:42,739
about Tokyo Trace we've renamed the

00:00:39,920 --> 00:00:45,050
library it's called tracing now

00:00:42,739 --> 00:00:46,670
it just happened after the light

00:00:45,050 --> 00:00:49,449
conference materials and the the

00:00:46,670 --> 00:00:52,309
programs and stuff were printed so

00:00:49,449 --> 00:00:54,650
here's your here's my first announcement

00:00:52,309 --> 00:00:57,800
of this it's it's not called tokyo trice

00:00:54,650 --> 00:01:00,920
anymore also it may upset in my speaker

00:00:57,800 --> 00:01:03,589
bio that i have two awful cats I regret

00:01:00,920 --> 00:01:05,630
my statement I only have one awful cat I

00:01:03,589 --> 00:01:10,580
have two cats but only one of them is

00:01:05,630 --> 00:01:12,380
awful and I hope all of you got the joke

00:01:10,580 --> 00:01:14,600
with the title music right that this

00:01:12,380 --> 00:01:19,090
talk is about logging and that was Kenny

00:01:14,600 --> 00:01:24,050
logging shout out to Adam filter who

00:01:19,090 --> 00:01:27,320
made that phone first so this is a talk

00:01:24,050 --> 00:01:28,880
about tracing not Tokyo trace tracing is

00:01:27,320 --> 00:01:31,490
a set of libraries that provide a

00:01:28,880 --> 00:01:33,650
framework for adding scoped structured

00:01:31,490 --> 00:01:36,500
and async aware diagnostics to rust

00:01:33,650 --> 00:01:38,840
programs so most of you are probably

00:01:36,500 --> 00:01:42,830
wondering why am I the most important

00:01:38,840 --> 00:01:45,080
logging thought leader right so my name

00:01:42,830 --> 00:01:47,360
is Eliza Wiseman I'm a system software

00:01:45,080 --> 00:01:50,270
engineer at a company called buoyant in

00:01:47,360 --> 00:01:51,710
San Francisco we make linker D the

00:01:50,270 --> 00:01:55,190
surface mesh for cloud native

00:01:51,710 --> 00:01:58,490
applications I've been writing rust for

00:01:55,190 --> 00:02:00,260
since 26 2015 I've been doing it I don't

00:01:58,490 --> 00:02:01,850
remember how long I've been writing rust

00:02:00,260 --> 00:02:05,030
since 2015 I've been doing it

00:02:01,850 --> 00:02:07,520
professionally for over two years and I

00:02:05,030 --> 00:02:10,599
am a core contributor to the Tokyo Tower

00:02:07,520 --> 00:02:13,040
and linker D to open source projects

00:02:10,599 --> 00:02:14,690
some of you've probably also seen my

00:02:13,040 --> 00:02:17,569
Twitter where I make bad programming

00:02:14,690 --> 00:02:20,569
jokes and post pictures of my cats cool

00:02:17,569 --> 00:02:22,310
so I guess the question really is why

00:02:20,569 --> 00:02:24,440
did I make another logging library right

00:02:22,310 --> 00:02:26,930
we already have a pretty robust

00:02:24,440 --> 00:02:29,239
ecosystem in rust around logging there's

00:02:26,930 --> 00:02:30,440
the log crate there's n vlogger and fern

00:02:29,239 --> 00:02:37,910
and so on

00:02:30,440 --> 00:02:39,350
so this is supposed to make my slide go

00:02:37,910 --> 00:02:42,740
oh there we go

00:02:39,350 --> 00:02:44,900
okay so right I I first of all I don't

00:02:42,740 --> 00:02:49,190
like to call it logging I like to call

00:02:44,900 --> 00:02:50,960
it GNU slash logging cool okay so I in

00:02:49,190 --> 00:02:54,140
my speaker notes it says like pause for

00:02:50,960 --> 00:02:56,270
laughter and so I I'm really glad that

00:02:54,140 --> 00:02:58,070
there was laughter yeah so that was a

00:02:56,270 --> 00:02:59,930
joke but I I don't like to call it

00:02:58,070 --> 00:03:03,140
logging I like to call it in process

00:02:59,930 --> 00:03:05,120
tracing and this is like a big very

00:03:03,140 --> 00:03:06,740
buzzword sounding name but we're gonna

00:03:05,120 --> 00:03:07,730
talk a little bit more later about what

00:03:06,740 --> 00:03:09,590
that actually means

00:03:07,730 --> 00:03:11,810
but to talk about the motivations for

00:03:09,590 --> 00:03:14,150
why I made another not vlogging library

00:03:11,810 --> 00:03:16,280
I have to ask some questions to the

00:03:14,150 --> 00:03:18,740
audience how many of you are using

00:03:16,280 --> 00:03:22,130
futures or now async/await show of hands

00:03:18,740 --> 00:03:24,950
okay that's a respectable number and are

00:03:22,130 --> 00:03:27,530
you like logging in those futures at all

00:03:24,950 --> 00:03:29,540
and does this make sense

00:03:27,530 --> 00:03:33,080
like you get something out of this

00:03:29,540 --> 00:03:36,250
that's readable any of you not really

00:03:33,080 --> 00:03:39,440
okay cool that's about what I thought a

00:03:36,250 --> 00:03:41,000
sync is hard there's supposed to be a

00:03:39,440 --> 00:03:42,620
posture laughter here but I guess you

00:03:41,000 --> 00:03:46,880
guys are just like so sad about this

00:03:42,620 --> 00:03:48,440
that but if you're writing any kind of

00:03:46,880 --> 00:03:51,170
like high-performance Network

00:03:48,440 --> 00:03:52,459
application or network library you need

00:03:51,170 --> 00:03:55,430
to use some kind of asynchronous

00:03:52,459 --> 00:03:57,800
programming if um but it presents some

00:03:55,430 --> 00:04:00,260
really unique challenges for Diagnostics

00:03:57,800 --> 00:04:02,180
especially when we're executing

00:04:00,260 --> 00:04:04,970
asynchronously the execution of the

00:04:02,180 --> 00:04:07,610
program is multiplex to cross different

00:04:04,970 --> 00:04:09,709
tasks and when they require something

00:04:07,610 --> 00:04:11,300
from input/output or they require

00:04:09,709 --> 00:04:13,250
something from another task instead of

00:04:11,300 --> 00:04:15,739
blocking the thread those tasks yield

00:04:13,250 --> 00:04:17,570
right and then we start executing

00:04:15,739 --> 00:04:19,459
another task and this is really good

00:04:17,570 --> 00:04:21,709
because it lets us like use all of our

00:04:19,459 --> 00:04:24,380
CPU time saturate the Nick whatever the

00:04:21,709 --> 00:04:26,930
bottleneck is but the problem is that

00:04:24,380 --> 00:04:31,640
because of this we can no longer really

00:04:26,930 --> 00:04:33,560
rely on events happening in order if we

00:04:31,640 --> 00:04:35,720
if we're logging in these asynchronous

00:04:33,560 --> 00:04:38,750
tasks those log messages come out

00:04:35,720 --> 00:04:40,700
interleaved or we see different contexts

00:04:38,750 --> 00:04:42,950
all logging information that might be

00:04:40,700 --> 00:04:44,060
very similar and we can easily trace

00:04:42,950 --> 00:04:47,450
what's going on

00:04:44,060 --> 00:04:48,860
between those log records by looking at

00:04:47,450 --> 00:04:52,790
the order in which they were displayed

00:04:48,860 --> 00:04:55,130
so how do we get good usable Diagnostics

00:04:52,790 --> 00:04:57,530
from asynchronous systems I'm going to

00:04:55,130 --> 00:04:59,750
touch on three what I see is the big

00:04:57,530 --> 00:05:01,550
pillars that we require if we want to

00:04:59,750 --> 00:05:03,500
have like Diagnostics

00:05:01,550 --> 00:05:06,740
in asynchronous systems that make sense

00:05:03,500 --> 00:05:09,620
we need to capture context causality and

00:05:06,740 --> 00:05:12,230
we want some form of structure so

00:05:09,620 --> 00:05:14,570
context when we record that some event

00:05:12,230 --> 00:05:16,610
has occurred we don't just need to know

00:05:14,570 --> 00:05:19,220
where it happened in the source code

00:05:16,610 --> 00:05:21,110
which are existing logging tools are

00:05:19,220 --> 00:05:23,030
very good at so they have like

00:05:21,110 --> 00:05:26,210
information about line numbers modules

00:05:23,030 --> 00:05:28,280
files and that's all great but it

00:05:26,210 --> 00:05:30,410
doesn't really tell us the runtime

00:05:28,280 --> 00:05:33,290
context in which some event that was

00:05:30,410 --> 00:05:35,270
recorded occurred in so for example if

00:05:33,290 --> 00:05:37,820
we have some HTTP server that's

00:05:35,270 --> 00:05:40,370
processing requests that context might

00:05:37,820 --> 00:05:41,480
include things like what client did this

00:05:40,370 --> 00:05:43,910
request come from

00:05:41,480 --> 00:05:46,190
what were their requests HTTP method

00:05:43,910 --> 00:05:48,650
what was its path what were the headers

00:05:46,190 --> 00:05:52,190
on that request and in synchronous code

00:05:48,650 --> 00:05:53,840
so not async we can infer that context

00:05:52,190 --> 00:05:56,900
by looking at log messages in order

00:05:53,840 --> 00:06:00,260
right if we see accepted request from

00:05:56,900 --> 00:06:02,510
this IP and then parsed a request with

00:06:00,260 --> 00:06:04,160
these headers after each other then we

00:06:02,510 --> 00:06:06,290
know oh this is the IP that sent their

00:06:04,160 --> 00:06:09,530
request but in async code where we're

00:06:06,290 --> 00:06:11,870
switching between these multiplex tasks

00:06:09,530 --> 00:06:14,690
based on readiness of i/o and other

00:06:11,870 --> 00:06:16,580
resources we switch between those

00:06:14,690 --> 00:06:18,410
contexts very rapidly and we can't

00:06:16,580 --> 00:06:22,880
really rely on the ordering of log

00:06:18,410 --> 00:06:24,370
messages to determine context second we

00:06:22,880 --> 00:06:27,080
care about causality

00:06:24,370 --> 00:06:29,270
there's complex chains of cause and

00:06:27,080 --> 00:06:31,190
effect in these asynchronous systems if

00:06:29,270 --> 00:06:33,380
I have some tasks that are running in

00:06:31,190 --> 00:06:35,810
the background like a DNS lookup or a

00:06:33,380 --> 00:06:38,360
database connection or something what

00:06:35,810 --> 00:06:40,970
caused them to start what caused those

00:06:38,360 --> 00:06:42,980
tasks to perform certain work and so on

00:06:40,970 --> 00:06:44,750
we can't rely on log ordering to

00:06:42,980 --> 00:06:47,140
determine this kind of causality either

00:06:44,750 --> 00:06:49,790
so we need to record it explicitly

00:06:47,140 --> 00:06:52,940
finally it's helpful to have structured

00:06:49,790 --> 00:06:56,090
Diagnostics traditional logging is based

00:06:52,940 --> 00:06:57,920
on human readable textual messages we

00:06:56,090 --> 00:06:59,990
prefer Diagnostics though that are

00:06:57,920 --> 00:07:02,300
machine-readable so that we can interact

00:06:59,990 --> 00:07:03,980
with them programmatically sure you can

00:07:02,300 --> 00:07:06,530
increment you can programmatically

00:07:03,980 --> 00:07:10,880
interact with unstructured logs if you

00:07:06,530 --> 00:07:14,210
use AA core grap but it's not good you

00:07:10,880 --> 00:07:16,280
know if anyone uses tracing after this

00:07:14,210 --> 00:07:19,430
talk and you ever have to grep through a

00:07:16,280 --> 00:07:23,360
log again you can come to my house and

00:07:19,430 --> 00:07:27,170
tell me this I will give you $20 you can

00:07:23,360 --> 00:07:30,770
record type data as type values and you

00:07:27,170 --> 00:07:32,830
can interact with that as type data so

00:07:30,770 --> 00:07:35,300
tracing tracing is a framework for

00:07:32,830 --> 00:07:38,120
instrumenting rust programs with

00:07:35,300 --> 00:07:40,520
contextual causal and structured

00:07:38,120 --> 00:07:42,350
Diagnostics as I said before it used to

00:07:40,520 --> 00:07:44,630
be called Tokyo trace but it's not

00:07:42,350 --> 00:07:47,440
called that anymore tracing is part of

00:07:44,630 --> 00:07:50,600
the Tokyo project so it's maintained by

00:07:47,440 --> 00:07:53,960
the people who brought you to Tokyo it

00:07:50,600 --> 00:07:56,450
doesn't require the Tokyo runtime so you

00:07:53,960 --> 00:07:58,550
can use it in synchronous programs you

00:07:56,450 --> 00:08:00,200
can use tracing in asynchronous programs

00:07:58,550 --> 00:08:02,270
that are using Tokyo you can use in an

00:08:00,200 --> 00:08:04,580
asynchronous programs that are using

00:08:02,270 --> 00:08:09,920
other runtimes you can use it in Waze

00:08:04,580 --> 00:08:13,660
improbably you can use it on on bare

00:08:09,920 --> 00:08:16,190
metal with no standard with some caveats

00:08:13,660 --> 00:08:18,290
you know ask me after class if this

00:08:16,190 --> 00:08:19,820
matters to you so I'm going to take a

00:08:18,290 --> 00:08:23,810
minute here and I'm going to switch

00:08:19,820 --> 00:08:31,510
gears so we're gonna look at a very

00:08:23,810 --> 00:08:31,510
quick demo okay so

00:08:34,720 --> 00:08:40,240
and in this demo I am running a web

00:08:37,210 --> 00:08:42,640
server and this web server implements an

00:08:40,240 --> 00:08:44,980
endpoint where you send HTTP requests

00:08:42,640 --> 00:08:47,080
where the path of those requests is a

00:08:44,980 --> 00:08:49,870
single ASCII character and then we

00:08:47,080 --> 00:08:52,300
implement something called character

00:08:49,870 --> 00:08:55,480
duplication as a service we send you a

00:08:52,300 --> 00:08:58,330
response where the body of that response

00:08:55,480 --> 00:09:00,220
is that character duplicated a number of

00:08:58,330 --> 00:09:03,070
times equal to the received content

00:09:00,220 --> 00:09:05,530
length header so you know this is like

00:09:03,070 --> 00:09:08,230
very important that like because

00:09:05,530 --> 00:09:11,500
web-scale like we have to do this as a

00:09:08,230 --> 00:09:14,380
micro service and and this is absolutely

00:09:11,500 --> 00:09:16,360
mission-critical right so but we happen

00:09:14,380 --> 00:09:19,230
to know that we're experiencing an

00:09:16,360 --> 00:09:21,850
elevated error rate in this service and

00:09:19,230 --> 00:09:23,410
so we're looking at these logs and as

00:09:21,850 --> 00:09:25,240
you see it's logging everything that's

00:09:23,410 --> 00:09:27,820
happening and this is scrolling really

00:09:25,240 --> 00:09:29,230
fast it's really hard to actually figure

00:09:27,820 --> 00:09:30,760
out what's going on here even though

00:09:29,230 --> 00:09:33,990
we're recording all of this information

00:09:30,760 --> 00:09:36,790
so we have very rich verbose Diagnostics

00:09:33,990 --> 00:09:38,740
the example server is hooked up to a

00:09:36,790 --> 00:09:40,780
load generator that's just like feeding

00:09:38,740 --> 00:09:42,040
requests into it and sometimes those

00:09:40,780 --> 00:09:43,600
requests are failing so we're gonna

00:09:42,040 --> 00:09:47,440
figure out why those requests are

00:09:43,600 --> 00:09:50,800
failing something we can do is that the

00:09:47,440 --> 00:09:56,010
example server I've added a little admin

00:09:50,800 --> 00:09:56,010
endpoint where you can you can send a

00:09:56,190 --> 00:10:02,050
post request and you can set a new

00:09:59,020 --> 00:10:04,810
filter that's used to reconfigure what

00:10:02,050 --> 00:10:10,210
tracing events are recorded so what we

00:10:04,810 --> 00:10:14,230
can do is we can start out by curl dash

00:10:10,210 --> 00:10:16,030
D and if you're familiar with the end

00:10:14,230 --> 00:10:18,790
vlogger crate you might recognize this

00:10:16,030 --> 00:10:21,480
syntax we're gonna look at the load

00:10:18,790 --> 00:10:21,480
generator only

00:10:27,970 --> 00:10:33,350
okay so we've dynamically reconfigured

00:10:30,890 --> 00:10:37,040
our Diagnostics so we're only looking at

00:10:33,350 --> 00:10:39,140
the load generator and here we see that

00:10:37,040 --> 00:10:41,180
the contexts in which these events are

00:10:39,140 --> 00:10:43,670
occurring it's being recorded with data

00:10:41,180 --> 00:10:45,290
about the request in which these errors

00:10:43,670 --> 00:10:48,110
are occurring so we have our four

00:10:45,290 --> 00:10:50,899
hundred errors therefore oh fours and we

00:10:48,110 --> 00:10:52,730
have our 500 errors looking at the 404s

00:10:50,899 --> 00:10:56,690
we see that there's this request dot

00:10:52,730 --> 00:11:00,470
path field and for the 404s it is just

00:10:56,690 --> 00:11:04,100
slash and for the 500 errors it is slash

00:11:00,470 --> 00:11:07,130
Z and we can determine that okay the

00:11:04,100 --> 00:11:09,680
404s are normal the spec for this

00:11:07,130 --> 00:11:11,660
example app is that you send a path with

00:11:09,680 --> 00:11:13,370
the single ASCII character the load

00:11:11,660 --> 00:11:15,620
generators failing to do that so the

00:11:13,370 --> 00:11:19,430
server is returning a 404 it's behaving

00:11:15,620 --> 00:11:22,220
correctly but the 500s are worrying so

00:11:19,430 --> 00:11:23,779
we want to look at the Diagnostics from

00:11:22,220 --> 00:11:27,110
the server to figure out what's causing

00:11:23,779 --> 00:11:28,940
those 500s and a very cool thing that we

00:11:27,110 --> 00:11:31,279
can do that you can't do with

00:11:28,940 --> 00:11:34,940
traditional unstructured logging is that

00:11:31,279 --> 00:11:37,250
if we go back to curl and we send a new

00:11:34,940 --> 00:11:40,040
request and this request that we're

00:11:37,250 --> 00:11:43,250
gonna send it's going to be a little

00:11:40,040 --> 00:11:46,040
fancier so this syntax is a superset of

00:11:43,250 --> 00:11:48,110
n vlogers filtering syntax right where

00:11:46,040 --> 00:11:50,510
you have these pairs of log targets and

00:11:48,110 --> 00:11:52,160
then verbosity levels I don't call them

00:11:50,510 --> 00:11:55,970
log levels because this isn't logging

00:11:52,160 --> 00:11:57,589
right so we're gonna introduce some new

00:11:55,970 --> 00:12:00,230
syntax now we have these square brackets

00:11:57,589 --> 00:12:02,600
and the square brackets indicate that we

00:12:00,230 --> 00:12:03,740
want to filter on a dynamic context this

00:12:02,600 --> 00:12:06,140
is one of the things that you have to do

00:12:03,740 --> 00:12:08,149
when you're adding a superset of an

00:12:06,140 --> 00:12:09,380
existing syntax is you have to add weird

00:12:08,149 --> 00:12:10,970
characters to it

00:12:09,380 --> 00:12:14,140
there's an entire programming language

00:12:10,970 --> 00:12:14,140
that's called Objective C

00:12:15,410 --> 00:12:23,639
yeah so alright so we're going to set

00:12:20,399 --> 00:12:27,120
this new filter and the filter we're

00:12:23,639 --> 00:12:29,519
gonna set is we care about field values

00:12:27,120 --> 00:12:31,380
so these structured data on the span

00:12:29,519 --> 00:12:34,230
context in which events are occurring

00:12:31,380 --> 00:12:36,079
and that's what the curly braces mean we

00:12:34,230 --> 00:12:38,399
care about a field and its value and

00:12:36,079 --> 00:12:43,260
specifically what we want is the field

00:12:38,399 --> 00:12:49,019
req or for request dot path and we want

00:12:43,260 --> 00:12:52,019
it to have the value /z and you'll see I

00:12:49,019 --> 00:12:56,490
have to escape the quotes here because

00:12:52,019 --> 00:12:59,910
my terminal but all I'm saying here is I

00:12:56,490 --> 00:13:02,850
want to see any requests whose path was

00:12:59,910 --> 00:13:05,100
Z I want to see the context where that

00:13:02,850 --> 00:13:08,010
event is being handled but I want to see

00:13:05,100 --> 00:13:11,010
all the Diagnostics in that context so I

00:13:08,010 --> 00:13:13,139
send that request look at that

00:13:11,010 --> 00:13:15,540
so we can now we're now seeing the

00:13:13,139 --> 00:13:19,050
entire life span of these requests right

00:13:15,540 --> 00:13:21,390
we see where the server is receiving the

00:13:19,050 --> 00:13:23,279
request we see the headers there then we

00:13:21,390 --> 00:13:25,529
see that we're handling the request with

00:13:23,279 --> 00:13:26,820
a handler and then we see this error

00:13:25,529 --> 00:13:29,070
that's being logged at a very high

00:13:26,820 --> 00:13:31,140
verbosity level that I don't like this

00:13:29,070 --> 00:13:34,290
letter and we're replying with the 500

00:13:31,140 --> 00:13:35,699
okay so we found the bug it's not it's

00:13:34,290 --> 00:13:39,720
not a good bug I put it there on purpose

00:13:35,699 --> 00:13:42,480
but you see here how we can trace the

00:13:39,720 --> 00:13:44,459
entire lifespan of this request and we

00:13:42,480 --> 00:13:47,040
can only look at requests that match

00:13:44,459 --> 00:13:49,829
this filter and even though this server

00:13:47,040 --> 00:13:52,350
is under really high load and lots of

00:13:49,829 --> 00:13:53,820
other stuff is going on here we've cut

00:13:52,350 --> 00:13:55,560
out all of that noise and we're looking

00:13:53,820 --> 00:14:00,089
only at these contexts that we care

00:13:55,560 --> 00:14:01,829
about so that's a demo of the power of

00:14:00,089 --> 00:14:04,529
what we can do with this kind of

00:14:01,829 --> 00:14:10,290
structured Diagnostics I am going to go

00:14:04,529 --> 00:14:14,000
back now to my slides is this are we

00:14:10,290 --> 00:14:17,160
looking at the right slides okay and

00:14:14,000 --> 00:14:18,779
demo all right so how does this tracing

00:14:17,160 --> 00:14:21,329
thing how does it actually work right

00:14:18,779 --> 00:14:25,019
you saw a cool demo everyone was wowed

00:14:21,329 --> 00:14:27,240
we owed a nod how do we do this what's

00:14:25,019 --> 00:14:28,139
actually happening here what did I mean

00:14:27,240 --> 00:14:31,259
when I

00:14:28,139 --> 00:14:34,139
in process tracing are any of you

00:14:31,259 --> 00:14:36,660
familiar with distributed tracing

00:14:34,139 --> 00:14:40,379
technologies like open tracing open

00:14:36,660 --> 00:14:42,449
telemetry Zipkin Jaeger so these are

00:14:40,379 --> 00:14:45,180
diagnostic tools for distributed systems

00:14:42,449 --> 00:14:47,610
since I only see a couple of hands I'm

00:14:45,180 --> 00:14:49,800
gonna just explain very briefly these

00:14:47,610 --> 00:14:52,529
tools are for diagnosing distributed

00:14:49,800 --> 00:14:55,199
systems they are designed to allow you

00:14:52,529 --> 00:14:58,139
to track contexts as they move between

00:14:55,199 --> 00:15:00,720
nodes in a distributed system so you

00:14:58,139 --> 00:15:02,819
have requests to one server that cause

00:15:00,720 --> 00:15:04,559
requests to another server and the way

00:15:02,819 --> 00:15:07,439
this works is we propagate some headers

00:15:04,559 --> 00:15:09,629
and those headers have an identifier

00:15:07,439 --> 00:15:12,899
that identifies a context called a span

00:15:09,629 --> 00:15:15,839
and the insight behind the tracing Krait

00:15:12,899 --> 00:15:17,790
not tracing the concept sorry it's a

00:15:15,839 --> 00:15:19,470
dictionary word I know that we can have

00:15:17,790 --> 00:15:22,290
collisions with these is that

00:15:19,470 --> 00:15:25,139
asynchronous programs are kind of

00:15:22,290 --> 00:15:27,930
analogous to distributed systems writ

00:15:25,139 --> 00:15:31,290
small right an asynchronous application

00:15:27,930 --> 00:15:32,819
in rust has concurrently running tasks

00:15:31,290 --> 00:15:35,790
that are communicating through message

00:15:32,819 --> 00:15:38,730
passing message passing is asynchronous

00:15:35,790 --> 00:15:40,170
it's fallible so it's sort of like the

00:15:38,730 --> 00:15:42,089
network I mean the network is worse

00:15:40,170 --> 00:15:44,759
right it's even more asynchronous and

00:15:42,089 --> 00:15:46,980
it's even more fallible but it's a

00:15:44,759 --> 00:15:48,779
similar concept the only difference is

00:15:46,980 --> 00:15:51,480
that now everything is running in the

00:15:48,779 --> 00:15:54,120
same address space so we can apply the

00:15:51,480 --> 00:15:56,370
same ideas that we use for tracing in

00:15:54,120 --> 00:15:57,959
distributed systems to tracing in a

00:15:56,370 --> 00:16:00,329
synchronous systems running in a single

00:15:57,959 --> 00:16:02,819
process so we introduced some core

00:16:00,329 --> 00:16:05,209
primitives in tracing and our core

00:16:02,819 --> 00:16:09,240
primitives are called spans and events

00:16:05,209 --> 00:16:11,759
water spans a span represents a period

00:16:09,240 --> 00:16:13,980
of time in the execution of a program it

00:16:11,759 --> 00:16:16,709
has a time when it starts and a time

00:16:13,980 --> 00:16:19,889
when it ends so it's the time period

00:16:16,709 --> 00:16:22,220
between those two points spans also can

00:16:19,889 --> 00:16:24,720
be entered and exited in tracing

00:16:22,220 --> 00:16:27,899
independently from being created and

00:16:24,720 --> 00:16:31,920
ending and we can enter and exit than

00:16:27,899 --> 00:16:33,929
multiple times this is how we track the

00:16:31,920 --> 00:16:36,750
asynchronous execution that moves

00:16:33,929 --> 00:16:39,420
between tasks context and a task might

00:16:36,750 --> 00:16:40,769
be executed within that context for a

00:16:39,420 --> 00:16:43,350
period of time

00:16:40,769 --> 00:16:45,869
and we yield we execute some other tasks

00:16:43,350 --> 00:16:48,809
we yield we execute some other tasks

00:16:45,869 --> 00:16:51,869
right and over the lifetime of a task it

00:16:48,809 --> 00:16:54,899
might be entered multiple times so we

00:16:51,869 --> 00:16:57,420
can record both how long the task

00:16:54,899 --> 00:17:00,779
existed for and how long it was being

00:16:57,420 --> 00:17:03,809
actively driven or executed we also can

00:17:00,779 --> 00:17:06,720
separate between just the existence of

00:17:03,809 --> 00:17:09,870
this thing and when we're in the context

00:17:06,720 --> 00:17:13,319
of that work right then here's how we

00:17:09,870 --> 00:17:16,649
make a span we have the span macro you

00:17:13,319 --> 00:17:20,069
get back this span object and here we're

00:17:16,649 --> 00:17:22,289
creating a span called migrate span then

00:17:20,069 --> 00:17:24,720
we have an enter method on the span

00:17:22,289 --> 00:17:27,360
object and that gives you back an ra íí-

00:17:24,720 --> 00:17:30,149
guard so you can scope the entry of a

00:17:27,360 --> 00:17:32,370
span to a stack frame or inside of a

00:17:30,149 --> 00:17:34,679
scope in a function and as long as you

00:17:32,370 --> 00:17:37,200
hold this guard you are considered to be

00:17:34,679 --> 00:17:40,590
executing inside this span when you drop

00:17:37,200 --> 00:17:43,230
the guard you exit the span right we

00:17:40,590 --> 00:17:45,630
also have kind of a fun tool which is

00:17:43,230 --> 00:17:47,220
this instrument procedural macro it's an

00:17:45,630 --> 00:17:49,500
attribute that you can put on a function

00:17:47,220 --> 00:17:52,770
and when you call that function you

00:17:49,500 --> 00:17:54,270
create a span for that function and it

00:17:52,770 --> 00:17:57,389
records all of the arguments to the

00:17:54,270 --> 00:18:00,480
function and it works on async functions

00:17:57,389 --> 00:18:03,120
and so async functions do sugar right to

00:18:00,480 --> 00:18:05,610
a future that's driven when you await

00:18:03,120 --> 00:18:08,580
the return type from the async function

00:18:05,610 --> 00:18:11,130
and so that returned future is

00:18:08,580 --> 00:18:13,710
instrumented so that when we pull that

00:18:11,130 --> 00:18:15,570
future we enter that span when we stop

00:18:13,710 --> 00:18:18,330
pulling the future we exit the span and

00:18:15,570 --> 00:18:19,889
that span can persist as long as the

00:18:18,330 --> 00:18:22,919
future that is returned by the async

00:18:19,889 --> 00:18:25,529
function consists or exists then we have

00:18:22,919 --> 00:18:27,840
a concept of events events are singular

00:18:25,529 --> 00:18:30,419
moments in time and they're basically

00:18:27,840 --> 00:18:32,730
just it's a log record but it's more

00:18:30,419 --> 00:18:35,159
structured than a log record we can add

00:18:32,730 --> 00:18:38,340
these structured fields to them their

00:18:35,159 --> 00:18:42,330
key value pairs and tracing subscribers

00:18:38,340 --> 00:18:44,580
can consume these pairs as a subtype of

00:18:42,330 --> 00:18:45,840
rough or a subset of russ primitives so

00:18:44,580 --> 00:18:48,000
there are some primitives that we know

00:18:45,840 --> 00:18:50,340
about like strings integers and so on

00:18:48,000 --> 00:18:53,309
and you can interact with them as those

00:18:50,340 --> 00:18:54,550
types instead of as oh it's a string

00:18:53,309 --> 00:18:56,770
cool I have a

00:18:54,550 --> 00:18:59,110
big string with a bunch of like stuff in

00:18:56,770 --> 00:19:00,850
it great I can't deal with that you need

00:18:59,110 --> 00:19:02,830
grip right so you don't need grip

00:19:00,850 --> 00:19:05,290
because we have structured fields and of

00:19:02,830 --> 00:19:07,050
type values and then we have this

00:19:05,290 --> 00:19:09,610
component called a subscriber a

00:19:07,050 --> 00:19:13,240
subscriber is the interface for a

00:19:09,610 --> 00:19:15,400
component that collects trace data it's

00:19:13,240 --> 00:19:16,900
basically like a logger right but you

00:19:15,400 --> 00:19:18,910
know in the log crate there's a log

00:19:16,900 --> 00:19:20,890
trait and the log trade has like two

00:19:18,910 --> 00:19:23,320
methods on it subscriber has a few more

00:19:20,890 --> 00:19:26,050
methods because it does a lot more than

00:19:23,320 --> 00:19:27,970
a logger but it's the same thing in that

00:19:26,050 --> 00:19:30,430
it's the main extension point for

00:19:27,970 --> 00:19:32,680
tracing and it actually collects the

00:19:30,430 --> 00:19:34,360
data that's emitted so libraries can

00:19:32,680 --> 00:19:36,460
provide subscriber implementations that

00:19:34,360 --> 00:19:39,040
do all kinds of different stuff like

00:19:36,460 --> 00:19:41,950
recording metrics printing logs to

00:19:39,040 --> 00:19:45,040
standard out whatever so how do we

00:19:41,950 --> 00:19:47,200
actually use this thing right I'm gonna

00:19:45,040 --> 00:19:49,390
work through a little example this

00:19:47,200 --> 00:19:52,390
example is drawn from a very important

00:19:49,390 --> 00:19:53,800
domain which is yak shaving some of you

00:19:52,390 --> 00:19:55,540
may have seen the version of this talk

00:19:53,800 --> 00:19:58,720
that I gave it a Russ meet-up in San

00:19:55,540 --> 00:20:01,330
Francisco where I had a slide much like

00:19:58,720 --> 00:20:03,490
this one I have since been informed I

00:20:01,330 --> 00:20:05,680
told you I had a few corrections to make

00:20:03,490 --> 00:20:07,990
I've since been informed that the animal

00:20:05,680 --> 00:20:11,790
on that slide was a yak or was not a yak

00:20:07,990 --> 00:20:14,440
it was a cow Google images mislead me

00:20:11,790 --> 00:20:17,950
this animal is the yak I have it on good

00:20:14,440 --> 00:20:19,720
authority so I take feedback from anyone

00:20:17,950 --> 00:20:22,210
in the audience and somebody told me

00:20:19,720 --> 00:20:24,400
this is not a yak so I fixed it here's a

00:20:22,210 --> 00:20:27,160
real act so we're shaving some yaks

00:20:24,400 --> 00:20:29,530
right looping over some yaks and shaving

00:20:27,160 --> 00:20:33,580
them but let's say we're shaving those

00:20:29,530 --> 00:20:35,140
yaks asynchronously right so this shaved

00:20:33,580 --> 00:20:36,940
yak function is asynchronous it's

00:20:35,140 --> 00:20:38,710
returning a future it could be an async

00:20:36,940 --> 00:20:40,840
FN or it could just be a function that

00:20:38,710 --> 00:20:43,600
returns a future it doesn't really

00:20:40,840 --> 00:20:46,140
matter so we're looping over these yaks

00:20:43,600 --> 00:20:49,060
we're spawning a task to shave that yak

00:20:46,140 --> 00:20:50,440
so we create this span called Shaving

00:20:49,060 --> 00:20:52,900
yaks this is where we're gonna do all

00:20:50,440 --> 00:20:54,790
the work of Shaving these yaks we can

00:20:52,900 --> 00:20:56,890
annotate it with whatever contextual

00:20:54,790 --> 00:20:59,410
information we want like say number of

00:20:56,890 --> 00:21:01,840
you actually were shaving and then we

00:20:59,410 --> 00:21:03,850
enter that span that indicates we're

00:21:01,840 --> 00:21:06,280
executing in the context of shaving

00:21:03,850 --> 00:21:08,230
these yaks and we have this enter guard

00:21:06,280 --> 00:21:11,179
that keeps us in the span

00:21:08,230 --> 00:21:12,049
and then we loop over the yaks you know

00:21:11,179 --> 00:21:14,630
okay

00:21:12,049 --> 00:21:18,260
so then every time we iterate that loop

00:21:14,630 --> 00:21:20,269
for a new yak we can create a span again

00:21:18,260 --> 00:21:22,760
it's called shave here and it records

00:21:20,269 --> 00:21:25,909
the current yak and the shaving span is

00:21:22,760 --> 00:21:28,490
a child of this span where we're shaving

00:21:25,909 --> 00:21:31,909
all the acts so it inherits that context

00:21:28,490 --> 00:21:35,000
so this span inherits the yak count from

00:21:31,909 --> 00:21:37,299
its parent and it adds the span that's

00:21:35,000 --> 00:21:39,740
or the Yak that's currently being shaved

00:21:37,299 --> 00:21:43,130
so we have this instrument Combinator

00:21:39,740 --> 00:21:44,870
this attaches a span to a future so

00:21:43,130 --> 00:21:46,880
whenever we pull this future that's

00:21:44,870 --> 00:21:48,380
shaving the yak we entered that span

00:21:46,880 --> 00:21:51,679
when we finished pulling it we exit

00:21:48,380 --> 00:21:54,830
right and we can also put that on a sink

00:21:51,679 --> 00:21:56,450
box so here now we're also recording an

00:21:54,830 --> 00:21:58,549
event after we finished shaving the Yak

00:21:56,450 --> 00:22:01,100
we call shaved yak we await the result

00:21:58,549 --> 00:22:04,190
we debug is logging in the debug level

00:22:01,100 --> 00:22:06,080
do we shape that yak turn okay we spawn

00:22:04,190 --> 00:22:07,970
this async block the instrumented with

00:22:06,080 --> 00:22:10,639
the span we're reshaping that yak so

00:22:07,970 --> 00:22:12,200
again this debug message inherits the

00:22:10,639 --> 00:22:15,740
yak that we're shaving the current yak

00:22:12,200 --> 00:22:18,289
and it inherits yak count and so on we

00:22:15,740 --> 00:22:20,269
have this tree of scopes in our program

00:22:18,289 --> 00:22:23,510
to represent the context in which we're

00:22:20,269 --> 00:22:25,880
executing finally okay so we can like

00:22:23,510 --> 00:22:28,220
match on that and we have either an

00:22:25,880 --> 00:22:30,019
error or we don't have an error we

00:22:28,220 --> 00:22:32,570
record that there was an error or we

00:22:30,019 --> 00:22:34,250
record that there wasn't an error and we

00:22:32,570 --> 00:22:36,590
recording this error is a structured

00:22:34,250 --> 00:22:39,529
value so actually as an instance of the

00:22:36,590 --> 00:22:41,000
standard error error type in the

00:22:39,529 --> 00:22:43,279
standard library so we're not just

00:22:41,000 --> 00:22:45,529
printing it or formatting it to a string

00:22:43,279 --> 00:22:47,929
the tracing subscriber can actually go

00:22:45,529 --> 00:22:50,659
oh this is an error it's a like dine

00:22:47,929 --> 00:22:53,330
error we can downcast it we can look at

00:22:50,659 --> 00:22:56,480
its source we can you format it with

00:22:53,330 --> 00:22:58,370
debug we can format it with display when

00:22:56,480 --> 00:23:00,320
the standard library adds back traces to

00:22:58,370 --> 00:23:02,389
errors we can look at its back trace so

00:23:00,320 --> 00:23:05,210
on and so forth right it's actually a

00:23:02,389 --> 00:23:07,100
typed object it's a rust struct or a

00:23:05,210 --> 00:23:09,139
rough trade object that we can interact

00:23:07,100 --> 00:23:11,299
with again we don't need to record

00:23:09,139 --> 00:23:13,669
anything about like what yak are we

00:23:11,299 --> 00:23:16,100
saving how many acts are we saving in

00:23:13,669 --> 00:23:18,200
these individual events because they

00:23:16,100 --> 00:23:21,980
inherit that from the span context in

00:23:18,200 --> 00:23:25,400
which they occur great so it also works

00:23:21,980 --> 00:23:27,140
very nicely with the log crate one way

00:23:25,400 --> 00:23:29,540
in which it works nicely is that our

00:23:27,140 --> 00:23:32,450
macros are a superset of the log crates

00:23:29,540 --> 00:23:36,080
macros so if this compiles right here

00:23:32,450 --> 00:23:37,610
I'm using log and then I'm logging if I

00:23:36,080 --> 00:23:43,220
want to switch to tracing in my

00:23:37,610 --> 00:23:45,920
application right oh sorry

00:23:43,220 --> 00:23:49,730
do you see the difference use log use

00:23:45,920 --> 00:23:51,710
tracing same syntax we have other syntax

00:23:49,730 --> 00:23:53,900
for doing more things like creating

00:23:51,710 --> 00:23:55,610
these structured fields that log only

00:23:53,900 --> 00:23:58,120
just now has a concept of but it's

00:23:55,610 --> 00:24:01,610
macros don't I'll get into that later

00:23:58,120 --> 00:24:04,130
but you get you have a super set of logs

00:24:01,610 --> 00:24:06,170
syntax so if you want to migrate you can

00:24:04,130 --> 00:24:07,730
just drop in tracing and then you can go

00:24:06,170 --> 00:24:10,670
back and add more structured information

00:24:07,730 --> 00:24:13,670
more spans whatever but it's very easy

00:24:10,670 --> 00:24:17,120
to adopt and then you can incrementally

00:24:13,670 --> 00:24:19,730
roll it out we also have adapters they

00:24:17,120 --> 00:24:22,130
let you record log records as tracing

00:24:19,730 --> 00:24:25,580
events and tracing events as log records

00:24:22,130 --> 00:24:27,650
so if you have a dependency that omits

00:24:25,580 --> 00:24:29,510
log records you can record them as

00:24:27,650 --> 00:24:31,730
tracing events that are within that span

00:24:29,510 --> 00:24:34,040
hierarchy even though the dependency

00:24:31,730 --> 00:24:35,450
doesn't know about tracing similarly if

00:24:34,040 --> 00:24:37,610
you have a library that many people

00:24:35,450 --> 00:24:40,040
depend on some of them are using tracing

00:24:37,610 --> 00:24:42,440
some we're using log we have a feature

00:24:40,040 --> 00:24:45,290
that when you enable it all of the

00:24:42,440 --> 00:24:47,540
tracing macros also emit log records so

00:24:45,290 --> 00:24:49,250
your users who depend on log records

00:24:47,540 --> 00:24:54,320
being there will still have their log

00:24:49,250 --> 00:24:56,630
records finally any runtime ins

00:24:54,320 --> 00:24:59,120
instrumentation has performance costs

00:24:56,630 --> 00:25:00,800
right you were doing something to record

00:24:59,120 --> 00:25:02,690
this data that you otherwise would not

00:25:00,800 --> 00:25:04,480
be doing you can't get away from that

00:25:02,690 --> 00:25:07,880
there's no such thing as a free lunch

00:25:04,480 --> 00:25:10,670
but tracings goal is to ensure that you

00:25:07,880 --> 00:25:13,070
only pay for what you eat when you know

00:25:10,670 --> 00:25:14,600
there is it's not a free lunch but you

00:25:13,070 --> 00:25:15,950
you don't have to pay for the whole

00:25:14,600 --> 00:25:17,060
lunch you just pay for the parts that

00:25:15,950 --> 00:25:19,400
you want

00:25:17,060 --> 00:25:21,140
we have tried really really hard to

00:25:19,400 --> 00:25:23,510
design these api's to ensure that there

00:25:21,140 --> 00:25:25,250
are no costs that you pay that you are

00:25:23,510 --> 00:25:25,730
not actually using so what does that

00:25:25,250 --> 00:25:28,730
mean

00:25:25,730 --> 00:25:31,190
first of all we when any instrumentation

00:25:28,730 --> 00:25:33,830
is disabled like the filtering that we

00:25:31,190 --> 00:25:35,600
were doing in the demo we've made sure

00:25:33,830 --> 00:25:38,450
that it is basically free to

00:25:35,600 --> 00:25:41,450
that there's like one atomic load and a

00:25:38,450 --> 00:25:43,970
branch so it's not free free but it's

00:25:41,450 --> 00:25:45,559
close it's about the same cost to

00:25:43,970 --> 00:25:47,750
skipping and disabled log line in the

00:25:45,559 --> 00:25:49,370
log crate we cache the evaluation of

00:25:47,750 --> 00:25:50,929
filters so that if you have like a regex

00:25:49,370 --> 00:25:52,549
that determines if something is enabled

00:25:50,929 --> 00:25:54,140
you don't have to like run the regex

00:25:52,549 --> 00:25:57,110
over and over and over for the same

00:25:54,140 --> 00:25:59,150
thing so we've optimized this a lot

00:25:57,110 --> 00:26:01,250
we've also designed the subscriber API

00:25:59,150 --> 00:26:04,039
to ensure that you don't pay cost by

00:26:01,250 --> 00:26:05,990
default so depending on the use case a

00:26:04,039 --> 00:26:07,820
subscriber that's recording trace events

00:26:05,990 --> 00:26:09,860
might do a lot of different things if

00:26:07,820 --> 00:26:11,900
you're doing time profiling and there's

00:26:09,860 --> 00:26:14,150
a crate that does time profiling on top

00:26:11,900 --> 00:26:16,250
of tracing you need to make sis calls to

00:26:14,150 --> 00:26:17,809
get timestamps if you're logging with

00:26:16,250 --> 00:26:19,880
timestamps you need to make sis calls to

00:26:17,809 --> 00:26:21,740
get timestamps but if you don't need

00:26:19,880 --> 00:26:23,299
those timestamps you don't need to make

00:26:21,740 --> 00:26:26,960
that sis call right to get that

00:26:23,299 --> 00:26:28,760
timestamp if you want to trap persistent

00:26:26,960 --> 00:26:30,260
data you have to allocate but if you

00:26:28,760 --> 00:26:32,120
don't need that persistent data you

00:26:30,260 --> 00:26:33,789
don't have to allocate right and so

00:26:32,120 --> 00:26:36,380
tracing doesn't do any of those things

00:26:33,789 --> 00:26:39,230
the subscriber can make the Syst calls

00:26:36,380 --> 00:26:41,870
the subscriber can allocate the storage

00:26:39,230 --> 00:26:44,600
if it needs to for the specific behavior

00:26:41,870 --> 00:26:47,690
that it implements tracing itself will

00:26:44,600 --> 00:26:49,250
never do those things finally it's worth

00:26:47,690 --> 00:26:51,590
noting that we're really trying to

00:26:49,250 --> 00:26:53,840
bootstrap a whole ecosystem of libraries

00:26:51,590 --> 00:26:57,080
here they're the core crates there's

00:26:53,840 --> 00:26:59,900
tracing core and tracing which are like

00:26:57,080 --> 00:27:02,690
the facade layer that you actually

00:26:59,900 --> 00:27:05,750
depend on that makes everything work but

00:27:02,690 --> 00:27:07,429
on top of that we have to actually

00:27:05,750 --> 00:27:10,549
implement these subscribers that have

00:27:07,429 --> 00:27:12,770
different behaviors for example we have

00:27:10,549 --> 00:27:15,230
a tracing format crate which is what I

00:27:12,770 --> 00:27:17,690
was using in the demo and it implements

00:27:15,230 --> 00:27:19,400
logging trace events to the console but

00:27:17,690 --> 00:27:22,520
there's all kinds of other things you

00:27:19,400 --> 00:27:26,480
can do like metrics or with time

00:27:22,520 --> 00:27:29,210
profiling john ging set has a tracing

00:27:26,480 --> 00:27:31,340
timing crate that allows you to do like

00:27:29,210 --> 00:27:33,679
histograms of how long a span takes to

00:27:31,340 --> 00:27:35,360
execute which i think is very cool but

00:27:33,679 --> 00:27:37,909
there's a lot of other really neat stuff

00:27:35,360 --> 00:27:40,760
we can build to consume this unified

00:27:37,909 --> 00:27:43,090
layer of instrumentation to output any

00:27:40,760 --> 00:27:45,110
kind of diagnostics that we want and

00:27:43,090 --> 00:27:47,870
there's a lot of stuff we can build

00:27:45,110 --> 00:27:49,340
using this and i think i probably have

00:27:47,870 --> 00:27:51,110
only thought of like a

00:27:49,340 --> 00:27:54,080
any amount of it so I'd really like to

00:27:51,110 --> 00:27:56,290
see what everyone else I can come up

00:27:54,080 --> 00:27:59,450
with so here's how you can get involved

00:27:56,290 --> 00:28:03,080
it's on crates do all of the core crates

00:27:59,450 --> 00:28:04,820
are and we have a github repository in

00:28:03,080 --> 00:28:09,710
the Tokyo organization that has all of

00:28:04,820 --> 00:28:11,870
the like core tracing and you know we

00:28:09,710 --> 00:28:15,470
also have a discussion group on git er

00:28:11,870 --> 00:28:17,990
and so on and so forth so please if

00:28:15,470 --> 00:28:19,460
you're interested open a pull request or

00:28:17,990 --> 00:28:22,040
an issue if there's something you want

00:28:19,460 --> 00:28:25,370
to see I love to get issues

00:28:22,040 --> 00:28:27,500
I love feature requests and if anyone

00:28:25,370 --> 00:28:29,120
actually wants to write those features

00:28:27,500 --> 00:28:33,130
they can do that too that would be great

00:28:29,120 --> 00:28:37,750
but so please check it out try it out

00:28:33,130 --> 00:28:41,180
and we would love to hear from you

00:28:37,750 --> 00:28:43,060
here's some links if you have any

00:28:41,180 --> 00:28:45,320
questions reach out to me after class

00:28:43,060 --> 00:28:47,330
here's my email address on my Twitter

00:28:45,320 --> 00:28:48,680
and you can get the slides from my

00:28:47,330 --> 00:28:50,600
website or I think they're on the

00:28:48,680 --> 00:28:52,490
restaurant website so you don't have to

00:28:50,600 --> 00:28:54,410
like keep taking pictures like I see

00:28:52,490 --> 00:28:56,480
people keep doing this is the only slide

00:28:54,410 --> 00:28:57,970
you need to take a picture of I should

00:28:56,480 --> 00:29:00,470
have told you that at the beginning

00:28:57,970 --> 00:29:02,570
there's a blog post I wrote on tracing

00:29:00,470 --> 00:29:05,450
that reproduces a lot of the same

00:29:02,570 --> 00:29:08,870
content from this talk or please reach

00:29:05,450 --> 00:29:10,820
out to me whenever you you like if you

00:29:08,870 --> 00:29:14,980
have any questions Thanks

00:29:10,820 --> 00:29:21,810
[Applause]

00:29:14,980 --> 00:29:23,870
[Music]

00:29:21,810 --> 00:29:23,870

YouTube URL: https://www.youtube.com/watch?v=JjItsfqFIdo


