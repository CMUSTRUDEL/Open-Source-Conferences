Title: Interactive Data Visualization Leveraging Jupyter, Rust and WebAssembly | SciPy 2018 |  Munk
Publication date: 2018-09-09
Playlist: Other Conferences 2018
Description: 
	This talk covers a Jupyter widget built using Rust and WebAssembly for interactive, browser-based visualization of datasets with yt, a python package used to analyze and visualize volumetric data in a number of scientific domains. Users can interact and explore datasets of varying sizes with our Jupyter widget. We minimize latency that results from data transmission between yt and the browser by compiling our pixelization routines to WebAssembly and pushing data to the browser. Operations on the canvas are subsequently done in the browser. Our tool enables interactive data exploration accessible to a broad user base.

See the full SciPy 2018 playlist at https://www.youtube.com/playlist?list=PLYx7XA2nY5Gd-tNhm79CNMe_qvi35PgUR
Captions: 
	00:00:00,030 --> 00:00:03,629
Thank You Chelsea yeah so that's a

00:00:02,610 --> 00:00:04,950
really long title

00:00:03,629 --> 00:00:07,259
hopefully we'll walk through it together

00:00:04,950 --> 00:00:08,580
today and you understand why I had to

00:00:07,259 --> 00:00:12,630
make it so long and I couldn't make it

00:00:08,580 --> 00:00:14,340
any shorter but first I want to tell you

00:00:12,630 --> 00:00:15,990
all a little about me I'm this is my

00:00:14,340 --> 00:00:22,289
first time at Syfy so I'm gonna give a

00:00:15,990 --> 00:00:23,850
little introduction thank you I got my

00:00:22,289 --> 00:00:28,099
PhD from the University of California

00:00:23,850 --> 00:00:30,840
Berkeley just under a year ago I got I

00:00:28,099 --> 00:00:33,870
did all of my work in radiation

00:00:30,840 --> 00:00:36,930
transport so simulating radiation moving

00:00:33,870 --> 00:00:38,520
through space and this was in

00:00:36,930 --> 00:00:40,920
collaboration with Oak Ridge National

00:00:38,520 --> 00:00:42,450
Labs and a lot of my work was done as a

00:00:40,920 --> 00:00:45,059
member of the Berkeley Institute for

00:00:42,450 --> 00:00:46,860
data science so I hovered around kind of

00:00:45,059 --> 00:00:50,129
creeped on the bed fellows but I wasn't

00:00:46,860 --> 00:00:51,210
actually a fellow now I'm at the

00:00:50,129 --> 00:00:54,469
University of Illinois at

00:00:51,210 --> 00:00:55,890
urbana-champaign yeah at the date at

00:00:54,469 --> 00:00:57,989
National Center for supercomputing

00:00:55,890 --> 00:01:00,090
applications specifically in the data

00:00:57,989 --> 00:01:02,430
exploration lab there's a lot of members

00:01:00,090 --> 00:01:05,159
of the data exploration lab here too at

00:01:02,430 --> 00:01:08,189
SCI PI this week you might have seen

00:01:05,159 --> 00:01:10,320
Nathan goldbam give an update on whitey

00:01:08,189 --> 00:01:13,049
the package I'm going to be kind of

00:01:10,320 --> 00:01:14,700
talking about today yesterday in the

00:01:13,049 --> 00:01:16,439
tools plenary session you might have

00:01:14,700 --> 00:01:21,299
seen Megan Lang give attack on

00:01:16,439 --> 00:01:23,820
interfacing science models in using CIS

00:01:21,299 --> 00:01:26,280
interface that was two days ago or you

00:01:23,820 --> 00:01:29,220
might have seen Casper carbolic give a

00:01:26,280 --> 00:01:31,590
talk on the whole tale and I'm also

00:01:29,220 --> 00:01:33,780
involved in scientific computing I'm in

00:01:31,590 --> 00:01:35,880
a software carpentry instructor I

00:01:33,780 --> 00:01:37,530
maintain the software carpentry get

00:01:35,880 --> 00:01:39,150
lesson and I'm a member of the

00:01:37,530 --> 00:01:41,310
curriculum Advisory Committee for cyber

00:01:39,150 --> 00:01:43,229
carpentry and I'm a part of the

00:01:41,310 --> 00:01:46,140
committee for diversity inclusion in

00:01:43,229 --> 00:01:48,979
scientific computing unfocus that's a

00:01:46,140 --> 00:01:50,850
lot of stuff sorry

00:01:48,979 --> 00:01:53,220
so we're in the data visualization

00:01:50,850 --> 00:01:55,290
section all of us care about data

00:01:53,220 --> 00:01:56,820
visualization and I'm going to be

00:01:55,290 --> 00:02:01,590
specifically talking mostly about a

00:01:56,820 --> 00:02:03,320
package called YT today YT is a package

00:02:01,590 --> 00:02:05,759
that is designed to visualize

00:02:03,320 --> 00:02:09,209
multi-dimensional data it was originally

00:02:05,759 --> 00:02:11,670
designed for astronomical data but now

00:02:09,209 --> 00:02:12,960
as Nathan mentioned yesterday it is

00:02:11,670 --> 00:02:14,760
branching into

00:02:12,960 --> 00:02:17,340
domaine so I've given a little selection

00:02:14,760 --> 00:02:19,740
of different domains that are that

00:02:17,340 --> 00:02:21,570
whitey is branching into here we have

00:02:19,740 --> 00:02:24,870
meteorology we have an original

00:02:21,570 --> 00:02:30,300
astronomy data set we have high energy

00:02:24,870 --> 00:02:33,000
physics and oceanography this is a like

00:02:30,300 --> 00:02:37,170
an earthquake simulation and so

00:02:33,000 --> 00:02:42,240
seismology and then also relativistic

00:02:37,170 --> 00:02:44,040
physics on the last one so we can

00:02:42,240 --> 00:02:46,530
visualize our data and when we want to

00:02:44,040 --> 00:02:48,300
publish papers we like want to get some

00:02:46,530 --> 00:02:50,220
really high quality images but in

00:02:48,300 --> 00:02:52,410
between that we want to interactively

00:02:50,220 --> 00:02:54,570
visualize our data and see where the

00:02:52,410 --> 00:02:56,670
interesting things are and so this is a

00:02:54,570 --> 00:02:59,750
different step in the data visualization

00:02:56,670 --> 00:03:01,710
sort of pathway that we want to go down

00:02:59,750 --> 00:03:03,420
interactivity allows on the fly

00:03:01,710 --> 00:03:05,640
parameter tuning you know we can change

00:03:03,420 --> 00:03:07,350
the color map to bring out features that

00:03:05,640 --> 00:03:09,240
interest us we might change the min and

00:03:07,350 --> 00:03:11,130
the max values of our data that are

00:03:09,240 --> 00:03:13,890
being visualized because we are

00:03:11,130 --> 00:03:15,990
interested in them but it also allows

00:03:13,890 --> 00:03:17,910
for this exploration of our data we can

00:03:15,990 --> 00:03:21,540
like zoom in on a feature that we care

00:03:17,910 --> 00:03:23,610
about and maybe we see things that we

00:03:21,540 --> 00:03:26,250
didn't expect in our simulations or in

00:03:23,610 --> 00:03:28,380
our observations this reveals the

00:03:26,250 --> 00:03:30,210
interesting science and it also allows

00:03:28,380 --> 00:03:31,680
science to be accessible we might have a

00:03:30,210 --> 00:03:34,320
data set that we want to share with the

00:03:31,680 --> 00:03:37,320
public and interactive data

00:03:34,320 --> 00:03:39,930
visualization allows the our science to

00:03:37,320 --> 00:03:42,750
be accessible to be non-scientists maybe

00:03:39,930 --> 00:03:45,240
to scientists that don't really like

00:03:42,750 --> 00:03:47,880
coding very much or find coding really

00:03:45,240 --> 00:03:51,300
intimidating and also the people who are

00:03:47,880 --> 00:03:53,520
new to the data set so these can be like

00:03:51,300 --> 00:03:55,290
I might pass my radiation simulation

00:03:53,520 --> 00:03:56,130
data to a friend and they don't really

00:03:55,290 --> 00:03:58,380
know it very well

00:03:56,130 --> 00:04:00,270
giving them an interactive tool to

00:03:58,380 --> 00:04:03,140
browse that data and visualize it

00:04:00,270 --> 00:04:06,000
interactively is very helpful to them

00:04:03,140 --> 00:04:08,100
and there's a lot of interactive tools

00:04:06,000 --> 00:04:10,050
that exist in the Python ecosystem we

00:04:08,100 --> 00:04:12,450
care about this this is our community

00:04:10,050 --> 00:04:13,980
right so I'm going to be specifically

00:04:12,450 --> 00:04:17,160
talking about interactive visualization

00:04:13,980 --> 00:04:19,500
with YT today YT has some interactive

00:04:17,160 --> 00:04:21,330
features already but I'm going to be

00:04:19,500 --> 00:04:23,760
talking about the niche area where

00:04:21,330 --> 00:04:26,380
you're going to be having data maybe on

00:04:23,760 --> 00:04:28,840
a remote server or something like that

00:04:26,380 --> 00:04:34,060
you want to browse it on your local

00:04:28,840 --> 00:04:35,290
machine so I'm gonna do like we were

00:04:34,060 --> 00:04:37,800
talking about the last one I'm gonna do

00:04:35,290 --> 00:04:41,740
a live demo so we'll see how this goes

00:04:37,800 --> 00:04:44,770
so we can so I especially want to talk

00:04:41,740 --> 00:04:48,790
about how amazing the jupiter widget

00:04:44,770 --> 00:04:50,710
ecosystem is i pi widgets has developed

00:04:48,790 --> 00:04:53,380
a whole suite of tools that you can use

00:04:50,710 --> 00:04:55,270
to interactively browse your data in a

00:04:53,380 --> 00:04:56,770
jupiter notebook i'm going to show you

00:04:55,270 --> 00:04:59,980
though that this can be limiting

00:04:56,770 --> 00:05:02,740
sometimes especially when you have

00:04:59,980 --> 00:05:04,510
larger datasets or if you have an image

00:05:02,740 --> 00:05:07,570
that's quite large or you're

00:05:04,510 --> 00:05:10,840
re-rendering things a lot so i'm going

00:05:07,570 --> 00:05:13,900
to import I'm using YT here is this also

00:05:10,840 --> 00:05:22,830
readable to everybody okay

00:05:13,900 --> 00:05:22,830
you want a bigger okay whoops sorry

00:05:27,490 --> 00:05:33,380
yeah I'm trying it I okay

00:05:31,970 --> 00:05:37,640
I'll talk through it I don't know why

00:05:33,380 --> 00:05:40,340
it's not going suing this time okay so

00:05:37,640 --> 00:05:44,480
I'm gonna interact this first execution

00:05:40,340 --> 00:05:47,120
is I'm loading my data set this is on my

00:05:44,480 --> 00:05:49,670
machine and I have I'm gonna be loading

00:05:47,120 --> 00:05:53,060
isolated galaxy which is a data set that

00:05:49,670 --> 00:05:54,740
you can download with the that's in the

00:05:53,060 --> 00:05:58,280
documentation of YT it's something

00:05:54,740 --> 00:06:03,290
that's used is to introduce beginners to

00:05:58,280 --> 00:06:04,990
YT so yes I want to download that oh

00:06:03,290 --> 00:06:12,590
great

00:06:04,990 --> 00:06:14,270
huh oh thank you that was me leaning on

00:06:12,590 --> 00:06:22,210
it oh I see what I did there

00:06:14,270 --> 00:06:25,400
thanks everybody there we go haha okay

00:06:22,210 --> 00:06:27,420
well good now everything's going super

00:06:25,400 --> 00:06:30,120
well

00:06:27,420 --> 00:06:31,860
so I've imported my data I get some

00:06:30,120 --> 00:06:34,380
information from whitey

00:06:31,860 --> 00:06:36,150
about my data set and now I'm gonna try

00:06:34,380 --> 00:06:41,130
and use Jupiter widgets out of the box

00:06:36,150 --> 00:06:44,670
with this data set so I'm creating I'm

00:06:41,130 --> 00:06:46,800
using a set of widgets to create I'm

00:06:44,670 --> 00:06:49,050
setting some traits first so trait let's

00:06:46,800 --> 00:06:53,760
are things that I can sync with Jupiter

00:06:49,050 --> 00:06:56,160
widgets and they you can use so if you

00:06:53,760 --> 00:06:57,690
have a trait you can sync it with one of

00:06:56,160 --> 00:06:59,700
the like slider widgets or something

00:06:57,690 --> 00:07:02,490
like that and it'll update so I'm going

00:06:59,700 --> 00:07:08,130
to setup a visualization using these

00:07:02,490 --> 00:07:10,440
trait lids and then I have an image I

00:07:08,130 --> 00:07:18,900
pie with just women image that I'm going

00:07:10,440 --> 00:07:20,520
to deposit my data into okay so the

00:07:18,900 --> 00:07:22,800
first render doesn't quite work but if i

00:07:20,520 --> 00:07:26,160
zoom slightly the first thing here is

00:07:22,800 --> 00:07:28,890
supposed to be zoom and then the next

00:07:26,160 --> 00:07:30,900
two widgets are x and y so we can see

00:07:28,890 --> 00:07:33,960
it's a very isolated galaxy there's

00:07:30,900 --> 00:07:37,170
nothing around in and if I start zooming

00:07:33,960 --> 00:07:39,090
and moving around what this is going to

00:07:37,170 --> 00:07:40,800
do is this is in it I'm going to have to

00:07:39,090 --> 00:07:44,670
update the image and I'm gonna have to

00:07:40,800 --> 00:07:50,670
re pixelize it to update the view if i

00:07:44,670 --> 00:07:55,350
zoom out and if I do this I'm gonna let

00:07:50,670 --> 00:07:56,940
go now and it's gonna keep moving and my

00:07:55,350 --> 00:07:59,120
T's printing some error messages which

00:07:56,940 --> 00:08:02,430
is why now we have this extra box

00:07:59,120 --> 00:08:04,470
so if I go down I can see that I've

00:08:02,430 --> 00:08:05,610
recreated this fixed resolution buffer

00:08:04,470 --> 00:08:08,160
this is part of YT

00:08:05,610 --> 00:08:10,380
and basically the fixed resolution

00:08:08,160 --> 00:08:15,660
buffer will take a slice and it'll

00:08:10,380 --> 00:08:18,990
create in an array that is fixed so if I

00:08:15,660 --> 00:08:21,030
have like a data set that has a mesh

00:08:18,990 --> 00:08:23,610
that's variable it's gonna make it so

00:08:21,030 --> 00:08:25,380
it's all equal so if I want 500 by 500

00:08:23,610 --> 00:08:28,020
pixels it's going to give me the array

00:08:25,380 --> 00:08:30,600
in that fixed resolution so I have to

00:08:28,020 --> 00:08:32,280
re-up date it every time with that new

00:08:30,600 --> 00:08:34,170
fixed resolution even though I have a

00:08:32,280 --> 00:08:37,349
slice that I had already taken out and

00:08:34,170 --> 00:08:39,710
I've done this lots of times so you can

00:08:37,349 --> 00:08:42,320
imagine as you are

00:08:39,710 --> 00:08:44,930
as you peruse your data set you're gonna

00:08:42,320 --> 00:08:47,120
be regenerating images lots and lots of

00:08:44,930 --> 00:08:49,310
times so if you have a really large data

00:08:47,120 --> 00:08:51,650
set on a machine or even on your

00:08:49,310 --> 00:09:04,430
computer this can take this can be very

00:08:51,650 --> 00:09:06,680
slow okay so I mentioned that this can

00:09:04,430 --> 00:09:09,350
be very slow what's really happening

00:09:06,680 --> 00:09:12,410
when we start rendering images on our in

00:09:09,350 --> 00:09:14,930
a browser but from on our local machine

00:09:12,410 --> 00:09:17,210
or even on a remote server we send a

00:09:14,930 --> 00:09:20,570
request from the browser to the machine

00:09:17,210 --> 00:09:22,460
and then that's gonna like serialize the

00:09:20,570 --> 00:09:24,110
data it's going to calculate the image

00:09:22,460 --> 00:09:26,210
and then it's going to send it back and

00:09:24,110 --> 00:09:28,460
we're gonna pull that image down from

00:09:26,210 --> 00:09:31,360
this remote server onto our machine and

00:09:28,460 --> 00:09:35,000
then we have a visualization super cool

00:09:31,360 --> 00:09:36,320
but as I said before you can get you

00:09:35,000 --> 00:09:39,230
know you can do this lots and lots of

00:09:36,320 --> 00:09:41,720
times so when might this become

00:09:39,230 --> 00:09:43,700
cumbersome we have the total time to

00:09:41,720 --> 00:09:45,260
generate a single image on the server

00:09:43,700 --> 00:09:47,120
and I've kind of selected a couple of

00:09:45,260 --> 00:09:48,680
different things that I think might

00:09:47,120 --> 00:09:51,560
spend time that you might spend time

00:09:48,680 --> 00:09:55,310
doing that you have the signal like the

00:09:51,560 --> 00:09:57,800
request signal to request this image the

00:09:55,310 --> 00:09:59,720
time to serialize the data the time to

00:09:57,800 --> 00:10:02,090
calculate the image on the server the

00:09:59,720 --> 00:10:04,310
time to pull it back down onto your into

00:10:02,090 --> 00:10:07,520
your browser and then the time to

00:10:04,310 --> 00:10:11,270
display the image but when you're doing

00:10:07,520 --> 00:10:13,850
it with this this process you have to do

00:10:11,270 --> 00:10:16,270
this n times and all of these times are

00:10:13,850 --> 00:10:18,290
good at all of these specific time

00:10:16,270 --> 00:10:21,710
variables are going to be multiplied by

00:10:18,290 --> 00:10:24,590
n interactions so if i zoom I might have

00:10:21,710 --> 00:10:26,630
like 20 images that are created in a

00:10:24,590 --> 00:10:29,690
zoom action if I want that animation

00:10:26,630 --> 00:10:32,030
with these data sets so what if instead

00:10:29,690 --> 00:10:33,650
of sending the image back from the

00:10:32,030 --> 00:10:35,480
server we send the request and we get a

00:10:33,650 --> 00:10:37,430
chunk of the data a chunk of the data

00:10:35,480 --> 00:10:39,230
that interests us and then we do the

00:10:37,430 --> 00:10:41,510
calculation and the display of the image

00:10:39,230 --> 00:10:43,550
in the browser so we pull some of the

00:10:41,510 --> 00:10:48,200
data into the browser rather than the

00:10:43,550 --> 00:10:51,560
image itself pushing data to the client

00:10:48,200 --> 00:10:53,329
makes sense as is if we can make the

00:10:51,560 --> 00:10:56,209
time to calculate the image

00:10:53,329 --> 00:10:58,819
the client-side smaller than the time to

00:10:56,209 --> 00:11:00,980
calculate it on the server side so I've

00:10:58,819 --> 00:11:03,279
kind of condensed those teeth

00:11:00,980 --> 00:11:06,679
those small T's in the previous slide

00:11:03,279 --> 00:11:09,860
into two kind of big chunks that I think

00:11:06,679 --> 00:11:13,100
are interesting so there's the number of

00:11:09,860 --> 00:11:14,600
interactions we have times the time T

00:11:13,100 --> 00:11:16,369
client is the time to calculate the

00:11:14,600 --> 00:11:19,069
image on the client side so in the

00:11:16,369 --> 00:11:21,709
browser and then we're going to add this

00:11:19,069 --> 00:11:23,569
with the time the data like how large

00:11:21,709 --> 00:11:27,139
the chunk of the data we're sending from

00:11:23,569 --> 00:11:28,999
the server divided by whatever our speed

00:11:27,139 --> 00:11:31,429
is so if we have an extremely fast

00:11:28,999 --> 00:11:35,420
internet connection this is going to be

00:11:31,429 --> 00:11:39,350
a very small component but we want that

00:11:35,420 --> 00:11:41,299
in particular to be less than this so

00:11:39,350 --> 00:11:44,449
the time to generate the image on the

00:11:41,299 --> 00:11:47,629
server plus the time to generate the to

00:11:44,449 --> 00:11:50,600
generate to the time that it's going to

00:11:47,629 --> 00:11:52,129
take to transfer it so the data divided

00:11:50,600 --> 00:11:53,959
by the rate to transfer it back and

00:11:52,129 --> 00:11:56,899
forth and you can see that we've taken

00:11:53,959 --> 00:11:59,389
this n and the number of interactions is

00:11:56,899 --> 00:12:03,739
only times the time to generate the

00:11:59,389 --> 00:12:07,100
image on the client on the left side so

00:12:03,739 --> 00:12:08,600
I've kind of talked through those so how

00:12:07,100 --> 00:12:11,149
might this happened what are the big

00:12:08,600 --> 00:12:13,639
features that we think we can make that

00:12:11,149 --> 00:12:16,339
happen first of all I kind of mentioned

00:12:13,639 --> 00:12:17,749
the more interactions you do the more

00:12:16,339 --> 00:12:19,399
time you're going to be generating

00:12:17,749 --> 00:12:21,589
you're going to be wasting transferring

00:12:19,399 --> 00:12:23,449
images from your server up onto your

00:12:21,589 --> 00:12:26,419
local machine or down onto your local

00:12:23,449 --> 00:12:27,860
machine also as you increase the size of

00:12:26,419 --> 00:12:30,499
the image this is going to get more and

00:12:27,860 --> 00:12:32,299
more cumbersome right because this this

00:12:30,499 --> 00:12:36,559
term over here is going to get much

00:12:32,299 --> 00:12:38,299
larger and also if we can decrease the

00:12:36,559 --> 00:12:40,399
time to calculate the image on the

00:12:38,299 --> 00:12:45,169
client side that's going to make this a

00:12:40,399 --> 00:12:46,699
more beneficial transfer so this is just

00:12:45,169 --> 00:12:48,919
an illustration kind of giving you an

00:12:46,699 --> 00:12:51,529
idea if you have a data set that has

00:12:48,919 --> 00:12:53,839
this multi-resolution data we can

00:12:51,529 --> 00:12:57,049
overlay what the grid looks like and you

00:12:53,839 --> 00:12:59,689
can see towards the edge of the data we

00:12:57,049 --> 00:13:01,339
have a pretty sparse set of data but in

00:12:59,689 --> 00:13:03,699
there there's some interesting regions

00:13:01,339 --> 00:13:05,769
where our mesh is much much finer

00:13:03,699 --> 00:13:07,509
now if we're going to be exploring this

00:13:05,769 --> 00:13:09,579
data set using a traditional method

00:13:07,509 --> 00:13:12,910
where you transfer the image every time

00:13:09,579 --> 00:13:15,369
you update and if you want like a 10 by

00:13:12,910 --> 00:13:17,559
10 pixel image that's not going to be a

00:13:15,369 --> 00:13:19,119
big deal but as in you increase the

00:13:17,559 --> 00:13:20,649
pixel resolution you're actually

00:13:19,119 --> 00:13:22,449
becoming very inefficient because you

00:13:20,649 --> 00:13:24,189
have all this sparse data and you're

00:13:22,449 --> 00:13:26,019
sending hundreds and hundreds of pixels

00:13:24,189 --> 00:13:31,059
that are exactly the same value in these

00:13:26,019 --> 00:13:36,939
outer regions so we created a widget

00:13:31,059 --> 00:13:42,009
that does this let's see if I can push

00:13:36,939 --> 00:13:45,639
Plus in the right place this time so

00:13:42,009 --> 00:13:47,949
this is the same data set and we have

00:13:45,639 --> 00:13:50,139
some controls here they go away but this

00:13:47,949 --> 00:13:55,720
is actually a fairly large image I have

00:13:50,139 --> 00:13:58,269
chosen at 1000 by 1000 pixel image and

00:13:55,720 --> 00:13:59,980
I'm using a PI widgets layout to shrink

00:13:58,269 --> 00:14:03,850
it down so it's not stretched weirdly

00:13:59,980 --> 00:14:08,529
during this during this interaction so I

00:14:03,850 --> 00:14:10,359
can change the color scale to live I can

00:14:08,529 --> 00:14:18,160
also change the color map to whatever I

00:14:10,359 --> 00:14:21,189
want it to be and then I also can click

00:14:18,160 --> 00:14:23,139
in the image and it updates way faster

00:14:21,189 --> 00:14:28,289
than if I was using traditional widgets

00:14:23,139 --> 00:14:31,389
I also can drag in it's gonna and

00:14:28,289 --> 00:14:33,249
that'll update immediately whereas if I

00:14:31,389 --> 00:14:35,619
did a drag event like this if I built

00:14:33,249 --> 00:14:37,089
this in purely on the Python side with

00:14:35,619 --> 00:14:39,399
the widget it would be much much slower

00:14:37,089 --> 00:14:41,619
because this is very significant

00:14:39,399 --> 00:14:43,720
transferring this 1000 by that 1000

00:14:41,619 --> 00:14:52,660
pixel array back and forth into the

00:14:43,720 --> 00:14:54,579
browser so what does this mean like we

00:14:52,660 --> 00:14:57,639
built this widget it's cool it seems

00:14:54,579 --> 00:15:00,100
kind of neat maybe not cool as an

00:14:57,639 --> 00:15:03,519
awesome cat plot but you know that's

00:15:00,100 --> 00:15:05,049
pretty cool but with a single fixed

00:15:03,519 --> 00:15:07,149
upfront cost we eliminate the

00:15:05,049 --> 00:15:08,850
requirement to transfer all of those

00:15:07,149 --> 00:15:11,679
images between the server and the client

00:15:08,850 --> 00:15:14,289
this is useful in some cases but not all

00:15:11,679 --> 00:15:15,770
so you know if you have a data set

00:15:14,289 --> 00:15:18,200
that's really dense

00:15:15,770 --> 00:15:21,800
and you have an extremely fast internet

00:15:18,200 --> 00:15:24,140
connection then maybe it's not going to

00:15:21,800 --> 00:15:26,060
be useful to use this but this is useful

00:15:24,140 --> 00:15:27,800
for a lot of different cases so I'm

00:15:26,060 --> 00:15:29,420
gonna kind of talk through what is

00:15:27,800 --> 00:15:31,030
happening and that and a little bit I'm

00:15:29,420 --> 00:15:34,310
going to tell you more about webassembly

00:15:31,030 --> 00:15:36,320
but so I'm going to tell you how the

00:15:34,310 --> 00:15:38,480
first render kind of works so we have

00:15:36,320 --> 00:15:41,120
our data from YT we send a couple of

00:15:38,480 --> 00:15:43,870
different arrays px and py are the

00:15:41,120 --> 00:15:46,280
center points of each of those mesh

00:15:43,870 --> 00:15:49,280
cells that you saw so you can see it's

00:15:46,280 --> 00:15:51,980
variable and P DX and P dy are the half

00:15:49,280 --> 00:15:54,230
width values of each of those mesh cells

00:15:51,980 --> 00:15:55,730
and then value could be any field that

00:15:54,230 --> 00:15:56,750
you're interested in it could be density

00:15:55,730 --> 00:15:58,730
it could be temperature or something

00:15:56,750 --> 00:16:00,560
like that and I have a little key down

00:15:58,730 --> 00:16:02,600
here so the yellow is going to be a

00:16:00,560 --> 00:16:05,690
function that we built in web assembly

00:16:02,600 --> 00:16:07,280
this is custom and then trait lips are

00:16:05,690 --> 00:16:09,020
things that we can like you saw before

00:16:07,280 --> 00:16:10,220
these are things that we can sync and

00:16:09,020 --> 00:16:12,590
these are on the Python side these are

00:16:10,220 --> 00:16:14,990
accessible to any user so you could you

00:16:12,590 --> 00:16:18,650
could modify these as you wanted to and

00:16:14,990 --> 00:16:20,990
then so we're going to pass this in to

00:16:18,650 --> 00:16:23,420
our widget it's called YT pi canvas and

00:16:20,990 --> 00:16:24,770
all of the threads are going to go into

00:16:23,420 --> 00:16:27,770
a widget called the fixed resolution

00:16:24,770 --> 00:16:30,200
buffer viewer this has two custom web

00:16:27,770 --> 00:16:32,270
assembly modules there's a variable mesh

00:16:30,200 --> 00:16:34,850
which is the data structure we store all

00:16:32,270 --> 00:16:36,590
of the data in and then there's a fixed

00:16:34,850 --> 00:16:38,510
resolution buffer which is like the view

00:16:36,590 --> 00:16:41,510
of the data that we're interested in so

00:16:38,510 --> 00:16:42,890
we pull that like little chunk out the

00:16:41,510 --> 00:16:45,140
variable mesh isn't going to change

00:16:42,890 --> 00:16:47,960
after we've uploaded the data we're

00:16:45,140 --> 00:16:49,700
going to pass it into a data array we're

00:16:47,960 --> 00:16:51,140
gonna this is going to make a data array

00:16:49,700 --> 00:16:54,740
and we're gonna pass it to our

00:16:51,140 --> 00:16:56,540
normalizer so we pass that array and we

00:16:54,740 --> 00:16:58,400
want to do another performance important

00:16:56,540 --> 00:17:00,470
function so we're gonna pass it into web

00:16:58,400 --> 00:17:01,910
assembly again and that's going to be

00:17:00,470 --> 00:17:03,920
color maps this is the name of the

00:17:01,910 --> 00:17:05,330
module but it's actually normalizing and

00:17:03,920 --> 00:17:07,070
it's creating an image or eight out of

00:17:05,330 --> 00:17:08,660
the data array so it's taking this

00:17:07,070 --> 00:17:10,160
single array that's all data points and

00:17:08,660 --> 00:17:13,040
it's going to make it into this RGB a

00:17:10,160 --> 00:17:14,390
image and then we're gonna pass that

00:17:13,040 --> 00:17:16,160
image array back into the fixed

00:17:14,390 --> 00:17:18,350
resolution buffer viewer which deposits

00:17:16,160 --> 00:17:22,970
it in a canvas and then renders the

00:17:18,350 --> 00:17:24,260
image if we change the color map I've

00:17:22,970 --> 00:17:26,530
now highlighted this in red

00:17:24,260 --> 00:17:29,000
nothing upstream of this needs to change

00:17:26,530 --> 00:17:32,090
so we don't actually have

00:17:29,000 --> 00:17:33,560
interact we don't have to interact at

00:17:32,090 --> 00:17:34,790
all with the variable mesh or the fixed

00:17:33,560 --> 00:17:37,400
resolution buffer because we didn't

00:17:34,790 --> 00:17:39,350
change where the view was so what this

00:17:37,400 --> 00:17:41,150
is going to do is going to send the data

00:17:39,350 --> 00:17:43,070
array back through the color Maps web

00:17:41,150 --> 00:17:47,330
assembly function it's going to change

00:17:43,070 --> 00:17:48,770
the imagery and the rendered image if we

00:17:47,330 --> 00:17:50,270
do a canvas interaction though we're

00:17:48,770 --> 00:17:54,470
going to be moving the fixed resolution

00:17:50,270 --> 00:17:57,020
buffer around in the variable mesh so

00:17:54,470 --> 00:18:00,500
the view width this is if we change the

00:17:57,020 --> 00:18:02,270
if we zoom in then that's gonna change

00:18:00,500 --> 00:18:04,580
where the fixed resolution buffer is

00:18:02,270 --> 00:18:07,220
that's going to consequently change the

00:18:04,580 --> 00:18:11,630
data array the image array and then the

00:18:07,220 --> 00:18:12,890
rendered image so I said I'm saying I

00:18:11,630 --> 00:18:14,450
just mentioned that we did this stuff

00:18:12,890 --> 00:18:16,550
and web assembly but I didn't really say

00:18:14,450 --> 00:18:19,630
what webassembly was so web assembly is

00:18:16,550 --> 00:18:22,070
what a lot of the web is built on it's

00:18:19,630 --> 00:18:24,140
it's a language that's supposed to work

00:18:22,070 --> 00:18:26,450
seamlessly with JavaScript but it's the

00:18:24,140 --> 00:18:30,110
performance important parts of the web

00:18:26,450 --> 00:18:32,780
so instead of using javascript and

00:18:30,110 --> 00:18:34,700
serializing to json all of our data we

00:18:32,780 --> 00:18:37,310
can put it directly in web assembly if

00:18:34,700 --> 00:18:39,860
we build custom web assembly modules but

00:18:37,310 --> 00:18:41,420
because web assembly was designed with

00:18:39,860 --> 00:18:42,950
interacting with javascript in mind

00:18:41,420 --> 00:18:45,650
these two can seamlessly interact

00:18:42,950 --> 00:18:47,180
together we also have a sandbox memory

00:18:45,650 --> 00:18:48,620
environment so all of our calculations

00:18:47,180 --> 00:18:50,630
are gonna be done in the browser and

00:18:48,620 --> 00:18:53,060
it's not gonna happen anywhere else and

00:18:50,630 --> 00:18:55,850
this reduces that t client that I talked

00:18:53,060 --> 00:18:58,670
about in that equation earlier and why

00:18:55,850 --> 00:19:00,440
restau well so you can compile into web

00:18:58,670 --> 00:19:04,220
assembly from a lot of languages from C

00:19:00,440 --> 00:19:07,160
or C++ so I have never programmed before

00:19:04,220 --> 00:19:10,640
this in rust or JavaScript and rest was

00:19:07,160 --> 00:19:13,550
extremely approachable it was had a

00:19:10,640 --> 00:19:16,160
pretty low time to get up to speed it

00:19:13,550 --> 00:19:19,580
was super fun I didn't expect that I

00:19:16,160 --> 00:19:22,310
don't know and it's it's performant it's

00:19:19,580 --> 00:19:26,630
designed with compiling to web assembly

00:19:22,310 --> 00:19:28,040
in mind so to do this to create our

00:19:26,630 --> 00:19:31,490
functions in web assembly we can

00:19:28,040 --> 00:19:33,290
annotate our this is in rust so we can

00:19:31,490 --> 00:19:35,390
annotate our functions with this wasum

00:19:33,290 --> 00:19:37,280
bind gen and this is saying we want to

00:19:35,390 --> 00:19:40,610
make these functions available to

00:19:37,280 --> 00:19:42,460
JavaScript from web assembly then when

00:19:40,610 --> 00:19:44,680
we compile that we get an autumn

00:19:42,460 --> 00:19:46,360
we created JavaScript a file and this is

00:19:44,680 --> 00:19:48,340
kind of what that structure data

00:19:46,360 --> 00:19:52,810
structure is going to look like when

00:19:48,340 --> 00:19:54,490
exposed from JavaScript another package

00:19:52,810 --> 00:19:56,950
that we found very useful is wasum pack

00:19:54,490 --> 00:20:00,160
so this actually compiles all your rest

00:19:56,950 --> 00:20:03,100
code into web assembly and then packages

00:20:00,160 --> 00:20:06,610
up in a package that you can put on NPM

00:20:03,100 --> 00:20:08,860
so this super easy you just upload it

00:20:06,610 --> 00:20:11,350
and so none of your users really have to

00:20:08,860 --> 00:20:13,030
deal with compiling to web assembly from

00:20:11,350 --> 00:20:14,830
rust or anything like that they just get

00:20:13,030 --> 00:20:16,870
to download the NPM package that's

00:20:14,830 --> 00:20:19,840
associated with it and this is actually

00:20:16,870 --> 00:20:22,180
me compiling our project on my machine

00:20:19,840 --> 00:20:27,580
and there's some cute emojis that are

00:20:22,180 --> 00:20:29,500
also included which is pretty cool so I

00:20:27,580 --> 00:20:32,610
have a demo of a larger data set I just

00:20:29,500 --> 00:20:37,090
showed you like a sample data set from

00:20:32,610 --> 00:20:40,530
YT so we have a couple of different

00:20:37,090 --> 00:20:44,050
things here this in particular is from a

00:20:40,530 --> 00:20:46,330
simulation of a population to star which

00:20:44,050 --> 00:20:48,990
is like the second generation of stars

00:20:46,330 --> 00:20:55,540
that's formed after the really light

00:20:48,990 --> 00:20:57,490
hydrogen helium based stars and I'm

00:20:55,540 --> 00:20:58,900
loading this in the original data set so

00:20:57,490 --> 00:21:01,090
I mentioned that we're taking chunks of

00:20:58,900 --> 00:21:03,580
data the original data set is several

00:21:01,090 --> 00:21:06,850
hundred gigabytes of data we pulled a

00:21:03,580 --> 00:21:11,620
slice down for this particular chunk so

00:21:06,850 --> 00:21:15,100
if I do that log I can see this data set

00:21:11,620 --> 00:21:21,120
I can also change the limits so it might

00:21:15,100 --> 00:21:21,120
be a little easier for you to see maybe

00:21:21,630 --> 00:21:28,270
and I can do the same thing just before

00:21:25,650 --> 00:21:30,310
so the slice is quite a bit smaller than

00:21:28,270 --> 00:21:32,170
the original data set but this is

00:21:30,310 --> 00:21:34,870
because we made this into a widget we

00:21:32,170 --> 00:21:37,570
can also leverage all the functionality

00:21:34,870 --> 00:21:42,090
of the wedges so we can link for example

00:21:37,570 --> 00:21:44,680
another field I've plotted density here

00:21:42,090 --> 00:21:46,360
but I can link it there's another field

00:21:44,680 --> 00:21:50,770
in this particular simulation of

00:21:46,360 --> 00:21:54,370
temperature of this star forming so I'm

00:21:50,770 --> 00:21:55,900
gonna first create a slider that allows

00:21:54,370 --> 00:21:58,750
me to see things

00:21:55,900 --> 00:22:02,740
in log scale because I know this data

00:21:58,750 --> 00:22:04,240
set is very sparse and then so I want to

00:22:02,740 --> 00:22:09,160
zoom in really far and then I'm going to

00:22:04,240 --> 00:22:11,710
create a temperature a temperature one

00:22:09,160 --> 00:22:13,810
as well so let's see what happens okay

00:22:11,710 --> 00:22:15,610
so let's say I decide okay I really hate

00:22:13,810 --> 00:22:18,550
this color map on the other side

00:22:15,610 --> 00:22:20,950
I've now linked the fields on both sides

00:22:18,550 --> 00:22:22,930
so I can do a log and we can see both of

00:22:20,950 --> 00:22:25,180
them and this looks pretty cool these

00:22:22,930 --> 00:22:28,030
are really different but I can change

00:22:25,180 --> 00:22:32,430
the color map just using the trait 'lets

00:22:28,030 --> 00:22:35,140
and then I can move these around as well

00:22:32,430 --> 00:22:42,310
and I can click to a new center that

00:22:35,140 --> 00:22:44,740
might interest me and do that I also can

00:22:42,310 --> 00:22:46,990
use a projection so YT has tons and tons

00:22:44,740 --> 00:22:48,430
of really interesting ways that you can

00:22:46,990 --> 00:22:50,560
explore your data that haven't been

00:22:48,430 --> 00:22:52,270
accessible and this interactive this

00:22:50,560 --> 00:22:54,040
directive and interactive way so this is

00:22:52,270 --> 00:22:57,490
doing everything I just did in one giant

00:22:54,040 --> 00:23:06,280
cell so I'm sorry it's like very much a

00:22:57,490 --> 00:23:08,260
wall of text and it's going to take a

00:23:06,280 --> 00:23:09,850
little bit because the I'm doing a

00:23:08,260 --> 00:23:11,950
projection instead of a slice which

00:23:09,850 --> 00:23:13,720
actually collapses all of the data and

00:23:11,950 --> 00:23:15,460
brings out features from all the

00:23:13,720 --> 00:23:18,130
dimensions I'm sure I've been showing XY

00:23:15,460 --> 00:23:19,930
slices so far but this is including this

00:23:18,130 --> 00:23:27,700
is trying to pull out some of the Z

00:23:19,930 --> 00:23:29,200
dimensional data ok so I have this and

00:23:27,700 --> 00:23:30,820
these are pretty interesting so let's

00:23:29,200 --> 00:23:34,770
say I think this is a pretty interesting

00:23:30,820 --> 00:23:34,770
part I can start zooming

00:23:39,240 --> 00:23:44,640
and this goes way faster than if I was

00:23:41,429 --> 00:23:46,500
doing this with anything else with if I

00:23:44,640 --> 00:23:48,210
was doing this with straight Python I

00:23:46,500 --> 00:23:49,970
wouldn't be able to do this and I

00:23:48,210 --> 00:24:04,700
wouldn't be able to interact this easily

00:23:49,970 --> 00:24:04,700
with my dataset oops sorry

00:24:07,010 --> 00:24:12,360
so we do have some limitations of this

00:24:09,540 --> 00:24:13,860
widget it requires a 2d data slice you

00:24:12,360 --> 00:24:16,230
just saw that I kind of talked a little

00:24:13,860 --> 00:24:18,720
bit about it so we can't fully interact

00:24:16,230 --> 00:24:21,120
in 3d yet and that's not a trivial

00:24:18,720 --> 00:24:24,210
change so that's something that we're

00:24:21,120 --> 00:24:26,010
hoping to do in the future there's also

00:24:24,210 --> 00:24:28,320
potential to limitation for data sizes

00:24:26,010 --> 00:24:30,030
I've shown this I've shown like some

00:24:28,320 --> 00:24:32,940
pretty large data sets and we haven't

00:24:30,030 --> 00:24:35,310
like reached a limit but it exists and

00:24:32,940 --> 00:24:38,370
we have limited functionality this is

00:24:35,310 --> 00:24:40,290
nowhere near like the ability of a lot

00:24:38,370 --> 00:24:42,120
of other interactive tools but this is

00:24:40,290 --> 00:24:45,680
the first that has web assembly that we

00:24:42,120 --> 00:24:48,330
know emotion and it requires multiple

00:24:45,680 --> 00:24:50,370
multiple packages and package ecosystems

00:24:48,330 --> 00:24:52,140
this is non-trivial and can be kind of

00:24:50,370 --> 00:24:56,070
rough sometimes and it's still really

00:24:52,140 --> 00:24:57,750
early in development moving forward we

00:24:56,070 --> 00:24:59,400
want to broaden the functionality we

00:24:57,750 --> 00:25:02,070
want to make it so it's even more

00:24:59,400 --> 00:25:04,620
intuitive for users to use I'm going to

00:25:02,070 --> 00:25:06,210
build out functionality with ytyt has

00:25:04,620 --> 00:25:08,130
all this cool these cool features that

00:25:06,210 --> 00:25:09,420
we're not exposing yet and we want a

00:25:08,130 --> 00:25:12,420
restructure of the widget to enhance

00:25:09,420 --> 00:25:14,130
performance even more there's some links

00:25:12,420 --> 00:25:15,390
I'm going to tweet this the slides of

00:25:14,130 --> 00:25:17,790
this talk so if you're really interested

00:25:15,390 --> 00:25:18,990
afterwards you can go these all link to

00:25:17,790 --> 00:25:22,470
everything you're interested in and I

00:25:18,990 --> 00:25:24,900
want to give Lois uber shout out he gave

00:25:22,470 --> 00:25:27,990
a poster on build restructuring some of

00:25:24,900 --> 00:25:30,900
your backends from C to rest also here

00:25:27,990 --> 00:25:32,910
at Syfy and we you can install this very

00:25:30,900 --> 00:25:35,640
easy we have as of this morning we have

00:25:32,910 --> 00:25:38,100
this widget on pipe I and you don't have

00:25:35,640 --> 00:25:39,780
to compile to rest and I'd like to thank

00:25:38,100 --> 00:25:41,400
the following individuals Matt Turk

00:25:39,780 --> 00:25:43,250
really helped me with this nathaniel

00:25:41,400 --> 00:25:46,440
klaussen did a lot of the early

00:25:43,250 --> 00:25:48,630
feasibility studies of this work Nathan

00:25:46,440 --> 00:25:50,490
Goldman and Castro Cavalli helped me

00:25:48,630 --> 00:25:51,600
debug a lot of things I'm just gonna let

00:25:50,490 --> 00:25:57,690
you know that debugging in three

00:25:51,600 --> 00:25:59,910
languages sucks also Britton Smith he

00:25:57,690 --> 00:26:03,300
did that he supplied the data for these

00:25:59,910 --> 00:26:05,940
larger Simula the pop to dataset and

00:26:03,300 --> 00:26:07,670
Katie Hoff who is my great friend and

00:26:05,940 --> 00:26:11,630
listened to the practice talk for this

00:26:07,670 --> 00:26:11,630
and I'd be happy to take any questions

00:26:24,530 --> 00:26:30,390
yeah thank you very much great talk

00:26:27,480 --> 00:26:33,690
thank you yeah you talk you talk a lot

00:26:30,390 --> 00:26:38,190
about the application side of it the

00:26:33,690 --> 00:26:40,860
programming or but as a user support or

00:26:38,190 --> 00:26:45,990
a consultant my worry is usually about

00:26:40,860 --> 00:26:49,770
the network the memory so how much does

00:26:45,990 --> 00:26:52,140
the memory count in serving as a

00:26:49,770 --> 00:26:56,220
bottleneck if you if you are computing

00:26:52,140 --> 00:27:01,080
from the HPC from the server versus the

00:26:56,220 --> 00:27:03,150
client and how much memory do you need

00:27:01,080 --> 00:27:04,890
because all the manipulations you were

00:27:03,150 --> 00:27:07,200
doing and that you are doing with a

00:27:04,890 --> 00:27:11,190
widget how much memory do you need and

00:27:07,200 --> 00:27:15,180
at what point do you have some sort of

00:27:11,190 --> 00:27:16,800
bottleneck yeah so I have not done a

00:27:15,180 --> 00:27:19,230
full benchmark of when we reach a

00:27:16,800 --> 00:27:20,910
bottleneck we know it exists but I don't

00:27:19,230 --> 00:27:24,210
have something off the top of my head

00:27:20,910 --> 00:27:26,550
for that I will say that this like very

00:27:24,210 --> 00:27:28,410
large data set is a pretty good example

00:27:26,550 --> 00:27:30,420
of the types of data sets that people

00:27:28,410 --> 00:27:34,140
would be interested in so we're pulling

00:27:30,420 --> 00:27:35,910
that slice down that slice we saw the

00:27:34,140 --> 00:27:37,770
projection was like several hundred

00:27:35,910 --> 00:27:39,810
megabytes and that was directly in the

00:27:37,770 --> 00:27:42,540
browser but I didn't I didn't pull like

00:27:39,810 --> 00:27:46,220
a full 3d data set into the browser so I

00:27:42,540 --> 00:27:46,220
don't know exactly what the limit is yet

00:27:47,540 --> 00:27:51,680
and maybe one more question

00:27:54,750 --> 00:28:00,310
thank you for the nice talk thank you

00:27:57,720 --> 00:28:02,140
question about transferring the data

00:28:00,310 --> 00:28:04,690
between mmm

00:28:02,140 --> 00:28:07,380
javascript and the web assembly mm-hmm

00:28:04,690 --> 00:28:09,100
and doing it for scientific data and

00:28:07,380 --> 00:28:11,650
scientific data types

00:28:09,100 --> 00:28:13,720
big arrays you have any thoughts or

00:28:11,650 --> 00:28:16,660
ideas on how to do that the best way to

00:28:13,720 --> 00:28:18,370
do that going for so actually because

00:28:16,660 --> 00:28:20,530
rest and web assembly are dozens are

00:28:18,370 --> 00:28:22,300
what web assembly and JavaScript are

00:28:20,530 --> 00:28:25,030
designed to work together we're actually

00:28:22,300 --> 00:28:28,300
just passing the pointer of the web

00:28:25,030 --> 00:28:30,280
assembly data through JavaScript we have

00:28:28,300 --> 00:28:33,580
like we're using clamped arrays we don't

00:28:30,280 --> 00:28:35,260
have the like serialization to JSON so

00:28:33,580 --> 00:28:37,810
it's actually like very friendly to

00:28:35,260 --> 00:28:40,360
transfer the data between JavaScript and

00:28:37,810 --> 00:28:41,950
web assembly the hard part is getting it

00:28:40,360 --> 00:28:44,190
down into the web assembly in the first

00:28:41,950 --> 00:28:44,190
place

00:28:46,050 --> 00:28:50,070
did that answer your question okay

00:28:51,870 --> 00:28:55,930
I'll be up the Sprint's tomorrow also if

00:28:54,370 --> 00:28:57,130
any of you have any questions or like

00:28:55,930 --> 00:28:59,580
want to play around with this or

00:28:57,130 --> 00:28:59,580
something like that

00:29:01,200 --> 00:29:04,880

YouTube URL: https://www.youtube.com/watch?v=5dl_m_6T2bU


