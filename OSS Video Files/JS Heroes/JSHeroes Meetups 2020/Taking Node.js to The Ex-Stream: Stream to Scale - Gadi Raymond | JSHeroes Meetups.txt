Title: Taking Node.js to The Ex-Stream: Stream to Scale - Gadi Raymond | JSHeroes Meetups
Publication date: 2020-08-02
Playlist: JSHeroes Meetups 2020
Description: 
	In the past our lives were simple. Big data chunks were lists of thousands of entities.

Today data is more complex and in much bigger quantities.
The solution that worked for small data just doesn’t scale.
Suddenly your beautiful microservice starts having memory and availability issues.

It might seem that JS may not be your ideal solution. or is it?
In this talk, I’ll show you how microservice can break with big data.
More importantly, I’ll show you how you can work on big data with Node.js Streams while keeping your dream JS job.

About Gadi

Experienced software developer, in the past few years I’m working with Node.js.
An expert in the areas of microservices, architecture and design, big data, and high scale applications.

Twitter: https://twitter.com/gadiray
Captions: 
	00:00:04,080 --> 00:00:08,160
welcome to

00:00:04,960 --> 00:00:11,840
our uh our meetup uh about

00:00:08,160 --> 00:00:14,639
uh note streams gandhi

00:00:11,840 --> 00:00:17,920
gadi sorry sorry for how do you

00:00:14,639 --> 00:00:17,920
pronounce it

00:00:18,640 --> 00:00:22,640
um god is gonna be our presenters today

00:00:21,520 --> 00:00:26,000
and he is gonna

00:00:22,640 --> 00:00:29,199
show us the insights of note streams

00:00:26,000 --> 00:00:30,800
and as i said a little bit earlier i'm

00:00:29,199 --> 00:00:34,559
really excited that we have

00:00:30,800 --> 00:00:36,160
no talk and

00:00:34,559 --> 00:00:39,280
daddy do you want to say a few words

00:00:36,160 --> 00:00:39,280
about you before you start

00:00:39,360 --> 00:00:46,399
uh yeah i'm really excited to be here

00:00:43,200 --> 00:00:51,039
to have this talk in this meetup uh

00:00:46,399 --> 00:00:51,039
i'll represent myself in the talk okay

00:00:51,280 --> 00:00:56,000
so uh you can you can start when you

00:00:53,280 --> 00:00:56,000
when you're ready

00:00:56,879 --> 00:00:59,840
all right

00:01:01,120 --> 00:01:06,720
so uh so this is the

00:01:04,720 --> 00:01:09,439
taking o.js to the extreme my name is

00:01:06,720 --> 00:01:09,439
gary raymond

00:01:10,320 --> 00:01:15,680
let me minimize it all right so a little

00:01:14,320 --> 00:01:18,720
bit about myself

00:01:15,680 --> 00:01:20,960
and i'm from israel uh

00:01:18,720 --> 00:01:22,080
i'm married to hilar we have a son son

00:01:20,960 --> 00:01:23,759
named marie

00:01:22,080 --> 00:01:25,680
and a dog named angie as you can see in

00:01:23,759 --> 00:01:27,600
those pictures

00:01:25,680 --> 00:01:30,720
i'm a senior footstep developer at a

00:01:27,600 --> 00:01:32,159
company called walk me

00:01:30,720 --> 00:01:33,840
i love to speak and write about

00:01:32,159 --> 00:01:34,320
technology just like i'm doing here

00:01:33,840 --> 00:01:36,640
today

00:01:34,320 --> 00:01:37,759
and feel free to follow me on twitter

00:01:36,640 --> 00:01:40,479
it's gadiray

00:01:37,759 --> 00:01:41,360
where many tweet about javascript

00:01:40,479 --> 00:01:43,920
node.js

00:01:41,360 --> 00:01:44,479
and basically everything that exciting

00:01:43,920 --> 00:01:47,439
and new

00:01:44,479 --> 00:01:47,439
in development

00:01:48,399 --> 00:01:53,680
so what we're going to cover in the next

00:01:50,880 --> 00:01:55,600
30 plus minutes

00:01:53,680 --> 00:01:58,880
i will show you my big data challenge

00:01:55,600 --> 00:02:01,680
that i had in walk me

00:01:58,880 --> 00:02:05,840
and then i'm going to i'm going to do it

00:02:01,680 --> 00:02:05,840
quick introduction about node.js streams

00:02:05,920 --> 00:02:10,160
and then i'm going to show you how i was

00:02:07,680 --> 00:02:12,959
i was able to solve the chart that i had

00:02:10,160 --> 00:02:12,959
using streams

00:02:13,200 --> 00:02:19,680
then i'm going i'm going to go over some

00:02:16,640 --> 00:02:20,959
tips of using streams and then we're

00:02:19,680 --> 00:02:23,440
going to dive into

00:02:20,959 --> 00:02:25,520
some more advanced stuff like asking

00:02:23,440 --> 00:02:29,599
iterators and asking generators

00:02:25,520 --> 00:02:29,599
and how they are related to streams

00:02:30,160 --> 00:02:36,080
so let's start with a little story um

00:02:33,760 --> 00:02:37,120
so when i had the challenge in walkme

00:02:36,080 --> 00:02:38,800
and one of the

00:02:37,120 --> 00:02:40,640
solutions to the challenge was using

00:02:38,800 --> 00:02:44,239
streams i had to admit that

00:02:40,640 --> 00:02:47,920
i was a bit afraid of using streams and

00:02:44,239 --> 00:02:50,160
because streams has a bad reputation

00:02:47,920 --> 00:02:51,360
people are saying the streams are hard

00:02:50,160 --> 00:02:54,480
hard to learn

00:02:51,360 --> 00:02:56,400
how to how to work with streams and

00:02:54,480 --> 00:02:58,080
people are afraid of using streams in

00:02:56,400 --> 00:03:01,120
production

00:02:58,080 --> 00:03:03,440
and i think the main reason for it is

00:03:01,120 --> 00:03:05,840
that streams are available to node since

00:03:03,440 --> 00:03:07,760
the first version of node

00:03:05,840 --> 00:03:10,319
and back then the api wasn't really

00:03:07,760 --> 00:03:12,080
baked like it is today

00:03:10,319 --> 00:03:13,360
so i think people are still remembering

00:03:12,080 --> 00:03:17,040
it remembering

00:03:13,360 --> 00:03:18,080
it and even in the social media you can

00:03:17,040 --> 00:03:21,360
find tweets like

00:03:18,080 --> 00:03:25,120
this or follow for all of your

00:03:21,360 --> 00:03:28,959
uh react lovers this is donna brammer

00:03:25,120 --> 00:03:33,120
the creator of redux he's saying that

00:03:28,959 --> 00:03:35,200
he's afraid of streams right so

00:03:33,120 --> 00:03:36,640
when i started working with streams and

00:03:35,200 --> 00:03:39,599
reading about streams

00:03:36,640 --> 00:03:40,000
uh i saw that streams are not that hard

00:03:39,599 --> 00:03:44,480
and

00:03:40,000 --> 00:03:48,000
actually the api sense node 10

00:03:44,480 --> 00:03:50,400
is really nice and my goal in this talk

00:03:48,000 --> 00:03:51,280
that your neck your next tweet will be

00:03:50,400 --> 00:03:54,159
this

00:03:51,280 --> 00:03:54,159
to love streams

00:03:54,400 --> 00:03:58,560
so in order to explain it the challenge

00:03:57,760 --> 00:04:01,760
that i had

00:03:58,560 --> 00:04:06,000
i need to do some sort of overview of

00:04:01,760 --> 00:04:06,560
our architecture so in walkme we have a

00:04:06,000 --> 00:04:09,920
web

00:04:06,560 --> 00:04:11,040
web application that shows all sorts of

00:04:09,920 --> 00:04:14,159
data

00:04:11,040 --> 00:04:17,359
and analytics about our user usage

00:04:14,159 --> 00:04:20,479
of rockley and

00:04:17,359 --> 00:04:23,280
users can choose to export this data in

00:04:20,479 --> 00:04:26,720
a csv file to their email

00:04:23,280 --> 00:04:29,759
so when a user clicks on export

00:04:26,720 --> 00:04:31,600
we send a request and send it to a

00:04:29,759 --> 00:04:34,800
report's queue

00:04:31,600 --> 00:04:37,600
and those messages have a

00:04:34,800 --> 00:04:39,840
generated sql query that we are

00:04:37,600 --> 00:04:42,000
generating according to the user filters

00:04:39,840 --> 00:04:44,560
and preferences

00:04:42,000 --> 00:04:45,600
and where the consumers those consumers

00:04:44,560 --> 00:04:48,560
you can see they

00:04:45,600 --> 00:04:50,160
there is more than one consumers that

00:04:48,560 --> 00:04:53,520
subscribe to this queue

00:04:50,160 --> 00:04:56,880
and those consumers are node.js apps

00:04:53,520 --> 00:05:00,400
and their job is to take those messages

00:04:56,880 --> 00:05:03,440
take the sql query and carry out our db

00:05:00,400 --> 00:05:06,080
which is called athena atina is a

00:05:03,440 --> 00:05:09,440
managed service in aws

00:05:06,080 --> 00:05:12,639
it's basically wraps analytical

00:05:09,440 --> 00:05:16,160
called presto presto is developed

00:05:12,639 --> 00:05:19,039
by facebook and what athena does it

00:05:16,160 --> 00:05:22,560
takes the result sets of presto

00:05:19,039 --> 00:05:26,560
and save the the result sets to

00:05:22,560 --> 00:05:29,759
a csv file save it to s3

00:05:26,560 --> 00:05:33,199
and return the url of s3

00:05:29,759 --> 00:05:36,960
of s3 and then return it to

00:05:33,199 --> 00:05:38,080
our consumers so now our consumer can

00:05:36,960 --> 00:05:41,600
take this

00:05:38,080 --> 00:05:45,280
file and send an email to the

00:05:41,600 --> 00:05:47,440
user that asks to export the report

00:05:45,280 --> 00:05:48,479
so this is basically the feature that we

00:05:47,440 --> 00:05:51,840
had

00:05:48,479 --> 00:05:54,479
and everything worked well in production

00:05:51,840 --> 00:05:56,720
until we started to grow more and more

00:05:54,479 --> 00:05:58,400
started to have more and more users

00:05:56,720 --> 00:06:00,319
using this feature

00:05:58,400 --> 00:06:02,240
so we started to have more and more

00:06:00,319 --> 00:06:05,360
messages in this queue

00:06:02,240 --> 00:06:08,800
and we didn't have problem and

00:06:05,360 --> 00:06:12,400
scaling those consumers in order to

00:06:08,800 --> 00:06:14,639
cope with those messages but we started

00:06:12,400 --> 00:06:18,000
to have a bottleneck in this area

00:06:14,639 --> 00:06:20,479
in the athena area the reason for the

00:06:18,000 --> 00:06:22,560
bottleneck is because

00:06:20,479 --> 00:06:24,479
as i said that in as a managed service

00:06:22,560 --> 00:06:26,639
it has some limitations

00:06:24,479 --> 00:06:27,520
the first limitation is that it only

00:06:26,639 --> 00:06:31,680
supports

00:06:27,520 --> 00:06:34,880
five concurrent sql query queries

00:06:31,680 --> 00:06:37,840
and in in our case uh

00:06:34,880 --> 00:06:38,160
since it's analytical db the queries can

00:06:37,840 --> 00:06:40,800
take

00:06:38,160 --> 00:06:42,080
long it can take a few minutes in our

00:06:40,800 --> 00:06:45,120
worst case it can take

00:06:42,080 --> 00:06:47,840
even 30 minutes so

00:06:45,120 --> 00:06:49,680
we started to have the bottleneck here

00:06:47,840 --> 00:06:53,520
and another limitation of athena

00:06:49,680 --> 00:06:56,319
is that the compute power

00:06:53,520 --> 00:06:57,360
is fixed you can't change it and as i

00:06:56,319 --> 00:06:58,880
said we

00:06:57,360 --> 00:07:00,400
grew more and more started to have more

00:06:58,880 --> 00:07:02,400
and more data

00:07:00,400 --> 00:07:03,759
and we simply needed more compute power

00:07:02,400 --> 00:07:07,919
to handle the

00:07:03,759 --> 00:07:10,880
complex queries so in order to solve it

00:07:07,919 --> 00:07:13,280
we decided to manage a presto cluster on

00:07:10,880 --> 00:07:15,840
our own now

00:07:13,280 --> 00:07:18,000
so now we don't have the limitation of

00:07:15,840 --> 00:07:20,319
the five concurrent queries

00:07:18,000 --> 00:07:22,400
and we can just scale in and scale out

00:07:20,319 --> 00:07:25,440
nodes in the cluster

00:07:22,400 --> 00:07:29,280
and and we don't have uh the limitation

00:07:25,440 --> 00:07:32,080
of the compute part we can just increase

00:07:29,280 --> 00:07:33,840
the machine compute power if you if you

00:07:32,080 --> 00:07:37,039
want

00:07:33,840 --> 00:07:40,960
and so now the flow uh

00:07:37,039 --> 00:07:42,479
goes like this the consumers takes the

00:07:40,960 --> 00:07:44,800
same sql queries

00:07:42,479 --> 00:07:45,759
but now they're acquiring the press to

00:07:44,800 --> 00:07:48,160
db

00:07:45,759 --> 00:07:49,759
and the presto db returns the data as

00:07:48,160 --> 00:07:52,960
json

00:07:49,759 --> 00:07:54,319
so now the it's on the consumer's

00:07:52,960 --> 00:07:58,080
responsibility

00:07:54,319 --> 00:08:01,440
to transform the data from json

00:07:58,080 --> 00:08:05,120
to csv files save it in s3

00:08:01,440 --> 00:08:06,560
get back to url and send the email just

00:08:05,120 --> 00:08:09,759
like

00:08:06,560 --> 00:08:10,560
we used to do before and this is

00:08:09,759 --> 00:08:11,919
basically

00:08:10,560 --> 00:08:15,199
the challenge that we needed to

00:08:11,919 --> 00:08:16,560
implement and

00:08:15,199 --> 00:08:18,240
this is what i'm going to talk about

00:08:16,560 --> 00:08:22,160
here now

00:08:18,240 --> 00:08:24,840
so this is an a

00:08:22,160 --> 00:08:26,319
solution to it this is a in-memory

00:08:24,840 --> 00:08:29,919
solution and

00:08:26,319 --> 00:08:32,880
when when we get the sql query here

00:08:29,919 --> 00:08:34,159
we have a function called export events

00:08:32,880 --> 00:08:37,839
and gateway events

00:08:34,159 --> 00:08:41,680
will return those events from

00:08:37,839 --> 00:08:44,880
the from our db for pesto db as json

00:08:41,680 --> 00:08:47,920
as i said before and so we need to

00:08:44,880 --> 00:08:51,839
convert them from json to series b right

00:08:47,920 --> 00:08:53,279
so we have json to csv function here

00:08:51,839 --> 00:08:55,279
as you can see here this is a

00:08:53,279 --> 00:08:57,120
synchronous operation

00:08:55,279 --> 00:08:59,360
and it's really really not recommended

00:08:57,120 --> 00:09:02,480
to do those things in node.js

00:08:59,360 --> 00:09:05,279
because simply because it can like

00:09:02,480 --> 00:09:06,640
block your event loop and in case you

00:09:05,279 --> 00:09:11,519
block your event loop you can't

00:09:06,640 --> 00:09:13,760
really receive any request and

00:09:11,519 --> 00:09:15,360
and you really want to avoid those kind

00:09:13,760 --> 00:09:19,279
of things

00:09:15,360 --> 00:09:22,320
so once we get a csv

00:09:19,279 --> 00:09:24,160
format we can write this file in our

00:09:22,320 --> 00:09:27,839
case to s3

00:09:24,160 --> 00:09:31,519
write this csv file

00:09:27,839 --> 00:09:34,720
so let's see this code in action i will

00:09:31,519 --> 00:09:34,720
i will do a quick demo

00:09:34,800 --> 00:09:38,560
so this is the code that i show you

00:09:36,560 --> 00:09:40,959
showed you

00:09:38,560 --> 00:09:40,959
and

00:09:42,080 --> 00:09:47,279
wait a second so i'm not really calling

00:09:46,160 --> 00:09:49,760
here a db

00:09:47,279 --> 00:09:52,080
i will simulate the result sets from db

00:09:49,760 --> 00:09:54,560
by reading from a file

00:09:52,080 --> 00:09:56,160
so i'm calling this function the export

00:09:54,560 --> 00:09:59,920
event in memory

00:09:56,160 --> 00:10:03,440
and and this file

00:09:59,920 --> 00:10:07,120
is a small file.json it's at

00:10:03,440 --> 00:10:09,040
eight megabytes of json and after it

00:10:07,120 --> 00:10:10,560
i'll print the memory usage of this

00:10:09,040 --> 00:10:14,160
program

00:10:10,560 --> 00:10:14,160
so let me run it really quick

00:10:14,880 --> 00:10:21,760
and it took 83 megabytes

00:10:18,000 --> 00:10:24,320
of memory and this is quite a lot right

00:10:21,760 --> 00:10:24,560
because i told you that small file.json

00:10:24,320 --> 00:10:30,160
is

00:10:24,560 --> 00:10:33,360
8 megabytes so what will happen

00:10:30,160 --> 00:10:34,560
if i change i'll change it to big

00:10:33,360 --> 00:10:38,240
file.json

00:10:34,560 --> 00:10:41,760
which is 400 megabytes of json

00:10:38,240 --> 00:10:44,399
so it as you can see it takes time

00:10:41,760 --> 00:10:47,120
i'm using node 14 which is the latest

00:10:44,399 --> 00:10:48,480
version of node and in node 14 the

00:10:47,120 --> 00:10:52,079
default

00:10:48,480 --> 00:10:55,120
memory size is 2 gigabytes so let's

00:10:52,079 --> 00:10:55,600
wait a few seconds in order to process

00:10:55,120 --> 00:10:59,040
it

00:10:55,600 --> 00:11:02,000
and let's see what will happen

00:10:59,040 --> 00:11:02,800
all right we've got an error as you can

00:11:02,000 --> 00:11:06,959
see here

00:11:02,800 --> 00:11:10,399
uh v8 which is the engine of node.js

00:11:06,959 --> 00:11:14,000
and a very long stacked race

00:11:10,399 --> 00:11:16,959
and its fatal error says javascript hip

00:11:14,000 --> 00:11:18,399
out of memory so we exceeded that two

00:11:16,959 --> 00:11:22,079
gigabytes of memory

00:11:18,399 --> 00:11:25,440
in this case um

00:11:22,079 --> 00:11:27,040
so i don't know if you know but there is

00:11:25,440 --> 00:11:30,079
a flag that's called the

00:11:27,040 --> 00:11:33,760
max hot space size that can

00:11:30,079 --> 00:11:34,880
increase our memory uh from the default

00:11:33,760 --> 00:11:37,600
two gigabytes

00:11:34,880 --> 00:11:38,720
to in this case four gigabytes so i can

00:11:37,600 --> 00:11:42,160
use it

00:11:38,720 --> 00:11:43,279
and let's see what will happen now yeah

00:11:42,160 --> 00:11:46,560
i was able to

00:11:43,279 --> 00:11:49,360
process this data it took me 2.6

00:11:46,560 --> 00:11:51,200
gigabytes of memory

00:11:49,360 --> 00:11:52,720
uh but there's a problem with this

00:11:51,200 --> 00:11:55,920
solution right because

00:11:52,720 --> 00:11:57,360
this solution doesn't really scale as

00:11:55,920 --> 00:11:59,120
our data will

00:11:57,360 --> 00:12:01,279
be will be bigger and bigger we have to

00:11:59,120 --> 00:12:03,760
increase our memory each time

00:12:01,279 --> 00:12:04,959
and if you're working with microservices

00:12:03,760 --> 00:12:07,760
architecture

00:12:04,959 --> 00:12:09,600
you want your services to be as slim as

00:12:07,760 --> 00:12:12,959
possible

00:12:09,600 --> 00:12:14,399
and also you want to avoid the this line

00:12:12,959 --> 00:12:17,760
that i told you before

00:12:14,399 --> 00:12:20,880
uh you don't want to avoid

00:12:17,760 --> 00:12:21,279
doing a cpu intensive stuff and as as

00:12:20,880 --> 00:12:23,519
your

00:12:21,279 --> 00:12:25,040
as your data will get bigger and bigger

00:12:23,519 --> 00:12:26,639
this

00:12:25,040 --> 00:12:28,240
this function will take more and more

00:12:26,639 --> 00:12:30,639
time to process

00:12:28,240 --> 00:12:31,680
and you simply will block your event

00:12:30,639 --> 00:12:33,760
loop

00:12:31,680 --> 00:12:35,279
so we really want to avoid those funny

00:12:33,760 --> 00:12:38,639
things

00:12:35,279 --> 00:12:40,880
so let's get back to the presentation

00:12:38,639 --> 00:12:42,079
and before i show you the solution using

00:12:40,880 --> 00:12:46,160
streams

00:12:42,079 --> 00:12:48,720
let's do introduction what are streams

00:12:46,160 --> 00:12:50,880
so streams are interfaces for reading

00:12:48,720 --> 00:12:53,920
and writing data

00:12:50,880 --> 00:12:56,160
and streams can be piped together

00:12:53,920 --> 00:12:58,079
uh just like linux command when you got

00:12:56,160 --> 00:13:00,959
the first command the pipe

00:12:58,079 --> 00:13:02,880
and the second command and the output of

00:13:00,959 --> 00:13:04,560
the first command will be passed to the

00:13:02,880 --> 00:13:07,440
input of the second command

00:13:04,560 --> 00:13:09,120
strings work the same strings are piped

00:13:07,440 --> 00:13:13,440
together to each other

00:13:09,120 --> 00:13:13,440
and they pass chunks of data

00:13:14,800 --> 00:13:19,839
and node.js streams extends the

00:13:16,560 --> 00:13:22,079
ventimeter which means that

00:13:19,839 --> 00:13:24,079
streams emitting and subscribing to

00:13:22,079 --> 00:13:24,880
events in order to communicate with each

00:13:24,079 --> 00:13:26,639
other

00:13:24,880 --> 00:13:27,920
so in order to pass chunks of data

00:13:26,639 --> 00:13:30,480
between streams

00:13:27,920 --> 00:13:31,760
students will emit and subscribe to the

00:13:30,480 --> 00:13:35,200
data

00:13:31,760 --> 00:13:35,920
event there are all kind of events there

00:13:35,200 --> 00:13:39,519
are a

00:13:35,920 --> 00:13:42,880
finish event close event error event

00:13:39,519 --> 00:13:45,199
etc and there are all sorts of uh

00:13:42,880 --> 00:13:46,480
stream types so there are four stream

00:13:45,199 --> 00:13:48,880
types

00:13:46,480 --> 00:13:49,920
the first type is readable stream

00:13:48,880 --> 00:13:53,040
readable stream

00:13:49,920 --> 00:13:56,160
uh will be will always be the first

00:13:53,040 --> 00:13:56,880
stream in the pipeline is responsible

00:13:56,160 --> 00:14:00,560
from

00:13:56,880 --> 00:14:02,720
reading data from from a source it could

00:14:00,560 --> 00:14:06,320
be a db it could be file

00:14:02,720 --> 00:14:07,760
it could be std and

00:14:06,320 --> 00:14:10,240
there's also writable streaming

00:14:07,760 --> 00:14:13,680
writeable stream you all will always be

00:14:10,240 --> 00:14:16,079
the last stream in the pipeline and

00:14:13,680 --> 00:14:16,800
just and is responsible for writing the

00:14:16,079 --> 00:14:19,680
data

00:14:16,800 --> 00:14:20,480
to against all sort of sources it could

00:14:19,680 --> 00:14:24,959
be filed

00:14:20,480 --> 00:14:28,240
the db and duplex stream

00:14:24,959 --> 00:14:29,680
e is readable and writable but the

00:14:28,240 --> 00:14:31,839
readable and the writable are

00:14:29,680 --> 00:14:34,959
independent with each other

00:14:31,839 --> 00:14:36,000
so a good example the duplex is http

00:14:34,959 --> 00:14:38,079
sockets

00:14:36,000 --> 00:14:39,279
when you can read from socket and write

00:14:38,079 --> 00:14:42,800
from socket

00:14:39,279 --> 00:14:46,240
independently and last is

00:14:42,800 --> 00:14:47,199
transform stream transfer stream extends

00:14:46,240 --> 00:14:48,880
duplex

00:14:47,199 --> 00:14:51,360
which means that is readable and

00:14:48,880 --> 00:14:52,880
writable but this time the readable and

00:14:51,360 --> 00:14:54,560
the writable are

00:14:52,880 --> 00:14:55,920
the read and the right are dependent

00:14:54,560 --> 00:14:58,000
with each other

00:14:55,920 --> 00:14:59,199
so that means the transfer stream can

00:14:58,000 --> 00:15:02,000
read data

00:14:59,199 --> 00:15:02,399
and transform it change it and write

00:15:02,000 --> 00:15:06,399
this

00:15:02,399 --> 00:15:06,399
the same data forward in the pipeline

00:15:07,199 --> 00:15:10,839
and this is the solution to the

00:15:09,199 --> 00:15:14,320
challenge using streams

00:15:10,839 --> 00:15:17,760
so uh

00:15:14,320 --> 00:15:20,800
i'm getting this is the same sql query

00:15:17,760 --> 00:15:21,760
uh i'm wrapping it with promise because

00:15:20,800 --> 00:15:24,839
i want to still

00:15:21,760 --> 00:15:28,240
work with promises and so now read all

00:15:24,839 --> 00:15:31,040
events uh will return a readable stream

00:15:28,240 --> 00:15:31,920
jason to ccd will return transforms to

00:15:31,040 --> 00:15:34,240
him

00:15:31,920 --> 00:15:35,360
and write all events will return a

00:15:34,240 --> 00:15:38,880
writable stream

00:15:35,360 --> 00:15:40,000
so after these three lines all i'm doing

00:15:38,880 --> 00:15:43,839
is initializing

00:15:40,000 --> 00:15:46,639
a stream's object nothing is done here

00:15:43,839 --> 00:15:47,120
only when i'm piping them together only

00:15:46,639 --> 00:15:49,120
then

00:15:47,120 --> 00:15:51,040
it will signal the readable stream to

00:15:49,120 --> 00:15:53,040
start with data

00:15:51,040 --> 00:15:55,600
and start move data in the pipeline

00:15:53,040 --> 00:15:58,639
chunks of data in the pipeline

00:15:55,600 --> 00:16:02,480
so since i'm working with promises

00:15:58,639 --> 00:16:05,040
uh i want to resolve the promise once

00:16:02,480 --> 00:16:06,240
the pipeline is done so i'm subscribing

00:16:05,040 --> 00:16:08,000
to the finish event

00:16:06,240 --> 00:16:09,680
on the last stream in the pipeline the

00:16:08,000 --> 00:16:13,120
right stern

00:16:09,680 --> 00:16:13,120
and then i can resolve the promise

00:16:13,600 --> 00:16:19,120
so this is the two solutions

00:16:16,639 --> 00:16:20,320
and now let's compare them this is a bit

00:16:19,120 --> 00:16:24,160
spoiler i know

00:16:20,320 --> 00:16:24,160
but you can probably guess the results

00:16:25,040 --> 00:16:31,680
so i have stream.js which is the

00:16:28,480 --> 00:16:34,880
code that i show you now

00:16:31,680 --> 00:16:38,160
and let's run it

00:16:34,880 --> 00:16:38,959
and i'm doing the centric here as i did

00:16:38,160 --> 00:16:41,680
before

00:16:38,959 --> 00:16:44,160
and not really calling a db but i'm

00:16:41,680 --> 00:16:47,440
reading for the file which is big json

00:16:44,160 --> 00:16:48,720
the bigfight.json which is 400 megabytes

00:16:47,440 --> 00:16:51,120
software

00:16:48,720 --> 00:16:52,560
of json and then printing the memory

00:16:51,120 --> 00:16:55,680
again

00:16:52,560 --> 00:16:59,120
so let's wait a few seconds here

00:16:55,680 --> 00:17:02,000
and see how how much memory

00:16:59,120 --> 00:17:02,000
this time we used

00:17:02,560 --> 00:17:10,160
yeah we used 22 megabytes and only 20

00:17:06,400 --> 00:17:13,280
22 megabytes which which is far far less

00:17:10,160 --> 00:17:16,400
than the 2.6 gigabytes right

00:17:13,280 --> 00:17:19,919
and what's more impressive about it

00:17:16,400 --> 00:17:23,199
is that that this solution can scale

00:17:19,919 --> 00:17:24,319
right uh here i used 400 megabytes of

00:17:23,199 --> 00:17:27,600
data

00:17:24,319 --> 00:17:30,960
in wakney we use we can get to

00:17:27,600 --> 00:17:33,200
gigabytes and tens of gigabytes of data

00:17:30,960 --> 00:17:34,160
and the memory usage will still be the

00:17:33,200 --> 00:17:36,880
same

00:17:34,160 --> 00:17:37,840
you can even work with terabytes of data

00:17:36,880 --> 00:17:41,120
and you can

00:17:37,840 --> 00:17:44,240
the memory usage will be

00:17:41,120 --> 00:17:46,480
will be like this so

00:17:44,240 --> 00:17:47,919
i had to admit it really surprised me

00:17:46,480 --> 00:17:51,360
that a single

00:17:47,919 --> 00:17:55,039
node process and streams can handle this

00:17:51,360 --> 00:17:57,280
kind of big data i always thought that

00:17:55,039 --> 00:17:58,720
in order to cope with big data you need

00:17:57,280 --> 00:18:01,760
some sort of big data

00:17:58,720 --> 00:18:03,840
solutions like hadoop sparks and

00:18:01,760 --> 00:18:06,559
clusters and things like that

00:18:03,840 --> 00:18:08,559
but it turns out that node.js and stream

00:18:06,559 --> 00:18:11,520
can really really do the job for you

00:18:08,559 --> 00:18:12,799
if you need to process uh really really

00:18:11,520 --> 00:18:15,840
big data

00:18:12,799 --> 00:18:15,840
with small memory usage

00:18:16,160 --> 00:18:24,320
so let's get back to the presentation

00:18:19,760 --> 00:18:26,960
and now that you saw that streams are

00:18:24,320 --> 00:18:28,160
awesome you probably ask yourself can we

00:18:26,960 --> 00:18:31,919
create a swim

00:18:28,160 --> 00:18:34,559
by our own and like that man said

00:18:31,919 --> 00:18:34,559
yes you can

00:18:35,679 --> 00:18:40,320
and this is an example of readable

00:18:38,080 --> 00:18:43,120
stream

00:18:40,320 --> 00:18:46,080
of a custom readable stream and this is

00:18:43,120 --> 00:18:48,799
the syntax sense note 10.

00:18:46,080 --> 00:18:49,280
and so you see i'm requiring requiring

00:18:48,799 --> 00:18:53,039
forms

00:18:49,280 --> 00:18:55,679
free model which is built in in ogs

00:18:53,039 --> 00:18:56,400
i have to do new readable here and

00:18:55,679 --> 00:18:59,520
implement

00:18:56,400 --> 00:19:02,640
a read method and this read the

00:18:59,520 --> 00:19:04,960
method has a size parameter

00:19:02,640 --> 00:19:06,960
here i'm not using the size format this

00:19:04,960 --> 00:19:08,320
the size parameter is the size that

00:19:06,960 --> 00:19:11,679
you're going to read

00:19:08,320 --> 00:19:12,960
in each chunk and i'm not using this

00:19:11,679 --> 00:19:15,360
parameter because

00:19:12,960 --> 00:19:16,080
here in this example i'm generating the

00:19:15,360 --> 00:19:20,320
data

00:19:16,080 --> 00:19:22,960
on my own uh this is hello just hero

00:19:20,320 --> 00:19:24,110
heroes string i'm using the spread

00:19:22,960 --> 00:19:26,320
operator here and

00:19:24,110 --> 00:19:30,080
[Music]

00:19:26,320 --> 00:19:32,799
changing it to a array of characters

00:19:30,080 --> 00:19:34,400
and iterating on over each character and

00:19:32,799 --> 00:19:38,160
doing this dot push

00:19:34,400 --> 00:19:40,160
to the character so it will

00:19:38,160 --> 00:19:41,440
write this data to the next remedy

00:19:40,160 --> 00:19:43,679
pipeline

00:19:41,440 --> 00:19:46,799
when i'm done iterating over this string

00:19:43,679 --> 00:19:49,120
i'm doing this dot push with now

00:19:46,799 --> 00:19:50,400
and this will signal the next rear in

00:19:49,120 --> 00:19:54,400
the pipeline that

00:19:50,400 --> 00:19:56,240
i'm done reading the data

00:19:54,400 --> 00:19:58,080
and this is an example of transfer

00:19:56,240 --> 00:20:00,960
stream again

00:19:58,080 --> 00:20:02,400
required for this three model uh doing

00:20:00,960 --> 00:20:04,840
new transform here

00:20:02,400 --> 00:20:06,000
and then i have to implement

00:20:04,840 --> 00:20:08,320
transformatory

00:20:06,000 --> 00:20:10,720
and transform method get chunk which is

00:20:08,320 --> 00:20:14,080
the data from the previous

00:20:10,720 --> 00:20:15,120
string encoding and callback we will

00:20:14,080 --> 00:20:18,000
call callback

00:20:15,120 --> 00:20:20,799
and once we are done uh transforming the

00:20:18,000 --> 00:20:23,520
data and we want to write it forward

00:20:20,799 --> 00:20:24,240
industry in the pipeline and the first

00:20:23,520 --> 00:20:28,000
parameter

00:20:24,240 --> 00:20:30,320
is an error so i'm passing you now

00:20:28,000 --> 00:20:32,159
and the second parameter is that data

00:20:30,320 --> 00:20:35,919
that we want to

00:20:32,159 --> 00:20:38,159
to transfer so

00:20:35,919 --> 00:20:39,520
i'm doing chunk dot 2 string because

00:20:38,159 --> 00:20:42,159
chunk is buffer

00:20:39,520 --> 00:20:44,559
buffer type and going to uppercase

00:20:42,159 --> 00:20:48,480
because this is the transformation that

00:20:44,559 --> 00:20:50,720
i want to do

00:20:48,480 --> 00:20:52,320
and if you pipe everything together the

00:20:50,720 --> 00:20:55,360
readable stream that we did

00:20:52,320 --> 00:20:55,919
and the transform stream that we did we

00:20:55,360 --> 00:20:58,400
pipe it

00:20:55,919 --> 00:20:59,440
to the processes std out which is a

00:20:58,400 --> 00:21:02,960
built-in

00:20:59,440 --> 00:21:06,720
a writable stream inode we will get

00:21:02,960 --> 00:21:10,240
hello jseo's all capital letters

00:21:06,720 --> 00:21:12,960
and this is a really basic example but

00:21:10,240 --> 00:21:13,280
just to demonstrate you how easy it is

00:21:12,960 --> 00:21:15,440
to

00:21:13,280 --> 00:21:17,840
work with your own streams and piping

00:21:15,440 --> 00:21:17,840
them together

00:21:20,000 --> 00:21:27,440
let's talk about tips of using streams

00:21:24,000 --> 00:21:31,440
and the first tip that i have is

00:21:27,440 --> 00:21:35,039
based on a real life example

00:21:31,440 --> 00:21:37,120
uh error handling so i had i had this

00:21:35,039 --> 00:21:40,480
code in production

00:21:37,120 --> 00:21:41,760
and this code can break right because we

00:21:40,480 --> 00:21:44,720
are reading data from

00:21:41,760 --> 00:21:45,360
the db we're transforming the data we

00:21:44,720 --> 00:21:48,159
are writing

00:21:45,360 --> 00:21:49,360
to s3 we're doing all sorts of things

00:21:48,159 --> 00:21:52,799
that can break in

00:21:49,360 --> 00:21:56,480
in the way so i did whatever

00:21:52,799 --> 00:21:58,799
every developer will do in this scenario

00:21:56,480 --> 00:22:01,360
i will wrap it with trying catch right

00:21:58,799 --> 00:22:04,559
in order to catch those errors

00:22:01,360 --> 00:22:08,159
but it turns out that this is not enough

00:22:04,559 --> 00:22:10,840
when you're using streams and basically

00:22:08,159 --> 00:22:12,559
we got unhanded promise rejections in

00:22:10,840 --> 00:22:15,200
production

00:22:12,559 --> 00:22:15,600
so in order to solve it what you need to

00:22:15,200 --> 00:22:19,039
do

00:22:15,600 --> 00:22:22,159
is subscribe to an error event

00:22:19,039 --> 00:22:24,720
in each stream so if

00:22:22,159 --> 00:22:26,240
an error will occur in a stream it would

00:22:24,720 --> 00:22:28,080
trigger the error event

00:22:26,240 --> 00:22:30,400
and then you can reject the promise and

00:22:28,080 --> 00:22:34,480
you won't get

00:22:30,400 --> 00:22:34,480
unhandled rejections that way

00:22:35,039 --> 00:22:38,960
but there's a duplication of code here

00:22:37,280 --> 00:22:41,120
right because you have to do their own

00:22:38,960 --> 00:22:44,400
error on each stream

00:22:41,120 --> 00:22:47,520
and you can improve it

00:22:44,400 --> 00:22:50,000
by instead of working with the pipe

00:22:47,520 --> 00:22:50,799
method you can work with the pipeline

00:22:50,000 --> 00:22:54,799
api

00:22:50,799 --> 00:22:57,360
which is built in in the module screen

00:22:54,799 --> 00:22:58,080
and pipeline api gets as parameters the

00:22:57,360 --> 00:23:00,880
strings

00:22:58,080 --> 00:23:02,400
and connect them to a pipeline and

00:23:00,880 --> 00:23:03,760
what's really cool about the pipeline

00:23:02,400 --> 00:23:07,120
api

00:23:03,760 --> 00:23:10,159
is that it has a callback so

00:23:07,120 --> 00:23:11,919
if i have an error no matter where in

00:23:10,159 --> 00:23:14,480
those strings

00:23:11,919 --> 00:23:15,840
it will call the callback with an arrow

00:23:14,480 --> 00:23:19,280
and then i can reject

00:23:15,840 --> 00:23:20,400
the promise so it removes the

00:23:19,280 --> 00:23:25,039
duplication of

00:23:20,400 --> 00:23:29,280
the own error on each on each stream

00:23:25,039 --> 00:23:33,200
another cool thing is that the callback

00:23:29,280 --> 00:23:35,200
if the pipeline is done successfully

00:23:33,200 --> 00:23:37,360
the callback will be triggered also with

00:23:35,200 --> 00:23:40,640
no arrow and then i can solve the

00:23:37,360 --> 00:23:41,679
resolve the promise so i can even remove

00:23:40,640 --> 00:23:44,960
the unfinished

00:23:41,679 --> 00:23:48,840
that i had before and

00:23:44,960 --> 00:23:50,720
if you want to improve this code even

00:23:48,840 --> 00:23:52,559
more

00:23:50,720 --> 00:23:53,760
sorry if you want to improve this code

00:23:52,559 --> 00:23:56,720
even more uh

00:23:53,760 --> 00:23:59,440
you can use util promoting file which is

00:23:56,720 --> 00:24:02,480
also built in ojs

00:23:59,440 --> 00:24:06,240
and it will change pipeline from working

00:24:02,480 --> 00:24:08,720
with callbacks to working with promises

00:24:06,240 --> 00:24:10,159
that way that way pipeline asking will

00:24:08,720 --> 00:24:12,000
return promise

00:24:10,159 --> 00:24:14,799
and then you can just await on the

00:24:12,000 --> 00:24:17,039
pipeline api and the pipeline sync

00:24:14,799 --> 00:24:18,320
and then you can try it with the wrap it

00:24:17,039 --> 00:24:22,799
with the dry catch

00:24:18,320 --> 00:24:22,799
and then you can catch those errors

00:24:24,720 --> 00:24:28,000
another important thing in streams is

00:24:27,039 --> 00:24:31,440
back pressure

00:24:28,000 --> 00:24:32,799
so back pressure is a scenario when you

00:24:31,440 --> 00:24:34,880
have two streams

00:24:32,799 --> 00:24:36,720
that are connected to each other and one

00:24:34,880 --> 00:24:39,919
stream uh produce more data

00:24:36,720 --> 00:24:42,960
than the other stream uh can handle

00:24:39,919 --> 00:24:45,039
and this this this can cause back

00:24:42,960 --> 00:24:48,559
pressure and back pressure and can

00:24:45,039 --> 00:24:50,799
can cause you to use a

00:24:48,559 --> 00:24:52,240
large amount of memory and you can have

00:24:50,799 --> 00:24:54,640
the javascript heat up

00:24:52,240 --> 00:24:56,159
keep out of memory just like i showed

00:24:54,640 --> 00:25:00,320
you before

00:24:56,159 --> 00:25:03,039
so you really want to avoid it and

00:25:00,320 --> 00:25:04,159
don't do this don't subscribe to the

00:25:03,039 --> 00:25:06,400
data event

00:25:04,159 --> 00:25:09,679
and write from this data event to the

00:25:06,400 --> 00:25:11,840
next stream in the pipeline

00:25:09,679 --> 00:25:14,880
it can potentially cause you back

00:25:11,840 --> 00:25:17,520
pressure problems

00:25:14,880 --> 00:25:19,279
what you need to do is work with the

00:25:17,520 --> 00:25:22,240
pipe and the python api

00:25:19,279 --> 00:25:24,240
that i showed you before and luckily

00:25:22,240 --> 00:25:27,360
luckily for us the core

00:25:24,240 --> 00:25:28,880
core team of node took care of a back

00:25:27,360 --> 00:25:32,000
pressure balancing

00:25:28,880 --> 00:25:34,000
in this in those apis

00:25:32,000 --> 00:25:36,400
so you just need to call them and you'll

00:25:34,000 --> 00:25:36,400
be good

00:25:37,760 --> 00:25:42,240
another useful thing is object mode

00:25:41,360 --> 00:25:45,360
option

00:25:42,240 --> 00:25:46,880
and the default

00:25:45,360 --> 00:25:48,640
object mode option is the option that

00:25:46,880 --> 00:25:51,440
you can pass through streams

00:25:48,640 --> 00:25:52,559
and the default value of object mode is

00:25:51,440 --> 00:25:56,640
false

00:25:52,559 --> 00:25:59,440
and when it falls you can

00:25:56,640 --> 00:26:01,520
read and write for streams only strings

00:25:59,440 --> 00:26:03,600
and buffer types

00:26:01,520 --> 00:26:05,039
so if you're working with objects like

00:26:03,600 --> 00:26:07,120
in this example

00:26:05,039 --> 00:26:08,400
you need to stringify the object here

00:26:07,120 --> 00:26:10,400
then push it

00:26:08,400 --> 00:26:13,679
and in the transform stream you need to

00:26:10,400 --> 00:26:13,679
parse it and

00:26:13,840 --> 00:26:19,600
transform it and then stringify it back

00:26:16,880 --> 00:26:20,400
so it's much more easier to work with

00:26:19,600 --> 00:26:24,480
object mode

00:26:20,400 --> 00:26:27,760
and then you can push objects in

00:26:24,480 --> 00:26:28,480
to two streams in the transform stream

00:26:27,760 --> 00:26:30,720
you have

00:26:28,480 --> 00:26:31,760
readable object mode in writable object

00:26:30,720 --> 00:26:34,480
mode

00:26:31,760 --> 00:26:35,440
and then you can just transform it and

00:26:34,480 --> 00:26:38,720
move it

00:26:35,440 --> 00:26:42,320
as an object and it's really useful

00:26:38,720 --> 00:26:46,320
and saves you all the stringify and

00:26:42,320 --> 00:26:48,960
powers another important option

00:26:46,320 --> 00:26:49,600
is high watermark options high watermark

00:26:48,960 --> 00:26:51,760
options

00:26:49,600 --> 00:26:53,200
set the val the the size that you're

00:26:51,760 --> 00:26:54,960
gonna read or write

00:26:53,200 --> 00:26:56,320
the site of the chunk that you're gonna

00:26:54,960 --> 00:26:59,279
read or write

00:26:56,320 --> 00:27:00,400
uh in the stream and the default value

00:26:59,279 --> 00:27:04,400
of high water rugs

00:27:00,400 --> 00:27:06,159
is 16k and

00:27:04,400 --> 00:27:07,760
you can play with this number in order

00:27:06,159 --> 00:27:11,520
to optimize things

00:27:07,760 --> 00:27:11,840
and it's basically a trade-off between

00:27:11,520 --> 00:27:14,880
the

00:27:11,840 --> 00:27:15,360
memory size that you will use and the

00:27:14,880 --> 00:27:18,320
speed

00:27:15,360 --> 00:27:21,840
that you will able to read or write from

00:27:18,320 --> 00:27:21,840
your stream

00:27:22,559 --> 00:27:26,559
so let's talk about generator functions

00:27:25,679 --> 00:27:28,720
now

00:27:26,559 --> 00:27:30,559
generator function is not something new

00:27:28,720 --> 00:27:33,679
in node

00:27:30,559 --> 00:27:36,320
a generated function creates

00:27:33,679 --> 00:27:37,039
a terrible object and stay with me i

00:27:36,320 --> 00:27:40,480
will

00:27:37,039 --> 00:27:43,120
explain it in a second

00:27:40,480 --> 00:27:44,320
this is an example of generator function

00:27:43,120 --> 00:27:47,120
so you can see

00:27:44,320 --> 00:27:49,520
it's a function with an asterisk and we

00:27:47,120 --> 00:27:52,559
have a yield keyword here

00:27:49,520 --> 00:27:55,760
so generate sequence takes start and

00:27:52,559 --> 00:27:59,360
end index indexes and

00:27:55,760 --> 00:27:59,360
iterating over uh

00:27:59,840 --> 00:28:05,440
with for loop from the start to the end

00:28:02,320 --> 00:28:08,640
and yielding each index

00:28:05,440 --> 00:28:09,520
so this is the usage of generator

00:28:08,640 --> 00:28:12,000
function

00:28:09,520 --> 00:28:13,840
so if i call generate sequence with 1

00:28:12,000 --> 00:28:16,960
and 3

00:28:13,840 --> 00:28:20,159
it will return the generator generate

00:28:16,960 --> 00:28:22,960
object which is any terrible object

00:28:20,159 --> 00:28:23,760
which means that is implementing the

00:28:22,960 --> 00:28:27,600
ethereal

00:28:23,760 --> 00:28:29,440
iterable terrible protocol and interval

00:28:27,600 --> 00:28:31,919
protocol means that

00:28:29,440 --> 00:28:33,120
this object has a next map and a next

00:28:31,919 --> 00:28:36,559
function

00:28:33,120 --> 00:28:40,240
and this next function return an object

00:28:36,559 --> 00:28:44,240
that has a value property and

00:28:40,240 --> 00:28:47,919
if you call next each time it will

00:28:44,240 --> 00:28:50,080
do generate the next uh sequence

00:28:47,919 --> 00:28:51,840
so if i'm calling next with value for

00:28:50,080 --> 00:28:55,120
the first time it prints one

00:28:51,840 --> 00:28:57,760
then prints two and then prints three

00:28:55,120 --> 00:28:58,880
but there's more elegant used to two

00:28:57,760 --> 00:29:03,039
generators

00:28:58,880 --> 00:29:06,000
and you can do for off loop over again

00:29:03,039 --> 00:29:07,600
and if you do for off loop over generate

00:29:06,000 --> 00:29:11,039
generate object

00:29:07,600 --> 00:29:12,320
and then you don't have to call the next

00:29:11,039 --> 00:29:14,960
in the value

00:29:12,320 --> 00:29:15,760
node will do it for you and then you can

00:29:14,960 --> 00:29:18,720
print one two

00:29:15,760 --> 00:29:20,080
three but why i'm talking about

00:29:18,720 --> 00:29:23,760
generator functions

00:29:20,080 --> 00:29:26,880
and how they are related to streams and

00:29:23,760 --> 00:29:28,480
the answer to it is that you can create

00:29:26,880 --> 00:29:32,000
readable streams from

00:29:28,480 --> 00:29:34,880
generator functions so

00:29:32,000 --> 00:29:36,640
take a look over this example this is

00:29:34,880 --> 00:29:38,399
the example that i showed you of

00:29:36,640 --> 00:29:42,159
creating a readable streams

00:29:38,399 --> 00:29:46,000
with hello.js jesus string

00:29:42,159 --> 00:29:49,520
and this is an example of generator

00:29:46,000 --> 00:29:52,240
a function that takes those characters

00:29:49,520 --> 00:29:56,799
and yielding each character

00:29:52,240 --> 00:29:59,760
so if i'm taking the readable from a

00:29:56,799 --> 00:30:01,120
screen model i can call readable form

00:29:59,760 --> 00:30:03,200
with the generator

00:30:01,120 --> 00:30:04,559
object here i'm calling the generate

00:30:03,200 --> 00:30:07,679
function

00:30:04,559 --> 00:30:10,480
and it will create a readable string

00:30:07,679 --> 00:30:12,559
from this generate function and you can

00:30:10,480 --> 00:30:13,200
see i can pipe it to the std out which

00:30:12,559 --> 00:30:16,559
is

00:30:13,200 --> 00:30:19,120
the writable string and this syntax is

00:30:16,559 --> 00:30:19,840
is much more easier and much more useful

00:30:19,120 --> 00:30:22,399
than

00:30:19,840 --> 00:30:25,360
implementing those read and doing this

00:30:22,399 --> 00:30:27,360
dot push and this dot push now

00:30:25,360 --> 00:30:29,760
and this is much more easier much more

00:30:27,360 --> 00:30:32,880
elegant and this is just

00:30:29,760 --> 00:30:36,080
an easy example but

00:30:32,880 --> 00:30:38,320
in my opinion this syntax helps a lot

00:30:36,080 --> 00:30:38,320
here

00:30:40,159 --> 00:30:44,000
let's talk about asking generator

00:30:42,799 --> 00:30:46,320
functions so i showed you

00:30:44,000 --> 00:30:48,799
generator functions and generator

00:30:46,320 --> 00:30:50,640
function can be async also

00:30:48,799 --> 00:30:54,159
and that means that they are creating

00:30:50,640 --> 00:30:56,159
async iterable object

00:30:54,159 --> 00:30:58,320
and this is the same example of general

00:30:56,159 --> 00:31:00,480
sequence but this time

00:30:58,320 --> 00:31:03,039
it is asking right you can see the async

00:31:00,480 --> 00:31:05,679
here and a wait

00:31:03,039 --> 00:31:06,480
and in this example i'm waiting for set

00:31:05,679 --> 00:31:11,519
amount

00:31:06,480 --> 00:31:11,519
set timeout with one second so

00:31:11,760 --> 00:31:14,880
let's see usage of it so this is

00:31:14,240 --> 00:31:18,880
generate

00:31:14,880 --> 00:31:22,320
sequence async it return a

00:31:18,880 --> 00:31:24,880
asking a terrible object uh

00:31:22,320 --> 00:31:26,240
this asking iterable object implements a

00:31:24,880 --> 00:31:29,360
singular terrible

00:31:26,240 --> 00:31:30,559
protocol which is basically the same as

00:31:29,360 --> 00:31:34,000
the terrible

00:31:30,559 --> 00:31:36,640
protocol but this time the next method

00:31:34,000 --> 00:31:37,840
is returning a promise that's the only

00:31:36,640 --> 00:31:39,760
difference

00:31:37,840 --> 00:31:41,279
so if i'm calling next year i have to

00:31:39,760 --> 00:31:44,399
wait and

00:31:41,279 --> 00:31:47,360
don't do the dot value and you

00:31:44,399 --> 00:31:48,080
it will print one after one second the

00:31:47,360 --> 00:31:50,159
second time

00:31:48,080 --> 00:31:51,919
it will bring two after one second and

00:31:50,159 --> 00:31:55,600
then bring three

00:31:51,919 --> 00:31:56,080
after one second and a more elegant use

00:31:55,600 --> 00:32:00,880
to it

00:31:56,080 --> 00:32:04,480
will be for a weight off loop over this

00:32:00,880 --> 00:32:07,279
async iterable object and then

00:32:04,480 --> 00:32:08,640
you will avoid doing the next and the

00:32:07,279 --> 00:32:10,720
dot value

00:32:08,640 --> 00:32:13,440
and it will basically print one two and

00:32:10,720 --> 00:32:16,320
three with one second delay

00:32:13,440 --> 00:32:16,320
over each one

00:32:19,440 --> 00:32:24,720
so streams can work with asking

00:32:22,559 --> 00:32:27,519
iterators

00:32:24,720 --> 00:32:28,080
because all readable screens are asking

00:32:27,519 --> 00:32:31,120
a terrible

00:32:28,080 --> 00:32:33,679
object by definition

00:32:31,120 --> 00:32:34,159
which means that you can do the 408 off

00:32:33,679 --> 00:32:37,279
loop

00:32:34,159 --> 00:32:37,760
of a readable screen and this is very

00:32:37,279 --> 00:32:39,760
very

00:32:37,760 --> 00:32:42,159
again very useful syntax if you're

00:32:39,760 --> 00:32:44,880
working with readable streams

00:32:42,159 --> 00:32:46,799
you can take the chunk of the data and

00:32:44,880 --> 00:32:47,279
basically do whatever you want with him

00:32:46,799 --> 00:32:49,200
here

00:32:47,279 --> 00:32:52,640
just showing you examples that you can

00:32:49,200 --> 00:32:56,000
do to offer case

00:32:52,640 --> 00:32:58,640
and what's even more cool about it

00:32:56,000 --> 00:33:00,880
is that you can work with us in

00:32:58,640 --> 00:33:03,039
generators and passing iterators you can

00:33:00,880 --> 00:33:05,039
combine those two together

00:33:03,039 --> 00:33:07,120
so this is an example of a sync

00:33:05,039 --> 00:33:10,799
generator function you can see i think

00:33:07,120 --> 00:33:13,200
with function asterisks we text

00:33:10,799 --> 00:33:14,000
the text available to him and doing 408

00:33:13,200 --> 00:33:18,080
off loop

00:33:14,000 --> 00:33:20,159
over this stream and yielding

00:33:18,080 --> 00:33:24,559
using the results and doing the two

00:33:20,159 --> 00:33:27,600
uppercase transformation

00:33:24,559 --> 00:33:30,720
and another thing that is cool uh

00:33:27,600 --> 00:33:33,760
pipeline api supports generators which

00:33:30,720 --> 00:33:36,960
is the brand new e node 14.

00:33:33,760 --> 00:33:40,080
this is a brand new syntax

00:33:36,960 --> 00:33:43,519
that the pipeline api supports so

00:33:40,080 --> 00:33:47,120
pipelining apis i showed you supports uh

00:33:43,519 --> 00:33:50,159
before route 14 supports only streams

00:33:47,120 --> 00:33:53,120
but as you can see here i'm passing it

00:33:50,159 --> 00:33:54,799
a anonymous generator functions

00:33:53,120 --> 00:33:57,120
generator function

00:33:54,799 --> 00:33:57,919
uh just doing all this doing is reading

00:33:57,120 --> 00:34:00,880
from the hello

00:33:57,919 --> 00:34:02,720
js heroes and yielding each character

00:34:00,880 --> 00:34:05,840
and the second parameter here

00:34:02,720 --> 00:34:06,559
is anonymous acid generator function

00:34:05,840 --> 00:34:09,119
that gets

00:34:06,559 --> 00:34:10,000
the this stream doing the four weight of

00:34:09,119 --> 00:34:13,440
loop

00:34:10,000 --> 00:34:14,800
and yielding and transforming it to two

00:34:13,440 --> 00:34:16,720
uppercase

00:34:14,800 --> 00:34:19,359
the third the third parameter is the

00:34:16,720 --> 00:34:22,159
processor cd-out which is the stream

00:34:19,359 --> 00:34:23,119
so it just you can combine them and it's

00:34:22,159 --> 00:34:26,399
very useful

00:34:23,119 --> 00:34:27,760
and very very cool syntax it really

00:34:26,399 --> 00:34:30,560
reminds me of

00:34:27,760 --> 00:34:32,240
express middlewares and when you can

00:34:30,560 --> 00:34:35,599
pipe those middlewares together

00:34:32,240 --> 00:34:36,000
and basically each middleware implements

00:34:35,599 --> 00:34:39,679
some

00:34:36,000 --> 00:34:43,280
contract it expresses required and next

00:34:39,679 --> 00:34:45,200
and here is the same

00:34:43,280 --> 00:34:46,879
generator functions they implement some

00:34:45,200 --> 00:34:50,720
sort of contract

00:34:46,879 --> 00:34:50,720
that supports support it

00:34:51,679 --> 00:34:56,720
so let's sum things up here um

00:34:55,040 --> 00:34:59,760
don't afraid to take node.js to the

00:34:56,720 --> 00:35:03,200
extreme that just like i showed you here

00:34:59,760 --> 00:35:07,920
it turns out that simple process of node

00:35:03,200 --> 00:35:10,160
and stream can handle really big data

00:35:07,920 --> 00:35:12,240
streams api is easy just like i showed

00:35:10,160 --> 00:35:13,200
you here we can create streams by your

00:35:12,240 --> 00:35:16,560
own

00:35:13,200 --> 00:35:19,839
uh the documentation of students is very

00:35:16,560 --> 00:35:22,160
very very good and justin

00:35:19,839 --> 00:35:23,119
as i showed you in the next last example

00:35:22,160 --> 00:35:26,079
uh

00:35:23,119 --> 00:35:30,640
the the core team of node keeps improves

00:35:26,079 --> 00:35:32,720
the api more and more

00:35:30,640 --> 00:35:33,920
and follow the best practices and tips

00:35:32,720 --> 00:35:37,680
that i showed you here

00:35:33,920 --> 00:35:42,240
so you can work with streams uh

00:35:37,680 --> 00:35:42,240
properly and you optimized your usage of

00:35:42,839 --> 00:35:48,000
streams

00:35:45,599 --> 00:35:49,280
that this is basically it if you have

00:35:48,000 --> 00:35:51,839
any questions

00:35:49,280 --> 00:35:51,839
feel free

00:35:55,280 --> 00:36:01,440
so for questions you can either

00:35:58,560 --> 00:36:03,200
mute yourself directly or you can write

00:36:01,440 --> 00:36:05,440
them in the channel it's a it's up to

00:36:03,200 --> 00:36:05,440
you

00:36:06,320 --> 00:36:12,320
i can start until

00:36:09,760 --> 00:36:13,280
everybody thinks i'm curious so you said

00:36:12,320 --> 00:36:15,760
you implemented

00:36:13,280 --> 00:36:17,040
the first method that was consuming a

00:36:15,760 --> 00:36:20,400
lot of memory first

00:36:17,040 --> 00:36:21,200
no what other options did you explore

00:36:20,400 --> 00:36:24,160
before

00:36:21,200 --> 00:36:25,680
choosing streams or how did you end up

00:36:24,160 --> 00:36:28,880
with streams

00:36:25,680 --> 00:36:32,240
yeah uh so

00:36:28,880 --> 00:36:34,320
we had another we have two options that

00:36:32,240 --> 00:36:37,359
we

00:36:34,320 --> 00:36:40,640
explored one option

00:36:37,359 --> 00:36:44,560
was to work with a child process

00:36:40,640 --> 00:36:47,680
and try to split this data

00:36:44,560 --> 00:36:50,720
the process of this data to chunks but

00:36:47,680 --> 00:36:51,920
it wasn't really effective and since

00:36:50,720 --> 00:36:55,200
we're using

00:36:51,920 --> 00:36:57,200
child processes if one of them will fail

00:36:55,200 --> 00:36:58,240
it will be very hard to synchronize

00:36:57,200 --> 00:37:01,920
their results

00:36:58,240 --> 00:37:04,800
and to handle the errors

00:37:01,920 --> 00:37:05,200
another another thing that we try to do

00:37:04,800 --> 00:37:09,200
is

00:37:05,200 --> 00:37:12,240
uh do some sort of pagination on the db

00:37:09,200 --> 00:37:16,240
and then as i

00:37:12,240 --> 00:37:18,880
showed you here we used crestodb

00:37:16,240 --> 00:37:20,400
and pagination on prestodb is something

00:37:18,880 --> 00:37:24,320
that is really really hard

00:37:20,400 --> 00:37:26,720
to do if you're working with postgres

00:37:24,320 --> 00:37:30,079
and mysql i think pagination is

00:37:26,720 --> 00:37:31,119
much more easier and we had problem

00:37:30,079 --> 00:37:34,160
doing the

00:37:31,119 --> 00:37:34,160
this pagination

00:37:34,240 --> 00:37:38,000
but if you think about streams streams

00:37:36,560 --> 00:37:41,359
are

00:37:38,000 --> 00:37:44,160
some sort of pagination because you are

00:37:41,359 --> 00:37:46,400
reading chunks of data each time so it's

00:37:44,160 --> 00:37:49,280
it's kind of pagination

00:37:46,400 --> 00:37:50,079
from the db and you read this data and

00:37:49,280 --> 00:37:53,440
move it forward

00:37:50,079 --> 00:37:57,359
read another data and move it forward

00:37:53,440 --> 00:38:05,839
so streams was the best solution that

00:37:57,359 --> 00:38:05,839
we saw

00:38:10,720 --> 00:38:13,440
don't be shy

00:38:14,240 --> 00:38:18,079
it's it's usually either either ways

00:38:17,280 --> 00:38:20,410
either too many

00:38:18,079 --> 00:38:23,580
questions or nobody's saying anything

00:38:20,410 --> 00:38:23,580
[Music]

00:38:31,040 --> 00:38:38,800
i can ask questions to the audience

00:38:34,400 --> 00:38:42,720
i'm curious if someone was experienced

00:38:38,800 --> 00:38:42,720
has has experience with streams in

00:38:44,839 --> 00:38:49,359
production

00:38:46,000 --> 00:38:49,359
i i don't

00:38:49,599 --> 00:38:56,720
yeah uh omri

00:38:52,960 --> 00:38:59,839
asked a question can you share some

00:38:56,720 --> 00:39:02,300
real world use cases

00:38:59,839 --> 00:39:04,160
yeah so

00:39:02,300 --> 00:39:06,560
[Music]

00:39:04,160 --> 00:39:08,640
this is a real world use case that i

00:39:06,560 --> 00:39:11,440
showed

00:39:08,640 --> 00:39:13,359
it's really a feature that we have but i

00:39:11,440 --> 00:39:17,359
can

00:39:13,359 --> 00:39:21,200
i can show a use case that

00:39:17,359 --> 00:39:24,240
you can probably more relate to it so

00:39:21,200 --> 00:39:27,599
if you are um if you want to

00:39:24,240 --> 00:39:28,160
stream a video i guess like netflix and

00:39:27,599 --> 00:39:31,920
youtube

00:39:28,160 --> 00:39:35,200
and things like that so um

00:39:31,920 --> 00:39:38,560
so you have probably a client

00:39:35,200 --> 00:39:42,000
in html and you want to

00:39:38,560 --> 00:39:44,720
to to fetch a

00:39:42,000 --> 00:39:45,839
video and video is a data and video can

00:39:44,720 --> 00:39:49,040
be big

00:39:45,839 --> 00:39:52,079
video can be jiggers uh of data

00:39:49,040 --> 00:39:53,599
and you don't want to uh to fetch all

00:39:52,079 --> 00:39:56,960
these data at once

00:39:53,599 --> 00:40:00,079
to your client it will be heavy

00:39:56,960 --> 00:40:03,040
and not efficient so what you do

00:40:00,079 --> 00:40:03,599
in a video you just ask the server each

00:40:03,040 --> 00:40:06,880
time

00:40:03,599 --> 00:40:09,920
for a chunk of data and the server

00:40:06,880 --> 00:40:12,400
will return stream for you actually

00:40:09,920 --> 00:40:16,000
there's a http

00:40:12,400 --> 00:40:19,599
http status for it it's 206

00:40:16,000 --> 00:40:23,520
and when we return 206

00:40:19,599 --> 00:40:26,560
the html knows to take it as the stream

00:40:23,520 --> 00:40:28,560
and process it each time and then you

00:40:26,560 --> 00:40:39,839
can play your video

00:40:28,560 --> 00:40:39,839
with stream

00:40:43,680 --> 00:40:51,760
i saw i am seeing another question

00:40:47,680 --> 00:40:55,280
you want me or you can you'll do it

00:40:51,760 --> 00:40:57,599
i can read it okay so

00:40:55,280 --> 00:40:58,960
didn't you have to stream the data from

00:40:57,599 --> 00:41:01,599
the db as well

00:40:58,960 --> 00:41:03,760
i assume the stream solutions work if

00:41:01,599 --> 00:41:06,560
the data source is also sometimes

00:41:03,760 --> 00:41:07,760
a stream form yeah this is something

00:41:06,560 --> 00:41:11,599
that's important

00:41:07,760 --> 00:41:15,760
and because

00:41:11,599 --> 00:41:18,800
i'm talking about jsons and streams and

00:41:15,760 --> 00:41:22,400
the db has to support some sort of

00:41:18,800 --> 00:41:22,400
fetching the data in chunks

00:41:22,480 --> 00:41:29,839
and it's so think about it if if you

00:41:26,720 --> 00:41:32,480
since we're working with jsons um

00:41:29,839 --> 00:41:33,119
we can't really cut those chunks in the

00:41:32,480 --> 00:41:36,960
middle

00:41:33,119 --> 00:41:40,079
you have to you have to have a full json

00:41:36,960 --> 00:41:41,520
uh in order to do the transformation and

00:41:40,079 --> 00:41:45,599
things like that

00:41:41,520 --> 00:41:48,960
and so yeah it supports

00:41:45,599 --> 00:41:51,599
this db support streams

00:41:48,960 --> 00:41:53,920
we start implementing it by our own but

00:41:51,599 --> 00:41:56,160
then we found the library

00:41:53,920 --> 00:41:56,160
that

00:41:57,119 --> 00:42:03,520
did it more efficiently

00:42:00,160 --> 00:42:06,079
this is a good

00:42:03,520 --> 00:42:07,599
a good tip or don't try to invent the

00:42:06,079 --> 00:42:10,319
wheel

00:42:07,599 --> 00:42:11,119
if it's if there is a good library don't

00:42:10,319 --> 00:42:14,640
be

00:42:11,119 --> 00:42:17,839
don't hesitate to use it

00:42:14,640 --> 00:42:21,280
so yes this db

00:42:17,839 --> 00:42:24,560
has some sort of this db

00:42:21,280 --> 00:42:27,599
we call it with http and it has an

00:42:24,560 --> 00:42:28,800
endpoint that supports fetching these

00:42:27,599 --> 00:42:34,319
data

00:42:28,800 --> 00:42:34,319
in chunks so it will import

00:42:37,839 --> 00:42:40,960
i see another question are strings

00:42:39,520 --> 00:42:44,800
similar

00:42:40,960 --> 00:42:48,240
similar with observables

00:42:44,800 --> 00:42:50,400
actually observables use streams also

00:42:48,240 --> 00:42:52,480
here in this talk i only talked about

00:42:50,400 --> 00:42:56,480
the

00:42:52,480 --> 00:42:59,920
streams of in the context of the

00:42:56,480 --> 00:43:02,160
data pipelines but there's a concept

00:42:59,920 --> 00:43:05,599
that called the reactive programming

00:43:02,160 --> 00:43:07,040
probably heard of it there is a famous

00:43:05,599 --> 00:43:11,599
library of

00:43:07,040 --> 00:43:15,440
rxjs and observable patterns

00:43:11,599 --> 00:43:17,280
and observable patterns use screams also

00:43:15,440 --> 00:43:19,440
but they used rims in order to

00:43:17,280 --> 00:43:22,960
communicate

00:43:19,440 --> 00:43:26,000
according to a triggering of events

00:43:22,960 --> 00:43:29,680
so it's really really useful and

00:43:26,000 --> 00:43:32,800
this pattern is very popular today and

00:43:29,680 --> 00:43:34,160
use it also but this is another used

00:43:32,800 --> 00:43:41,839
case of strings yeah

00:43:34,160 --> 00:43:41,839
observable used streams also

00:43:42,319 --> 00:43:48,800
i have one more question

00:43:45,680 --> 00:43:51,440
so yeah can you use the streams just to

00:43:48,800 --> 00:43:52,319
read data from a database or for example

00:43:51,440 --> 00:43:55,839
if

00:43:52,319 --> 00:43:59,200
we have a form on on a website and

00:43:55,839 --> 00:44:01,200
a user uploads a file he's allowed to

00:43:59,200 --> 00:44:02,000
upload the file and he uploads a one

00:44:01,200 --> 00:44:05,760
gigabyte

00:44:02,000 --> 00:44:07,200
file can you retrieve that as a stream

00:44:05,760 --> 00:44:10,400
and not have to read

00:44:07,200 --> 00:44:12,160
everything like that one gigabyte at

00:44:10,400 --> 00:44:15,599
once

00:44:12,160 --> 00:44:19,119
yeah yeah you can you can watch streams

00:44:15,599 --> 00:44:22,880
and actually the

00:44:19,119 --> 00:44:26,560
the request object and response object

00:44:22,880 --> 00:44:26,560
in ojs and streams also

00:44:26,640 --> 00:44:31,520
i'm not i can't remember one

00:44:29,839 --> 00:44:34,480
which one is readable and which one is

00:44:31,520 --> 00:44:37,520
writable but there are streams also

00:44:34,480 --> 00:44:40,720
so you can uh just walk with those

00:44:37,520 --> 00:44:43,280
objects and stream them and

00:44:40,720 --> 00:44:46,079
like if you want to do some sort of

00:44:43,280 --> 00:44:48,480
manipulation to it you can

00:44:46,079 --> 00:44:49,280
pipe it to transform stream or if you

00:44:48,480 --> 00:44:52,000
just want to

00:44:49,280 --> 00:44:52,720
write it forward to some sort of source

00:44:52,000 --> 00:44:56,800
you can

00:44:52,720 --> 00:44:56,800
connect the requests that you have

00:44:56,960 --> 00:44:59,599
to a stream

00:45:03,680 --> 00:45:07,599
okay i see another question you had an

00:45:05,599 --> 00:45:10,480
example with generator

00:45:07,599 --> 00:45:11,920
within an iterator what is the benefit

00:45:10,480 --> 00:45:14,800
of having a async

00:45:11,920 --> 00:45:17,760
a generator inside a nasty iterator

00:45:14,800 --> 00:45:20,160
isn't it enough

00:45:17,760 --> 00:45:21,839
it have a async generator within an

00:45:20,160 --> 00:45:25,760
async iterator

00:45:21,839 --> 00:45:28,560
oh yeah i'm a bit confused

00:45:25,760 --> 00:45:30,839
uh what is the benefit of having an

00:45:28,560 --> 00:45:33,520
async generator inside an asking

00:45:30,839 --> 00:45:36,480
iterator

00:45:33,520 --> 00:45:37,920
i don't really understand it from the

00:45:36,480 --> 00:45:40,240
question

00:45:37,920 --> 00:45:42,560
okay i'll give an example it will be

00:45:40,240 --> 00:45:42,560
best

00:45:45,119 --> 00:45:50,240
you can also end unmute yourself and

00:45:47,920 --> 00:45:50,240
talk

00:45:50,400 --> 00:46:01,839
yeah it will be great

00:46:05,520 --> 00:46:09,520
i i i know the feeling i have my kids in

00:46:08,319 --> 00:46:11,760
the other room and they're like

00:46:09,520 --> 00:46:14,319
screaming and running so that's why i'm

00:46:11,760 --> 00:46:17,680
muting myself from time to time

00:46:14,319 --> 00:46:21,359
yeah my my kid is sleeping right now

00:46:17,680 --> 00:46:21,359
you lucky guy yeah

00:46:21,839 --> 00:46:25,520
okay in the meantime you can take other

00:46:23,839 --> 00:46:28,960
questions okay

00:46:25,520 --> 00:46:32,319
but let me talk about uh so i think

00:46:28,960 --> 00:46:35,680
acurate results in generators are

00:46:32,319 --> 00:46:39,760
are basically uh you can think of it as

00:46:35,680 --> 00:46:44,160
synthetic synthetic sugar and

00:46:39,760 --> 00:46:44,160
they help simplify your

00:46:44,480 --> 00:46:52,400
picture first of all name with

00:46:49,280 --> 00:46:57,200
the thin

00:46:52,400 --> 00:46:59,359
frames and you can work with this also

00:46:57,200 --> 00:47:00,560
but i think uh inverters and i think

00:46:59,359 --> 00:47:03,599
generators

00:47:00,560 --> 00:47:07,359
make things uh very easy and

00:47:03,599 --> 00:47:10,400
uh much less plate and things like that

00:47:07,359 --> 00:47:25,839
and it's much much more intuitive

00:47:10,400 --> 00:47:25,839
to yield your results each time

00:47:29,280 --> 00:47:39,839
okay anyone has any other questions

00:47:42,160 --> 00:47:47,280
um i i will get back to mine uh it's

00:47:45,440 --> 00:47:51,520
it will be it will take some time until

00:47:47,280 --> 00:47:55,440
i do the code maybe i can ask gaddy to

00:47:51,520 --> 00:47:58,000
go back to the slides with the examples

00:47:55,440 --> 00:47:58,000
yeah sure

00:47:58,960 --> 00:48:02,400
i have to do the host again

00:48:03,200 --> 00:48:06,240
can you please make me the host again

00:48:05,040 --> 00:48:08,559
awesome

00:48:06,240 --> 00:48:08,559
sure

00:48:14,800 --> 00:48:17,440
all right

00:48:18,720 --> 00:48:23,599
which is insane yeah let's see

00:48:22,240 --> 00:48:25,599
you're talking about the astringent

00:48:23,599 --> 00:48:30,319
iterator the nasty generators

00:48:25,599 --> 00:48:30,319
yeah yeah okay so

00:48:30,400 --> 00:48:35,119
this is the generator right now you had

00:48:33,040 --> 00:48:38,400
an example where you had an

00:48:35,119 --> 00:48:43,760
uh is this generator you had it

00:48:38,400 --> 00:48:43,760
within an iterator at some point

00:48:46,400 --> 00:48:49,839
with an iterator

00:48:51,760 --> 00:48:55,680
i know no that's okay uh please go back

00:48:54,559 --> 00:48:58,800
to the other slide

00:48:55,680 --> 00:49:02,480
so what's the difference

00:48:58,800 --> 00:49:06,240
so what's the benefit of using

00:49:02,480 --> 00:49:10,079
uh the await in the for loop uh

00:49:06,240 --> 00:49:14,480
the parent wrapper function is already

00:49:10,079 --> 00:49:17,520
async yeah

00:49:14,480 --> 00:49:20,640
but think of it i think

00:49:17,520 --> 00:49:22,800
this will explain more uh

00:49:20,640 --> 00:49:24,800
this is just to demonstrate that you can

00:49:22,800 --> 00:49:27,440
combine those two i'm not saying

00:49:24,800 --> 00:49:28,720
you should do it every time but it's

00:49:27,440 --> 00:49:30,800
just a proof of

00:49:28,720 --> 00:49:33,119
of concept that you can combine async

00:49:30,800 --> 00:49:36,319
generators and asking iterators

00:49:33,119 --> 00:49:38,720
uh together and

00:49:36,319 --> 00:49:42,160
but i think we can agree that four

00:49:38,720 --> 00:49:45,440
weight off loop is very very nice

00:49:42,160 --> 00:49:47,680
nice syntax and

00:49:45,440 --> 00:49:48,640
again it's it's in syntactic sugar you

00:49:47,680 --> 00:49:52,559
can think of it

00:49:48,640 --> 00:49:55,040
as syntactic sugar and

00:49:52,559 --> 00:49:56,720
because you can you can work with

00:49:55,040 --> 00:49:57,280
streams without the four weight of look

00:49:56,720 --> 00:49:59,599
right

00:49:57,280 --> 00:50:00,640
because you can pass those chunks in the

00:49:59,599 --> 00:50:02,559
stream

00:50:00,640 --> 00:50:03,680
maybe if you don't want to work with

00:50:02,559 --> 00:50:05,839
streams and

00:50:03,680 --> 00:50:06,720
and just want to do something in this

00:50:05,839 --> 00:50:09,920
chunk

00:50:06,720 --> 00:50:12,079
it will be it's a useful thing and

00:50:09,920 --> 00:50:13,200
also in the last example that i showed

00:50:12,079 --> 00:50:17,200
you here

00:50:13,200 --> 00:50:19,920
um here i think it's really nice that

00:50:17,200 --> 00:50:23,599
you can iterate over

00:50:19,920 --> 00:50:26,960
this readable stream and doing the

00:50:23,599 --> 00:50:27,599
the yielding of the data uh the year

00:50:26,960 --> 00:50:30,640
thing is

00:50:27,599 --> 00:50:32,319
uh is uh okay i'm just

00:50:30,640 --> 00:50:35,520
i was just wondering what are the

00:50:32,319 --> 00:50:38,240
benefits of the weight

00:50:35,520 --> 00:50:40,559
because it's syntactic sugar over the

00:50:38,240 --> 00:50:43,839
promise api basically

00:50:40,559 --> 00:50:46,319
yeah and uh you already have

00:50:43,839 --> 00:50:48,400
a top-level promise object with the

00:50:46,319 --> 00:50:51,440
async

00:50:48,400 --> 00:50:53,760
that that's what i want that's what my

00:50:51,440 --> 00:50:55,599
question is basically

00:50:53,760 --> 00:50:58,480
would you have the same performance

00:50:55,599 --> 00:50:58,480
without the weight

00:50:58,640 --> 00:51:03,200
we only four a year without the weight

00:51:01,440 --> 00:51:05,240
yeah

00:51:03,200 --> 00:51:06,720
um i i don't think you can

00:51:05,240 --> 00:51:09,839
[Music]

00:51:06,720 --> 00:51:12,240
do it let me see

00:51:09,839 --> 00:51:14,079
we cannot yield without any weight we

00:51:12,240 --> 00:51:17,359
can right

00:51:14,079 --> 00:51:23,839
wait i have to see

00:51:17,359 --> 00:51:23,839
like if we're doing form

00:51:25,040 --> 00:51:28,880
yeah i don't think you can do a four of

00:51:27,760 --> 00:51:32,720
uh

00:51:28,880 --> 00:51:33,280
streams uh okay okay so that yeah that's

00:51:32,720 --> 00:51:35,599
the

00:51:33,280 --> 00:51:37,040
difference okay yeah but they are asking

00:51:35,599 --> 00:51:39,280
iterator objects

00:51:37,040 --> 00:51:40,240
uh by definition so you have to do the

00:51:39,280 --> 00:51:43,680
following

00:51:40,240 --> 00:51:48,960
otherwise you can't iterate over streams

00:51:43,680 --> 00:51:48,960
you are not regular generators

00:51:49,040 --> 00:51:55,839
i see and um from your

00:51:52,079 --> 00:51:59,760
uh code did you actually implement this

00:51:55,839 --> 00:52:04,640
in production uh

00:51:59,760 --> 00:52:08,079
the async iterator no no i didn't in my

00:52:04,640 --> 00:52:09,440
case uh because i have a pretty easy

00:52:08,079 --> 00:52:13,680
case right because

00:52:09,440 --> 00:52:15,440
i i just have three pipelines and

00:52:13,680 --> 00:52:17,359
and i'm just piping them together this

00:52:15,440 --> 00:52:20,880
is the code that i have in production

00:52:17,359 --> 00:52:22,960
basically i didn't use it

00:52:20,880 --> 00:52:24,240
but as i read more and more about

00:52:22,960 --> 00:52:27,760
streams

00:52:24,240 --> 00:52:33,839
i saw that the api keeps improving

00:52:27,760 --> 00:52:33,839
and it's really nice in my opinion

00:52:39,760 --> 00:52:42,160
all right

00:52:44,160 --> 00:52:47,839
any other questions

00:53:05,280 --> 00:53:09,040
i don't think so so uh thank you thank

00:53:08,079 --> 00:53:11,599
you very much

00:53:09,040 --> 00:53:12,839
gaddy for uh for showing us the insights

00:53:11,599 --> 00:53:16,400
of

00:53:12,839 --> 00:53:19,760
strings it was a pleasure to

00:53:16,400 --> 00:53:21,760
to have you and hopefully to see you

00:53:19,760 --> 00:53:23,520
again in other in other meetups if you

00:53:21,760 --> 00:53:27,599
want to present again

00:53:23,520 --> 00:53:30,160
just let me know sure

00:53:27,599 --> 00:53:30,720
thank you so much for for having me here

00:53:30,160 --> 00:53:34,640
at the

00:53:30,720 --> 00:53:37,040
really good time thank you all

00:53:34,640 --> 00:53:37,040
thank you

00:53:38,000 --> 00:53:43,359
take care thanks bye bye bye everyone

00:53:40,960 --> 00:53:46,559
have a good day and stay safe

00:53:43,359 --> 00:53:56,240
yeah bye bye thank you bye-bye

00:53:46,559 --> 00:53:59,920
thank you gadi bye-bye

00:53:56,240 --> 00:54:01,599
awesome can you make me host again yes

00:53:59,920 --> 00:54:03,599
i'm not sure if i have to close it or

00:54:01,599 --> 00:54:05,680
you have to close it just to make sure

00:54:03,599 --> 00:54:07,440
the recording it's going to take a few

00:54:05,680 --> 00:54:10,640
days and then we're going to

00:54:07,440 --> 00:54:14,559
post it we have colleague that he

00:54:10,640 --> 00:54:18,800
he has to cut the beginning and

00:54:14,559 --> 00:54:18,800
just leave the presentation okay

00:54:22,240 --> 00:54:26,480
okay thank you very much and it was it

00:54:24,960 --> 00:54:29,839
was really nice

00:54:26,480 --> 00:54:33,200
i i missed some good old coding and not

00:54:29,839 --> 00:54:36,160
just like uh like hands-on stuff

00:54:33,200 --> 00:54:38,079
somehow because some many many meetups

00:54:36,160 --> 00:54:39,280
you know just talk about like concepts

00:54:38,079 --> 00:54:42,319
and stuff but this

00:54:39,280 --> 00:54:45,280
like this is a solution for a problem

00:54:42,319 --> 00:54:47,040
yeah i try to show as much code as i can

00:54:45,280 --> 00:54:49,440
and do some demo

00:54:47,040 --> 00:54:50,400
yeah it's it's really useful yeah thank

00:54:49,440 --> 00:54:52,559
you you should uh

00:54:50,400 --> 00:54:54,720
actually if you have time and i think it

00:54:52,559 --> 00:54:58,000
would be really good if you could do a

00:54:54,720 --> 00:55:01,040
an article i think would really

00:54:58,000 --> 00:55:01,520
really work if you have one yeah i want

00:55:01,040 --> 00:55:04,559
to do

00:55:01,520 --> 00:55:07,359
some sort of article about it but it

00:55:04,559 --> 00:55:08,240
takes time yeah i know but it's really

00:55:07,359 --> 00:55:11,040
nice and it

00:55:08,240 --> 00:55:12,559
really fixes a problem that users and

00:55:11,040 --> 00:55:14,400
many people have it and

00:55:12,559 --> 00:55:16,000
you found the solution and i think it's

00:55:14,400 --> 00:55:19,280
really useful

00:55:16,000 --> 00:55:21,119
yeah yeah i want to write more but

00:55:19,280 --> 00:55:24,079
i just said i don't have time to it yet

00:55:21,119 --> 00:55:27,040
yeah i know

00:55:24,079 --> 00:55:27,040
you got this problem

00:55:27,280 --> 00:55:35,839
yeah thank you

00:55:30,640 --> 00:55:35,839

YouTube URL: https://www.youtube.com/watch?v=aflayity_mk


