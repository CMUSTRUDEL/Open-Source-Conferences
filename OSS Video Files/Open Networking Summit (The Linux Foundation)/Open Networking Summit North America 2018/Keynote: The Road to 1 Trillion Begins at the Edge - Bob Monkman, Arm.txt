Title: Keynote: The Road to 1 Trillion Begins at the Edge - Bob Monkman, Arm
Publication date: 2018-03-29
Playlist: Open Networking Summit North America 2018
Description: 
	Keynote: The Road to 1 Trillion Begins at the Edge - Bob Monkman, Director, Software Strategy and Ecosystem Programs, Network Infrastructure, Arm

Today’s cloud is not built to support the demands of tomorrow’s network infrastructure, where the edge of the network is lined with up to 1 trillion intelligent devices by 2035, many requiring very low latency and efficient acceleration. A massive transformation in network infrastructure is underway and the Arm ecosystem will play a prominent role in the realization of this vision, bringing unique and compelling solutions based on lower TCO, efficiencies in compute density, performance/watt, greater scalability, and security in the face of challenging industry goals for virtualization and 5G metrics. Join us for a comprehensive and insightful view into the approach taken by the Arm ecosystem to deliver efficient, heterogeneous, scale-out architecture for next-generation infrastructure support AI/AR/ML use cases and more. Attendees will walk away with an appreciation for the fundamental Arm value proposition, our contribution and initiatives within the Linux Foundation Open Networking community, proof points and progress to date in enabling this vision.

About Bob Monkman
Bob Monkman is part of the Infrastructure Business Line at Arm, based in San Jose, CA and focused on networking software strategy and ecosystem programs. Bob oversees Arm’s participation in the Linux Foundation Networking projects, ensuring multi-architecture support with the Arm server ecosystem and holds a seat on the LFN Board and the Marketing Advisory Committee. Bob also drives engagement and participation in Linaro, ONF/CORD, DPDK and other relevant industry consortia.

Bob has been active in the telecommunications industry for over 30 years, starting as a HW/SW engineer for Tellabs after obtaining a BSEE degree from the University of Illinois, Chicago. Bob then moved into the commercial software arena in 1992, holding a wide range of technical, product management, strategic marketing and business development roles at Ready Systems, Mentor Graphics, Wind River Systems, MontaVista Software, Penguin Computing, QNX Software/Blackberry before joining Arm in October 2012.
Captions: 
	00:00:00,030 --> 00:00:04,049
thank you very much sharpen I'm very

00:00:01,380 --> 00:00:07,080
pleased to be speaking to you today I

00:00:04,049 --> 00:00:09,240
wanted as arpan said I want to give you

00:00:07,080 --> 00:00:12,570
an overview of who we are and what we're

00:00:09,240 --> 00:00:15,990
doing in this space and what value that

00:00:12,570 --> 00:00:18,359
we bring and I'd like to say that we you

00:00:15,990 --> 00:00:20,130
know we didn't invent the concept of nfe

00:00:18,359 --> 00:00:21,900
but we make it more efficient and

00:00:20,130 --> 00:00:24,269
hopefully at the end of this talk you're

00:00:21,900 --> 00:00:26,519
going to really get a sense of what we

00:00:24,269 --> 00:00:28,019
mean by that and I want to and I want to

00:00:26,519 --> 00:00:32,820
put that in the context of sort of the

00:00:28,019 --> 00:00:38,550
big picture here just get that title

00:00:32,820 --> 00:00:41,730
slide so the the growth of the ARM

00:00:38,550 --> 00:00:45,059
architecture in the industry is rapidly

00:00:41,730 --> 00:00:48,480
increasing as you can see here it took

00:00:45,059 --> 00:00:51,719
us nearly 22 years to ship 50 billion

00:00:48,480 --> 00:00:52,800
devices based on arm and again if you're

00:00:51,719 --> 00:00:56,430
not familiar with the ARM architecture

00:00:52,800 --> 00:00:59,309
we have over 400 partners that build

00:00:56,430 --> 00:01:03,329
chips we don't make chips we make the IP

00:00:59,309 --> 00:01:07,080
and over 400 partners make chips for all

00:01:03,329 --> 00:01:11,159
sorts of markets and so but that is

00:01:07,080 --> 00:01:13,080
really rapidly increasing into this next

00:01:11,159 --> 00:01:14,400
decade you can see the growth that's

00:01:13,080 --> 00:01:18,119
that's coming here everything from

00:01:14,400 --> 00:01:19,860
energy harvesting sensors to servers and

00:01:18,119 --> 00:01:21,920
you're going to be able to see some of

00:01:19,860 --> 00:01:29,159
that Hardware on the floor today

00:01:21,920 --> 00:01:30,509
now our vision is that by 2035 we

00:01:29,159 --> 00:01:34,590
believe that there's going to be one

00:01:30,509 --> 00:01:38,159
trillion intelligent devices connected

00:01:34,590 --> 00:01:43,259
to the network and we also believe that

00:01:38,159 --> 00:01:47,100
by 2035 roughly speaking the sort of the

00:01:43,259 --> 00:01:49,409
the the market opportunity in that year

00:01:47,100 --> 00:01:53,840
will be about one trillion dollars for

00:01:49,409 --> 00:01:57,450
IOT devices an arm expects to play a

00:01:53,840 --> 00:02:01,380
significant role in delivering on that

00:01:57,450 --> 00:02:05,790
vision and being implemented in those

00:02:01,380 --> 00:02:09,840
one trillion devices and we say that the

00:02:05,790 --> 00:02:13,319
infrastructure necessary to support all

00:02:09,840 --> 00:02:14,100
of these super intelligent devices is

00:02:13,319 --> 00:02:16,040
going to

00:02:14,100 --> 00:02:18,660
have to be different than it is today

00:02:16,040 --> 00:02:21,600
it's going to be it's going to have to

00:02:18,660 --> 00:02:25,020
be highly efficient space efficient

00:02:21,600 --> 00:02:31,560
power efficient dollar efficient and

00:02:25,020 --> 00:02:33,510
that's what we do before I move into the

00:02:31,560 --> 00:02:37,050
next slides I just wanted to in case you

00:02:33,510 --> 00:02:40,050
missed it from yesterday we generate a

00:02:37,050 --> 00:02:41,520
lot of IP we generate cores we design

00:02:40,050 --> 00:02:43,590
cores we delight we deliver

00:02:41,520 --> 00:02:46,200
interconnects memory controllers all

00:02:43,590 --> 00:02:48,270
sorts of different IP a couple in last

00:02:46,200 --> 00:02:50,970
month we announced project Trillium

00:02:48,270 --> 00:02:54,800
where we're delivering a whole new suite

00:02:50,970 --> 00:02:57,840
of IP for highly efficient machine

00:02:54,800 --> 00:03:00,960
learning and object detection processor

00:02:57,840 --> 00:03:02,910
technology that can be embedded into the

00:03:00,960 --> 00:03:05,580
devices of the future and we've talked a

00:03:02,910 --> 00:03:07,320
lot about deep learning machine learning

00:03:05,580 --> 00:03:10,020
and this is an open program and so

00:03:07,320 --> 00:03:13,320
yesterday at the the GPU technology

00:03:10,020 --> 00:03:15,770
conference the CEO of Nvidia announced

00:03:13,320 --> 00:03:19,100
that they're going to be bringing their

00:03:15,770 --> 00:03:23,100
open-source NV de la technology IP

00:03:19,100 --> 00:03:25,620
contributing into the project Trillium

00:03:23,100 --> 00:03:26,850
program to add value and I don't know if

00:03:25,620 --> 00:03:28,500
it's one of the points that we make

00:03:26,850 --> 00:03:30,750
about the program is that it's very open

00:03:28,500 --> 00:03:34,560
for any anyone to bring in their unique

00:03:30,750 --> 00:03:38,040
IP and really help deliver highly

00:03:34,560 --> 00:03:40,380
efficient highly capable accelerated AI

00:03:38,040 --> 00:03:41,700
machine learning deep learning and this

00:03:40,380 --> 00:03:44,250
sort of thing so this is a really

00:03:41,700 --> 00:03:47,100
exciting announcement it was it glad to

00:03:44,250 --> 00:03:52,320
see that so let's talk a little bit more

00:03:47,100 --> 00:03:57,030
about this efficiency so our view is

00:03:52,320 --> 00:04:01,350
that with the race to 5g 2020 is going

00:03:57,030 --> 00:04:03,120
to need a much more efficient telco

00:04:01,350 --> 00:04:05,910
cloud infrastructure and we use the term

00:04:03,120 --> 00:04:07,830
intelligent flexible cloud I'm going to

00:04:05,910 --> 00:04:10,020
talk more about what that means on the

00:04:07,830 --> 00:04:11,730
next slide but it's not an unfamiliar

00:04:10,020 --> 00:04:14,250
concept a lot of people are default

00:04:11,730 --> 00:04:17,670
computing and other monikers other

00:04:14,250 --> 00:04:20,040
approaches the idea is putting that

00:04:17,670 --> 00:04:22,500
intelligence deeper into the network

00:04:20,040 --> 00:04:24,780
driving it to the edge where you can get

00:04:22,500 --> 00:04:27,600
that quality of experience where you can

00:04:24,780 --> 00:04:33,830
get that efficiency that's required

00:04:27,600 --> 00:04:36,690
and for armed I talked about efficiency

00:04:33,830 --> 00:04:39,000
space efficiency dollar efficiency power

00:04:36,690 --> 00:04:41,970
efficiency the compute density we

00:04:39,000 --> 00:04:44,820
believe that by 2020 we're going to be

00:04:41,970 --> 00:04:47,630
able to deliver machines that deliver

00:04:44,820 --> 00:04:50,850
three times the compute density of

00:04:47,630 --> 00:04:53,430
conventional servers and today even

00:04:50,850 --> 00:04:55,290
today we have plenty of examples one

00:04:53,430 --> 00:04:58,110
that was published last month in on

00:04:55,290 --> 00:05:00,240
Forbes where we're delivering north of

00:04:58,110 --> 00:05:03,120
2x compute density what does that mean

00:05:00,240 --> 00:05:04,950
that means it starts at the very lowest

00:05:03,120 --> 00:05:08,700
silicon layer where we can just

00:05:04,950 --> 00:05:12,510
fundamentally lay down more cores in a

00:05:08,700 --> 00:05:14,550
smaller area and it manifests itself in

00:05:12,510 --> 00:05:18,060
the server level where you can

00:05:14,550 --> 00:05:21,320
essentially get twice the consistently

00:05:18,060 --> 00:05:25,230
twice the compute density out of a 1u

00:05:21,320 --> 00:05:27,780
server and our view is when we look at

00:05:25,230 --> 00:05:31,650
the challenges of that the network

00:05:27,780 --> 00:05:33,930
operators face they've got physical

00:05:31,650 --> 00:05:35,790
buildings central offices they still

00:05:33,930 --> 00:05:38,430
have to maintain while they generate new

00:05:35,790 --> 00:05:41,430
point of point of presence clusters and

00:05:38,430 --> 00:05:43,680
and new new intelligence out at the edge

00:05:41,430 --> 00:05:46,110
they still have to reuse these existing

00:05:43,680 --> 00:05:48,440
facilities they've got fixed real estate

00:05:46,110 --> 00:05:50,940
they've got a fixed power envelope and

00:05:48,440 --> 00:05:55,140
fundamentally we're going to help them

00:05:50,940 --> 00:05:57,870
pack more compute capacity into that

00:05:55,140 --> 00:05:59,550
existing space either at the same power

00:05:57,870 --> 00:06:01,530
or at lower power so you can sort of

00:05:59,550 --> 00:06:04,020
balance that as you want it and just

00:06:01,530 --> 00:06:07,110
want to see and as you'll see more

00:06:04,020 --> 00:06:09,930
detail in the next slide a lot of what

00:06:07,110 --> 00:06:12,150
the innovation and value add of the arm

00:06:09,930 --> 00:06:17,180
partners the over 400 arm partners

00:06:12,150 --> 00:06:23,510
deliver is they take our IP and they add

00:06:17,180 --> 00:06:25,470
GPUs DSPs FPGAs other sort of

00:06:23,510 --> 00:06:28,020
optimization for traffic management

00:06:25,470 --> 00:06:30,510
packet processing graphics machine

00:06:28,020 --> 00:06:32,970
learning they add that IP to what we

00:06:30,510 --> 00:06:35,669
deliver and create workload optimized

00:06:32,970 --> 00:06:40,200
SOC s that's the whole basis of our

00:06:35,669 --> 00:06:41,490
ecosystem and when they do that we've

00:06:40,200 --> 00:06:43,470
got plenty of examples

00:06:41,490 --> 00:06:46,740
you see some of the numbers here of the

00:06:43,470 --> 00:06:48,750
kinds of efficiencies the kind of

00:06:46,740 --> 00:06:50,849
acceleration the kind of compute density

00:06:48,750 --> 00:06:52,349
that you can get from these sorts of

00:06:50,849 --> 00:06:55,729
solutions so let's look at it a little

00:06:52,349 --> 00:07:00,270
bit more closely as to how we envision

00:06:55,729 --> 00:07:03,710
the network looking in this intelligent

00:07:00,270 --> 00:07:06,030
flexible cloud so the idea here is again

00:07:03,710 --> 00:07:09,270
we're going to need to push more

00:07:06,030 --> 00:07:13,020
intelligent out towards the edge and the

00:07:09,270 --> 00:07:16,789
arm ecosystem is uniquely positioned to

00:07:13,020 --> 00:07:19,949
deliver extraordinary value in this

00:07:16,789 --> 00:07:21,900
migration because again the whole the

00:07:19,949 --> 00:07:25,909
whole idea the whole business model of

00:07:21,900 --> 00:07:29,690
arm is that our partners put together

00:07:25,909 --> 00:07:33,750
the optimal combinations of compute

00:07:29,690 --> 00:07:37,380
storage and acceleration into workload

00:07:33,750 --> 00:07:39,090
optimized SOC s for running the

00:07:37,380 --> 00:07:41,310
workloads at different points in the

00:07:39,090 --> 00:07:43,710
network and they're all competing and

00:07:41,310 --> 00:07:47,310
delivering flexibility and choice in

00:07:43,710 --> 00:07:52,680
that entire range from the sensors to

00:07:47,310 --> 00:07:55,770
the servers in the cloud and so as we go

00:07:52,680 --> 00:07:59,900
towards this race towards 5g where we

00:07:55,770 --> 00:08:04,080
have phenomenal demands on capacity on

00:07:59,900 --> 00:08:07,530
latency you know we're seeing five to 20

00:08:04,080 --> 00:08:09,570
millisecond latency requirements you're

00:08:07,530 --> 00:08:11,819
going to we believe that the future of

00:08:09,570 --> 00:08:14,430
compute is going to have to be secure

00:08:11,819 --> 00:08:18,199
and highly efficient we're not going to

00:08:14,430 --> 00:08:20,400
be able to realize these kinds of

00:08:18,199 --> 00:08:23,520
latencies these kinds of qualities

00:08:20,400 --> 00:08:26,370
experiences kind of capacity with just

00:08:23,520 --> 00:08:28,889
taking only conventional solutions the

00:08:26,370 --> 00:08:32,550
future of network infrastructure cloud

00:08:28,889 --> 00:08:36,270
infrastructure in this world hey I am L

00:08:32,550 --> 00:08:38,640
applications is heterogeneous and it's

00:08:36,270 --> 00:08:42,630
going to be workload optimizing arm is

00:08:38,640 --> 00:08:45,209
going to be delivering this highly

00:08:42,630 --> 00:08:47,399
flexible highly efficient intellectual

00:08:45,209 --> 00:08:51,420
property along with our partners that

00:08:47,399 --> 00:08:54,690
that help this vision be realized and I

00:08:51,420 --> 00:08:55,320
were to ask me to sort of give some some

00:08:54,690 --> 00:08:57,630
use cases

00:08:55,320 --> 00:08:59,670
and some examples of this and so I'm

00:08:57,630 --> 00:09:02,790
gonna I'm going to go into some details

00:08:59,670 --> 00:09:08,910
of how we're actually working on this

00:09:02,790 --> 00:09:10,860
today and so we are a committed member

00:09:08,910 --> 00:09:12,740
of Linux Foundation Network we've been

00:09:10,860 --> 00:09:16,080
involved in many of these projects and

00:09:12,740 --> 00:09:17,970
growing in these projects and mostly

00:09:16,080 --> 00:09:20,430
what we're doing is first of all making

00:09:17,970 --> 00:09:22,500
sure that we're in the CI CD loop all

00:09:20,430 --> 00:09:25,170
the frameworks that the operators are

00:09:22,500 --> 00:09:27,150
asking for the community the

00:09:25,170 --> 00:09:29,310
applications to run on we want to make

00:09:27,150 --> 00:09:32,430
sure that they're available stable and

00:09:29,310 --> 00:09:34,590
highly optimized for arm we we do a lot

00:09:32,430 --> 00:09:36,390
of special focus on helping the

00:09:34,590 --> 00:09:40,260
community make sure that everything is

00:09:36,390 --> 00:09:42,060
cleanly multi architecture we do a lot

00:09:40,260 --> 00:09:44,610
of work in the data plane optimization

00:09:42,060 --> 00:09:47,250
and we're doing a lot of work we're

00:09:44,610 --> 00:09:49,650
actually actually driving in an in phyto

00:09:47,250 --> 00:09:51,990
and own app and open Fe we're driving

00:09:49,650 --> 00:09:55,380
and participating in several projects on

00:09:51,990 --> 00:09:59,490
the whole movement to containerized nfe

00:09:55,380 --> 00:10:03,090
kubernetes docker we want to explore and

00:09:59,490 --> 00:10:06,000
assess and demonstrate what are the

00:10:03,090 --> 00:10:08,070
efficiencies of using this cloud native

00:10:06,000 --> 00:10:10,020
going to this cloud native approach and

00:10:08,070 --> 00:10:11,400
so I've got some examples of that and

00:10:10,020 --> 00:10:13,710
you can you've seen it if you came to

00:10:11,400 --> 00:10:16,500
our mini summit yesterday you've got

00:10:13,710 --> 00:10:18,500
some deep dives on some of that but I

00:10:16,500 --> 00:10:21,840
want to go through a few use case

00:10:18,500 --> 00:10:24,690
examples of exactly what we're doing so

00:10:21,840 --> 00:10:27,780
we drive the the product we know pian if

00:10:24,690 --> 00:10:29,490
we we call auto for automation and it's

00:10:27,780 --> 00:10:32,790
really just taking some select

00:10:29,490 --> 00:10:36,000
components of own app so that we can

00:10:32,790 --> 00:10:39,060
manage the infrastructure and manage the

00:10:36,000 --> 00:10:41,250
lifecycle of VN apps now we support we

00:10:39,060 --> 00:10:43,920
know we're working on OpenStack and heat

00:10:41,250 --> 00:10:47,520
with VMs but we have a particular focus

00:10:43,920 --> 00:10:49,920
on kubernetes helm and some of these

00:10:47,520 --> 00:10:53,400
technologies that allow us to get really

00:10:49,920 --> 00:10:56,370
efficient lifecycle management of cloud

00:10:53,400 --> 00:10:59,100
native VN EPS and we've put together

00:10:56,370 --> 00:11:03,090
some use cases for edge cloud for

00:10:59,100 --> 00:11:05,730
enterprise VC PE and resiliency failover

00:11:03,090 --> 00:11:08,220
managing all of this so we're we're

00:11:05,730 --> 00:11:08,940
working with a wide range of ecosystem

00:11:08,220 --> 00:11:13,770
partners our

00:11:08,940 --> 00:11:16,830
creators OMS is fees and we are showing

00:11:13,770 --> 00:11:19,050
how this can work between the two

00:11:16,830 --> 00:11:20,700
projects how can we manage these life

00:11:19,050 --> 00:11:23,340
cycles we've got really good broad

00:11:20,700 --> 00:11:24,990
participation in that project so one of

00:11:23,340 --> 00:11:28,920
the examples of where we're driving

00:11:24,990 --> 00:11:31,410
these efficient concepts in our booth

00:11:28,920 --> 00:11:34,140
near the registration desk we're showing

00:11:31,410 --> 00:11:36,530
a reference design for a highly

00:11:34,140 --> 00:11:40,470
efficient highly cost-effective

00:11:36,530 --> 00:11:43,620
Universal CPE solution we're working

00:11:40,470 --> 00:11:45,030
with telco systems and NXP and some of

00:11:43,620 --> 00:11:48,320
the vnf vendors that you see in the

00:11:45,030 --> 00:11:52,110
slide and a white box vendor to deliver

00:11:48,320 --> 00:11:54,410
compelling value for this kind of edge

00:11:52,110 --> 00:11:57,540
solution this customer premise type

00:11:54,410 --> 00:12:00,390
application here and I don't want to

00:11:57,540 --> 00:12:03,690
belabor the the details of this so much

00:12:00,390 --> 00:12:04,440
as I want to emphasize or why are they

00:12:03,690 --> 00:12:06,810
choosing arm

00:12:04,440 --> 00:12:10,260
what did what does telco systems in

00:12:06,810 --> 00:12:13,290
there and their desire to diversify and

00:12:10,260 --> 00:12:16,290
add some unique TCO benefits to the

00:12:13,290 --> 00:12:18,300
operators what do they see what are they

00:12:16,290 --> 00:12:21,240
getting out of working with an ARM based

00:12:18,300 --> 00:12:24,600
SOC well again as I talked about earlier

00:12:21,240 --> 00:12:26,730
we consistently deliver compute density

00:12:24,600 --> 00:12:30,390
lower power better performance per watt

00:12:26,730 --> 00:12:32,610
so these these offload engines for

00:12:30,390 --> 00:12:34,500
offloading OBS and how their packet

00:12:32,610 --> 00:12:36,780
processing these things are being

00:12:34,500 --> 00:12:39,420
leveraged and so the TCO value

00:12:36,780 --> 00:12:43,050
proposition the security equation is

00:12:39,420 --> 00:12:44,990
just better and so they feel like in

00:12:43,050 --> 00:12:47,400
this case with the NXP Semiconductors

00:12:44,990 --> 00:12:49,010
example they've built they're gonna

00:12:47,400 --> 00:12:51,720
deliver they're gonna deliver an

00:12:49,010 --> 00:12:54,210
alternative and option for these kinds

00:12:51,720 --> 00:12:56,790
of devices that's going to be more

00:12:54,210 --> 00:13:00,390
compelling from a TCO standpoint another

00:12:56,790 --> 00:13:02,400
example this was a really cool one we

00:13:00,390 --> 00:13:07,230
participated in the Mobile World

00:13:02,400 --> 00:13:12,810
Congress in a chord demo with onf very

00:13:07,230 --> 00:13:15,030
complete end-to-end 5g edge cloud and in

00:13:12,810 --> 00:13:17,339
infrastructure solution or demonstration

00:13:15,030 --> 00:13:18,960
and you can see here it's got all of the

00:13:17,339 --> 00:13:20,970
core infrastructure it's got the own

00:13:18,960 --> 00:13:22,410
house infrastructure in it there was a

00:13:20,970 --> 00:13:24,209
lot of different use cases

00:13:22,410 --> 00:13:26,879
they had a video streaming slice they

00:13:24,209 --> 00:13:28,829
had a facial recognition slice that's by

00:13:26,879 --> 00:13:32,040
the waist available and being shown here

00:13:28,829 --> 00:13:34,110
again at ons so it's over in the onf

00:13:32,040 --> 00:13:36,329
booth booth number Ted but I guess

00:13:34,110 --> 00:13:39,240
they're not numbered we're particularly

00:13:36,329 --> 00:13:40,800
focused on I mean we can run all the

00:13:39,240 --> 00:13:43,139
corn infrastructure but in this demo

00:13:40,800 --> 00:13:46,740
we're doing the facial recognition part

00:13:43,139 --> 00:13:49,529
and we're using arm plus GPU plus

00:13:46,740 --> 00:13:50,910
storage to show I mean you could do that

00:13:49,529 --> 00:13:53,250
a number of ways you can take a

00:13:50,910 --> 00:13:56,939
conventional server and you could take

00:13:53,250 --> 00:13:59,370
an expensive PCI card that's highly

00:13:56,939 --> 00:14:01,439
capable and you can plug that into that

00:13:59,370 --> 00:14:04,230
server and you can do it that way but it

00:14:01,439 --> 00:14:06,839
is not the most cost efficient cost

00:14:04,230 --> 00:14:10,949
efficient power efficient way to do it

00:14:06,839 --> 00:14:15,750
we just wanted to demonstrate another

00:14:10,949 --> 00:14:19,199
way we built our partner here built an

00:14:15,750 --> 00:14:22,079
amazing prototype server to demonstrate

00:14:19,199 --> 00:14:26,850
if you think outside of the conventional

00:14:22,079 --> 00:14:28,889
box and do something different not only

00:14:26,850 --> 00:14:31,259
with the software but with the hardware

00:14:28,889 --> 00:14:33,540
you can really get some tremendous

00:14:31,259 --> 00:14:35,430
advantages and and we want to

00:14:33,540 --> 00:14:38,459
demonstrate how thinking outside of that

00:14:35,430 --> 00:14:41,009
box and how leveraging the efficiency of

00:14:38,459 --> 00:14:43,259
the arm ecosystem the hundreds of

00:14:41,009 --> 00:14:45,149
companies that are delivering SOC s and

00:14:43,259 --> 00:14:47,370
doing the software in a little bit

00:14:45,149 --> 00:14:49,730
different way you can really do this so

00:14:47,370 --> 00:14:53,310
one of the key things about this was we

00:14:49,730 --> 00:14:54,959
essentially he's got really some small

00:14:53,310 --> 00:14:57,180
examples of these little micro servers

00:14:54,959 --> 00:14:59,370
out there in the bench but he also built

00:14:57,180 --> 00:15:01,920
this full 1u enclosure with all

00:14:59,370 --> 00:15:03,930
commercial off-the-shelf components to

00:15:01,920 --> 00:15:07,589
demonstrate how you could leverage a sea

00:15:03,930 --> 00:15:11,069
of arm plus GPU plus storage put it in a

00:15:07,589 --> 00:15:12,870
1u rack with all cots components and get

00:15:11,069 --> 00:15:15,870
a server that when compared to a

00:15:12,870 --> 00:15:20,600
conventional solution is four point four

00:15:15,870 --> 00:15:24,689
times the performance 30% the power and

00:15:20,600 --> 00:15:26,519
40% of the cost with a handmade solution

00:15:24,689 --> 00:15:29,279
so you get incredible sort of

00:15:26,519 --> 00:15:30,990
performance per dollar numbers and what

00:15:29,279 --> 00:15:34,319
we're but what we're doing here is we're

00:15:30,990 --> 00:15:36,360
we're also proving another point we did

00:15:34,319 --> 00:15:39,240
the slice in such a way that

00:15:36,360 --> 00:15:43,380
we don't go through a conventional PCI

00:15:39,240 --> 00:15:46,010
card through a big host server and then

00:15:43,380 --> 00:15:49,820
try and distribute and load balance

00:15:46,010 --> 00:15:54,620
these images we're basically taking four

00:15:49,820 --> 00:15:58,160
giggling forward four megabyte photos

00:15:54,620 --> 00:16:02,400
we're breaking them down into a 200 byte

00:15:58,160 --> 00:16:04,740
sort of metadata and we're doing pattern

00:16:02,400 --> 00:16:07,710
matching casting it off to the GPU but

00:16:04,740 --> 00:16:09,120
we don't go through a host server and go

00:16:07,710 --> 00:16:11,100
through all of the infrastructure

00:16:09,120 --> 00:16:13,920
getting rid of all the benefit of

00:16:11,100 --> 00:16:15,840
getting right to the computation you

00:16:13,920 --> 00:16:17,670
could have hundreds or thousands or

00:16:15,840 --> 00:16:20,340
hundreds of thousands in a real system

00:16:17,670 --> 00:16:22,890
of these images coming in and we

00:16:20,340 --> 00:16:25,110
basically have designed it such that we

00:16:22,890 --> 00:16:28,680
take it we drive it right to where the

00:16:25,110 --> 00:16:31,080
storage arm and GPU processors are we do

00:16:28,680 --> 00:16:33,870
the pattern matching matching and give

00:16:31,080 --> 00:16:37,110
the result with incredibly low latency

00:16:33,870 --> 00:16:41,430
and we're doing it for on these little

00:16:37,110 --> 00:16:42,960
servers that are basically two watts to

00:16:41,430 --> 00:16:45,270
or two four watts on each one of them

00:16:42,960 --> 00:16:48,180
we're just trying to show what can be

00:16:45,270 --> 00:16:50,550
done again as you if you want to think

00:16:48,180 --> 00:16:53,250
outside the box and choose to get better

00:16:50,550 --> 00:16:56,790
efficiency get better TCO so you can see

00:16:53,250 --> 00:17:00,210
this demo in the own F booth and it's a

00:16:56,790 --> 00:17:03,630
really an incredible thing another

00:17:00,210 --> 00:17:06,930
example of where we wanted to sort of

00:17:03,630 --> 00:17:08,550
demonstrate what can be done here is you

00:17:06,930 --> 00:17:10,830
know what we've been involved in the OPN

00:17:08,550 --> 00:17:15,330
fe project for for since the beginning

00:17:10,830 --> 00:17:17,370
and we do have conventional six node

00:17:15,330 --> 00:17:19,850
wracked pods around the world in

00:17:17,370 --> 00:17:23,430
operator labs where people are doing

00:17:19,850 --> 00:17:25,290
pocs and lab trials and we support the

00:17:23,430 --> 00:17:27,150
the end of the building of the software

00:17:25,290 --> 00:17:30,900
but we wanted to demonstrate what if you

00:17:27,150 --> 00:17:32,760
could take really small cheap two

00:17:30,900 --> 00:17:37,050
hundred three hundred dollar boards arm

00:17:32,760 --> 00:17:38,970
boards with ten gig interfaces and you

00:17:37,050 --> 00:17:43,380
know a modest amount of memory and put

00:17:38,970 --> 00:17:45,810
it into a one cubic foot package and run

00:17:43,380 --> 00:17:48,450
it as a full Farrow spot well we did

00:17:45,810 --> 00:17:50,190
that we demonstrated this in Beijing

00:17:48,450 --> 00:17:54,060
last summer and we've brought it here

00:17:50,190 --> 00:17:55,740
again today and again the idea is we

00:17:54,060 --> 00:17:59,130
wanted to show that if you think outside

00:17:55,740 --> 00:18:03,770
the box you can actually do quite a bit

00:17:59,130 --> 00:18:07,440
with really low-power low-cost highly

00:18:03,770 --> 00:18:09,450
space efficient systems by leveraging

00:18:07,440 --> 00:18:15,840
the power of the RM ecosystem in the

00:18:09,450 --> 00:18:17,970
innovation there so in this you know

00:18:15,840 --> 00:18:19,590
sort of short overview I'm hoping that

00:18:17,970 --> 00:18:23,790
you're seeing the point that I'm trying

00:18:19,590 --> 00:18:29,400
to make arm is committed to delivering

00:18:23,790 --> 00:18:32,730
the the the sort of hardened and

00:18:29,400 --> 00:18:35,760
optimized frameworks that the operators

00:18:32,730 --> 00:18:37,830
expect for vnfs to run on we're having

00:18:35,760 --> 00:18:40,950
we're putting a great deal of focus on

00:18:37,830 --> 00:18:44,310
how do we exploit the unique space

00:18:40,950 --> 00:18:47,010
efficiency power efficiency and dollar

00:18:44,310 --> 00:18:51,270
efficiency of the arm ecosystem to

00:18:47,010 --> 00:18:53,640
deliver compelling value as we get to go

00:18:51,270 --> 00:18:56,880
to this race to 5g and all these new

00:18:53,640 --> 00:18:59,400
applications that are going to be lining

00:18:56,880 --> 00:19:02,250
the edge of the network with traffic we

00:18:59,400 --> 00:19:05,040
want it's going to have to be more

00:19:02,250 --> 00:19:07,950
efficiently done and we can deliver that

00:19:05,040 --> 00:19:10,320
it's what we do so please come and visit

00:19:07,950 --> 00:19:13,380
us in our booth come and see some of the

00:19:10,320 --> 00:19:15,290
demos that I've pointed to and I thank

00:19:13,380 --> 00:19:21,690
you for your time

00:19:15,290 --> 00:19:21,690

YouTube URL: https://www.youtube.com/watch?v=nClIt6jrZk0


