Title: Bringing Realtime Optimizations to Edge Deployments - Renu N. Navale & Prakash Kartha, Intel
Publication date: 2020-10-28
Playlist: Open Networking & Edge Summit 2020
Description: 
	Bringing Realtime Optimizations to Edge Deployments - Renu N. Navale & Prakash Kartha, Intel
Captions: 
	00:00:07,120 --> 00:00:11,679
hello everyone

00:00:08,720 --> 00:00:13,759
we're excited to be here at o nes

00:00:11,679 --> 00:00:16,880
september 2020.

00:00:13,759 --> 00:00:19,119
my name is renu naplay and i'm vpn gm

00:00:16,880 --> 00:00:20,000
of the edge computing and ecosystem

00:00:19,119 --> 00:00:23,039
enabling

00:00:20,000 --> 00:00:25,119
division at intel with me

00:00:23,039 --> 00:00:27,840
i have prakash kartha who is the

00:00:25,119 --> 00:00:28,880
director of edge services segment at

00:00:27,840 --> 00:00:30,960
intel

00:00:28,880 --> 00:00:32,239
together we're going to be presenting to

00:00:30,960 --> 00:00:34,160
you how

00:00:32,239 --> 00:00:35,360
we're bringing in real-time

00:00:34,160 --> 00:00:38,559
optimizations

00:00:35,360 --> 00:00:38,559
to edge deployments

00:00:38,879 --> 00:00:44,399
now the whole industry is shifting

00:00:41,600 --> 00:00:47,200
massively towards edge computing

00:00:44,399 --> 00:00:49,200
the reasons for this are multi-fold

00:00:47,200 --> 00:00:51,280
there's an explosion of data

00:00:49,200 --> 00:00:53,920
across different types of devices and

00:00:51,280 --> 00:00:56,000
different types of you know locations

00:00:53,920 --> 00:00:58,160
there is the rise of artificial

00:00:56,000 --> 00:01:01,199
intelligence and analytics

00:00:58,160 --> 00:01:04,159
as well as the advent of 5g

00:01:01,199 --> 00:01:06,799
all of this is propelling the industry

00:01:04,159 --> 00:01:09,920
massively towards edge computing

00:01:06,799 --> 00:01:13,680
and some of the underlying drivers are

00:01:09,920 --> 00:01:14,799
low latency high bandwidth end-to-end

00:01:13,680 --> 00:01:17,520
security

00:01:14,799 --> 00:01:18,960
as well as seamless and frictionless

00:01:17,520 --> 00:01:22,159
connectivity

00:01:18,960 --> 00:01:22,960
almost every business or enterprise or

00:01:22,159 --> 00:01:24,880
industry

00:01:22,960 --> 00:01:27,360
is looking at how they can take

00:01:24,880 --> 00:01:30,560
advantage of edge computing

00:01:27,360 --> 00:01:33,360
to derive you know actionable insights

00:01:30,560 --> 00:01:34,320
from the data so they can then impact

00:01:33,360 --> 00:01:39,840
their own

00:01:34,320 --> 00:01:42,159
business or attribute value to their own

00:01:39,840 --> 00:01:44,079
intel is looking at edge computing from

00:01:42,159 --> 00:01:46,479
two different directions

00:01:44,079 --> 00:01:48,720
on from one direction we are looking at

00:01:46,479 --> 00:01:50,880
how to continue to extend

00:01:48,720 --> 00:01:52,720
our cloudification and network

00:01:50,880 --> 00:01:54,960
transformation of the

00:01:52,720 --> 00:01:56,399
network transformation efforts that

00:01:54,960 --> 00:02:00,079
we've been at

00:01:56,399 --> 00:02:02,560
since 2011. at the same time we're also

00:02:00,079 --> 00:02:04,560
looking at it from the iot side

00:02:02,560 --> 00:02:05,680
where we're looking at how single

00:02:04,560 --> 00:02:07,840
function

00:02:05,680 --> 00:02:09,280
in embedded devices are getting

00:02:07,840 --> 00:02:12,000
transformed to be

00:02:09,280 --> 00:02:13,520
multi-function intelligent edge

00:02:12,000 --> 00:02:15,760
platforms

00:02:13,520 --> 00:02:16,959
both of these efforts are together

00:02:15,760 --> 00:02:20,400
complementing

00:02:16,959 --> 00:02:22,400
and creating robust edge platforms that

00:02:20,400 --> 00:02:23,360
can address a variety of different use

00:02:22,400 --> 00:02:26,080
cases

00:02:23,360 --> 00:02:27,200
both on the on-premise edge as well as

00:02:26,080 --> 00:02:30,319
the network

00:02:27,200 --> 00:02:30,319
or the telco edge

00:02:30,560 --> 00:02:37,760
as we look at what the intel strategy is

00:02:33,840 --> 00:02:41,840
for edge computing it's three-fold

00:02:37,760 --> 00:02:46,000
intel has a diverse portfolio of silicon

00:02:41,840 --> 00:02:49,599
cpus accelerators ethernet

00:02:46,000 --> 00:02:53,040
storage so all of this diverse portfolio

00:02:49,599 --> 00:02:54,560
has been optimized specifically for edge

00:02:53,040 --> 00:02:57,440
computing

00:02:54,560 --> 00:02:58,959
in addition to that we have a robust set

00:02:57,440 --> 00:03:00,959
of developer tools

00:02:58,959 --> 00:03:02,159
developer tools that are driving the

00:03:00,959 --> 00:03:05,040
convergence

00:03:02,159 --> 00:03:07,599
of analytics and inferencing media

00:03:05,040 --> 00:03:09,680
capabilities or media optimizations

00:03:07,599 --> 00:03:10,800
as well as a variety of networking

00:03:09,680 --> 00:03:12,959
workloads

00:03:10,800 --> 00:03:14,959
with some very vertical industry

00:03:12,959 --> 00:03:17,599
specific offerings

00:03:14,959 --> 00:03:18,319
some of these tools are called openvino

00:03:17,599 --> 00:03:21,519
for

00:03:18,319 --> 00:03:23,599
ai deep learning inferencing opennas

00:03:21,519 --> 00:03:25,920
which is being used for networking and

00:03:23,599 --> 00:03:29,040
5g capabilities

00:03:25,920 --> 00:03:33,599
open visual cloud for media enhancements

00:03:29,040 --> 00:03:36,959
and dpdk for data plane acceleration

00:03:33,599 --> 00:03:40,159
and on the third pillar of our strategy

00:03:36,959 --> 00:03:42,480
is ecosystem scale we work with over

00:03:40,159 --> 00:03:45,840
1200 ecosystem partners

00:03:42,480 --> 00:03:46,480
and over 15 000 end users in order to

00:03:45,840 --> 00:03:49,200
drive

00:03:46,480 --> 00:03:51,200
scale of these deployments and we use a

00:03:49,200 --> 00:03:53,519
variety of different initiatives

00:03:51,200 --> 00:03:55,040
such as the market ready solutions the

00:03:53,519 --> 00:03:57,120
rfp ready kits

00:03:55,040 --> 00:04:00,640
the intel network builders program as

00:03:57,120 --> 00:04:02,720
well as the intel select solutions

00:04:00,640 --> 00:04:04,080
i will now hand off to prakash who will

00:04:02,720 --> 00:04:06,239
dive deeper

00:04:04,080 --> 00:04:08,080
into some of these very specific

00:04:06,239 --> 00:04:11,200
optimizations that we are doing

00:04:08,080 --> 00:04:14,480
for the edge so prakash

00:04:11,200 --> 00:04:17,040
thanks renu great to be here so

00:04:14,480 --> 00:04:17,840
uh the topic for the day is really

00:04:17,040 --> 00:04:20,720
around

00:04:17,840 --> 00:04:22,479
how to enable different types of

00:04:20,720 --> 00:04:24,639
locations on the edge

00:04:22,479 --> 00:04:26,400
with cloud native capabilities so

00:04:24,639 --> 00:04:29,280
whether you are on the

00:04:26,400 --> 00:04:31,120
uh the access edge or the near edge or

00:04:29,280 --> 00:04:33,919
the on-premise edge

00:04:31,120 --> 00:04:34,320
our belief is that you need a common set

00:04:33,919 --> 00:04:37,840
of

00:04:34,320 --> 00:04:40,080
building blocks to have a uniform view

00:04:37,840 --> 00:04:42,240
of the architecture when it comes to

00:04:40,080 --> 00:04:43,919
different edge locations so there are

00:04:42,240 --> 00:04:45,120
three things that are very critical to

00:04:43,919 --> 00:04:48,160
understand before we get

00:04:45,120 --> 00:04:51,199
deeper into the topic number one is

00:04:48,160 --> 00:04:54,080
to have a scalable platform to have

00:04:51,199 --> 00:04:55,759
a architecture that works on all of

00:04:54,080 --> 00:04:57,840
these different edge locations

00:04:55,759 --> 00:05:00,000
you need a cloud-like environment and

00:04:57,840 --> 00:05:01,280
that's why cloud native has become so

00:05:00,000 --> 00:05:03,520
critical

00:05:01,280 --> 00:05:04,639
for the edge you need a very modular

00:05:03,520 --> 00:05:06,560
approach too because

00:05:04,639 --> 00:05:08,160
once you start to put these different

00:05:06,560 --> 00:05:10,000
building blocks together

00:05:08,160 --> 00:05:11,680
you can piece these things together in

00:05:10,000 --> 00:05:14,080
different ways to serve

00:05:11,680 --> 00:05:15,919
specific use cases for these different

00:05:14,080 --> 00:05:18,160
edge locations

00:05:15,919 --> 00:05:19,759
um and you can you can drive all kinds

00:05:18,160 --> 00:05:21,360
of synergies between software

00:05:19,759 --> 00:05:24,000
investments that you're making

00:05:21,360 --> 00:05:25,039
uh between uh the the cloud native

00:05:24,000 --> 00:05:27,120
capabilities

00:05:25,039 --> 00:05:30,160
and you do that by putting together

00:05:27,120 --> 00:05:32,800
these common sets of building blocks

00:05:30,160 --> 00:05:34,160
coming out of a common technology pool

00:05:32,800 --> 00:05:35,199
if you have these common sense of

00:05:34,160 --> 00:05:38,400
building blocks

00:05:35,199 --> 00:05:42,160
then you can enable the ecosystem

00:05:38,400 --> 00:05:42,160
in a very uniform way

00:05:43,280 --> 00:05:46,720
so there are three things we want to

00:05:45,120 --> 00:05:48,880
talk about um

00:05:46,720 --> 00:05:50,560
one is you kind of start at the bottom

00:05:48,880 --> 00:05:53,360
of this pyramid that you see here

00:05:50,560 --> 00:05:55,440
in terms of having a cloud native

00:05:53,360 --> 00:05:56,560
architectural foundation we talked about

00:05:55,440 --> 00:05:59,120
it being

00:05:56,560 --> 00:06:00,080
scalable modular flexible so that's the

00:05:59,120 --> 00:06:02,240
foundation

00:06:00,080 --> 00:06:05,840
once you have that depending on the

00:06:02,240 --> 00:06:09,280
workload that you're trying to enable

00:06:05,840 --> 00:06:11,919
whether it's a a base station a 5g base

00:06:09,280 --> 00:06:14,880
station or a core network

00:06:11,919 --> 00:06:16,800
you can start to implement certain kpis

00:06:14,880 --> 00:06:17,360
and the kind of kpis that we're looking

00:06:16,800 --> 00:06:18,960
at

00:06:17,360 --> 00:06:21,039
in all of these locations would be

00:06:18,960 --> 00:06:24,240
things like high throughput

00:06:21,039 --> 00:06:26,880
very low latency and high determinism so

00:06:24,240 --> 00:06:28,479
to get these kinds of kpis across these

00:06:26,880 --> 00:06:31,759
different edge locations

00:06:28,479 --> 00:06:33,759
you need these consistent scalable cloud

00:06:31,759 --> 00:06:36,080
native platforms underneath that

00:06:33,759 --> 00:06:37,280
and once you have that then you can

00:06:36,080 --> 00:06:39,600
start to enable

00:06:37,280 --> 00:06:41,120
all kinds of services innovation on top

00:06:39,600 --> 00:06:45,039
of it starting with

00:06:41,120 --> 00:06:48,000
convergence of workloads you start out

00:06:45,039 --> 00:06:49,039
with enabling your core workload whether

00:06:48,000 --> 00:06:51,759
it be a

00:06:49,039 --> 00:06:53,199
networking workload whether it's a 5g

00:06:51,759 --> 00:06:57,360
base station or a

00:06:53,199 --> 00:07:00,720
a a d-pack inspection or a

00:06:57,360 --> 00:07:02,639
a user plane function but then you also

00:07:00,720 --> 00:07:04,720
start to integrate other

00:07:02,639 --> 00:07:06,080
non-networking workloads because that's

00:07:04,720 --> 00:07:08,560
where the future is going

00:07:06,080 --> 00:07:10,479
and to enable that cloud name that cloud

00:07:08,560 --> 00:07:11,280
native workload converged kind of

00:07:10,479 --> 00:07:14,240
environment

00:07:11,280 --> 00:07:16,000
you also need open apis because once you

00:07:14,240 --> 00:07:18,479
have those open apis

00:07:16,000 --> 00:07:19,120
then you can accelerate your application

00:07:18,479 --> 00:07:20,319
development

00:07:19,120 --> 00:07:22,720
so a lot of what we're going to talk

00:07:20,319 --> 00:07:24,000
about today is how all these concepts

00:07:22,720 --> 00:07:27,120
going to come together

00:07:24,000 --> 00:07:31,520
into building blocks put together

00:07:27,120 --> 00:07:34,160
in the form of blueprints

00:07:31,520 --> 00:07:36,160
so now let's dive a little bit deeper

00:07:34,160 --> 00:07:38,720
into one particular example

00:07:36,160 --> 00:07:42,400
in this case we're going to talk about

00:07:38,720 --> 00:07:43,840
the vran the virtualized ran and how

00:07:42,400 --> 00:07:45,440
all these different cloud native

00:07:43,840 --> 00:07:46,800
building blocks all the concepts we

00:07:45,440 --> 00:07:50,080
talked about so far

00:07:46,800 --> 00:07:52,080
come together to enable a cloud native

00:07:50,080 --> 00:07:53,919
vram platform in this example we're

00:07:52,080 --> 00:07:57,120
going to talk about flex ram

00:07:53,919 --> 00:07:58,560
and flextran is the is though is the

00:07:57,120 --> 00:08:02,000
containerized

00:07:58,560 --> 00:08:04,319
um layer one for a 5g base station

00:08:02,000 --> 00:08:06,160
and we'll talk about how flexran layered

00:08:04,319 --> 00:08:07,759
on top of the openness

00:08:06,160 --> 00:08:10,000
framework which provides the cloud

00:08:07,759 --> 00:08:12,080
native ingredients builds together

00:08:10,000 --> 00:08:14,240
brings together the full platform

00:08:12,080 --> 00:08:15,599
so let's talk through some examples the

00:08:14,240 --> 00:08:18,240
first one we'll talk about

00:08:15,599 --> 00:08:19,520
is the container network interfaces the

00:08:18,240 --> 00:08:22,560
cni's

00:08:19,520 --> 00:08:24,479
so flex ran requires multiple cni's

00:08:22,560 --> 00:08:26,000
so the first thing you would need to

00:08:24,479 --> 00:08:29,120
consider is

00:08:26,000 --> 00:08:29,599
multis so multi cni enables you to

00:08:29,120 --> 00:08:32,240
attach

00:08:29,599 --> 00:08:34,159
multiple network interfaces to you to

00:08:32,240 --> 00:08:35,279
your pods so typically in kubernetes

00:08:34,159 --> 00:08:38,320
each part

00:08:35,279 --> 00:08:38,959
has just one network interface with

00:08:38,320 --> 00:08:42,399
multis

00:08:38,959 --> 00:08:42,959
you can create a multi-home pod which is

00:08:42,399 --> 00:08:44,560
multiple

00:08:42,959 --> 00:08:46,560
network interfaces that's the first

00:08:44,560 --> 00:08:48,240
thing to consider

00:08:46,560 --> 00:08:50,959
the default cni that we have in this

00:08:48,240 --> 00:08:52,959
particular configuration is calico

00:08:50,959 --> 00:08:54,640
but there's more to it so for example

00:08:52,959 --> 00:08:55,600
the next question that comes up is how

00:08:54,640 --> 00:08:58,720
do you connect your

00:08:55,600 --> 00:09:02,240
containers to your nic interfaces so

00:08:58,720 --> 00:09:05,120
srio for example the sriv cni

00:09:02,240 --> 00:09:07,200
is used when you want containers to get

00:09:05,120 --> 00:09:09,440
access to virtual functions on your nic

00:09:07,200 --> 00:09:13,360
ports that are srio enabled

00:09:09,440 --> 00:09:15,440
meaning those nics that are

00:09:13,360 --> 00:09:16,560
that have both physical functions and

00:09:15,440 --> 00:09:20,080
virtual functions

00:09:16,560 --> 00:09:22,720
and you're able to treat each func each

00:09:20,080 --> 00:09:23,440
virtual function as a separate network

00:09:22,720 --> 00:09:27,360
interface

00:09:23,440 --> 00:09:30,320
and you can configure its own uh mac

00:09:27,360 --> 00:09:31,440
vlan ip and so on now that's one option

00:09:30,320 --> 00:09:34,640
the alternate

00:09:31,440 --> 00:09:36,080
is if you want a simpler plugin

00:09:34,640 --> 00:09:38,160
you would use something like a host

00:09:36,080 --> 00:09:41,200
device cni

00:09:38,160 --> 00:09:42,480
which will essentially move the

00:09:41,200 --> 00:09:45,120
requested device

00:09:42,480 --> 00:09:47,279
from the host network name space to the

00:09:45,120 --> 00:09:49,040
container's network namespace

00:09:47,279 --> 00:09:50,560
again you would use this if you did not

00:09:49,040 --> 00:09:53,120
have any complicated

00:09:50,560 --> 00:09:55,200
configuration that mentioned earlier you

00:09:53,120 --> 00:09:56,080
can use a more simplified cni like the

00:09:55,200 --> 00:09:59,040
host cni

00:09:56,080 --> 00:10:00,320
host device cni the next example of

00:09:59,040 --> 00:10:02,240
another cni you would use

00:10:00,320 --> 00:10:05,040
is the user space cni now the user space

00:10:02,240 --> 00:10:07,680
cni is designed to implement

00:10:05,040 --> 00:10:09,680
user space networking as opposed to

00:10:07,680 --> 00:10:10,959
kernel space networking so an example of

00:10:09,680 --> 00:10:12,640
that would be dppdk

00:10:10,959 --> 00:10:14,399
you know something like obs dpdk with

00:10:12,640 --> 00:10:17,360
containers so that's an example

00:10:14,399 --> 00:10:18,160
so another one would be the bond cni so

00:10:17,360 --> 00:10:20,000
bonding

00:10:18,160 --> 00:10:21,200
is uh you know basically provides a

00:10:20,000 --> 00:10:23,440
method to

00:10:21,200 --> 00:10:24,480
aggregate multiple network interfaces

00:10:23,440 --> 00:10:26,880
into a single

00:10:24,480 --> 00:10:28,560
logical bonded interface so for that you

00:10:26,880 --> 00:10:30,560
would use a bond cni

00:10:28,560 --> 00:10:33,200
there's another one called tuning cni a

00:10:30,560 --> 00:10:35,600
very utilitarian cni that would you use

00:10:33,200 --> 00:10:36,320
for that you would use for changing

00:10:35,600 --> 00:10:39,839
certain

00:10:36,320 --> 00:10:41,519
system controls uh interface attributes

00:10:39,839 --> 00:10:42,959
and network namespace and so on so

00:10:41,519 --> 00:10:45,279
ultimately what we're talking about here

00:10:42,959 --> 00:10:46,640
is a multi-cni type interface and you

00:10:45,279 --> 00:10:48,240
pick different cni's

00:10:46,640 --> 00:10:51,360
based on the particular aspect that

00:10:48,240 --> 00:10:52,959
you're trying to accentuate

00:10:51,360 --> 00:10:54,240
so the next element of the architecture

00:10:52,959 --> 00:10:56,720
are the what are the system parts that

00:10:54,240 --> 00:10:59,760
you would need to have

00:10:56,720 --> 00:11:03,839
node feature discovery is a uh

00:10:59,760 --> 00:11:06,959
kubernetes plug-in that you can use

00:11:03,839 --> 00:11:09,200
uh to uh detect an ad you know it's

00:11:06,959 --> 00:11:11,040
basically techno advertise hardware um

00:11:09,200 --> 00:11:12,720
and software capabilities on a platform

00:11:11,040 --> 00:11:14,399
so it can be discovered

00:11:12,720 --> 00:11:16,480
and it facilitates intelligent

00:11:14,399 --> 00:11:17,519
scheduling again a very useful micro

00:11:16,480 --> 00:11:21,040
service to have

00:11:17,519 --> 00:11:23,120
within your um within your vran

00:11:21,040 --> 00:11:24,560
cloud native architecture the next one

00:11:23,120 --> 00:11:26,640
is core pinning

00:11:24,560 --> 00:11:28,800
a core pinning is a again a kubernetes

00:11:26,640 --> 00:11:31,040
plug-in that provides core affinity

00:11:28,800 --> 00:11:32,640
for applications deployed as kubernetes

00:11:31,040 --> 00:11:34,240
parts

00:11:32,640 --> 00:11:35,680
now let's take a look at some of the uh

00:11:34,240 --> 00:11:38,959
the platform parts

00:11:35,680 --> 00:11:40,560
so an interesting micro service that we

00:11:38,959 --> 00:11:42,800
we added to this particular

00:11:40,560 --> 00:11:43,360
configuration is something called rmd or

00:11:42,800 --> 00:11:46,240
resource

00:11:43,360 --> 00:11:46,959
management daemon so rmd is based on

00:11:46,240 --> 00:11:49,279
intel's

00:11:46,959 --> 00:11:51,680
resource director technology what it

00:11:49,279 --> 00:11:54,320
does is it provides a framework

00:11:51,680 --> 00:11:54,959
for monitoring and allocating cache and

00:11:54,320 --> 00:11:58,639
memory

00:11:54,959 --> 00:12:01,680
so in the vran context rdt aids

00:11:58,639 --> 00:12:03,839
detection of uh code noise neighbors

00:12:01,680 --> 00:12:05,279
which helps reduce performance

00:12:03,839 --> 00:12:07,600
interference

00:12:05,279 --> 00:12:10,240
that's one example another example is

00:12:07,600 --> 00:12:13,279
you need specialized hardware like fpgas

00:12:10,240 --> 00:12:14,800
for managing certain uh parts of a vr

00:12:13,279 --> 00:12:15,760
and pipeline like the forward error

00:12:14,800 --> 00:12:18,320
correction

00:12:15,760 --> 00:12:20,079
so we provide a kubernetes operator that

00:12:18,320 --> 00:12:21,680
manages the software update the

00:12:20,079 --> 00:12:23,440
automation of the fpga

00:12:21,680 --> 00:12:24,880
which can get quite complex without

00:12:23,440 --> 00:12:27,839
without this infrastructure

00:12:24,880 --> 00:12:30,160
and finally in an overran type context

00:12:27,839 --> 00:12:33,200
we have a dynamic device profile

00:12:30,160 --> 00:12:35,600
or a ddp for the

00:12:33,200 --> 00:12:37,200
smart nix that intel offers which

00:12:35,600 --> 00:12:39,519
basically run filters for different

00:12:37,200 --> 00:12:42,959
types of orange profiles like the oran

00:12:39,519 --> 00:12:44,639
front hall so you can see how all these

00:12:42,959 --> 00:12:47,600
different building blocks become

00:12:44,639 --> 00:12:48,079
essential for you to consider as you

00:12:47,600 --> 00:12:51,519
build

00:12:48,079 --> 00:12:52,639
the overall platform now as we move

00:12:51,519 --> 00:12:54,480
forward

00:12:52,639 --> 00:12:55,760
let's talk about uh let's do a little

00:12:54,480 --> 00:12:58,320
bit of a double click

00:12:55,760 --> 00:13:00,880
and and think through what are those

00:12:58,320 --> 00:13:03,680
specific real-time optimizations

00:13:00,880 --> 00:13:05,680
that we've enabled through openness for

00:13:03,680 --> 00:13:06,560
uh for flex ran and for vlan so we're

00:13:05,680 --> 00:13:07,279
going to double click a little bit

00:13:06,560 --> 00:13:09,920
further

00:13:07,279 --> 00:13:11,120
so first let's talk about deterministic

00:13:09,920 --> 00:13:13,360
i o so you're talking about

00:13:11,120 --> 00:13:16,000
deterministic i o on the front hall

00:13:13,360 --> 00:13:17,760
to achieve ultra low latency and high

00:13:16,000 --> 00:13:19,200
performance

00:13:17,760 --> 00:13:22,160
so openness provides a number of

00:13:19,200 --> 00:13:26,320
optimizations to achieve this including

00:13:22,160 --> 00:13:28,959
optimizations in dpdk offloads to next

00:13:26,320 --> 00:13:31,120
current level optimizations for srioe so

00:13:28,959 --> 00:13:32,720
overall with these optimizations we are

00:13:31,120 --> 00:13:36,480
able to achieve

00:13:32,720 --> 00:13:38,959
less than 20 micro seconds max latency

00:13:36,480 --> 00:13:40,160
on the front hall and we've tested this

00:13:38,959 --> 00:13:42,560
on an extended

00:13:40,160 --> 00:13:43,760
over an extended period with various

00:13:42,560 --> 00:13:46,160
conditions like

00:13:43,760 --> 00:13:46,800
noisy neighbors a mix of you know real

00:13:46,160 --> 00:13:48,720
time

00:13:46,800 --> 00:13:51,120
and non-real-time traffic and this 20

00:13:48,720 --> 00:13:54,000
microseconds is the max so the average

00:13:51,120 --> 00:13:54,880
is closer to the min um but that's the

00:13:54,000 --> 00:13:58,639
max we've

00:13:54,880 --> 00:14:02,959
we've encountered the next element is

00:13:58,639 --> 00:14:04,720
deterministic acceleration so

00:14:02,959 --> 00:14:07,040
you know similarly openness provides a

00:14:04,720 --> 00:14:08,720
highly optimized implementation of 4g

00:14:07,040 --> 00:14:11,440
and 5g effect we talked about

00:14:08,720 --> 00:14:13,519
this in the previous slide so these are

00:14:11,440 --> 00:14:16,320
through optimizations in dpdk

00:14:13,519 --> 00:14:17,839
we have flexible apis to execute in

00:14:16,320 --> 00:14:20,880
either hardware or software

00:14:17,839 --> 00:14:22,639
in the fpga or in an easec

00:14:20,880 --> 00:14:24,639
look aside models for hardware

00:14:22,639 --> 00:14:26,800
arbitration with optimizations for

00:14:24,639 --> 00:14:28,880
configuring uplink downlink ratios

00:14:26,800 --> 00:14:31,120
configuring number of queues and so on

00:14:28,880 --> 00:14:31,920
and so forth a lot of good optimizations

00:14:31,120 --> 00:14:34,240
around

00:14:31,920 --> 00:14:37,199
just running forward error correction um

00:14:34,240 --> 00:14:39,600
on that fpga or in the asic

00:14:37,199 --> 00:14:41,199
the next element is cloud native

00:14:39,600 --> 00:14:43,040
orchestration how to do that

00:14:41,199 --> 00:14:44,800
in a deterministic fashion we spoke

00:14:43,040 --> 00:14:46,399
about this a little bit uh on the

00:14:44,800 --> 00:14:46,959
previous slide but just kind of couple

00:14:46,399 --> 00:14:49,760
you know

00:14:46,959 --> 00:14:51,519
uh pick out a couple more points so new

00:14:49,760 --> 00:14:53,040
awareness so numa awareness is something

00:14:51,519 --> 00:14:55,040
that you achieve with a module called

00:14:53,040 --> 00:14:55,760
topology manager now topology managers

00:14:55,040 --> 00:14:57,360
are part of

00:14:55,760 --> 00:14:59,600
now i've been upstream to kubernetes but

00:14:57,360 --> 00:15:00,720
it's a very important component that you

00:14:59,600 --> 00:15:02,639
would need to have

00:15:00,720 --> 00:15:04,800
in your architecture what the topology

00:15:02,639 --> 00:15:06,800
manager does is that it maximizes the

00:15:04,800 --> 00:15:09,360
performance by ensuring

00:15:06,800 --> 00:15:10,320
that the workload in this case flex ran

00:15:09,360 --> 00:15:13,279
is placed

00:15:10,320 --> 00:15:14,560
on the socket in such a way that it

00:15:13,279 --> 00:15:17,360
removes the need for

00:15:14,560 --> 00:15:19,279
cross upi communication what that means

00:15:17,360 --> 00:15:20,959
is upi stands for ultra path

00:15:19,279 --> 00:15:21,680
interconnect so it's interconnect that

00:15:20,959 --> 00:15:24,480
connects to

00:15:21,680 --> 00:15:25,600
cpus so if you have new mobile nodes and

00:15:24,480 --> 00:15:28,560
you're able to actually

00:15:25,600 --> 00:15:29,839
land your um your your workload in this

00:15:28,560 --> 00:15:32,880
case flex ran

00:15:29,839 --> 00:15:33,519
on on certain sockets that minimizes

00:15:32,880 --> 00:15:35,839
that

00:15:33,519 --> 00:15:36,720
you know cross-cpi communication again

00:15:35,839 --> 00:15:39,440
it's all about

00:15:36,720 --> 00:15:40,240
determinism and latency we talked about

00:15:39,440 --> 00:15:42,240
core pinning

00:15:40,240 --> 00:15:43,759
you know support for hyper threading

00:15:42,240 --> 00:15:45,600
allocating cpu

00:15:43,759 --> 00:15:47,600
resources to parts and then we also

00:15:45,600 --> 00:15:49,199
talked about node feature discovery is

00:15:47,600 --> 00:15:51,600
another important part

00:15:49,199 --> 00:15:52,480
and finally after all these software

00:15:51,600 --> 00:15:54,560
optimizations

00:15:52,480 --> 00:15:56,079
you still need a very deterministic

00:15:54,560 --> 00:15:58,320
overall platform

00:15:56,079 --> 00:15:59,920
so foundational to this is going to be

00:15:58,320 --> 00:16:03,120
implementing real-time

00:15:59,920 --> 00:16:05,279
and real-time preemption in linux so

00:16:03,120 --> 00:16:07,120
this is work that intel has enabled with

00:16:05,279 --> 00:16:08,320
with our operating system partners for

00:16:07,120 --> 00:16:10,480
several years

00:16:08,320 --> 00:16:12,079
and now we're making this available with

00:16:10,480 --> 00:16:13,920
kubernetes as part of the openness

00:16:12,079 --> 00:16:16,160
experience kit

00:16:13,920 --> 00:16:18,000
what this enables you to do in addition

00:16:16,160 --> 00:16:20,399
to the real time is also

00:16:18,000 --> 00:16:21,759
enable that core isolation allowing a

00:16:20,399 --> 00:16:24,000
user to deploy

00:16:21,759 --> 00:16:26,240
a deterministic workload like flexrand

00:16:24,000 --> 00:16:29,360
like the randu for example

00:16:26,240 --> 00:16:31,120
on an isolated core and then operate

00:16:29,360 --> 00:16:32,720
without any interference from other

00:16:31,120 --> 00:16:34,800
kernel threads

00:16:32,720 --> 00:16:36,399
and even if you have a context which

00:16:34,800 --> 00:16:38,240
let's say from

00:16:36,399 --> 00:16:40,240
you know context to a higher priority

00:16:38,240 --> 00:16:40,959
kernel thread then you are able to

00:16:40,240 --> 00:16:42,880
switch

00:16:40,959 --> 00:16:44,480
back to the real-time thread in a very

00:16:42,880 --> 00:16:44,959
deterministic manner so that's the key

00:16:44,480 --> 00:16:46,560
point

00:16:44,959 --> 00:16:48,000
so it's not that you cannot context

00:16:46,560 --> 00:16:49,600
switch when you come back you do that in

00:16:48,000 --> 00:16:51,920
a very deterministic manner and their

00:16:49,600 --> 00:16:54,000
optimization specifically for that

00:16:51,920 --> 00:16:56,480
uh similarly we have optimizations for

00:16:54,000 --> 00:16:56,480
bios

00:16:56,639 --> 00:17:00,320
on this on this configuration again an

00:16:59,120 --> 00:17:03,440
example of that would be

00:17:00,320 --> 00:17:05,360
from our determinism standpoint

00:17:03,440 --> 00:17:07,679
is uh there are certain extensions

00:17:05,360 --> 00:17:10,480
certain advanced kernel instructions

00:17:07,679 --> 00:17:11,600
uh like avx 512 that is required for

00:17:10,480 --> 00:17:14,480
flex ran

00:17:11,600 --> 00:17:15,839
uh which may take higher power right um

00:17:14,480 --> 00:17:17,600
and that that may cause certain

00:17:15,839 --> 00:17:18,000
fluctuations and frequencies which may

00:17:17,600 --> 00:17:19,600
impact

00:17:18,000 --> 00:17:21,439
determinism so we have implemented

00:17:19,600 --> 00:17:25,199
optimizations to minimize

00:17:21,439 --> 00:17:27,120
um those those those fluctuations

00:17:25,199 --> 00:17:29,520
and then finally power management

00:17:27,120 --> 00:17:31,520
putting cores to lower frequencies

00:17:29,520 --> 00:17:33,200
idle you know lower idle states with

00:17:31,520 --> 00:17:34,799
power states and so on

00:17:33,200 --> 00:17:37,280
so you know collectively what we're

00:17:34,799 --> 00:17:40,000
saying here is a lot of these

00:17:37,280 --> 00:17:42,400
you know pointed optimizations are

00:17:40,000 --> 00:17:44,400
coming together in the form of this

00:17:42,400 --> 00:17:45,679
um this recipe that we've built in

00:17:44,400 --> 00:17:47,600
openness it

00:17:45,679 --> 00:17:49,200
makes it kind of easy for you to go

00:17:47,600 --> 00:17:52,960
deploy

00:17:49,200 --> 00:17:54,480
deploy the far edge or the access edge

00:17:52,960 --> 00:17:56,559
so now let's talk a little bit about

00:17:54,480 --> 00:17:58,559
another use case so now let's talk about

00:17:56,559 --> 00:18:00,320
the near edge so near edge is the next

00:17:58,559 --> 00:18:02,960
level of aggregation

00:18:00,320 --> 00:18:04,240
from the far edge so what's obviously

00:18:02,960 --> 00:18:05,760
the big difference with the near edge is

00:18:04,240 --> 00:18:07,840
what is the workload running on it right

00:18:05,760 --> 00:18:08,720
so now we're talking about the 5g upf

00:18:07,840 --> 00:18:11,200
you're talking about

00:18:08,720 --> 00:18:12,400
deep packet inspection network analytics

00:18:11,200 --> 00:18:15,440
but also

00:18:12,400 --> 00:18:18,160
we have um ai you have

00:18:15,440 --> 00:18:20,559
media all of these different use cases

00:18:18,160 --> 00:18:23,039
are now starting to converge

00:18:20,559 --> 00:18:24,400
so what we have done is if you think

00:18:23,039 --> 00:18:26,480
about the

00:18:24,400 --> 00:18:28,160
uh the platform that you where we talked

00:18:26,480 --> 00:18:30,720
about for rand the exact

00:18:28,160 --> 00:18:32,080
same platform with different with a

00:18:30,720 --> 00:18:34,640
slightly different set of

00:18:32,080 --> 00:18:37,039
ingredients we are enabling that for the

00:18:34,640 --> 00:18:38,880
near edge you start so we start with a

00:18:37,039 --> 00:18:40,640
solid foundation right the solid

00:18:38,880 --> 00:18:42,960
foundation is our hardware

00:18:40,640 --> 00:18:43,760
ecosystem so through the intel select

00:18:42,960 --> 00:18:45,679
program

00:18:43,760 --> 00:18:47,679
we have for example what's known as the

00:18:45,679 --> 00:18:49,679
nfvi forwarding plane

00:18:47,679 --> 00:18:50,720
which is an intel select solution for

00:18:49,679 --> 00:18:53,840
the near edge

00:18:50,720 --> 00:18:57,120
which has the right skew of cpu

00:18:53,840 --> 00:18:58,000
of ethernet next quick assist um even

00:18:57,120 --> 00:19:00,799
the ability

00:18:58,000 --> 00:19:01,840
um to take that intel select and start

00:19:00,799 --> 00:19:03,360
to add on

00:19:01,840 --> 00:19:06,000
you know different types of you know

00:19:03,360 --> 00:19:08,080
accelerators like ai cards

00:19:06,000 --> 00:19:10,240
um so you start with that as a baseline

00:19:08,080 --> 00:19:10,880
and then what you do is you add on top

00:19:10,240 --> 00:19:13,679
of that

00:19:10,880 --> 00:19:14,400
the the the high throughput data plane

00:19:13,679 --> 00:19:17,200
right so you see

00:19:14,400 --> 00:19:18,720
the whole dpdk family you know obs dpdk

00:19:17,200 --> 00:19:20,799
um so that becomes the

00:19:18,720 --> 00:19:21,840
the the data plane on top of that then

00:19:20,799 --> 00:19:23,520
you layer on top

00:19:21,840 --> 00:19:25,520
the openness distribution that we just

00:19:23,520 --> 00:19:28,240
talked about tweaked for

00:19:25,520 --> 00:19:29,120
the near edge use cases and then finally

00:19:28,240 --> 00:19:31,039
you bring in

00:19:29,120 --> 00:19:32,160
reference implementations for the

00:19:31,039 --> 00:19:34,799
network functions

00:19:32,160 --> 00:19:37,039
the the edge services and what we've

00:19:34,799 --> 00:19:40,000
done is we put all the stuff together

00:19:37,039 --> 00:19:40,320
into essentially a blueprint and what we

00:19:40,000 --> 00:19:42,400
and

00:19:40,320 --> 00:19:43,679
and as we move forward we'll show you

00:19:42,400 --> 00:19:46,640
how this blueprint

00:19:43,679 --> 00:19:53,120
is not just for the for the near edge

00:19:46,640 --> 00:19:55,360
but also for other locations

00:19:53,120 --> 00:19:56,720
so now let's talk about how this one

00:19:55,360 --> 00:20:00,240
blueprint

00:19:56,720 --> 00:20:01,919
um is is kind of expanded to different

00:20:00,240 --> 00:20:04,840
edge locations so we talked about the

00:20:01,919 --> 00:20:07,200
near edge which is more of a 5g

00:20:04,840 --> 00:20:09,200
upf but

00:20:07,200 --> 00:20:11,280
this architecture is something that

00:20:09,200 --> 00:20:12,240
we've been investing in for almost 18

00:20:11,280 --> 00:20:14,320
months now

00:20:12,240 --> 00:20:15,760
something we call the converged edge

00:20:14,320 --> 00:20:17,200
reference architecture

00:20:15,760 --> 00:20:18,880
the idea that you can take an

00:20:17,200 --> 00:20:19,520
architectural blueprint and bring

00:20:18,880 --> 00:20:22,720
together

00:20:19,520 --> 00:20:24,799
workloads from different starting points

00:20:22,720 --> 00:20:26,640
and networking workload and inferencing

00:20:24,799 --> 00:20:27,760
and vision and media work are all coming

00:20:26,640 --> 00:20:30,000
together

00:20:27,760 --> 00:20:31,520
into a common architecture what we call

00:20:30,000 --> 00:20:32,559
the converged edge reference

00:20:31,520 --> 00:20:36,000
architecture or

00:20:32,559 --> 00:20:39,280
setup so we in fact launched this

00:20:36,000 --> 00:20:40,320
um in 2019 with the first instantiation

00:20:39,280 --> 00:20:43,280
for 4g

00:20:40,320 --> 00:20:44,400
in an on-premise type environment which

00:20:43,280 --> 00:20:47,520
included

00:20:44,400 --> 00:20:51,440
a a private wireless recipe

00:20:47,520 --> 00:20:53,039
for outdoor ruggedized type deployments

00:20:51,440 --> 00:20:55,360
what we're doing now is we're taking the

00:20:53,039 --> 00:20:57,440
same concept and we started to build out

00:20:55,360 --> 00:20:58,400
seras or converged edge reference

00:20:57,440 --> 00:21:01,520
architectures

00:20:58,400 --> 00:21:03,360
for different network edge locations the

00:21:01,520 --> 00:21:06,480
first one they'll be releasing

00:21:03,360 --> 00:21:08,080
later in september is going to be for

00:21:06,480 --> 00:21:10,480
the nearest so we'll have a

00:21:08,080 --> 00:21:12,159
converged edge reference architecture

00:21:10,480 --> 00:21:15,120
that we make available through

00:21:12,159 --> 00:21:15,520
the openness distribution for the near

00:21:15,120 --> 00:21:18,320
edge

00:21:15,520 --> 00:21:20,559
and then we're also working to upgrade

00:21:18,320 --> 00:21:24,000
the on-premise edge

00:21:20,559 --> 00:21:26,480
uh sera with support for 5g

00:21:24,000 --> 00:21:27,280
so you can see how we've taken the idea

00:21:26,480 --> 00:21:29,520
of

00:21:27,280 --> 00:21:31,280
you know a cloud-native platform

00:21:29,520 --> 00:21:34,080
building out a blueprint

00:21:31,280 --> 00:21:36,880
and then scaling it out into different

00:21:34,080 --> 00:21:36,880
edge locations

00:21:38,080 --> 00:21:41,600
so the the the end game for all the

00:21:41,039 --> 00:21:45,200
stuff

00:21:41,600 --> 00:21:47,520
is that um the

00:21:45,200 --> 00:21:49,039
the sera is kind of the starting point

00:21:47,520 --> 00:21:50,640
from a design perspective it's an

00:21:49,039 --> 00:21:54,400
architecture

00:21:50,640 --> 00:21:57,200
and strata is based on openness

00:21:54,400 --> 00:21:57,679
as the underlying cloud native platform

00:21:57,200 --> 00:21:59,760
now

00:21:57,679 --> 00:22:01,679
for us it's all about the ecosystem at

00:21:59,760 --> 00:22:04,720
the end of the day because the ecosystem

00:22:01,679 --> 00:22:04,720
has to be able to

00:22:05,039 --> 00:22:09,679
take these reference architectures and

00:22:08,000 --> 00:22:11,679
be able to

00:22:09,679 --> 00:22:12,880
scale that into the into actual

00:22:11,679 --> 00:22:16,720
deployments

00:22:12,880 --> 00:22:17,360
so we have uh an excellent set of scale

00:22:16,720 --> 00:22:19,600
programs

00:22:17,360 --> 00:22:20,480
at intel one of the scale programs is

00:22:19,600 --> 00:22:23,360
called the intel

00:22:20,480 --> 00:22:25,120
rfp ready kits program what the intel

00:22:23,360 --> 00:22:27,520
rfp ready kits program is

00:22:25,120 --> 00:22:29,120
is you you have the ability to work with

00:22:27,520 --> 00:22:32,720
commercial partners

00:22:29,120 --> 00:22:34,880
to construct essentially

00:22:32,720 --> 00:22:37,360
kits that can be read that are ready to

00:22:34,880 --> 00:22:39,679
be deployed at customer rfps

00:22:37,360 --> 00:22:40,400
so um what we're doing now is we're

00:22:39,679 --> 00:22:43,280
taking

00:22:40,400 --> 00:22:44,400
these uh seras these converged reference

00:22:43,280 --> 00:22:47,440
architectures

00:22:44,400 --> 00:22:49,039
and then converting them into rfp ready

00:22:47,440 --> 00:22:52,480
kits we already have

00:22:49,039 --> 00:22:54,720
our purity kits for the 4g on-prem

00:22:52,480 --> 00:22:55,919
status that we built earlier so those

00:22:54,720 --> 00:22:58,159
are already available

00:22:55,919 --> 00:22:59,520
as part of the catalog that you can get

00:22:58,159 --> 00:23:01,600
access to

00:22:59,520 --> 00:23:03,120
and then for the new series that we're

00:23:01,600 --> 00:23:04,000
building we're going to convert those

00:23:03,120 --> 00:23:07,120
also

00:23:04,000 --> 00:23:09,679
into intel rfp ready kits but we don't

00:23:07,120 --> 00:23:11,440
stop there so once an rfp ready kit is

00:23:09,679 --> 00:23:13,600
available the next step

00:23:11,440 --> 00:23:14,799
is to actually get them deployed in

00:23:13,600 --> 00:23:17,360
commercial

00:23:14,799 --> 00:23:19,200
instances so that's when that rfp ready

00:23:17,360 --> 00:23:21,520
kit becomes what we call a

00:23:19,200 --> 00:23:23,280
market ready solution the market ready

00:23:21,520 --> 00:23:26,480
solution is another

00:23:23,280 --> 00:23:29,360
scale program focused more on deployment

00:23:26,480 --> 00:23:30,240
so once you have a number of these rfp

00:23:29,360 --> 00:23:32,400
ready kits

00:23:30,240 --> 00:23:33,440
deployed in the market then you can

00:23:32,400 --> 00:23:36,000
start to get scale

00:23:33,440 --> 00:23:38,159
that's when system integrators come in

00:23:36,000 --> 00:23:40,000
and take these market ready solutions

00:23:38,159 --> 00:23:40,480
and then you have this rental repeat you

00:23:40,000 --> 00:23:42,640
you

00:23:40,480 --> 00:23:44,320
you get the same solution deployed with

00:23:42,640 --> 00:23:45,760
different types of use cases

00:23:44,320 --> 00:23:47,360
at different customers different

00:23:45,760 --> 00:23:50,159
enterprises and telcos

00:23:47,360 --> 00:23:50,880
so you can see how we've taken the idea

00:23:50,159 --> 00:23:53,600
of

00:23:50,880 --> 00:23:55,600
a cloud-native platform converted into a

00:23:53,600 --> 00:23:56,880
reference architecture and scaled into

00:23:55,600 --> 00:23:58,559
the market

00:23:56,880 --> 00:24:01,279
okay so that that was our presentation

00:23:58,559 --> 00:24:04,159
hopefully you enjoyed it we um

00:24:01,279 --> 00:24:04,880
uh we are really looking forward to

00:24:04,159 --> 00:24:08,000
having

00:24:04,880 --> 00:24:10,720
more and more uh you know investments in

00:24:08,000 --> 00:24:14,080
cloud-native architecture specifically

00:24:10,720 --> 00:24:16,000
uh for the telco edge with uh with

00:24:14,080 --> 00:24:18,000
the access and far edge going into the

00:24:16,000 --> 00:24:20,240
near edge and continuing to make

00:24:18,000 --> 00:24:22,000
investments in optimizing it converting

00:24:20,240 --> 00:24:23,679
them into reference architectures like

00:24:22,000 --> 00:24:25,760
the sara program we talked about

00:24:23,679 --> 00:24:27,760
and scaling it into the ecosystem thank

00:24:25,760 --> 00:24:33,840
you very much and

00:24:27,760 --> 00:24:33,840
have a good day

00:24:50,799 --> 00:24:54,080
all right precaution renee thank you so

00:24:52,640 --> 00:24:56,720
much we have you on

00:24:54,080 --> 00:24:57,360
um feel free to answer any questions now

00:24:56,720 --> 00:25:00,400
that are

00:24:57,360 --> 00:25:03,039
in the q a panel we have about five

00:25:00,400 --> 00:25:03,039
minutes left

00:25:12,880 --> 00:25:29,840
and you are live whenever you're ready

00:25:30,799 --> 00:25:34,080
so prakash i think we have one question

00:25:33,200 --> 00:25:37,200
here which is

00:25:34,080 --> 00:25:40,320
um are there any good resources to learn

00:25:37,200 --> 00:25:42,240
more about the real-time optimizations

00:25:40,320 --> 00:25:44,919
to edge deployments

00:25:42,240 --> 00:25:46,720
i think on our website which is

00:25:44,919 --> 00:25:48,640
openness.org

00:25:46,720 --> 00:25:50,240
you you should find a number of

00:25:48,640 --> 00:25:52,400
resources

00:25:50,240 --> 00:25:53,600
white papers and other documents that

00:25:52,400 --> 00:25:56,000
also talk

00:25:53,600 --> 00:25:59,120
more about the real-time optimizations

00:25:56,000 --> 00:26:01,799
prakash anything you want to add

00:25:59,120 --> 00:26:03,440
no that's good right now so if you go to

00:26:01,799 --> 00:26:06,640
openness.org

00:26:03,440 --> 00:26:08,240
just look for a specific white paper on

00:26:06,640 --> 00:26:11,360
ram

00:26:08,240 --> 00:26:13,360
and you'll see a pretty detailed um

00:26:11,360 --> 00:26:16,000
playbook and all the different things we

00:26:13,360 --> 00:26:18,080
talked about or documented there

00:26:16,000 --> 00:26:19,840
yeah and these uh these optimizations

00:26:18,080 --> 00:26:22,320
are included in the um

00:26:19,840 --> 00:26:24,320
public version of openness so you that

00:26:22,320 --> 00:26:26,080
is the open source version so

00:26:24,320 --> 00:26:29,039
you should be able to get it from the

00:26:26,080 --> 00:26:29,039
open sourced version

00:26:29,840 --> 00:26:32,960
uh i think there's another question on

00:26:31,679 --> 00:26:36,159
do you plan to include

00:26:32,960 --> 00:26:40,480
nfvi acceleration in any kit obs

00:26:36,159 --> 00:26:41,440
or vr i believe we do prakash do you

00:26:40,480 --> 00:26:44,880
want to take that

00:26:41,440 --> 00:26:47,919
uh yeah yeah so um

00:26:44,880 --> 00:26:50,400
so for ovs uh we have

00:26:47,919 --> 00:26:52,240
two versions of this the ovs and the

00:26:50,400 --> 00:26:55,360
obvious dpdk

00:26:52,240 --> 00:26:58,400
both are supported as cni's

00:26:55,360 --> 00:27:00,039
through a project called cube oven and

00:26:58,400 --> 00:27:02,880
so again if you go to

00:27:00,039 --> 00:27:04,480
openness.org this do a search for cube

00:27:02,880 --> 00:27:07,600
oven cube obn

00:27:04,480 --> 00:27:08,799
and you'll see a specific cni that we've

00:27:07,600 --> 00:27:12,640
integrated

00:27:08,799 --> 00:27:14,640
to you know if you want to implement obs

00:27:12,640 --> 00:27:16,400
or obs dpdk

00:27:14,640 --> 00:27:20,399
in your cloud native environment that's

00:27:16,400 --> 00:27:21,760
the recipe that you can use uh there's

00:27:20,399 --> 00:27:24,080
another question on

00:27:21,760 --> 00:27:26,240
um have any components of setup be

00:27:24,080 --> 00:27:27,039
deployed in telcos already yes so we

00:27:26,240 --> 00:27:29,440
have

00:27:27,039 --> 00:27:30,080
um so like like we talked about earlier

00:27:29,440 --> 00:27:33,840
there are

00:27:30,080 --> 00:27:36,399
uh deployments today for the 4g

00:27:33,840 --> 00:27:37,679
on-premise version of zela we have

00:27:36,399 --> 00:27:41,200
deployments in a

00:27:37,679 --> 00:27:43,360
uh in more of an enterprise context

00:27:41,200 --> 00:27:45,360
this includes a private wireless

00:27:43,360 --> 00:27:47,600
deployment in an industrial context as

00:27:45,360 --> 00:27:49,520
well as a retail context

00:27:47,600 --> 00:27:51,200
we are moving now into the near edge so

00:27:49,520 --> 00:28:03,840
you start to see more near edge type

00:27:51,200 --> 00:28:03,840
diplomas in future

00:28:14,720 --> 00:28:18,080
all right um do you have a couple more

00:28:16,480 --> 00:28:21,679
minutes is there any more questions or

00:28:18,080 --> 00:28:21,679
anything else from the audience

00:28:27,039 --> 00:28:31,039
all right well if not precaution review

00:28:29,360 --> 00:28:33,279
thank you so much for your time this

00:28:31,039 --> 00:28:35,520
is great um we're going to end it a

00:28:33,279 --> 00:28:37,120
minute early thanks for your time

00:28:35,520 --> 00:28:39,279
thank you so much thank you for having

00:28:37,120 --> 00:28:45,840
us here

00:28:39,279 --> 00:28:45,840
oh you better thank you

00:28:49,279 --> 00:28:51,360

YouTube URL: https://www.youtube.com/watch?v=9EWqJPmgXcY


