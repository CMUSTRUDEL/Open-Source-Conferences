Title: Karl Broman - Data cleaning principles
Publication date: 2021-05-19
Playlist: CSVConf 2021
Description: 
	Why don't we teach data cleaning? It has been said that it is difficult to generalize: that what we learn from cleaning Medicare data cannot be readily applied to the cleaning of RNA-seq data. To the contrary, I think there are important general principles for cleaning data, and there are more commonalities in the creative process of data cleaning than in other aspects of data analysis. I will seek to delineate and illustrate these principles, which include:
(1) think about what might have gone wrong and how it might be revealed
(2) study the pattern of missing data and ask why they are missing
(3) use care when merging datasets and focus on labels not position
(4) if things are supposed to match, check that they do
(5) if things are supposed to be distinct, check that they are
(6) look for outliers and other oddities by making lots of plots, particularly scatterplots
(7) look for batch effects by making lots of plots, particularly plots against time and scatterplots colored by batch
(8) ask for the primary data and also metadata
(9) don’t be shy about asking questions
(10) document not just what you did but also why you did it
(11) don’t trust anyone (even yourself)
(12) allocate sufficient time and energy to the effort
Captions: 
	00:00:05,488 --> 00:00:08,880
Karl: I'm a statistician working  mostly in mouse genetics.  

00:00:09,760 --> 00:00:16,320
I spend a lot of time cleaning data. And have any  of us had any formal training in data cleaning?  

00:00:17,520 --> 00:00:24,240
Some say that it's just difficult to  generalize. Hadley Wickham wrote that  

00:00:24,240 --> 00:00:30,960
"Tidy data are all alike, but every messy  dataset is messy in its own way." He was  

00:00:30,960 --> 00:00:38,000
talking about data structure rather than cleaning.  But still is every messy dataset uniquely messy? 

00:00:41,200 --> 00:00:43,840
My collaborators do show  

00:00:45,280 --> 00:00:52,320
great creativity in their data handling. But we  also see many of the same problems repeatedly.  

00:00:55,920 --> 00:01:01,280
Roger Peng asked "If I clean -- clean up  Medicare data -- does any of the knowledge  

00:01:01,280 --> 00:01:10,160
I gain apply to the processing of RNA-seq data?" My response is, absolutely. The context matters,  

00:01:10,160 --> 00:01:16,560
but cleaning one dataset is good for the next one,  even if it's from a completely different field.  

00:01:21,360 --> 00:01:28,320
One of the -- the best things to happen in this  pandemic was Data Mishaps Night. A short Friday  

00:01:28,320 --> 00:01:32,560
night conference where 16 people gave 5-minute  talks about mistakes they'd made with data.  

00:01:33,680 --> 00:01:38,720
Many concerned data cleaning.  And I felt a great closeness with  

00:01:38,720 --> 00:01:42,240
the community through our shared  experience and struggles with data.  

00:01:44,320 --> 00:01:48,880
We may actually have more in common in our data  cleaning efforts than in the rest of or work. 

00:01:52,080 --> 00:01:57,520
So, I think the reason that we don't teach  data cleaning is that it's tedious, the  

00:01:57,520 --> 00:02:04,160
results are often embarrassing. It does need the  context. And it often doesn't feel like progress.  

00:02:05,920 --> 00:02:13,280
Like, how many students are gonna be excited  to sign up for a course called "Data cleaning"? 

00:02:16,560 --> 00:02:23,200
At the same time, it requires, you know, enormous  creativity. And our most advanced programming  

00:02:23,200 --> 00:02:29,200
skills. And what we do in data cleaning  has a huge effect on the final results.  

00:02:31,760 --> 00:02:37,040
I think that there are principles that  underlie our data cleaning work. And  

00:02:37,040 --> 00:02:43,280
I would like to propose a set. I've split  them into five parts. Some fundamental ideas  

00:02:43,280 --> 00:02:49,840
plus four main concepts. Verify,  explore, ask, and document. 

00:02:53,120 --> 00:02:57,360
The first fundamental principle is, don't  clean data when you're tired or hungry.  

00:02:58,880 --> 00:03:03,840
Ghazal Gulati said this at the Data  Mishaps Might. And we were all like,  

00:03:04,880 --> 00:03:12,720
right on. Data cleaning requires time  and really intense concentration. So,  

00:03:14,240 --> 00:03:17,840
you know, grab a Snickers and a  cup of coffee before you again.  

00:03:20,160 --> 00:03:26,480
The next is don't trust anyone, even  yourself. Maybe someone you really  

00:03:26,480 --> 00:03:34,160
respect compiled the data. Maybe it was  you. But still, you should double check. 

00:03:36,480 --> 00:03:41,600
Jenny Bryan once Tweeted, "My motto is  trust no one... except maybe kwbroman?"  

00:03:43,200 --> 00:03:51,120
Which is maybe one of the nicest things ever  said about me. But still, don't trust him either. 

00:03:57,120 --> 00:04:01,600
The central principle for me is think about  what might have gone wrong and how it might be  

00:04:01,600 --> 00:04:08,400
revealed. This -- the illustration here is from  what's maybe my biggest data cleaning success.  

00:04:09,920 --> 00:04:15,360
A genetics project where 20% of the samples  ended up -- almost 20% of the samples were  

00:04:17,120 --> 00:04:25,360
mixed up. The DNA samples were arranged in these  8x12 grids and a dot here is indicating that  

00:04:26,160 --> 00:04:30,800
a sample was in the correct place. But the arrows  are pointing from where a sample should have been  

00:04:32,400 --> 00:04:39,280
to where it actually turned up. So, there's some  long range sample swaps. But then a big series  

00:04:39,280 --> 00:04:46,240
of off by one and off by two errors. Came to this  understanding of these sample mixups by following  

00:04:46,240 --> 00:04:51,520
this basic principle of, Think about what might  have gone wrong and how it can be revealed. 

00:04:54,880 --> 00:05:02,160
Four, use care when merging data files. I  call this a fundamental principle because  

00:05:02,160 --> 00:05:07,120
a lot of the problems that show up have to do  with the merging of data files. Here are two  

00:05:08,400 --> 00:05:14,640
different batches of data where the columns have  been -- the order of the columns have changed.  

00:05:16,240 --> 00:05:22,560
Kind of a key point here is to focus on the  labels on the columns rather than the position.  

00:05:22,560 --> 00:05:26,480
But, you know, use care when merging files  because this sort of thing happens all the time. 

00:05:29,520 --> 00:05:37,200
Principle five, dates and categories suck. You'll  spend much of your time trying to deal with  

00:05:37,200 --> 00:05:41,040
inconsistencies, typos in dates  and categorical variables.  

00:05:43,840 --> 00:05:50,240
You may be wondering, how is that a principle?  I'm with you. I was thinking the same thing. Like  

00:05:51,120 --> 00:05:57,840
what is a principle? So, my working definition  is that a principle is a fundamental truth that  

00:05:57,840 --> 00:06:05,840
guides our thinking. And with that definition, I  would say, you know, dates and categories suck.  

00:06:07,840 --> 00:06:10,480
Fundamental principle that  guides our thinking, you know,  

00:06:11,040 --> 00:06:15,520
this -- this counts as a principle. I'm  gonna -- principle broadly considered.  

00:06:15,520 --> 00:06:21,440
But this is totally a principle. And, you know,  be glad if you're not working with time zones. 

00:06:23,840 --> 00:06:28,160
Moving to the next section is verify.  Basically, think about all the things that  

00:06:28,720 --> 00:06:35,200
should be true about the data and check that  they actually are true. Principle six is, check  

00:06:35,200 --> 00:06:40,400
the things that are supposed to be distinct really  are distinct. So, here's a dataset where there's a  

00:06:40,960 --> 00:06:46,160
subject ID, identifier column, that each  value is supposed to appear no more than  

00:06:46,160 --> 00:06:51,840
once. And I found a couple of IDs that are  in duplicate. Where one of them was a typo. 

00:06:54,240 --> 00:06:59,520
Seven, check that things that are supposed to  match actually match. So, if the same data are  

00:06:59,520 --> 00:07:05,520
repeated between two files, check that their  -- it's the same data in both cases. Here,  

00:07:06,960 --> 00:07:13,760
one subjects for this number of generations  column was 22 in one file and 21 in another  

00:07:13,760 --> 00:07:17,360
file. If there are those kinds of mistakes, you  want to find them. So, you need to look for them. 

00:07:19,040 --> 00:07:24,480
And eight, check any calculations. Any  calculations that were done, check,  

00:07:24,480 --> 00:07:30,880
you know, verify them. So, HOMA_IR, this  is the ratio of serum glucose to insulin.  

00:07:32,320 --> 00:07:39,440
If that's provided, you can check, recalculate  it, that's useful for finding errors and for  

00:07:40,240 --> 00:07:43,840
checking your understanding of the calculation. 

00:07:45,760 --> 00:07:51,280
Plotting my calculation against the provided  values. I like to pull out the missing values  

00:07:51,280 --> 00:07:57,360
in the margins. And that was useful here because  it shows some value that were missing for this  

00:07:57,360 --> 00:08:01,760
calculated value that maybe shouldn't have been  missing because glucose and insulin were provided.  

00:08:02,800 --> 00:08:06,640
And then if you're looking for differences, if  you're -- I mean, that's what we're trying to  

00:08:06,640 --> 00:08:11,440
do here. See how they were different. It's often  best to calculate the differences and plot those  

00:08:11,440 --> 00:08:16,480
directly. So, here I'm plotting the difference  between my calculated value and the provided  

00:08:16,480 --> 00:08:21,360
value and you see that for the most part it is  -- they differ just by some round off error.  

00:08:22,160 --> 00:08:26,640
But there are a batch of values where  they were rounded maybe more coarsely. 

00:08:28,640 --> 00:08:32,240
I see this a lot with, you know,  some sort of copy-paste action.  

00:08:35,280 --> 00:08:38,000
And you also notice here, a  batch of values that are missing  

00:08:38,640 --> 00:08:40,720
that are maybe the same as these values over here. 

00:08:44,400 --> 00:08:49,120
And then nine, look for -- if you find a problem  -- look for other instances of that problem. You  

00:08:49,120 --> 00:08:56,000
know, this is just like say debugging code. If you  find a bug, you identify what mistake you made,  

00:08:56,000 --> 00:09:00,560
you should always look for are there any  other -- did you make that mistake elsewhere?  

00:09:02,480 --> 00:09:06,320
So, having verified what you --  what should be true about the data,  

00:09:06,320 --> 00:09:11,360
you move to kind of exploring the data  more broadly to try to find other problems.  

00:09:12,000 --> 00:09:19,440
And principle ten is just make lots of plots.  Plot -- plot things by time or the order that  

00:09:19,440 --> 00:09:26,480
they appear in the file. This particular plot of  IL3 against the order in which the measurements  

00:09:26,480 --> 00:09:30,560
were made showed that the measurement went  kind of wonky halfway through the project. 

00:09:34,720 --> 00:09:41,040
Make scatterplots. So, this is a plot of  6 week body weight against 10 week body  

00:09:41,600 --> 00:09:45,600
weight. And you can see everything mostly  looks good. But there are a couple of  

00:09:46,240 --> 00:09:54,560
individuals -- these are mice -- that this one  lost a lot of weight. And this one gained a lot  

00:09:54,560 --> 00:09:59,200
of weight. But it -- it turned out they were right  next to each other and it was just that two of  

00:09:59,200 --> 00:10:07,680
the -- two of the data points got transposed. And mostly, you're making plots and looking  

00:10:07,680 --> 00:10:12,960
for outliers. And then try to figure out  outliers are caused by. You're looking for  

00:10:12,960 --> 00:10:24,800
error in the data they show up as out liers.  There were values close to zero. It turns out  

00:10:25,600 --> 00:10:28,240
those measurements are were in  grams rather than milligrams.  

00:10:31,040 --> 00:10:35,040
You look at this plot and you see some kind of  batch effects too. These are kind of high, these  

00:10:35,040 --> 00:10:45,440
are kind of low. And then it's kind of high here. And then -- and then always look at the pattern  

00:10:45,440 --> 00:10:51,520
of missing values. A couple R packages that are  really useful for are with visdat which gives you  

00:10:52,080 --> 00:11:01,360
a heatmap -- shows you which values are missing  that can often be useful. And this other package.  

00:11:04,240 --> 00:11:08,400
Makes it easy to make -- it has a lot of  tools for finding missing -- or studying  

00:11:08,400 --> 00:11:14,960
missing values or making use of missing values  or dealing with them. Including scatterplots that  

00:11:14,960 --> 00:11:19,040
instead of hiding the missing values,  that they highlight them in the margins. 

00:11:22,720 --> 00:11:28,240
And next, with massive datasets, you should  be making more plots rather than fewer.  

00:11:28,800 --> 00:11:34,960
There's often a tendency that you think, I can't  look at 500 histograms. And so, you end up looking  

00:11:34,960 --> 00:11:42,800
at no histograms. You can look at 500 histograms.  You can put 25 on a page and flip through a  

00:11:42,800 --> 00:11:49,600
PDF that has 20 pages. Maybe sort them by some  variable like how variable they are. Or here I've  

00:11:51,680 --> 00:11:57,093
created a bunch of density estimates and super  posed them. So, 500 density estimates super-posed.  

00:11:58,240 --> 00:12:02,080
It's sometimes useful to highlight those  that are most variable to try to look for,  

00:12:02,880 --> 00:12:09,840
is there a group that's really different? I always like to calculate summary statistics  

00:12:09,840 --> 00:12:17,040
and make a scatterplot of those. Here I have  the inter-quartile range versus the median.  

00:12:20,840 --> 00:12:24,400
Showing a group of samples that are  quite different from the others.  

00:12:26,400 --> 00:12:34,800
Or, you know, to try to make -- to try to explore  graphically massive datasets, you need to maybe  

00:12:34,800 --> 00:12:39,600
think a little differently about what are  our standard plots? So, this is sort of the  

00:12:39,600 --> 00:12:46,000
equivalent of 500 box plots smashed against each  other and going farther out into the tails. Each  

00:12:46,800 --> 00:12:53,280
is a quantile. The median in blue. I have sorted  the samples from the highest median to the lowest.  

00:12:53,280 --> 00:13:07,840
And the 25th and 75th in black, and the 10th and  50th and 2th and 95th and the first and ninth. The  

00:13:07,840 --> 00:13:15,440
first 120 samples or so have a elevated median and  a long left tail. Something really weird happened. 

00:13:18,320 --> 00:13:26,800
And principle 13, follow up any artifacts.  This is a heatmap of a correlation matrix.  

00:13:27,520 --> 00:13:34,640
With a questionable choice of color  scale and a weird plaid pattern.  

00:13:35,920 --> 00:13:42,560
If you see this kind of abomination, you  should ask, what happened? And not just about  

00:13:44,240 --> 00:13:50,960
Karl's color choices. But also, what happened to  his data? What led to this -- this awful picture?  

00:13:54,240 --> 00:13:56,080
Running short on time. So, I will  

00:13:58,640 --> 00:14:04,160
do the next two kind of more quickly. The next  two batches of principles. Sort of a key principle  

00:14:04,160 --> 00:14:10,240
is ask questions. Feel -- don't be shy about  asking questions. Ask questions. Ask for the  

00:14:10,240 --> 00:14:17,120
primary data. Ask for the metadata. Like, what  the heck are these data? And ask why data are  

00:14:17,120 --> 00:14:22,640
missing? Are the values -- the missing values,  are they gonna introduce bias in some way? Are  

00:14:22,640 --> 00:14:28,480
they missing just because something didn't work  or the values were too low or the values too high?  

00:14:29,680 --> 00:14:34,400
And document what you did. Create checklists and pipelines to,  

00:14:35,760 --> 00:14:39,920
you know, just sort of -- so that the next  person or with the next dataset that you  

00:14:39,920 --> 00:14:45,760
can build on what you've learned from this  dataset. And your data cleaning work needs  

00:14:45,760 --> 00:14:50,960
to be more than just reproducible. You should  document not just what you did, but also why  

00:14:50,960 --> 00:14:58,960
you chose to do it. And data cleaning is not just  like a step in a longer process, but it's really  

00:15:00,560 --> 00:15:10,720
kind of -- it -- it's a continual process that  you will return to repeatedly. As you learn more  

00:15:10,720 --> 00:15:14,720
about the data, that will lead you to think,  again, about other things that you might check  

00:15:14,720 --> 00:15:20,640
or other hints that something might be wrong. That  you'll come back to it and see it all over again. 

00:15:22,480 --> 00:15:30,480
So, these are my 20 proposed data cleaning  principles. Some fundamental things like  

00:15:30,480 --> 00:15:39,840
don't trust anyone. And then the four main  groups of verify, explore, ask and document. 

00:15:42,480 --> 00:15:48,720
Allison Reichel Tweeted: I will let the  data speak for itself when it cleans itself. 

00:15:52,240 --> 00:16:01,600
Every time I read that, I get a little jolt  of joy. But yeah. The data -- they will not  

00:16:01,600 --> 00:16:08,240
be cleaning themselves. We will be doing data  cleaning as an important part of our work, always.  

00:16:14,400 --> 00:16:19,200
So, thanks so much for having me. I'm  so glad to participate in this awesome  

00:16:19,200 --> 00:16:23,280
conference. I'm looking forward to the next  two days. And here is where you can find  

00:16:23,280 --> 00:16:31,920
me and here is where you can find my slides. Serah: Fantastic! Thank you so much for sharing  

00:16:31,920 --> 00:16:40,400
this excellent advice. And remind us, Karl. We  have time for one question. It's from Caitlin.  

00:16:40,400 --> 00:16:46,960
And Caitlin asks: Do you have any advice for how  to collaborate with principle investigators to  

00:16:46,960 --> 00:16:54,000
improve collection or generate clean data  prior to them sending it to statisticians? 

00:16:56,160 --> 00:17:05,920
Karl: I wish. It -- I mean, you  form relationships with people.  

00:17:06,640 --> 00:17:13,760
And have them both appreciate your work and  you be sensitive about their difficulties. And,  

00:17:13,760 --> 00:17:19,760
you know, you really make it a very  long-term collaboration. I think my approach  

00:17:21,040 --> 00:17:29,200
in my career has not always been very good.  So, I'm not, I think, maybe the best person  

00:17:29,200 --> 00:17:35,040
to -- it will be -- I'll be interested to see the  discussion on Slack about that point because it's  

00:17:35,040 --> 00:17:36,760
really important. Serah:  

00:17:38,720 --> 00:17:44,080
Amazing. Thank you. We have 2 minutes  to go. So, I will go right down to the  

00:17:44,080 --> 00:17:50,000
bottom. And someone asked -- Kim asked, for  the purposes of spreading the word, how are  

00:17:50,000 --> 00:17:58,640
you defining "Cleaning" in the first place? Karl: Yeah. I would say, you know, identify  

00:18:00,880 --> 00:18:07,040
problems in the data that will affect the  results and that you'll want to try to fix  

00:18:15,280 --> 00:18:17,440
that I guess that's how I define it.  

00:18:18,400 --> 00:18:21,560
I mean, keep it broad? Serah:  

00:18:24,080 --> 00:18:29,680

YouTube URL: https://www.youtube.com/watch?v=7Ma8WIDinDc


