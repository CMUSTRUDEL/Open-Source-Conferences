Title: Bernease Herman - Static datasets aren't enough: where deployed systems differ from research
Publication date: 2021-05-20
Playlist: CSVConf 2021
Description: 
	The focus on static datasets in machine learning and AI training fails to translate to how these systems are being deployed in industry. As a result, data scientists and engineers aren't considering how these systems perform in changing, real world environments nor the feedback mechanisms and societal implications that these systems can cause. In the session, we will highlight existing tools that work with dynamic (and perhaps streaming) data. We will suggest some preliminary studies of activities and lessons that may bridge the gap in data science training for realistic data.The goal of the talk is to:
- Point to resources for AI practitioners to engage with dynamic datasets
- Engage in discussion about the impact of feedback loops and other consequences on the real world
- Brainstorm new approaches to teaching skills on dynamic datasets
Find Bernease Herman's work on GitHub · View Talk Slides ·
Captions: 
	00:00:03,040 --> 00:00:07,200
hi everyone

00:00:04,080 --> 00:00:08,960
um i'm bernice herman i am a data

00:00:07,200 --> 00:00:12,000
scientist at y labs

00:00:08,960 --> 00:00:15,599
and i'm here to talk to you today about

00:00:12,000 --> 00:00:18,640
why static data sets aren't enough

00:00:15,599 --> 00:00:21,119
and where deployed systems differ from

00:00:18,640 --> 00:00:21,119
research

00:00:21,279 --> 00:00:25,760
just to note that i this work does not

00:00:24,240 --> 00:00:27,039
represent the views or the work

00:00:25,760 --> 00:00:28,160
conducted at the university of

00:00:27,039 --> 00:00:32,160
washington where i

00:00:28,160 --> 00:00:35,920
also am a data scientist

00:00:32,160 --> 00:00:37,440
okay so um why why do i feel like static

00:00:35,920 --> 00:00:39,680
data sets aren't enough

00:00:37,440 --> 00:00:40,800
um i would say that my varied

00:00:39,680 --> 00:00:43,120
experiences

00:00:40,800 --> 00:00:45,680
in both industry and academia have

00:00:43,120 --> 00:00:48,719
informed these views for me

00:00:45,680 --> 00:00:49,760
so currently i am a data scientist at y

00:00:48,719 --> 00:00:52,879
labs

00:00:49,760 --> 00:00:53,440
the ai observability company and we've

00:00:52,879 --> 00:00:55,680
created

00:00:53,440 --> 00:00:57,520
and maintained y logs an open source

00:00:55,680 --> 00:00:59,840
data logging library

00:00:57,520 --> 00:01:02,239
that uses statistical profiling for an

00:00:59,840 --> 00:01:05,520
efficient logging solution that scales

00:01:02,239 --> 00:01:05,520
and works in real time

00:01:08,000 --> 00:01:10,960
many more features

00:01:11,280 --> 00:01:16,479
so i apologize could you hear me for

00:01:14,880 --> 00:01:17,280
that i'm gonna i'll i'll just repeat it

00:01:16,479 --> 00:01:20,799
just in case

00:01:17,280 --> 00:01:23,280
so i'm a data scientist at y labs um

00:01:20,799 --> 00:01:23,920
the ai observability company we created

00:01:23,280 --> 00:01:26,880
and maintain

00:01:23,920 --> 00:01:27,680
y logs an open source data logging

00:01:26,880 --> 00:01:30,000
library

00:01:27,680 --> 00:01:32,240
that uses statistical profiling for an

00:01:30,000 --> 00:01:34,000
efficient logging solution that scales

00:01:32,240 --> 00:01:36,000
and works in real time

00:01:34,000 --> 00:01:39,759
i'm also a research scientist at the

00:01:36,000 --> 00:01:42,640
university of washington e-science

00:01:39,759 --> 00:01:43,119
and there we do a number of programs so

00:01:42,640 --> 00:01:45,600
i

00:01:43,119 --> 00:01:47,520
conduct research on evaluation metrics

00:01:45,600 --> 00:01:50,479
and model interpretability

00:01:47,520 --> 00:01:50,799
i also run um along with the others at

00:01:50,479 --> 00:01:53,920
the

00:01:50,799 --> 00:01:55,360
science institute programs like the

00:01:53,920 --> 00:01:56,320
summer data science for social good

00:01:55,360 --> 00:01:58,960
program and

00:01:56,320 --> 00:02:00,719
academic hack weeks and other programs

00:01:58,960 --> 00:02:02,799
um prior to that i was a software

00:02:00,719 --> 00:02:04,880
engineering at amazon and uh

00:02:02,799 --> 00:02:06,079
prior to that research did research at

00:02:04,880 --> 00:02:08,479
morgan stanley

00:02:06,079 --> 00:02:09,360
all of those things kind of feed into my

00:02:08,479 --> 00:02:11,920
views

00:02:09,360 --> 00:02:13,680
on how we think about static data sets

00:02:11,920 --> 00:02:14,319
and how we think about real time data

00:02:13,680 --> 00:02:16,239
sets

00:02:14,319 --> 00:02:19,360
because there are some real differences

00:02:16,239 --> 00:02:21,520
across industry and academia

00:02:19,360 --> 00:02:22,800
all right so many of the machine

00:02:21,520 --> 00:02:26,400
learning and data science

00:02:22,800 --> 00:02:29,680
resources and um and tutorials and um

00:02:26,400 --> 00:02:30,800
and learning you do surround are kind of

00:02:29,680 --> 00:02:33,519
surrounded by

00:02:30,800 --> 00:02:34,879
static data sets uh so some example data

00:02:33,519 --> 00:02:36,879
sets up here

00:02:34,879 --> 00:02:38,160
these are data sets that uh you know

00:02:36,879 --> 00:02:40,720
have been collected

00:02:38,160 --> 00:02:41,280
maybe from the internet maybe uh curated

00:02:40,720 --> 00:02:43,519
uh

00:02:41,280 --> 00:02:45,280
more specifically in some way but they

00:02:43,519 --> 00:02:45,840
reference they're represented by just

00:02:45,280 --> 00:02:49,440
one

00:02:45,840 --> 00:02:53,040
large you know csv file or

00:02:49,440 --> 00:02:56,879
hdf5 or any any other source

00:02:53,040 --> 00:02:56,879
but they're treated kind of as a whole

00:02:56,959 --> 00:03:01,040
but realistic data sets especially when

00:02:59,920 --> 00:03:04,319
you deploy

00:03:01,040 --> 00:03:07,280
systems in the real world often

00:03:04,319 --> 00:03:08,239
um change over time so here's an example

00:03:07,280 --> 00:03:09,599
of a csv

00:03:08,239 --> 00:03:11,599
which i think you have to include for

00:03:09,599 --> 00:03:14,319
this conference um of

00:03:11,599 --> 00:03:15,760
pronto which is a bike-sharing company

00:03:14,319 --> 00:03:18,640
that was in seattle

00:03:15,760 --> 00:03:19,519
um and they have a the data of all of

00:03:18,640 --> 00:03:23,120
the bike

00:03:19,519 --> 00:03:25,599
trips for some period of time

00:03:23,120 --> 00:03:26,560
this is a classic example of a data set

00:03:25,599 --> 00:03:29,680
that um

00:03:26,560 --> 00:03:32,879
that does have several columns

00:03:29,680 --> 00:03:34,480
with time and really when we analyze

00:03:32,879 --> 00:03:35,200
these data sets we should be thinking

00:03:34,480 --> 00:03:37,440
about them

00:03:35,200 --> 00:03:38,480
with that time in mind we're indexing by

00:03:37,440 --> 00:03:41,760
time uh

00:03:38,480 --> 00:03:43,840
and we're also um if we if we think

00:03:41,760 --> 00:03:47,440
about our analysis we shouldn't

00:03:43,840 --> 00:03:49,920
assume that we have future data

00:03:47,440 --> 00:03:52,000
we should be thinking about our analysis

00:03:49,920 --> 00:03:54,080
only looking at the past never looking

00:03:52,000 --> 00:03:56,879
forward

00:03:54,080 --> 00:03:58,959
right and here's one one graph of that

00:03:56,879 --> 00:04:00,400
from the y logs open source library

00:03:58,959 --> 00:04:02,080
we'll talk a little bit more about that

00:04:00,400 --> 00:04:04,720
later

00:04:02,080 --> 00:04:05,680
so in deployed systems uh the static

00:04:04,720 --> 00:04:08,159
approach

00:04:05,680 --> 00:04:11,040
uh to having a data set leads to kind of

00:04:08,159 --> 00:04:12,959
these periodic data set patches

00:04:11,040 --> 00:04:14,080
so and model retraining so you'll start

00:04:12,959 --> 00:04:16,560
with a static data

00:04:14,080 --> 00:04:18,880
set uh you'll do your experiments your

00:04:16,560 --> 00:04:21,199
training your evaluation

00:04:18,880 --> 00:04:22,240
and then deploy it and then at some

00:04:21,199 --> 00:04:24,639
point

00:04:22,240 --> 00:04:26,639
who knows when uh maybe maybe you've

00:04:24,639 --> 00:04:27,840
seen you've run into issues or maybe you

00:04:26,639 --> 00:04:30,479
just feel like you've

00:04:27,840 --> 00:04:32,000
enough time has passed or you've gotten

00:04:30,479 --> 00:04:35,360
a significant amount of

00:04:32,000 --> 00:04:36,880
um inference on that data set you might

00:04:35,360 --> 00:04:40,320
take that data

00:04:36,880 --> 00:04:43,040
that that you've applied while deployed

00:04:40,320 --> 00:04:44,320
and included into that static training

00:04:43,040 --> 00:04:47,199
data set that we have

00:04:44,320 --> 00:04:48,320
to retrain or uh to to update kind of

00:04:47,199 --> 00:04:50,000
our data set

00:04:48,320 --> 00:04:51,520
um and so i'm considering that kind of a

00:04:50,000 --> 00:04:54,160
patch to this data set

00:04:51,520 --> 00:04:56,479
um and it creates this this singular

00:04:54,160 --> 00:04:58,160
updated data set these are static data

00:04:56,479 --> 00:05:00,160
sets

00:04:58,160 --> 00:05:01,759
these are static data sets despite the

00:05:00,160 --> 00:05:05,039
fact that we live in this

00:05:01,759 --> 00:05:06,639
kind of time world

00:05:05,039 --> 00:05:09,360
but maybe we should be logging and

00:05:06,639 --> 00:05:11,520
storing our data in a dynamic way

00:05:09,360 --> 00:05:12,720
so just getting your head around the

00:05:11,520 --> 00:05:15,440
concept that

00:05:12,720 --> 00:05:17,520
we have static training data set we may

00:05:15,440 --> 00:05:18,320
do our experimentation and training and

00:05:17,520 --> 00:05:20,960
evaluation

00:05:18,320 --> 00:05:22,880
on that static data set but after we

00:05:20,960 --> 00:05:25,039
deploy this data set

00:05:22,880 --> 00:05:27,199
we are going to continue to see more

00:05:25,039 --> 00:05:30,560
data that gets included

00:05:27,199 --> 00:05:31,520
into uh the the data that we have at our

00:05:30,560 --> 00:05:33,360
disposal

00:05:31,520 --> 00:05:34,560
um and we should be thinking about that

00:05:33,360 --> 00:05:37,440
data in that way

00:05:34,560 --> 00:05:38,000
um that these are all separate data sets

00:05:37,440 --> 00:05:41,680
that can

00:05:38,000 --> 00:05:44,080
be combined as opposed to thinking about

00:05:41,680 --> 00:05:45,440
them as one fixed data set that will

00:05:44,080 --> 00:05:47,560
never change

00:05:45,440 --> 00:05:49,120
um that doesn't allow us to kind of

00:05:47,560 --> 00:05:51,680
dynamically

00:05:49,120 --> 00:05:53,039
add to our training data set or not our

00:05:51,680 --> 00:05:53,840
training data set but our data set

00:05:53,039 --> 00:05:58,160
overall

00:05:53,840 --> 00:06:00,160
uh over which you can later do training

00:05:58,160 --> 00:06:02,720
and so this is why we've created and

00:06:00,160 --> 00:06:05,759
open source our library y logs

00:06:02,720 --> 00:06:06,479
um at y labs this is uh this library is

00:06:05,759 --> 00:06:09,039
all about

00:06:06,479 --> 00:06:11,520
um statistically profiling um and

00:06:09,039 --> 00:06:14,319
monitoring your machine learning data

00:06:11,520 --> 00:06:15,039
from end to end um and using these

00:06:14,319 --> 00:06:17,840
concepts

00:06:15,039 --> 00:06:18,720
of time and batches that that we're

00:06:17,840 --> 00:06:22,000
going to

00:06:18,720 --> 00:06:23,199
um oh it's a bit patchy that we're going

00:06:22,000 --> 00:06:26,000
to

00:06:23,199 --> 00:06:28,800
continue to think about our data in this

00:06:26,000 --> 00:06:32,000
real-time way and this really is the way

00:06:28,800 --> 00:06:33,919
that going forward um as you deploy

00:06:32,000 --> 00:06:36,800
real systems in the world you should be

00:06:33,919 --> 00:06:40,240
thinking about your data

00:06:36,800 --> 00:06:42,240
so my goal here is to really start a

00:06:40,240 --> 00:06:44,960
conversation about

00:06:42,240 --> 00:06:46,479
time-batch data and other skills that

00:06:44,960 --> 00:06:48,400
that might be missing from the data

00:06:46,479 --> 00:06:51,360
science learning pathways

00:06:48,400 --> 00:06:52,880
that um if you do as i've done and

00:06:51,360 --> 00:06:54,560
transitioned back and forth between

00:06:52,880 --> 00:06:56,720
academia and industry

00:06:54,560 --> 00:06:58,000
you really find are lacking in some

00:06:56,720 --> 00:07:00,400
places in academia

00:06:58,000 --> 00:07:03,759
and some in places in industry as well

00:07:00,400 --> 00:07:07,440
um but really this like realistic

00:07:03,759 --> 00:07:10,240
time element is a huge one

00:07:07,440 --> 00:07:11,680
so we shouldn't be ignoring this uh this

00:07:10,240 --> 00:07:14,720
deployment stage right

00:07:11,680 --> 00:07:16,240
the preparation of data um the building

00:07:14,720 --> 00:07:18,560
and training of models those are

00:07:16,240 --> 00:07:20,880
generally in common across all of

00:07:18,560 --> 00:07:22,800
the data scientists that i know but the

00:07:20,880 --> 00:07:25,759
deploying and prediction

00:07:22,800 --> 00:07:27,280
um is not it's so some people especially

00:07:25,759 --> 00:07:28,400
as an academic you really don't think

00:07:27,280 --> 00:07:30,080
about deployment

00:07:28,400 --> 00:07:32,000
and you don't think about the effects

00:07:30,080 --> 00:07:33,599
that deployment has on the way you think

00:07:32,000 --> 00:07:35,759
about the data the way you model

00:07:33,599 --> 00:07:38,160
your data and the way you evaluate your

00:07:35,759 --> 00:07:38,160
data

00:07:38,479 --> 00:07:43,599
so one one thing that's really cool um

00:07:41,759 --> 00:07:45,599
that i won't go too far into but i

00:07:43,599 --> 00:07:48,000
really suggest that you look into

00:07:45,599 --> 00:07:49,680
is progressive validation and delayed

00:07:48,000 --> 00:07:52,720
progressive validation

00:07:49,680 --> 00:07:53,360
so this is a way of validating your data

00:07:52,720 --> 00:07:55,120
kind of

00:07:53,360 --> 00:07:56,840
that that is different from

00:07:55,120 --> 00:07:58,800
cross-validation or really builds on

00:07:56,840 --> 00:08:02,479
cross-validation

00:07:58,800 --> 00:08:02,960
but is meant for the online use case the

00:08:02,479 --> 00:08:04,720
type

00:08:02,960 --> 00:08:06,639
the type of use case where you have

00:08:04,720 --> 00:08:10,319
continuous data going in

00:08:06,639 --> 00:08:12,800
and the main idea is that um we

00:08:10,319 --> 00:08:14,560
we shouldn't be evaluating our data on

00:08:12,800 --> 00:08:17,360
data that is from the future

00:08:14,560 --> 00:08:18,160
so how do you um and perhaps you need

00:08:17,360 --> 00:08:21,199
some delay

00:08:18,160 --> 00:08:23,840
perhaps it takes a while to get the

00:08:21,199 --> 00:08:26,160
ground truth for new data that you have

00:08:23,840 --> 00:08:27,199
and so when you evaluate and run your

00:08:26,160 --> 00:08:30,240
model you shouldn't

00:08:27,199 --> 00:08:31,520
assume that you had that data and that's

00:08:30,240 --> 00:08:32,880
how we should check our model because

00:08:31,520 --> 00:08:34,959
that's how it's going to be deployed in

00:08:32,880 --> 00:08:37,680
the real world

00:08:34,959 --> 00:08:40,000
all right so all data scientists need

00:08:37,680 --> 00:08:42,880
these skills for time batch data

00:08:40,000 --> 00:08:45,120
i did yesterday i went on to kaggle and

00:08:42,880 --> 00:08:46,480
by hand looked through the top 40 most

00:08:45,120 --> 00:08:49,839
voted data sets

00:08:46,480 --> 00:08:52,720
and 14 of those 40 had some date or time

00:08:49,839 --> 00:08:54,080
index column that was at least daily and

00:08:52,720 --> 00:08:57,200
so this is an example

00:08:54,080 --> 00:08:57,519
of data that was kind of forced to be in

00:08:57,200 --> 00:08:59,920
a

00:08:57,519 --> 00:09:00,640
csv or in a kind of a static data set

00:08:59,920 --> 00:09:03,120
form

00:09:00,640 --> 00:09:05,440
but really wants to live as this dynamic

00:09:03,120 --> 00:09:07,920
data

00:09:05,440 --> 00:09:09,440
all right and just here's an example of

00:09:07,920 --> 00:09:10,560
some papers talking about the

00:09:09,440 --> 00:09:13,760
relationship between

00:09:10,560 --> 00:09:16,880
academia and industry and um

00:09:13,760 --> 00:09:17,360
showing how much these these two fields

00:09:16,880 --> 00:09:19,760
are

00:09:17,360 --> 00:09:21,600
converging and working together and

00:09:19,760 --> 00:09:22,000
motivating hopefully the academics to

00:09:21,600 --> 00:09:24,640
also

00:09:22,000 --> 00:09:25,360
think about the same time batch data

00:09:24,640 --> 00:09:27,120
even if you

00:09:25,360 --> 00:09:28,560
previously thought of it as a deployment

00:09:27,120 --> 00:09:31,760
thing

00:09:28,560 --> 00:09:33,519
um and one thing so one reason that i am

00:09:31,760 --> 00:09:34,320
a data scientist and one thing that i'm

00:09:33,519 --> 00:09:36,720
really

00:09:34,320 --> 00:09:38,240
motivated by is the impact of data

00:09:36,720 --> 00:09:41,279
science applications

00:09:38,240 --> 00:09:41,920
on the world and i think a lot of that

00:09:41,279 --> 00:09:43,920
impact

00:09:41,920 --> 00:09:45,839
does come from industrial machine

00:09:43,920 --> 00:09:49,040
learning and so

00:09:45,839 --> 00:09:50,000
building the skills in this area and

00:09:49,040 --> 00:09:51,920
other areas that

00:09:50,000 --> 00:09:53,440
align with kind of how these things are

00:09:51,920 --> 00:09:55,760
actually deployed

00:09:53,440 --> 00:09:57,760
for large scale systems are incredibly

00:09:55,760 --> 00:10:01,040
important here are just a number of

00:09:57,760 --> 00:10:04,000
kind of uh very common issues and

00:10:01,040 --> 00:10:05,839
things that have come up within kind of

00:10:04,000 --> 00:10:06,399
machine learning and data science as of

00:10:05,839 --> 00:10:09,600
late

00:10:06,399 --> 00:10:11,440
and how having um knowledge in the

00:10:09,600 --> 00:10:14,000
industrial machine learning space is

00:10:11,440 --> 00:10:17,200
important for everyone

00:10:14,000 --> 00:10:18,640
all right so um to log your data i'll go

00:10:17,200 --> 00:10:19,120
through this very quickly but for while

00:10:18,640 --> 00:10:20,880
logs

00:10:19,120 --> 00:10:22,160
you can log your data in just a few

00:10:20,880 --> 00:10:24,560
lines of code

00:10:22,160 --> 00:10:25,279
this is some code from pi spark but we

00:10:24,560 --> 00:10:28,800
have a

00:10:25,279 --> 00:10:29,920
pure python we have a java and um and

00:10:28,800 --> 00:10:33,120
spark

00:10:29,920 --> 00:10:35,040
for for y logs right now

00:10:33,120 --> 00:10:37,279
and you can explore trends in a few

00:10:35,040 --> 00:10:39,440
lines of code as well so this is um

00:10:37,279 --> 00:10:40,320
using our visualizer to look at a

00:10:39,440 --> 00:10:43,279
specific

00:10:40,320 --> 00:10:45,760
feature in that code and it's very very

00:10:43,279 --> 00:10:48,880
storage computation

00:10:45,760 --> 00:10:51,279
efficient and data analysis friendly

00:10:48,880 --> 00:10:51,920
so that's it for me uh sorry this text

00:10:51,279 --> 00:10:54,800
is so big

00:10:51,920 --> 00:10:57,600
um but do check out why logs at um so

00:10:54,800 --> 00:10:59,519
you can go to bitly.ylogs and

00:10:57,600 --> 00:11:01,920
uh and go to the github website from

00:10:59,519 --> 00:11:05,279
there you can also email me

00:11:01,920 --> 00:11:07,200
at bernice ylabs.ai

00:11:05,279 --> 00:11:10,560
and thank you very much i'm happy to

00:11:07,200 --> 00:11:10,560
answer any questions we have

00:11:10,640 --> 00:11:15,760
thank you for that yeah um we did hear

00:11:13,839 --> 00:11:17,680
uh in the chat there was there's a

00:11:15,760 --> 00:11:20,160
little bit of distortion on the

00:11:17,680 --> 00:11:21,760
display like the resh but i think if you

00:11:20,160 --> 00:11:23,600
can post the slides to

00:11:21,760 --> 00:11:24,959
zenoto afterwards people can definitely

00:11:23,600 --> 00:11:26,560
take a look yes

00:11:24,959 --> 00:11:29,040
um if you have any questions feel free

00:11:26,560 --> 00:11:32,320
to put them in the act ask a question

00:11:29,040 --> 00:11:33,910
and um one of the questions that i have

00:11:32,320 --> 00:11:35,440
is really about um

00:11:33,910 --> 00:11:38,800
[Music]

00:11:35,440 --> 00:11:40,480
you know that the if this is a you know

00:11:38,800 --> 00:11:42,640
it seems to be very connected to the

00:11:40,480 --> 00:11:45,519
idea of quote-unquote versioning

00:11:42,640 --> 00:11:45,839
yes so um you know that the time the

00:11:45,519 --> 00:11:48,320
time

00:11:45,839 --> 00:11:50,079
stamps of you know and when you look at

00:11:48,320 --> 00:11:50,880
data being recorded in places like

00:11:50,079 --> 00:11:52,800
kaggle

00:11:50,880 --> 00:11:55,120
like the way that it's stored is just

00:11:52,800 --> 00:11:57,120
like you know tons and tons of more rows

00:11:55,120 --> 00:11:58,720
it's like you know versions become rows

00:11:57,120 --> 00:12:02,320
and then just it's just like

00:11:58,720 --> 00:12:05,680
completely unmanageable so um

00:12:02,320 --> 00:12:07,760
is there an aspect of this where um

00:12:05,680 --> 00:12:10,160
like people who want to better manage

00:12:07,760 --> 00:12:13,600
that stuff for reuse

00:12:10,160 --> 00:12:14,320
um should you know kind of jump in in a

00:12:13,600 --> 00:12:16,079
different way

00:12:14,320 --> 00:12:17,680
or is it like a training problem that

00:12:16,079 --> 00:12:19,760
people have or is it uh

00:12:17,680 --> 00:12:21,839
is it just uh it's a simple export

00:12:19,760 --> 00:12:23,680
problem like what is the reason why that

00:12:21,839 --> 00:12:25,440
becomes the default

00:12:23,680 --> 00:12:27,360
yeah so i mean i think there's a number

00:12:25,440 --> 00:12:27,920
of reasons why that becomes the default

00:12:27,360 --> 00:12:29,760
i think

00:12:27,920 --> 00:12:31,839
um in machine learning right we have

00:12:29,760 --> 00:12:34,079
this assumption that our data is kind of

00:12:31,839 --> 00:12:36,079
um independent and identically

00:12:34,079 --> 00:12:38,880
distributed so we're already kind of

00:12:36,079 --> 00:12:41,120
assuming that each row of data

00:12:38,880 --> 00:12:42,399
can kind of stand on their own we don't

00:12:41,120 --> 00:12:44,480
we don't um

00:12:42,399 --> 00:12:46,240
we don't build these time assumptions

00:12:44,480 --> 00:12:47,839
into our models i think that

00:12:46,240 --> 00:12:49,839
there's certainly work in that space but

00:12:47,839 --> 00:12:52,880
very little uh so i think that's

00:12:49,839 --> 00:12:55,200
one space that that really kind of

00:12:52,880 --> 00:12:56,000
influences us to lean toward the static

00:12:55,200 --> 00:12:59,200
data

00:12:56,000 --> 00:13:02,800
um but with respect to logging i think

00:12:59,200 --> 00:13:03,440
one big thing is is just the difference

00:13:02,800 --> 00:13:07,040
between

00:13:03,440 --> 00:13:08,959
kind of large scale and

00:13:07,040 --> 00:13:10,079
at a smaller scale i think when we have

00:13:08,959 --> 00:13:12,320
a static data set

00:13:10,079 --> 00:13:13,839
uh you know lots of rows and a csv or

00:13:12,320 --> 00:13:15,839
any other solution

00:13:13,839 --> 00:13:17,279
but that really doesn't work when we

00:13:15,839 --> 00:13:20,000
think about

00:13:17,279 --> 00:13:21,680
lots of deployed systems um and so we

00:13:20,000 --> 00:13:24,880
need to kind of completely

00:13:21,680 --> 00:13:26,800
reimagine this and think about kind of

00:13:24,880 --> 00:13:29,120
approximate statistics and other

00:13:26,800 --> 00:13:32,160
techniques to get away from this

00:13:29,120 --> 00:13:35,200
kind of new data equals new rows and

00:13:32,160 --> 00:13:37,760
in the data set um some people

00:13:35,200 --> 00:13:39,680
in industry do sampling and but sampling

00:13:37,760 --> 00:13:40,639
has a number of problems you lose a lot

00:13:39,680 --> 00:13:42,480
of um

00:13:40,639 --> 00:13:45,279
you lose the min and max and mean and

00:13:42,480 --> 00:13:45,279
lots of other things

00:13:46,560 --> 00:13:50,560
yeah um so

00:13:50,880 --> 00:13:56,560
any other questions from the community

00:13:54,480 --> 00:13:57,600
i think we're we apologize for the late

00:13:56,560 --> 00:14:00,720
start

00:13:57,600 --> 00:14:02,880
no way thank you and so then um y

00:14:00,720 --> 00:14:04,800
labs the y labs link that you put in

00:14:02,880 --> 00:14:08,639
there that's specifically to

00:14:04,800 --> 00:14:10,880
how to use this like yeah to the website

00:14:08,639 --> 00:14:12,240
is there something oh it goes straight

00:14:10,880 --> 00:14:15,360
to github i believe

00:14:12,240 --> 00:14:17,120
okay and so then there is the the

00:14:15,360 --> 00:14:20,959
website as well for additional

00:14:17,120 --> 00:14:24,399
like um yes yes if you go to ylabs.ai

00:14:20,959 --> 00:14:27,040
um you can see more information about

00:14:24,399 --> 00:14:27,600
both um why logs which is the open

00:14:27,040 --> 00:14:30,079
source

00:14:27,600 --> 00:14:32,639
uh library but then also the platform

00:14:30,079 --> 00:14:35,360
that we have on top of that

00:14:32,639 --> 00:14:37,839
makes sense very cool awesome um and

00:14:35,360 --> 00:14:39,199
then let me look real quick and see

00:14:37,839 --> 00:14:41,760
it looks like we have one question that

00:14:39,199 --> 00:14:43,360
just came in from borjan which says

00:14:41,760 --> 00:14:45,760
where do people stumble when picking up

00:14:43,360 --> 00:14:47,920
time batch to data skills

00:14:45,760 --> 00:14:49,279
yeah that's a great question um i think

00:14:47,920 --> 00:14:52,000
one place

00:14:49,279 --> 00:14:53,199
i mean so one is this we don't talk

00:14:52,000 --> 00:14:55,279
about those skills we don't really

00:14:53,199 --> 00:14:56,560
provide as many tutorials or things like

00:14:55,279 --> 00:14:59,360
that for it

00:14:56,560 --> 00:15:00,160
so a major place that people stumble i

00:14:59,360 --> 00:15:01,600
think

00:15:00,160 --> 00:15:04,240
is that they're um they're really not

00:15:01,600 --> 00:15:07,839
used to evaluating

00:15:04,240 --> 00:15:09,600
data um that has this time component so

00:15:07,839 --> 00:15:11,120
when you're evaluating data you really

00:15:09,600 --> 00:15:14,079
need to think about

00:15:11,120 --> 00:15:16,639
um have i seen this data before right

00:15:14,079 --> 00:15:18,560
there there's lots of target poisoning

00:15:16,639 --> 00:15:20,000
which basically says okay well i have

00:15:18,560 --> 00:15:21,519
this information i have both the

00:15:20,000 --> 00:15:23,440
the inputs and the outputs for my

00:15:21,519 --> 00:15:27,040
training data but

00:15:23,440 --> 00:15:28,000
does that poison my evaluation my test

00:15:27,040 --> 00:15:30,240
data set

00:15:28,000 --> 00:15:32,240
and that can happen in a number of ways

00:15:30,240 --> 00:15:33,600
especially when it's time based

00:15:32,240 --> 00:15:35,360
and so i think people really struggle

00:15:33,600 --> 00:15:38,079
with evaluating in particular but

00:15:35,360 --> 00:15:40,720
there's lots of other places

00:15:38,079 --> 00:15:40,720

YouTube URL: https://www.youtube.com/watch?v=JOm2NuSDBio


