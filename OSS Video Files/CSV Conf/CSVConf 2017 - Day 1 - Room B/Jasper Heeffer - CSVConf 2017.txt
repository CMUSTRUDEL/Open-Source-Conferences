Title: Jasper Heeffer - CSVConf 2017
Publication date: 2017-05-28
Playlist: CSVConf 2017 - Day 1 - Room B
Description: 
	
Captions: 
	00:00:01,949 --> 00:00:09,880
all right how y'all doing good yeah so

00:00:08,010 --> 00:00:12,730
probably have loud enough like this

00:00:09,880 --> 00:00:15,190
right so I'm from jetliner and what we

00:00:12,730 --> 00:00:17,830
want to spread is a fact-based worldview

00:00:15,190 --> 00:00:20,350
and how do we know if we're actually

00:00:17,830 --> 00:00:22,990
spreading that well we're trying to get

00:00:20,350 --> 00:00:24,880
effects on how SEC based people's world

00:00:22,990 --> 00:00:26,140
views are so we're asking questions to

00:00:24,880 --> 00:00:29,020
people I want to do one of these

00:00:26,140 --> 00:00:30,400
questions with you today question is how

00:00:29,020 --> 00:00:34,329
many children will there be in the year

00:00:30,400 --> 00:00:37,390
2100 I can tell you that in 1950 we had

00:00:34,329 --> 00:00:41,829
1 billion people in the 2000s we have 2

00:00:37,390 --> 00:00:43,929
billion our children 2 billion mm so

00:00:41,829 --> 00:00:45,940
what will it be in 2100 will be 2

00:00:43,929 --> 00:00:46,929
billion 3 billion or 4 billion hoots

00:00:45,940 --> 00:00:50,730
that's 2 billion

00:00:46,929 --> 00:00:55,059
raise your hand okay reset 3 billion

00:00:50,730 --> 00:00:59,920
okay reset score billion okay okay

00:00:55,059 --> 00:01:01,780
so we're about 30% of something I had a

00:00:59,920 --> 00:01:03,579
right to billion people actually we are

00:01:01,780 --> 00:01:04,500
a peak child right now there will be no

00:01:03,579 --> 00:01:06,640
more children

00:01:04,500 --> 00:01:10,120
adding yeah no more children I'm sorry

00:01:06,640 --> 00:01:12,250
it's a very sad thing so but don't be

00:01:10,120 --> 00:01:14,220
afraid that for people that answer it

00:01:12,250 --> 00:01:16,300
wrong because when we artists to

00:01:14,220 --> 00:01:20,530
representative samples of people in the

00:01:16,300 --> 00:01:23,590
world turns out that people do very very

00:01:20,530 --> 00:01:26,560
bad like 11% since whedon here in the

00:01:23,590 --> 00:01:28,510
u.s. 7% got it right and just to show

00:01:26,560 --> 00:01:30,880
how that that is if you go to the zoo

00:01:28,510 --> 00:01:33,820
and you give a chimp three bananas a B

00:01:30,880 --> 00:01:35,500
and C it will choose 33% of the times

00:01:33,820 --> 00:01:38,320
right so you're doing worse than the

00:01:35,500 --> 00:01:41,260
chimps there's something very wrong

00:01:38,320 --> 00:01:43,240
there so what is it dang that's that

00:01:41,260 --> 00:01:44,650
that's going wrong well we don't think

00:01:43,240 --> 00:01:47,290
people are stupid but people have

00:01:44,650 --> 00:01:49,060
preconceived ideas and that's a problem

00:01:47,290 --> 00:01:51,550
how do we how do we get preconceived

00:01:49,060 --> 00:01:52,900
ideas we say there is people have

00:01:51,550 --> 00:01:55,660
outdated world views from earlier

00:01:52,900 --> 00:01:57,610
education we're not taught how to make a

00:01:55,660 --> 00:02:00,040
world view we're taught a world view and

00:01:57,610 --> 00:02:01,960
that gets outdated after a while on top

00:02:00,040 --> 00:02:04,270
of that our brains are biased toward

00:02:01,960 --> 00:02:05,740
survival not towards fact-based world

00:02:04,270 --> 00:02:08,379
views we have all these biases that

00:02:05,740 --> 00:02:11,650
influences we have like confirmation

00:02:08,379 --> 00:02:14,620
bias negativity bias we crave for fat

00:02:11,650 --> 00:02:15,090
sugar and drama and the drama is then

00:02:14,620 --> 00:02:18,180
what we

00:02:15,090 --> 00:02:20,250
remember so not the actual facts and on

00:02:18,180 --> 00:02:23,069
top of that the media amplifies her

00:02:20,250 --> 00:02:25,200
biases they need to know generate clicks

00:02:23,069 --> 00:02:27,780
they need to sell advertisements myself

00:02:25,200 --> 00:02:29,550
and so they they don't really help in

00:02:27,780 --> 00:02:31,440
giving us a fact this worldview if you

00:02:29,550 --> 00:02:33,090
want that don't look at the media don't

00:02:31,440 --> 00:02:36,090
watch the news if you want to know how

00:02:33,090 --> 00:02:38,430
the world really looks so what is then

00:02:36,090 --> 00:02:39,680
the solution to all this we say

00:02:38,430 --> 00:02:42,599
tactfulness

00:02:39,680 --> 00:02:44,910
so that's that lovely calm mental state

00:02:42,599 --> 00:02:48,090
that you reach when you know your

00:02:44,910 --> 00:02:49,799
opinions are based on facts so how do

00:02:48,090 --> 00:02:51,510
you reach that mental stage well like we

00:02:49,799 --> 00:02:53,640
said don't watch the media we don't

00:02:51,510 --> 00:02:54,959
really believe that it's nice of course

00:02:53,640 --> 00:02:57,090
you can you can learn things from the

00:02:54,959 --> 00:02:59,819
media but we believe in education so

00:02:57,090 --> 00:03:03,390
that's why we make educational material

00:02:59,819 --> 00:03:05,790
and what does educational material don't

00:03:03,390 --> 00:03:07,260
have first of all of course sex that's

00:03:05,790 --> 00:03:10,019
that's important this is kind of our

00:03:07,260 --> 00:03:12,060
basic fact framework so we show where

00:03:10,019 --> 00:03:14,459
people live in the world we show like

00:03:12,060 --> 00:03:16,260
the biggest change in the course of the

00:03:14,459 --> 00:03:17,239
last century the number of babies that

00:03:16,260 --> 00:03:19,410
were born per woman

00:03:17,239 --> 00:03:21,060
so here the colors are the different

00:03:19,410 --> 00:03:23,130
world regions like you see them there

00:03:21,060 --> 00:03:25,049
and where people live on income levels

00:03:23,130 --> 00:03:26,819
so the world isn't divided in the poor

00:03:25,049 --> 00:03:29,069
and the rich but most of the people live

00:03:26,819 --> 00:03:32,130
in the middle these kind of facts we

00:03:29,069 --> 00:03:33,690
teach people but on top of that you can

00:03:32,130 --> 00:03:35,880
still have correct sets and misleading

00:03:33,690 --> 00:03:38,970
worldviews look at that map of Australia

00:03:35,880 --> 00:03:41,639
except it's not Australia they were all

00:03:38,970 --> 00:03:43,709
beautiful maps that are correct but they

00:03:41,639 --> 00:03:46,650
give you a worldview that is misleading

00:03:43,709 --> 00:03:49,470
so what you also need to do is to know

00:03:46,650 --> 00:03:50,910
your biases and the biases in the media

00:03:49,470 --> 00:03:52,470
both in your brain in the media and try

00:03:50,910 --> 00:03:54,569
to fight them so we try to teach people

00:03:52,470 --> 00:03:56,489
with this framework what are the

00:03:54,569 --> 00:03:58,200
instincts that you have like fear and

00:03:56,489 --> 00:04:00,329
you exaggerate things and you see gaps

00:03:58,200 --> 00:04:02,849
see or you see patterns that are not

00:04:00,329 --> 00:04:04,650
there and how you can fight them but

00:04:02,849 --> 00:04:06,389
enough of that we go back to facts

00:04:04,650 --> 00:04:10,139
because that work what we're we're we're

00:04:06,389 --> 00:04:12,870
here for data and we think statistics

00:04:10,139 --> 00:04:14,910
are great facts because they're there by

00:04:12,870 --> 00:04:17,880
definition representative of the people

00:04:14,910 --> 00:04:20,039
it's not just it's not just

00:04:17,880 --> 00:04:20,639
exaggerations or the outliers the weird

00:04:20,039 --> 00:04:23,190
people

00:04:20,639 --> 00:04:25,469
it's everyone that's what statistics are

00:04:23,190 --> 00:04:29,249
about so that's already a big bias that

00:04:25,469 --> 00:04:31,649
is gone because of that now we come

00:04:29,249 --> 00:04:32,429
to the actual part of the talk where you

00:04:31,649 --> 00:04:36,809
all came for

00:04:32,429 --> 00:04:39,059
hopefully it's our how we store all

00:04:36,809 --> 00:04:41,579
these facts so we store it in something

00:04:39,059 --> 00:04:43,319
that we called EDF which is a

00:04:41,579 --> 00:04:47,579
multi-dimensional collaborative

00:04:43,319 --> 00:04:49,679
statistics model so basically it's just

00:04:47,579 --> 00:04:52,679
a how we normally store it is a bunch of

00:04:49,679 --> 00:04:55,499
CSV files a data set consisting of a lot

00:04:52,679 --> 00:04:57,239
of CSV files a lot of tables so what

00:04:55,499 --> 00:05:00,299
does that look like well let's start

00:04:57,239 --> 00:05:02,879
with simple table where we have a

00:05:00,299 --> 00:05:06,719
population life expectancy and GDP per

00:05:02,879 --> 00:05:08,819
capita for a country over years and what

00:05:06,719 --> 00:05:10,739
is important here is that we define what

00:05:08,819 --> 00:05:11,999
the primary key of the table is because

00:05:10,739 --> 00:05:14,719
everyone knows where the primary key

00:05:11,999 --> 00:05:17,849
means someone doesn't okay good so

00:05:14,719 --> 00:05:19,499
because that kind of describes what what

00:05:17,849 --> 00:05:21,449
the object is that we're describing so

00:05:19,499 --> 00:05:24,779
here we say something about Sweden in

00:05:21,449 --> 00:05:27,779
2015 and what we can do with that then

00:05:24,779 --> 00:05:30,929
is to play that over time and you can

00:05:27,779 --> 00:05:32,429
see the bubbles move so yeah these

00:05:30,929 --> 00:05:34,139
bubbles I will do that throughout the

00:05:32,429 --> 00:05:37,709
talk show a little bit what kind of

00:05:34,139 --> 00:05:39,809
visualizations our data format allows

00:05:37,709 --> 00:05:41,399
for so we build on we add on extra

00:05:39,809 --> 00:05:43,529
features and we see that we can do more

00:05:41,399 --> 00:05:46,439
things with them so here every bubble is

00:05:43,529 --> 00:05:49,619
a country the size of the bubble is the

00:05:46,439 --> 00:05:51,659
population size the color is just one

00:05:49,619 --> 00:05:54,689
color for now and here we have the

00:05:51,659 --> 00:05:57,239
income per person and life expectancy on

00:05:54,689 --> 00:06:00,449
the under y-axis so here you should have

00:05:57,239 --> 00:06:03,419
like the poor and unhealthy people and

00:06:00,449 --> 00:06:06,299
up there somewhere the rich and healthy

00:06:03,419 --> 00:06:07,919
people but you can see for example

00:06:06,299 --> 00:06:08,459
already that everything's a little bit

00:06:07,919 --> 00:06:11,369
to the left

00:06:08,459 --> 00:06:13,919
that's because GDP per capita or income

00:06:11,369 --> 00:06:16,110
it's a moral logarithmic kind of idea

00:06:13,919 --> 00:06:17,519
like if you have one dollar one more

00:06:16,110 --> 00:06:18,929
dollar is a lot if you're a thousand

00:06:17,519 --> 00:06:20,399
dollars one more dollar is nothing so

00:06:18,929 --> 00:06:23,129
you should have it on a logarithmic

00:06:20,399 --> 00:06:28,349
scale but we can see later how we can do

00:06:23,129 --> 00:06:30,269
these kind of things now what we also do

00:06:28,349 --> 00:06:32,939
so this is one table what we like to do

00:06:30,269 --> 00:06:34,409
is to put every single indicator

00:06:32,939 --> 00:06:36,389
actually in a separate table so you're

00:06:34,409 --> 00:06:39,569
at there we had three indicators in one

00:06:36,389 --> 00:06:41,189
table normally we put it in one CSV for

00:06:39,569 --> 00:06:42,540
per indicator because that way if we

00:06:41,189 --> 00:06:44,940
want to switch

00:06:42,540 --> 00:06:47,880
indicator - for example show co2 per

00:06:44,940 --> 00:06:50,660
capita on the y-axis then it only has to

00:06:47,880 --> 00:06:53,280
load one CSV file instead of all of them

00:06:50,660 --> 00:06:57,480
to just show one indicator that'd be a

00:06:53,280 --> 00:06:59,250
bit inefficient so yeah this is this is

00:06:57,480 --> 00:07:01,260
the basic statistics but maybe we want

00:06:59,250 --> 00:07:02,760
to say something about the countries we

00:07:01,260 --> 00:07:04,020
want to say what it's what the name of

00:07:02,760 --> 00:07:06,390
the country is instead of just an

00:07:04,020 --> 00:07:09,000
identifier or which world region they

00:07:06,390 --> 00:07:10,470
lie so for that we have another table we

00:07:09,000 --> 00:07:13,320
could we could of course add that here

00:07:10,470 --> 00:07:15,990
just out of a column name and you could

00:07:13,320 --> 00:07:18,480
say Sweden in at a color column world

00:07:15,990 --> 00:07:21,570
region but that would be not normalized

00:07:18,480 --> 00:07:23,160
data and it would be a lot of redundant

00:07:21,570 --> 00:07:25,500
there especially if you start adding a

00:07:23,160 --> 00:07:27,090
lot of things a lot of redundant data

00:07:25,500 --> 00:07:30,840
you don't want that in your data set so

00:07:27,090 --> 00:07:32,250
we create another CC file in which we

00:07:30,840 --> 00:07:35,460
enumerate all the different countries

00:07:32,250 --> 00:07:38,820
and properties about them so that allows

00:07:35,460 --> 00:07:41,580
us for example to color the bubbles by

00:07:38,820 --> 00:07:44,190
the world region therein so Sweden is in

00:07:41,580 --> 00:07:45,840
Europe use days in Americas and now

00:07:44,190 --> 00:07:49,260
they're colored by that so Americas are

00:07:45,840 --> 00:07:53,040
all green Africa is blue Asia is red and

00:07:49,260 --> 00:07:55,590
Europe is yellow that's nice indeed and

00:07:53,040 --> 00:07:57,210
you can see if you hover them they now

00:07:55,590 --> 00:08:00,210
have their actual names instead of just

00:07:57,210 --> 00:08:02,040
identifiers but maybe we also want to

00:08:00,210 --> 00:08:04,470
say something about the world regions we

00:08:02,040 --> 00:08:06,720
take that variable and we enumerate does

00:08:04,470 --> 00:08:09,180
so we give names through the world

00:08:06,720 --> 00:08:11,760
regions and we can add a topo JSON file

00:08:09,180 --> 00:08:13,950
that describes what they actually look

00:08:11,760 --> 00:08:20,070
like on a map and with that we can draw

00:08:13,950 --> 00:08:21,930
a color legend in a map so we already

00:08:20,070 --> 00:08:24,000
did a little bit of a visualization is

00:08:21,930 --> 00:08:25,320
getting nicer now we might want to say

00:08:24,000 --> 00:08:27,060
something more about the actual

00:08:25,320 --> 00:08:31,560
variables in our data set have some

00:08:27,060 --> 00:08:33,720
metadata and then oh wait yes no I'm

00:08:31,560 --> 00:08:36,210
just going to skip that so we want to

00:08:33,720 --> 00:08:38,099
say something about the variables we

00:08:36,210 --> 00:08:40,080
call them concepts so every single

00:08:38,099 --> 00:08:42,300
variable every single header basically

00:08:40,080 --> 00:08:44,370
in your CSV file that is in your data

00:08:42,300 --> 00:08:46,050
set you enumerate it you can say things

00:08:44,370 --> 00:08:48,540
about them for example what the name is

00:08:46,050 --> 00:08:51,240
or a description of it or methodology

00:08:48,540 --> 00:08:53,610
how it was gathered or what skills are

00:08:51,240 --> 00:08:56,130
allowed for it so what you see now is

00:08:53,610 --> 00:08:58,710
that we have a logarithmic scale for

00:08:56,130 --> 00:09:03,180
a person that's because we defined that

00:08:58,710 --> 00:09:05,040
GDP per capita is shown preferably on a

00:09:03,180 --> 00:09:06,950
logarithmic scale but can also be shown

00:09:05,040 --> 00:09:09,720
on a linear scale so we can click it and

00:09:06,950 --> 00:09:11,820
change the skill to linear and then the

00:09:09,720 --> 00:09:14,490
scale isn't linear but for a life

00:09:11,820 --> 00:09:17,730
expectancy we can't do that because only

00:09:14,490 --> 00:09:19,500
a linear scale is allowed so we can as a

00:09:17,730 --> 00:09:21,270
data set constructor we can say things

00:09:19,500 --> 00:09:23,250
about the variables and that influences

00:09:21,270 --> 00:09:25,070
right away the visualization because you

00:09:23,250 --> 00:09:29,970
know how something should be visualized

00:09:25,070 --> 00:09:33,750
most likely so that's kind of the basics

00:09:29,970 --> 00:09:36,150
of the IDF we have statistics data

00:09:33,750 --> 00:09:38,490
points we say something about the

00:09:36,150 --> 00:09:39,960
entities in our data sets or search

00:09:38,490 --> 00:09:41,850
countries or world regions but it can

00:09:39,960 --> 00:09:44,930
also be genders or age groups or income

00:09:41,850 --> 00:09:49,080
groups any of those and we describe the

00:09:44,930 --> 00:09:51,240
variables in our data set nice but now

00:09:49,080 --> 00:09:56,130
comes the juicy part this is not

00:09:51,240 --> 00:10:00,270
everything there is more so I introduced

00:09:56,130 --> 00:10:02,100
entity sets before we had enumeration of

00:10:00,270 --> 00:10:03,870
all the countries and say something

00:10:02,100 --> 00:10:06,000
about them but maybe we want to say

00:10:03,870 --> 00:10:08,700
something by all the geographic places

00:10:06,000 --> 00:10:10,860
in the world so not just countries but

00:10:08,700 --> 00:10:14,520
also cities like Singapore and Stockholm

00:10:10,860 --> 00:10:16,020
or oceans or other places but we want to

00:10:14,520 --> 00:10:18,330
group them in a certain way so they're

00:10:16,020 --> 00:10:21,750
all Geographic places they all belong to

00:10:18,330 --> 00:10:24,150
the same domain so you say for the

00:10:21,750 --> 00:10:25,950
variable geo so we have it there that's

00:10:24,150 --> 00:10:28,580
an entity domain a domain of entities

00:10:25,950 --> 00:10:32,160
and within that you can have sets of

00:10:28,580 --> 00:10:34,080
entities that belong to that domain this

00:10:32,160 --> 00:10:35,990
might be a bit abstract but maybe your

00:10:34,080 --> 00:10:38,880
Venn diagram helps in explaining it

00:10:35,990 --> 00:10:41,160
where you have that big square it's the

00:10:38,880 --> 00:10:43,500
domain or the universe where in which

00:10:41,160 --> 00:10:46,320
all the different Geographic places live

00:10:43,500 --> 00:10:48,660
and then you can draw circles around

00:10:46,320 --> 00:10:51,720
them to show which all belong to a

00:10:48,660 --> 00:10:53,640
certain set now why would you want to do

00:10:51,720 --> 00:10:56,910
this why is it or is this nice to do

00:10:53,640 --> 00:10:59,700
well if you start defining things for

00:10:56,910 --> 00:11:02,130
these entities for example what its name

00:10:59,700 --> 00:11:06,330
is or what the world region or what the

00:11:02,130 --> 00:11:08,850
population was in a certain year you

00:11:06,330 --> 00:11:09,840
want to when you do that once for one

00:11:08,850 --> 00:11:12,300
entity

00:11:09,840 --> 00:11:14,700
it's done for all the types that that

00:11:12,300 --> 00:11:17,490
entity has so when I say the name of

00:11:14,700 --> 00:11:19,680
Singapore the name of sgp is Singapore

00:11:17,490 --> 00:11:21,810
just count for the country it's it's

00:11:19,680 --> 00:11:23,390
both for the city Singapore air for the

00:11:21,810 --> 00:11:29,190
country Singapore effort downstate

00:11:23,390 --> 00:11:32,760
Singapore so when I when I want to show

00:11:29,190 --> 00:11:35,700
in my my visualization all the cities

00:11:32,760 --> 00:11:38,820
and their populations or all the

00:11:35,700 --> 00:11:40,290
countries and their populations the data

00:11:38,820 --> 00:11:42,750
for Singapore will come from the same

00:11:40,290 --> 00:11:45,060
data point same if I want to show all

00:11:42,750 --> 00:11:50,250
the countries for example like I have

00:11:45,060 --> 00:11:53,100
here but now I want to show UN states so

00:11:50,250 --> 00:11:54,930
for example we now have countries and I

00:11:53,100 --> 00:11:57,720
can show that Taiwan is right there

00:11:54,930 --> 00:12:00,300
Taiwan is a country but as we can see

00:11:57,720 --> 00:12:06,840
here Taiwan is out of the UN state set

00:12:00,300 --> 00:12:10,320
so if I switch to UM States now then

00:12:06,840 --> 00:12:14,070
Taiwan is gone but the nice thing is

00:12:10,320 --> 00:12:15,960
that all the other all the other data

00:12:14,070 --> 00:12:17,670
points that are in this day in the data

00:12:15,960 --> 00:12:20,490
set they're still exactly the same we

00:12:17,670 --> 00:12:22,800
don't have any redundancy in describing

00:12:20,490 --> 00:12:24,180
the population of the country China and

00:12:22,800 --> 00:12:25,950
the UN state China or the country

00:12:24,180 --> 00:12:28,380
Singapore in the city Singapore they're

00:12:25,950 --> 00:12:30,090
all the same same for the labels and all

00:12:28,380 --> 00:12:31,680
these things and it's a better way

00:12:30,090 --> 00:12:34,920
really to describe the real world

00:12:31,680 --> 00:12:37,860
because like I'm a person but I'm also a

00:12:34,920 --> 00:12:41,070
son and I'm also a tennis player and I'm

00:12:37,860 --> 00:12:42,750
also an employee and I'm more multiple

00:12:41,070 --> 00:12:46,110
things at once and you want to describe

00:12:42,750 --> 00:12:50,060
that in your data set so those are

00:12:46,110 --> 00:12:55,290
entity sets next juicy bit

00:12:50,060 --> 00:12:57,900
multidimensionality so we saw population

00:12:55,290 --> 00:13:00,780
per country per year we've seen that

00:12:57,900 --> 00:13:02,820
before in the talk but maybe you want to

00:13:00,780 --> 00:13:03,930
say so you want to split that up because

00:13:02,820 --> 00:13:06,510
you want to say something about

00:13:03,930 --> 00:13:08,670
populations per age group per country

00:13:06,510 --> 00:13:10,770
per year or maybe per age group for

00:13:08,670 --> 00:13:14,600
gender per per country per year or you

00:13:10,770 --> 00:13:17,310
can make it as crazy as you want really

00:13:14,600 --> 00:13:19,030
for example you would want the second

00:13:17,310 --> 00:13:23,380
one to show

00:13:19,030 --> 00:13:29,800
just a little bit too much but let's

00:13:23,380 --> 00:13:32,470
start off with a H pyramid actually it

00:13:29,800 --> 00:13:41,170
should be what can I change that here

00:13:32,470 --> 00:13:44,560
probably yeah color so I show this is

00:13:41,170 --> 00:13:45,880
this is grabbing data from this one here

00:13:44,560 --> 00:13:50,440
the country is actually the whole world

00:13:45,880 --> 00:13:52,870
and the year is 2015 and we have one bar

00:13:50,440 --> 00:13:55,870
for each age group and this is the

00:13:52,870 --> 00:13:58,800
population how long the bar is so we can

00:13:55,870 --> 00:14:01,540
show this but now for example we want to

00:13:58,800 --> 00:14:04,000
run we want to see genders on the site

00:14:01,540 --> 00:14:07,440
of the age pyramid so all we have to do

00:14:04,000 --> 00:14:10,030
is change the gender and because of

00:14:07,440 --> 00:14:12,690
because of the data format it rightaway

00:14:10,030 --> 00:14:15,970
knows how to grab data for that table

00:14:12,690 --> 00:14:17,800
BAM there you have it and you don't have

00:14:15,970 --> 00:14:19,210
to say anything about you get it from

00:14:17,800 --> 00:14:21,610
that table or something no I just want

00:14:19,210 --> 00:14:23,920
to see a pro gender so we add gender to

00:14:21,610 --> 00:14:26,140
the primary key of the table and voila

00:14:23,920 --> 00:14:28,150
you can see it and right now we we are

00:14:26,140 --> 00:14:32,680
showing data for the world but we can

00:14:28,150 --> 00:14:34,390
for example also instead showing gender

00:14:32,680 --> 00:14:36,850
on the side show world regions on the

00:14:34,390 --> 00:14:40,690
side and the different sides and then

00:14:36,850 --> 00:14:42,670
this country or actually this here

00:14:40,690 --> 00:14:44,380
country is replaced by world region so

00:14:42,670 --> 00:14:52,630
it grabs it from a different table again

00:14:44,380 --> 00:14:54,400
and if the data load so this is

00:14:52,630 --> 00:15:00,310
connecting to our servers in Sweden I

00:14:54,400 --> 00:15:07,630
know it's a little far away like demos

00:15:00,310 --> 00:15:09,970
yeah so another example what you can do

00:15:07,630 --> 00:15:14,770
with it this is migration patterns in

00:15:09,970 --> 00:15:16,900
South Africa so you can see where people

00:15:14,770 --> 00:15:20,380
move for example here the capital area a

00:15:16,900 --> 00:15:22,450
lot of people move into that but it's

00:15:20,380 --> 00:15:24,490
interesting once you start like taking

00:15:22,450 --> 00:15:26,320
these things apart looking in different

00:15:24,490 --> 00:15:28,450
age groups for example if you look at

00:15:26,320 --> 00:15:31,240
the black African population they're in

00:15:28,450 --> 00:15:32,990
South Africa you can see that youth

00:15:31,240 --> 00:15:36,290
still is all

00:15:32,990 --> 00:15:39,529
moving into the urban capital province

00:15:36,290 --> 00:15:40,630
but elderly there right moving the other

00:15:39,529 --> 00:15:43,700
way around

00:15:40,630 --> 00:15:45,290
because they go there to to live to live

00:15:43,700 --> 00:15:47,959
their old lives back in the places where

00:15:45,290 --> 00:15:50,660
they came from so pulling out the data

00:15:47,959 --> 00:15:52,100
just taking it apart and showing these

00:15:50,660 --> 00:15:53,810
aggregations of data can be very

00:15:52,100 --> 00:15:56,240
interesting and that's native to our

00:15:53,810 --> 00:15:58,820
data model so it allows us to do these

00:15:56,240 --> 00:16:03,260
things very easily next thing's

00:15:58,820 --> 00:16:05,390
translation it's another juicy bit so we

00:16:03,260 --> 00:16:07,370
saw basically every string that you have

00:16:05,390 --> 00:16:09,709
in your data set you can translate that

00:16:07,370 --> 00:16:12,560
so we have here for example this this

00:16:09,709 --> 00:16:15,620
file the concepts of the of the data set

00:16:12,560 --> 00:16:17,420
or the geographic they're the geographic

00:16:15,620 --> 00:16:20,930
places entities and they have like a

00:16:17,420 --> 00:16:23,209
name or the long name and then we can

00:16:20,930 --> 00:16:25,670
start translating them to for example

00:16:23,209 --> 00:16:27,110
erratic and we just do that by copying

00:16:25,670 --> 00:16:29,420
the file and putting it in a special

00:16:27,110 --> 00:16:31,610
folder Lang and then the language of the

00:16:29,420 --> 00:16:33,380
fire you can leave out columns like the

00:16:31,610 --> 00:16:36,050
skills column we're not interested in or

00:16:33,380 --> 00:16:38,360
leave leave some translations blank and

00:16:36,050 --> 00:16:41,029
we'll just go back and take the English

00:16:38,360 --> 00:16:42,920
version but what it allows us to do is

00:16:41,029 --> 00:16:45,640
to have a completely English data set

00:16:42,920 --> 00:16:49,640
like you see here everything's English

00:16:45,640 --> 00:16:52,310
the descriptions and whatnot and we can

00:16:49,640 --> 00:16:55,910
then with a push of the button it

00:16:52,310 --> 00:16:57,380
changed it to Arabic and our whole

00:16:55,910 --> 00:17:00,230
visual things are able to do that

00:16:57,380 --> 00:17:02,510
right-to-left formatting as well and

00:17:00,230 --> 00:17:05,179
there you have it the whole data set is

00:17:02,510 --> 00:17:07,400
in Arabic including all descriptions all

00:17:05,179 --> 00:17:11,600
strings basically that you have are in

00:17:07,400 --> 00:17:14,569
Arabic so those are translations those

00:17:11,600 --> 00:17:16,370
were kind of all the juicy features that

00:17:14,569 --> 00:17:18,829
we have I want to compare a little bit

00:17:16,370 --> 00:17:22,040
to other data formats because we we try

00:17:18,829 --> 00:17:24,380
to combine things like graph formats

00:17:22,040 --> 00:17:26,689
like RDF or freebase if you know them

00:17:24,380 --> 00:17:28,730
they allow this multi typing you know

00:17:26,689 --> 00:17:32,150
one entity one node in a graph can have

00:17:28,730 --> 00:17:34,460
multiple types but those formats are

00:17:32,150 --> 00:17:36,200
often very hard to understand RDF is

00:17:34,460 --> 00:17:37,250
kind of generic hell you can do a lot

00:17:36,200 --> 00:17:39,380
with it but you really have to

00:17:37,250 --> 00:17:42,400
understand it and it is very hard to

00:17:39,380 --> 00:17:45,919
start with that so that's why we use

00:17:42,400 --> 00:17:46,360
nice CSV files that everyone can can

00:17:45,919 --> 00:17:50,010
either

00:17:46,360 --> 00:17:53,559
start with you have another sdmx maybe

00:17:50,010 --> 00:17:56,409
some of you know that that's a former

00:17:53,559 --> 00:17:58,659
that UN uses to interchange statistical

00:17:56,409 --> 00:18:01,600
data but also that is very very

00:17:58,659 --> 00:18:04,320
difficult very strict standard to use so

00:18:01,600 --> 00:18:09,070
we created this to have the

00:18:04,320 --> 00:18:11,590
accessibility kind of easy CSV files but

00:18:09,070 --> 00:18:13,260
still be able to build on top of that

00:18:11,590 --> 00:18:17,590
like you saw we can start with a simple

00:18:13,260 --> 00:18:22,720
statistics table but but expand it with

00:18:17,590 --> 00:18:24,610
a lot of functionalities so PDF doesn't

00:18:22,720 --> 00:18:30,279
isn't a thing on its own we we actually

00:18:24,610 --> 00:18:33,130
use it in our data pipeline to go from

00:18:30,279 --> 00:18:34,720
from data sources that live there all

00:18:33,130 --> 00:18:38,169
over the world like the UN like the

00:18:34,720 --> 00:18:39,909
World Bank like I actually to transform

00:18:38,169 --> 00:18:42,610
the data in our data kitchen harmonized

00:18:39,909 --> 00:18:45,309
it and we hosted on github in the open

00:18:42,610 --> 00:18:47,970
numbers organization we have a validator

00:18:45,309 --> 00:18:53,350
that validates this is really formative

00:18:47,970 --> 00:18:55,690
DDF we have our own MongoDB server that

00:18:53,350 --> 00:18:57,130
can host these data sets and then the

00:18:55,690 --> 00:18:57,519
visualization framework that you saw

00:18:57,130 --> 00:19:00,130
before

00:18:57,519 --> 00:19:01,779
by the way that framework can also read

00:19:00,130 --> 00:19:04,269
any data form and you just have to write

00:19:01,779 --> 00:19:06,460
a reader for it and all the

00:19:04,269 --> 00:19:08,440
visualizations are still there or just a

00:19:06,460 --> 00:19:09,880
CSV file as well if you want to test

00:19:08,440 --> 00:19:13,059
that come to us and we can show you how

00:19:09,880 --> 00:19:14,919
to do that and we use it you can use it

00:19:13,059 --> 00:19:17,380
on your own website decisions it's an

00:19:14,919 --> 00:19:18,519
open source library basically so I want

00:19:17,380 --> 00:19:20,110
to show a little bit more about this

00:19:18,519 --> 00:19:23,039
data kitchen because that's where some

00:19:20,110 --> 00:19:23,039
interesting things happen

00:19:23,950 --> 00:19:30,070
so we have for example here I'll show

00:19:26,889 --> 00:19:34,000
how we make our co2 emission data set so

00:19:30,070 --> 00:19:35,799
we have data from the CCD ACK it's a us

00:19:34,000 --> 00:19:38,080
organization here that gathers

00:19:35,799 --> 00:19:40,870
information from all the countries in

00:19:38,080 --> 00:19:43,720
the world but it has some things it

00:19:40,870 --> 00:19:45,970
doesn't go back to the 1800s with with

00:19:43,720 --> 00:19:52,059
its co2 per capita and we'd like to have

00:19:45,970 --> 00:19:53,740
long time series so what we do is we

00:19:52,059 --> 00:19:56,860
create our own data set way in which we

00:19:53,740 --> 00:19:59,550
do these things and we want to harmonize

00:19:56,860 --> 00:20:02,850
all the data because see diac uses

00:19:59,550 --> 00:20:05,040
own identifies four countries UN the UN

00:20:02,850 --> 00:20:09,290
uses its own identifiers will bank uses

00:20:05,040 --> 00:20:12,180
its own identifiers so this is not very

00:20:09,290 --> 00:20:15,060
nice to be able to we want to show all

00:20:12,180 --> 00:20:17,910
these indicators combined compare them

00:20:15,060 --> 00:20:20,520
with each other see correlations so what

00:20:17,910 --> 00:20:23,220
we do is we have first we write a Python

00:20:20,520 --> 00:20:25,890
script that seemed tactically harmonizes

00:20:23,220 --> 00:20:28,560
the data which is just means it puts it

00:20:25,890 --> 00:20:32,700
all into DBF so that all is the same

00:20:28,560 --> 00:20:34,890
format and then we have another Python

00:20:32,700 --> 00:20:38,940
script which you call the chef which

00:20:34,890 --> 00:20:41,100
takes a recipe which recipe is a JSON or

00:20:38,940 --> 00:20:42,930
a general file which says like what take

00:20:41,100 --> 00:20:44,460
these datasets and then cut them up in

00:20:42,930 --> 00:20:48,680
this way paste them together in another

00:20:44,460 --> 00:20:51,240
way and out comes another PDF data set

00:20:48,680 --> 00:20:54,860
so that's what I'm going to show you now

00:20:51,240 --> 00:20:58,230
so what we have here is that we first

00:20:54,860 --> 00:21:00,900
transform all of these to all this data

00:20:58,230 --> 00:21:04,350
from different data providers to BDS

00:21:00,900 --> 00:21:07,230
format then what we do here is we make

00:21:04,350 --> 00:21:11,070
our own population data set in which we

00:21:07,230 --> 00:21:13,500
take our own geo entity domains or our

00:21:11,070 --> 00:21:16,860
own identifiers for countries and we

00:21:13,500 --> 00:21:18,660
translate the identifier of the UM to

00:21:16,860 --> 00:21:21,000
our own identifiers and we have our own

00:21:18,660 --> 00:21:23,340
historical time series for population

00:21:21,000 --> 00:21:24,780
that we researched based on all kinds of

00:21:23,340 --> 00:21:28,620
different sources so that we can have

00:21:24,780 --> 00:21:32,520
data back to 1800 and we have our own

00:21:28,620 --> 00:21:34,560
population data set now then we do the

00:21:32,520 --> 00:21:38,940
same again with the CD ack information

00:21:34,560 --> 00:21:42,330
we we translate the identifiers so CD

00:21:38,940 --> 00:21:44,540
ack to our own identifier and we add our

00:21:42,330 --> 00:21:48,840
own population data set so we can have a

00:21:44,540 --> 00:21:51,390
co2 emissions per capita so what does

00:21:48,840 --> 00:21:53,250
such a recipe look like then a little

00:21:51,390 --> 00:21:57,510
bit of an idea maybe it's a bit small

00:21:53,250 --> 00:22:01,370
but you define ingredients so you say

00:21:57,510 --> 00:22:05,670
well from the CD ACK PDF data set take

00:22:01,370 --> 00:22:07,260
take all the data points oh it take take

00:22:05,670 --> 00:22:09,840
all the the entities of all the nations

00:22:07,260 --> 00:22:11,370
or countries with they're called nations

00:22:09,840 --> 00:22:14,940
in celiac

00:22:11,370 --> 00:22:16,910
and from our own data set take all the

00:22:14,940 --> 00:22:19,530
countries and then you start translating

00:22:16,910 --> 00:22:23,340
you so you start cooking with these

00:22:19,530 --> 00:22:28,140
ingredients so we start translating the

00:22:23,340 --> 00:22:31,320
column which column see a little bit of

00:22:28,140 --> 00:22:36,330
it Lots myself now but we take there we

00:22:31,320 --> 00:22:38,550
take the CD AK entities and well

00:22:36,330 --> 00:22:40,740
basically we trance we translate sing a

00:22:38,550 --> 00:22:43,770
dictionary that we define from our own

00:22:40,740 --> 00:22:47,190
Gapminder entity so we have here's all

00:22:43,770 --> 00:22:49,320
these different columns in our Gapminder

00:22:47,190 --> 00:22:52,140
entity that consists contain all kinds

00:22:49,320 --> 00:22:53,940
of different synonyms that can be used

00:22:52,140 --> 00:22:57,210
so also sentiments that are used there

00:22:53,940 --> 00:23:01,170
and basically it translates using that

00:22:57,210 --> 00:23:05,430
synonym dictionary to our own GUI

00:23:01,170 --> 00:23:11,990
identifiers you could take that recipe

00:23:05,430 --> 00:23:15,780
and make it into a graph so the

00:23:11,990 --> 00:23:17,640
procedure that you just looked at is

00:23:15,780 --> 00:23:19,500
this preceded procedure here at the

00:23:17,640 --> 00:23:21,660
translate column but we do some other

00:23:19,500 --> 00:23:24,390
things in the recipe for example we

00:23:21,660 --> 00:23:27,930
merge entities like West and East

00:23:24,390 --> 00:23:29,460
Germany we merge together to Germany we

00:23:27,930 --> 00:23:32,850
split some entities like for example

00:23:29,460 --> 00:23:35,280
Russia only has data starting 1990

00:23:32,850 --> 00:23:39,230
because before it didn't exist but we

00:23:35,280 --> 00:23:43,260
split them up we split the data of the

00:23:39,230 --> 00:23:45,990
SSR you the Soviet republic up in

00:23:43,260 --> 00:23:48,120
Ukraine and Russia and another as are

00:23:45,990 --> 00:23:52,200
you states to be able to have data for

00:23:48,120 --> 00:23:54,600
just Russia also before 1990 here we do

00:23:52,200 --> 00:23:57,240
some some more things like rolling some

00:23:54,600 --> 00:24:00,480
to get a total emissions accumulated sum

00:23:57,240 --> 00:24:03,720
of emissions over all of the years this

00:24:00,480 --> 00:24:06,500
is where we draw in data points from our

00:24:03,720 --> 00:24:10,140
popular from a population data set and

00:24:06,500 --> 00:24:17,880
we calculate co2 per capita is the co2

00:24:10,140 --> 00:24:20,190
that comes from some of that so we take

00:24:17,880 --> 00:24:21,360
the co2 from the Syriac data set and

00:24:20,190 --> 00:24:24,250
population for hours and then we

00:24:21,360 --> 00:24:26,200
calculate co2 per capita

00:24:24,250 --> 00:24:30,850
I mean yet we merge it all to one nice

00:24:26,200 --> 00:24:33,010
data set so yeah that way we build a lot

00:24:30,850 --> 00:24:35,289
of data sets and harmonize them and we

00:24:33,010 --> 00:24:37,900
all host them like I set on open numbers

00:24:35,289 --> 00:24:41,049
which is a github repo or get up

00:24:37,900 --> 00:24:43,990
organization that we run and we really

00:24:41,049 --> 00:24:45,250
want everyone to come in and use diff as

00:24:43,990 --> 00:24:47,500
well because we want to crowdsource

00:24:45,250 --> 00:24:48,820
all these statistics where we can't do

00:24:47,500 --> 00:24:51,220
everything ourselves we have we have

00:24:48,820 --> 00:24:54,669
seven people working for us but we need

00:24:51,220 --> 00:24:57,250
the world to to to help us item build

00:24:54,669 --> 00:24:58,750
this big data set of course like

00:24:57,250 --> 00:25:01,510
everyone wants but this is our

00:24:58,750 --> 00:25:04,360
initiative of doing that so I want to

00:25:01,510 --> 00:25:06,190
invite you all to build that fact base

00:25:04,360 --> 00:25:09,250
for the fact-based worldview together

00:25:06,190 --> 00:25:12,130
you can look on Gapminder org slash

00:25:09,250 --> 00:25:16,030
tools possibly to see our big data set

00:25:12,130 --> 00:25:18,010
you can look up here DDS documentation

00:25:16,030 --> 00:25:20,340
and and all the data sets that we have

00:25:18,010 --> 00:25:23,590
this is a visualization framework and

00:25:20,340 --> 00:25:27,210
here you can get in touch with me thank

00:25:23,590 --> 00:25:27,210
you oh yes

00:25:30,560 --> 00:25:36,450
by the way this is a little bit of a

00:25:33,570 --> 00:25:38,640
commemoration of Hans Rosling you might

00:25:36,450 --> 00:25:41,030
know him he was our boss but he just

00:25:38,640 --> 00:25:45,360
passed away a couple of months ago but

00:25:41,030 --> 00:25:47,850
he always used a huge pointer so a

00:25:45,360 --> 00:25:49,350
little bit as a remembrance to him so if

00:25:47,850 --> 00:25:49,770
there's any questions if there's still

00:25:49,350 --> 00:25:54,810
time

00:25:49,770 --> 00:25:57,480
yeah sure so how you handle resolving

00:25:54,810 --> 00:25:59,460
and keep it separate IDs or camera keys

00:25:57,480 --> 00:26:02,520
and a bunch of different tables like if

00:25:59,460 --> 00:26:08,490
you have germany i sell in a different

00:26:02,520 --> 00:26:10,230
way the streamlined way you do that well

00:26:08,490 --> 00:26:13,020
basically you have to have somewhere

00:26:10,230 --> 00:26:16,020
like define like an ontology of synonyms

00:26:13,020 --> 00:26:19,710
for for germany right so we we know that

00:26:16,020 --> 00:26:23,190
we call Jeremy ger and then we have like

00:26:19,710 --> 00:26:26,160
I said in we have a table basically

00:26:23,190 --> 00:26:28,230
where we have all these yeah it's like a

00:26:26,160 --> 00:26:31,320
dictionary that we build in a in a CSV

00:26:28,230 --> 00:26:33,870
file yeah that's how we use it and if we

00:26:31,320 --> 00:26:37,620
find find new ones then we add them to

00:26:33,870 --> 00:26:40,160
the dictionary yeah yeah we stop okay

00:26:37,620 --> 00:26:40,160
thank you

00:26:42,140 --> 00:26:46,339

YouTube URL: https://www.youtube.com/watch?v=i5FmqreQ6zk


