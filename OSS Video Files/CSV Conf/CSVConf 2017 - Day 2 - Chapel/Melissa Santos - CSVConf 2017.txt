Title: Melissa Santos - CSVConf 2017
Publication date: 2017-05-27
Playlist: CSVConf 2017 - Day 2 - Chapel
Description: 
	
Captions: 
	00:00:00,190 --> 00:00:09,360
[Music]

00:00:05,629 --> 00:00:11,519
thanks for being here with me but this

00:00:09,360 --> 00:00:13,139
is a very entry level talk why because I

00:00:11,519 --> 00:00:15,120
want to be excited to spend this time

00:00:13,139 --> 00:00:16,710
being really excited about how easy it

00:00:15,120 --> 00:00:18,750
is to do machine learning these days and

00:00:16,710 --> 00:00:20,189
convince you that you can do it which

00:00:18,750 --> 00:00:21,449
also means that if you've ever made a

00:00:20,189 --> 00:00:22,920
model with scikit-learn

00:00:21,449 --> 00:00:25,080
you should probably leave now because

00:00:22,920 --> 00:00:27,390
I'm going to bore you just it's okay I

00:00:25,080 --> 00:00:33,149
won't feel bad it's fine you can just

00:00:27,390 --> 00:00:34,770
leave all right please okay this was fun

00:00:33,149 --> 00:00:38,250
stuff it's very exciting it's going to

00:00:34,770 --> 00:00:40,950
be good so I hope you know a little bit

00:00:38,250 --> 00:00:42,059
of Python or at least some pseudo codes

00:00:40,950 --> 00:00:44,340
and so yeah this is not going to be

00:00:42,059 --> 00:00:46,110
totally agree but we're going to go to

00:00:44,340 --> 00:00:47,579
start out with even what even is machine

00:00:46,110 --> 00:00:49,079
learning we're going to take a look at

00:00:47,579 --> 00:00:50,670
what's available in scikit-learn and

00:00:49,079 --> 00:00:57,149
then we're going to do an example which

00:00:50,670 --> 00:00:59,129
wheels data real data friends so I hate

00:00:57,149 --> 00:01:00,809
the term machine learning I have a

00:00:59,129 --> 00:01:03,359
statistics backgrounds which is all just

00:01:00,809 --> 00:01:04,860
the operations research I don't know I

00:01:03,359 --> 00:01:06,570
found this lovely illustration of

00:01:04,860 --> 00:01:08,369
machine tailoring and I feel like that's

00:01:06,570 --> 00:01:12,630
a better example of what's actually

00:01:08,369 --> 00:01:13,890
happening you tell the computer you're

00:01:12,630 --> 00:01:16,259
good at looking at lots and lots of

00:01:13,890 --> 00:01:17,960
options you can do it fast I know you

00:01:16,259 --> 00:01:20,189
want something in this kind of shape

00:01:17,960 --> 00:01:23,729
here's some data make it fit to this

00:01:20,189 --> 00:01:25,439
variant it makes leave longer pains ahem

00:01:23,729 --> 00:01:27,689
do whatever you need to do to make

00:01:25,439 --> 00:01:30,329
something in this shape fit this data

00:01:27,689 --> 00:01:32,430
that I've given you so it's not it's not

00:01:30,329 --> 00:01:34,590
learning but it's making its making the

00:01:32,430 --> 00:01:36,689
best of the shape you've told it but the

00:01:34,590 --> 00:01:42,720
data that you've given up the bottom

00:01:36,689 --> 00:01:45,420
seems fair and scikit-learn helps us out

00:01:42,720 --> 00:01:48,840
so much and I have a ton of examples for

00:01:45,420 --> 00:01:51,119
us this top roll is kind of a the top

00:01:48,840 --> 00:01:53,399
level what are the types of machine

00:01:51,119 --> 00:01:54,780
learning classification is anything we

00:01:53,399 --> 00:01:57,360
were going to get back out a categorical

00:01:54,780 --> 00:01:59,399
variable so whether you're gendering

00:01:57,360 --> 00:02:02,340
chickens or you're trying to find guest

00:01:59,399 --> 00:02:03,740
people's favorite colors you're going to

00:02:02,340 --> 00:02:05,610
do some kind of specification problem

00:02:03,740 --> 00:02:07,170
regression is anything that gives back

00:02:05,610 --> 00:02:08,759
out a continuous variable you're trying

00:02:07,170 --> 00:02:12,300
to get people's salaries or

00:02:08,759 --> 00:02:13,950
iq are their SAT scores plus legs a

00:02:12,300 --> 00:02:17,310
little different because all you tell it

00:02:13,950 --> 00:02:20,010
is I think I have some group like four

00:02:17,310 --> 00:02:22,769
how about four which you can get me

00:02:20,010 --> 00:02:24,629
schema converts back and it just given

00:02:22,769 --> 00:02:27,510
whatever shape of algorithm you told it

00:02:24,629 --> 00:02:30,629
to do it finds the best group in that

00:02:27,510 --> 00:02:33,660
data these other three things are that

00:02:30,629 --> 00:02:35,430
80% of the work of data science where

00:02:33,660 --> 00:02:36,660
you're actually pre-processing data are

00:02:35,430 --> 00:02:38,610
figuring out which of these models is

00:02:36,660 --> 00:02:40,230
the best model are changing those

00:02:38,610 --> 00:02:42,450
variables or picking the variables that

00:02:40,230 --> 00:02:43,920
go into the she mary model but the

00:02:42,450 --> 00:02:45,810
important thing for getting started is

00:02:43,920 --> 00:02:48,810
there a whole bunch of really cool

00:02:45,810 --> 00:02:50,459
examples up on site get learn for those

00:02:48,810 --> 00:02:53,670
three main machine learning problems you

00:02:50,459 --> 00:02:56,040
might wanted to go we're going to look

00:02:53,670 --> 00:02:58,950
at classification because i like it and

00:02:56,040 --> 00:03:01,079
it's simple and I filled it straight off

00:02:58,950 --> 00:03:04,739
the scikit-learn example page so you can

00:03:01,079 --> 00:03:07,650
look at it yeah there are tiny little

00:03:04,739 --> 00:03:09,390
numbers in the corner it's trying to

00:03:07,650 --> 00:03:10,980
show you the difference between these

00:03:09,390 --> 00:03:13,680
algorithms and how they behave on

00:03:10,980 --> 00:03:15,510
different data sets the top one has like

00:03:13,680 --> 00:03:18,870
a lump of blue up in the middle towards

00:03:15,510 --> 00:03:21,599
the red the middle one has blue in the

00:03:18,870 --> 00:03:23,310
center and the one at the bottom has a

00:03:21,599 --> 00:03:24,540
nice split and so you can see how

00:03:23,310 --> 00:03:26,880
different algorithms treat that

00:03:24,540 --> 00:03:28,739
differently would be shaded areas are

00:03:26,880 --> 00:03:35,010
for probabilistic algorithms and I was

00:03:28,739 --> 00:03:36,720
less sure in the shaded areas so if you

00:03:35,010 --> 00:03:38,040
already know something about the shape

00:03:36,720 --> 00:03:39,480
of your data if you have some

00:03:38,040 --> 00:03:39,750
information about what you're dealing

00:03:39,480 --> 00:03:40,970
with

00:03:39,750 --> 00:03:44,190
you can already make an informed guess

00:03:40,970 --> 00:03:46,859
about what classifier might be good but

00:03:44,190 --> 00:03:49,590
we're using the same library to fit any

00:03:46,859 --> 00:03:50,880
of these so you can get it set up into

00:03:49,590 --> 00:03:53,280
your example with one of them and if

00:03:50,880 --> 00:03:54,959
it's terrible it's probably not that

00:03:53,280 --> 00:03:56,819
hard to find the scikit-learn example

00:03:54,959 --> 00:04:00,180
that probably takes them very similarly

00:03:56,819 --> 00:04:02,010
shaped data so try a different one so if

00:04:00,180 --> 00:04:03,599
you're not you don't have to choose the

00:04:02,010 --> 00:04:08,340
right one right away it's okay we're

00:04:03,599 --> 00:04:10,889
going to play we're gonna learn we're

00:04:08,340 --> 00:04:12,359
going to do decision trees I really like

00:04:10,889 --> 00:04:14,129
decision trees because it's you need to

00:04:12,359 --> 00:04:16,079
explain what they're doing it's not

00:04:14,129 --> 00:04:18,719
super easy to explain how they're doing

00:04:16,079 --> 00:04:20,880
it but all they do is they say I have

00:04:18,719 --> 00:04:24,030
some data how

00:04:20,880 --> 00:04:26,900
blitzes data so that my gift next step

00:04:24,030 --> 00:04:28,920
is best possible gift I can make and

00:04:26,900 --> 00:04:31,170
then I usually go until they hit

00:04:28,920 --> 00:04:32,760
whatever stopping criteria and the nice

00:04:31,170 --> 00:04:34,170
thing about that is your model is going

00:04:32,760 --> 00:04:35,790
to be wrong and you're going to miss

00:04:34,170 --> 00:04:38,700
classify something and with a decision

00:04:35,790 --> 00:04:40,950
tree you're able to figure out where it

00:04:38,700 --> 00:04:43,860
ended up you can follow the path of how

00:04:40,950 --> 00:04:45,990
that observation got classified as

00:04:43,860 --> 00:04:47,460
favorite color blue when clearly it

00:04:45,990 --> 00:04:49,380
should have been favorite color pink and

00:04:47,460 --> 00:04:50,940
then you can see which variables went

00:04:49,380 --> 00:04:52,470
into that decision and decide whether

00:04:50,940 --> 00:04:53,730
there are more things you want to add or

00:04:52,470 --> 00:04:56,040
that maybe you should taken out because

00:04:53,730 --> 00:04:58,170
they were misleading this is a very

00:04:56,040 --> 00:05:00,990
simple example but again I took straight

00:04:58,170 --> 00:05:03,450
from the psyche of iron webpage yeah why

00:05:00,990 --> 00:05:05,070
I'm here to just a day in July the

00:05:03,450 --> 00:05:06,720
scikit-learn package to you I'm tell you

00:05:05,070 --> 00:05:10,440
that it is wonderful and it is there for

00:05:06,720 --> 00:05:13,710
you I work for a company called Big

00:05:10,440 --> 00:05:15,600
Cartel we're 35 people we support we

00:05:13,710 --> 00:05:18,150
make shelf online we especially like the

00:05:15,600 --> 00:05:19,760
support artists and makers we have about

00:05:18,150 --> 00:05:22,320
ninety thousand active shops right now

00:05:19,760 --> 00:05:25,290
and I've been there a sole data person

00:05:22,320 --> 00:05:28,080
for the last year a lot of fun and we're

00:05:25,290 --> 00:05:30,060
going to pull some data and get that I'm

00:05:28,080 --> 00:05:32,340
gonna go to my Jupiter notebook don't

00:05:30,060 --> 00:05:34,500
worry the slides the Jupiter notebook

00:05:32,340 --> 00:05:38,120
and that big ugly tree graphs are all up

00:05:34,500 --> 00:05:38,120
on my github so you can find them later

00:05:43,159 --> 00:05:47,959
so I have a bunch of URLs in here

00:05:46,009 --> 00:05:50,779
because I want you to know that I don't

00:05:47,959 --> 00:05:52,729
know these things I look them up you

00:05:50,779 --> 00:05:55,039
will look sum up it's okay

00:05:52,729 --> 00:05:58,849
we're following example it's great

00:05:55,039 --> 00:06:05,019
that's what the web's for we're just

00:05:58,849 --> 00:06:07,519
gonna wear a following this example just

00:06:05,019 --> 00:06:08,809
classification industries and trees just

00:06:07,519 --> 00:06:10,819
trying to do exactly with it if this is

00:06:08,809 --> 00:06:15,709
the one that generates that graph that

00:06:10,819 --> 00:06:18,229
we just saw we're going to import numpy

00:06:15,709 --> 00:06:19,999
so that if I can't learn to do things

00:06:18,229 --> 00:06:22,159
with numbers that's always good

00:06:19,999 --> 00:06:23,179
we're importing matplotlib just like

00:06:22,159 --> 00:06:25,729
this we're not actually gonna use this

00:06:23,179 --> 00:06:28,069
sorry we're going to import Candice

00:06:25,729 --> 00:06:33,139
which is a data frame library for Python

00:06:28,069 --> 00:06:34,699
and it's big and it's complex and I

00:06:33,139 --> 00:06:35,539
don't really know how to use it but I'm

00:06:34,699 --> 00:06:37,699
going to show you a couple of cool

00:06:35,539 --> 00:06:39,800
things that it does for us here that I

00:06:37,699 --> 00:06:41,419
had to Google to figure out how to do so

00:06:39,800 --> 00:06:43,519
that's okay but it makes it a little

00:06:41,419 --> 00:06:44,719
easy to do something and probably excuse

00:06:43,519 --> 00:06:47,199
me to do a lot of things I just don't

00:06:44,719 --> 00:06:50,240
know all of them yet

00:06:47,199 --> 00:06:52,009
luckily I have a lot of data that we've

00:06:50,240 --> 00:06:53,269
already gathered in a white format any

00:06:52,009 --> 00:06:55,789
of our normal database that has

00:06:53,269 --> 00:06:58,819
everything aggregate segregated out but

00:06:55,789 --> 00:07:01,729
we have a tool that we use for support

00:06:58,819 --> 00:07:03,199
so when people want to ask questions and

00:07:01,729 --> 00:07:05,329
find out more about their shop and make

00:07:03,199 --> 00:07:06,769
sure things are working right the whole

00:07:05,329 --> 00:07:08,809
bunch of data about their shop is

00:07:06,769 --> 00:07:11,269
already available in the tool for our

00:07:08,809 --> 00:07:13,509
support professionals to use I just

00:07:11,269 --> 00:07:15,740
downloaded a bunch of data I was there

00:07:13,509 --> 00:07:17,059
then I got a whole bunch of data that we

00:07:15,740 --> 00:07:18,619
know is very relevant about the shop

00:07:17,059 --> 00:07:21,169
that we know we're interested in I was

00:07:18,619 --> 00:07:24,079
able to get it in one place so I cheated

00:07:21,169 --> 00:07:25,969
I recommend cheating I'm not going to

00:07:24,079 --> 00:07:27,559
run these but it is what I did run it

00:07:25,969 --> 00:07:30,409
recently so we can inspect these later

00:07:27,559 --> 00:07:32,389
in the QA so I just I grabbed a whole

00:07:30,409 --> 00:07:35,809
bunch of recent people things we've seen

00:07:32,389 --> 00:07:37,999
basically on the website there's a whole

00:07:35,809 --> 00:07:39,649
lot of columns if they're capitalized in

00:07:37,999 --> 00:07:41,599
fancy format it they probably came under

00:07:39,649 --> 00:07:43,490
the support same if there are

00:07:41,599 --> 00:07:45,430
underscores and lines and they're

00:07:43,490 --> 00:07:47,320
probably things we put in there

00:07:45,430 --> 00:07:49,210
that it has all sorts of information

00:07:47,320 --> 00:07:52,270
from how many products they have how

00:07:49,210 --> 00:07:55,150
many times they logged in when was the

00:07:52,270 --> 00:07:57,340
thing created how where we find them in

00:07:55,150 --> 00:07:58,990
our system whether they have a custom

00:07:57,340 --> 00:08:00,850
domain just all sorts of information

00:07:58,990 --> 00:08:02,980
that is useful to support people and

00:08:00,850 --> 00:08:09,010
might be useful thrills in a model at

00:08:02,980 --> 00:08:12,370
least think is this a place to start and

00:08:09,010 --> 00:08:14,950
this is a pretty big data frame a little

00:08:12,370 --> 00:08:17,470
over 100 thousand observations so we can

00:08:14,950 --> 00:08:19,450
just willy-nilly we're like yes we got

00:08:17,470 --> 00:08:20,700
some stuff it's fine I have to worry

00:08:19,450 --> 00:08:22,390
about whether we have enough data

00:08:20,700 --> 00:08:27,210
normally you would like to have some

00:08:22,390 --> 00:08:30,700
data probably more than a hundred things

00:08:27,210 --> 00:08:32,530
and because this is just an example I

00:08:30,700 --> 00:08:34,240
just picked a random categorical balance

00:08:32,530 --> 00:08:35,920
variable that had some variation in the

00:08:34,240 --> 00:08:37,210
data set and so we're going to pick some

00:08:35,920 --> 00:08:39,340
variables and see if we can make a

00:08:37,210 --> 00:08:41,230
decision tree that predicts whether or

00:08:39,340 --> 00:08:42,730
not this particular customer is using

00:08:41,230 --> 00:08:44,110
the using discounts whether they've

00:08:42,730 --> 00:08:50,230
created any discount codes

00:08:44,110 --> 00:08:52,030
I create my Y column which I probably

00:08:50,230 --> 00:08:53,860
didn't need to do I probably could have

00:08:52,030 --> 00:08:56,770
just said it so we spent using discounts

00:08:53,860 --> 00:08:59,830
but I felt better making knowing it was

00:08:56,770 --> 00:09:02,260
zeros and ones explicitly actually and

00:08:59,830 --> 00:09:04,180
you can see that not all of using

00:09:02,260 --> 00:09:06,010
discounts is filled in the count is

00:09:04,180 --> 00:09:07,870
lower than the shape of a thing so by

00:09:06,010 --> 00:09:19,270
explicitly making them one zero I get

00:09:07,870 --> 00:09:21,040
the zeros for the undefined so we just

00:09:19,270 --> 00:09:22,510
print a couple of fun variables that I

00:09:21,040 --> 00:09:25,510
thought might be interesting I get a mix

00:09:22,510 --> 00:09:27,130
of categorical and continuous variables

00:09:25,510 --> 00:09:29,190
product count and log and count are

00:09:27,130 --> 00:09:31,720
going to between zero and a whole bunch

00:09:29,190 --> 00:09:34,540
browser has a much more limited set of

00:09:31,720 --> 00:09:36,310
values that you're going to see seeing

00:09:34,540 --> 00:09:37,450
is just how they're one of our themes

00:09:36,310 --> 00:09:39,010
they've chosen to make your website look

00:09:37,450 --> 00:09:41,340
pretty plan is how much they're paying

00:09:39,010 --> 00:09:41,340
yes

00:09:44,340 --> 00:09:49,540
so we're going to build up our expand

00:09:46,600 --> 00:09:50,950
tricks and I hope matrices are not scary

00:09:49,540 --> 00:09:53,170
I'm sorry I have a math background

00:09:50,950 --> 00:09:55,780
they're fun to me

00:09:53,170 --> 00:09:57,550
so we're trying no but why we're trying

00:09:55,780 --> 00:09:58,870
to do they use discount or not so we're

00:09:57,550 --> 00:10:01,330
trying to build a set of things that

00:09:58,870 --> 00:10:02,590
we're going to predict why with so we're

00:10:01,330 --> 00:10:04,930
going to start with this continuous one

00:10:02,590 --> 00:10:07,870
so get product count on there logging

00:10:04,930 --> 00:10:08,740
town on there and we could just put the

00:10:07,870 --> 00:10:11,320
rest of them in right

00:10:08,740 --> 00:10:15,220
turns out scikit-learn required your

00:10:11,320 --> 00:10:16,360
classifier to have 0 1 columns and this

00:10:15,220 --> 00:10:17,770
is when we get to use some really fun

00:10:16,360 --> 00:10:20,520
stuff out a pan that is to help us out

00:10:17,770 --> 00:10:20,520
and lazy

00:10:21,330 --> 00:10:27,610
so pandas has this get dummies function

00:10:25,540 --> 00:10:29,860
and it will take a column and it will

00:10:27,610 --> 00:10:33,550
make a set of columns of that column so

00:10:29,860 --> 00:10:37,300
when we look at this nice observation

00:10:33,550 --> 00:10:38,770
it's beam is sidecar the get dummies is

00:10:37,300 --> 00:10:40,960
going to create all the theme variable

00:10:38,770 --> 00:10:42,520
and that observation will have a 1 under

00:10:40,960 --> 00:10:44,260
sidecar and a 0 under all the other

00:10:42,520 --> 00:10:46,300
theme variables and they all become

00:10:44,260 --> 00:10:48,070
columns as your own ones which make

00:10:46,300 --> 00:10:50,080
machine learning algorithms much happier

00:10:48,070 --> 00:10:52,720
and we do that for all of our

00:10:50,080 --> 00:10:54,130
categorical values which I didn't know

00:10:52,720 --> 00:10:54,730
was a thing until I stride to set this

00:10:54,130 --> 00:10:56,710
up for y'all

00:10:54,730 --> 00:10:58,060
and then we concatenate them all

00:10:56,710 --> 00:11:00,340
together we just jam them on the side of

00:10:58,060 --> 00:11:01,930
our X matrix I didn't know how to do

00:11:00,340 --> 00:11:05,020
that pandas and so I get a little bit

00:11:01,930 --> 00:11:10,060
for how to do it for you all so just

00:11:05,020 --> 00:11:11,950
know it's possible and then because our

00:11:10,060 --> 00:11:13,510
data set is kind of it comes from a

00:11:11,950 --> 00:11:15,760
support thing if some of those people

00:11:13,510 --> 00:11:17,170
are just leads sometimes things aren't

00:11:15,760 --> 00:11:18,720
filled in think about things up there's

00:11:17,170 --> 00:11:21,520
some there are some things that aren't

00:11:18,720 --> 00:11:23,350
filled out there and so we're just

00:11:21,520 --> 00:11:26,050
filling them in I think pandas please

00:11:23,350 --> 00:11:26,800
fill all the things with 0 it's better

00:11:26,050 --> 00:11:28,060
not defined

00:11:26,800 --> 00:11:33,790
please thank you that would make the

00:11:28,060 --> 00:11:36,250
algorithm happier and it obliges so now

00:11:33,790 --> 00:11:37,450
that we've built up our X matrix we ask

00:11:36,250 --> 00:11:39,130
it again what it has and you can see

00:11:37,450 --> 00:11:40,390
that the themes are now pulled out I

00:11:39,130 --> 00:11:42,820
said different columns and you can view

00:11:40,390 --> 00:11:45,400
the time zone so we have a whole lot

00:11:42,820 --> 00:11:46,780
more columns now we have 256 columns so

00:11:45,400 --> 00:11:48,370
we're going to try and use to predict

00:11:46,780 --> 00:11:50,500
whether the people use this counts or

00:11:48,370 --> 00:11:54,540
not well cool that's all we need we have

00:11:50,500 --> 00:11:54,540
an X and a wild fit as decisions real

00:11:55,260 --> 00:12:01,920
so we fit one cool and then we say hey

00:11:58,560 --> 00:12:04,230
treat how could you with 99% correct

00:12:01,920 --> 00:12:05,970
pretty cool right pretty cool

00:12:04,230 --> 00:12:10,980
well it's asked to treat some other

00:12:05,970 --> 00:12:12,270
stuff tree how many flips did you do to

00:12:10,980 --> 00:12:16,290
get 99% correct

00:12:12,270 --> 00:12:19,320
I made 56 split he's bought this really

00:12:16,290 --> 00:12:22,860
good I found all the things like that's

00:12:19,320 --> 00:12:24,470
kind of a lot but just it gets really

00:12:22,860 --> 00:12:27,270
hard to deal with to look through

00:12:24,470 --> 00:12:29,970
picking a smaller but not too small

00:12:27,270 --> 00:12:33,300
number out of a hat it takes 20 until we

00:12:29,970 --> 00:12:39,450
just try again and these are just things

00:12:33,300 --> 00:12:41,850
you can tell it good and it it's Python

00:12:39,450 --> 00:12:43,080
it's documented these are just things it

00:12:41,850 --> 00:12:44,580
tells you and they tell you what the

00:12:43,080 --> 00:12:48,030
possible values are and you can just try

00:12:44,580 --> 00:12:51,390
some of them so we're going to change

00:12:48,030 --> 00:12:53,160
the max depths to 20 we're bad 2000 is

00:12:51,390 --> 00:12:55,560
enough you're getting you're going to

00:12:53,160 --> 00:12:57,540
overfitting a little man and so when we

00:12:55,560 --> 00:13:00,950
do that with our same dataset it only

00:12:57,540 --> 00:13:03,300
fits 91 percent of them correctly so

00:13:00,950 --> 00:13:10,440
made a big difference and how much I was

00:13:03,300 --> 00:13:12,270
able to explain so but actually we're

00:13:10,440 --> 00:13:15,600
kind of cheating because we're asking it

00:13:12,270 --> 00:13:17,850
how well it did on fitting predicting

00:13:15,600 --> 00:13:20,250
the data that it just fit it knows what

00:13:17,850 --> 00:13:22,560
that data is it just tailored it for

00:13:20,250 --> 00:13:24,390
that data so what we ought to do we

00:13:22,560 --> 00:13:27,750
really I do is we have split our dataset

00:13:24,390 --> 00:13:29,670
and the training and testing I just I

00:13:27,750 --> 00:13:32,790
don't know why I 630 thousands because

00:13:29,670 --> 00:13:35,010
it seems big thanks good so we split

00:13:32,790 --> 00:13:38,910
them up and now to make our next tree

00:13:35,010 --> 00:13:41,760
and we tell it to make some model based

00:13:38,910 --> 00:13:43,620
on just the training data set and it's

00:13:41,760 --> 00:13:47,250
like yeah I did good on the training

00:13:43,620 --> 00:13:49,110
dataset at 94% of those right like yeah

00:13:47,250 --> 00:13:55,080
how does that generalize the only one

00:13:49,110 --> 00:13:56,850
like 82% tried and that tells us

00:13:55,080 --> 00:13:58,530
something that tells us that these are

00:13:56,850 --> 00:14:01,590
probably not very good variables for

00:13:58,530 --> 00:14:02,790
predicting list that's cool maybe we go

00:14:01,590 --> 00:14:05,430
back and choose some different variables

00:14:02,790 --> 00:14:06,339
to put the model is everything you view

00:14:05,430 --> 00:14:08,620
doesn't have to be

00:14:06,339 --> 00:14:10,509
model if it's 99% everything you will

00:14:08,620 --> 00:14:14,170
still learn something by finding a model

00:14:10,509 --> 00:14:16,749
that fits badly so now look at another

00:14:14,170 --> 00:14:18,939
couple of cool things following that

00:14:16,749 --> 00:14:20,559
same exact example that gave us the

00:14:18,939 --> 00:14:24,759
thing before the graph a May we're gonna

00:14:20,559 --> 00:14:26,620
make a graph like there so the tree

00:14:24,759 --> 00:14:30,189
library has the ability to make graphs

00:14:26,620 --> 00:14:32,110
is file they're plain text files I put

00:14:30,189 --> 00:14:34,649
it on the github repo and then you run a

00:14:32,110 --> 00:14:41,170
magic command and you get this horrible

00:14:34,649 --> 00:14:44,199
horrible PDF but I'm sorry for that's

00:14:41,170 --> 00:14:45,339
our trees that's what my steps of 20

00:14:44,199 --> 00:14:47,079
isn't it beautiful

00:14:45,339 --> 00:14:49,120
I try to what we tried to make it so

00:14:47,079 --> 00:14:51,480
much nicer like it would have done 56 or

00:14:49,120 --> 00:15:01,149
something I would have been so many more

00:14:51,480 --> 00:15:02,470
yeah you don't feel as yet alright but

00:15:01,149 --> 00:15:04,180
we were able to pass at the names of the

00:15:02,470 --> 00:15:06,459
column and things like that so we can

00:15:04,180 --> 00:15:08,800
see how it made these decisions what

00:15:06,459 --> 00:15:10,749
variables went into those decisions and

00:15:08,800 --> 00:15:12,970
then the purity to the notes afterwards

00:15:10,749 --> 00:15:14,559
what what what ends up in that set for

00:15:12,970 --> 00:15:16,269
its new split so it's kind of really

00:15:14,559 --> 00:15:17,350
cool to see how it does it and be able

00:15:16,269 --> 00:15:20,230
to trace back through it

00:15:17,350 --> 00:15:21,399
even if 20 splits might be a little more

00:15:20,230 --> 00:15:25,110
than you want to go through it from more

00:15:21,399 --> 00:15:25,110
than one or two really bust it variables

00:15:30,920 --> 00:15:35,430
yeah pause to look at terrifying PDF

00:15:33,630 --> 00:15:37,320
okay another thing that the tree will

00:15:35,430 --> 00:15:39,240
tell you is how important the various

00:15:37,320 --> 00:15:41,070
variables you gave it are be variable

00:15:39,240 --> 00:15:43,620
they're called features you feed it

00:15:41,070 --> 00:15:45,750
features so we asked it about the future

00:15:43,620 --> 00:15:48,060
importances and it's like cool here's a

00:15:45,750 --> 00:15:50,790
major so here's a vector of 256

00:15:48,060 --> 00:15:53,820
importance it's not the most fun thing

00:15:50,790 --> 00:15:58,200
to read so we'll play with that a little

00:15:53,820 --> 00:16:00,990
bit so tree what is the best what is the

00:15:58,200 --> 00:16:03,600
most important thing and it says zero I

00:16:00,990 --> 00:16:04,680
mean I don't know about you but when the

00:16:03,600 --> 00:16:06,899
computer tells me the answer to

00:16:04,680 --> 00:16:08,250
something is zero I'm a little suspect I

00:16:06,899 --> 00:16:11,040
want to make sure I check a couple of

00:16:08,250 --> 00:16:12,959
things it could really mean zero or it

00:16:11,040 --> 00:16:16,140
could mean I am mad in some unspecified

00:16:12,959 --> 00:16:18,839
way here's a zero pub so we're going to

00:16:16,140 --> 00:16:20,520
get the top 10 and the hot turned out to

00:16:18,839 --> 00:16:22,230
be weird and hard Thank You Stack

00:16:20,520 --> 00:16:23,790
Overflow for helping me so I gave you

00:16:22,230 --> 00:16:25,709
the URLs that's a nice people on Stack

00:16:23,790 --> 00:16:28,529
Overflow who helped me figure this out

00:16:25,709 --> 00:16:30,660
it turns out numpy has this arg

00:16:28,529 --> 00:16:33,330
partition thing that will give you the

00:16:30,660 --> 00:16:35,160
top X things in the array

00:16:33,330 --> 00:16:37,529
it doesn't do some to you in any

00:16:35,160 --> 00:16:38,850
particular order all right I'm sure that

00:16:37,529 --> 00:16:39,420
makes it more efficient great cool

00:16:38,850 --> 00:16:43,620
thanks

00:16:39,420 --> 00:16:46,110
fix Mumbai and then r j-- sort lets us

00:16:43,620 --> 00:16:48,150
get them in an order but it says ten

00:16:46,110 --> 00:16:49,920
nine eight I want to I want one to be

00:16:48,150 --> 00:16:52,589
first what is important to me

00:16:49,920 --> 00:16:55,650
so then NP touch lifts up down because

00:16:52,589 --> 00:16:57,200
it's a vector right I'm so picky I just

00:16:55,650 --> 00:16:59,370
wanted to do what I want

00:16:57,200 --> 00:17:02,820
so this is what we actually get is it

00:16:59,370 --> 00:17:05,010
says 0 X 1 so our arc max is right it

00:17:02,820 --> 00:17:07,199
wasn't just like flying tuning so it

00:17:05,010 --> 00:17:08,640
didn't know what I was talking about the

00:17:07,199 --> 00:17:10,740
first one and then the seventeenth one

00:17:08,640 --> 00:17:12,600
and what are those I will just there's

00:17:10,740 --> 00:17:15,089
the same index with the columns of X R

00:17:12,600 --> 00:17:18,300
so that's our product count on our login

00:17:15,089 --> 00:17:20,280
count gold is our free pant plan so kind

00:17:18,300 --> 00:17:22,309
of sense that the whether you pass or

00:17:20,280 --> 00:17:24,420
not tells me a lot about how you act

00:17:22,309 --> 00:17:27,839
it's interesting to see the browsers

00:17:24,420 --> 00:17:29,760
come up and but when you look at the

00:17:27,839 --> 00:17:33,780
actual values for the future importance

00:17:29,760 --> 00:17:34,570
of their third zig trail off really

00:17:33,780 --> 00:17:36,550
quickly

00:17:34,570 --> 00:17:39,460
so if I'm actually trying to do a better

00:17:36,550 --> 00:17:41,230
job with this model maybe I keep those

00:17:39,460 --> 00:17:42,970
first two continuous variables and I

00:17:41,230 --> 00:17:44,770
swap out those random categorical

00:17:42,970 --> 00:17:47,140
variables but it was really fun to learn

00:17:44,770 --> 00:17:48,010
how to make that B's for but I try and

00:17:47,140 --> 00:17:50,140
find something that might be a little

00:17:48,010 --> 00:17:51,310
more relevant and put those into the

00:17:50,140 --> 00:17:52,360
model next time and give it a shot

00:17:51,310 --> 00:17:54,490
because we're seeing that so many of

00:17:52,360 --> 00:17:55,960
those are really not contributing so we

00:17:54,490 --> 00:17:57,460
are able to just inspect that model and

00:17:55,960 --> 00:18:01,150
learn something about the dataset and

00:17:57,460 --> 00:18:03,520
about what kind of model fits as well so

00:18:01,150 --> 00:18:08,190
you can do this how the dataset

00:18:03,520 --> 00:18:16,150
just follow the example and Google a lot

00:18:08,190 --> 00:18:16,570
how we do I do have some resources for

00:18:16,150 --> 00:18:18,700
you

00:18:16,570 --> 00:18:20,860
besides this data science from scratch

00:18:18,700 --> 00:18:22,840
is helps you try and build the stuff up

00:18:20,860 --> 00:18:24,040
from Python I have not used it

00:18:22,840 --> 00:18:26,080
personally but I've heard really good

00:18:24,040 --> 00:18:28,180
things I really like elements of

00:18:26,080 --> 00:18:30,790
statistical learning but it's pretty

00:18:28,180 --> 00:18:32,140
dense but it's a semi PDF so at least

00:18:30,790 --> 00:18:34,330
you're not investing a lot of money in

00:18:32,140 --> 00:18:37,330
dense thing and all these labels earn

00:18:34,330 --> 00:18:39,010
our warrant um some of my colleagues

00:18:37,330 --> 00:18:41,500
helpfully provided these other titles

00:18:39,010 --> 00:18:43,870
for us so I cannot vouch for them

00:18:41,500 --> 00:18:45,160
directly but Ryan and Rebecca are very

00:18:43,870 --> 00:18:49,510
smart people I'm sure they knew what

00:18:45,160 --> 00:18:51,160
they're talking about thank you for

00:18:49,510 --> 00:18:53,080
hanging out with me it's been an amazing

00:18:51,160 --> 00:18:56,730
conference we have transferred a lot of

00:18:53,080 --> 00:18:56,730
data between us just hunt these two days

00:18:58,280 --> 00:19:02,940
[Applause]

00:19:03,430 --> 00:19:05,490

YouTube URL: https://www.youtube.com/watch?v=6LkQ8Ue8ieM


