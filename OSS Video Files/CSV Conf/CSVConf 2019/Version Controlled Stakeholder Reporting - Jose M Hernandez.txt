Title: Version Controlled Stakeholder Reporting - Jose M Hernandez
Publication date: 2019-06-21
Playlist: CSVConf 2019
Description: 
	Talk title: Version Controlled Stakeholder Reporting: Building an End-to-End Data Reporting Infrastructure

King County, Washington is currently undergoing complex social and economic changes that have both positive and negative impacts on local residents. With rising rents displacing low-income households to outlying areas or into homelessness, there is a critical need to understand the prevalence and mechanisms of housing insecurity for government organizations tasked to address these issues. Currently, our team of Data and social scientists at the University of Washington, eScience Institute are collaborating with stakeholders across the King County Housing and Homelessness prevention agencies to derive meaningful insights from their data. While their aim is not to produce academic research, our findings may have significant and immediate impact for their organizational practices and the communities they are tasked to serve. In this context and where there is an iterative and constant feedback loop present, reproducibility of the results we present to them, from figures, tables, and even written language is critical. To ensure a successful collaboration, our team has built an end to end data reporting infrastructure to produce reports for our stakeholders that are reproducible and version controlled from raw data to final product. We employ some common open source tools to accomplish this, including R/Rstudio, Python, Rmarkdown, and git.

Talk page: https://csvconf.com/speakers/#jose-m-hernandez
Captions: 
	00:00:01,980 --> 00:00:08,860
well hi everyone my name is Jose

00:00:06,460 --> 00:00:11,110
Hernandez and I'm a data scientist at

00:00:08,860 --> 00:00:13,510
the UW nervouser Washington East Science

00:00:11,110 --> 00:00:16,090
Institute just a little bit about myself

00:00:13,510 --> 00:00:18,789
my background is in apply statistics

00:00:16,090 --> 00:00:23,650
Social Sciences educational measurement

00:00:18,789 --> 00:00:25,630
actually and before that I did some data

00:00:23,650 --> 00:00:28,449
science work in the nonprofit sector

00:00:25,630 --> 00:00:30,400
working with Education data and then way

00:00:28,449 --> 00:00:32,200
before that I'm actually from South

00:00:30,400 --> 00:00:33,850
Central Los Angeles and Santa Ana

00:00:32,200 --> 00:00:42,550
California anyone hear from those two

00:00:33,850 --> 00:00:44,649
places also which one oh nice so yeah so

00:00:42,550 --> 00:00:46,059
you know Santa Ana and now I'm here and

00:00:44,649 --> 00:00:48,519
I never thought I would be talking about

00:00:46,059 --> 00:00:51,039
version control stakeholder reporting

00:00:48,519 --> 00:00:52,510
building an end-to-end reporting

00:00:51,039 --> 00:00:54,670
infrastructure so I'm happy to be here

00:00:52,510 --> 00:00:57,489
this is my first time at CSV conference

00:00:54,670 --> 00:01:01,359
it's great I saw the though amar is it

00:00:57,489 --> 00:01:02,739
it's not it's a llama but it's okay I'm

00:01:01,359 --> 00:01:06,790
not an alpaca okay

00:01:02,739 --> 00:01:08,830
all right I I took a picture of it I

00:01:06,790 --> 00:01:12,670
didn't take a picture with the with the

00:01:08,830 --> 00:01:14,860
llama so today I'm just gonna talk to

00:01:12,670 --> 00:01:18,370
you guys about a a collaboration that's

00:01:14,860 --> 00:01:20,170
ongoing that a team at East science

00:01:18,370 --> 00:01:22,360
including myself have been kind of

00:01:20,170 --> 00:01:24,940
working on for the last couple of years

00:01:22,360 --> 00:01:26,650
and just to kind of say this I've only

00:01:24,940 --> 00:01:28,210
been at he signs for one year so when I

00:01:26,650 --> 00:01:30,610
came in it was kind of came in to this

00:01:28,210 --> 00:01:32,710
project that already existed but it's

00:01:30,610 --> 00:01:34,750
evolved a lot from that year when I came

00:01:32,710 --> 00:01:36,640
in I'll tell you a little bit about what

00:01:34,750 --> 00:01:40,360
the East Science Institute is kind of

00:01:36,640 --> 00:01:43,030
who we are what we do and why we exist I

00:01:40,360 --> 00:01:45,420
try to do it justice there's other

00:01:43,030 --> 00:01:47,890
people in this room that have way better

00:01:45,420 --> 00:01:51,270
background on this yeah not just no

00:01:47,890 --> 00:01:53,710
pressure right the type of

00:01:51,270 --> 00:01:57,120
collaborations and projects that we kind

00:01:53,710 --> 00:02:00,360
of foster and and develop at a science

00:01:57,120 --> 00:02:03,700
and in particular I'm gonna focus on a

00:02:00,360 --> 00:02:05,680
project that we have with the housing

00:02:03,700 --> 00:02:07,649
authorities in Seattle and in King

00:02:05,680 --> 00:02:11,140
County and also the homelessness

00:02:07,649 --> 00:02:14,379
management intervention system in King

00:02:11,140 --> 00:02:15,160
County and so talk about that project as

00:02:14,379 --> 00:02:18,340
an example

00:02:15,160 --> 00:02:20,950
how we kind of started thinking about

00:02:18,340 --> 00:02:22,540
how we were gonna collaborate with these

00:02:20,950 --> 00:02:25,030
folks that are in the trenches doing

00:02:22,540 --> 00:02:26,980
work that I want they have a lot of data

00:02:25,030 --> 00:02:29,140
and that kind of want inform their

00:02:26,980 --> 00:02:30,910
practice so I'll talk a little bit about

00:02:29,140 --> 00:02:32,440
the different types of collaboration so

00:02:30,910 --> 00:02:34,240
there's academic collaborations where

00:02:32,440 --> 00:02:36,190
we're thinking about research and things

00:02:34,240 --> 00:02:38,470
that are more traditional in academia

00:02:36,190 --> 00:02:40,300
but there's also collaborations with

00:02:38,470 --> 00:02:42,550
folks on the ground that wants you kind

00:02:40,300 --> 00:02:44,560
of inform their practice and we find

00:02:42,550 --> 00:02:46,600
both of those as valuable as each other

00:02:44,560 --> 00:02:47,890
so I'll talk about that project in

00:02:46,600 --> 00:02:49,510
particular and then some of the tools

00:02:47,890 --> 00:02:51,550
that we've developed and build for that

00:02:49,510 --> 00:02:53,080
project and then kind of what that

00:02:51,550 --> 00:02:55,270
collaboration looks like it's iterative

00:02:53,080 --> 00:02:57,250
is changing this is all work in progress

00:02:55,270 --> 00:02:58,630
in terms of what we're building but also

00:02:57,250 --> 00:03:01,240
how we're collaborating we're learning

00:02:58,630 --> 00:03:04,120
as we go it's not there's no like

00:03:01,240 --> 00:03:05,740
science or I mean there there are best

00:03:04,120 --> 00:03:07,690
practices and we're trying to kind of

00:03:05,740 --> 00:03:10,360
figure out a way that to kind of make

00:03:07,690 --> 00:03:12,100
this work and we're using this in our

00:03:10,360 --> 00:03:13,390
other collaborations with other folks so

00:03:12,100 --> 00:03:15,640
for example I collaborate a lot with

00:03:13,390 --> 00:03:17,680
folks in the education sector and I

00:03:15,640 --> 00:03:20,580
essentially borrow this blueprints and

00:03:17,680 --> 00:03:23,290
kind of implemented in that as well

00:03:20,580 --> 00:03:25,420
so what is e science institute

00:03:23,290 --> 00:03:28,240
essentially we are the data science hub

00:03:25,420 --> 00:03:30,490
at the University of Washington we

00:03:28,240 --> 00:03:32,920
really do believe that open science is a

00:03:30,490 --> 00:03:35,260
foundation for scientific discovery and

00:03:32,920 --> 00:03:36,610
there's several ways that we kind of do

00:03:35,260 --> 00:03:38,080
this are there's three areas that we

00:03:36,610 --> 00:03:40,360
really focus on so one of them is

00:03:38,080 --> 00:03:43,000
research so data during research both on

00:03:40,360 --> 00:03:44,830
the application of data science but also

00:03:43,000 --> 00:03:46,930
like the methodology that people use in

00:03:44,830 --> 00:03:49,300
this huge umbrella that is data science

00:03:46,930 --> 00:03:52,239
we provide data science training this

00:03:49,300 --> 00:03:54,750
could be in forms of workshops so

00:03:52,239 --> 00:03:56,680
there's folks in on staff that actually

00:03:54,750 --> 00:03:59,410
collaborate a lot with the data

00:03:56,680 --> 00:04:00,820
carpentry and software carpentry but

00:03:59,410 --> 00:04:03,190
there's also a lot of folks are doing a

00:04:00,820 --> 00:04:05,500
lot of work on actually formalizing data

00:04:03,190 --> 00:04:07,150
Sciences as a career track so for

00:04:05,500 --> 00:04:09,280
example there's a data science master

00:04:07,150 --> 00:04:11,380
there's a there's a way for other

00:04:09,280 --> 00:04:12,940
programs in the university to actually

00:04:11,380 --> 00:04:15,400
have for example a data science

00:04:12,940 --> 00:04:18,280
concentration in their curricula and so

00:04:15,400 --> 00:04:20,290
that's I think that's huge kind of a

00:04:18,280 --> 00:04:22,300
huge contribution to data science as a

00:04:20,290 --> 00:04:24,370
field and ultimately we're building a

00:04:22,300 --> 00:04:26,890
community of practice that's open

00:04:24,370 --> 00:04:28,070
reproducible rigorous and ethical we

00:04:26,890 --> 00:04:30,980
really do kind of

00:04:28,070 --> 00:04:33,470
stick to those principles and we try to

00:04:30,980 --> 00:04:35,840
practice them inside our academic

00:04:33,470 --> 00:04:37,220
collaborations but also outside kind of

00:04:35,840 --> 00:04:39,230
their collaborations with government

00:04:37,220 --> 00:04:42,080
government organizations that have very

00:04:39,230 --> 00:04:43,820
sensitive data that are actually working

00:04:42,080 --> 00:04:46,550
with folks on the ground and trying to

00:04:43,820 --> 00:04:51,500
you know kind of help people have better

00:04:46,550 --> 00:04:54,140
lives locally so like I mentioned types

00:04:51,500 --> 00:04:56,780
of collaboration in academia as data

00:04:54,140 --> 00:05:00,650
becomes more available as fields become

00:04:56,780 --> 00:05:02,480
more data rich folks need a way to be

00:05:00,650 --> 00:05:04,670
able to work with these data and we're

00:05:02,480 --> 00:05:06,740
situated in a way that we can offer

00:05:04,670 --> 00:05:09,260
those resources to folks within the

00:05:06,740 --> 00:05:11,690
academic setting and like I mentioned

00:05:09,260 --> 00:05:14,530
government and nonprofits specifically

00:05:11,690 --> 00:05:17,570
as people fine-tune administrative data

00:05:14,530 --> 00:05:19,760
kind of systems we see these as

00:05:17,570 --> 00:05:21,320
previously untapped data sources that we

00:05:19,760 --> 00:05:23,450
can leverage for research and inquiry

00:05:21,320 --> 00:05:25,400
but like I mentioned before that the

00:05:23,450 --> 00:05:27,020
organizations are the agencies that have

00:05:25,400 --> 00:05:29,090
this data can also leverage to inform

00:05:27,020 --> 00:05:30,290
their practice and kind of kind of

00:05:29,090 --> 00:05:31,880
iterate and get better at what they're

00:05:30,290 --> 00:05:33,860
doing on the ground and so these are

00:05:31,880 --> 00:05:35,960
kind of the two things and these happen

00:05:33,860 --> 00:05:37,580
either formally or informally so

00:05:35,960 --> 00:05:40,190
formally for example we do have some

00:05:37,580 --> 00:05:41,870
programs that folks within the

00:05:40,190 --> 00:05:43,940
institution and outside can kind of

00:05:41,870 --> 00:05:45,830
apply to be part of so for example the

00:05:43,940 --> 00:05:48,440
data science for social good it's like a

00:05:45,830 --> 00:05:50,660
summer program ten weeks where folks

00:05:48,440 --> 00:05:52,430
that are either within the academic

00:05:50,660 --> 00:05:54,770
setting of UW and other kind of

00:05:52,430 --> 00:05:57,560
government organizations locally can

00:05:54,770 --> 00:05:59,450
apply and essentially they turn in like

00:05:57,560 --> 00:06:02,150
a proposal for a project with their data

00:05:59,450 --> 00:06:03,950
that they need that they might need data

00:06:02,150 --> 00:06:05,480
science support for these folks might

00:06:03,950 --> 00:06:07,370
not have the resources for example to

00:06:05,480 --> 00:06:09,260
hire data scientist for the full time

00:06:07,370 --> 00:06:11,090
and so they get paired up if they get

00:06:09,260 --> 00:06:12,950
selected with a data scientist that's in

00:06:11,090 --> 00:06:14,990
on staff and they're also actually

00:06:12,950 --> 00:06:17,150
there's students that apply from all

00:06:14,990 --> 00:06:18,200
over the US to be part of these projects

00:06:17,150 --> 00:06:20,630
so they get paired up with a data

00:06:18,200 --> 00:06:22,160
scientist plus some student support in

00:06:20,630 --> 00:06:23,750
the form of four or five students per

00:06:22,160 --> 00:06:26,390
project and this is in the summer

00:06:23,750 --> 00:06:28,520
there's also winter incubator program in

00:06:26,390 --> 00:06:29,990
the winter where traditionally it's been

00:06:28,520 --> 00:06:31,610
more academic folks it's more

00:06:29,990 --> 00:06:34,160
personalized so people come in with

00:06:31,610 --> 00:06:36,160
projects and they get paired up with a

00:06:34,160 --> 00:06:38,110
data scientist and they work kinda

00:06:36,160 --> 00:06:41,260
one-on-one and a specific kind of data

00:06:38,110 --> 00:06:43,390
topic or project and this is for the the

00:06:41,260 --> 00:06:44,770
duration of the winter quarter and so

00:06:43,390 --> 00:06:46,840
they get kind of this one-on-one

00:06:44,770 --> 00:06:48,970
training or help on something that they

00:06:46,840 --> 00:06:51,670
want to kind of develop and from these

00:06:48,970 --> 00:06:54,520
things either spin off into bigger

00:06:51,670 --> 00:06:56,140
projects we all saw for office hours for

00:06:54,520 --> 00:06:58,000
example people would come to our office

00:06:56,140 --> 00:07:00,340
hours and just kind of ask us whatever

00:06:58,000 --> 00:07:01,840
they want I had a student once come in I

00:07:00,340 --> 00:07:03,490
think they were participating in one of

00:07:01,840 --> 00:07:05,380
these boot camps and they needed help on

00:07:03,490 --> 00:07:07,330
one a project assignment that they were

00:07:05,380 --> 00:07:09,690
doing and so you know help them out and

00:07:07,330 --> 00:07:12,850
it's okay

00:07:09,690 --> 00:07:14,590
and so from this I got mentioned one of

00:07:12,850 --> 00:07:16,090
the projects for example that came out

00:07:14,590 --> 00:07:17,560
of the data science for social good

00:07:16,090 --> 00:07:19,900
program about three years ago was a

00:07:17,560 --> 00:07:21,790
project specifically working with the

00:07:19,900 --> 00:07:26,770
homelessness management intervention

00:07:21,790 --> 00:07:29,020
system in King County and from that I

00:07:26,770 --> 00:07:30,880
was later expanded into a bigger project

00:07:29,020 --> 00:07:33,280
to incorporate the other housing

00:07:30,880 --> 00:07:36,460
authorities with the help of funding

00:07:33,280 --> 00:07:39,040
from the the bill and Gates Foundation

00:07:36,460 --> 00:07:41,620
and so they essentially you know there

00:07:39,040 --> 00:07:43,870
were they did a grant proposal where we

00:07:41,620 --> 00:07:45,790
were able to get funding to actually

00:07:43,870 --> 00:07:47,860
investigate not just the homelessness

00:07:45,790 --> 00:07:50,380
intervention system but also the housing

00:07:47,860 --> 00:07:52,480
authorities and the primarily primary

00:07:50,380 --> 00:07:54,970
question here was kind of understanding

00:07:52,480 --> 00:07:57,850
housing instability in King County in

00:07:54,970 --> 00:08:00,520
the sense of kind of the population

00:07:57,850 --> 00:08:02,500
we're exploring was homeless individuals

00:08:00,520 --> 00:08:04,960
or people that are at risk of becoming

00:08:02,500 --> 00:08:06,490
homeless and so they really wanted to

00:08:04,960 --> 00:08:07,960
understand their interaction with the

00:08:06,490 --> 00:08:11,530
human services through these several

00:08:07,960 --> 00:08:13,120
agencies these agencies cannot for

00:08:11,530 --> 00:08:15,220
example share data with each other they

00:08:13,120 --> 00:08:17,169
can link these data and so they came to

00:08:15,220 --> 00:08:19,690
us in a sense say okay well there's

00:08:17,169 --> 00:08:20,950
these three data sources we want to

00:08:19,690 --> 00:08:23,490
understand how people are kind of

00:08:20,950 --> 00:08:26,590
navigating or transitioning to and from

00:08:23,490 --> 00:08:29,320
either homelessness to better housing

00:08:26,590 --> 00:08:31,090
situations or from very dire housing

00:08:29,320 --> 00:08:33,250
situations to homelessness and so this

00:08:31,090 --> 00:08:35,110
kind of project was that's kind of the

00:08:33,250 --> 00:08:36,640
essence of this project to figure that

00:08:35,110 --> 00:08:38,079
out

00:08:36,640 --> 00:08:40,000
in some of the questions these

00:08:38,079 --> 00:08:41,589
stakeholders have for example they're

00:08:40,000 --> 00:08:43,269
like are there significant differences

00:08:41,589 --> 00:08:44,920
in those household is successfully

00:08:43,269 --> 00:08:47,769
successfully transitioning from like

00:08:44,920 --> 00:08:51,490
HMIS to sha or kha so from homelessness

00:08:47,769 --> 00:08:53,560
to the housing authorities what what is

00:08:51,490 --> 00:08:55,420
a successful transition looked like for

00:08:53,560 --> 00:08:57,339
example so we spend a lot of time trying

00:08:55,420 --> 00:09:00,190
to answer these questions with the folks

00:08:57,339 --> 00:09:02,050
on the ground and then more kind of

00:09:00,190 --> 00:09:03,970
deeper is can we model successful

00:09:02,050 --> 00:09:06,610
transitions from like HMIS to like a

00:09:03,970 --> 00:09:08,589
housing like a subsidized housing for

00:09:06,610 --> 00:09:13,209
example these are the kind of questions

00:09:08,589 --> 00:09:15,610
that we they give us and in a sense we

00:09:13,209 --> 00:09:17,320
reiterate through these kind of the the

00:09:15,610 --> 00:09:18,579
data that we have and then try to answer

00:09:17,320 --> 00:09:20,079
the questions that they have on the

00:09:18,579 --> 00:09:22,240
ground so these aren't intended to be

00:09:20,079 --> 00:09:23,410
like public reports that they want to

00:09:22,240 --> 00:09:24,880
actually put out they just want to

00:09:23,410 --> 00:09:26,980
really understand like what's happening

00:09:24,880 --> 00:09:28,690
with our population and who's accessing

00:09:26,980 --> 00:09:33,700
our services how can we get better at

00:09:28,690 --> 00:09:36,010
that from the get-go like I mentioned

00:09:33,700 --> 00:09:37,029
this is messy administrative data three

00:09:36,010 --> 00:09:39,940
data sources

00:09:37,029 --> 00:09:42,279
there's no comment key to link across

00:09:39,940 --> 00:09:44,110
these so then the one I know these

00:09:42,279 --> 00:09:46,660
trajectories and so it was kind of their

00:09:44,110 --> 00:09:47,880
like how how are we gonna do that how

00:09:46,660 --> 00:09:51,640
are you guys gonna do that and so we

00:09:47,880 --> 00:09:53,589
implemented kind of a data linking

00:09:51,640 --> 00:09:55,510
method for example that's prominent in

00:09:53,589 --> 00:09:57,760
medicine when they link medical records

00:09:55,510 --> 00:09:59,980
we do have a lot of PII so personal

00:09:57,760 --> 00:10:02,529
identifiable information that we can

00:09:59,980 --> 00:10:04,570
leverage to kind of find individuals

00:10:02,529 --> 00:10:07,750
across these different data sets and so

00:10:04,570 --> 00:10:11,079
that's the majority of the the bulk of

00:10:07,750 --> 00:10:12,910
the of the work of this grant was really

00:10:11,079 --> 00:10:14,709
figuring out going through different

00:10:12,910 --> 00:10:16,750
algorithms and implementing them and

00:10:14,709 --> 00:10:18,790
seeing which one was kind of the better

00:10:16,750 --> 00:10:20,350
one to use for our case and I guess ID

00:10:18,790 --> 00:10:22,390
is still ongoing right now we're using

00:10:20,350 --> 00:10:24,760
like a fuzzy kind of matching type of

00:10:22,390 --> 00:10:27,000
string matching implementation but we're

00:10:24,760 --> 00:10:29,980
moving towards more probabilistic method

00:10:27,000 --> 00:10:32,649
to kind of determine matches between

00:10:29,980 --> 00:10:35,050
individuals so we're iterating at this

00:10:32,649 --> 00:10:36,880
piece as we go as well and as you'll see

00:10:35,050 --> 00:10:39,310
later there's a lot of pieces that are

00:10:36,880 --> 00:10:42,820
in constant iteration in terms of making

00:10:39,310 --> 00:10:45,040
sure that we're doing things right at

00:10:42,820 --> 00:10:46,660
the foundation of course of everything

00:10:45,040 --> 00:10:48,010
that we do at east science in our

00:10:46,660 --> 00:10:49,290
collaboration is really developing

00:10:48,010 --> 00:10:51,570
software

00:10:49,290 --> 00:10:54,089
open reproducible and that folks can use

00:10:51,570 --> 00:10:55,259
on the ground we knew that we had this

00:10:54,089 --> 00:10:57,180
partnership with these housing

00:10:55,259 --> 00:10:58,860
authorities and we wanted to make sure

00:10:57,180 --> 00:11:01,470
that whatever we use to for example

00:10:58,860 --> 00:11:03,029
processing clean the data that would be

00:11:01,470 --> 00:11:05,910
able to they would be able to be adopted

00:11:03,029 --> 00:11:08,449
by them after the for example the grant

00:11:05,910 --> 00:11:11,730
dense our grant has like a end date that

00:11:08,449 --> 00:11:13,199
we hope that through what we build they

00:11:11,730 --> 00:11:15,180
can actually implement and use it

00:11:13,199 --> 00:11:19,380
in-house for their own purposes so we

00:11:15,180 --> 00:11:20,579
we're really trying hard to do that and

00:11:19,380 --> 00:11:22,649
I'm going to go over kind of some of the

00:11:20,579 --> 00:11:24,660
pieces of software that we've developed

00:11:22,649 --> 00:11:26,100
that are open-source and some that are

00:11:24,660 --> 00:11:29,310
not and I'll mention why they're not

00:11:26,100 --> 00:11:31,319
open so for example Puget was based on

00:11:29,310 --> 00:11:33,569
code that was developed during this data

00:11:31,319 --> 00:11:35,430
science for social good collaboration

00:11:33,569 --> 00:11:38,550
but it was reengineering

00:11:35,430 --> 00:11:41,160
to fit our specific needs so in the dss

00:11:38,550 --> 00:11:42,839
g program they they had this

00:11:41,160 --> 00:11:44,430
homelessness intervention management

00:11:42,839 --> 00:11:46,620
system data they did a lot of work to

00:11:44,430 --> 00:11:49,410
process this data and clean it up and

00:11:46,620 --> 00:11:51,269
make it kind of easy to use for analysis

00:11:49,410 --> 00:11:53,040
so then we were able to kind of just

00:11:51,269 --> 00:11:55,019
leverage that you know that work that

00:11:53,040 --> 00:11:57,120
was already done and build on top of it

00:11:55,019 --> 00:11:59,399
in terms of making it more general for

00:11:57,120 --> 00:12:01,050
what we need it to use they also added a

00:11:59,399 --> 00:12:03,269
lot of test coverage so there's a lot of

00:12:01,050 --> 00:12:05,279
kind of unit tests built into this

00:12:03,269 --> 00:12:07,500
software and then because of the grants

00:12:05,279 --> 00:12:09,000
were able to focus and develop more kind

00:12:07,500 --> 00:12:11,699
of handling PII matching information

00:12:09,000 --> 00:12:13,050
record linkage and then we improved kind

00:12:11,699 --> 00:12:16,079
of our clustering method that were using

00:12:13,050 --> 00:12:18,660
for this one thing that was very easy to

00:12:16,079 --> 00:12:21,660
in terms of adopting and using the the

00:12:18,660 --> 00:12:23,430
two people that created this code are on

00:12:21,660 --> 00:12:24,870
our team right now as well so it was

00:12:23,430 --> 00:12:26,519
easy to say okay well we're gonna use

00:12:24,870 --> 00:12:29,430
this we're gonna iterate and build on

00:12:26,519 --> 00:12:32,010
top of it so that was I guess easy and

00:12:29,430 --> 00:12:33,829
Eric Coates but it was it really

00:12:32,010 --> 00:12:36,329
obviously made it easy to kind of

00:12:33,829 --> 00:12:38,130
iterate and shift to like making it more

00:12:36,329 --> 00:12:41,839
general to encompass a different data

00:12:38,130 --> 00:12:44,610
that we have this other one was housing

00:12:41,839 --> 00:12:47,069
package that is in our so Fugit is

00:12:44,610 --> 00:12:49,380
actually built in Python housing is an R

00:12:47,069 --> 00:12:51,810
and this code initially was developed

00:12:49,380 --> 00:12:54,509
from another collaboration at u-dub with

00:12:51,810 --> 00:12:56,220
social science with Seattle housing and

00:12:54,509 --> 00:12:58,620
the King County housing authorities and

00:12:56,220 --> 00:13:00,930
this code what it did essentially it

00:12:58,620 --> 00:13:02,610
cleaned up the administrative data from

00:13:00,930 --> 00:13:05,160
these two agencies and I've created

00:13:02,610 --> 00:13:09,540
like a match the essentially database of

00:13:05,160 --> 00:13:11,610
these two agencies that was maybe five

00:13:09,540 --> 00:13:14,310
years ago but then it was adopted by the

00:13:11,610 --> 00:13:16,230
King County Public Health is initially

00:13:14,310 --> 00:13:18,990
it was actually just one analyst who did

00:13:16,230 --> 00:13:20,550
further further development to really to

00:13:18,990 --> 00:13:22,620
match it against like public health data

00:13:20,550 --> 00:13:26,010
so they expanded it to kind of fit the

00:13:22,620 --> 00:13:27,930
needs that they had at the agency and we

00:13:26,010 --> 00:13:29,940
had a decision to make at you know for

00:13:27,930 --> 00:13:31,740
this project in the sense we were

00:13:29,940 --> 00:13:37,110
building our data pipeline all in Python

00:13:31,740 --> 00:13:39,060
and we we knew that technically speaking

00:13:37,110 --> 00:13:40,680
we could have essentially build

00:13:39,060 --> 00:13:42,720
everything in Python in in order to

00:13:40,680 --> 00:13:45,540
clean the data that we had from these

00:13:42,720 --> 00:13:47,490
agencies but really wanted to kind of

00:13:45,540 --> 00:13:49,920
practice what we preach right they had

00:13:47,490 --> 00:13:52,529
already kind of ran with this and

00:13:49,920 --> 00:13:55,769
developed it to fit their specific needs

00:13:52,529 --> 00:13:58,829
and so we decided to actually use what

00:13:55,769 --> 00:14:01,560
they had already done kind of developed

00:13:58,829 --> 00:14:04,440
this workflow pipeline of doing Forks

00:14:01,560 --> 00:14:07,410
and remotes and doing poor requests on

00:14:04,440 --> 00:14:09,269
their repository that they had and kind

00:14:07,410 --> 00:14:10,920
of work with them to make it more

00:14:09,269 --> 00:14:12,540
general so that we can actually use it

00:14:10,920 --> 00:14:14,130
as well so they they were developing

00:14:12,540 --> 00:14:16,800
this too for a very specific purpose

00:14:14,130 --> 00:14:19,470
that they have at King County Public

00:14:16,800 --> 00:14:21,120
Health and so we continue to work with

00:14:19,470 --> 00:14:23,490
them and I'm the point person on this

00:14:21,120 --> 00:14:24,959
one in terms of making sure that it's

00:14:23,490 --> 00:14:27,180
general so that we can use it but

00:14:24,959 --> 00:14:29,490
whatever we add doesn't break what they

00:14:27,180 --> 00:14:32,310
need for example to do more internally

00:14:29,490 --> 00:14:34,829
and so this is this has been a pretty

00:14:32,310 --> 00:14:36,839
awesome experience it's it's very hard

00:14:34,829 --> 00:14:38,370
and complicated but it's actually we

00:14:36,839 --> 00:14:41,940
know that the rewards gonna be great

00:14:38,370 --> 00:14:44,070
afterwards right so part of the kind of

00:14:41,940 --> 00:14:45,779
the challenge when you develop of open

00:14:44,070 --> 00:14:47,339
source 2 is there are people really

00:14:45,779 --> 00:14:48,990
adopting them are they using them on the

00:14:47,339 --> 00:14:50,640
ground this was a case where they had

00:14:48,990 --> 00:14:52,140
adopted something and they were using it

00:14:50,640 --> 00:14:54,990
and we just had to kind of work

00:14:52,140 --> 00:14:57,990
backwards and essentially I'm involved a

00:14:54,990 --> 00:15:00,269
really crazy rebase that I had to do and

00:14:57,990 --> 00:15:01,560
that was kind of when I came into the

00:15:00,269 --> 00:15:04,829
team and they're like oh you know our

00:15:01,560 --> 00:15:07,079
and you know some Python well she should

00:15:04,829 --> 00:15:08,699
rebase this to kind of what what they

00:15:07,079 --> 00:15:10,230
have because we were behind for like two

00:15:08,699 --> 00:15:11,610
years on what they had developed and

00:15:10,230 --> 00:15:13,589
that was a great learning experience and

00:15:11,610 --> 00:15:16,880
I could say I did a whole rebase and I

00:15:13,589 --> 00:15:16,880
lived to tell the story

00:15:17,680 --> 00:15:25,910
and then lastly there is this IDO us

00:15:22,570 --> 00:15:28,730
utility so we we interface our art our

00:15:25,910 --> 00:15:31,070
work essentially is all in the cloud we

00:15:28,730 --> 00:15:34,040
use for example as three buckets to

00:15:31,070 --> 00:15:36,350
start data and we need we needed to kind

00:15:34,040 --> 00:15:38,210
of help us get our raw data kind of

00:15:36,350 --> 00:15:40,690
process said do all the procedures that

00:15:38,210 --> 00:15:43,370
are in Puget and in housing and

00:15:40,690 --> 00:15:45,410
essentially spit out this data table

00:15:43,370 --> 00:15:47,300
that is used for analysis so this data

00:15:45,410 --> 00:15:50,180
table has a linked record for example

00:15:47,300 --> 00:15:51,830
and we use that in order to answer some

00:15:50,180 --> 00:15:54,500
of the questions that the agencies have

00:15:51,830 --> 00:15:56,240
for us and so it's like I said the

00:15:54,500 --> 00:15:58,820
family functions that just processes the

00:15:56,240 --> 00:16:00,860
data from raw to link link longitudinal

00:15:58,820 --> 00:16:03,230
file essentially it does depend both on

00:16:00,860 --> 00:16:05,780
Puget and housing and these are the data

00:16:03,230 --> 00:16:07,550
cleaning workhorses of this pipeline and

00:16:05,780 --> 00:16:10,400
then this really means that we do have

00:16:07,550 --> 00:16:11,900
to communicate and really collaborate

00:16:10,400 --> 00:16:13,400
with the folks in public health that may

00:16:11,900 --> 00:16:15,110
maintain for example the housing

00:16:13,400 --> 00:16:18,560
repository that's in our so we always

00:16:15,110 --> 00:16:20,870
have to a lot of it now talked a lot of

00:16:18,560 --> 00:16:22,910
about this and near the end it not only

00:16:20,870 --> 00:16:25,370
involved a collaboration but it involved

00:16:22,910 --> 00:16:27,170
a lot of like training and education in

00:16:25,370 --> 00:16:28,460
terms of going to their office and like

00:16:27,170 --> 00:16:31,550
sitting down with them and saying hey

00:16:28,460 --> 00:16:33,290
this is how the like a fork remote kind

00:16:31,550 --> 00:16:36,830
of workflow works and how to do pull

00:16:33,290 --> 00:16:38,450
requests how to do kind of issues for

00:16:36,830 --> 00:16:40,040
example and so this is also a work in

00:16:38,450 --> 00:16:41,960
progress and it's it's part of our

00:16:40,040 --> 00:16:44,480
collaboration so it's not just us

00:16:41,960 --> 00:16:46,430
providing data support and information

00:16:44,480 --> 00:16:49,130
it's also providing training and

00:16:46,430 --> 00:16:50,750
education in terms of how to kind of

00:16:49,130 --> 00:16:53,570
collaborate with open source tools and

00:16:50,750 --> 00:16:57,380
technology and I'll kind of show you a

00:16:53,570 --> 00:16:59,510
visual of how it kind of works so like I

00:16:57,380 --> 00:17:02,089
mentioned there's a housing repository

00:16:59,510 --> 00:17:05,089
are there's a puget in Python these are

00:17:02,089 --> 00:17:07,130
both open source repositories so anyone

00:17:05,089 --> 00:17:10,069
can look them up and contribute if they

00:17:07,130 --> 00:17:11,480
like there's some useful of cleaning

00:17:10,069 --> 00:17:13,069
function functions for example in

00:17:11,480 --> 00:17:14,990
housing we're trying to actually build

00:17:13,069 --> 00:17:16,939
in testing now into the the housing

00:17:14,990 --> 00:17:20,360
repository so that's kind of work in

00:17:16,939 --> 00:17:22,480
progress but we also have this our AWS

00:17:20,360 --> 00:17:24,439
tools it is in a private repository

00:17:22,480 --> 00:17:27,829
mostly because we're working with PI

00:17:24,439 --> 00:17:29,100
data and we wanted to keep everything

00:17:27,829 --> 00:17:31,440
kind of secure and private

00:17:29,100 --> 00:17:34,950
so we have a private posit Ori for that

00:17:31,440 --> 00:17:36,929
and this so essentially gets the the

00:17:34,950 --> 00:17:39,360
scripts that we need from huge data and

00:17:36,929 --> 00:17:44,760
housing and produces this final like

00:17:39,360 --> 00:17:46,620
data table that we use and so at the end

00:17:44,760 --> 00:17:48,660
it produces this analysis data table

00:17:46,620 --> 00:17:51,000
this is reproducible version control we

00:17:48,660 --> 00:17:53,789
can essentially go from raw to like data

00:17:51,000 --> 00:17:56,490
table that we were used for analysis so

00:17:53,789 --> 00:17:58,950
on the ground it looks kind of like you

00:17:56,490 --> 00:18:01,140
know we we have this data that we got

00:17:58,950 --> 00:18:03,990
from our pipeline and then initially

00:18:01,140 --> 00:18:05,340
we're using Jupiter and you know maybe

00:18:03,990 --> 00:18:07,530
there are some are scripts and Python

00:18:05,340 --> 00:18:10,799
scripts I created for example tables and

00:18:07,530 --> 00:18:12,990
visuals that were then kind of put into

00:18:10,799 --> 00:18:14,640
a document that was shareable with our

00:18:12,990 --> 00:18:17,370
stakeholders so in this case it was like

00:18:14,640 --> 00:18:20,520
either slides or like a Google Doc for

00:18:17,370 --> 00:18:22,039
example and you know that was our

00:18:20,520 --> 00:18:25,110
stakeholders we get that information

00:18:22,039 --> 00:18:26,520
luckily we maintain a very good

00:18:25,110 --> 00:18:29,039
relationship with them so we actually

00:18:26,520 --> 00:18:31,830
meet with them every twice a month for

00:18:29,039 --> 00:18:32,880
example and we talk about kind of what

00:18:31,830 --> 00:18:34,830
they see in the report

00:18:32,880 --> 00:18:37,440
what other things they want to want us

00:18:34,830 --> 00:18:39,960
to kind of look at or inquire if they

00:18:37,440 --> 00:18:42,090
see some weird data like number errors

00:18:39,960 --> 00:18:44,760
and they let us know and so that's

00:18:42,090 --> 00:18:48,840
that's good now but we knew that it was

00:18:44,760 --> 00:18:50,280
not it was it was working but we needed

00:18:48,840 --> 00:18:52,350
something that was a little better and

00:18:50,280 --> 00:18:54,780
so that's when we started leveraging

00:18:52,350 --> 00:18:56,780
like our markdown we wanted to have a

00:18:54,780 --> 00:18:59,159
way to be able to version control and

00:18:56,780 --> 00:19:01,860
reproduce these like reports that they

00:18:59,159 --> 00:19:04,890
were seen on their end and so our

00:19:01,860 --> 00:19:07,850
markdown is work seamlessly with our

00:19:04,890 --> 00:19:10,950
it's essentially a markdown kind of a

00:19:07,850 --> 00:19:13,890
form to create markdowns using our and

00:19:10,950 --> 00:19:16,620
then so this way we we can actually not

00:19:13,890 --> 00:19:18,179
only version control our code chunks

00:19:16,620 --> 00:19:20,070
that create the tables or the visuals

00:19:18,179 --> 00:19:21,840
but we can actually also look at some of

00:19:20,070 --> 00:19:24,390
the text that goes into these reports so

00:19:21,840 --> 00:19:27,059
we can keep track of these in a you know

00:19:24,390 --> 00:19:29,220
more version controlled way we weren't

00:19:27,059 --> 00:19:31,919
we were happy with that but we're like

00:19:29,220 --> 00:19:34,049
okay that's that's great but what if we

00:19:31,919 --> 00:19:36,929
actually dumped these reports into their

00:19:34,049 --> 00:19:39,360
own repository also a prior repositories

00:19:36,929 --> 00:19:40,590
are not meant to be public reports

00:19:39,360 --> 00:19:43,500
and we wanted a way for our stakeholders

00:19:40,590 --> 00:19:45,630
to kind of interact with this kind of

00:19:43,500 --> 00:19:48,780
open source version controlled pipeline

00:19:45,630 --> 00:19:51,090
and and kind of leverage kind of the

00:19:48,780 --> 00:19:53,040
tools that were using so we created a

00:19:51,090 --> 00:19:55,080
repository for those reports we gave our

00:19:53,040 --> 00:19:58,740
stakeholders access to the to this

00:19:55,080 --> 00:20:01,050
repository and then we we kind of had

00:19:58,740 --> 00:20:03,720
some trainings and talks about how to

00:20:01,050 --> 00:20:06,210
kind of use the issue issue system in

00:20:03,720 --> 00:20:07,680
these repositories so now they have

00:20:06,210 --> 00:20:09,480
access to the report they read the

00:20:07,680 --> 00:20:11,520
report they see something that maybe

00:20:09,480 --> 00:20:13,500
they didn't really see during our

00:20:11,520 --> 00:20:15,630
meeting they might have read it after

00:20:13,500 --> 00:20:17,640
later and so now they actually create

00:20:15,630 --> 00:20:21,000
issues of things they see in our reports

00:20:17,640 --> 00:20:24,630
and they tag people that for example our

00:20:21,000 --> 00:20:26,130
team is six people and so we're all

00:20:24,630 --> 00:20:27,780
working on different questions that they

00:20:26,130 --> 00:20:30,120
ask these are different remotes for

00:20:27,780 --> 00:20:32,070
example in this repository and so

00:20:30,120 --> 00:20:33,360
they're able to tag the people that are

00:20:32,070 --> 00:20:34,980
working on the specific questions

00:20:33,360 --> 00:20:37,110
they're able to tag lines that they see

00:20:34,980 --> 00:20:38,220
kind of questions or they have maybe

00:20:37,110 --> 00:20:39,690
they see a table and they're like these

00:20:38,220 --> 00:20:41,130
numbers don't make sense so we can

00:20:39,690 --> 00:20:43,350
actually go back to our pipeline and

00:20:41,130 --> 00:20:45,440
kinda iterate over that we push a button

00:20:43,350 --> 00:20:47,880
and then it spits out the updated report

00:20:45,440 --> 00:20:50,190
maybe not just push a button I mean it's

00:20:47,880 --> 00:20:52,800
it's like you kind of push a button you

00:20:50,190 --> 00:20:56,550
have to push and you know pull ad

00:20:52,800 --> 00:20:58,350
commits push in the networks and so and

00:20:56,550 --> 00:21:00,810
there and it's like a work in progress I

00:20:58,350 --> 00:21:02,100
get said it's not it's not something our

00:21:00,810 --> 00:21:03,990
folks on the ground are used to

00:21:02,100 --> 00:21:06,660
interacting with like these interfaces

00:21:03,990 --> 00:21:07,950
so then we need to kind of bring it up

00:21:06,660 --> 00:21:09,870
to speed and it we do take

00:21:07,950 --> 00:21:11,340
responsibility for that we see it as our

00:21:09,870 --> 00:21:12,890
responsibility to make sure that they're

00:21:11,340 --> 00:21:16,770
able to kind of interact with these

00:21:12,890 --> 00:21:18,830
tools and so there's I guess

00:21:16,770 --> 00:21:21,240
double-sided are also final thoughts

00:21:18,830 --> 00:21:22,830
there's no final report that we hand out

00:21:21,240 --> 00:21:24,570
because of the nature of the data and

00:21:22,830 --> 00:21:26,910
the way that it's iterative and alive

00:21:24,570 --> 00:21:29,130
really dark so there's a lot of turnover

00:21:26,910 --> 00:21:30,900
in the agency so new people come in they

00:21:29,130 --> 00:21:32,430
have new questions and so we're we're

00:21:30,900 --> 00:21:34,950
happy to kind of incorporate new

00:21:32,430 --> 00:21:36,240
questions communication is key and we

00:21:34,950 --> 00:21:38,820
take it very seriously

00:21:36,240 --> 00:21:40,860
it's our stakeholders provide the

00:21:38,820 --> 00:21:42,990
content expertise and the context of the

00:21:40,860 --> 00:21:45,060
data that we have a lot of technical

00:21:42,990 --> 00:21:47,010
skills but we might not have the context

00:21:45,060 --> 00:21:48,600
or the content expertise to really know

00:21:47,010 --> 00:21:50,970
what the data is about and we take that

00:21:48,600 --> 00:21:52,050
really seriously education training is a

00:21:50,970 --> 00:21:53,940
component of our

00:21:52,050 --> 00:21:56,430
raishin it just has to be and we're

00:21:53,940 --> 00:21:58,770
happy with that so for example last year

00:21:56,430 --> 00:22:01,410
in April in the beginning we convened

00:21:58,770 --> 00:22:04,500
the group of analysts that are we're

00:22:01,410 --> 00:22:06,300
supposed to work with these data and we

00:22:04,500 --> 00:22:09,420
created we adopted software carpentry

00:22:06,300 --> 00:22:10,980
lessons and kind of made them into data

00:22:09,420 --> 00:22:13,110
science for administrative data for

00:22:10,980 --> 00:22:14,790
example so we we kind of tweaked them to

00:22:13,110 --> 00:22:16,650
address some of the issues that we had

00:22:14,790 --> 00:22:19,560
seen in the data and so that was like

00:22:16,650 --> 00:22:21,000
round one and the carpentry lessons were

00:22:19,560 --> 00:22:23,430
great cuz their introductory now we're

00:22:21,000 --> 00:22:26,130
moving into doing more kind of advanced

00:22:23,430 --> 00:22:28,680
more focused kind of lessons also kind

00:22:26,130 --> 00:22:30,660
of barring those the type of like car

00:22:28,680 --> 00:22:32,970
software carpentry lessons we'll invite

00:22:30,660 --> 00:22:35,130
our collaborators and we really focus on

00:22:32,970 --> 00:22:36,330
the training and the tools for that they

00:22:35,130 --> 00:22:38,790
can so that they can actually contribute

00:22:36,330 --> 00:22:41,040
and use this when our prayer our grant

00:22:38,790 --> 00:22:43,380
is over essentially like I said our

00:22:41,040 --> 00:22:45,420
approach they work in progress and of

00:22:43,380 --> 00:22:48,360
course the a great team that I worked

00:22:45,420 --> 00:22:49,800
with Brenda hazel tends research

00:22:48,360 --> 00:22:52,320
scientists at the e Science Institute

00:22:49,800 --> 00:22:54,630
her backgrounds in physics area real

00:22:52,320 --> 00:22:56,670
chem is data scientists and his

00:22:54,630 --> 00:22:58,080
background is in neuroscience and then

00:22:56,670 --> 00:22:59,850
we have Tim Tim Thomas was a

00:22:58,080 --> 00:23:02,130
postdoctoral fellow at the East Science

00:22:59,850 --> 00:23:04,500
Institute and sociology and we have

00:23:02,130 --> 00:23:06,180
Breann from Rio Mahaska a PhD student

00:23:04,500 --> 00:23:08,910
from sociology and we have Luke

00:23:06,180 --> 00:23:10,140
Rodriguez from the high school the

00:23:08,910 --> 00:23:13,050
information school he's a piece there

00:23:10,140 --> 00:23:14,640
isn't there and so yeah it's like pretty

00:23:13,050 --> 00:23:17,190
pretty amazing team actually really

00:23:14,640 --> 00:23:19,130
really learned a lot from everyone like

00:23:17,190 --> 00:23:22,730
every time we meet and we meet weekly

00:23:19,130 --> 00:23:26,490
every every week so once once a week so

00:23:22,730 --> 00:23:27,380
this is my information thank you you

00:23:26,490 --> 00:23:31,319
have any questions

00:23:27,380 --> 00:23:31,319

YouTube URL: https://www.youtube.com/watch?v=0_QcovcYmbI


