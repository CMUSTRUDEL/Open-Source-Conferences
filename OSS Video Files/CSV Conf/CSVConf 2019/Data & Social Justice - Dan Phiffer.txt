Title: Data & Social Justice - Dan Phiffer
Publication date: 2019-05-19
Playlist: CSVConf 2019
Description: 
	This talk will provide an overview of the course I'm currently teaching at Bennington College called Data & Social Justice. I'll outline some of the issues my students have been organizing around, as well as techniques they've developed for doing outreach, using data visualization to support their causes, and describing how I've supported their efforts through my own faculty activism.

Slides: https://doi.org/10.5281/zenodo.2673409#.XNRXPFY3Ub4
Talk page: https://csvconf.com/speakers/#dan-phiffer
Captions: 
	00:00:00,580 --> 00:00:05,430
before I begin I want to acknowledge

00:00:02,469 --> 00:00:08,879
that we're on unceded territory

00:00:05,430 --> 00:00:11,260
according to the website native land CA

00:00:08,879 --> 00:00:13,869
we are at the intersection of

00:00:11,260 --> 00:00:15,369
Clackamas Cowlitz and Chinook tribal

00:00:13,869 --> 00:00:19,330
nations and others I learned this

00:00:15,369 --> 00:00:21,420
morning and I wanted to call out there's

00:00:19,330 --> 00:00:24,220
a documentary film that you can watch

00:00:21,420 --> 00:00:27,460
about mission operations fight for

00:00:24,220 --> 00:00:29,920
pretty right this isn't a past problem

00:00:27,460 --> 00:00:31,710
it's an ongoing thing so I encourage you

00:00:29,920 --> 00:00:35,560
to check it out it's a promised land

00:00:31,710 --> 00:00:40,180
calm and it's also being screened in

00:00:35,560 --> 00:00:42,430
November at the University of Oregon so

00:00:40,180 --> 00:00:44,260
I should mention I'm a software

00:00:42,430 --> 00:00:46,210
developer at the American Civil

00:00:44,260 --> 00:00:49,899
Liberties Union but this talk is not

00:00:46,210 --> 00:00:52,210
about my work there my name is Dan

00:00:49,899 --> 00:00:54,579
Pfeiffer and I'd like to use my time

00:00:52,210 --> 00:00:56,260
here to tell you about of course I

00:00:54,579 --> 00:01:01,510
taught this past fall called data and

00:00:56,260 --> 00:01:03,489
social justice it was my first time

00:01:01,510 --> 00:01:05,319
teaching this course and I proposed it

00:01:03,489 --> 00:01:08,319
because it was a class that I wanted to

00:01:05,319 --> 00:01:10,479
take this was in the digital arts

00:01:08,319 --> 00:01:12,369
department at Bennington College which

00:01:10,479 --> 00:01:12,880
is a small liberal arts school and in

00:01:12,369 --> 00:01:18,340
Vermont

00:01:12,880 --> 00:01:20,079
I think of advocacy and organizing as a

00:01:18,340 --> 00:01:22,990
central infrastructure for the

00:01:20,079 --> 00:01:25,240
maintenance of a healthy democracy I'm

00:01:22,990 --> 00:01:28,779
preoccupied with the question what new

00:01:25,240 --> 00:01:31,810
tools and strategies should exist for

00:01:28,779 --> 00:01:34,869
social justice organizing so this talk

00:01:31,810 --> 00:01:40,090
is a brief overview of the course that I

00:01:34,869 --> 00:01:42,399
taught in four parts we have weekly

00:01:40,090 --> 00:01:46,630
readings and discussions and I'll

00:01:42,399 --> 00:01:48,630
mention some of the highlights we began

00:01:46,630 --> 00:01:53,380
by looking at the root of the word data

00:01:48,630 --> 00:01:54,700
which means given in its latin form i

00:01:53,380 --> 00:01:58,270
don't actually speak latin but that's

00:01:54,700 --> 00:02:01,090
what this essay was about in cases where

00:01:58,270 --> 00:02:05,069
data is collected without true consent a

00:02:01,090 --> 00:02:05,069
better word might actually be captain

00:02:06,500 --> 00:02:13,260
we're every red tar Robertsons keynote

00:02:09,990 --> 00:02:15,060
at the Leda forum and she talks about

00:02:13,260 --> 00:02:18,630
her experience as a former sex worker

00:02:15,060 --> 00:02:20,610
turned librarian and how it informs her

00:02:18,630 --> 00:02:24,540
views on the ethics of digital

00:02:20,610 --> 00:02:26,700
digitizing collections I recommend you

00:02:24,540 --> 00:02:31,190
you read the talk good actually all

00:02:26,700 --> 00:02:35,520
these all these readings I recommend me

00:02:31,190 --> 00:02:38,910
oh no ha ha I didn't mangling her name

00:02:35,520 --> 00:02:40,860
sorry maybe Todd a precursor to my class

00:02:38,910 --> 00:02:43,950
at Bennington and gave an excellent talk

00:02:40,860 --> 00:02:47,010
at i/o on the subjectivity of data

00:02:43,950 --> 00:02:49,380
collection you may have heard of her art

00:02:47,010 --> 00:02:50,970
project called missing data sets and if

00:02:49,380 --> 00:02:55,530
you haven't I recommend you check that

00:02:50,970 --> 00:02:57,750
out too we read the fifth chapter of

00:02:55,530 --> 00:03:01,260
Kathy O'Neill's weapons of mass

00:02:57,750 --> 00:03:03,360
destruction on how software systems can

00:03:01,260 --> 00:03:06,120
mistake living in poverty for criminal

00:03:03,360 --> 00:03:08,580
activity and she offers a technical

00:03:06,120 --> 00:03:11,940
analysis of policing techniques

00:03:08,580 --> 00:03:15,570
including pred poll and stop and frisk

00:03:11,940 --> 00:03:18,660
and the book itself in general is good

00:03:15,570 --> 00:03:20,400
and we also read the ProPublica

00:03:18,660 --> 00:03:22,020
investigation of risk assessment

00:03:20,400 --> 00:03:25,320
software that's used in criminal

00:03:22,020 --> 00:03:27,930
sentencing the article shows two

00:03:25,320 --> 00:03:30,810
different effects when comparing the

00:03:27,930 --> 00:03:36,420
software assigned risk scores which with

00:03:30,810 --> 00:03:38,459
actual recidivism rates so the two

00:03:36,420 --> 00:03:41,160
effects are that black defendants are

00:03:38,459 --> 00:03:44,280
disproportionately given high restores

00:03:41,160 --> 00:03:47,040
when they didn't reoffending conversely

00:03:44,280 --> 00:03:51,090
the white defendants were given low

00:03:47,040 --> 00:03:52,850
scores and they did reoffending is

00:03:51,090 --> 00:03:59,190
pretty stark it's in the order of like

00:03:52,850 --> 00:04:01,980
25% to 75% this was an optional reading

00:03:59,190 --> 00:04:04,620
on the distinction between activism and

00:04:01,980 --> 00:04:05,590
organizing and in retrospect it was

00:04:04,620 --> 00:04:08,739
pretty influential

00:04:05,590 --> 00:04:09,910
my approach to the class I wanted my

00:04:08,739 --> 00:04:12,819
students to focus on creating

00:04:09,910 --> 00:04:17,820
opportunities for others to help them

00:04:12,819 --> 00:04:19,930
with their social justice projects and

00:04:17,820 --> 00:04:21,700
there are a lot of other readings we

00:04:19,930 --> 00:04:24,520
didn't get to due to time constraints

00:04:21,700 --> 00:04:26,790
but the course is on github and there's

00:04:24,520 --> 00:04:29,110
a issue page where I've been like

00:04:26,790 --> 00:04:30,639
accumulating other readings and of

00:04:29,110 --> 00:04:35,230
course I'd be curious to hear about your

00:04:30,639 --> 00:04:38,110
suggestions are too so a central premise

00:04:35,230 --> 00:04:40,720
for the course is that organizing a

00:04:38,110 --> 00:04:45,610
cohort of collaborators multiplies the

00:04:40,720 --> 00:04:48,070
capacity of any individual activist we

00:04:45,610 --> 00:04:50,710
covered an assortment of issues and I

00:04:48,070 --> 00:04:51,880
encourage students to pick issues that

00:04:50,710 --> 00:04:54,520
they felt most passionate about

00:04:51,880 --> 00:04:55,840
themselves and in some cases these are

00:04:54,520 --> 00:05:03,490
things that they were already working on

00:04:55,840 --> 00:05:05,860
that they brought to the class so we

00:05:03,490 --> 00:05:10,900
also covered a wide variety of digital

00:05:05,860 --> 00:05:13,030
and analog tools for organizing this is

00:05:10,900 --> 00:05:15,669
these are both partial lists it was it

00:05:13,030 --> 00:05:17,440
was kind of like a sprawling class that

00:05:15,669 --> 00:05:21,970
probably should have been pared down a

00:05:17,440 --> 00:05:24,100
little bit so as a content learning in

00:05:21,970 --> 00:05:26,400
the next few slides I'll be discussing

00:05:24,100 --> 00:05:28,840
gun violence and mass shootings and

00:05:26,400 --> 00:05:34,600
later science will include mentions of

00:05:28,840 --> 00:05:35,979
sexual assault and transphobia Mother

00:05:34,600 --> 00:05:39,280
Jones magazine has been doing an

00:05:35,979 --> 00:05:43,960
excellent job covering gun violence in

00:05:39,280 --> 00:05:45,610
America as a topic they've assembled a

00:05:43,960 --> 00:05:48,160
comprehensive guide to mass shootings

00:05:45,610 --> 00:05:51,750
and have released the underlying data

00:05:48,160 --> 00:05:51,750
for others to use in their research

00:05:54,030 --> 00:05:59,590
mother Jones's editors maintain a public

00:05:57,039 --> 00:06:01,570
Google spreadsheet that contains details

00:05:59,590 --> 00:06:04,870
about all the known mass shootings since

00:06:01,570 --> 00:06:07,570
1982 and I should mention that since I

00:06:04,870 --> 00:06:08,950
have screen grabs this this list it's

00:06:07,570 --> 00:06:11,910
already out of date there's like a new

00:06:08,950 --> 00:06:11,910
mass shooting

00:06:14,400 --> 00:06:19,410
several students use this data set to

00:06:16,650 --> 00:06:21,360
create visualizations showing the

00:06:19,410 --> 00:06:24,120
epidemic of mass shootings in the US

00:06:21,360 --> 00:06:25,770
this is Matt's map which gives a sense

00:06:24,120 --> 00:06:30,600
for where they occurred in their

00:06:25,770 --> 00:06:32,430
severity Cassidy a student whose friend

00:06:30,600 --> 00:06:34,979
was wounded in a shooting at Thousand

00:06:32,430 --> 00:06:36,930
Oaks California organized an event on

00:06:34,979 --> 00:06:40,229
campus with a group called gun since

00:06:36,930 --> 00:06:42,500
Vermont and it is probably worth

00:06:40,229 --> 00:06:46,020
mentioning Vermont is a a very gun

00:06:42,500 --> 00:06:51,000
friendly state third their gun laws are

00:06:46,020 --> 00:06:53,070
very permissive of the digital tools we

00:06:51,000 --> 00:06:56,780
looked at typeform was among the most

00:06:53,070 --> 00:07:03,900
popular for collecting data in this case

00:06:56,780 --> 00:07:06,300
this is a video creating support for

00:07:03,900 --> 00:07:15,060
survival survivors of on campus sexual

00:07:06,300 --> 00:07:18,660
assault another student used net form in

00:07:15,060 --> 00:07:22,580
a more storytelling mode and used it to

00:07:18,660 --> 00:07:22,580
link out to other existing resources

00:07:43,819 --> 00:07:48,210
at times I use my role as a faculty

00:07:46,319 --> 00:07:53,250
member to advocate when my students

00:07:48,210 --> 00:07:55,259
behalf Toby a transgender student in the

00:07:53,250 --> 00:07:57,300
course told us about his traumatic

00:07:55,259 --> 00:08:01,830
experience of the student mailboxes at

00:07:57,300 --> 00:08:04,710
Pennington so student mailboxes have

00:08:01,830 --> 00:08:07,740
name labels on them and those names on

00:08:04,710 --> 00:08:10,979
the labels consistently dead named trans

00:08:07,740 --> 00:08:13,199
students every year he would walk over

00:08:10,979 --> 00:08:15,569
to the mailboxes and stick his own label

00:08:13,199 --> 00:08:19,190
on top of the incorrect name that the

00:08:15,569 --> 00:08:21,780
Bennington administrators had provided I

00:08:19,190 --> 00:08:24,569
noticed that my course roster data

00:08:21,780 --> 00:08:27,270
export included legal names but not

00:08:24,569 --> 00:08:29,550
preferred names I've omitted the

00:08:27,270 --> 00:08:34,979
sensitive details here including Toby's

00:08:29,550 --> 00:08:36,479
legal first name so first name is one of

00:08:34,979 --> 00:08:39,589
those database columns you might think

00:08:36,479 --> 00:08:43,260
as simple and straightforward but it

00:08:39,589 --> 00:08:45,089
required some context a legal first name

00:08:43,260 --> 00:08:47,640
is used by the college for financial aid

00:08:45,089 --> 00:08:50,700
purposes and other things that come into

00:08:47,640 --> 00:08:52,350
contact with federal government there's

00:08:50,700 --> 00:08:54,420
no good reason that my roster should

00:08:52,350 --> 00:08:58,610
include a legal first name for a trance

00:08:54,420 --> 00:09:01,290
- Danine is like you can call me Danny a

00:08:58,610 --> 00:09:04,170
preferred name is an important aspect of

00:09:01,290 --> 00:09:05,940
a trans student gender identity and

00:09:04,170 --> 00:09:08,490
getting it wrong is extremely

00:09:05,940 --> 00:09:12,390
disrespectful and the systems were

00:09:08,490 --> 00:09:14,070
consistently getting it wrong so I filed

00:09:12,390 --> 00:09:17,130
a bug report with the school's database

00:09:14,070 --> 00:09:22,050
software vendor an Idaho based company

00:09:17,130 --> 00:09:24,149
called Populi I made three requests of

00:09:22,050 --> 00:09:24,750
Populi and the Bennington Registrar's

00:09:24,149 --> 00:09:27,570
Office

00:09:24,750 --> 00:09:29,610
first student roster data exports should

00:09:27,570 --> 00:09:32,579
have a they had a critical omission and

00:09:29,610 --> 00:09:36,000
that should be easy to fix secondly this

00:09:32,579 --> 00:09:38,040
is a data privacy issue and then finally

00:09:36,000 --> 00:09:40,980
there are trans students at all campuses

00:09:38,040 --> 00:09:43,589
and a lot of colleges use the software

00:09:40,980 --> 00:09:46,500
so they should make the change across

00:09:43,589 --> 00:09:49,740
all the schools and publicly explain why

00:09:46,500 --> 00:09:51,120
they're making the change they agreed to

00:09:49,740 --> 00:09:53,250
my first request

00:09:51,120 --> 00:09:56,710
[Music]

00:09:53,250 --> 00:09:59,920
so now you know student data exports

00:09:56,710 --> 00:10:01,779
include the preferred name column the

00:09:59,920 --> 00:10:03,430
data model still confuses a preferred

00:10:01,779 --> 00:10:04,600
name with a nickname but at least now

00:10:03,430 --> 00:10:06,990
there's some possibility for

00:10:04,600 --> 00:10:08,980
administrators to get this right

00:10:06,990 --> 00:10:11,140
previously there was no way for them to

00:10:08,980 --> 00:10:16,300
know which of these names was going to

00:10:11,140 --> 00:10:18,339
be hurtful to a trained student dobby

00:10:16,300 --> 00:10:21,070
also use tech form to mobilize fellow

00:10:18,339 --> 00:10:23,290
students around the cause and wrote an

00:10:21,070 --> 00:10:25,410
online resource guide that explained

00:10:23,290 --> 00:10:28,029
things like you know how to get the

00:10:25,410 --> 00:10:32,020
medical providers to give you the

00:10:28,029 --> 00:10:34,720
hormones you need so throughout the prep

00:10:32,020 --> 00:10:38,380
of the semester i prototyped a new

00:10:34,720 --> 00:10:39,910
website for organizing groups I wanted

00:10:38,380 --> 00:10:42,730
to make an alternative to Facebook

00:10:39,910 --> 00:10:47,890
groups for specifically for political

00:10:42,730 --> 00:10:50,320
organizers so even if you as the group

00:10:47,890 --> 00:10:52,900
administrator fully internalized so each

00:10:50,320 --> 00:10:54,700
of these privacy settings mean if

00:10:52,900 --> 00:10:56,589
someone in your group members doesn't

00:10:54,700 --> 00:10:59,440
understand the model it could put them

00:10:56,589 --> 00:11:01,960
at risk or the group at risk and in a

00:10:59,440 --> 00:11:04,210
social justice context the stakes for

00:11:01,960 --> 00:11:06,100
not understanding the nuances of

00:11:04,210 --> 00:11:11,500
Facebook privacy settings can be quite

00:11:06,100 --> 00:11:14,110
significant so like Facebook this

00:11:11,500 --> 00:11:16,720
website organizer dot network lets you

00:11:14,110 --> 00:11:18,760
create new groups easily but it has a

00:11:16,720 --> 00:11:21,550
uniform privacy model so everyone kind

00:11:18,760 --> 00:11:26,200
of understands well what the settings

00:11:21,550 --> 00:11:27,640
are because they don't change and it was

00:11:26,200 --> 00:11:29,700
interesting to see how my students use

00:11:27,640 --> 00:11:33,130
the software

00:11:29,700 --> 00:11:35,920
lots of shitposting inside jokes some

00:11:33,130 --> 00:11:40,750
feature requests I think this is the

00:11:35,920 --> 00:11:42,100
first day that I released it but you

00:11:40,750 --> 00:11:45,339
know actual organizing work also

00:11:42,100 --> 00:11:47,020
happened there and I should I should

00:11:45,339 --> 00:11:48,040
mention that its role as a social space

00:11:47,020 --> 00:11:50,560
was in

00:11:48,040 --> 00:11:52,600
I have an ongoing interest in how

00:11:50,560 --> 00:11:54,220
software can assist discrete sets of

00:11:52,600 --> 00:11:58,990
people who gather in room light like

00:11:54,220 --> 00:12:01,560
this one so the mechanism for the site

00:11:58,990 --> 00:12:04,210
district basic you can send messages to

00:12:01,560 --> 00:12:07,120
the people who are in the group and they

00:12:04,210 --> 00:12:09,820
can send you messages membership for

00:12:07,120 --> 00:12:11,350
each group is invite only and you can

00:12:09,820 --> 00:12:21,300
host it on your own server it's it's

00:12:11,350 --> 00:12:23,290
open source software this is me typing I

00:12:21,300 --> 00:12:26,860
figured it was better than doing a live

00:12:23,290 --> 00:12:30,640
demo so that links that i just copied

00:12:26,860 --> 00:12:32,320
there that's if you have that link then

00:12:30,640 --> 00:12:34,930
you can join this group that's that's

00:12:32,320 --> 00:12:37,810
the idea these person has a unique link

00:12:34,930 --> 00:12:44,140
so you can like track how how the group

00:12:37,810 --> 00:12:46,060
grew from from which people Julien a

00:12:44,140 --> 00:12:47,980
student organizing to form a Student

00:12:46,060 --> 00:12:51,370
Union registered the domain name

00:12:47,980 --> 00:12:53,380
Bennington Dot education a slightly

00:12:51,370 --> 00:12:57,100
longer and less official variation on

00:12:53,380 --> 00:12:59,290
Bennington edu he set up an incidents of

00:12:57,100 --> 00:13:01,810
organizer network on it and rebranded it

00:12:59,290 --> 00:13:03,580
as connect Bennington and one thing that

00:13:01,810 --> 00:13:06,130
point out here which i think is an

00:13:03,580 --> 00:13:08,740
improvement of her over my copy is he

00:13:06,130 --> 00:13:12,040
points out that the data is unprotected

00:13:08,740 --> 00:13:14,770
I mean it's unencrypted I guess is the

00:13:12,040 --> 00:13:16,810
way to put it but that's that's a

00:13:14,770 --> 00:13:20,890
problem that I haven't yet tried to

00:13:16,810 --> 00:13:23,230
solve with the software so I created a

00:13:20,890 --> 00:13:26,200
group for this talk and this if you have

00:13:23,230 --> 00:13:28,570
this invite link you can you can connect

00:13:26,200 --> 00:13:30,550
to each other of course you know there's

00:13:28,570 --> 00:13:31,900
a slack team that you can draw in this

00:13:30,550 --> 00:13:34,540
there's a lot of ways that we can all

00:13:31,900 --> 00:13:37,090
connect to each other but this specific

00:13:34,540 --> 00:13:38,530
set of people are the people who saw

00:13:37,090 --> 00:13:43,690
this talk or maybe you're watching on

00:13:38,530 --> 00:13:47,100
the live stream so thank you and I think

00:13:43,690 --> 00:13:47,100

YouTube URL: https://www.youtube.com/watch?v=rF7AKsRvPyA


