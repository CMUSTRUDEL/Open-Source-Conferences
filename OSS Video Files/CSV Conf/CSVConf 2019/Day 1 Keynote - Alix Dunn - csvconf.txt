Title: Day 1 Keynote - Alix Dunn - csvconf
Publication date: 2019-05-19
Playlist: CSVConf 2019
Description: 
	Alix Dunn gives the afternoon keynote during day 1 of csv,conf,v4, "Ethics & Consistency"

csv,conf is a community conference for data makers everywhere.

Featuring stories about data sharing and data analysis from science, journalism, government, and open source.

https://csvconf.com/
Captions: 
	00:00:00,560 --> 00:00:05,689
so I have the privilege and distinction

00:00:03,840 --> 00:00:08,010
of speaking to you at the end of the day

00:00:05,689 --> 00:00:10,230
so the first thing I'd like to do if

00:00:08,010 --> 00:00:13,890
you're ok with it if we could stand if

00:00:10,230 --> 00:00:17,160
you're able and just take three really

00:00:13,890 --> 00:00:19,350
deep breaths to get your blood flowing

00:00:17,160 --> 00:00:28,279
to your brain stretch if you would like

00:00:19,350 --> 00:00:30,510
to we're in the home stretch cool and

00:00:28,279 --> 00:00:32,099
sit when you're ready you want to keep

00:00:30,510 --> 00:00:34,489
stretching that's fine I'll start

00:00:32,099 --> 00:00:34,489
talking

00:00:36,090 --> 00:00:41,590
so today I'm going to talk about the

00:00:39,400 --> 00:00:43,570
role of consistency and ethical

00:00:41,590 --> 00:00:45,460
technical production and I don't know if

00:00:43,570 --> 00:00:47,890
you've noticed but there's been a lot of

00:00:45,460 --> 00:00:50,920
discussion about the role of ethics in

00:00:47,890 --> 00:00:53,230
technology within industry whose sort of

00:00:50,920 --> 00:00:55,239
freaking out about the media coverage of

00:00:53,230 --> 00:00:57,670
how their tools are causing harm but

00:00:55,239 --> 00:01:00,310
also within civil society organizations

00:00:57,670 --> 00:01:01,960
who have missions and values but are

00:01:00,310 --> 00:01:04,660
struggling to translate those missions

00:01:01,960 --> 00:01:05,800
and values into the technical choices

00:01:04,660 --> 00:01:08,590
that they make it's not a

00:01:05,800 --> 00:01:10,840
straightforward exercise to go from we

00:01:08,590 --> 00:01:13,119
believe X about who we're serving and

00:01:10,840 --> 00:01:14,610
how we want to serve them to this is the

00:01:13,119 --> 00:01:17,470
decision we're gonna make about

00:01:14,610 --> 00:01:19,509
persistent cookies on a website that we

00:01:17,470 --> 00:01:22,050
have facing constituents so I'm going to

00:01:19,509 --> 00:01:24,430
talk a little bit about consistency as a

00:01:22,050 --> 00:01:27,610
particular aspect of thinking about

00:01:24,430 --> 00:01:29,259
ethics and technical production and just

00:01:27,610 --> 00:01:31,000
for some context so over the past five

00:01:29,259 --> 00:01:33,009
years I've been working with civil

00:01:31,000 --> 00:01:34,660
society organizations who are really

00:01:33,009 --> 00:01:36,700
doing their best they're essentially

00:01:34,660 --> 00:01:38,679
saying when we make technical choices

00:01:36,700 --> 00:01:40,390
when we use data when we engage with

00:01:38,679 --> 00:01:41,710
communities and collect data about them

00:01:40,390 --> 00:01:43,810
we want to do that in ways that are

00:01:41,710 --> 00:01:46,630
responsible that don't undermine our

00:01:43,810 --> 00:01:48,850
advocacy goals that are connecting with

00:01:46,630 --> 00:01:50,649
those communities and not producing

00:01:48,850 --> 00:01:53,350
things about them in gross ways that

00:01:50,649 --> 00:01:55,899
aren't respecting them but the

00:01:53,350 --> 00:01:57,940
challenges are real so watching

00:01:55,899 --> 00:02:00,429
organizations struggle to figure out

00:01:57,940 --> 00:02:02,200
when we build this tool when we bring in

00:02:00,429 --> 00:02:05,830
an outside firm to help us do something

00:02:02,200 --> 00:02:07,569
how do we constrain technology to do

00:02:05,830 --> 00:02:09,550
what we want it to do and not sort of

00:02:07,569 --> 00:02:12,430
move outside of what we're comfortable

00:02:09,550 --> 00:02:14,740
with and in the past year I've started

00:02:12,430 --> 00:02:16,530
doing more work with companies which has

00:02:14,740 --> 00:02:19,150
been a really surprising and interesting

00:02:16,530 --> 00:02:20,350
discovery process the one thing I've

00:02:19,150 --> 00:02:22,120
learned that I feel like if you take

00:02:20,350 --> 00:02:24,670
away one thing is that they're not

00:02:22,120 --> 00:02:26,170
monolithic so some companies you go in

00:02:24,670 --> 00:02:28,120
and you talk to people and you think I'm

00:02:26,170 --> 00:02:30,000
really upset that these people are

00:02:28,120 --> 00:02:32,170
building things that I'm supposed to use

00:02:30,000 --> 00:02:34,120
and other companies you go in and you

00:02:32,170 --> 00:02:35,190
see people who genuinely go to work

00:02:34,120 --> 00:02:37,350
every day try

00:02:35,190 --> 00:02:38,910
to make products that means something to

00:02:37,350 --> 00:02:41,360
people that are useful for people that

00:02:38,910 --> 00:02:45,030
are respecting of their time and energy

00:02:41,360 --> 00:02:46,440
and and rights so but it's been an

00:02:45,030 --> 00:02:47,610
interesting process and I think even

00:02:46,440 --> 00:02:49,560
within companies that have unlimited

00:02:47,610 --> 00:02:51,780
resources so you look at civil society

00:02:49,560 --> 00:02:54,150
got the best intentions best practices

00:02:51,780 --> 00:02:56,280
are difficult to define companies maybe

00:02:54,150 --> 00:02:58,200
not the best intentions tons and tons of

00:02:56,280 --> 00:03:01,080
resources and they still can't figure it

00:02:58,200 --> 00:03:05,510
out so what's this sort of what are the

00:03:01,080 --> 00:03:08,390
issues at play I'm going to talk about

00:03:05,510 --> 00:03:11,010
particularly the role of consistency and

00:03:08,390 --> 00:03:12,240
I want to start with inconsistency so we

00:03:11,010 --> 00:03:13,440
can sort of talk a little bit about what

00:03:12,240 --> 00:03:14,360
that looks like before we talk about

00:03:13,440 --> 00:03:17,400
consistency

00:03:14,360 --> 00:03:19,770
and I'm going to use two big examples

00:03:17,400 --> 00:03:22,170
just in the past year that are companies

00:03:19,770 --> 00:03:24,180
that were inconsistent across time so a

00:03:22,170 --> 00:03:25,740
to the exact same decision they were

00:03:24,180 --> 00:03:28,200
confronted with they make two different

00:03:25,740 --> 00:03:32,460
decisions back-to-back so last year

00:03:28,200 --> 00:03:34,320
Twitter decides not to ban Infowars we

00:03:32,460 --> 00:03:35,550
could debate at length about whether

00:03:34,320 --> 00:03:36,930
that was a good decision or a bad

00:03:35,550 --> 00:03:38,300
decision I personally think it was a

00:03:36,930 --> 00:03:41,700
terrible decision

00:03:38,300 --> 00:03:43,440
but what really sort of riled us I think

00:03:41,700 --> 00:03:45,990
differently than just the quality of the

00:03:43,440 --> 00:03:48,600
decision was when the very next year

00:03:45,990 --> 00:03:51,510
they say these are dangerous individuals

00:03:48,600 --> 00:03:54,030
and they also group Louis Farrakhan in

00:03:51,510 --> 00:03:55,770
with with with Infowars almost to sort

00:03:54,030 --> 00:03:57,660
of cluster a group so they could then

00:03:55,770 --> 00:03:59,970
pretend like they hadn't said the exact

00:03:57,660 --> 00:04:01,950
opposite of the year before and so it

00:03:59,970 --> 00:04:04,230
wasn't I think looking at inconsistency

00:04:01,950 --> 00:04:07,320
it's not that the choice that they came

00:04:04,230 --> 00:04:09,570
to is wrong or right it's the fact that

00:04:07,320 --> 00:04:11,520
they didn't have values underpinning

00:04:09,570 --> 00:04:15,390
that choice so they had no sort of sense

00:04:11,520 --> 00:04:16,650
of orientation of how to make that

00:04:15,390 --> 00:04:18,739
decision which made it easy for them to

00:04:16,650 --> 00:04:22,410
change their mind less than a year later

00:04:18,739 --> 00:04:23,910
and another example of this I'm not sure

00:04:22,410 --> 00:04:26,910
how many of you all are familiar with

00:04:23,910 --> 00:04:28,890
deep mind but it's an alphabet company

00:04:26,910 --> 00:04:31,500
that's based in London and they do a lot

00:04:28,890 --> 00:04:32,970
of machine learning work and they were

00:04:31,500 --> 00:04:36,180
working a lot with the National Health

00:04:32,970 --> 00:04:39,210
Service in the UK instead of the

00:04:36,180 --> 00:04:40,620
so well any concerns than being a part

00:04:39,210 --> 00:04:42,540
of alphabet that they would never

00:04:40,620 --> 00:04:44,400
connect the health data that they were

00:04:42,540 --> 00:04:47,100
collecting within the NHS with any

00:04:44,400 --> 00:04:49,640
Google user services or products that

00:04:47,100 --> 00:04:54,060
came out I said it really forcefully and

00:04:49,640 --> 00:04:56,220
literally two years later I I mean I'll

00:04:54,060 --> 00:04:57,810
let you guess what happened so now D

00:04:56,220 --> 00:05:01,200
mind is handing over deep mind health to

00:04:57,810 --> 00:05:03,360
Google and you could you could argue

00:05:01,200 --> 00:05:05,940
that maybe conditions have changed and

00:05:03,360 --> 00:05:07,500
they argue that they want to be able to

00:05:05,940 --> 00:05:08,970
provide these services globally and that

00:05:07,500 --> 00:05:10,740
the infrastructure of deep mind isn't

00:05:08,970 --> 00:05:11,730
what the infrastructure of Google is and

00:05:10,740 --> 00:05:13,320
that Google is going to be a better

00:05:11,730 --> 00:05:16,110
channel for them to change the world

00:05:13,320 --> 00:05:18,330
which I'd say value maybe there's some

00:05:16,110 --> 00:05:21,000
merit to that argument but the fact that

00:05:18,330 --> 00:05:23,250
they backtracked so publicly and the

00:05:21,000 --> 00:05:25,050
decision was so inconsistent one it

00:05:23,250 --> 00:05:26,850
showed us that companies can change

00:05:25,050 --> 00:05:28,470
direction and we have no say over

00:05:26,850 --> 00:05:30,030
whether that happens so there's sort of

00:05:28,470 --> 00:05:33,120
a feeling of disempowerment when we see

00:05:30,030 --> 00:05:36,150
this inconsistency but there's also sort

00:05:33,120 --> 00:05:38,130
of a question of where are these

00:05:36,150 --> 00:05:41,550
decisions even coming from they sort of

00:05:38,130 --> 00:05:44,370
emerge from the ether as though it was

00:05:41,550 --> 00:05:45,840
always going to be thus and I think it

00:05:44,370 --> 00:05:48,150
demonstrates three big things it's

00:05:45,840 --> 00:05:50,100
either a lack of values it's a lack of

00:05:48,150 --> 00:05:51,750
clarity about this value so how do those

00:05:50,100 --> 00:05:53,400
values translate into actual decisions

00:05:51,750 --> 00:05:55,860
or it's a lack of commitment to those

00:05:53,400 --> 00:05:57,540
values so when confronted with an

00:05:55,860 --> 00:05:58,710
incentive that takes you this direction

00:05:57,540 --> 00:06:03,840
and your values would take you this

00:05:58,710 --> 00:06:05,220
direction you choose this way and then I

00:06:03,840 --> 00:06:06,270
think important to mention before I

00:06:05,220 --> 00:06:08,700
start talking about what consistency

00:06:06,270 --> 00:06:12,630
looks like is that if one of your values

00:06:08,700 --> 00:06:15,000
is optionality you will never value

00:06:12,630 --> 00:06:16,850
anything else you will never go in the

00:06:15,000 --> 00:06:20,220
direction of your values if literally

00:06:16,850 --> 00:06:22,860
you maximize for optionality and this

00:06:20,220 --> 00:06:26,220
was a quote in a piece this week about

00:06:22,860 --> 00:06:27,420
Google and I don't know how wrong they

00:06:26,220 --> 00:06:30,750
could be to have two people on two

00:06:27,420 --> 00:06:32,340
different teams have that distinct of a

00:06:30,750 --> 00:06:33,420
perspective on how data and a project is

00:06:32,340 --> 00:06:37,680
going to be used but I think it says

00:06:33,420 --> 00:06:39,210
everything so I'm going to talk a little

00:06:37,680 --> 00:06:42,570
bit about so those are sort of very

00:06:39,210 --> 00:06:44,200
public facing in inconsistencies across

00:06:42,570 --> 00:06:45,520
time so the same

00:06:44,200 --> 00:06:47,230
taken two different ways over a period

00:06:45,520 --> 00:06:48,760
of time but there's also tons of other

00:06:47,230 --> 00:06:50,620
types of decisions that we make all the

00:06:48,760 --> 00:06:52,210
time and there's four sort of big

00:06:50,620 --> 00:06:53,560
buckets there's obviously different ones

00:06:52,210 --> 00:06:54,610
but just to sort of get a handle on what

00:06:53,560 --> 00:06:56,350
I'm talking about when I talk about

00:06:54,610 --> 00:06:58,990
consistency so I'm looking at like

00:06:56,350 --> 00:07:01,210
service optimization so what are we

00:06:58,990 --> 00:07:03,130
building for who and by building for

00:07:01,210 --> 00:07:04,810
those people who re not building for so

00:07:03,130 --> 00:07:06,340
the really explicit choices that we make

00:07:04,810 --> 00:07:09,190
about the services that we build and

00:07:06,340 --> 00:07:11,740
what types of choices reflect what types

00:07:09,190 --> 00:07:14,380
of values the second bucket is redress

00:07:11,740 --> 00:07:16,300
so if somebody is affected let's say for

00:07:14,380 --> 00:07:18,130
example the Twitter or Facebook real

00:07:16,300 --> 00:07:18,760
name policy if somebody's affected by

00:07:18,130 --> 00:07:20,770
that policy

00:07:18,760 --> 00:07:23,230
what is the redress process for that

00:07:20,770 --> 00:07:25,030
person how do they report how is how are

00:07:23,230 --> 00:07:26,800
those reports responded to what is that

00:07:25,030 --> 00:07:28,930
what decisions is a company or an

00:07:26,800 --> 00:07:30,660
organization make around that the third

00:07:28,930 --> 00:07:33,490
big bucket is around data and inference

00:07:30,660 --> 00:07:35,680
so thinking about not just the units of

00:07:33,490 --> 00:07:37,690
data and information but also the sort

00:07:35,680 --> 00:07:40,600
of increasingly analytically derived

00:07:37,690 --> 00:07:42,880
profiles about us how those are managed

00:07:40,600 --> 00:07:44,710
how they're destroyed how they're

00:07:42,880 --> 00:07:47,560
sourced and then thinking about

00:07:44,710 --> 00:07:50,760
monetization so what do we allow to be

00:07:47,560 --> 00:07:53,830
monetized sort of going back to this

00:07:50,760 --> 00:07:55,840
maybe it's a slippery decision of what

00:07:53,830 --> 00:07:57,400
is monetized when and sort of how do we

00:07:55,840 --> 00:07:59,400
communicate about it but that's a whole

00:07:57,400 --> 00:08:03,460
other bucket is sort of thinking about

00:07:59,400 --> 00:08:05,590
how values transfer into decisions about

00:08:03,460 --> 00:08:06,970
monetization those are four big areas

00:08:05,590 --> 00:08:09,400
and just taking a really specific

00:08:06,970 --> 00:08:11,920
example when thinking about consistency

00:08:09,400 --> 00:08:13,600
of those types of decisions if you're in

00:08:11,920 --> 00:08:16,210
a financial institution let's say and

00:08:13,600 --> 00:08:18,430
you've been asked to build an algorithm

00:08:16,210 --> 00:08:20,860
of some sort that will make

00:08:18,430 --> 00:08:23,830
recommendations to a front line bank

00:08:20,860 --> 00:08:26,650
teller so customer a walks in and says

00:08:23,830 --> 00:08:29,320
hi I'm here to deposit a cheque this

00:08:26,650 --> 00:08:31,150
recommendation algorithm would say okay

00:08:29,320 --> 00:08:34,719
while they're here you should recommend

00:08:31,150 --> 00:08:35,890
one financial service for them and this

00:08:34,719 --> 00:08:37,719
is the financial service that this

00:08:35,890 --> 00:08:39,099
algorithm would recommend here maybe a

00:08:37,719 --> 00:08:40,409
couple other options if the teller

00:08:39,099 --> 00:08:41,879
happens to know something

00:08:40,409 --> 00:08:47,220
about that person that the algorithm

00:08:41,879 --> 00:08:49,290
doesn't know how would you for that so

00:08:47,220 --> 00:08:51,870
let's say you have two different product

00:08:49,290 --> 00:08:53,370
teams one of them says well of course we

00:08:51,870 --> 00:08:55,560
would optimize on the likelihood of

00:08:53,370 --> 00:08:57,240
uptake so we want to recommend the

00:08:55,560 --> 00:08:59,279
financial service that we think is more

00:08:57,240 --> 00:09:01,350
likely or most likely to be taken up by

00:08:59,279 --> 00:09:02,939
the person right the other team says no

00:09:01,350 --> 00:09:05,160
no no that's not within our values

00:09:02,939 --> 00:09:06,870
actually our values say we want it to be

00:09:05,160 --> 00:09:10,019
a recommendation that will have the most

00:09:06,870 --> 00:09:12,209
positive impact on that customers future

00:09:10,019 --> 00:09:15,870
let's say financial wealth or something

00:09:12,209 --> 00:09:18,089
so the way that those kinds of decisions

00:09:15,870 --> 00:09:20,250
get translated into in this example a

00:09:18,089 --> 00:09:21,899
data science problem our project has

00:09:20,250 --> 00:09:23,370
huge impacts on the way that an

00:09:21,899 --> 00:09:27,600
organization expresses its values

00:09:23,370 --> 00:09:29,490
through its technical decisions so what

00:09:27,600 --> 00:09:32,279
is consistency look like so it increases

00:09:29,490 --> 00:09:34,620
alignment between values and actions so

00:09:32,279 --> 00:09:36,569
there's all these companies that are

00:09:34,620 --> 00:09:39,029
talking about here's our 10 principles

00:09:36,569 --> 00:09:43,470
for X or Y or here's our you know our

00:09:39,029 --> 00:09:44,699
world you on Z but what does that

00:09:43,470 --> 00:09:45,810
actually mean in practice how does that

00:09:44,699 --> 00:09:47,730
actually influence the choices they're

00:09:45,810 --> 00:09:50,370
making and consistency is the sort of

00:09:47,730 --> 00:09:52,529
middle layer that says this is how we

00:09:50,370 --> 00:09:55,920
translate those things into decisions

00:09:52,529 --> 00:09:57,540
it also guards against mistakes so if

00:09:55,920 --> 00:09:59,279
you have a level of consistency that

00:09:57,540 --> 00:10:01,800
means that you're not leaving everything

00:09:59,279 --> 00:10:04,380
up to chance and probability and

00:10:01,800 --> 00:10:07,079
individuals to say you know whatever

00:10:04,380 --> 00:10:08,550
let's do this this time because it

00:10:07,079 --> 00:10:10,920
creates a sort of institutional memory

00:10:08,550 --> 00:10:13,889
and an institutional set of expectations

00:10:10,920 --> 00:10:15,839
and then in turn it creates clarity for

00:10:13,889 --> 00:10:17,670
teams and users no team wants to be in a

00:10:15,839 --> 00:10:19,050
situation where every project they're

00:10:17,670 --> 00:10:21,720
doing they have to consider the entire

00:10:19,050 --> 00:10:24,029
scope of all of the ethical dimensions

00:10:21,720 --> 00:10:25,649
of all over the work of a company so

00:10:24,029 --> 00:10:27,000
what would it look like for teams to go

00:10:25,649 --> 00:10:28,230
into those kinds of projects and

00:10:27,000 --> 00:10:30,300
conversations with at least some

00:10:28,230 --> 00:10:31,889
foundation of this is a project that's

00:10:30,300 --> 00:10:33,930
similar that we did before these are the

00:10:31,889 --> 00:10:35,189
decisions that we made this is why these

00:10:33,930 --> 00:10:37,230
are the kinds of things that we think

00:10:35,189 --> 00:10:39,809
you should be thinking about and then it

00:10:37,230 --> 00:10:40,920
also can be measured and improved so one

00:10:39,809 --> 00:10:42,899
of the big challenges of

00:10:40,920 --> 00:10:45,899
we're gonna improve well-being or

00:10:42,899 --> 00:10:48,149
ethical whatever of technology it has

00:10:45,899 --> 00:10:50,459
the benefit for some people of not being

00:10:48,149 --> 00:10:51,839
measurable so you're able to say we

00:10:50,459 --> 00:10:54,179
prefer you can't it's a counterfactual

00:10:51,839 --> 00:10:55,709
to say this was a better decision than

00:10:54,179 --> 00:10:57,509
this other thing because you prevented

00:10:55,709 --> 00:10:59,149
something from happening which makes it

00:10:57,509 --> 00:11:03,509
very difficult to sort of show and

00:10:59,149 --> 00:11:04,949
measure progress and success so what's

00:11:03,509 --> 00:11:06,839
cool about consistency is that there's

00:11:04,949 --> 00:11:08,489
actually methods of measuring it you can

00:11:06,839 --> 00:11:10,649
actually see if product teams take those

00:11:08,489 --> 00:11:12,689
values in the same way which means that

00:11:10,649 --> 00:11:17,939
you can get better over time as a team

00:11:12,689 --> 00:11:19,980
in organization and I would so I think

00:11:17,939 --> 00:11:22,350
mistake is maybe an aggressive word to

00:11:19,980 --> 00:11:24,149
use here but I think talking about the

00:11:22,350 --> 00:11:26,069
types of mistakes an organization makes

00:11:24,149 --> 00:11:28,100
is really important because I think a

00:11:26,069 --> 00:11:31,169
lot of times we conflate incompetence

00:11:28,100 --> 00:11:32,999
with with evilness and I think sometimes

00:11:31,169 --> 00:11:36,899
it's important maybe not to confuse

00:11:32,999 --> 00:11:38,819
those two things but Atul Gawande who

00:11:36,899 --> 00:11:41,339
wrote the checklist manifesto which is

00:11:38,819 --> 00:11:42,629
about how in medicine we take complexity

00:11:41,339 --> 00:11:44,759
and we sort of reduce it into sort of

00:11:42,629 --> 00:11:46,319
steps because there's so much history of

00:11:44,759 --> 00:11:48,360
Medicine you have to know so much about

00:11:46,319 --> 00:11:49,799
so many different fields to get certain

00:11:48,360 --> 00:11:51,179
things right that breaking things down

00:11:49,799 --> 00:11:52,860
and checklist is revolutionary for

00:11:51,179 --> 00:11:54,449
medicine I don't think checklists are

00:11:52,860 --> 00:11:56,519
revolutionary for technology for what

00:11:54,449 --> 00:11:58,949
it's worth but I think his perspective

00:11:56,519 --> 00:12:01,679
on mistakes is really interesting so he

00:11:58,949 --> 00:12:03,869
breaks errors down into two types one is

00:12:01,679 --> 00:12:05,699
an error ignorance which is mistakes we

00:12:03,869 --> 00:12:07,769
make because we don't know enough and

00:12:05,699 --> 00:12:09,600
the other is errors of ineptitude

00:12:07,769 --> 00:12:12,259
so mistakes we make because we didn't

00:12:09,600 --> 00:12:15,059
properly use what we know and I think

00:12:12,259 --> 00:12:16,889
making those two distinctions can make a

00:12:15,059 --> 00:12:18,600
big difference in how we diagnose and

00:12:16,889 --> 00:12:22,410
then treat the problems that we see

00:12:18,600 --> 00:12:24,389
within technology and I want it so

00:12:22,410 --> 00:12:25,499
and those two errors I think are really

00:12:24,389 --> 00:12:27,299
important to keep in mind when we think

00:12:25,499 --> 00:12:28,619
about the sort of components of

00:12:27,299 --> 00:12:30,629
consistency so I'm not gonna walk us

00:12:28,619 --> 00:12:32,009
through four sort of big bucket aspects

00:12:30,629 --> 00:12:33,899
of consistency that you can think about

00:12:32,009 --> 00:12:35,669
when you think about whether or not your

00:12:33,899 --> 00:12:38,189
organization is consistent with the way

00:12:35,669 --> 00:12:40,589
it translates values into decisions so

00:12:38,189 --> 00:12:44,759
the before here diversity reflection

00:12:40,589 --> 00:12:47,489
comparison and iteration in diversity I

00:12:44,759 --> 00:12:48,540
realize there was a point made at the

00:12:47,489 --> 00:12:50,130
earlier keynote today

00:12:48,540 --> 00:12:52,260
that diversity isn't enough we need

00:12:50,130 --> 00:12:54,750
equity and inclusion this is actually

00:12:52,260 --> 00:12:57,960
surely about diversity so it's purely

00:12:54,750 --> 00:13:01,050
about representation of different

00:12:57,960 --> 00:13:02,820
perspectives not the underlying sort of

00:13:01,050 --> 00:13:04,800
moral prerogative of having

00:13:02,820 --> 00:13:06,510
representation actually mean equity and

00:13:04,800 --> 00:13:10,340
power within an organization just to

00:13:06,510 --> 00:13:12,270
clarify so I'll start with that I mean I

00:13:10,340 --> 00:13:14,130
so I don't know how many of you have

00:13:12,270 --> 00:13:15,410
heard this little tidbit but I find it

00:13:14,130 --> 00:13:19,680
fascinating every time I think about it

00:13:15,410 --> 00:13:22,050
and is the human brain can receive or

00:13:19,680 --> 00:13:23,970
has in its environment 11 million bits

00:13:22,050 --> 00:13:27,050
of information available to it every

00:13:23,970 --> 00:13:30,330
second but we only process 40 to 60 bits

00:13:27,050 --> 00:13:32,070
so the amount of arrogance to think that

00:13:30,330 --> 00:13:34,080
we know what decision to make in any

00:13:32,070 --> 00:13:36,150
moment is shocking

00:13:34,080 --> 00:13:39,900
I mean we're sort of walking overly

00:13:36,150 --> 00:13:41,490
confident creatures and when you think

00:13:39,900 --> 00:13:43,320
about diversity so essentially if you

00:13:41,490 --> 00:13:44,940
hire the same type of person over and

00:13:43,320 --> 00:13:47,460
over and over again you're essentially

00:13:44,940 --> 00:13:49,740
committing to only as a team being able

00:13:47,460 --> 00:13:52,110
to process 40 to 60 bits of information

00:13:49,740 --> 00:13:55,260
you're literally refusing to add

00:13:52,110 --> 00:13:56,310
additional perspectives to be able to

00:13:55,260 --> 00:13:58,410
see different types of bits of

00:13:56,310 --> 00:14:00,420
information and so it's sort of being

00:13:58,410 --> 00:14:04,590
like willfully incompetent to have a

00:14:00,420 --> 00:14:07,200
non-diverse team so I think when

00:14:04,590 --> 00:14:08,670
thinking about consistency I think about

00:14:07,200 --> 00:14:10,020
their adversity I think about three big

00:14:08,670 --> 00:14:12,510
areas one is diversity of lived

00:14:10,020 --> 00:14:14,760
experience because that's obviously

00:14:12,510 --> 00:14:16,800
critical diversity of expertise and then

00:14:14,760 --> 00:14:18,420
diversity of thought and diversity of

00:14:16,800 --> 00:14:20,250
thought has increasingly been used as

00:14:18,420 --> 00:14:22,230
shorthand for being tolerant of people

00:14:20,250 --> 00:14:23,880
like James Day more so I'll be a little

00:14:22,230 --> 00:14:28,520
clearer about what I mean by diversity

00:14:23,880 --> 00:14:31,290
of thought and I think we all we all

00:14:28,520 --> 00:14:33,300
sometimes I think under estimate the

00:14:31,290 --> 00:14:36,690
amount we all think really differently

00:14:33,300 --> 00:14:39,450
like on project teams in my head having

00:14:36,690 --> 00:14:42,810
managed many people the blue sky thinker

00:14:39,450 --> 00:14:44,550
versus the devil's advocate versus the

00:14:42,810 --> 00:14:46,170
pragmatist who's like let's just start

00:14:44,550 --> 00:14:49,200
why are we not starting let's do this

00:14:46,170 --> 00:14:50,440
versus the resource obsessed person

00:14:49,200 --> 00:14:51,700
who's like

00:14:50,440 --> 00:14:52,990
how are you pay for this how we're gonna

00:14:51,700 --> 00:14:54,190
do it happen where's the time we don't

00:14:52,990 --> 00:14:56,650
have the time for this

00:14:54,190 --> 00:14:59,200
and it takes all those kinds of people

00:14:56,650 --> 00:15:00,700
to sort of make the world go round so

00:14:59,200 --> 00:15:02,230
thinking about diversity not just in

00:15:00,700 --> 00:15:03,850
terms of lived experience and expertise

00:15:02,230 --> 00:15:05,710
which are both critical but I think also

00:15:03,850 --> 00:15:07,630
about how we approach problems because I

00:15:05,710 --> 00:15:09,400
think in the same way we're prone to

00:15:07,630 --> 00:15:11,590
hiring people that look like us and have

00:15:09,400 --> 00:15:13,390
a background like us we're also really

00:15:11,590 --> 00:15:16,090
good at hiring people that think like us

00:15:13,390 --> 00:15:18,610
which really limits our ability to see

00:15:16,090 --> 00:15:19,720
more of the picture than we otherwise

00:15:18,610 --> 00:15:23,770
would by ourselves

00:15:19,720 --> 00:15:26,410
that's diversity the second component of

00:15:23,770 --> 00:15:27,730
consistency I think of his reflection so

00:15:26,410 --> 00:15:29,080
a lot of times people hear the word

00:15:27,730 --> 00:15:33,850
reflection and they're like oh so that's

00:15:29,080 --> 00:15:35,800
like my personal feelings about what I

00:15:33,850 --> 00:15:39,010
want to do and why sort of an

00:15:35,800 --> 00:15:42,010
exploration of self or something it's

00:15:39,010 --> 00:15:45,460
mushy it's individual but that's what

00:15:42,010 --> 00:15:47,860
technology design is we're taking next

00:15:45,460 --> 00:15:50,230
to no information and stabbing in the

00:15:47,860 --> 00:15:52,240
dark at like something based on all of

00:15:50,230 --> 00:15:54,550
our biases and all the things all of our

00:15:52,240 --> 00:15:55,900
preferences so this idea that like as a

00:15:54,550 --> 00:15:58,510
team we're objective because there's

00:15:55,900 --> 00:16:00,010
more than one of us is crazy so another

00:15:58,510 --> 00:16:04,360
sort of thing to think about with in the

00:16:00,010 --> 00:16:07,870
context of consistency is having real

00:16:04,360 --> 00:16:10,330
space for reflection and not just this

00:16:07,870 --> 00:16:12,490
is fun we're having a conversation but

00:16:10,330 --> 00:16:14,320
like what questions do we ask at what

00:16:12,490 --> 00:16:15,790
phases of the project who has to be in

00:16:14,320 --> 00:16:17,230
those conversations what does the

00:16:15,790 --> 00:16:19,060
reflection look like how do we document

00:16:17,230 --> 00:16:20,470
it so that we can go back and see if we

00:16:19,060 --> 00:16:23,230
were wrong and then figure out why were

00:16:20,470 --> 00:16:25,150
we wrong at the end like really making

00:16:23,230 --> 00:16:27,730
it in and I think teams have been really

00:16:25,150 --> 00:16:29,530
good at introducing reflection at the

00:16:27,730 --> 00:16:32,170
end so I see a lot of organizations do

00:16:29,530 --> 00:16:33,580
retros now which is fantastic because it

00:16:32,170 --> 00:16:35,080
actually gives people time to talk about

00:16:33,580 --> 00:16:38,230
a project outside of the pressure of

00:16:35,080 --> 00:16:39,490
delivery but it also is too late to fix

00:16:38,230 --> 00:16:41,620
anything

00:16:39,490 --> 00:16:43,120
so so maybe thinking about aspects of

00:16:41,620 --> 00:16:45,490
reflection that we can include in other

00:16:43,120 --> 00:16:46,660
types of project phases and be really

00:16:45,490 --> 00:16:48,070
consistent about it because it's a

00:16:46,660 --> 00:16:50,650
really important component of figuring

00:16:48,070 --> 00:16:52,180
out what we don't know and then the

00:16:50,650 --> 00:16:53,889
third is comparison there's really

00:16:52,180 --> 00:16:55,359
excited here a group

00:16:53,889 --> 00:16:57,100
earlier presenting on qualitative

00:16:55,359 --> 00:16:59,049
research because I think that's actually

00:16:57,100 --> 00:17:00,220
a huge thing that we could use in

00:16:59,049 --> 00:17:02,709
technology production that we just

00:17:00,220 --> 00:17:04,299
ignore so we're confronted with lots of

00:17:02,709 --> 00:17:06,159
subjective information and make a ton of

00:17:04,299 --> 00:17:07,569
subjective decisions and then pretend

00:17:06,159 --> 00:17:09,339
that it was always gonna be like that

00:17:07,569 --> 00:17:13,059
and it was really math which is insane

00:17:09,339 --> 00:17:15,610
so when thinking about comparison so I

00:17:13,059 --> 00:17:17,019
find inner code or reliability a really

00:17:15,610 --> 00:17:20,079
interesting thing to think about when

00:17:17,019 --> 00:17:22,360
thinking about product teams so inner

00:17:20,079 --> 00:17:24,179
coder reliability is if you have a

00:17:22,360 --> 00:17:26,589
researcher and they're studying

00:17:24,179 --> 00:17:28,870
documentation that is very subjective so

00:17:26,589 --> 00:17:30,460
let's say it's transcribed interviews so

00:17:28,870 --> 00:17:32,500
it's somebody waxing poetic about their

00:17:30,460 --> 00:17:34,899
thoughts and feelings about a topic how

00:17:32,500 --> 00:17:36,399
do you turn that into science and

00:17:34,899 --> 00:17:38,769
evidence and facts and then write

00:17:36,399 --> 00:17:40,899
academic papers about it well how it

00:17:38,769 --> 00:17:45,279
works is you have multiple research

00:17:40,899 --> 00:17:46,960
assistants that code that content and

00:17:45,279 --> 00:17:49,779
then you can actually using those

00:17:46,960 --> 00:17:52,149
coatings compare and say weird

00:17:49,779 --> 00:17:53,679
so that person gave it a this and this

00:17:52,149 --> 00:17:55,690
other person gave it to this on that

00:17:53,679 --> 00:17:58,659
there's something wrong with the way I'm

00:17:55,690 --> 00:18:01,090
asking them to do this this thing an

00:17:58,659 --> 00:18:02,649
intro to reliability is a way of testing

00:18:01,090 --> 00:18:04,659
whether or not you've given clear enough

00:18:02,649 --> 00:18:07,330
instructions to translate the subjective

00:18:04,659 --> 00:18:09,730
into something really concrete and if

00:18:07,330 --> 00:18:13,539
you think about it within technical

00:18:09,730 --> 00:18:15,370
teams imagining two really subjective

00:18:13,539 --> 00:18:16,929
scenarios that are identical or given to

00:18:15,370 --> 00:18:19,179
two different project teams and you say

00:18:16,929 --> 00:18:21,659
hey so how would you score this on level

00:18:19,179 --> 00:18:25,389
of sensitivity of the data you're using

00:18:21,659 --> 00:18:27,639
importance of figuring out how X

00:18:25,389 --> 00:18:29,529
community would feel about this product

00:18:27,639 --> 00:18:31,960
before you launch it all those types of

00:18:29,529 --> 00:18:34,149
variables that are pretty subjective and

00:18:31,960 --> 00:18:36,399
difficult to pin down and you ask both

00:18:34,149 --> 00:18:38,169
groups to rate those based on your

00:18:36,399 --> 00:18:40,120
organizational values and you have

00:18:38,169 --> 00:18:41,679
radically different interpretations of

00:18:40,120 --> 00:18:43,779
what that project would require to do

00:18:41,679 --> 00:18:45,610
well and do and do epically and you to

00:18:43,779 --> 00:18:47,559
do and aligned with your values then you

00:18:45,610 --> 00:18:50,620
have a serious problem because

00:18:47,559 --> 00:18:53,169
essentially two teams have interpreted

00:18:50,620 --> 00:18:54,460
your values in a way that are completely

00:18:53,169 --> 00:18:56,019
different that means that you're not

00:18:54,460 --> 00:18:57,850
doing a good job of communicating them

00:18:56,019 --> 00:18:58,960
you're not making it clear enough

00:18:57,850 --> 00:19:00,460
of how they should be thinking about

00:18:58,960 --> 00:19:02,500
them when it comes to really specific

00:19:00,460 --> 00:19:05,370
decisions and so in record of

00:19:02,500 --> 00:19:07,450
reliability I think it's an under used

00:19:05,370 --> 00:19:09,070
technique that's super common in the

00:19:07,450 --> 00:19:13,179
social sciences but has been largely

00:19:09,070 --> 00:19:17,260
ignored by the mathy and then the lasas

00:19:13,179 --> 00:19:19,929
iteration this one's pretty obvious you

00:19:17,260 --> 00:19:21,280
can't get this right first try and if

00:19:19,929 --> 00:19:25,360
you think that you did then you're

00:19:21,280 --> 00:19:27,730
really bad at it so I think thinking

00:19:25,360 --> 00:19:29,830
about as you're testing them updating

00:19:27,730 --> 00:19:32,110
your documentation your guidance giving

00:19:29,830 --> 00:19:34,090
Flair and story to the types of

00:19:32,110 --> 00:19:35,289
decisions that you want people making so

00:19:34,090 --> 00:19:37,809
if you feel like there's a there's a

00:19:35,289 --> 00:19:39,909
scenario where you messed up so badly

00:19:37,809 --> 00:19:41,650
right it's taking the time write that

00:19:39,909 --> 00:19:43,150
down say this is why we think we made

00:19:41,650 --> 00:19:44,710
these mistakes this is what the mistakes

00:19:43,150 --> 00:19:46,419
look like this is the harm the mistakes

00:19:44,710 --> 00:19:48,669
cause this is what we're gonna do

00:19:46,419 --> 00:19:50,130
differently next time so really taking

00:19:48,669 --> 00:19:52,270
it seriously this is a learning process

00:19:50,130 --> 00:19:54,460
and something that you only get better

00:19:52,270 --> 00:19:57,100
at if you keep paying attention to it

00:19:54,460 --> 00:20:01,299
over time and what does this mean for

00:19:57,100 --> 00:20:04,630
you I mean I I I'm really hopeful that

00:20:01,299 --> 00:20:06,789
organizations that that are increasingly

00:20:04,630 --> 00:20:08,880
interested in values are realizing quite

00:20:06,789 --> 00:20:12,789
quickly that it's not enough to just say

00:20:08,880 --> 00:20:14,650
don't do evil because that's like it's

00:20:12,789 --> 00:20:16,270
just super vague and it's not helpful

00:20:14,650 --> 00:20:18,100
when it comes to actually making choices

00:20:16,270 --> 00:20:21,970
and so until we start sort of making

00:20:18,100 --> 00:20:24,419
that link between that sort of sky level

00:20:21,970 --> 00:20:27,070
thinking and the sort of earth level

00:20:24,419 --> 00:20:30,100
weeds I think it's gonna be really

00:20:27,070 --> 00:20:31,929
difficult to see change in the big

00:20:30,100 --> 00:20:33,700
companies around us but I think it's

00:20:31,929 --> 00:20:35,650
also a really amazing time for

00:20:33,700 --> 00:20:37,270
organization smaller organizations civil

00:20:35,650 --> 00:20:39,340
society organizations and those that

00:20:37,270 --> 00:20:41,650
whose constituencies expect more and

00:20:39,340 --> 00:20:43,720
should expect more from them to

00:20:41,650 --> 00:20:45,640
demonstrate what we want to see

00:20:43,720 --> 00:20:47,590
technical production to look like so

00:20:45,640 --> 00:20:49,330
when we look at diversity not only what

00:20:47,590 --> 00:20:50,830
type of diversity do you want in product

00:20:49,330 --> 00:20:52,630
teams but what type of diversity do you

00:20:50,830 --> 00:20:53,919
have to have in terms of consultation

00:20:52,630 --> 00:20:56,230
and conversation before you actually

00:20:53,919 --> 00:20:58,080
launch something because the hubris of

00:20:56,230 --> 00:20:59,159
making something digital

00:20:58,080 --> 00:21:02,370
and then just sending it out to a

00:20:59,159 --> 00:21:06,080
billion people is it's insane and unless

00:21:02,370 --> 00:21:08,760
we show why that level of hubris is

00:21:06,080 --> 00:21:09,840
unacceptable we're not gonna we're not

00:21:08,760 --> 00:21:11,100
gonna get anywhere we're gonna sort of

00:21:09,840 --> 00:21:14,399
be on the outside just are throwing

00:21:11,100 --> 00:21:15,659
rocks at people that have power and I

00:21:14,399 --> 00:21:17,010
think we can actually demonstrate the

00:21:15,659 --> 00:21:18,090
power of these kinds of approaches

00:21:17,010 --> 00:21:20,429
because I think it means you build

00:21:18,090 --> 00:21:22,559
better technology people rely on it more

00:21:20,429 --> 00:21:24,299
and it's it's more in line with a

00:21:22,559 --> 00:21:29,970
society that we that we want to be

00:21:24,299 --> 00:21:32,940
building so I have time for questions a

00:21:29,970 --> 00:21:35,429
lot of time for questions but but

00:21:32,940 --> 00:21:37,919
generally speaking like I think the

00:21:35,429 --> 00:21:39,419
Devils in the details and I think we

00:21:37,919 --> 00:21:40,590
don't want to be Twitter like I wouldn't

00:21:39,419 --> 00:21:43,350
want to be in Twitter's position right

00:21:40,590 --> 00:21:44,370
now but I think we also probably

00:21:43,350 --> 00:21:45,690
everybody in this room could do better

00:21:44,370 --> 00:21:49,370
than then and I think part of that

00:21:45,690 --> 00:21:49,370
starts with being consistent

00:21:49,880 --> 00:21:53,059
[Music]

00:21:53,900 --> 00:21:58,449

YouTube URL: https://www.youtube.com/watch?v=BAsi0iEpEWg


