Title: Our Quest to Clean Up Institutional Affiliations in Dryad - Daniella Lowenberg & Ted Habermann
Publication date: 2019-05-19
Playlist: CSVConf 2019
Description: 
	Data publications and other scholarly outputs do not have clean information on institutional affiliations for researchers. This is caused by a mix of not asking researchers for this information up front, as well as incomplete metadata being submitted by repositories to DataCite and (publications to) Crossref. Without this standardized information we can't properly report on or provide statistics on deposits, usage metrics, or reach by institution. Join us for a session about our work using OpenRefine, organizational identifiers (ROR), and some manual sleuthing to update and improve Dryad institutional metadata for 25,000 data publications.

talk page: https://csvconf.com/speakers/#daniella-lowenberg-ted-habermann
Captions: 
	00:00:00,549 --> 00:00:08,650
hello I am Daniela I'm Ted and I am the

00:00:06,609 --> 00:00:14,260
product manager for Jaya and I work at

00:00:08,650 --> 00:00:27,460
California digital library and Ted's put

00:00:14,260 --> 00:00:28,630
in here the roar for CDL and so we're

00:00:27,460 --> 00:00:31,869
gonna talk about is that we have this

00:00:28,630 --> 00:00:34,690
problem so drivers 27000 data

00:00:31,869 --> 00:00:37,060
publications and because of different

00:00:34,690 --> 00:00:39,250
standards and one weird thing about

00:00:37,060 --> 00:00:41,620
publishing articles and data and not

00:00:39,250 --> 00:00:43,950
having a standard for institutions we

00:00:41,620 --> 00:00:46,180
never actually collected the

00:00:43,950 --> 00:00:48,250
institutional affiliations for any of

00:00:46,180 --> 00:00:51,430
the authors for these data publications

00:00:48,250 --> 00:00:54,370
and that's a huge missing thing that

00:00:51,430 --> 00:00:56,079
we're looking for and what what makes

00:00:54,370 --> 00:00:57,760
that a problem well a lot of

00:00:56,079 --> 00:01:00,579
institutions want to know research

00:00:57,760 --> 00:01:02,530
output from their institution we want to

00:01:00,579 --> 00:01:04,809
know the usage by researchers in their

00:01:02,530 --> 00:01:06,909
institution we want to be able to see

00:01:04,809 --> 00:01:08,740
what's coming in to a central place like

00:01:06,909 --> 00:01:11,200
dry out and then send it back out to an

00:01:08,740 --> 00:01:13,209
institution and really right now we just

00:01:11,200 --> 00:01:15,130
don't have any standard way to find that

00:01:13,209 --> 00:01:18,149
and we're also just don't even have that

00:01:15,130 --> 00:01:23,319
raw information to start with

00:01:18,149 --> 00:01:25,479
so that's us so we came together and

00:01:23,319 --> 00:01:27,880
talked about how are we gonna find all

00:01:25,479 --> 00:01:30,880
this information for these dry add data

00:01:27,880 --> 00:01:33,670
publications and we know that in the

00:01:30,880 --> 00:01:36,189
past red has only required that data be

00:01:33,670 --> 00:01:38,079
related to an article and we know that

00:01:36,189 --> 00:01:41,619
journals send that information to

00:01:38,079 --> 00:01:42,789
CrossRef and that was the first place

00:01:41,619 --> 00:01:45,249
that we were gonna start looking for

00:01:42,789 --> 00:01:47,310
this but when we started we found that

00:01:45,249 --> 00:01:50,169
we can only find half of all the

00:01:47,310 --> 00:01:52,389
affiliations in CrossRef and that's

00:01:50,169 --> 00:01:54,669
because there isn't a standard that's

00:01:52,389 --> 00:01:58,119
far far for institutions to be sending

00:01:54,669 --> 00:01:59,950
that information and so we also had to

00:01:58,119 --> 00:02:00,820
start looking at places like class that

00:01:59,950 --> 00:02:03,040
have open

00:02:00,820 --> 00:02:09,550
yeah that allowed for us to start

00:02:03,040 --> 00:02:11,080
pulling this information bring on Ted so

00:02:09,550 --> 00:02:14,230
we got the affiliations out of either

00:02:11,080 --> 00:02:16,180
CrossRef or plus we also have a small

00:02:14,230 --> 00:02:18,240
army of curators that are manually

00:02:16,180 --> 00:02:22,060
generating something which is of course

00:02:18,240 --> 00:02:24,220
hard and much appreciated work and it

00:02:22,060 --> 00:02:26,050
goes into the meat grinder and after

00:02:24,220 --> 00:02:28,870
that comes a token and the token goes

00:02:26,050 --> 00:02:30,730
into roar to try and convert the token

00:02:28,870 --> 00:02:33,459
into an identifier and the goal at the

00:02:30,730 --> 00:02:35,770
end is to get those identifiers into the

00:02:33,459 --> 00:02:38,950
data sight metadata for this for these

00:02:35,770 --> 00:02:40,810
data sets and I'm going to focus on

00:02:38,950 --> 00:02:43,120
today is really this part taking the

00:02:40,810 --> 00:02:49,300
affiliation data from cross-reference

00:02:43,120 --> 00:02:52,269
loss and trying to generate roars roars

00:02:49,300 --> 00:02:55,600
roars our research organization registry

00:02:52,269 --> 00:02:58,209
I Derek there are new open identifiers

00:02:55,600 --> 00:03:03,940
Maria gold gave a talk earlier today

00:02:58,209 --> 00:03:05,560
she's back here if you have questions so

00:03:03,940 --> 00:03:07,390
this is what a perfect affiliation

00:03:05,560 --> 00:03:10,600
stream looks like people that are

00:03:07,390 --> 00:03:11,769
teaching people scientists how to do

00:03:10,600 --> 00:03:14,080
things effectively with their

00:03:11,769 --> 00:03:16,239
publications should work on writing

00:03:14,080 --> 00:03:19,780
simple affiliation strings that we can

00:03:16,239 --> 00:03:21,760
we can extract things like names of the

00:03:19,780 --> 00:03:23,530
universities from this is a good one

00:03:21,760 --> 00:03:25,660
because it has consistent alignment

00:03:23,530 --> 00:03:27,549
IRS's semicolons in this case and

00:03:25,660 --> 00:03:29,860
there's a single affiliation that

00:03:27,549 --> 00:03:32,110
happened to be delimited by those two

00:03:29,860 --> 00:03:34,090
limiters so we can obviously recognize

00:03:32,110 --> 00:03:36,750
that pretty easily and turned it into a

00:03:34,090 --> 00:03:39,430
roar so this is a very simple project

00:03:36,750 --> 00:03:42,870
unfortunately the world looks a little

00:03:39,430 --> 00:03:45,010
bit more like this there's a lot we have

00:03:42,870 --> 00:03:46,570
you know some number of tens of

00:03:45,010 --> 00:03:49,030
thousands of these strings that we're

00:03:46,570 --> 00:03:50,920
trying to work with them and here were

00:03:49,030 --> 00:03:53,860
it we're at CSV and that's really

00:03:50,920 --> 00:03:55,690
wonderful if there are commas separating

00:03:53,860 --> 00:03:57,820
the tokens that you're interested in and

00:03:55,690 --> 00:03:59,980
you can see some of these have commas

00:03:57,820 --> 00:04:02,200
but some of them have semicolons so

00:03:59,980 --> 00:04:04,329
there's multiple - limiters and and we

00:04:02,200 --> 00:04:06,070
need to try and work work with multiple

00:04:04,329 --> 00:04:07,510
- limiters and then of course there are

00:04:06,070 --> 00:04:08,709
some strings that don't have any -

00:04:07,510 --> 00:04:13,389
limiters that you're trying to find

00:04:08,709 --> 00:04:13,770
these tokens in so my approach that is -

00:04:13,389 --> 00:04:16,440
I

00:04:13,770 --> 00:04:18,570
to create some targets which are strings

00:04:16,440 --> 00:04:20,970
that are expected in organization names

00:04:18,570 --> 00:04:23,580
and these are things that that you find

00:04:20,970 --> 00:04:25,530
by looking at the data doing word counts

00:04:23,580 --> 00:04:27,210
or just becoming familiar with it and

00:04:25,530 --> 00:04:31,050
these become the targets that we're

00:04:27,210 --> 00:04:35,400
looking for to try to identify the names

00:04:31,050 --> 00:04:37,710
of organizations in these strings and so

00:04:35,400 --> 00:04:41,040
it looks like this this is a unit the

00:04:37,710 --> 00:04:43,140
most common word in names of

00:04:41,040 --> 00:04:46,590
organizations research organizations

00:04:43,140 --> 00:04:49,320
happens to be aq niversity it happens in

00:04:46,590 --> 00:04:53,100
many languages so a use unit which works

00:04:49,320 --> 00:04:55,830
in most languages things like national

00:04:53,100 --> 00:04:57,960
is also useful in a lot of situations

00:04:55,830 --> 00:04:59,940
and a lot of these tokens or things like

00:04:57,960 --> 00:05:01,640
Department one of the things about that

00:04:59,940 --> 00:05:03,960
we know about organizational

00:05:01,640 --> 00:05:05,960
organizations they're hierarchical so

00:05:03,960 --> 00:05:09,300
there are usually a Department of X

00:05:05,960 --> 00:05:12,420
University of Y Rohrer is currently

00:05:09,300 --> 00:05:14,010
focusing on the university level but I

00:05:12,420 --> 00:05:16,740
want to try and build this tool so that

00:05:14,010 --> 00:05:18,570
we can do it at different levels of

00:05:16,740 --> 00:05:20,310
hierarchy at some point that becomes

00:05:18,570 --> 00:05:22,440
necessary so the department can be

00:05:20,310 --> 00:05:24,330
important but there are also strings

00:05:22,440 --> 00:05:26,220
where a department is actually the

00:05:24,330 --> 00:05:28,380
identifier for the organization that

00:05:26,220 --> 00:05:30,510
you're looking for so if it's Department

00:05:28,380 --> 00:05:33,480
of Agriculture or Department of Interior

00:05:30,510 --> 00:05:35,580
or other things like that you want to be

00:05:33,480 --> 00:05:37,740
able to find those tokens that start

00:05:35,580 --> 00:05:39,420
with Department as well that are gonna

00:05:37,740 --> 00:05:44,580
be at the right level and the hierarchy

00:05:39,420 --> 00:05:46,290
for or so this is just a selection of

00:05:44,580 --> 00:05:49,580
Union things and we already know that

00:05:46,290 --> 00:05:51,690
the University of Arizona is a perfect

00:05:49,580 --> 00:05:53,780
token in this case a perfect

00:05:51,690 --> 00:05:56,250
organizational name there are other

00:05:53,780 --> 00:05:58,680
challenges in this in the status of

00:05:56,250 --> 00:06:01,080
things like names of universities or

00:05:58,680 --> 00:06:03,390
other organizations in non-english

00:06:01,080 --> 00:06:05,760
languages which unfortunately is a

00:06:03,390 --> 00:06:09,090
challenge for me if it's not English or

00:06:05,760 --> 00:06:13,590
German a lot of funny characters sort of

00:06:09,090 --> 00:06:16,200
that are in these strings and cause some

00:06:13,590 --> 00:06:17,910
challenges and then also strings as I

00:06:16,200 --> 00:06:19,650
mentioned before that are delimited by

00:06:17,910 --> 00:06:22,420
other things so in this case they're

00:06:19,650 --> 00:06:24,220
delimited by commas

00:06:22,420 --> 00:06:26,680
obviously it's a simple problem but this

00:06:24,220 --> 00:06:27,340
is one of the kinds of so simple

00:06:26,680 --> 00:06:29,050
problems

00:06:27,340 --> 00:06:32,830
add up when you're trying to munch a

00:06:29,050 --> 00:06:35,380
fair amount of text so this just shows a

00:06:32,830 --> 00:06:38,740
a set of replacements that are made in

00:06:35,380 --> 00:06:41,410
the process of converting the original

00:06:38,740 --> 00:06:44,410
affiliation strings into these tokens a

00:06:41,410 --> 00:06:46,360
lot of replacements for you knew the dot

00:06:44,410 --> 00:06:47,680
another good thing when you're writing

00:06:46,360 --> 00:06:50,320
these strings if you're writing them

00:06:47,680 --> 00:06:53,200
into your publication platforms let's

00:06:50,320 --> 00:06:56,620
try to avoid abbreviations that's sort

00:06:53,200 --> 00:06:59,710
of a good thing in most many data

00:06:56,620 --> 00:07:04,990
processing tasks so this is a lot of

00:06:59,710 --> 00:07:07,330
unit BRE VA so this is that original

00:07:04,990 --> 00:07:09,880
input we looked at and these are the the

00:07:07,330 --> 00:07:13,140
tokens that were identified using

00:07:09,880 --> 00:07:16,150
looking for these for these targets and

00:07:13,140 --> 00:07:18,880
now we have other challenges which is

00:07:16,150 --> 00:07:21,670
one is that we have affiliation strings

00:07:18,880 --> 00:07:27,790
with multiple targets so this one at the

00:07:21,670 --> 00:07:29,260
top is a laboratory in China it comes

00:07:27,790 --> 00:07:31,210
from the China Agricultural University

00:07:29,260 --> 00:07:34,930
which is the token that we're looking

00:07:31,210 --> 00:07:37,660
for here and the rest of these are

00:07:34,930 --> 00:07:39,310
things that we need to try and avoid or

00:07:37,660 --> 00:07:42,310
they're they might be candidate it would

00:07:39,310 --> 00:07:45,640
be called candidate tokens but in the

00:07:42,310 --> 00:07:48,250
first string we just want one in the

00:07:45,640 --> 00:07:48,880
second string we've got a few different

00:07:48,250 --> 00:07:50,950
things

00:07:48,880 --> 00:07:52,570
we've got Cavendish laboratory which

00:07:50,950 --> 00:07:55,600
sounds like it could be at a war

00:07:52,570 --> 00:07:57,640
appropriate level for Wars we've got

00:07:55,600 --> 00:08:00,520
Imperial College London and of course

00:07:57,640 --> 00:08:02,740
College is one of our targets but notice

00:08:00,520 --> 00:08:04,420
in this second string and the way that I

00:08:02,740 --> 00:08:06,870
highlighted this makes it a little bit

00:08:04,420 --> 00:08:09,630
difficult to see but there's actually

00:08:06,870 --> 00:08:12,640
affiliations for four authors here and

00:08:09,630 --> 00:08:14,920
the affiliation for two three and four

00:08:12,640 --> 00:08:17,440
have two three and four written in front

00:08:14,920 --> 00:08:20,170
of them but so this is the situation

00:08:17,440 --> 00:08:22,750
that occurs them in a lot of in a lot of

00:08:20,170 --> 00:08:26,410
these examples and people also write

00:08:22,750 --> 00:08:29,920
extraneous text like from the department

00:08:26,410 --> 00:08:31,900
of zoology or fall you know just

00:08:29,920 --> 00:08:33,580
extraneous labels if they're writing

00:08:31,900 --> 00:08:35,380
those labels because they understand

00:08:33,580 --> 00:08:37,150
that labeling things is good and it's

00:08:35,380 --> 00:08:38,410
generally a good practice but

00:08:37,150 --> 00:08:40,120
unfortunately when you're trying to

00:08:38,410 --> 00:08:44,110
process a bunch of these things those

00:08:40,120 --> 00:08:47,830
labels can become difficult we're back

00:08:44,110 --> 00:08:50,800
to our data set so now we've got a bunch

00:08:47,830 --> 00:08:53,050
of affiliations like we recognized back

00:08:50,800 --> 00:08:54,460
here and now the question is how can we

00:08:53,050 --> 00:08:59,710
convert those to wars

00:08:54,460 --> 00:09:01,660
so warg RoR org has a nice API for

00:08:59,710 --> 00:09:03,520
giving it a string or giving it other

00:09:01,660 --> 00:09:05,950
kinds of identifiers which is going to

00:09:03,520 --> 00:09:08,770
turn out to be pretty important giving

00:09:05,950 --> 00:09:13,360
it a string and getting search results

00:09:08,770 --> 00:09:17,080
so and there's also a a first pass that

00:09:13,360 --> 00:09:19,990
a reconciler for or that is compliant

00:09:17,080 --> 00:09:24,790
with refine so it's another approach so

00:09:19,990 --> 00:09:27,160
in many of those affiliation tokens that

00:09:24,790 --> 00:09:30,520
we talked about they in making an exact

00:09:27,160 --> 00:09:33,940
match so you can go against the the Roar

00:09:30,520 --> 00:09:35,770
API with a thing like the University of

00:09:33,940 --> 00:09:37,180
Arizona and you get something back

00:09:35,770 --> 00:09:39,850
that's called the University of

00:09:37,180 --> 00:09:41,140
organization and you get the roars in a

00:09:39,850 --> 00:09:42,970
lot of cases because of these

00:09:41,140 --> 00:09:46,090
differences in de limiters or these

00:09:42,970 --> 00:09:49,330
things that are piled together those

00:09:46,090 --> 00:09:50,470
matches are not quite so easy or it

00:09:49,330 --> 00:09:52,270
could be that some of those funny

00:09:50,470 --> 00:09:54,280
characters are at different places in

00:09:52,270 --> 00:09:57,130
the words unfortunately it doesn't seem

00:09:54,280 --> 00:09:59,260
to be a systematic replacement in that

00:09:57,130 --> 00:10:01,960
case and those things of course came

00:09:59,260 --> 00:10:03,700
from cross craft for applause so so we

00:10:01,960 --> 00:10:07,240
want to keep them those of the strings

00:10:03,700 --> 00:10:10,630
we're searching for so in other cases

00:10:07,240 --> 00:10:13,960
you need to look at these affiliation

00:10:10,630 --> 00:10:16,840
tokens by month with a human brain at

00:10:13,960 --> 00:10:19,120
least in this first pass and try and say

00:10:16,840 --> 00:10:21,070
this this is not an exact match but it

00:10:19,120 --> 00:10:23,740
is a valid match so we have two kinds of

00:10:21,070 --> 00:10:27,040
matches either exact or valid and that

00:10:23,740 --> 00:10:28,720
gives us you're looking at this there's

00:10:27,040 --> 00:10:32,730
about this many exacts

00:10:28,720 --> 00:10:36,760
and about this many exacts or pallets so

00:10:32,730 --> 00:10:37,720
the results so far in a sample of the

00:10:36,760 --> 00:10:42,639
cross

00:10:37,720 --> 00:10:44,649
metadata we've got 8826 do eyes and of

00:10:42,639 --> 00:10:46,269
course those do eyes have publications

00:10:44,649 --> 00:10:48,610
they have multiple authors and some

00:10:46,269 --> 00:10:52,209
authors have multiple affiliations so

00:10:48,610 --> 00:10:54,129
the number of affiliations expands the

00:10:52,209 --> 00:10:55,480
number of affiliation tokens gets a

00:10:54,129 --> 00:10:57,279
little smaller in this case which is

00:10:55,480 --> 00:11:00,339
good we have eleven thousand of those

00:10:57,279 --> 00:11:03,610
and we're matching those up with 2500

00:11:00,339 --> 00:11:06,850
drawers so in this case of the do is we

00:11:03,610 --> 00:11:10,809
have 75 71 percent of that were able to

00:11:06,850 --> 00:11:12,879
assign Wars too and 65 percent of the

00:11:10,809 --> 00:11:16,180
authors that we actually have Wars and

00:11:12,879 --> 00:11:18,160
and those numbers grow in two ways we

00:11:16,180 --> 00:11:21,879
increased the number of that we

00:11:18,160 --> 00:11:24,459
know or we go through and look at the

00:11:21,879 --> 00:11:26,319
data and try and match things up at this

00:11:24,459 --> 00:11:28,689
point by hand by improving the

00:11:26,319 --> 00:11:30,939
algorithms that we're using in the

00:11:28,689 --> 00:11:36,180
Palast case we started with a smaller

00:11:30,939 --> 00:11:39,069
data set of 2,400 2,400 and 96 do is

00:11:36,180 --> 00:11:40,899
roughly you know seventy five hundred

00:11:39,069 --> 00:11:44,829
eighty five eighty six hundred

00:11:40,899 --> 00:11:46,990
affiliations and tokens and 1592 roars

00:11:44,829 --> 00:11:52,660
so in that case we actually have wars

00:11:46,990 --> 00:11:55,420
for 91 percent of the diys and 75

00:11:52,660 --> 00:11:58,300
percent of the authors I hoping I'm

00:11:55,420 --> 00:11:59,800
hoping that these numbers can improve of

00:11:58,300 --> 00:12:01,540
course there are a lot of affiliation

00:11:59,800 --> 00:12:03,699
strings there are there are some

00:12:01,540 --> 00:12:06,129
organizations that don't have roars on

00:12:03,699 --> 00:12:07,749
not very many of those but there's a lot

00:12:06,129 --> 00:12:10,050
of affiliation strings that don't

00:12:07,749 --> 00:12:15,040
actually include names of organizations

00:12:10,050 --> 00:12:16,420
there are addresses or random words you

00:12:15,040 --> 00:12:21,309
know there are some affiliation strings

00:12:16,420 --> 00:12:22,809
that our department and so we I don't

00:12:21,309 --> 00:12:25,990
think we'll get to a hundred percent on

00:12:22,809 --> 00:12:29,910
hoping that we can get like in the class

00:12:25,990 --> 00:12:32,439
case at least over 90 percent of the

00:12:29,910 --> 00:12:34,179
affiliations or the deal eyes with roars

00:12:32,439 --> 00:12:37,029
and of course this will improve as a

00:12:34,179 --> 00:12:39,370
function of time so future directions

00:12:37,029 --> 00:12:42,970
but what this project is really about is

00:12:39,370 --> 00:12:46,389
about the adoption of unambiguous

00:12:42,970 --> 00:12:48,699
identifiers in metadata systems and

00:12:46,389 --> 00:12:50,270
metadata repositories we know that we

00:12:48,699 --> 00:12:54,950
have a lot of metadata

00:12:50,270 --> 00:12:56,930
or in the case of the Dryad one that was

00:12:54,950 --> 00:12:59,839
one that didn't have information that we

00:12:56,930 --> 00:13:02,060
needed and we also have repositories

00:12:59,839 --> 00:13:04,820
that have affiliation information or

00:13:02,060 --> 00:13:07,160
they have human names but they don't

00:13:04,820 --> 00:13:08,779
have identifiers for those affiliations

00:13:07,160 --> 00:13:11,149
and they don't have things like orchids

00:13:08,779 --> 00:13:14,060
for those IDs how many people here know

00:13:11,149 --> 00:13:15,800
about CrossRef so cross Christ we'll

00:13:14,060 --> 00:13:19,820
talk about it in a minute it's got a

00:13:15,800 --> 00:13:23,470
hundred and ten million deal wise how

00:13:19,820 --> 00:13:26,810
many of you here know about orchids

00:13:23,470 --> 00:13:28,339
how many have orchids okay

00:13:26,810 --> 00:13:31,100
well it turns out that only nine percent

00:13:28,339 --> 00:13:33,950
of the records that are in crossref

00:13:31,100 --> 00:13:35,630
actually have orchids okay so there's a

00:13:33,950 --> 00:13:38,180
lot of lot of room for getting

00:13:35,630 --> 00:13:40,279
identifiers zin there something like

00:13:38,180 --> 00:13:42,230
thirteen percent of the records that are

00:13:40,279 --> 00:13:45,130
in cross growth have affiliations so

00:13:42,230 --> 00:13:48,800
we're trying to try and get get this

00:13:45,130 --> 00:13:51,020
attached a system to crossref and also

00:13:48,800 --> 00:13:53,480
today to cite for inserting these he's

00:13:51,020 --> 00:13:56,510
getting these identifiers in there so

00:13:53,480 --> 00:13:58,490
that we have a nothing there that we can

00:13:56,510 --> 00:14:00,230
demonstrate the benefits there's a lot

00:13:58,490 --> 00:14:01,940
of great talks there about helping

00:14:00,230 --> 00:14:05,209
people understand the benefits of

00:14:01,940 --> 00:14:06,589
various aspects of open science and

00:14:05,209 --> 00:14:10,720
helping people understand the benefits

00:14:06,589 --> 00:14:13,880
of unique and persistent identifiers for

00:14:10,720 --> 00:14:17,180
people organizations publications

00:14:13,880 --> 00:14:19,579
instruments algorithms locations etc

00:14:17,180 --> 00:14:24,860
helping people understand that requires

00:14:19,579 --> 00:14:26,750
having having some a critical mass that

00:14:24,860 --> 00:14:27,980
you can demonstrate the benefits so

00:14:26,750 --> 00:14:30,800
that's really what we're trying to start

00:14:27,980 --> 00:14:35,000
out with here many people here are and

00:14:30,800 --> 00:14:36,800
are familiar with open refine we there

00:14:35,000 --> 00:14:40,070
was a talk earlier about the carbon

00:14:36,800 --> 00:14:41,860
trees a great talk by Kerry mentioned

00:14:40,070 --> 00:14:44,930
openrefine

00:14:41,860 --> 00:14:46,610
it's a useful tool it's got a user

00:14:44,930 --> 00:14:49,399
interface is sort of challenging if you

00:14:46,610 --> 00:14:51,370
have large datasets and I need to look

00:14:49,399 --> 00:14:53,750
at try and learn the API for that

00:14:51,370 --> 00:14:56,440
assignment is here sitting in the back

00:14:53,750 --> 00:14:58,040
and us in this really bright colored

00:14:56,440 --> 00:15:01,130
checkered shirt

00:14:58,040 --> 00:15:03,140
Simon is a is a wiki data expert

00:15:01,130 --> 00:15:05,930
one that he's our first partner this

00:15:03,140 --> 00:15:09,080
week there may be others today and we

00:15:05,930 --> 00:15:11,870
still got options and he's adding war as

00:15:09,080 --> 00:15:13,670
a property to wiki data so what that

00:15:11,870 --> 00:15:16,810
means is that we can use the wiki data

00:15:13,670 --> 00:15:20,710
reconciler that's already built in to

00:15:16,810 --> 00:15:24,050
open refine and has existed and been

00:15:20,710 --> 00:15:26,690
evolved over the years to to reconcile

00:15:24,050 --> 00:15:30,410
all these names and then we can use we

00:15:26,690 --> 00:15:31,910
can just once we find a wiki data ID for

00:15:30,410 --> 00:15:33,890
somewhere in the station we can say give

00:15:31,910 --> 00:15:37,040
us the roar for this organization so

00:15:33,890 --> 00:15:39,380
that's going to be a huge change it will

00:15:37,040 --> 00:15:44,480
also allow us to connect to the existing

00:15:39,380 --> 00:15:46,640
Wiki Wikipedia pages for those

00:15:44,480 --> 00:15:48,290
organizations as landing pages for those

00:15:46,640 --> 00:15:53,860
organizations that's another cool thing

00:15:48,290 --> 00:15:55,910
at work and you know or Simon's got a

00:15:53,860 --> 00:15:58,660
ambitious schedule for that we hope to

00:15:55,910 --> 00:16:02,480
have it working during this month and

00:15:58,660 --> 00:16:04,820
this would be super cool and then also

00:16:02,480 --> 00:16:06,500
testing an implementation with more

00:16:04,820 --> 00:16:08,270
partners so we're looking for partners

00:16:06,500 --> 00:16:09,650
if they're here if some of you here are

00:16:08,270 --> 00:16:11,840
interested in this we'd love to work

00:16:09,650 --> 00:16:14,570
with you another nice thing about cross

00:16:11,840 --> 00:16:17,540
growth in this case is it has over

00:16:14,570 --> 00:16:20,290
12,000 numbers so if you're if even if

00:16:17,540 --> 00:16:22,760
you can only convince 1% of them that

00:16:20,290 --> 00:16:26,510
this is interesting and that's enough to

00:16:22,760 --> 00:16:28,690
up to keep us busy so I developed some

00:16:26,510 --> 00:16:32,150
tools just a little while ago for

00:16:28,690 --> 00:16:34,640
visualizing CrossRef metadata and in the

00:16:32,150 --> 00:16:38,450
upper right hand corner this is the

00:16:34,640 --> 00:16:40,910
percentage of records in CrossRef that

00:16:38,450 --> 00:16:43,780
have affiliations on the left is the

00:16:40,910 --> 00:16:47,420
Korean Society for plant biotechnology

00:16:43,780 --> 00:16:49,220
and the orange in here is data that's

00:16:47,420 --> 00:16:52,790
older than two years and the blue is

00:16:49,220 --> 00:16:54,860
data that is two years or less so this

00:16:52,790 --> 00:16:56,570
this drill in this case in the last two

00:16:54,860 --> 00:16:58,730
years has had a huge increase in the

00:16:56,570 --> 00:17:02,060
number of affiliations in their CrossRef

00:16:58,730 --> 00:17:04,040
metadata so I can use this analytic at

00:17:02,060 --> 00:17:06,030
looking at the metadata to identify

00:17:04,040 --> 00:17:07,530
potential partners who have I

00:17:06,030 --> 00:17:10,140
mostly Clou DML you know they've made

00:17:07,530 --> 00:17:12,569
some organizational decisions that have

00:17:10,140 --> 00:17:15,030
resulted in in increasing the number of

00:17:12,569 --> 00:17:16,560
affiliations in their metadata and so

00:17:15,030 --> 00:17:18,630
when you're trying to convince them that

00:17:16,560 --> 00:17:20,790
identifier as for those affiliations

00:17:18,630 --> 00:17:24,150
might be useful this is a good target

00:17:20,790 --> 00:17:26,100
audience on the right is him da we of

00:17:24,150 --> 00:17:31,530
enlisted view many of you know about him

00:17:26,100 --> 00:17:34,590
Davi yes no open publisher does 20,000

00:17:31,530 --> 00:17:35,940
articles a year roughly some maybe it's

00:17:34,590 --> 00:17:37,770
I think it's No maybe

00:17:35,940 --> 00:17:42,240
yeah I think it is 20,000 they have

00:17:37,770 --> 00:17:44,900
about 40,000 resources in crossref and

00:17:42,240 --> 00:17:48,240
you can see they have a long history of

00:17:44,900 --> 00:17:50,730
populating those those metadata records

00:17:48,240 --> 00:17:53,070
with affiliations so and they're also

00:17:50,730 --> 00:17:56,550
interested in open science and you can

00:17:53,070 --> 00:17:58,560
see because all around this report the

00:17:56,550 --> 00:18:01,190
the lines are close to a hundred percent

00:17:58,560 --> 00:18:04,320
they've got a lot of stuff and a lot of

00:18:01,190 --> 00:18:07,200
affiliations in do eyes so those are the

00:18:04,320 --> 00:18:11,460
kinds of groups that I'm looking to to

00:18:07,200 --> 00:18:13,910
try and partner in this work any

00:18:11,460 --> 00:18:13,910
questions

00:18:14,060 --> 00:18:21,239

YouTube URL: https://www.youtube.com/watch?v=O1aq0lNrrZ0


