Title: Hunter Owens -  CSVConf 2017
Publication date: 2017-06-04
Playlist: CSVConf 2017
Description: 
	Towards a Taxonomy of Government Data
Captions: 
	00:00:00,180 --> 00:00:11,160
[Music]

00:00:06,649 --> 00:00:14,880
everybody can you all hear me awesome

00:00:11,160 --> 00:00:17,690
so as mentioned my name is hunter Owens

00:00:14,880 --> 00:00:20,550
I work for the city of Los Angeles and

00:00:17,690 --> 00:00:23,130
this talk is towards a taxonomy of

00:00:20,550 --> 00:00:24,900
government data which thankfully I got

00:00:23,130 --> 00:00:26,189
scheduled pretty late in the conference

00:00:24,900 --> 00:00:29,310
I think we've heard a lot about a lot of

00:00:26,189 --> 00:00:30,929
government data the last 36 hours or so

00:00:29,310 --> 00:00:33,899
so now we can hopefully all categorize

00:00:30,929 --> 00:00:37,559
it just a little background about myself

00:00:33,899 --> 00:00:40,680
I'm a data scientist for the city of LA

00:00:37,559 --> 00:00:42,360
prior to joining the city I worked at

00:00:40,680 --> 00:00:44,190
the impact lab which is a consultancy

00:00:42,360 --> 00:00:45,480
for social sector organizations

00:00:44,190 --> 00:00:47,789
including mostly governments and

00:00:45,480 --> 00:00:49,530
educational institutions the data

00:00:47,789 --> 00:00:51,930
science for social good fellowship I

00:00:49,530 --> 00:00:54,239
worked there for a while keep me Jersey

00:00:51,930 --> 00:00:56,579
I helped work on projects with a charter

00:00:54,239 --> 00:00:57,989
school district in Newark and when I

00:00:56,579 --> 00:00:59,340
used to live in Chicago I was at shack

00:00:57,989 --> 00:01:01,379
night a lot and now that I live in LA

00:00:59,340 --> 00:01:03,059
I'm a hack for LA go to your local over

00:01:01,379 --> 00:01:05,010
did do cool data projects I highly

00:01:03,059 --> 00:01:06,869
highly endorse them and get to play with

00:01:05,010 --> 00:01:10,260
lots of fun and interesting government

00:01:06,869 --> 00:01:12,360
data so when I tell people I work as a

00:01:10,260 --> 00:01:15,200
data scientist for the city this is what

00:01:12,360 --> 00:01:17,700
they think I do which have these massive

00:01:15,200 --> 00:01:19,350
categorized tables full of all of

00:01:17,700 --> 00:01:21,240
everybody's your speeding tickets your

00:01:19,350 --> 00:01:23,670
potholes when your trash got picked up

00:01:21,240 --> 00:01:26,280
did you pay your taxes on time and I can

00:01:23,670 --> 00:01:28,439
be like you did not pay your taxes on

00:01:26,280 --> 00:01:29,939
time and you have three parking

00:01:28,439 --> 00:01:33,509
violations on the record and that is not

00:01:29,939 --> 00:01:37,860
true what I actually do is dis send

00:01:33,509 --> 00:01:40,290
follow-up emails all the time trying to

00:01:37,860 --> 00:01:43,250
figure out how was this data collected

00:01:40,290 --> 00:01:46,710
does it even exist why was it collected

00:01:43,250 --> 00:01:48,090
who maintains it who has it was some

00:01:46,710 --> 00:01:51,299
vendor in charge of it did somebody

00:01:48,090 --> 00:01:53,009
retire at the city we have a huge wave

00:01:51,299 --> 00:01:57,469
of retirements so literally people are

00:01:53,009 --> 00:02:00,060
walking out of the door with data so

00:01:57,469 --> 00:02:01,590
what I end up having do a lot of the

00:02:00,060 --> 00:02:03,000
times is start to think about what

00:02:01,590 --> 00:02:04,799
assumptions can I make about this

00:02:03,000 --> 00:02:05,969
problem when somebody comes to me and

00:02:04,799 --> 00:02:07,409
says hunter we'd like to do something

00:02:05,969 --> 00:02:09,390
about affordability of rental housing

00:02:07,409 --> 00:02:12,629
that great so what data might exist

00:02:09,390 --> 00:02:13,330
about it and what's useful to know is

00:02:12,629 --> 00:02:17,440
how

00:02:13,330 --> 00:02:19,840
taxonomy sort of heuristic for what data

00:02:17,440 --> 00:02:21,940
is good what data is bad where it might

00:02:19,840 --> 00:02:24,700
exist so you have these sort of

00:02:21,940 --> 00:02:27,100
universal set of problems that you see

00:02:24,700 --> 00:02:28,330
actually quick questions before I get in

00:02:27,100 --> 00:02:30,490
a little how many of you in the room

00:02:28,330 --> 00:02:32,260
work for a government or funded by a

00:02:30,490 --> 00:02:36,160
government how many of you are

00:02:32,260 --> 00:02:37,180
journalists librarians because I think

00:02:36,160 --> 00:02:38,800
there are a lot of you here yet

00:02:37,180 --> 00:02:41,410
librarians are awesome thank you all for

00:02:38,800 --> 00:02:44,650
coming and listening to me I do not know

00:02:41,410 --> 00:02:47,350
what you guys know more about this than

00:02:44,650 --> 00:02:49,330
I do but

00:02:47,350 --> 00:02:51,400
and then finally who has used a

00:02:49,330 --> 00:02:52,900
government data set in this room hi

00:02:51,400 --> 00:02:54,250
that's a good answer I wanted I need

00:02:52,900 --> 00:02:57,910
full commitment of your mind body and

00:02:54,250 --> 00:02:59,590
personal brand to this talk so who is

00:02:57,910 --> 00:03:01,390
asked these questions before these are

00:02:59,590 --> 00:03:03,100
sort of these common sort of questions

00:03:01,390 --> 00:03:05,920
that we asked about how do I get it who

00:03:03,100 --> 00:03:09,220
maintains it what about these all these

00:03:05,920 --> 00:03:13,060
you know I saw talk was every home in DC

00:03:09,220 --> 00:03:15,370
was built in 1990 i mean i sorry 1900

00:03:13,060 --> 00:03:17,140
because that's when they started

00:03:15,370 --> 00:03:20,800
counting oh this is an old building so

00:03:17,140 --> 00:03:22,810
it's just built in 1900 so those sort of

00:03:20,800 --> 00:03:25,090
weird outliers exist and you have to

00:03:22,810 --> 00:03:26,980
constantly figure out all these problems

00:03:25,090 --> 00:03:30,100
before you can do an analysis make a

00:03:26,980 --> 00:03:32,920
visualization build a report do any sort

00:03:30,100 --> 00:03:36,700
of thing with data because you're often

00:03:32,920 --> 00:03:38,580
not the one who collected it so I think

00:03:36,700 --> 00:03:41,950
we all need to think like biologists

00:03:38,580 --> 00:03:45,300
Carl Linnaeus proposed a system of

00:03:41,950 --> 00:03:48,550
mapping the Tree of Life all biological

00:03:45,300 --> 00:03:50,200
things from bacteria to human beings are

00:03:48,550 --> 00:03:53,530
somehow related to each other in a

00:03:50,200 --> 00:03:55,330
taxonomy this is those cladograms you

00:03:53,530 --> 00:04:00,250
have to do in seventh grade biology

00:03:55,330 --> 00:04:02,440
class they look like this these are

00:04:00,250 --> 00:04:05,440
actually really really useful tools for

00:04:02,440 --> 00:04:08,080
us because they organize our practice of

00:04:05,440 --> 00:04:09,580
work of investigating government data

00:04:08,080 --> 00:04:12,100
because that's what we all are doing

00:04:09,580 --> 00:04:15,459
we're playing detective before we can do

00:04:12,100 --> 00:04:17,530
anything else it helps us figure out

00:04:15,459 --> 00:04:22,210
what possible pitfalls there are with

00:04:17,530 --> 00:04:23,860
this data so in my experience I played

00:04:22,210 --> 00:04:26,710
with a lot of government data but I'm

00:04:23,860 --> 00:04:29,130
going to propose four main branch

00:04:26,710 --> 00:04:32,229
is of government data descriptive data

00:04:29,130 --> 00:04:36,039
programmatic data evaluative data and

00:04:32,229 --> 00:04:42,370
not data and seriously that's a real

00:04:36,039 --> 00:04:44,080
category these are proposed please

00:04:42,370 --> 00:04:46,810
argue with me in a question and answer

00:04:44,080 --> 00:04:48,819
section I'm not wedded to these in any

00:04:46,810 --> 00:04:51,699
way but I'm suggesting this will be

00:04:48,819 --> 00:04:53,349
useful for all of us as a community to

00:04:51,699 --> 00:04:56,139
use to understand how governments

00:04:53,349 --> 00:04:58,300
collect and use data first category

00:04:56,139 --> 00:05:00,370
descriptive data this is your bread and

00:04:58,300 --> 00:05:02,259
butter government data it's going to use

00:05:00,370 --> 00:05:04,990
your census it's your parcel shapefiles

00:05:02,259 --> 00:05:07,240
it's your voter records and it describes

00:05:04,990 --> 00:05:09,250
a feature of the government unit it's

00:05:07,240 --> 00:05:11,919
frequently released in like a website or

00:05:09,250 --> 00:05:15,849
a formal package it's mandated often by

00:05:11,919 --> 00:05:17,440
law do you know how much the government

00:05:15,849 --> 00:05:20,979
values the census it's in the

00:05:17,440 --> 00:05:22,780
Constitution you cannot avoid a definite

00:05:20,979 --> 00:05:25,120
ending all census it's so important to

00:05:22,780 --> 00:05:27,789
how the government functions voter

00:05:25,120 --> 00:05:29,590
records you know those are such a key

00:05:27,789 --> 00:05:32,500
part so this descriptive data is often

00:05:29,590 --> 00:05:35,650
the easiest lowest hanging fruit of open

00:05:32,500 --> 00:05:38,740
data it's been around for forever our

00:05:35,650 --> 00:05:42,370
next category is programmatic data these

00:05:38,740 --> 00:05:44,560
are byproducts of government programs in

00:05:42,370 --> 00:05:46,900
my line of work we have the information

00:05:44,560 --> 00:05:51,360
systems which is local government so I

00:05:46,900 --> 00:05:56,969
can tell you there is him bim's HMIS

00:05:51,360 --> 00:05:58,870
Tim's themes Zemus which are all

00:05:56,969 --> 00:06:02,560
information systems that describe

00:05:58,870 --> 00:06:04,180
housing yeah so that's housing

00:06:02,560 --> 00:06:05,440
information management system building

00:06:04,180 --> 00:06:07,300
information incentives

00:06:05,440 --> 00:06:09,099
homelessness management information

00:06:07,300 --> 00:06:10,599
system which is all where the house

00:06:09,099 --> 00:06:12,820
you're homeless people not the actual

00:06:10,599 --> 00:06:14,409
database for of homeless people that the

00:06:12,820 --> 00:06:16,240
our vendor assumed that we were

00:06:14,409 --> 00:06:19,180
collecting it was a fun conversation I

00:06:16,240 --> 00:06:21,250
had and these are full of errors

00:06:19,180 --> 00:06:24,550
compared to our official record data

00:06:21,250 --> 00:06:26,860
like who voted which we kind of assume

00:06:24,550 --> 00:06:28,900
is not full of errors or the census

00:06:26,860 --> 00:06:31,180
which has very cleanly documented error

00:06:28,900 --> 00:06:33,190
rates they tell you exactly what's wrong

00:06:31,180 --> 00:06:35,770
with it you look you go into ACS data

00:06:33,190 --> 00:06:39,070
and has like plus or minus these are

00:06:35,770 --> 00:06:40,540
used to run a government program so for

00:06:39,070 --> 00:06:43,600
example we use

00:06:40,540 --> 00:06:46,570
HM is to keep track of who's using

00:06:43,600 --> 00:06:48,580
shelters in all of LA County actually

00:06:46,570 --> 00:06:50,950
every single jurisdiction in this

00:06:48,580 --> 00:06:52,450
country has an HMIS system it's mandated

00:06:50,950 --> 00:06:54,670
by the federal government as part of

00:06:52,450 --> 00:06:56,470
receiving housing and urban development

00:06:54,670 --> 00:06:58,450
funds so if you are interested in

00:06:56,470 --> 00:07:00,010
homelessness data and sort of who's

00:06:58,450 --> 00:07:02,500
using shelters that's where you can go

00:07:00,010 --> 00:07:05,530
look obviously a lot of it has PII

00:07:02,500 --> 00:07:08,380
concerns so be careful what you ask for

00:07:05,530 --> 00:07:11,200
but the key thing about this is one the

00:07:08,380 --> 00:07:14,230
data has a vector of much more closer to

00:07:11,200 --> 00:07:15,670
real time than our descriptive data our

00:07:14,230 --> 00:07:18,280
descriptive data is collected as a

00:07:15,670 --> 00:07:19,930
reporting period they say how often it's

00:07:18,280 --> 00:07:22,750
going to be collected this is collected

00:07:19,930 --> 00:07:27,280
in effectively real time to describe our

00:07:22,750 --> 00:07:30,220
program our next category is evaluative

00:07:27,280 --> 00:07:34,360
data um who among you comes from a

00:07:30,220 --> 00:07:37,720
public policy background anybody read a

00:07:34,360 --> 00:07:39,220
lot of public policy papers you can see

00:07:37,720 --> 00:07:41,140
that they have these magically clean

00:07:39,220 --> 00:07:42,880
data sets that I wonder how they created

00:07:41,140 --> 00:07:45,790
them where they've got like well the

00:07:42,880 --> 00:07:47,710
cross-reference census data with number

00:07:45,790 --> 00:07:50,670
of new construction permits issued in

00:07:47,710 --> 00:07:52,240
three census blocks you see a

00:07:50,670 --> 00:07:54,580
relationship between these two

00:07:52,240 --> 00:07:59,050
particular features or if you see how

00:07:54,580 --> 00:08:00,430
many people boarded the bus against how

00:07:59,050 --> 00:08:02,800
many people were driving to work and

00:08:00,430 --> 00:08:06,520
they have these really nice clean data

00:08:02,800 --> 00:08:08,530
frames so what I argue that this type of

00:08:06,520 --> 00:08:11,440
data that is frequently used for the

00:08:08,530 --> 00:08:14,170
policy and evaluation of policy tools is

00:08:11,440 --> 00:08:15,610
actually even though it may have existed

00:08:14,170 --> 00:08:17,620
originally as programmatic or

00:08:15,610 --> 00:08:20,440
descriptions it is a new form of data

00:08:17,620 --> 00:08:23,770
that is used in the government realm to

00:08:20,440 --> 00:08:26,380
determine how we make policy it's

00:08:23,770 --> 00:08:27,790
generally used created once if you ever

00:08:26,380 --> 00:08:29,290
ask a public policy for something like

00:08:27,790 --> 00:08:32,760
great it's been three years since we did

00:08:29,290 --> 00:08:35,800
your study on like bus route

00:08:32,760 --> 00:08:38,770
optimization see in Greater downtown

00:08:35,800 --> 00:08:40,570
Portland and you ask them to rerun it

00:08:38,770 --> 00:08:44,710
it's a total mess because they've been

00:08:40,570 --> 00:08:46,660
playing around in Excel for so long

00:08:44,710 --> 00:08:48,600
there's actually a fairly famous thing

00:08:46,660 --> 00:08:51,700
this is also a problem in economics

00:08:48,600 --> 00:08:53,290
where the rhein are Rogoff paper which

00:08:51,700 --> 00:08:56,170
was fairly important in

00:08:53,290 --> 00:08:58,149
anyhow we left the financial crisis they

00:08:56,170 --> 00:09:01,930
copied and pasted a line into their main

00:08:58,149 --> 00:09:04,269
Excel model off one they put it down one

00:09:01,930 --> 00:09:06,399
row rather than putting it in the state

00:09:04,269 --> 00:09:08,529
in the header row so they actually

00:09:06,399 --> 00:09:10,540
assumed a link between a country's debt

00:09:08,529 --> 00:09:12,040
and the ability to escape a recession

00:09:10,540 --> 00:09:15,339
where there wasn't actually a

00:09:12,040 --> 00:09:18,519
correlative link this was is the Excel

00:09:15,339 --> 00:09:19,870
area that changed the world if you fund

00:09:18,519 --> 00:09:22,149
story if you ever want to read into it

00:09:19,870 --> 00:09:24,550
and it's a good reason to be very very

00:09:22,149 --> 00:09:25,959
skeptical of Excel so make sure to

00:09:24,550 --> 00:09:29,139
double check when you're copying and

00:09:25,959 --> 00:09:32,019
pasting and the final category is not

00:09:29,139 --> 00:09:34,569
data which is to say government

00:09:32,019 --> 00:09:36,339
employees do not view this type of data

00:09:34,569 --> 00:09:38,889
that you and I would met in this

00:09:36,339 --> 00:09:41,230
community would see as data as data at

00:09:38,889 --> 00:09:43,899
all it's actually just this weird

00:09:41,230 --> 00:09:46,660
exhaust by-product it's often you'll

00:09:43,899 --> 00:09:49,269
need to make an inference about whether

00:09:46,660 --> 00:09:51,970
it's data or not so to give an example

00:09:49,269 --> 00:09:56,009
of that from my personal line of work is

00:09:51,970 --> 00:09:59,980
at SAC this is at SAC who sees data here

00:09:56,009 --> 00:10:01,930
anybody this is all the traffic control

00:09:59,980 --> 00:10:04,449
signals for the entirety of Los Angeles

00:10:01,930 --> 00:10:06,579
you could shut down LA if this room

00:10:04,449 --> 00:10:10,240
stopped existing because the street

00:10:06,579 --> 00:10:11,860
lights would not change so what we've

00:10:10,240 --> 00:10:13,329
discovered here is in the original

00:10:11,860 --> 00:10:15,930
implementation of the app pack program

00:10:13,329 --> 00:10:18,760
it does not collect recorded data on

00:10:15,930 --> 00:10:20,350
when lights are changing or not which

00:10:18,760 --> 00:10:23,709
means it's hard to do any sort of

00:10:20,350 --> 00:10:25,630
optimization making traffic flow faster

00:10:23,709 --> 00:10:27,850
so what we've started to argue in the

00:10:25,630 --> 00:10:29,199
not data category is this is when you

00:10:27,850 --> 00:10:30,850
can be brought into the program to say

00:10:29,199 --> 00:10:34,000
this is the data we should be collecting

00:10:30,850 --> 00:10:36,279
this is what's useful for us to have

00:10:34,000 --> 00:10:38,439
another example is street sweeping

00:10:36,279 --> 00:10:42,430
routes those are actually not digitized

00:10:38,439 --> 00:10:44,110
in the city yet they're just mandated so

00:10:42,430 --> 00:10:46,630
we're working on digitizing those those

00:10:44,110 --> 00:10:48,699
have been passed down from sign sign

00:10:46,630 --> 00:10:50,620
vendor to sign vendors so one of the

00:10:48,699 --> 00:10:52,389
categories you'll often see in working

00:10:50,620 --> 00:10:54,550
with government data is if you ask a

00:10:52,389 --> 00:10:56,230
pretty basic question is like it's

00:10:54,550 --> 00:10:58,180
actually not been collected before so

00:10:56,230 --> 00:11:03,220
that's your opportunity to advocate for

00:10:58,180 --> 00:11:05,800
its collection and optimization now when

00:11:03,220 --> 00:11:07,020
I when you encounter a question like

00:11:05,800 --> 00:11:08,850
what is housing

00:11:07,020 --> 00:11:10,500
like what or in the federal level like

00:11:08,850 --> 00:11:12,480
how is the economy doing you know these

00:11:10,500 --> 00:11:14,160
big sort of meta questions that you may

00:11:12,480 --> 00:11:16,020
be asked as part of your job

00:11:14,160 --> 00:11:17,400
so librarian as a researcher as a

00:11:16,020 --> 00:11:20,610
journalist like you want to investigate

00:11:17,400 --> 00:11:22,440
a certain subject ah the key to starting

00:11:20,610 --> 00:11:24,240
to taxonomy is it into one of these four

00:11:22,440 --> 00:11:26,430
categories to ask your basic questions

00:11:24,240 --> 00:11:28,950
who collected this data why was it

00:11:26,430 --> 00:11:30,690
collected was it legally mandated look

00:11:28,950 --> 00:11:32,150
for legal mandates of data collection

00:11:30,690 --> 00:11:34,830
this is how you can often find

00:11:32,150 --> 00:11:36,660
interesting time series data it's like

00:11:34,830 --> 00:11:38,610
again going back to my example of HMIS

00:11:36,660 --> 00:11:40,380
it's because the federal government has

00:11:38,610 --> 00:11:42,840
mandated for 20 years that we keep track

00:11:40,380 --> 00:11:44,970
in a database of who is sleeping in

00:11:42,840 --> 00:11:49,980
shelter beds every night

00:11:44,970 --> 00:11:52,470
also look for your vendors often going

00:11:49,980 --> 00:11:54,510
back to the example of a GTFS Google

00:11:52,470 --> 00:11:56,910
Transit feed specification like a lot of

00:11:54,510 --> 00:11:59,490
bus real-time bus data comes from one

00:11:56,910 --> 00:12:01,500
particular vendor that puts the GPS

00:11:59,490 --> 00:12:02,760
sensor in the bus and if you can see

00:12:01,500 --> 00:12:04,530
that your metro agency has a

00:12:02,760 --> 00:12:07,170
relationship with that vendor you can go

00:12:04,530 --> 00:12:10,170
after that data so let's take an example

00:12:07,170 --> 00:12:12,750
is anybody in the education data world

00:12:10,170 --> 00:12:15,000
in this room anybody awesome I was glad

00:12:12,750 --> 00:12:15,480
got one so you might have seen this

00:12:15,000 --> 00:12:18,990
before

00:12:15,480 --> 00:12:22,860
forgive me this is a local example so

00:12:18,990 --> 00:12:24,840
this is called the nwea map education

00:12:22,860 --> 00:12:28,680
and government data love's abbreviation

00:12:24,840 --> 00:12:30,540
some anon practice Northwest educators

00:12:28,680 --> 00:12:33,720
association measures of academic

00:12:30,540 --> 00:12:35,930
progress this is an exam that is issued

00:12:33,720 --> 00:12:38,880
to students in last time I checked

00:12:35,930 --> 00:12:42,750
fifteen or sixteen states and it's one

00:12:38,880 --> 00:12:46,020
of the three main formative assessments

00:12:42,750 --> 00:12:49,440
that you see handed out every time so if

00:12:46,020 --> 00:12:53,040
you get map data I don't actually I'm

00:12:49,440 --> 00:12:54,750
not showing you the real actual data but

00:12:53,040 --> 00:12:56,220
this is basically what it looks like so

00:12:54,750 --> 00:13:00,330
you see certain things you'd expect

00:12:56,220 --> 00:13:03,060
school ID student ID for the winter

00:13:00,330 --> 00:13:05,100
observed growth fall to spring observed

00:13:03,060 --> 00:13:08,700
growth winter to spring so you know it's

00:13:05,100 --> 00:13:11,970
like basically it's a test that's issued

00:13:08,700 --> 00:13:13,890
twice or twice a year in the fall and in

00:13:11,970 --> 00:13:16,350
the spring and they give out these

00:13:13,890 --> 00:13:18,330
things called RIT scores and goal ones

00:13:16,350 --> 00:13:19,560
and goals twos which are your progress

00:13:18,330 --> 00:13:20,970
in certain

00:13:19,560 --> 00:13:24,300
measures of learning you can look into

00:13:20,970 --> 00:13:26,340
all this sort of nuances of the NWA math

00:13:24,300 --> 00:13:29,100
exam but how can we make some quick

00:13:26,340 --> 00:13:31,080
assumptions about the NWA map to say

00:13:29,100 --> 00:13:34,920
this is the type of analysis we could do

00:13:31,080 --> 00:13:38,070
with this data if we had it so you can

00:13:34,920 --> 00:13:40,380
know it's mandated by reporting laws or

00:13:38,070 --> 00:13:42,720
contracts with particular charter school

00:13:40,380 --> 00:13:45,000
organizations so you'll have it for

00:13:42,720 --> 00:13:46,650
every year it will cover every student

00:13:45,000 --> 00:13:49,320
you don't have to look for

00:13:46,650 --> 00:13:50,610
oh it's missing like these three you

00:13:49,320 --> 00:13:52,050
know it's missing half the schools in

00:13:50,610 --> 00:13:53,339
New Jersey no because like the state of

00:13:52,050 --> 00:13:55,890
New Jersey require or the state of

00:13:53,339 --> 00:13:57,390
Oregon requires every student in certain

00:13:55,890 --> 00:13:58,650
grades to take the map so you can say

00:13:57,390 --> 00:14:01,400
like now we have an assumption about

00:13:58,650 --> 00:14:03,930
this data that is fairly useful to use

00:14:01,400 --> 00:14:05,940
we know the frequency is mandated by

00:14:03,930 --> 00:14:08,550
this law and we know it's a formative

00:14:05,940 --> 00:14:11,070
assessment so we can assume that it is

00:14:08,550 --> 00:14:12,420
used as an evaluative data set because

00:14:11,070 --> 00:14:14,550
it's only issued it's not your

00:14:12,420 --> 00:14:15,690
programmatic data that's what if you're

00:14:14,550 --> 00:14:17,730
if you're in a school district you're

00:14:15,690 --> 00:14:21,120
going to have your evaluative data how

00:14:17,730 --> 00:14:23,160
do you do your evaluations teacher

00:14:21,120 --> 00:14:24,780
evaluations how do you meet your

00:14:23,160 --> 00:14:26,339
standards and reporting requirements so

00:14:24,780 --> 00:14:28,880
that's your test scores and then you

00:14:26,339 --> 00:14:31,020
have your programmatic data which is

00:14:28,880 --> 00:14:33,690
which students are enrolled in which

00:14:31,020 --> 00:14:35,100
class how many of them get free and

00:14:33,690 --> 00:14:36,960
reduced-price lunch and that's going to

00:14:35,100 --> 00:14:39,360
be stored in a separate system called a

00:14:36,960 --> 00:14:42,089
SAS is which is a student information

00:14:39,360 --> 00:14:44,790
system they're like the secret Kingdom

00:14:42,089 --> 00:14:46,920
keys to school and if every every movie

00:14:44,790 --> 00:14:48,900
you've seen where some kid hacks his way

00:14:46,920 --> 00:14:51,900
into the school's mainframe and like

00:14:48,900 --> 00:14:54,420
resets all his grades to an A or her

00:14:51,900 --> 00:15:00,240
grade it's generally he cuz pop culture

00:14:54,420 --> 00:15:03,209
in Hollywood I'm sorry those uh those

00:15:00,240 --> 00:15:05,970
are FIS systems there's one big vendor

00:15:03,209 --> 00:15:08,250
called power school they actually own 23

00:15:05,970 --> 00:15:09,930
percent of the grades issued by high

00:15:08,250 --> 00:15:13,950
schools in the United States and they're

00:15:09,930 --> 00:15:15,540
it's legally theirs it's weird run up

00:15:13,950 --> 00:15:17,640
into that License Agreement but anyways

00:15:15,540 --> 00:15:19,170
now we know this is an evaluative data

00:15:17,640 --> 00:15:20,790
system and we've been able to make

00:15:19,170 --> 00:15:23,820
certain assumptions about it which means

00:15:20,790 --> 00:15:25,650
that when we would if you have to walk

00:15:23,820 --> 00:15:28,020
into a project in the education space

00:15:25,650 --> 00:15:29,670
with no knowledge come back you've been

00:15:28,020 --> 00:15:31,050
able to make some fairly decent

00:15:29,670 --> 00:15:33,480
assumptions about what data you're

00:15:31,050 --> 00:15:36,490
looking at pretty quickly

00:15:33,480 --> 00:15:38,740
so I think the crucial thing to starting

00:15:36,490 --> 00:15:41,529
these taxonomy these data sets is to

00:15:38,740 --> 00:15:44,320
make a flow diagram of how the data was

00:15:41,529 --> 00:15:46,329
collected what steps were taken who's

00:15:44,320 --> 00:15:48,459
collecting it where did it go

00:15:46,329 --> 00:15:52,269
so make these diagrams they're fairly

00:15:48,459 --> 00:15:54,459
useful and now I want to talk about how

00:15:52,269 --> 00:15:56,949
you start to see the evolutions of these

00:15:54,459 --> 00:15:58,240
systems I proposed this taxonomy but I

00:15:56,949 --> 00:16:02,350
want to say where all the systems come

00:15:58,240 --> 00:16:03,970
from so in California I apologize for

00:16:02,350 --> 00:16:06,160
the California centric nature of this

00:16:03,970 --> 00:16:08,649
talk and the Californian so it's but

00:16:06,160 --> 00:16:12,149
there are equivalent laws on the books

00:16:08,649 --> 00:16:15,399
in a lot of states but this is SB 272

00:16:12,149 --> 00:16:17,320
the California Public Records Act local

00:16:15,399 --> 00:16:19,690
agencies : inventory

00:16:17,320 --> 00:16:23,019
sounds like a super interesting law

00:16:19,690 --> 00:16:25,300
everybody wants to read right all right

00:16:23,019 --> 00:16:27,490
this law mandates that every government

00:16:25,300 --> 00:16:30,579
body in California so whether it's a

00:16:27,490 --> 00:16:32,980
metro a local government a county

00:16:30,579 --> 00:16:36,399
government a school board a water

00:16:32,980 --> 00:16:38,680
district has to categorize every single

00:16:36,399 --> 00:16:41,260
database they have and what data is

00:16:38,680 --> 00:16:44,290
collected in those databases so we get

00:16:41,260 --> 00:16:47,680
something like this this is the LA

00:16:44,290 --> 00:16:49,329
County Enterprise Systems catalog which

00:16:47,680 --> 00:16:50,769
is published on their open data portal

00:16:49,329 --> 00:16:52,000
some of these some of these agencies

00:16:50,769 --> 00:16:54,399
don't publish this on an open data

00:16:52,000 --> 00:16:57,069
portal but you can ask for their SB 272

00:16:54,399 --> 00:16:58,839
compliance form so you can see we've got

00:16:57,069 --> 00:17:00,639
like Department the enterprise system

00:16:58,839 --> 00:17:02,529
name why is the data collected what's

00:17:00,639 --> 00:17:03,850
the frequency the data is all the

00:17:02,529 --> 00:17:05,770
information we need to fit it into a

00:17:03,850 --> 00:17:08,520
taxonomy of whether it's being used

00:17:05,770 --> 00:17:10,780
programmatically evaluative lis

00:17:08,520 --> 00:17:12,339
descriptively or it's not even being

00:17:10,780 --> 00:17:14,530
used with data system those ones don't

00:17:12,339 --> 00:17:17,079
really fit into this category so we can

00:17:14,530 --> 00:17:18,610
take a look into this some of the super

00:17:17,079 --> 00:17:22,179
interesting data systems that pop up in

00:17:18,610 --> 00:17:24,880
here is the ALPR systems does anybody

00:17:22,179 --> 00:17:26,559
know what the ALPR systems are those are

00:17:24,880 --> 00:17:29,260
the ones that read your license plates

00:17:26,559 --> 00:17:35,530
from police cameras so you can start to

00:17:29,260 --> 00:17:36,820
see like what exact data that the city

00:17:35,530 --> 00:17:39,730
and the condition of the LA County

00:17:36,820 --> 00:17:42,460
Sheriff's Office is collecting license

00:17:39,730 --> 00:17:43,990
plate recognitions on ok this is a

00:17:42,460 --> 00:17:46,320
stolen car we can look it up and see

00:17:43,990 --> 00:17:48,029
when it's been caught you know with

00:17:46,320 --> 00:17:50,039
in certain area so you can see exactly

00:17:48,029 --> 00:17:52,470
whether use but then you can also see

00:17:50,039 --> 00:17:55,139
stuff that is a little bit more prosaic

00:17:52,470 --> 00:17:57,120
the absence management system that's

00:17:55,139 --> 00:17:59,159
keeping track of which employees are in

00:17:57,120 --> 00:18:02,279
the office or not at the Department of

00:17:59,159 --> 00:18:03,899
the Human Resources office and this is

00:18:02,279 --> 00:18:05,850
just the first 10 lines of this data set

00:18:03,899 --> 00:18:07,200
and I'm sure some of you have ideas on

00:18:05,850 --> 00:18:10,230
what you'd want to do with this data

00:18:07,200 --> 00:18:12,450
it's pretty interesting stuff the other

00:18:10,230 --> 00:18:14,309
way to determine where data is collected

00:18:12,450 --> 00:18:17,100
and why it's being collected is to

00:18:14,309 --> 00:18:19,500
follow the budget your budget is your

00:18:17,100 --> 00:18:21,600
secret data portal it's got all the

00:18:19,500 --> 00:18:23,269
information about spending and which

00:18:21,600 --> 00:18:26,879
data systems you're implementing and

00:18:23,269 --> 00:18:30,059
where where priorities are being placed

00:18:26,879 --> 00:18:31,730
I have my favorite Joe Biden ISM here

00:18:30,059 --> 00:18:34,259
which is don't tell me what you value

00:18:31,730 --> 00:18:36,389
show me your budget and I will tell you

00:18:34,259 --> 00:18:39,120
what you value it is still the most

00:18:36,389 --> 00:18:42,779
useful quote I have heard to think about

00:18:39,120 --> 00:18:44,429
any government agency ever look at their

00:18:42,779 --> 00:18:45,710
budgets it will tell you what they care

00:18:44,429 --> 00:18:48,389
about ah

00:18:45,710 --> 00:18:50,759
so I wanted to leave some time for

00:18:48,389 --> 00:18:52,950
questions so I have a few takeaways

00:18:50,759 --> 00:18:54,720
taxonomies are good they help us define

00:18:52,950 --> 00:18:56,940
our problem space and make assumptions

00:18:54,720 --> 00:18:59,850
without having to like spend hours

00:18:56,940 --> 00:19:01,590
looking at individual data sets and tell

00:18:59,850 --> 00:19:03,659
us you know we can tell our superiors or

00:19:01,590 --> 00:19:05,009
we can tell our colleagues like what we

00:19:03,659 --> 00:19:06,960
think is possible with this data and

00:19:05,009 --> 00:19:11,009
what isn't without having to do a ton of

00:19:06,960 --> 00:19:12,629
work and this is a little guy through

00:19:11,009 --> 00:19:13,830
government data a little tour from

00:19:12,629 --> 00:19:18,809
somebody who has been on the inside for

00:19:13,830 --> 00:19:20,100
a little bit and then finally uh what I

00:19:18,809 --> 00:19:21,809
want us all to think about as a

00:19:20,100 --> 00:19:24,299
community is what is a more formal way

00:19:21,809 --> 00:19:26,580
of classifying government data based on

00:19:24,299 --> 00:19:29,970
known characteristics to argue for their

00:19:26,580 --> 00:19:31,470
similarity or dissimilarity I don't have

00:19:29,970 --> 00:19:34,019
an answer to that it's a really big

00:19:31,470 --> 00:19:37,950
question but I think it will be useful

00:19:34,019 --> 00:19:39,450
for this community moving forward to be

00:19:37,950 --> 00:19:41,669
able to say that there's a certain

00:19:39,450 --> 00:19:43,399
taxonomy of government data and certain

00:19:41,669 --> 00:19:46,150
things fit into different spaces and not

00:19:43,399 --> 00:19:48,210
so thank you

00:19:46,150 --> 00:19:48,210
you

00:19:49,650 --> 00:19:53,859

YouTube URL: https://www.youtube.com/watch?v=4M7v1COLckg


