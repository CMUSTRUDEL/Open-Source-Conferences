Title: Dare Anne Brawley - CSVConf 2017
Publication date: 2017-06-04
Playlist: CSVConf 2017
Description: 
	
Captions: 
	00:00:03,070 --> 00:00:07,210
so I currently work as a researcher at

00:00:05,529 --> 00:00:09,700
somewhere called the Center for spatial

00:00:07,210 --> 00:00:12,040
research at Columbia University we're

00:00:09,700 --> 00:00:13,299
housed within the Graduate School of

00:00:12,040 --> 00:00:16,330
Architecture planning and preservation

00:00:13,299 --> 00:00:18,730
within Columbia and I'll say that my

00:00:16,330 --> 00:00:21,070
work and training is grounded in the

00:00:18,730 --> 00:00:23,349
context of data-driven urban planning

00:00:21,070 --> 00:00:26,470
and policy with the focus on the ethics

00:00:23,349 --> 00:00:28,689
and politics of data visualization and

00:00:26,470 --> 00:00:31,689
much of my work both at the Center for

00:00:28,689 --> 00:00:33,580
Social Research and before explores the

00:00:31,689 --> 00:00:37,240
interplay between information landscapes

00:00:33,580 --> 00:00:39,250
and urban landscape so today I'm going

00:00:37,240 --> 00:00:41,560
to be talking about a project that I

00:00:39,250 --> 00:00:43,210
worked on a couple of years ago that I

00:00:41,560 --> 00:00:45,430
think speaks to many of the core

00:00:43,210 --> 00:00:48,820
challenges embedded in data-driven

00:00:45,430 --> 00:00:50,320
decision-making in urban environments it

00:00:48,820 --> 00:00:52,980
speaks to many of the challenging

00:00:50,320 --> 00:00:56,410
ethical issues often hidden behind

00:00:52,980 --> 00:00:57,640
data-driven urban and public policy and

00:00:56,410 --> 00:01:00,190
that I also think is a powerful

00:00:57,640 --> 00:01:02,230
illustration and reminder about the kind

00:01:00,190 --> 00:01:05,710
of abstraction that goes into making any

00:01:02,230 --> 00:01:07,509
and all data and I'll say that these

00:01:05,710 --> 00:01:09,609
kinds of considerations have a real

00:01:07,509 --> 00:01:13,299
urgency right now within the field of

00:01:09,609 --> 00:01:15,609
urban planning and design when it seems

00:01:13,299 --> 00:01:17,950
like every day there's a new proposal

00:01:15,609 --> 00:01:21,369
for how the city could be understood

00:01:17,950 --> 00:01:23,829
governed optimized insert your word here

00:01:21,369 --> 00:01:27,009
by algorithms with no democratic

00:01:23,829 --> 00:01:28,240
processes needed and so one of the

00:01:27,009 --> 00:01:30,249
things that I think is under discussed

00:01:28,240 --> 00:01:32,710
in a lot of these debates is the inputs

00:01:30,249 --> 00:01:34,390
the underlying data that's going into

00:01:32,710 --> 00:01:37,149
how were we supposed Lee making these

00:01:34,390 --> 00:01:39,369
decisions and in light of this I'm

00:01:37,149 --> 00:01:41,499
interested today about the ways that

00:01:39,369 --> 00:01:43,929
sources of data often invisibly and

00:01:41,499 --> 00:01:46,600
sometimes perniciously shape public

00:01:43,929 --> 00:01:50,530
policy through the methods behind their

00:01:46,600 --> 00:01:53,639
collections so I in this project I

00:01:50,530 --> 00:01:56,109
recently explored how data was used and

00:01:53,639 --> 00:01:58,149
created by state and corporate entities

00:01:56,109 --> 00:02:00,369
in the aftermath of the 2008 financial

00:01:58,149 --> 00:02:03,850
crisis I'll explain what this is in a

00:02:00,369 --> 00:02:06,189
minute and I focused especially on the

00:02:03,850 --> 00:02:07,929
role that imperfect data sets played in

00:02:06,189 --> 00:02:10,260
the dispersment of federal aid in

00:02:07,929 --> 00:02:12,490
response to the foreclosure crisis I

00:02:10,260 --> 00:02:14,470
threw this project I surveyed the

00:02:12,490 --> 00:02:15,430
patchwork of available sources of key

00:02:14,470 --> 00:02:17,590
information

00:02:15,430 --> 00:02:20,140
in order to look at what the foreclosure

00:02:17,590 --> 00:02:23,470
crisis reveals for how we've begun to

00:02:20,140 --> 00:02:27,040
use data to depict manage and intervene

00:02:23,470 --> 00:02:31,780
in urban environments the project's

00:02:27,040 --> 00:02:36,489
medium was maps 165 of them curated into

00:02:31,780 --> 00:02:39,459
an exhibit through these maps I created

00:02:36,489 --> 00:02:43,090
a time lapse cartographic portrait oops

00:02:39,459 --> 00:02:46,390
right of the rate of residential vacancy

00:02:43,090 --> 00:02:49,510
across the US and also in for case study

00:02:46,390 --> 00:02:53,170
cities spanning the period from 2005 to

00:02:49,510 --> 00:02:55,209
2013 the datasets that I analyzed in

00:02:53,170 --> 00:02:56,980
order to make these maps is something

00:02:55,209 --> 00:03:00,730
called the US Postal Service they can

00:02:56,980 --> 00:03:02,829
see survey and I learned about this

00:03:00,730 --> 00:03:05,440
obscure dataset because it was one of

00:03:02,829 --> 00:03:08,430
the inputs that was used in determining

00:03:05,440 --> 00:03:10,930
how federal funds would be allocated

00:03:08,430 --> 00:03:14,140
geographically under the dodd-frank Act

00:03:10,930 --> 00:03:15,129
of 2010 specifically under a US

00:03:14,140 --> 00:03:16,989
Department of Housing and Urban

00:03:15,129 --> 00:03:20,739
Development Program called the

00:03:16,989 --> 00:03:23,169
Neighborhood Stabilization program so in

00:03:20,739 --> 00:03:25,269
2010 when Josh Frank was passed by

00:03:23,169 --> 00:03:27,280
Congress and signed into law this is

00:03:25,269 --> 00:03:31,389
some great applause for when that that

00:03:27,280 --> 00:03:34,720
act was signed yeah thank you Getty

00:03:31,389 --> 00:03:36,180
Images so in addition to passing some

00:03:34,720 --> 00:03:38,440
though I'll say not nearly enough

00:03:36,180 --> 00:03:41,349
reforms for Wall Street to sort of

00:03:38,440 --> 00:03:44,169
mitigate the kinds of financial and data

00:03:41,349 --> 00:03:47,290
dealings that got us into this mess 1

00:03:44,169 --> 00:03:49,599
billion dollars was earmarked and made

00:03:47,290 --> 00:03:51,250
available as to communities in order

00:03:49,599 --> 00:03:54,669
through the US Department of Housing and

00:03:51,250 --> 00:03:57,790
Urban Development in order to target

00:03:54,669 --> 00:04:00,069
communities that were most severely

00:03:57,790 --> 00:04:02,919
impacted by the foreclosure crisis it

00:04:00,069 --> 00:04:05,099
was designed to the earmark for these

00:04:02,919 --> 00:04:09,639
communities witnessing the worst impact

00:04:05,099 --> 00:04:11,440
so HUD determined how to directly target

00:04:09,639 --> 00:04:14,199
these funds to communities of greatest

00:04:11,440 --> 00:04:16,090
need through a formula it was

00:04:14,199 --> 00:04:18,669
distributed across towns and cities and

00:04:16,090 --> 00:04:20,109
counties according to this formula which

00:04:18,669 --> 00:04:23,320
used several different datasets as

00:04:20,109 --> 00:04:25,030
inputs this is their documentation just

00:04:23,320 --> 00:04:26,979
a screenshot actually that was made

00:04:25,030 --> 00:04:28,389
available when the funding was made

00:04:26,979 --> 00:04:30,520
available and

00:04:28,389 --> 00:04:32,860
and ever lies primarily on delinquency

00:04:30,520 --> 00:04:35,439
and foreclosure filings from the

00:04:32,860 --> 00:04:38,919
Mortgage Bankers Association national

00:04:35,439 --> 00:04:41,560
delinquency survey as well as data from

00:04:38,919 --> 00:04:44,379
an agency called Nick - analytics which

00:04:41,560 --> 00:04:46,180
they use to train a model which was then

00:04:44,379 --> 00:04:48,340
comprised of publicly available datasets

00:04:46,180 --> 00:04:50,289
that would predict serious delinquency

00:04:48,340 --> 00:04:52,930
rates at the census tracts level across

00:04:50,289 --> 00:04:55,360
the US and then on top of this because

00:04:52,930 --> 00:04:56,439
the goal in this third round of

00:04:55,360 --> 00:04:58,930
Neighborhood Stabilization program

00:04:56,439 --> 00:05:01,689
funding which was coming in 2010

00:04:58,930 --> 00:05:03,340
so when vacancy was really becoming one

00:05:01,689 --> 00:05:05,080
of the core impacts of the foreclosure

00:05:03,340 --> 00:05:07,569
crisis no it wasn't just that people

00:05:05,080 --> 00:05:09,599
were being going delinquent on their

00:05:07,569 --> 00:05:11,469
loans and leaving their homes but now

00:05:09,599 --> 00:05:14,710
communities were really seeing the

00:05:11,469 --> 00:05:18,129
impact of this massive urban crisis with

00:05:14,710 --> 00:05:20,710
abandonment so because the goal of this

00:05:18,129 --> 00:05:23,259
trough of funding was to target these

00:05:20,710 --> 00:05:26,229
neighborhood effects a vacancy they also

00:05:23,259 --> 00:05:28,569
added an additional data set the US

00:05:26,229 --> 00:05:30,819
Postal Service vacancy survey so the

00:05:28,569 --> 00:05:33,310
funding was distributed first at a

00:05:30,819 --> 00:05:35,529
statewide level and then more locally to

00:05:33,310 --> 00:05:37,150
target local geographies and then they

00:05:35,529 --> 00:05:39,250
came out with dollar amounts that went

00:05:37,150 --> 00:05:42,669
to specific municipalities across the

00:05:39,250 --> 00:05:45,159
u.s. so one of the things that I found

00:05:42,669 --> 00:05:47,770
really striking when I was digging into

00:05:45,159 --> 00:05:49,569
researching the inputs that went into

00:05:47,770 --> 00:05:52,719
this methodology that HUD was using is

00:05:49,569 --> 00:05:55,000
that most of the data sources that went

00:05:52,719 --> 00:05:57,900
into it or that informed their model

00:05:55,000 --> 00:06:00,759
where one's held by for-profit companies

00:05:57,900 --> 00:06:02,860
indeed many for-profit companies who

00:06:00,759 --> 00:06:05,379
were themselves profiting off of the

00:06:02,860 --> 00:06:08,919
foreclosure crisis that this policy is

00:06:05,379 --> 00:06:12,490
meant to to impact you know you can't

00:06:08,919 --> 00:06:14,409
make the stuff up so I was interested in

00:06:12,490 --> 00:06:17,139
investigating these underlying inputs as

00:06:14,409 --> 00:06:19,210
I mentioned to know more about how and

00:06:17,139 --> 00:06:22,389
what they represented of the United

00:06:19,210 --> 00:06:24,819
States and my goal with the project was

00:06:22,389 --> 00:06:28,360
not at all to dismantle the funding

00:06:24,819 --> 00:06:30,969
allocation methodology by HUD plus by

00:06:28,360 --> 00:06:33,279
this point in 2010 knowing which

00:06:30,969 --> 00:06:35,169
communities were most hard-hit by the

00:06:33,279 --> 00:06:38,469
foreclosure crisis was something that

00:06:35,169 --> 00:06:40,360
was fairly well known and not owned not

00:06:38,469 --> 00:06:42,580
only on the basis of

00:06:40,360 --> 00:06:45,879
when the peak number of mortgage

00:06:42,580 --> 00:06:47,949
delinquency filings were made so as the

00:06:45,879 --> 00:06:50,469
core public non-proprietary data source

00:06:47,949 --> 00:06:52,949
I set out to learn more about this US

00:06:50,469 --> 00:06:56,379
Postal Service vacancy survey this is a

00:06:52,949 --> 00:07:01,300
screenshot of some though not all of the

00:06:56,379 --> 00:07:04,289
columns in said data set so as it turns

00:07:01,300 --> 00:07:07,479
out the US Postal Service vacancy survey

00:07:04,289 --> 00:07:08,620
it's created by postal workers when they

00:07:07,479 --> 00:07:11,289
are going on their daily routes

00:07:08,620 --> 00:07:13,960
delivering mail across the US at each

00:07:11,289 --> 00:07:16,169
home or business on their route postal

00:07:13,960 --> 00:07:18,520
workers in addition to dropping off mail

00:07:16,169 --> 00:07:20,009
note whether the occupants of that

00:07:18,520 --> 00:07:23,110
address have been picking up their mail

00:07:20,009 --> 00:07:26,020
and the residences that are left empty

00:07:23,110 --> 00:07:28,030
for 90 days or longer are the ones that

00:07:26,020 --> 00:07:29,949
are represented in this data set which

00:07:28,030 --> 00:07:33,190
you see flickering across the screen

00:07:29,949 --> 00:07:35,289
right now so the responses are recorded

00:07:33,190 --> 00:07:37,419
and then they're a grated into quarterly

00:07:35,289 --> 00:07:38,349
snapshots which are shared to the US

00:07:37,419 --> 00:07:40,509
Department of Housing and Urban

00:07:38,349 --> 00:07:43,930
Development at the census tract level

00:07:40,509 --> 00:07:46,060
every three months as I said and I'd

00:07:43,930 --> 00:07:48,969
like to pause this to just convey how

00:07:46,060 --> 00:07:50,919
remarkable I think this is that everyday

00:07:48,969 --> 00:07:53,979
postal workers visit every address

00:07:50,919 --> 00:07:55,839
across the US and they look at the

00:07:53,979 --> 00:07:58,229
address and they write down whether

00:07:55,839 --> 00:08:02,259
there are people there that's amazing

00:07:58,229 --> 00:08:06,250
and I was really drawn to this deeply

00:08:02,259 --> 00:08:09,219
poetic in my mind connection between the

00:08:06,250 --> 00:08:11,169
everyday those visits of postal workers

00:08:09,219 --> 00:08:13,690
to addresses across the US and the

00:08:11,169 --> 00:08:18,250
abstract numbers of vacant housing units

00:08:13,690 --> 00:08:21,069
per census tract for the entire US so

00:08:18,250 --> 00:08:23,110
that really you know that but basically

00:08:21,069 --> 00:08:26,050
the census takes ten years to

00:08:23,110 --> 00:08:27,580
orchestrate doing a survey of all of the

00:08:26,050 --> 00:08:29,710
residences across the u.s. is such a

00:08:27,580 --> 00:08:32,490
massive undertaking that it takes this

00:08:29,710 --> 00:08:35,320
much planning to go into nevertheless

00:08:32,490 --> 00:08:38,169
postal workers are having encounters as

00:08:35,320 --> 00:08:42,550
front doors and post office boxes every

00:08:38,169 --> 00:08:45,779
single day except for Sunday's so why

00:08:42,550 --> 00:08:45,779
does this data set exist

00:08:46,020 --> 00:08:50,760
the first step in my mind and doing

00:08:48,510 --> 00:08:53,010
ethical work with data is understanding

00:08:50,760 --> 00:08:56,430
where it comes from why was it collected

00:08:53,010 --> 00:08:59,190
what went into its collection that may

00:08:56,430 --> 00:09:02,040
or may not impact the actual information

00:08:59,190 --> 00:09:03,780
about the real world that it records and

00:09:02,040 --> 00:09:08,490
so in this case the US Postal Service

00:09:03,780 --> 00:09:10,020
Agency survey is collected in order to

00:09:08,490 --> 00:09:13,260
sell it to advertisers

00:09:10,020 --> 00:09:14,820
it's the origins of junk mail the u.s.

00:09:13,260 --> 00:09:16,200
mobile service has a vested interest in

00:09:14,820 --> 00:09:17,850
knowing which are active addresses

00:09:16,200 --> 00:09:19,620
because they can sell it to advertisers

00:09:17,850 --> 00:09:22,200
who are willing to pay for this

00:09:19,620 --> 00:09:25,350
information to send you unwanted pieces

00:09:22,200 --> 00:09:26,280
of paper so the fact that the US

00:09:25,350 --> 00:09:29,610
Department of Housing and Urban

00:09:26,280 --> 00:09:33,420
Development can use this data set as of

00:09:29,610 --> 00:09:35,670
a much more fine-grained measure of how

00:09:33,420 --> 00:09:36,630
full making these across the u.s. then

00:09:35,670 --> 00:09:39,290
you would get through the American

00:09:36,630 --> 00:09:41,430
Community Survey or the census etc is

00:09:39,290 --> 00:09:44,460
completely accidental a really

00:09:41,430 --> 00:09:47,300
unintended byproduct of its original

00:09:44,460 --> 00:09:47,300
reason for being collected

00:09:47,370 --> 00:09:53,700
but even as this accidental by-product

00:09:50,220 --> 00:09:55,140
it's a very powerful data set I would

00:09:53,700 --> 00:09:57,660
think through using it I was able to

00:09:55,140 --> 00:10:00,630
dynamically visualize the ways and

00:09:57,660 --> 00:10:03,210
places where the foreclosure crisis had

00:10:00,630 --> 00:10:05,970
erupted into a vacancy crisis while

00:10:03,210 --> 00:10:08,100
foreclosure is always a crisis for

00:10:05,970 --> 00:10:11,510
individual households vacancy is really

00:10:08,100 --> 00:10:14,070
the way that the foreclosure becomes a

00:10:11,510 --> 00:10:15,630
collective crisis for communities an

00:10:14,070 --> 00:10:18,690
agent for collective urban

00:10:15,630 --> 00:10:19,980
transformation and so behind each of

00:10:18,690 --> 00:10:21,780
these flickering census tracts are

00:10:19,980 --> 00:10:25,320
stories of loss and community

00:10:21,780 --> 00:10:30,090
transformation powerful ones that

00:10:25,320 --> 00:10:31,380
deserve further inquiry and so through

00:10:30,090 --> 00:10:34,020
the project I made some interesting

00:10:31,380 --> 00:10:36,090
findings about the data set itself for

00:10:34,020 --> 00:10:38,300
example Phoenix Arizona one of the

00:10:36,090 --> 00:10:41,010
cities I focused on reached its peak

00:10:38,300 --> 00:10:45,510
vacancy rate in for the period that I

00:10:41,010 --> 00:10:48,090
looked at in June 2010 where 6.7 2% of

00:10:45,510 --> 00:10:50,490
all homes in Phoenix Arizona were marked

00:10:48,090 --> 00:10:53,430
as vacant for 90 days or longer in the

00:10:50,490 --> 00:10:55,380
data set miami-dade County Florida and

00:10:53,430 --> 00:10:58,880
York City both reached their peaks by

00:10:55,380 --> 00:11:00,650
September of 2010 as well

00:10:58,880 --> 00:11:02,450
whereas Detroit Michigan shows an

00:11:00,650 --> 00:11:05,950
altogether different pattern with

00:11:02,450 --> 00:11:08,540
vacancy rates continuing to rise to 2013

00:11:05,950 --> 00:11:10,640
it's worth noting that HUD in their

00:11:08,540 --> 00:11:12,980
funding allocation formula uses the

00:11:10,640 --> 00:11:15,140
number of vacant homes as of June 2008

00:11:12,980 --> 00:11:17,390
which is well before the number of

00:11:15,140 --> 00:11:19,390
vacant homes Peaks for the US as a whole

00:11:17,390 --> 00:11:23,030
or any of the cities that I looked at

00:11:19,390 --> 00:11:25,130
and I also discovered that there are

00:11:23,030 --> 00:11:27,290
major inconsistencies in the method of

00:11:25,130 --> 00:11:29,150
collecting this data for this period as

00:11:27,290 --> 00:11:30,830
one would expect of a dataset collected

00:11:29,150 --> 00:11:32,330
by thousands and thousands of

00:11:30,830 --> 00:11:36,500
individuals for the purpose of

00:11:32,330 --> 00:11:37,670
distributing junk mail and led to large

00:11:36,500 --> 00:11:42,020
spikes in the overall number of

00:11:37,670 --> 00:11:43,910
residential addresses and so the other

00:11:42,020 --> 00:11:47,210
thing that I was really especially drawn

00:11:43,910 --> 00:11:49,460
to here is how the data set really

00:11:47,210 --> 00:11:53,210
reveals the logic of abstraction that's

00:11:49,460 --> 00:11:57,020
at work in all data the National vacancy

00:11:53,210 --> 00:11:59,300
rate fully masks and is yet dependent on

00:11:57,020 --> 00:12:01,100
the individual routines of postal

00:11:59,300 --> 00:12:03,740
workers as they visit addresses across

00:12:01,100 --> 00:12:06,500
the US so these postal workers daily

00:12:03,740 --> 00:12:11,060
walks are hidden behind the CSD or

00:12:06,500 --> 00:12:13,190
actually the DBS table that this is is

00:12:11,060 --> 00:12:15,950
hidden these individual stories are

00:12:13,190 --> 00:12:18,230
hidden within this data set and so the

00:12:15,950 --> 00:12:21,500
project combines data visualization

00:12:18,230 --> 00:12:23,390
critical cartography and uses both to

00:12:21,500 --> 00:12:26,180
explore tensions between the

00:12:23,390 --> 00:12:27,880
cartographic statistical and ordinary

00:12:26,180 --> 00:12:30,020
ways of understanding the built world

00:12:27,880 --> 00:12:32,690
and this split between the cartographic

00:12:30,020 --> 00:12:34,550
and the everyday is a principal interest

00:12:32,690 --> 00:12:38,030
of mine something I've returned to on a

00:12:34,550 --> 00:12:39,410
number of projects both at my at my

00:12:38,030 --> 00:12:41,900
current job at the Center for spatial

00:12:39,410 --> 00:12:43,580
research and before and the stakes for

00:12:41,900 --> 00:12:47,150
engaging with these kinds of questions

00:12:43,580 --> 00:12:49,130
become especially clear in the context

00:12:47,150 --> 00:12:51,200
of data-driven policy programs like the

00:12:49,130 --> 00:12:53,960
Neighborhood Stabilization program where

00:12:51,200 --> 00:12:56,210
abstractions you sort of have this loop

00:12:53,960 --> 00:12:58,580
from individual encounters with postal

00:12:56,210 --> 00:13:01,820
workers in the real world abstraction

00:12:58,580 --> 00:13:05,540
which feeds into policy which then has

00:13:01,820 --> 00:13:07,280
real impact in the real world I'm this

00:13:05,540 --> 00:13:08,990
kind of tension is something that the

00:13:07,280 --> 00:13:10,790
geographer Trevor Paglen

00:13:08,990 --> 00:13:14,210
writes on in the

00:13:10,790 --> 00:13:16,390
text approaches cartography I won't need

00:13:14,210 --> 00:13:19,430
this whole quote because you all can

00:13:16,390 --> 00:13:22,400
where he talks about the God's eye view

00:13:19,430 --> 00:13:25,310
of cartographic analysis is often not

00:13:22,400 --> 00:13:27,320
helpful for depicting relationships that

00:13:25,310 --> 00:13:29,870
he's really interested in relationships

00:13:27,320 --> 00:13:31,640
about the everyday because of the forms

00:13:29,870 --> 00:13:35,020
of power that are embedded in this

00:13:31,640 --> 00:13:37,190
cartographic view that often obscure

00:13:35,020 --> 00:13:39,110
notions of fragmented myths and

00:13:37,190 --> 00:13:42,920
incompleteness that on the ground

00:13:39,110 --> 00:13:47,090
viewpoints do a better job of embracing

00:13:42,920 --> 00:13:48,680
and so while I completely agree with his

00:13:47,090 --> 00:13:50,900
insights and then the big fan of his

00:13:48,680 --> 00:13:53,630
work I would argue and I think this

00:13:50,900 --> 00:13:55,940
project argues that fragmented miss and

00:13:53,630 --> 00:13:59,120
incompleteness are not at all

00:13:55,940 --> 00:14:01,670
characteristics that are reserved for on

00:13:59,120 --> 00:14:03,920
the ground everyday viewpoints but

00:14:01,670 --> 00:14:06,410
instead what's particularly insidious

00:14:03,920 --> 00:14:08,630
about the gods eye view

00:14:06,410 --> 00:14:12,860
or the gods eye mode of big data

00:14:08,630 --> 00:14:16,760
analysis is its claims to see or reveal

00:14:12,860 --> 00:14:18,080
an unfragmented and complete world that

00:14:16,760 --> 00:14:21,110
the claims that the US Postal Service

00:14:18,080 --> 00:14:23,210
dataset is a picture of all residential

00:14:21,110 --> 00:14:24,500
vacancies in the US and so by

00:14:23,210 --> 00:14:27,020
highlighting the relationship between

00:14:24,500 --> 00:14:29,270
the dataset and its mode of collection I

00:14:27,020 --> 00:14:32,060
think there's an opportunity to reveal

00:14:29,270 --> 00:14:35,900
precisely how fragmented this supposedly

00:14:32,060 --> 00:14:38,390
complete picture often is in her recent

00:14:35,900 --> 00:14:40,460
book Cathy o Neill sneaks to the

00:14:38,390 --> 00:14:42,290
disastrous consequences of fragmented

00:14:40,460 --> 00:14:45,020
nests but in the context of algorithmic

00:14:42,290 --> 00:14:46,940
decision making and where for her the

00:14:45,020 --> 00:14:53,900
God's eye view of cartography is instead

00:14:46,940 --> 00:14:55,940
the ever powerful algorithm and she

00:14:53,900 --> 00:14:58,610
speaks about the ways that biased and

00:14:55,940 --> 00:15:00,500
skewed and incomplete datasets are often

00:14:58,610 --> 00:15:02,470
one of the key ways that algorithms lead

00:15:00,500 --> 00:15:05,240
to unethical modes of decision-making

00:15:02,470 --> 00:15:06,590
the data is an abstraction that's how

00:15:05,240 --> 00:15:10,580
it's useful but that's also how it's

00:15:06,590 --> 00:15:13,280
dangerous and I'll sort of wrap up wrap

00:15:10,580 --> 00:15:15,770
up here but so she urgent's users of

00:15:13,280 --> 00:15:17,300
data and makers of models to think about

00:15:15,770 --> 00:15:19,850
the data that goes into them and also to

00:15:17,300 --> 00:15:22,290
understand all of these inputs as moral

00:15:19,850 --> 00:15:27,310
questions

00:15:22,290 --> 00:15:29,860
so I lend and with her her quote here to

00:15:27,310 --> 00:15:31,870
say that I completely agree with her

00:15:29,860 --> 00:15:34,959
concerns that we need to do a better job

00:15:31,870 --> 00:15:37,060
of knitting together connections between

00:15:34,959 --> 00:15:39,250
technical models and everyday people

00:15:37,060 --> 00:15:41,709
they're sneaking to describe and change

00:15:39,250 --> 00:15:43,569
the lives of and one of the things that

00:15:41,709 --> 00:15:45,310
I found powerful about the vacancy

00:15:43,569 --> 00:15:48,819
survey is the way that it really does

00:15:45,310 --> 00:15:50,680
this that it captures the routines of

00:15:48,819 --> 00:15:52,750
these people as they go through every

00:15:50,680 --> 00:15:55,480
address in the US and is a powerful

00:15:52,750 --> 00:15:57,610
reminder that all of our work to

00:15:55,480 --> 00:15:59,949
transform the world through data really

00:15:57,610 --> 00:16:02,740
needs to keep this in mind so that

00:15:59,949 --> 00:16:04,269
data-driven processes can be powerful

00:16:02,740 --> 00:16:07,620
ones but ones that are also deeply

00:16:04,269 --> 00:16:07,620
democratic thank you

00:16:12,850 --> 00:16:18,509
I think there are time for a few

00:16:15,100 --> 00:16:18,509
questions if people have them yeah

00:16:18,870 --> 00:16:31,449
looking right now that something that

00:16:29,709 --> 00:16:34,779
would would be good to dig further into

00:16:31,449 --> 00:16:37,000
my guess would be that those are that

00:16:34,779 --> 00:16:38,740
sort of area of northern Alabama and

00:16:37,000 --> 00:16:40,089
particular is fairly rural there's an

00:16:38,740 --> 00:16:41,920
issue in the datasets that I didn't

00:16:40,089 --> 00:16:44,680
think about which is also they have a

00:16:41,920 --> 00:16:46,990
category called no stat addresses that

00:16:44,680 --> 00:16:49,029
puts a lot of fuzziness around it as a

00:16:46,990 --> 00:16:50,860
measure of vacancy in rural zones it's a

00:16:49,029 --> 00:16:53,550
much more accurate measure in cities and

00:16:50,860 --> 00:16:56,199
so that could be one potential cause

00:16:53,550 --> 00:16:58,600
maybe there's less of a directive in

00:16:56,199 --> 00:17:00,970
Alabama for postal workers to record

00:16:58,600 --> 00:17:03,339
this information than there then their

00:17:00,970 --> 00:17:06,130
neighbors in Georgia and elsewhere yes

00:17:03,339 --> 00:17:08,699
so all good eyes and interesting

00:17:06,130 --> 00:17:08,699
questions yes

00:17:13,279 --> 00:17:22,289
yeah yeah so basically I uncovered those

00:17:20,220 --> 00:17:24,179
through a combination of looking so the

00:17:22,289 --> 00:17:26,909
data is released in quarterly snapshots

00:17:24,179 --> 00:17:31,380
so is a big undertaking to combine all

00:17:26,909 --> 00:17:33,000
of those massive GBF tables and so I

00:17:31,380 --> 00:17:34,500
looked at it as a time series as opposed

00:17:33,000 --> 00:17:36,090
to just looking at individual snapshots

00:17:34,500 --> 00:17:38,640
which is how HUD used it in their

00:17:36,090 --> 00:17:40,620
methodology so to be fair the fact that

00:17:38,640 --> 00:17:41,880
it changed over time is not a concern

00:17:40,620 --> 00:17:43,740
for them because they weren't actually

00:17:41,880 --> 00:17:47,340
doing an average over time etc but still

00:17:43,740 --> 00:17:49,860
it speaks to me about the inconsistency

00:17:47,340 --> 00:17:51,149
of it as a solid measure and so just

00:17:49,860 --> 00:17:52,830
there were literally spikes in the

00:17:51,149 --> 00:17:55,200
number the total number of addresses

00:17:52,830 --> 00:17:57,210
that existed in the US by the tens of

00:17:55,200 --> 00:17:58,080
thousands from like one three-month

00:17:57,210 --> 00:18:08,399
period to the next

00:17:58,080 --> 00:18:11,029
yeah craziness yeah seriously like when

00:18:08,399 --> 00:18:13,710
the postal worker feels like something

00:18:11,029 --> 00:18:16,590
and I'd like are they ready we're really

00:18:13,710 --> 00:18:21,649
running down like Tuesday these three

00:18:16,590 --> 00:18:24,659
pick up their mail Wednesday yes yeah um

00:18:21,649 --> 00:18:26,279
well so underneath one of the things

00:18:24,659 --> 00:18:28,080
that I'll say is good about the way that

00:18:26,279 --> 00:18:30,450
the dataset is released you wouldn't

00:18:28,080 --> 00:18:33,840
really want to have a you know day by

00:18:30,450 --> 00:18:36,049
day picture of every single home in the

00:18:33,840 --> 00:18:38,789
US that's really terrifying actually

00:18:36,049 --> 00:18:40,260
so HUD gets the data and makes it

00:18:38,789 --> 00:18:42,270
available to nonprofits I work at a

00:18:40,260 --> 00:18:45,270
university and was able to get through

00:18:42,270 --> 00:18:47,309
it that way it was aggregated so that

00:18:45,270 --> 00:18:49,440
covers a lot of it so in terms of the

00:18:47,309 --> 00:18:50,669
methodology of how the postal workers

00:18:49,440 --> 00:18:52,620
you know what they're supposed to do

00:18:50,669 --> 00:18:56,490
what the interface is for how they're

00:18:52,620 --> 00:18:59,760
entering this information no idea and

00:18:56,490 --> 00:19:01,919
and the methodology is that they report

00:18:59,760 --> 00:19:04,110
is that we collect this information for

00:19:01,919 --> 00:19:05,580
our own purposes and then also make it

00:19:04,110 --> 00:19:07,409
available so they sort of wring their

00:19:05,580 --> 00:19:09,649
hands of responsibility that way yeah

00:19:07,409 --> 00:19:09,649
yeah

00:19:12,090 --> 00:19:17,710
that's a very good question yeah I know

00:19:15,460 --> 00:19:19,180
it feels like there would be a lot a lot

00:19:17,710 --> 00:19:21,550
they could do there I don't know frankly

00:19:19,180 --> 00:19:23,260
this is the only like when I was doing

00:19:21,550 --> 00:19:24,820
research until we know why this existed

00:19:23,260 --> 00:19:26,440
and all that this is the only data set

00:19:24,820 --> 00:19:28,360
that I came across so they collect or

00:19:26,440 --> 00:19:32,440
certainly that's made available that

00:19:28,360 --> 00:19:35,580
they collect yeah awesome I know I'm up

00:19:32,440 --> 00:19:40,770
against time well thank you all so much

00:19:35,580 --> 00:19:40,770

YouTube URL: https://www.youtube.com/watch?v=4AbVxA6T4sA


