Title: Serena Peruzzo - Improving law interpretability using NLP
Publication date: 2020-05-28
Playlist: CSVConf 2020
Description: 
	Laws define how people may or may not behave in society, but are often hard to interpret and inaccessible to the public. Data Scientists from Bardess, in collaboration with a research group from the Government of Ontario, have investigated how NLP can be applied to understand linguistic patterns in legislative texts and extract information that is meaningful for the public. The methodology developed provides us with a framework for representing legal texts that can be used to simplify the way information in the law is accessed and, at the same time, inform legislators on how to write more clear and accessible legislation by highlighting parts of the law that are particularly hard to interpret.

--
csv,conf,v5 is a community conference for data makers everywhere, featuring stories about data sharing and data analysis from science, journalism, government, and open source.  Held May 13-14, 2020, Online. https://csvconf.com/
Captions: 
	00:00:00,000 --> 00:00:04,020
hello everyone my name is Serena my

00:00:02,220 --> 00:00:06,810
pronouns are she her

00:00:04,020 --> 00:00:08,760
I am busy in Toronto Canada and I'm

00:00:06,810 --> 00:00:10,769
currently on a three-month sabbatical at

00:00:08,760 --> 00:00:12,480
the recurse Center if you haven't heard

00:00:10,769 --> 00:00:14,490
of the recurse Center it's a magical

00:00:12,480 --> 00:00:17,640
place when you can basically can do a

00:00:14,490 --> 00:00:18,960
writer's retreat for programmers and I

00:00:17,640 --> 00:00:22,410
encourage you to ask me about it if

00:00:18,960 --> 00:00:24,630
you're interested previously I was a

00:00:22,410 --> 00:00:28,199
data scientist and a consultant at the

00:00:24,630 --> 00:00:30,119
Partners Group as part of that I worked

00:00:28,199 --> 00:00:32,610
on a project in collaboration with the

00:00:30,119 --> 00:00:34,860
government of Ontario where a goal was

00:00:32,610 --> 00:00:37,110
to explore ways in which natural

00:00:34,860 --> 00:00:39,870
language processing could be used to

00:00:37,110 --> 00:00:42,000
extract information from laws that can

00:00:39,870 --> 00:00:43,710
be useful to the public so today I'm

00:00:42,000 --> 00:00:44,520
here to talk to you about improving law

00:00:43,710 --> 00:00:48,960
interpretability

00:00:44,520 --> 00:00:52,170
using natural language processing but

00:00:48,960 --> 00:00:55,140
what does interpretability mean let's

00:00:52,170 --> 00:00:58,590
take a step back and think about the

00:00:55,140 --> 00:01:00,750
context by a lot the definition of law

00:00:58,590 --> 00:01:01,940
is the system of rules which a

00:01:00,750 --> 00:01:04,769
particular country or community

00:01:01,940 --> 00:01:07,500
recognizes as regulating the actions of

00:01:04,769 --> 00:01:09,840
its members so it's basically a system

00:01:07,500 --> 00:01:11,760
of rules that tell you how you may or

00:01:09,840 --> 00:01:12,990
may not behave in a society and it's

00:01:11,760 --> 00:01:15,240
pretty important that you know about it

00:01:12,990 --> 00:01:17,340
because ignorance is no excuse for

00:01:15,240 --> 00:01:20,820
breaking it and so really important to

00:01:17,340 --> 00:01:23,250
understand them in terms of

00:01:20,820 --> 00:01:24,840
interpretability in this context there's

00:01:23,250 --> 00:01:26,970
two aspects I want to draw your

00:01:24,840 --> 00:01:28,770
attention to on one side the contents

00:01:26,970 --> 00:01:31,500
and we want to be able to extract rules

00:01:28,770 --> 00:01:34,500
and obligation from the text and then we

00:01:31,500 --> 00:01:36,720
want to be able to identify the entities

00:01:34,500 --> 00:01:40,500
that are responsible for compliance and

00:01:36,720 --> 00:01:42,509
are affected by the legislation in terms

00:01:40,500 --> 00:01:44,369
of technical implementation that means

00:01:42,509 --> 00:01:45,540
find a representation of the rules that

00:01:44,369 --> 00:01:47,460
makes more that makes them more

00:01:45,540 --> 00:01:49,140
accessible and understandable and if you

00:01:47,460 --> 00:01:51,659
do that you may be able to see things

00:01:49,140 --> 00:01:53,100
like patterns across industries maybe

00:01:51,659 --> 00:01:54,329
see the difference between private and

00:01:53,100 --> 00:01:56,850
public sector whether there's a

00:01:54,329 --> 00:02:01,950
difference in responsibilities or I'll

00:01:56,850 --> 00:02:03,780
or even highlight ambiguities there are

00:02:01,950 --> 00:02:05,340
several challenges in this space the

00:02:03,780 --> 00:02:08,369
first one is there's no level set

00:02:05,340 --> 00:02:10,979
available to us so no one sat down in

00:02:08,369 --> 00:02:12,780
Ontario and annotated the text of all

00:02:10,979 --> 00:02:13,800
the laws saying this is interesting this

00:02:12,780 --> 00:02:16,080
is not

00:02:13,800 --> 00:02:20,550
so the first problem is we can't run any

00:02:16,080 --> 00:02:23,190
supervised analysis the second language

00:02:20,550 --> 00:02:24,090
parsing and tokenization is kind of hard

00:02:23,190 --> 00:02:25,860
I lost

00:02:24,090 --> 00:02:27,600
they're all formatted with bullet points

00:02:25,860 --> 00:02:29,190
bullet points and refer to other pullet

00:02:27,600 --> 00:02:31,830
points and lots of references to other

00:02:29,190 --> 00:02:36,690
laws and that can break the parsing and

00:02:31,830 --> 00:02:39,780
tokenization algorithms very easily next

00:02:36,690 --> 00:02:42,870
laws tend to have limited lexicon so the

00:02:39,780 --> 00:02:44,520
vocabulary is relatively limited but

00:02:42,870 --> 00:02:46,740
they're very specialized in context

00:02:44,520 --> 00:02:48,480
specific so the same word can be used in

00:02:46,740 --> 00:02:50,340
different places in the same text but

00:02:48,480 --> 00:02:54,870
with different context and so have

00:02:50,340 --> 00:02:58,680
different meanings sentences can also be

00:02:54,870 --> 00:03:00,900
very complex so they can be really long

00:02:58,680 --> 00:03:03,810
and convoluted and sometimes it's hard

00:03:00,900 --> 00:03:06,060
to tell who's responsible for what where

00:03:03,810 --> 00:03:09,420
is the rule what is actually you can get

00:03:06,060 --> 00:03:12,050
lost in the sentences basically and then

00:03:09,420 --> 00:03:14,940
finally they're very domain-specific so

00:03:12,050 --> 00:03:19,650
think about a domain in terms of an

00:03:14,940 --> 00:03:22,170
industry or a topic or a geography so if

00:03:19,650 --> 00:03:24,600
we had a data set from Europe for

00:03:22,170 --> 00:03:26,130
example and we trained a model on it we

00:03:24,600 --> 00:03:32,070
wouldn't be able to generalize as well

00:03:26,130 --> 00:03:35,340
to Canada so in light of this challenges

00:03:32,070 --> 00:03:38,190
we instead of building a single model we

00:03:35,340 --> 00:03:41,070
decided to build a framework of analysis

00:03:38,190 --> 00:03:42,810
and we put together a mix of pre train

00:03:41,070 --> 00:03:46,560
natural language processing models and

00:03:42,810 --> 00:03:48,030
unsupervised machine learning and this

00:03:46,560 --> 00:03:50,940
was with the goal of extracting

00:03:48,030 --> 00:03:52,680
information and that information and

00:03:50,940 --> 00:03:54,480
Beulah's down to the rules that are

00:03:52,680 --> 00:03:57,870
defining the tax the antes are

00:03:54,480 --> 00:03:59,070
responsible for compliance but also

00:03:57,870 --> 00:04:01,050
things like the difference between

00:03:59,070 --> 00:04:02,970
public and private responsibilities and

00:04:01,050 --> 00:04:04,590
trying to organize the rules into

00:04:02,970 --> 00:04:08,150
homogeneous groups and we'll see in a

00:04:04,590 --> 00:04:10,530
few minutes what I mean by homogeneous

00:04:08,150 --> 00:04:12,780
before moving forward I want to do a

00:04:10,530 --> 00:04:14,880
quick grammar refresher just because I'm

00:04:12,780 --> 00:04:16,620
going to use this words a lot in the

00:04:14,880 --> 00:04:18,590
next few slides and I want everyone to

00:04:16,620 --> 00:04:22,169
be on the same page

00:04:18,590 --> 00:04:24,270
so in grammar the subjects is the word

00:04:22,169 --> 00:04:27,710
of rates that indicates who or what

00:04:24,270 --> 00:04:30,050
performs the action of the verb so

00:04:27,710 --> 00:04:32,120
in the context of law this is going to

00:04:30,050 --> 00:04:34,009
point us to the entities responsible for

00:04:32,120 --> 00:04:35,720
complying with the rules and I have an

00:04:34,009 --> 00:04:37,759
example of a sentence here where every

00:04:35,720 --> 00:04:39,380
employer is the subject grammatically

00:04:37,759 --> 00:04:43,120
and it's also the entity that is

00:04:39,380 --> 00:04:45,800
responsible for providing some time and

00:04:43,120 --> 00:04:48,139
next we have the object of the sentence

00:04:45,800 --> 00:04:50,990
so that's the entity that is acted upon

00:04:48,139 --> 00:04:53,360
upon by the subject and so in this

00:04:50,990 --> 00:04:55,400
context it is a role specification so we

00:04:53,360 --> 00:04:57,530
had the that every employer employer was

00:04:55,400 --> 00:05:00,500
the subject the object of this of this

00:04:57,530 --> 00:05:03,919
sentence is workplace emergency response

00:05:00,500 --> 00:05:08,720
information that's what the employer

00:05:03,919 --> 00:05:11,120
should provide okay so getting into more

00:05:08,720 --> 00:05:13,370
of the analysis we built a proof of

00:05:11,120 --> 00:05:15,740
concept based on the accessibility for

00:05:13,370 --> 00:05:18,650
Ontarians with disability act this is a

00:05:15,740 --> 00:05:20,960
statue and a regulation passed in 2015

00:05:18,650 --> 00:05:23,810
it defines rules and requirements for

00:05:20,960 --> 00:05:26,060
accessibility in Ontario and it also

00:05:23,810 --> 00:05:30,919
sets up processes for eliminating

00:05:26,060 --> 00:05:33,889
barriers so in this context what we're

00:05:30,919 --> 00:05:37,250
really the rules that were interested in

00:05:33,889 --> 00:05:39,110
are called burdens so a burden is a

00:05:37,250 --> 00:05:41,090
requirement or obligation that

00:05:39,110 --> 00:05:43,820
organizations have to comply with and

00:05:41,090 --> 00:05:46,099
that can be related to physical and

00:05:43,820 --> 00:05:47,030
architectural barriers like step ups

00:05:46,099 --> 00:05:49,759
stairs

00:05:47,030 --> 00:05:51,169
sidewalks but also things that are left

00:05:49,759 --> 00:05:57,409
handed would like documentation and

00:05:51,169 --> 00:05:59,810
training the analysis articulates into

00:05:57,409 --> 00:06:01,340
three steps and we don't have time to

00:05:59,810 --> 00:06:03,259
cover all the details of the

00:06:01,340 --> 00:06:06,110
implementation because I would like to

00:06:03,259 --> 00:06:07,820
leave some time for questions but I'll

00:06:06,110 --> 00:06:09,710
try to give an overview of the

00:06:07,820 --> 00:06:13,490
challenges in the solutions at each of

00:06:09,710 --> 00:06:15,530
these steps step one burdens extraction

00:06:13,490 --> 00:06:19,039
so finding the sentences in the text

00:06:15,530 --> 00:06:21,620
that define rules in this case having a

00:06:19,039 --> 00:06:24,199
limited vocabulary actually works in our

00:06:21,620 --> 00:06:27,289
favor so we can come up with a short

00:06:24,199 --> 00:06:29,449
list with a set of verbs that are very

00:06:27,289 --> 00:06:33,620
likely to point us at the definition of

00:06:29,449 --> 00:06:36,110
a burden so for each sentence if any of

00:06:33,620 --> 00:06:38,870
these verbs appear in the text then

00:06:36,110 --> 00:06:39,430
we'll label that sentence as a burden it

00:06:38,870 --> 00:06:41,680
is a pretty

00:06:39,430 --> 00:06:46,270
course classification rule but we don't

00:06:41,680 --> 00:06:49,000
have a label set and even you know being

00:06:46,270 --> 00:06:51,580
a pretty high level business troll we

00:06:49,000 --> 00:06:53,620
get point 89 accuracy so the proportion

00:06:51,580 --> 00:06:56,890
of sentences correctly classified it's

00:06:53,620 --> 00:06:59,320
89 percent and we get point 97 recall

00:06:56,890 --> 00:07:01,260
where the proportion which is a

00:06:59,320 --> 00:07:08,260
proportion of burdens classified

00:07:01,260 --> 00:07:10,570
correctly classified as four then the

00:07:08,260 --> 00:07:12,130
next step is to identifying the subjects

00:07:10,570 --> 00:07:14,080
so we want to know who's responsible for

00:07:12,130 --> 00:07:16,210
complying with this rules the problem

00:07:14,080 --> 00:07:18,040
here is the sentence and the sentences

00:07:16,210 --> 00:07:19,960
can be really long can be complicated

00:07:18,040 --> 00:07:23,890
and sometimes it can be sentences the

00:07:19,960 --> 00:07:26,020
subject can be a sentence on its own so

00:07:23,890 --> 00:07:28,270
we use a dependency parser to represent

00:07:26,020 --> 00:07:30,790
the syntactic relationship between words

00:07:28,270 --> 00:07:33,190
as a tree structure and then we navigate

00:07:30,790 --> 00:07:35,620
the subtree of the subject to identify

00:07:33,190 --> 00:07:37,560
all the words that define an and I have

00:07:35,620 --> 00:07:40,360
an example here to make it more clear

00:07:37,560 --> 00:07:43,360
the subject the main verb of the

00:07:40,360 --> 00:07:46,840
sentence here is keep and that's the

00:07:43,360 --> 00:07:49,120
head of our tree we also have that the

00:07:46,840 --> 00:07:51,250
subject the dependency parser identifies

00:07:49,120 --> 00:07:54,250
organizations as the subject of the

00:07:51,250 --> 00:07:57,700
sentence and then all of the words that

00:07:54,250 --> 00:07:59,950
define organizations are actually have

00:07:57,700 --> 00:08:02,140
actually a parent-child relationship

00:07:59,950 --> 00:08:04,710
with organization and so that's why

00:08:02,140 --> 00:08:07,660
navigating the tree this sub tree will

00:08:04,710 --> 00:08:11,580
just let us find all of the definition

00:08:07,660 --> 00:08:11,580
the full definition of the subject here

00:08:11,910 --> 00:08:18,190
the final step is clustering analysis of

00:08:15,700 --> 00:08:20,170
the subjects so the objective here is to

00:08:18,190 --> 00:08:22,300
organize the burdens into homogeneous

00:08:20,170 --> 00:08:27,100
groups based on the entities that they

00:08:22,300 --> 00:08:30,850
affect at this point we're not entirely

00:08:27,100 --> 00:08:32,470
sure still of what we want to be what

00:08:30,850 --> 00:08:34,000
what to expect from the results of the

00:08:32,470 --> 00:08:36,520
analysis that's why we use clustering

00:08:34,000 --> 00:08:39,550
but we want to see we're looking for any

00:08:36,520 --> 00:08:41,110
kind of pattern or regularity and we

00:08:39,550 --> 00:08:42,910
would like to see a difference between

00:08:41,110 --> 00:08:45,730
public and private and responsibilities

00:08:42,910 --> 00:08:50,600
if they exist and maybe similarities

00:08:45,730 --> 00:08:52,190
across industries before we can

00:08:50,600 --> 00:08:54,470
the clustering analysis we need to

00:08:52,190 --> 00:08:56,330
represent subjects of the burdens into a

00:08:54,470 --> 00:08:59,750
vector space that we need to have some

00:08:56,330 --> 00:09:01,520
numbers instead of strings and so before

00:08:59,750 --> 00:09:03,470
we even do that we need to do some

00:09:01,520 --> 00:09:04,520
sentence normalization this is one of

00:09:03,470 --> 00:09:06,170
the steps that would you here for

00:09:04,520 --> 00:09:08,480
example is to delete the stop words

00:09:06,170 --> 00:09:11,480
these are words that appear very

00:09:08,480 --> 00:09:13,070
frequently in the text like the but they

00:09:11,480 --> 00:09:17,030
don't really add a lot of information so

00:09:13,070 --> 00:09:18,740
we're just going to ignore them the next

00:09:17,030 --> 00:09:21,680
step is we need to actually project to

00:09:18,740 --> 00:09:24,320
this the sentences into a vector

00:09:21,680 --> 00:09:26,960
representation and so we do that by

00:09:24,320 --> 00:09:30,410
using a semantic space in a semantic

00:09:26,960 --> 00:09:33,170
space words that have similar meaning

00:09:30,410 --> 00:09:34,730
are going to be projected with vectors

00:09:33,170 --> 00:09:36,890
that are close to each other in that

00:09:34,730 --> 00:09:41,000
space and so you can do operations on

00:09:36,890 --> 00:09:42,650
the vectors and one popular example is

00:09:41,000 --> 00:09:45,230
if you take the vector for King and

00:09:42,650 --> 00:09:47,030
subtract the vector for men and then add

00:09:45,230 --> 00:09:47,690
the vector for women you get the vector

00:09:47,030 --> 00:09:49,160
for Qin

00:09:47,690 --> 00:09:52,700
so you can do this kind of operate kinds

00:09:49,160 --> 00:09:56,270
of operations the third step is

00:09:52,700 --> 00:09:57,530
dimensionality reduction the vectors in

00:09:56,270 --> 00:09:59,870
the semantic space are still pretty

00:09:57,530 --> 00:10:02,360
large and so we just do some fancy math

00:09:59,870 --> 00:10:02,950
to represent them into two-dimensional

00:10:02,360 --> 00:10:05,060
space

00:10:02,950 --> 00:10:09,710
and then finally we can do clocks

00:10:05,060 --> 00:10:12,650
running for clustering I use k-means the

00:10:09,710 --> 00:10:15,700
goal of k-means is to partition and data

00:10:12,650 --> 00:10:18,380
points into K clusters and it does so by

00:10:15,700 --> 00:10:21,530
assigning each data point to the cluster

00:10:18,380 --> 00:10:23,060
with the nearest me there is one of the

00:10:21,530 --> 00:10:25,130
reasons to choose camions is that it's

00:10:23,060 --> 00:10:27,080
very easy to interpret the results and

00:10:25,130 --> 00:10:29,240
they're very very intuitive so the

00:10:27,080 --> 00:10:31,070
average of the cluster can serve as a

00:10:29,240 --> 00:10:32,150
prototype for the group so that means

00:10:31,070 --> 00:10:35,150
that you can just look at this one

00:10:32,150 --> 00:10:37,070
average centroid and kind of get a feel

00:10:35,150 --> 00:10:42,680
for what the group represents if you've

00:10:37,070 --> 00:10:44,960
done a good job the plot here shows the

00:10:42,680 --> 00:10:46,670
representation of the Birdland subjects

00:10:44,960 --> 00:10:49,640
into the 2d metro space so that's what

00:10:46,670 --> 00:10:52,340
each point is and you can see that the

00:10:49,640 --> 00:10:55,520
the projection has this nice like three

00:10:52,340 --> 00:10:57,260
points three shapes coming out of the

00:10:55,520 --> 00:10:59,650
center of the plot so it looks like

00:10:57,260 --> 00:11:03,040
we've we've done a good job in terms of

00:10:59,650 --> 00:11:06,480
creating the groups

00:11:03,040 --> 00:11:09,670
for evaluation we're going to use tf-idf

00:11:06,480 --> 00:11:11,650
t f stands for term frequency that's the

00:11:09,670 --> 00:11:13,270
number of time a word or a term appears

00:11:11,650 --> 00:11:16,540
in a document which in our case is a

00:11:13,270 --> 00:11:20,350
sentence and the inverse document

00:11:16,540 --> 00:11:22,360
frequency this is the this is

00:11:20,350 --> 00:11:24,280
proportional to the number of documents

00:11:22,360 --> 00:11:27,760
which in again in this case our

00:11:24,280 --> 00:11:30,220
sentences where the word appears so what

00:11:27,760 --> 00:11:34,750
tf-idf does basically is gives you a

00:11:30,220 --> 00:11:37,060
measure of the term frequency but also

00:11:34,750 --> 00:11:39,280
it weights it down if the word appears

00:11:37,060 --> 00:11:41,110
in many documents and so that's

00:11:39,280 --> 00:11:43,870
important because a word that appears in

00:11:41,110 --> 00:11:45,870
many documents will have less power in

00:11:43,870 --> 00:11:49,810
explaining the difference between them

00:11:45,870 --> 00:11:52,780
so what's important here we consider the

00:11:49,810 --> 00:11:54,670
top the tf-idf score for the top words

00:11:52,780 --> 00:11:55,600
in each group and what's important here

00:11:54,670 --> 00:11:58,420
is that they're pretty well separated

00:11:55,600 --> 00:12:03,700
there's no overlapping so that's what we

00:11:58,420 --> 00:12:07,150
want going to look into more details in

00:12:03,700 --> 00:12:08,800
the group the first group you can see

00:12:07,150 --> 00:12:11,560
that this first three with the top three

00:12:08,800 --> 00:12:13,870
words here for tf-idf are transportation

00:12:11,560 --> 00:12:17,410
service and provider and every other

00:12:13,870 --> 00:12:20,110
word has a much lower score so we can

00:12:17,410 --> 00:12:22,630
say that this is a group that focuses on

00:12:20,110 --> 00:12:24,010
transportation standards we don't see

00:12:22,630 --> 00:12:25,810
difference between public and private

00:12:24,010 --> 00:12:28,870
responsibilities but that kind of makes

00:12:25,810 --> 00:12:31,560
sense and this is about 21% of the

00:12:28,870 --> 00:12:31,560
burdens in this work

00:12:31,920 --> 00:12:41,200
the second group has words like surface

00:12:36,430 --> 00:12:43,030
trail axis parking these are old words

00:12:41,200 --> 00:12:46,210
that refer to physical barriers and

00:12:43,030 --> 00:12:48,400
public spaces and so that's what we're

00:12:46,210 --> 00:12:50,440
gonna call this group there game there's

00:12:48,400 --> 00:12:53,920
no difference between public and private

00:12:50,440 --> 00:12:57,220
here there's there's no really really no

00:12:53,920 --> 00:12:59,650
reason for that to happen so that's fine

00:12:57,220 --> 00:13:01,390
and then we have about 25 percent of the

00:12:59,650 --> 00:13:05,530
burdens that are classified in this

00:13:01,390 --> 00:13:08,380
group and then finally we have this

00:13:05,530 --> 00:13:11,200
group where organization is by far the

00:13:08,380 --> 00:13:13,980
husband fired the highest score and then

00:13:11,200 --> 00:13:16,089
everything else can be a little bit

00:13:13,980 --> 00:13:19,209
confusing so if we

00:13:16,089 --> 00:13:22,480
we can have we have public over here we

00:13:19,209 --> 00:13:25,209
have municipality and Minister so that

00:13:22,480 --> 00:13:27,430
points is as burdens that are probably

00:13:25,209 --> 00:13:29,879
government responsibility but then we

00:13:27,430 --> 00:13:33,490
have words like organization person

00:13:29,879 --> 00:13:35,589
employer and others that are kind of

00:13:33,490 --> 00:13:37,529
ambiguous we can't really say whether

00:13:35,589 --> 00:13:40,899
it's public or private responsibility

00:13:37,529 --> 00:13:43,059
and there are more in-depth analysis of

00:13:40,899 --> 00:13:45,579
the burdens in this group it turns out

00:13:43,059 --> 00:13:48,129
that the bus that they're mostly about

00:13:45,579 --> 00:13:49,899
administration compliance and standards

00:13:48,129 --> 00:13:51,749
and then about half of the length of the

00:13:49,899 --> 00:13:58,420
burdens that we extracted from the tax

00:13:51,749 --> 00:14:01,389
so this third is ambiguity to recap

00:13:58,420 --> 00:14:03,339
everything we were in terms of content

00:14:01,389 --> 00:14:04,839
we wanted to find those and obligations

00:14:03,339 --> 00:14:08,769
and we were able to automate the

00:14:04,839 --> 00:14:10,360
extraction of burdens in terms of still

00:14:08,769 --> 00:14:12,220
in terms of content we wanted to know

00:14:10,360 --> 00:14:15,009
what the entities affected were and we

00:14:12,220 --> 00:14:18,819
were able to do that by extracting the

00:14:15,009 --> 00:14:20,230
subjects of the sentences and then we

00:14:18,819 --> 00:14:23,110
wanted to find some homogeneous group

00:14:20,230 --> 00:14:25,559
which we did successfully by organizing

00:14:23,110 --> 00:14:28,589
them into three groups which he means

00:14:25,559 --> 00:14:31,089
the next thing we wanted to look at was

00:14:28,589 --> 00:14:32,829
patterns across industries and we didn't

00:14:31,089 --> 00:14:34,809
really find that but we did find that

00:14:32,829 --> 00:14:36,790
the legislation has a strong focus on

00:14:34,809 --> 00:14:38,439
physical barriers and transportation and

00:14:36,790 --> 00:14:40,660
then a large proportion that is

00:14:38,439 --> 00:14:42,249
dedicated to administration and

00:14:40,660 --> 00:14:46,660
standard-definition so we got this like

00:14:42,249 --> 00:14:48,639
three main topics we where I'm really

00:14:46,660 --> 00:14:51,160
able to find the difference between

00:14:48,639 --> 00:14:53,290
private and public and that was partly

00:14:51,160 --> 00:14:55,749
because it wasn't really important but

00:14:53,290 --> 00:14:57,699
also not super clear in the last group

00:14:55,749 --> 00:15:00,249
and so we were able to highlight some

00:14:57,699 --> 00:15:04,990
ambiguities with respect to the last

00:15:00,249 --> 00:15:06,850
group so this project was a

00:15:04,990 --> 00:15:08,319
proof-of-concept and so it was limited

00:15:06,850 --> 00:15:09,939
in scope and there's definitely more

00:15:08,319 --> 00:15:11,259
that can be done in terms of refining

00:15:09,939 --> 00:15:14,499
the kind of information that is

00:15:11,259 --> 00:15:16,839
destructed but it is a framework that

00:15:14,499 --> 00:15:19,809
can be generalized and easily applied to

00:15:16,839 --> 00:15:21,819
any legislation and an e domain so I see

00:15:19,809 --> 00:15:24,490
it as a first step towards an abstract

00:15:21,819 --> 00:15:26,529
representation of laws and that can

00:15:24,490 --> 00:15:28,360
serve the purpose of improving my

00:15:26,529 --> 00:15:30,030
interpret ability in at least a couple

00:15:28,360 --> 00:15:31,920
of ways

00:15:30,030 --> 00:15:34,920
on one end it helps extracting

00:15:31,920 --> 00:15:36,600
information and summarizing it so that

00:15:34,920 --> 00:15:38,430
the rules and requirements can be made

00:15:36,600 --> 00:15:39,810
more accessible to anyone that needs to

00:15:38,430 --> 00:15:41,670
follow them whether they're an

00:15:39,810 --> 00:15:44,880
organization we don't like a department

00:15:41,670 --> 00:15:47,430
or a regular person and then on the

00:15:44,880 --> 00:15:49,140
other hand it can help lawmakers by

00:15:47,430 --> 00:15:51,450
highlighting parts of the legislation

00:15:49,140 --> 00:15:53,670
that is ambiguous and could be rewritten

00:15:51,450 --> 00:15:56,460
or adapted to be more clear and more

00:15:53,670 --> 00:15:58,020
accessible so this could be an

00:15:56,460 --> 00:15:59,850
instrument for both helping the

00:15:58,020 --> 00:16:01,890
understanding of the existing

00:15:59,850 --> 00:16:04,500
legislation but also improving the way

00:16:01,890 --> 00:16:06,660
we write laws so that going forward our

00:16:04,500 --> 00:16:08,850
legislators can write laws that are more

00:16:06,660 --> 00:16:13,380
interpretable and more approachable for

00:16:08,850 --> 00:16:16,260
everyone if you're interested in seeing

00:16:13,380 --> 00:16:18,380
the code and sort of like the technical

00:16:16,260 --> 00:16:24,870
details of the implementation there's a

00:16:18,380 --> 00:16:28,110
repository on github at Fargus this

00:16:24,870 --> 00:16:31,590
slides are on my personal github and you

00:16:28,110 --> 00:16:36,920
can find me in the slack at CSP 5 - QA

00:16:31,590 --> 00:16:40,560
or feel free to eat DM me on Twitter

00:16:36,920 --> 00:16:44,520
great thank you very much yeah so we did

00:16:40,560 --> 00:16:47,250
get a couple questions we want to jump

00:16:44,520 --> 00:16:49,830
straight into the yeah yeah the

00:16:47,250 --> 00:16:55,260
questions are I can help as well oh I

00:16:49,830 --> 00:16:57,570
get sued I'm good okay so the first one

00:16:55,260 --> 00:16:59,850
both Canada and the US have common law

00:16:57,570 --> 00:17:02,310
systems would you need to approach a

00:16:59,850 --> 00:17:04,589
European style or even Quebec civil law

00:17:02,310 --> 00:17:12,560
systems with a more closed known

00:17:04,589 --> 00:17:14,490
historical system differently um I just

00:17:12,560 --> 00:17:16,079
digest the question I'm not entirely

00:17:14,490 --> 00:17:17,520
sure that I understand what you mean by

00:17:16,079 --> 00:17:25,589
that in terms of technical

00:17:17,520 --> 00:17:29,040
implementation I think this is focused

00:17:25,589 --> 00:17:30,870
on the access to information with common

00:17:29,040 --> 00:17:33,090
law versus civil laws some sort of

00:17:30,870 --> 00:17:35,370
systems that deal with more closed

00:17:33,090 --> 00:17:40,080
non-historic systems historical based

00:17:35,370 --> 00:17:42,300
systems need to be approached

00:17:40,080 --> 00:17:43,950
differently to be honest

00:17:42,300 --> 00:17:46,830
if I understand correctly the question

00:17:43,950 --> 00:17:50,040
in terms of technical implementation I

00:17:46,830 --> 00:17:56,490
think this would be a way to like it

00:17:50,040 --> 00:17:57,600
would be possible to sort of back apply

00:17:56,490 --> 00:18:00,900
the same frame where you can tweak it

00:17:57,600 --> 00:18:04,830
very easily it's not that that's why I

00:18:00,900 --> 00:18:06,120
was saying the the the it doesn't use it

00:18:04,830 --> 00:18:08,820
because it doesn't use a supervised

00:18:06,120 --> 00:18:11,940
methodology there's a lot more freedom

00:18:08,820 --> 00:18:15,559
and how you play around with parameters

00:18:11,940 --> 00:18:15,559
and the steps of the process in general

00:18:17,510 --> 00:18:22,410
the next one

00:18:19,410 --> 00:18:24,179
but sorry Kyla feel free to like hang me

00:18:22,410 --> 00:18:25,590
if I haven't answered your question like

00:18:24,179 --> 00:18:27,690
if I haven't actually answered your

00:18:25,590 --> 00:18:32,250
questions I'm not entirely sure that

00:18:27,690 --> 00:18:37,290
I've hit the point um the next one did

00:18:32,250 --> 00:18:39,240
fancy math Indonesia okay I didn't want

00:18:37,290 --> 00:18:41,400
to go down the path of explaining what a

00:18:39,240 --> 00:18:46,860
manifold is and then you know lose

00:18:41,400 --> 00:18:50,420
everyone yeah it's a it's hard to fit

00:18:46,860 --> 00:18:50,420
everything into a short 15 minute

00:18:52,550 --> 00:18:59,160
tactical stuff that I couldn't pack into

00:18:55,590 --> 00:19:01,050
the 20 minutes yeah and there's a lot of

00:18:59,160 --> 00:19:02,670
conversation going on in the thread here

00:19:01,050 --> 00:19:05,160
are around different types of tools and

00:19:02,670 --> 00:19:07,980
different people pointing to different

00:19:05,160 --> 00:19:09,990
workflows and processes but I think this

00:19:07,980 --> 00:19:13,890
is a great thing for us to continue in

00:19:09,990 --> 00:19:16,290
slack and we can have the thread here

00:19:13,890 --> 00:19:18,990
available to you and also anybody who's

00:19:16,290 --> 00:19:24,210
got questions just jump over to the

00:19:18,990 --> 00:19:26,400
slack channel so I think yeah oh yeah if

00:19:24,210 --> 00:19:30,000
you can't give me access to this threat

00:19:26,400 --> 00:19:35,390
I will respond to everyone sounds great

00:19:30,000 --> 00:19:35,390

YouTube URL: https://www.youtube.com/watch?v=8texkXDprQE


