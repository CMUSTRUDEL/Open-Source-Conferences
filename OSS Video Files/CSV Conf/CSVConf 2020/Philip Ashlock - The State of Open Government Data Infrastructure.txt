Title: Philip Ashlock - The State of Open Government Data Infrastructure
Publication date: 2020-05-28
Playlist: CSVConf 2020
Description: 
	This talk provides an overview of the current state of open government data infrastructure and the broader ecosystem from the perspective of Data.gov and the implementation of open data laws in the United States. This will cover the widespread use of the W3C DCAT metadata standard across all Federal agencies as well as widespread use by state and local governments. This same metadata also helps generate the Schema.org variant of the specification with fuels listings on general purpose platforms like Google Dataset Search. The European Union has been updating their DCAT Application Profile with the recent development of DCAT 2.0 and the US Government will be revising its DCAT specification to meet updated requirements in the new comprehensive open data law ("Evidence Act") with public input on GitHub. This talk will provide an overview of the current state of this infrastructure and ecosystem and ponder how other metadata standards including CSVW, Tabular Data Packages, DSPL, and SDMX fit into the mix as well as how we can better leverage CSVs and tabular data tools and capabilities within platforms like Data.gov and other CKAN-based data catalogs. Since this talk should be in the midst of the public comment period for revising our USG-focused profile of DCAT, it will also be a good opportunity to solicit comments and public participation in the update to the metadata specification used across all government agencies. The current legacy version of this can be found at https://resources.data.gov/schemas/dcat-us/v1.1/

--
csv,conf,v5 is a community conference for data makers everywhere, featuring stories about data sharing and data analysis from science, journalism, government, and open source.  Held May 13-14, 2020, Online. https://csvconf.com/
Captions: 
	00:00:00,000 --> 00:00:07,980
all right well thank you all for joining

00:00:03,030 --> 00:00:09,960
this session so I am Phil Ashlock can

00:00:07,980 --> 00:00:11,460
you talk about the state of open

00:00:09,960 --> 00:00:12,360
government data infrastructure obviously

00:00:11,460 --> 00:00:13,889
a little bit from my own bias

00:00:12,360 --> 00:00:16,890
perspective but I think it'll be useful

00:00:13,889 --> 00:00:19,710
for a lot of folks here so just first a

00:00:16,890 --> 00:00:23,210
little bit about myself I'm coming to

00:00:19,710 --> 00:00:25,380
you from from sunny Washington DC

00:00:23,210 --> 00:00:27,269
actually its I have a beautiful view

00:00:25,380 --> 00:00:29,849
from from my apartment so welcome to my

00:00:27,269 --> 00:00:31,050
my apartment I wish I could show it to

00:00:29,849 --> 00:00:34,079
you what I can't move the camera around

00:00:31,050 --> 00:00:35,910
but if you've never been to DC hopefully

00:00:34,079 --> 00:00:37,590
you'll get a chance to sometime sorry

00:00:35,910 --> 00:00:39,660
can't help be here in person but but

00:00:37,590 --> 00:00:43,079
maybe next time I joined the federal

00:00:39,660 --> 00:00:45,600
government in 2012 and I am currently

00:00:43,079 --> 00:00:49,739
the director of the data and analytics

00:00:45,600 --> 00:00:52,230
portfolio which sits in GSA technology

00:00:49,739 --> 00:00:54,690
transformational services division so

00:00:52,230 --> 00:00:56,670
it's mostly just like a big or try to

00:00:54,690 --> 00:01:00,109
describe here more than my title but for

00:00:56,670 --> 00:01:02,789
those who aren't familiar GSA is a

00:01:00,109 --> 00:01:05,129
agency that mostly serves other agencies

00:01:02,789 --> 00:01:06,510
we manage public buildings and

00:01:05,129 --> 00:01:09,210
government-wide contracting and then we

00:01:06,510 --> 00:01:10,710
do technology services for other

00:01:09,210 --> 00:01:14,130
agencies as well as directly to the

00:01:10,710 --> 00:01:16,560
public including sites like usa.gov and

00:01:14,130 --> 00:01:19,380
data gov data.gov is where I've spent

00:01:16,560 --> 00:01:21,570
most of my time and continue to support

00:01:19,380 --> 00:01:23,700
level work there and our team also works

00:01:21,570 --> 00:01:25,409
closely to support the office of the

00:01:23,700 --> 00:01:29,280
federal chief information officer on

00:01:25,409 --> 00:01:30,930
federal IT policy on data policy and

00:01:29,280 --> 00:01:33,930
that's that's part of the White House

00:01:30,930 --> 00:01:35,280
Office management budget one colleague

00:01:33,930 --> 00:01:37,979
there in particular Rebecca Williams I

00:01:35,280 --> 00:01:41,159
believe will be giving a talk later

00:01:37,979 --> 00:01:42,600
today as well and just let stuff I care

00:01:41,159 --> 00:01:44,640
about I care about open government open

00:01:42,600 --> 00:01:47,460
data open standards that's that's why

00:01:44,640 --> 00:01:49,710
I'm here and in this context and the

00:01:47,460 --> 00:01:52,439
public sector I really like to emphasize

00:01:49,710 --> 00:01:54,869
this idea of infrastructure Civic

00:01:52,439 --> 00:01:57,479
infrastructure especially in the 21st

00:01:54,869 --> 00:01:58,920
century I think it's important to kind

00:01:57,479 --> 00:02:00,780
of help elevate some of these kind of

00:01:58,920 --> 00:02:03,149
more abstract and invisible parts of

00:02:00,780 --> 00:02:04,619
infrastructure that we don't see as much

00:02:03,149 --> 00:02:06,630
as traditional infrastructure like roads

00:02:04,619 --> 00:02:08,970
and bridges and you know public

00:02:06,630 --> 00:02:10,950
transportation systems but is you know

00:02:08,970 --> 00:02:13,950
equally if not more important in many

00:02:10,950 --> 00:02:15,959
ways in terms of helping to shape it

00:02:13,950 --> 00:02:18,360
and be involved with it and maintain it

00:02:15,959 --> 00:02:21,330
and and make sure it serves the public

00:02:18,360 --> 00:02:23,160
good so let's see the idea of

00:02:21,330 --> 00:02:25,769
infrastructure behind my top um but

00:02:23,160 --> 00:02:27,900
before talking about the current state I

00:02:25,769 --> 00:02:30,360
think it's good to sort of provide some

00:02:27,900 --> 00:02:32,340
historical context so if we're talking

00:02:30,360 --> 00:02:34,349
about machine readable open government

00:02:32,340 --> 00:02:37,080
data we got to start with the machine

00:02:34,349 --> 00:02:39,989
readable part which you know actually

00:02:37,080 --> 00:02:43,049
dates back to an invention here in

00:02:39,989 --> 00:02:45,090
Washington DC back in the 1890s the

00:02:43,049 --> 00:02:48,239
Herman Herman Hollerith created the

00:02:45,090 --> 00:02:50,819
tabulating machine actually to perform

00:02:48,239 --> 00:02:54,450
the 1890 census and that was really the

00:02:50,819 --> 00:02:56,370
birth of machinery to machine readable

00:02:54,450 --> 00:02:58,110
data processing there's actually the

00:02:56,370 --> 00:02:59,310
factory down in Georgetown in DC still

00:02:58,110 --> 00:03:00,930
exists if you're ever here and want to

00:02:59,310 --> 00:03:02,579
sort of see that the kind of birthplace

00:03:00,930 --> 00:03:04,950
of machine readable data and then the

00:03:02,579 --> 00:03:06,269
open part really kind of in the modern

00:03:04,950 --> 00:03:09,480
era comes with the Freedom of

00:03:06,269 --> 00:03:12,209
Information Act in 1966 which still

00:03:09,480 --> 00:03:14,760
serves as the bedrock for kind of open

00:03:12,209 --> 00:03:16,170
data and open access to information and

00:03:14,760 --> 00:03:19,200
the federal government here in the US

00:03:16,170 --> 00:03:20,609
and many other other countries and state

00:03:19,200 --> 00:03:22,980
local ruins have similar laws as well

00:03:20,609 --> 00:03:24,329
and then of course we start to get you

00:03:22,980 --> 00:03:29,340
know some of this data on the web in the

00:03:24,329 --> 00:03:31,380
1990s and then it's the it's around 2009

00:03:29,340 --> 00:03:33,209
and and thereafter where we start

00:03:31,380 --> 00:03:36,120
getting these big data catalogues so

00:03:33,209 --> 00:03:38,700
DITA actually launched almost exactly 11

00:03:36,120 --> 00:03:40,530
years ago in 2009 and then many other

00:03:38,700 --> 00:03:42,299
you know data backup UK many other

00:03:40,530 --> 00:03:44,250
countries state local data catalogues

00:03:42,299 --> 00:03:46,889
and our data policy is kind of

00:03:44,250 --> 00:03:50,100
incrementally started to develop from

00:03:46,889 --> 00:03:51,239
there and then at least here in the

00:03:50,100 --> 00:03:53,790
federal government we've kind of come to

00:03:51,239 --> 00:03:55,440
a new era with with policy and that

00:03:53,790 --> 00:03:57,480
really sort of sets a strong foundation

00:03:55,440 --> 00:03:58,470
for this work moving forward so the

00:03:57,480 --> 00:04:02,130
foundations for evidence-based

00:03:58,470 --> 00:04:03,480
policymaking Act came into effect last

00:04:02,130 --> 00:04:05,579
year and there's a lot of work on

00:04:03,480 --> 00:04:09,389
implementing it as well as the federal

00:04:05,579 --> 00:04:12,569
data strategy which sets a sort of a

00:04:09,389 --> 00:04:14,310
strong foundation for data management in

00:04:12,569 --> 00:04:16,799
the government really for the next

00:04:14,310 --> 00:04:18,450
decade or so and so I'm gonna be getting

00:04:16,799 --> 00:04:20,639
into some of these things on the bottom

00:04:18,450 --> 00:04:22,109
of this slide and so the current state

00:04:20,639 --> 00:04:25,490
in the future but just want to provide

00:04:22,109 --> 00:04:27,810
some of that historical context first so

00:04:25,490 --> 00:04:29,430
you know my main focus has been

00:04:27,810 --> 00:04:32,639
it's Bendita documents I just want to

00:04:29,430 --> 00:04:35,400
give a quick overview of that like I

00:04:32,639 --> 00:04:37,800
mentioned it launched 11 years ago it's

00:04:35,400 --> 00:04:39,090
gone through a couple iterations it

00:04:37,800 --> 00:04:42,900
looks like this right now I'm sure

00:04:39,090 --> 00:04:44,669
you're familiar with it and just a quick

00:04:42,900 --> 00:04:46,470
sort of overview of some of the stats so

00:04:44,669 --> 00:04:48,030
it serves as the the federal government

00:04:46,470 --> 00:04:50,250
the US federal government's open data

00:04:48,030 --> 00:04:52,530
catalog but we also try and think it as

00:04:50,250 --> 00:04:54,600
a national catalog in the sense that it

00:04:52,530 --> 00:04:57,960
also incorporates some state and local

00:04:54,600 --> 00:05:00,030
government data catalogues on a

00:04:57,960 --> 00:05:02,070
voluntary basis actually we're right now

00:05:00,030 --> 00:05:03,270
about 85 percent of our data sets are

00:05:02,070 --> 00:05:05,940
from the federal government and 15

00:05:03,270 --> 00:05:07,260
percent from local and it includes these

00:05:05,940 --> 00:05:10,860
comprehensive enterprise data

00:05:07,260 --> 00:05:12,570
inventories of metadata from from

00:05:10,860 --> 00:05:14,160
federal agencies and even includes some

00:05:12,570 --> 00:05:16,410
information about some non-public data

00:05:14,160 --> 00:05:17,760
sets which are not available to download

00:05:16,410 --> 00:05:20,340
but just the information about them is

00:05:17,760 --> 00:05:22,889
public and so currently we're operating

00:05:20,340 --> 00:05:24,990
under this new statutory requirement

00:05:22,889 --> 00:05:26,100
from the the Evidence Act and title 2 of

00:05:24,990 --> 00:05:29,970
that just called the open government

00:05:26,100 --> 00:05:31,919
data act and that sort of sort of builds

00:05:29,970 --> 00:05:32,910
a sort of more permanent foundation for

00:05:31,919 --> 00:05:35,940
the work that we're doing but also

00:05:32,910 --> 00:05:37,860
expands the scope of the agencies

00:05:35,940 --> 00:05:39,930
covered so went from just the two dozen

00:05:37,860 --> 00:05:41,340
or so sort of primary federal agencies

00:05:39,930 --> 00:05:43,320
covered so you really all sort of

00:05:41,340 --> 00:05:44,700
independent agency is another agency so

00:05:43,320 --> 00:05:46,229
about a hundred additional agencies are

00:05:44,700 --> 00:05:49,550
now sort of more clearly covered by this

00:05:46,229 --> 00:05:52,890
new law so it kind of got no more to the

00:05:49,550 --> 00:05:55,680
stronger bigger longer more mandate more

00:05:52,890 --> 00:05:59,789
permanent mandate moving forward but

00:05:55,680 --> 00:06:01,289
what happened in 2013 with the sort of

00:05:59,789 --> 00:06:04,080
executive order that sort of first

00:06:01,289 --> 00:06:05,760
started to set be the kind of

00:06:04,080 --> 00:06:07,860
architecture for how we operate is it

00:06:05,760 --> 00:06:09,810
changed data.gov and kind of the

00:06:07,860 --> 00:06:11,669
publishing model for this catalog to be

00:06:09,810 --> 00:06:14,190
more decentralized and to be and to have

00:06:11,669 --> 00:06:17,270
this federated model so that each

00:06:14,190 --> 00:06:19,650
federal agency is publishing a metadata

00:06:17,270 --> 00:06:22,229
inventory using a standard metadata

00:06:19,650 --> 00:06:23,850
schema publishing it as a DJ JSON file

00:06:22,229 --> 00:06:25,919
and then theater I could have acts more

00:06:23,850 --> 00:06:27,960
like an aggregator and the same way that

00:06:25,919 --> 00:06:30,090
other entities arguable too as well

00:06:27,960 --> 00:06:31,919
including those that are doing similar

00:06:30,090 --> 00:06:34,380
types of aggregation now today like

00:06:31,919 --> 00:06:35,789
Google data set search so this

00:06:34,380 --> 00:06:39,539
decentralized model has also helped us

00:06:35,789 --> 00:06:40,979
sort of scale and evolve so just some

00:06:39,539 --> 00:06:41,490
sort of details about this kind of

00:06:40,979 --> 00:06:43,919
federated

00:06:41,490 --> 00:06:45,569
boosting model you know we're not

00:06:43,919 --> 00:06:47,400
hosting the data we're really just

00:06:45,569 --> 00:06:50,009
providing these kind of card catalog

00:06:47,400 --> 00:06:52,470
entries of metadata describing each data

00:06:50,009 --> 00:06:54,330
set and that includes the URLs to

00:06:52,470 --> 00:06:56,340
download the data if it is available for

00:06:54,330 --> 00:06:59,729
download and we're pulling those

00:06:56,340 --> 00:07:02,550
metadata from these these data out JSON

00:06:59,729 --> 00:07:05,190
files that each agency usually on a

00:07:02,550 --> 00:07:07,560
daily basis so it's all decentralized

00:07:05,190 --> 00:07:09,139
people aren't editing metadata directly

00:07:07,560 --> 00:07:14,819
onto a directive it's through their own

00:07:09,139 --> 00:07:17,310
metadata files and because of this

00:07:14,819 --> 00:07:20,909
decentralized model we also sort of try

00:07:17,310 --> 00:07:22,889
and provide some quality checks that do

00:07:20,909 --> 00:07:26,039
some automated analysis of metadata at

00:07:22,889 --> 00:07:27,870
each agencies instead of some QA because

00:07:26,039 --> 00:07:29,370
it's so decentralized there's it's

00:07:27,870 --> 00:07:31,440
helpful to sort of provide lots of

00:07:29,370 --> 00:07:32,940
checks and provide feedback so we have

00:07:31,440 --> 00:07:35,509
dashboards and some tools that help

00:07:32,940 --> 00:07:39,690
agency is sort of validate and and

00:07:35,509 --> 00:07:41,430
publish their data JSON files so just to

00:07:39,690 --> 00:07:44,130
get a little bit more of an overview and

00:07:41,430 --> 00:07:46,949
detail some of the recent policy that

00:07:44,130 --> 00:07:48,389
kind of has underpins all this so like I

00:07:46,949 --> 00:07:51,930
said the kind of current era started

00:07:48,389 --> 00:07:53,699
with this 2013 executive order and that

00:07:51,930 --> 00:07:56,340
really you know set the kind of

00:07:53,699 --> 00:07:58,340
architecture for how metadata is

00:07:56,340 --> 00:08:00,690
published and managed and also really

00:07:58,340 --> 00:08:03,960
set a really broad comprehensive scope

00:08:00,690 --> 00:08:06,719
for the the metadata that it was tasking

00:08:03,960 --> 00:08:08,639
agencies to include so it wasn't just

00:08:06,719 --> 00:08:10,050
public datasets it was really thinking

00:08:08,639 --> 00:08:12,150
about all their data assets and sort of

00:08:10,050 --> 00:08:14,430
having a consistent way of classifying

00:08:12,150 --> 00:08:17,270
access level to those and basic details

00:08:14,430 --> 00:08:20,099
about each one and then that policy was

00:08:17,270 --> 00:08:22,380
passed you know as law through through

00:08:20,099 --> 00:08:25,860
Congress through very strong bipartisan

00:08:22,380 --> 00:08:30,300
law itself came from a bipartisan

00:08:25,860 --> 00:08:32,579
commission of experts and and that so

00:08:30,300 --> 00:08:34,020
you know expands the scope of the law in

00:08:32,579 --> 00:08:36,539
terms of agencies covered and really

00:08:34,020 --> 00:08:38,219
makes it a permanent thing through

00:08:36,539 --> 00:08:40,979
legislation as opposed to just an

00:08:38,219 --> 00:08:43,860
executive order and then we also have

00:08:40,979 --> 00:08:47,190
this federal data strategy which is sort

00:08:43,860 --> 00:08:49,350
of setting a framework for kind of

00:08:47,190 --> 00:08:52,410
fundamental principles and practices and

00:08:49,350 --> 00:08:54,520
these here by your action plans to help

00:08:52,410 --> 00:08:58,690
really kind of

00:08:54,520 --> 00:09:01,420
set a long-term foundation and sort of

00:08:58,690 --> 00:09:04,000
have a capacity building for better data

00:09:01,420 --> 00:09:05,470
management across the government really

00:09:04,000 --> 00:09:07,930
you know in the long term so looking at

00:09:05,470 --> 00:09:09,970
like a 10-year long sort of vision but

00:09:07,930 --> 00:09:11,500
doing so through year by year action

00:09:09,970 --> 00:09:13,990
plans and so we're in the first year

00:09:11,500 --> 00:09:15,610
action plan and there's there's quite a

00:09:13,990 --> 00:09:16,720
lot of actions in that that you can

00:09:15,610 --> 00:09:18,330
refer to that are probably of interest

00:09:16,720 --> 00:09:21,310
to you and there's a couple that I will

00:09:18,330 --> 00:09:23,410
refer to here later but just as far as

00:09:21,310 --> 00:09:26,529
some of the specific responsibilities at

00:09:23,410 --> 00:09:28,510
least forty drove in the new law so it

00:09:26,529 --> 00:09:30,190
you know sort of doubles down on on this

00:09:28,510 --> 00:09:31,990
role of managing this federal data

00:09:30,190 --> 00:09:33,550
catalog and it also talks about us

00:09:31,990 --> 00:09:35,770
managing this repository of resources

00:09:33,550 --> 00:09:38,620
which we currently have it resources

00:09:35,770 --> 00:09:40,120
data of it's kind of an interim site

00:09:38,620 --> 00:09:41,350
there that that's about to relaunch in a

00:09:40,120 --> 00:09:43,630
couple weeks but that's meant to help

00:09:41,350 --> 00:09:45,850
provide this repository of tools best

00:09:43,630 --> 00:09:48,250
practices and schema standards to solve

00:09:45,850 --> 00:09:51,940
help support the data catalog and

00:09:48,250 --> 00:09:54,970
related work and then as I mentioned the

00:09:51,940 --> 00:09:57,850
federal data strategy you can read up on

00:09:54,970 --> 00:09:59,410
it at strategy gov but it's it's a

00:09:57,850 --> 00:10:01,990
pretty comprehensive framework that

00:09:59,410 --> 00:10:04,060
really is implemented through these your

00:10:01,990 --> 00:10:05,380
yearly action plans and I just

00:10:04,060 --> 00:10:06,910
highlighted a couple of the actions that

00:10:05,380 --> 00:10:09,700
really relates the work that we're doing

00:10:06,910 --> 00:10:11,440
with data.gov and some of the metadata

00:10:09,700 --> 00:10:15,430
standards but I'll be getting it's a

00:10:11,440 --> 00:10:16,810
little bit more so really the bulk of

00:10:15,430 --> 00:10:19,540
kind of what I want to focus on is kind

00:10:16,810 --> 00:10:20,500
of the state and and future of kind of

00:10:19,540 --> 00:10:24,279
the metadata standards that we're

00:10:20,500 --> 00:10:27,250
working with here so from the 2013

00:10:24,279 --> 00:10:29,230
policy we had this website the project

00:10:27,250 --> 00:10:31,600
open data website that provides from the

00:10:29,230 --> 00:10:34,060
technical guidance and documented the

00:10:31,600 --> 00:10:36,940
schema for implementing this kind of

00:10:34,060 --> 00:10:40,149
decentralized federated model and that's

00:10:36,940 --> 00:10:42,970
evolved over time and as part of the new

00:10:40,149 --> 00:10:44,920
law and updates the work we're doing on

00:10:42,970 --> 00:10:46,959
metadata schema these are kind of being

00:10:44,920 --> 00:10:49,510
renamed so the project open data site is

00:10:46,959 --> 00:10:51,760
now moving over to resources Cedar Cove

00:10:49,510 --> 00:10:54,279
and what we used to refer to you is the

00:10:51,760 --> 00:10:56,320
the metadata schema we called it the

00:10:54,279 --> 00:10:58,180
project open data metadata schema we're

00:10:56,320 --> 00:10:59,709
now trying to start refer to that as DK

00:10:58,180 --> 00:11:03,790
us because it is based on this

00:10:59,709 --> 00:11:06,760
international decad standard and as I

00:11:03,790 --> 00:11:08,060
said before we also have a this new site

00:11:06,760 --> 00:11:10,190
and actually this is a street

00:11:08,060 --> 00:11:11,360
shot of staging site we have actually

00:11:10,190 --> 00:11:14,810
relaunched the site yeah but that should

00:11:11,360 --> 00:11:16,130
be coming next couple weeks but so Tcat

00:11:14,810 --> 00:11:19,750
I'm sure many of you are familiar with

00:11:16,130 --> 00:11:22,160
it but it is the data catalog vocabulary

00:11:19,750 --> 00:11:24,290
metadata standard that's used for a lot

00:11:22,160 --> 00:11:28,540
of data catalogues it Corpse

00:11:24,290 --> 00:11:30,890
incorporates existing vocabularies from

00:11:28,540 --> 00:11:35,720
from things like dublin core sort of

00:11:30,890 --> 00:11:37,460
standard metadata concepts and and

00:11:35,720 --> 00:11:41,060
itself as evolved of years that the

00:11:37,460 --> 00:11:44,390
first incarnation was finalized in 2013

00:11:41,060 --> 00:11:47,150
or 14 and actually we the because of the

00:11:44,390 --> 00:11:49,370
2013 era policy was finalized actually a

00:11:47,150 --> 00:11:51,230
little bit before at the w3c as a

00:11:49,370 --> 00:11:53,660
standards body had finalized the d cat

00:11:51,230 --> 00:11:56,000
specification things were actually a

00:11:53,660 --> 00:11:58,370
little bit out of sync when when we

00:11:56,000 --> 00:12:00,550
wouldn't we published from when the the

00:11:58,370 --> 00:12:03,380
final version of d cat was published so

00:12:00,550 --> 00:12:07,790
we have this public engagement process

00:12:03,380 --> 00:12:09,980
through github both to get feedback on

00:12:07,790 --> 00:12:12,310
issues with that with our version 1.0 of

00:12:09,980 --> 00:12:14,720
the metadata schema but also to look at

00:12:12,310 --> 00:12:17,150
you know things that had been updated in

00:12:14,720 --> 00:12:18,920
the the latest version of d cat so that

00:12:17,150 --> 00:12:21,620
we could align that and so over the

00:12:18,920 --> 00:12:23,030
course of six months or so we went

00:12:21,620 --> 00:12:26,450
through a revision process with a lot of

00:12:23,030 --> 00:12:29,440
public input and input from agencies to

00:12:26,450 --> 00:12:31,520
produce version 1.1 of the schema and

00:12:29,440 --> 00:12:34,640
also got some support from those

00:12:31,520 --> 00:12:37,460
involved with d cat folks from w3c like

00:12:34,640 --> 00:12:39,440
phil archer who helped us kind of

00:12:37,460 --> 00:12:41,090
finalize the json-ld version of our

00:12:39,440 --> 00:12:43,070
metadata schema to ensure that it was

00:12:41,090 --> 00:12:44,840
you know really kind of compatible with

00:12:43,070 --> 00:12:48,410
with T cat and using the proper

00:12:44,840 --> 00:12:52,250
namespaces and all things like that and

00:12:48,410 --> 00:12:54,020
so this is you know just the page that

00:12:52,250 --> 00:12:55,940
documents the current spec the version

00:12:54,020 --> 00:12:58,700
1.1 spec that we're still continuing to

00:12:55,940 --> 00:13:02,570
use although we have a revision process

00:12:58,700 --> 00:13:04,340
that will be coming soon and for those

00:13:02,570 --> 00:13:05,780
who are not familiar it's a quick sort

00:13:04,340 --> 00:13:08,240
of overview of the the kind of data

00:13:05,780 --> 00:13:09,650
model of the spec and I've there's a

00:13:08,240 --> 00:13:11,630
couple fields here that are highlighted

00:13:09,650 --> 00:13:13,580
better custom unique fields for the

00:13:11,630 --> 00:13:14,810
federal government's which I've

00:13:13,580 --> 00:13:19,040
documented here but I won't go into

00:13:14,810 --> 00:13:20,570
detail but you know teeka is actually

00:13:19,040 --> 00:13:21,240
pretty pretty widely used in different

00:13:20,570 --> 00:13:24,870
Shay

00:13:21,240 --> 00:13:26,190
in forms around the world so not only is

00:13:24,870 --> 00:13:28,070
it being used you know by all these

00:13:26,190 --> 00:13:30,779
federal agencies as part of this policy

00:13:28,070 --> 00:13:31,980
but we've because it is based on this

00:13:30,779 --> 00:13:34,290
international standard you know we

00:13:31,980 --> 00:13:35,279
encouraged it's abused by state and

00:13:34,290 --> 00:13:37,440
local governments even though they're

00:13:35,279 --> 00:13:38,820
not bound by the same policy but on a

00:13:37,440 --> 00:13:41,850
voluntary basis they can incorporate

00:13:38,820 --> 00:13:44,160
their metadata into the data catalog as

00:13:41,850 --> 00:13:46,399
long as they sort of meet this minimum

00:13:44,160 --> 00:13:49,320
requirements from this decap based

00:13:46,399 --> 00:13:51,060
schema so there's quite a quite a number

00:13:49,320 --> 00:13:53,700
of federal local governments that are

00:13:51,060 --> 00:13:56,399
that are implementing it as well and

00:13:53,700 --> 00:13:58,260
then you know other other national

00:13:56,399 --> 00:14:00,630
governments so you'll actually sometimes

00:13:58,260 --> 00:14:02,310
you can see references to to our Dean

00:14:00,630 --> 00:14:05,610
about JSON sort of convention and the

00:14:02,310 --> 00:14:08,430
project open data fields strum from some

00:14:05,610 --> 00:14:11,220
other folks like Jeter back up to UK and

00:14:08,430 --> 00:14:13,620
then you know the European Union member

00:14:11,220 --> 00:14:15,930
states have I think works on an

00:14:13,620 --> 00:14:17,520
application profile for dica in the EU

00:14:15,930 --> 00:14:19,649
which is also just gone through a

00:14:17,520 --> 00:14:23,310
revision process and along with the

00:14:19,649 --> 00:14:26,040
update Siddiq at w3c sort of

00:14:23,310 --> 00:14:27,720
international version and then there's a

00:14:26,040 --> 00:14:30,899
schema.org schema for data set which

00:14:27,720 --> 00:14:33,270
itself is based on D cat and that's used

00:14:30,899 --> 00:14:35,550
by Google and other folks that are

00:14:33,270 --> 00:14:37,260
working with schema.org so that's been

00:14:35,550 --> 00:14:40,110
sort of the basis for for things like

00:14:37,260 --> 00:14:41,970
Google's data set search and their

00:14:40,110 --> 00:14:44,760
announcement from a couple months ago

00:14:41,970 --> 00:14:47,160
they noted that schema.org is actually

00:14:44,760 --> 00:14:49,980
widely used by by governments in their

00:14:47,160 --> 00:14:52,980
data catalogs and at least when this was

00:14:49,980 --> 00:14:56,820
published the US had had the most number

00:14:52,980 --> 00:14:57,750
of entries with about two million but DK

00:14:56,820 --> 00:15:00,600
has been going through a revision

00:14:57,750 --> 00:15:02,430
process to be honest I have not been as

00:15:00,600 --> 00:15:04,770
closely involved with this as I as I

00:15:02,430 --> 00:15:08,250
wish I was but is something that I think

00:15:04,770 --> 00:15:10,050
is is is pretty stable now although I

00:15:08,250 --> 00:15:11,670
see that the editors draft date

00:15:10,050 --> 00:15:13,649
continues to be updated so I haven't

00:15:11,670 --> 00:15:15,390
haven't tracked the latest changes but I

00:15:13,649 --> 00:15:18,570
see this dates from just about a week or

00:15:15,390 --> 00:15:20,430
so ago and just to highlight some fields

00:15:18,570 --> 00:15:22,320
in our metadata schema that I think

00:15:20,430 --> 00:15:25,680
might be things I want to dig into a

00:15:22,320 --> 00:15:27,540
little bit more I'm not gonna go into

00:15:25,680 --> 00:15:29,699
too much detail about these but this was

00:15:27,540 --> 00:15:30,980
trying to be a little bit future proof

00:15:29,699 --> 00:15:33,720
and kind of have some extent

00:15:30,980 --> 00:15:35,080
extensibility and our metadata schema to

00:15:33,720 --> 00:15:37,360
let people reference

00:15:35,080 --> 00:15:39,670
kind of lower level metadata so like a

00:15:37,360 --> 00:15:41,710
data dictionary or a schema or a data

00:15:39,670 --> 00:15:44,050
standard that was much more sort of

00:15:41,710 --> 00:15:46,000
specific to that data set because the

00:15:44,050 --> 00:15:47,560
the kind of high-level decap metadata

00:15:46,000 --> 00:15:49,840
fields that we're using are pretty high

00:15:47,560 --> 00:15:51,280
level and they don't really get into the

00:15:49,840 --> 00:15:53,110
level of the richness that you might

00:15:51,280 --> 00:15:55,480
want to provide with a fully documented

00:15:53,110 --> 00:15:57,040
schema our data dictionary so these are

00:15:55,480 --> 00:15:58,720
some ways to reference that or reference

00:15:57,040 --> 00:16:01,390
sort of domain-specific data standard

00:15:58,720 --> 00:16:03,730
that might be being used by that data

00:16:01,390 --> 00:16:05,320
set to be honest these aren't very

00:16:03,730 --> 00:16:07,870
widely used but I'm something I would

00:16:05,320 --> 00:16:09,280
like to to explore further and see what

00:16:07,870 --> 00:16:11,650
we could do to sort of better leverage

00:16:09,280 --> 00:16:14,080
that kind of capability and speaking of

00:16:11,650 --> 00:16:15,700
the future sort a lot of a lot of

00:16:14,080 --> 00:16:17,680
thoughts about you know what more we can

00:16:15,700 --> 00:16:19,060
do and really a big part of my

00:16:17,680 --> 00:16:21,100
motivation for being here is to get

00:16:19,060 --> 00:16:23,680
input from all of you on the future of

00:16:21,100 --> 00:16:25,750
this work it is actually part of our

00:16:23,680 --> 00:16:27,520
mandate to engage the public and have a

00:16:25,750 --> 00:16:29,590
you know standard that's sort of a

00:16:27,520 --> 00:16:32,440
voluntary standards based process for

00:16:29,590 --> 00:16:34,450
developing things like this so just some

00:16:32,440 --> 00:16:37,690
thoughts on sort of the the future of

00:16:34,450 --> 00:16:39,250
some of this work so we do have you know

00:16:37,690 --> 00:16:41,080
we are gonna launch your revision

00:16:39,250 --> 00:16:42,250
process for the metadata schema it

00:16:41,080 --> 00:16:43,540
actually hopes to have that already

00:16:42,250 --> 00:16:45,160
launched and underway by the time of

00:16:43,540 --> 00:16:45,730
this talk but we're a little bit behind

00:16:45,160 --> 00:16:48,850
schedule

00:16:45,730 --> 00:16:50,530
but I will point you to two things to

00:16:48,850 --> 00:16:51,940
sort of get engaged as we kick that off

00:16:50,530 --> 00:16:54,880
but you know we want to incorporate

00:16:51,940 --> 00:16:57,190
updates from TK 2.0 and some new

00:16:54,880 --> 00:16:58,480
requirements from the Evidence Act you

00:16:57,190 --> 00:17:00,250
know want to consider sort of ways to

00:16:58,480 --> 00:17:02,670
better integrate or harmonize other

00:17:00,250 --> 00:17:04,780
standards so there's the the geospatial

00:17:02,670 --> 00:17:06,850
metadata stands that we work actually

00:17:04,780 --> 00:17:09,459
quite a bit with already like iso:191

00:17:06,850 --> 00:17:12,550
five which has had some updates there's

00:17:09,459 --> 00:17:13,900
everything schema.org is doing neem is

00:17:12,550 --> 00:17:15,910
the national information exchange model

00:17:13,900 --> 00:17:17,830
which is sort of like a schema.org and

00:17:15,910 --> 00:17:19,900
the government's is the data set

00:17:17,830 --> 00:17:22,570
publishing language which is more like

00:17:19,900 --> 00:17:25,209
used for statistical data as well as

00:17:22,570 --> 00:17:26,890
sdmx for statistical data and then

00:17:25,209 --> 00:17:28,840
tabular data packages and CSVs on the

00:17:26,890 --> 00:17:29,710
web which I'm sure this community is

00:17:28,840 --> 00:17:30,880
familiar whether they think there's

00:17:29,710 --> 00:17:32,590
there's probably opportunities for us to

00:17:30,880 --> 00:17:34,660
better leverage incorporate some of

00:17:32,590 --> 00:17:36,700
those things there's a lot of

00:17:34,660 --> 00:17:37,720
opportunities to I think do more with

00:17:36,700 --> 00:17:40,600
things like digital object identifiers

00:17:37,720 --> 00:17:42,100
or make them maybe your requirements as

00:17:40,600 --> 00:17:44,500
well as other opportunity to better use

00:17:42,100 --> 00:17:46,720
unique identifiers across our metadata

00:17:44,500 --> 00:17:48,250
and have better site like better data

00:17:46,720 --> 00:17:49,000
you know ability to generate data set

00:17:48,250 --> 00:17:50,620
citations

00:17:49,000 --> 00:17:53,530
and then you know there's also some

00:17:50,620 --> 00:17:55,510
emerging technologies you know get like

00:17:53,530 --> 00:17:58,570
distributed version control concepts

00:17:55,510 --> 00:18:01,090
applied to data things like that and

00:17:58,570 --> 00:18:03,670
then of course you know domain-specific

00:18:01,090 --> 00:18:04,990
data standards that that could be sort

00:18:03,670 --> 00:18:06,220
of better leveraged or aggregated as

00:18:04,990 --> 00:18:07,840
we're providing sort of a national

00:18:06,220 --> 00:18:10,180
catalog that could aggregate sort of

00:18:07,840 --> 00:18:11,430
common data standards across across

00:18:10,180 --> 00:18:13,600
local governments and things like that

00:18:11,430 --> 00:18:16,090
which actually brings me again to

00:18:13,600 --> 00:18:18,910
another point so action 20 in the

00:18:16,090 --> 00:18:21,370
federal data strategy is to develop a

00:18:18,910 --> 00:18:23,620
data standards repository so this will

00:18:21,370 --> 00:18:26,860
likely be part of the resources data

00:18:23,620 --> 00:18:28,630
archive site we kind of are expected to

00:18:26,860 --> 00:18:29,890
have an initial version of this develop

00:18:28,630 --> 00:18:31,210
throughout this year and expect to like

00:18:29,890 --> 00:18:33,430
properly launched launched that

00:18:31,210 --> 00:18:34,630
development process here in the next

00:18:33,430 --> 00:18:36,880
month or so

00:18:34,630 --> 00:18:38,680
and there are some existing resources

00:18:36,880 --> 00:18:40,210
letter so much of this so data standards

00:18:38,680 --> 00:18:43,270
that directory or fair assuring gorg

00:18:40,210 --> 00:18:46,240
these are directories of data standards

00:18:43,270 --> 00:18:47,290
some for the public sector so we're

00:18:46,240 --> 00:18:48,580
looking to have something like this

00:18:47,290 --> 00:18:50,260
that's sort of more tailored to the

00:18:48,580 --> 00:18:51,610
federal government but this is something

00:18:50,260 --> 00:18:53,620
we'll be looking for input from the

00:18:51,610 --> 00:18:55,270
public on in terms of you know not

00:18:53,620 --> 00:18:57,430
reinventing the wheel and what's most

00:18:55,270 --> 00:19:00,130
useful to sort of document you know the

00:18:57,430 --> 00:19:05,380
data stands that are currently in use or

00:19:00,130 --> 00:19:06,850
or could be undeveloped so I know I

00:19:05,380 --> 00:19:10,660
probably didn't leave a ton of time for

00:19:06,850 --> 00:19:12,430
for Q&A right now but again really my my

00:19:10,660 --> 00:19:14,740
point was to open up sort of the the

00:19:12,430 --> 00:19:16,240
floor to input on the work that's going

00:19:14,740 --> 00:19:19,300
on and let you all know sort of the

00:19:16,240 --> 00:19:21,040
background on context and encourage you

00:19:19,300 --> 00:19:23,040
to participate so one of the things is

00:19:21,040 --> 00:19:25,000
you know we are gonna be doing this

00:19:23,040 --> 00:19:26,350
revision to the metadata schema we

00:19:25,000 --> 00:19:27,460
haven't fully kicked off that process

00:19:26,350 --> 00:19:28,480
but it will be done through you have

00:19:27,460 --> 00:19:30,490
issues like we did for the previous

00:19:28,480 --> 00:19:32,560
revisions so I have actually highlighted

00:19:30,490 --> 00:19:34,360
issue 630 in that give repose is one

00:19:32,560 --> 00:19:36,990
particularly to follow and and other

00:19:34,360 --> 00:19:39,610
sort of URLs and things to reference but

00:19:36,990 --> 00:19:41,830
certainly I will be available in CSV

00:19:39,610 --> 00:19:43,000
slack as much as I can the next two days

00:19:41,830 --> 00:19:46,240
although maybe a little bit more so

00:19:43,000 --> 00:19:48,370
tomorrow so there's the QA channel there

00:19:46,240 --> 00:19:50,080
which which I'll be keeping tabs of

00:19:48,370 --> 00:19:51,640
although it may not be respond to all

00:19:50,080 --> 00:19:53,350
your questions in real time but

00:19:51,640 --> 00:19:55,240
certainly we'll try and get back to

00:19:53,350 --> 00:19:56,740
everything as much as I can so I don't

00:19:55,240 --> 00:19:57,730
know if it's worth trying to open up the

00:19:56,740 --> 00:19:58,270
floor for questions right now we're at

00:19:57,730 --> 00:20:00,310
four at a time

00:19:58,270 --> 00:20:02,380
well No thank you very much for that

00:20:00,310 --> 00:20:04,030
though I I've been checking

00:20:02,380 --> 00:20:05,290
some of the questions and we don't have

00:20:04,030 --> 00:20:08,200
a lot of time we do need to move over

00:20:05,290 --> 00:20:09,970
but um I think that one of the main

00:20:08,200 --> 00:20:11,740
questions that we have here is I think

00:20:09,970 --> 00:20:13,300
you've really highlighted that the US

00:20:11,740 --> 00:20:15,580
federal government's been very involved

00:20:13,300 --> 00:20:17,650
in building foundational technologies

00:20:15,580 --> 00:20:19,780
and setting trends in this space for a

00:20:17,650 --> 00:20:22,120
long time and there was just a set of

00:20:19,780 --> 00:20:24,100
questions around kind of the role of GSA

00:20:22,120 --> 00:20:25,780
and how there's long-living projects

00:20:24,100 --> 00:20:27,000
that go across administration's within

00:20:25,780 --> 00:20:29,860
the US federal government and how

00:20:27,000 --> 00:20:31,120
data.gov and the kind of initiatives

00:20:29,860 --> 00:20:33,550
that you're working on how do they

00:20:31,120 --> 00:20:35,830
relate to the kind of the ebbs and flows

00:20:33,550 --> 00:20:37,480
of politics throughout the US government

00:20:35,830 --> 00:20:39,100
so I don't know if you want to just

00:20:37,480 --> 00:20:41,290
comment a little bit about the way that

00:20:39,100 --> 00:20:44,230
the projects work within the US federal

00:20:41,290 --> 00:20:46,270
government real quick yeah I mean it's

00:20:44,230 --> 00:20:49,510
it's I don't know that there's any one

00:20:46,270 --> 00:20:52,840
consistent sort of rule that applies

00:20:49,510 --> 00:20:54,490
universally sometimes you know

00:20:52,840 --> 00:20:56,410
initiatives can come and go with

00:20:54,490 --> 00:20:59,200
different administrations I think we've

00:20:56,410 --> 00:21:01,020
been you know there's that we've really

00:20:59,200 --> 00:21:03,700
there's been a lot of you know

00:21:01,020 --> 00:21:05,170
opportunity with the consistency of this

00:21:03,700 --> 00:21:08,590
work and particularly with the

00:21:05,170 --> 00:21:10,060
legislation passing so having this as

00:21:08,590 --> 00:21:12,550
part of the legislation especially

00:21:10,060 --> 00:21:14,350
something that was very bipartisan is

00:21:12,550 --> 00:21:15,790
something that helps you know ensure

00:21:14,350 --> 00:21:17,710
that is something that will sort of you

00:21:15,790 --> 00:21:19,240
know I think extend and continue between

00:21:17,710 --> 00:21:21,970
multiple administration's so that really

00:21:19,240 --> 00:21:23,680
changes I think the perspective not only

00:21:21,970 --> 00:21:26,380
from the outside but also from how folks

00:21:23,680 --> 00:21:28,000
kind of I think approach to policy

00:21:26,380 --> 00:21:30,430
internally and how things are funded and

00:21:28,000 --> 00:21:31,780
staffed and things like that but that's

00:21:30,430 --> 00:21:34,150
really the thing that sort of makes the

00:21:31,780 --> 00:21:35,770
biggest difference in sort of thinking

00:21:34,150 --> 00:21:37,630
about this as long-term infrastructure

00:21:35,770 --> 00:21:40,150
and not just some sort of initiative of

00:21:37,630 --> 00:21:41,680
an administration but you know well

00:21:40,150 --> 00:21:43,360
thank you yeah thanks for your talking

00:21:41,680 --> 00:21:46,480
also thank you for the work that you and

00:21:43,360 --> 00:21:48,460
your colleagues do you know your uncle

00:21:46,480 --> 00:21:50,380
heroes in the data world so thank you

00:21:48,460 --> 00:21:53,760
very much well thanks for having me glad

00:21:50,380 --> 00:21:53,760

YouTube URL: https://www.youtube.com/watch?v=EvEy_gveqzg


