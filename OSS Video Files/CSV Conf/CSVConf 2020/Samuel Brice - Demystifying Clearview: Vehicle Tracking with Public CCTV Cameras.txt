Title: Samuel Brice - Demystifying Clearview: Vehicle Tracking with Public CCTV Cameras
Publication date: 2020-06-26
Playlist: CSVConf 2020
Description: 
	Recently, the New York Times published an article about Clearview AI - the secretive company that might end privacy as we know it. Using a database of billions of images scrapped from websites such as Facebook, and Instagram Clearview can track and identify anyone with a web presence. The tool is actively being used by police agencies around the country and many citizens are concerned about its potential for abuse.

My talks goes into detail explaining how Clearview's system works by demonstrating a similar system for tracking and identifying cars using public CCTV cameras. I will cover the steps of implementing such a pipeline from collecting training data, to building a neural net model, to tracking the movements of a car in time and space.

Lastly I will cover the implications of such a capability on privacy as well as what can be done to protect our privacy today.

--
csv,conf,v5 is a community conference for data makers everywhere, featuring stories about data sharing and data analysis from science, journalism, government, and open source. Held May 13-14, 2020, Online. https://csvconf.com/
Captions: 
	00:00:00,079 --> 00:00:05,310
Thank You Jo hey everyone my name is Sam

00:00:03,270 --> 00:00:07,790
I'm a software engineer in New York City

00:00:05,310 --> 00:00:10,889
I work primarily on machine learning

00:00:07,790 --> 00:00:13,700
applications for a quantitative hedge

00:00:10,889 --> 00:00:16,379
fund and my talk is called misuk

00:00:13,700 --> 00:00:17,880
demystifying Clearview where effectively

00:00:16,379 --> 00:00:20,730
I'm going to give you a demonstration

00:00:17,880 --> 00:00:22,730
how you would leverage to this existence

00:00:20,730 --> 00:00:25,380
chronologies to unit the same kind of

00:00:22,730 --> 00:00:27,890
detection and recognition a like for

00:00:25,380 --> 00:00:30,090
functionality that clearly currently has

00:00:27,890 --> 00:00:32,579
but the New York town was the first

00:00:30,090 --> 00:00:35,280
outlet to actually publish an article by

00:00:32,579 --> 00:00:37,620
Clearview which went into detail as to

00:00:35,280 --> 00:00:38,790
the amount of information and the types

00:00:37,620 --> 00:00:41,520
of people that I have actually been

00:00:38,790 --> 00:00:43,050
using this application over the years a

00:00:41,520 --> 00:00:44,789
lot of other outlets have come out you

00:00:43,050 --> 00:00:46,590
know with more information and in fact

00:00:44,789 --> 00:00:50,370
there have been several hacks of

00:00:46,590 --> 00:00:52,260
clearing your software to that wanted to

00:00:50,370 --> 00:00:54,000
detail us for like who did who was

00:00:52,260 --> 00:00:55,620
really sharing it initially clearly said

00:00:54,000 --> 00:00:57,809
it was primarily law enforcement using

00:00:55,620 --> 00:01:00,690
it but then what we can to find out it

00:00:57,809 --> 00:01:02,550
is that there are a lot of organizations

00:01:00,690 --> 00:01:04,159
that we're not a law enforcement and

00:01:02,550 --> 00:01:06,600
specifically there are individuals I

00:01:04,159 --> 00:01:07,950
really liked a lot of their backers and

00:01:06,600 --> 00:01:12,689
clients that were actually using the

00:01:07,950 --> 00:01:14,729
application for various reasons so a lot

00:01:12,689 --> 00:01:16,350
of those outlets have talked about you

00:01:14,729 --> 00:01:17,880
know the information that Cleary has

00:01:16,350 --> 00:01:19,530
which is roughly 2 billion images

00:01:17,880 --> 00:01:21,540
they've also talked about the people

00:01:19,530 --> 00:01:25,460
that I've been using Clearview such as

00:01:21,540 --> 00:01:28,320
the ISE interpret and actually some some

00:01:25,460 --> 00:01:30,180
some like other countries as well

00:01:28,320 --> 00:01:31,860
countries with the questionable human

00:01:30,180 --> 00:01:33,450
rights records but instead of talking

00:01:31,860 --> 00:01:35,159
about those things I actually want to

00:01:33,450 --> 00:01:37,680
focus on the technical aspects of

00:01:35,159 --> 00:01:39,630
Clearview which specifically boils down

00:01:37,680 --> 00:01:42,030
to the two methods that they've

00:01:39,630 --> 00:01:43,740
mentioned or went into detail as far as

00:01:42,030 --> 00:01:45,299
explaining how they actually went about

00:01:43,740 --> 00:01:49,140
collecting the data and how they're

00:01:45,299 --> 00:01:51,350
currently using technology to or how

00:01:49,140 --> 00:01:56,640
they're currently using AI to detect and

00:01:51,350 --> 00:01:58,350
and kind of categorize people they said

00:01:56,640 --> 00:02:00,119
web scraping but in reality what they've

00:01:58,350 --> 00:02:02,100
been doing is breaking the law and also

00:02:00,119 --> 00:02:03,869
breaking a lot of the users and user

00:02:02,100 --> 00:02:05,520
angry bits that are a lot of the

00:02:03,869 --> 00:02:07,259
websites just as Google and Facebook has

00:02:05,520 --> 00:02:10,229
the difficulty is that it's very

00:02:07,259 --> 00:02:13,430
difficult to stop it marginally because

00:02:10,229 --> 00:02:15,799
to to Facebook or to Google

00:02:13,430 --> 00:02:17,720
there's no distinction between a but

00:02:15,799 --> 00:02:19,519
that's actually saving the image versus

00:02:17,720 --> 00:02:22,280
a browser that's actually viewing the

00:02:19,519 --> 00:02:23,870
image and as far as the article as far

00:02:22,280 --> 00:02:25,819
as the artificial intelligent transpose

00:02:23,870 --> 00:02:27,769
um there isn't really anything

00:02:25,819 --> 00:02:29,750
revolutionary to a cleavage doing and

00:02:27,769 --> 00:02:31,730
part the reason why I'm going to the

00:02:29,750 --> 00:02:33,829
process of demonstrating in this app is

00:02:31,730 --> 00:02:35,959
primarily to show you that without any

00:02:33,829 --> 00:02:38,720
kind of view technology without any kind

00:02:35,959 --> 00:02:40,790
of anything special I can actually just

00:02:38,720 --> 00:02:44,510
build something that pulls data from

00:02:40,790 --> 00:02:46,760
online sources and runs a few libraries

00:02:44,510 --> 00:02:49,489
on top of it to actually give you very

00:02:46,760 --> 00:02:50,870
easy tracking and recognition that the

00:02:49,489 --> 00:02:52,549
kind of tracking a recognition that you

00:02:50,870 --> 00:02:57,739
know ten years ago you'd only see in

00:02:52,549 --> 00:02:59,599
movies so going back to the very very I

00:02:57,739 --> 00:03:02,180
guess the beginnings of facial

00:02:59,599 --> 00:03:04,790
recognition the technology itself is

00:03:02,180 --> 00:03:07,370
extremely old it goes back to the 1960s

00:03:04,790 --> 00:03:10,010
when a gentleman named Walter Wilson

00:03:07,370 --> 00:03:12,859
Bledsoe was doing a lot of research into

00:03:10,010 --> 00:03:15,019
what pieces of face can you actually

00:03:12,859 --> 00:03:17,359
analyze to be able to distinguish one

00:03:15,019 --> 00:03:19,160
person the other back in those days a

00:03:17,359 --> 00:03:20,989
lot of the work was manual which meant

00:03:19,160 --> 00:03:24,319
that the researcher would have to

00:03:20,989 --> 00:03:27,319
manually tell the computer where the

00:03:24,319 --> 00:03:28,909
noses were where the eyes were and based

00:03:27,319 --> 00:03:31,069
on the coordinates the computer would

00:03:28,909 --> 00:03:34,010
kind of like figure out this is one

00:03:31,069 --> 00:03:36,519
person this is another person what's the

00:03:34,010 --> 00:03:40,310
the major kind of a technical

00:03:36,519 --> 00:03:44,449
breakthrough that happened was primarily

00:03:40,310 --> 00:03:46,370
around 2008 and Google and Facebook you

00:03:44,449 --> 00:03:48,169
might not see them as being a technical

00:03:46,370 --> 00:03:52,849
breakthroughs but they very much were in

00:03:48,169 --> 00:03:55,220
a lot of ways because they made it kind

00:03:52,849 --> 00:03:57,530
of easy and somewhat fun to do two

00:03:55,220 --> 00:03:59,870
things that research is back in those

00:03:57,530 --> 00:04:02,540
days were not able to do which is one

00:03:59,870 --> 00:04:04,159
they made it easy for people to submit

00:04:02,540 --> 00:04:06,979
their information to a centralized place

00:04:04,159 --> 00:04:09,079
and second they made it easy for that

00:04:06,979 --> 00:04:11,540
information to be organized in a lot of

00:04:09,079 --> 00:04:14,299
ways Facebook and Google were different

00:04:11,540 --> 00:04:15,829
companies but together they enabled a

00:04:14,299 --> 00:04:18,079
lot of the technology that we currently

00:04:15,829 --> 00:04:19,579
have today because without all these

00:04:18,079 --> 00:04:21,229
images from Facebook

00:04:19,579 --> 00:04:23,000
and without all this indexing from

00:04:21,229 --> 00:04:24,560
Google there would be a lot harder to

00:04:23,000 --> 00:04:26,980
actually train Amada right now and

00:04:24,560 --> 00:04:31,230
showing identifying not just people but

00:04:26,980 --> 00:04:34,960
so objects so for a bit of context as to

00:04:31,230 --> 00:04:37,060
the size of the data set that clearly

00:04:34,960 --> 00:04:39,370
has collected the FBI has been

00:04:37,060 --> 00:04:44,200
collecting patient wear condition data

00:04:39,370 --> 00:04:45,970
since 1992 they were first required by

00:04:44,200 --> 00:04:47,950
Congress to report how much information

00:04:45,970 --> 00:04:50,440
they had who they who they had the

00:04:47,950 --> 00:04:53,110
information on and back in those days

00:04:50,440 --> 00:04:55,090
they only had the only the only database

00:04:53,110 --> 00:04:56,860
that they had it was primarily from like

00:04:55,090 --> 00:04:59,380
booking photos and mug shots of

00:04:56,860 --> 00:05:01,990
criminals and other other people that

00:04:59,380 --> 00:05:03,700
actually had a record and for a long

00:05:01,990 --> 00:05:05,740
time they didn't report the Congress any

00:05:03,700 --> 00:05:07,690
Mars to what they were doing with that

00:05:05,740 --> 00:05:10,390
technology and it we didn't really find

00:05:07,690 --> 00:05:12,550
that up until 2008 that their database

00:05:10,390 --> 00:05:14,710
had grunt groan - roughly 400 million

00:05:12,550 --> 00:05:16,090
more people in pictures and the reason

00:05:14,710 --> 00:05:18,700
that agreed that size is primarily

00:05:16,090 --> 00:05:21,730
because a lot of state agencies or

00:05:18,700 --> 00:05:23,950
sharing state agencies and also federal

00:05:21,730 --> 00:05:26,920
agencies were sharing pictures such as

00:05:23,950 --> 00:05:29,980
license license photos passport photos

00:05:26,920 --> 00:05:31,840
with the FBI and effectively FBI was

00:05:29,980 --> 00:05:34,810
using technology and using the

00:05:31,840 --> 00:05:38,290
technology and sharing the technology

00:05:34,810 --> 00:05:40,540
with them to to give them like a lot

00:05:38,290 --> 00:05:42,480
more insights into the US population the

00:05:40,540 --> 00:05:45,550
problem with that the problem with the

00:05:42,480 --> 00:05:47,680
reality in 1992 in reality in 2008 is

00:05:45,550 --> 00:05:49,210
that whereas 1992 the database was

00:05:47,680 --> 00:05:50,920
primarily of people that actually had a

00:05:49,210 --> 00:05:53,920
criminal record that had a reason to

00:05:50,920 --> 00:05:55,630
actually be within the FBI's database by

00:05:53,920 --> 00:05:57,280
2008 the majority of the people that

00:05:55,630 --> 00:05:59,590
were actually within a database where

00:05:57,280 --> 00:06:01,450
people had to have record at all and so

00:05:59,590 --> 00:06:04,720
that was very concerning to Congress and

00:06:01,450 --> 00:06:06,250
I believe at that point the FBI started

00:06:04,720 --> 00:06:09,340
getting like a lot more oversight into

00:06:06,250 --> 00:06:11,290
what they were doing and in whose data

00:06:09,340 --> 00:06:14,470
that they had and I think beginning in

00:06:11,290 --> 00:06:16,240
2008 they got a like a lot of pushback a

00:06:14,470 --> 00:06:17,740
lot of congressmen we're actually trying

00:06:16,240 --> 00:06:18,730
to put legislation in to make it such

00:06:17,740 --> 00:06:20,680
that they don't use those kind of

00:06:18,730 --> 00:06:22,330
technologies and for the most part the

00:06:20,680 --> 00:06:24,190
FBI's capabilities as far as special

00:06:22,330 --> 00:06:26,320
recognition goes effectively started to

00:06:24,190 --> 00:06:29,650
stagnate around that time up until the

00:06:26,320 --> 00:06:31,050
September 11th in which case we haven't

00:06:29,650 --> 00:06:33,730
even heard much about it but nonetheless

00:06:31,050 --> 00:06:37,420
that's kind of tied to become irrelevant

00:06:33,730 --> 00:06:39,220
but within the context of Clearview in

00:06:37,420 --> 00:06:40,930
just you know a couple of years because

00:06:39,220 --> 00:06:44,139
cliff he started back in one

00:06:40,930 --> 00:06:46,660
c18 or so within a couple years Livia's

00:06:44,139 --> 00:06:49,870
obviously surpass what it took the FBI

00:06:46,660 --> 00:06:51,130
roughly ten years to do and what's the

00:06:49,870 --> 00:06:52,900
reason for that there's a very specific

00:06:51,130 --> 00:06:54,759
reason for that primarily because the

00:06:52,900 --> 00:06:56,889
technology that they're using somewhat

00:06:54,759 --> 00:06:58,960
mandates having that large of a data set

00:06:56,889 --> 00:07:01,720
and whereas a store like whereas in the

00:06:58,960 --> 00:07:03,820
past to have 300 billion images to sort

00:07:01,720 --> 00:07:06,039
through would be an impossible task to

00:07:03,820 --> 00:07:08,380
find one person but because of the way

00:07:06,039 --> 00:07:10,210
that technology actually works it makes

00:07:08,380 --> 00:07:12,400
it such that you have to have that many

00:07:10,210 --> 00:07:16,570
images to be able to effectively track

00:07:12,400 --> 00:07:18,220
and identify people so like I mentioned

00:07:16,570 --> 00:07:20,349
I'm going to actually go through the

00:07:18,220 --> 00:07:22,690
development process with you guys as far

00:07:20,349 --> 00:07:24,820
as collecting data processing later and

00:07:22,690 --> 00:07:26,289
analyzing it and putting it in a way

00:07:24,820 --> 00:07:27,789
such that you can actually you know

00:07:26,289 --> 00:07:30,280
carry out whatever application that

00:07:27,789 --> 00:07:32,320
you're trying to carry out but I'm gonna

00:07:30,280 --> 00:07:34,090
give you a broad overview of what the

00:07:32,320 --> 00:07:35,949
process would be if we're actually to go

00:07:34,090 --> 00:07:39,039
end to end as far as production izing it

00:07:35,949 --> 00:07:41,770
today what I'm going to focus on is like

00:07:39,039 --> 00:07:43,120
the first four steps primarily showing

00:07:41,770 --> 00:07:45,760
you how the data collection process

00:07:43,120 --> 00:07:47,320
would happen the kind of things you

00:07:45,760 --> 00:07:50,020
would do here and there to clean the

00:07:47,320 --> 00:07:51,970
data fill the gaps in and then secondly

00:07:50,020 --> 00:07:55,060
I'll talk about the actual machine

00:07:51,970 --> 00:07:58,449
learning models that you would build to

00:07:55,060 --> 00:08:00,789
either do classification or to do kind

00:07:58,449 --> 00:08:03,430
of categorizing

00:08:00,789 --> 00:08:05,889
one or categorizing one object from a

00:08:03,430 --> 00:08:09,220
different object and lastly I'll kind of

00:08:05,889 --> 00:08:12,190
give you a broad idea as to how you can

00:08:09,220 --> 00:08:14,169
actually take the the deep learning

00:08:12,190 --> 00:08:17,080
technology or deep learning methods and

00:08:14,169 --> 00:08:19,120
then combine that with broadly speaking

00:08:17,080 --> 00:08:21,280
just regular product development

00:08:19,120 --> 00:08:23,710
software engineering to actually get one

00:08:21,280 --> 00:08:29,110
type like a specific type of capability

00:08:23,710 --> 00:08:31,900
out of it like for me the process of

00:08:29,110 --> 00:08:33,880
actually getting CTV data's was very

00:08:31,900 --> 00:08:34,779
transparent and straightforward because

00:08:33,880 --> 00:08:37,810
the Department of Transportation

00:08:34,779 --> 00:08:39,909
actually has a website where it lists

00:08:37,810 --> 00:08:42,250
all the webcams that are currently

00:08:39,909 --> 00:08:45,579
running live on all traffic that goes

00:08:42,250 --> 00:08:47,709
within Manhattan as well as Brooklyn I

00:08:45,579 --> 00:08:49,510
know for a fact that from San Francisco

00:08:47,709 --> 00:08:52,660
has one but I'm not quite sure about a

00:08:49,510 --> 00:08:54,430
lot of other major cities but the gist

00:08:52,660 --> 00:08:54,940
of it is that this this information is

00:08:54,430 --> 00:08:58,270
probably

00:08:54,940 --> 00:09:01,410
anyone it's it's available to anyone who

00:08:58,270 --> 00:09:05,680
actually wants to get to it and whereas

00:09:01,410 --> 00:09:07,510
the DLT has a fairly fairly open API for

00:09:05,680 --> 00:09:10,270
a lot of information that I'm trying to

00:09:07,510 --> 00:09:11,740
get for clear view the equivalent would

00:09:10,270 --> 00:09:14,260
pretty much just be going to a site like

00:09:11,740 --> 00:09:16,090
Twitter looking into the source code or

00:09:14,260 --> 00:09:19,030
just watching the network traffic and

00:09:16,090 --> 00:09:23,320
pulling in all the images that gets fed

00:09:19,030 --> 00:09:25,150
in to the browser as far as Twitter's

00:09:23,320 --> 00:09:26,410
like end user License Agreement goes

00:09:25,150 --> 00:09:28,780
it's not supposed to be doing this but

00:09:26,410 --> 00:09:31,420
as I've just shown you Twitter doesn't

00:09:28,780 --> 00:09:33,100
have a very easy way of distinguishing a

00:09:31,420 --> 00:09:35,560
person that's legitimately going to the

00:09:33,100 --> 00:09:36,970
oversight versus or about that's going

00:09:35,560 --> 00:09:40,330
don't go and do their site and scraping

00:09:36,970 --> 00:09:43,570
the pictures so the hardest part for me

00:09:40,330 --> 00:09:46,780
anyways and they're not being well it's

00:09:43,570 --> 00:09:48,610
kind of fun but the the nuts and bolts

00:09:46,780 --> 00:09:50,590
parts as far as pulling in the data is

00:09:48,610 --> 00:09:52,600
really having to do it

00:09:50,590 --> 00:09:55,000
figuring out how many cameras that I

00:09:52,600 --> 00:09:57,820
wanted that's happen too and once I had

00:09:55,000 --> 00:09:59,770
that like the broadly speaking the

00:09:57,820 --> 00:10:02,050
cameras that I wanted to target on it's

00:09:59,770 --> 00:10:04,450
a matter of like basically setting up

00:10:02,050 --> 00:10:06,280
processes such that as the cameras are

00:10:04,450 --> 00:10:08,620
recording I'm actually able to record

00:10:06,280 --> 00:10:10,960
that data and put it somewhere where I

00:10:08,620 --> 00:10:14,590
can actually access it later it's easier

00:10:10,960 --> 00:10:17,980
said than done primarily because I might

00:10:14,590 --> 00:10:19,840
get only have one laptop and so I have

00:10:17,980 --> 00:10:21,700
to use a laptop for the things and all

00:10:19,840 --> 00:10:23,320
these all this processing is very very

00:10:21,700 --> 00:10:25,780
very mom-like

00:10:23,320 --> 00:10:30,430
CPU intensive and so the solution to

00:10:25,780 --> 00:10:32,680
that it's actually using a a service

00:10:30,430 --> 00:10:35,680
like AWS and so what I ended up doing is

00:10:32,680 --> 00:10:37,750
actually well I created an AWS account

00:10:35,680 --> 00:10:40,090
and unfortunately they give you 750

00:10:37,750 --> 00:10:43,120
hours for free as far as computing power

00:10:40,090 --> 00:10:45,550
goes and so once I had roughly a cluster

00:10:43,120 --> 00:10:47,980
of a computers I spun up each computer

00:10:45,550 --> 00:10:50,740
such that it would record a camera feed

00:10:47,980 --> 00:10:52,870
and through over the course of 72 hours

00:10:50,740 --> 00:10:54,490
it would just effectively record every

00:10:52,870 --> 00:10:57,370
second that was coming back from the

00:10:54,490 --> 00:11:02,200
CCTV camera and saves it locally such

00:10:57,370 --> 00:11:06,270
that I can process it later and what

00:11:02,200 --> 00:11:08,050
you're seeing here is pretty much for

00:11:06,270 --> 00:11:11,380
compute instance

00:11:08,050 --> 00:11:13,510
that's taking in data from the CCTV

00:11:11,380 --> 00:11:16,180
feeds and just either saving it or

00:11:13,510 --> 00:11:21,100
processing it on those on those specific

00:11:16,180 --> 00:11:27,339
machines and ultimately what you end up

00:11:21,100 --> 00:11:29,260
with is a real-time feed but not

00:11:27,339 --> 00:11:30,670
real-time feed but it's effectively what

00:11:29,260 --> 00:11:33,269
you would normally what you end up with

00:11:30,670 --> 00:11:36,220
is like a local recording of the CCTV

00:11:33,269 --> 00:11:39,880
cameras that you would otherwise have to

00:11:36,220 --> 00:11:44,380
go through the Department of translation

00:11:39,880 --> 00:11:46,959
or camp website to to to analyze running

00:11:44,380 --> 00:11:50,050
the machine learning models on top of it

00:11:46,959 --> 00:11:52,630
gives you what you're seeing here which

00:11:50,050 --> 00:11:54,220
is one you had the original feed on the

00:11:52,630 --> 00:11:55,990
left side and the right side you have

00:11:54,220 --> 00:12:00,279
all these kind of like objects that are

00:11:55,990 --> 00:12:02,649
being tracked on the on the frames the

00:12:00,279 --> 00:12:04,029
depending on the model that you're that

00:12:02,649 --> 00:12:05,740
you're running you can actually track a

00:12:04,029 --> 00:12:08,890
lot more than just cars some models

00:12:05,740 --> 00:12:12,190
track people they track bicycles they

00:12:08,890 --> 00:12:14,380
track motorcycles and buses but for for

00:12:12,190 --> 00:12:17,589
for our methods I'm only tracking cars

00:12:14,380 --> 00:12:20,410
because one it takes a lot of compute

00:12:17,589 --> 00:12:24,220
power and secondly as you track each

00:12:20,410 --> 00:12:26,260
object the the library also pulls out

00:12:24,220 --> 00:12:31,240
and it's extract the objects into

00:12:26,260 --> 00:12:34,529
individual individual kind of the the

00:12:31,240 --> 00:12:37,420
detections and the reason for that is

00:12:34,529 --> 00:12:38,649
obviously you have different things that

00:12:37,420 --> 00:12:42,520
you could apply this kind of technology

00:12:38,649 --> 00:12:44,560
to right so one application is like

00:12:42,520 --> 00:12:46,329
speed limits within school zones we

00:12:44,560 --> 00:12:47,920
already have cover cameras so that does

00:12:46,329 --> 00:12:49,660
this another application that's a lot

00:12:47,920 --> 00:12:51,760
more specific to this kind of technology

00:12:49,660 --> 00:12:53,800
is something like Amber Alert and the

00:12:51,760 --> 00:12:55,990
reason is because as I mentioned when

00:12:53,800 --> 00:12:58,199
the machine learning model pulls out

00:12:55,990 --> 00:13:00,910
each of the individual cajon the

00:12:58,199 --> 00:13:04,870
individual cars that are scanned and

00:13:00,910 --> 00:13:08,230
from like these snapshots it is able to

00:13:04,870 --> 00:13:10,720
like order the cars within within a

00:13:08,230 --> 00:13:12,670
classification that says that this car

00:13:10,720 --> 00:13:14,769
is closer to another car may not be

00:13:12,670 --> 00:13:17,050
because of color because of make because

00:13:14,769 --> 00:13:19,690
of model and based on that information

00:13:17,050 --> 00:13:21,730
you can specifically pick for example

00:13:19,690 --> 00:13:24,279
I'm looking for a red Acura

00:13:21,730 --> 00:13:26,170
and simply by giving it that search term

00:13:24,279 --> 00:13:28,290
we're giving it like what a right

00:13:26,170 --> 00:13:30,790
accurate would look like it can tell you

00:13:28,290 --> 00:13:33,430
from all the different traffic cameras

00:13:30,790 --> 00:13:36,880
throughout the city where such a car has

00:13:33,430 --> 00:13:38,980
been spotted and so this is great for if

00:13:36,880 --> 00:13:40,750
you have any police officers within the

00:13:38,980 --> 00:13:44,820
area you can tell them hey watch out for

00:13:40,750 --> 00:13:47,709
this car within you know 3rd and 23rd so

00:13:44,820 --> 00:13:50,139
that's a very simple application that I

00:13:47,709 --> 00:13:51,399
not quite sure if it's currently in use

00:13:50,139 --> 00:13:52,870
but it's certainly one of those things I

00:13:51,399 --> 00:13:54,430
can actually be implemented fairly easy

00:13:52,870 --> 00:13:57,430
right now with this kind of technology

00:13:54,430 --> 00:13:59,920
and just to mention in terms of the

00:13:57,430 --> 00:14:02,440
development of this it took me roughly

00:13:59,920 --> 00:14:05,320
three days to collect the data and one

00:14:02,440 --> 00:14:07,089
day to pre-process it and another day to

00:14:05,320 --> 00:14:10,149
actually run the machine running on top

00:14:07,089 --> 00:14:12,790
of it so this is just me doing this on

00:14:10,149 --> 00:14:15,790
my laptop and also what if you have AWS

00:14:12,790 --> 00:14:17,680
computers so you can imagine clear view

00:14:15,790 --> 00:14:18,670
with several million dollars of backing

00:14:17,680 --> 00:14:22,630
and also the Department of

00:14:18,670 --> 00:14:24,490
Transportation with their existing feed

00:14:22,630 --> 00:14:25,899
into this data not even have to do the

00:14:24,490 --> 00:14:27,910
pre-processing that I'm having to do

00:14:25,899 --> 00:14:32,160
they can certainly do this kind of stuff

00:14:27,910 --> 00:14:35,560
in real time Sam you have five minutes

00:14:32,160 --> 00:14:37,420
okay great so i guess real quickly so

00:14:35,560 --> 00:14:40,779
there's a there's a detection part

00:14:37,420 --> 00:14:43,540
there's also the search part the

00:14:40,779 --> 00:14:45,399
detection itself is fairly easy and the

00:14:43,540 --> 00:14:47,589
the thing that concerns a lot of people

00:14:45,399 --> 00:14:48,910
is really clearly the ability to search

00:14:47,589 --> 00:14:50,589
throughout different dimensions and

00:14:48,910 --> 00:14:53,260
match matchup one person from another

00:14:50,589 --> 00:14:55,360
the reality is did are actually do

00:14:53,260 --> 00:14:59,620
recognition as much as they do image

00:14:55,360 --> 00:15:01,329
searching and from from some screen shot

00:14:59,620 --> 00:15:03,880
uptick news a screen use app what

00:15:01,329 --> 00:15:05,740
they've basically done is implemented

00:15:03,880 --> 00:15:07,870
Google Image Search but the difference

00:15:05,740 --> 00:15:09,310
between Image Search and what they have

00:15:07,870 --> 00:15:11,589
is obviously the fact that they have

00:15:09,310 --> 00:15:13,810
several they have a lot a lot more

00:15:11,589 --> 00:15:17,199
pictures of people that they're able to

00:15:13,810 --> 00:15:18,880
match up together and so the danger of

00:15:17,199 --> 00:15:20,769
this is a lot of people are not aware

00:15:18,880 --> 00:15:23,100
that these pictures worth includes a

00:15:20,769 --> 00:15:25,660
database and oftentimes they're not

00:15:23,100 --> 00:15:26,199
they're not publicly available pictures

00:15:25,660 --> 00:15:28,029
per se

00:15:26,199 --> 00:15:29,440
for example if law enforcement or

00:15:28,029 --> 00:15:32,709
officials actually use all clear view

00:15:29,440 --> 00:15:35,350
you know without being sanctioned by his

00:15:32,709 --> 00:15:37,660
department up flows a picture of your

00:15:35,350 --> 00:15:40,060
was licensed all of a sudden trivia now

00:15:37,660 --> 00:15:42,670
has that picture which it should be

00:15:40,060 --> 00:15:44,140
having in the first place and it also

00:15:42,670 --> 00:15:45,730
makes it easier for other people to kind

00:15:44,140 --> 00:15:47,650
of like if there were a hacks Clearview

00:15:45,730 --> 00:15:50,200
not only are they able to get clear view

00:15:47,650 --> 00:15:51,760
source scored clear views on plant list

00:15:50,200 --> 00:15:54,190
but they can also now have your picture

00:15:51,760 --> 00:15:55,990
on cliffie like just made a lot easier

00:15:54,190 --> 00:15:57,670
for everybody to get so in terms of how

00:15:55,990 --> 00:15:59,350
we can defend yourself against such a

00:15:57,670 --> 00:16:00,820
technology there's been a couple

00:15:59,350 --> 00:16:02,710
different ways that's come out let's

00:16:00,820 --> 00:16:04,360
come up butts come up over the up the

00:16:02,710 --> 00:16:07,950
years one of the primary ways was

00:16:04,360 --> 00:16:10,330
primarily using our mom strobes to

00:16:07,950 --> 00:16:11,830
interfere with the cameras ability or

00:16:10,330 --> 00:16:13,450
infrared storms anyways to interfere

00:16:11,830 --> 00:16:15,700
with the cameras ability to effectively

00:16:13,450 --> 00:16:18,280
get the pixels back to match up one

00:16:15,700 --> 00:16:19,960
person with another but another for

00:16:18,280 --> 00:16:21,160
court for clear views case which is

00:16:19,960 --> 00:16:22,990
where they're actually taking pictures

00:16:21,160 --> 00:16:25,210
that are not suppose to and uploading

00:16:22,990 --> 00:16:26,740
into the database the the primary way

00:16:25,210 --> 00:16:28,390
that you're actually going to defend

00:16:26,740 --> 00:16:31,000
yourself against such a such a thing is

00:16:28,390 --> 00:16:32,500
actually by modifying your pictures to

00:16:31,000 --> 00:16:34,870
begin with you can think of it as being

00:16:32,500 --> 00:16:37,090
a filter that to a human being is

00:16:34,870 --> 00:16:38,650
actually not noticeable but to a deep

00:16:37,090 --> 00:16:42,010
learning model because of the way that

00:16:38,650 --> 00:16:43,540
the model is implemented it's it's able

00:16:42,010 --> 00:16:46,240
to trick them into believing in one

00:16:43,540 --> 00:16:48,490
thing is another or rather it's able to

00:16:46,240 --> 00:16:50,080
it's able to confuse them as to what

00:16:48,490 --> 00:16:51,580
exactly they're looking at because if

00:16:50,080 --> 00:16:53,260
learning models are actually looking at

00:16:51,580 --> 00:16:55,900
every pixel of the picture they're not

00:16:53,260 --> 00:16:57,970
looking at the high level abstraction

00:16:55,900 --> 00:17:05,710
that the picture is trying to

00:16:57,970 --> 00:17:08,230
demonstrate and so the josephus is that

00:17:05,710 --> 00:17:11,380
like a lot of this technology is not you

00:17:08,230 --> 00:17:12,940
and the defenses for it like they

00:17:11,380 --> 00:17:15,700
they're there but they're an

00:17:12,940 --> 00:17:18,190
inconvenience to you and i as far as the

00:17:15,700 --> 00:17:20,860
the reason why Clear View has kind of

00:17:18,190 --> 00:17:22,510
been so brazen with what they're doing

00:17:20,860 --> 00:17:24,400
is because they're using the argument

00:17:22,510 --> 00:17:27,520
that it's legal but the reality is when

00:17:24,400 --> 00:17:29,680
you look at losses GCC PA which nowadays

00:17:27,520 --> 00:17:30,910
mandates that companies have to tell you

00:17:29,680 --> 00:17:32,590
what they're doing with your data and

00:17:30,910 --> 00:17:34,450
specifically you have the right of

00:17:32,590 --> 00:17:36,160
asking them to delete your data it's

00:17:34,450 --> 00:17:38,230
very easy for you to go to Clear View

00:17:36,160 --> 00:17:42,370
and say like delete all my pictures the

00:17:38,230 --> 00:17:44,530
problem is as I've shown you a few steps

00:17:42,370 --> 00:17:46,450
back is there's a lot of information

00:17:44,530 --> 00:17:48,010
that's generated by this by these

00:17:46,450 --> 00:17:49,180
machine learning models for example

00:17:48,010 --> 00:17:50,950
these pictures

00:17:49,180 --> 00:17:52,630
as you seeing them right now they're

00:17:50,950 --> 00:17:54,490
just a regular you know RGB

00:17:52,630 --> 00:17:56,890
representation but there's also an

00:17:54,490 --> 00:17:59,920
immediate representations that you and I

00:17:56,890 --> 00:18:01,360
can't see because they are not in 2d or

00:17:59,920 --> 00:18:03,490
3d space but rather in like

00:18:01,360 --> 00:18:05,320
multi-dimensional space and those

00:18:03,490 --> 00:18:08,170
pictures are saved on career view

00:18:05,320 --> 00:18:10,210
servers and clearly uses those pictures

00:18:08,170 --> 00:18:12,340
to train their models and so in reality

00:18:10,210 --> 00:18:13,720
they might you know say they've deleted

00:18:12,340 --> 00:18:15,090
all your pictures but they're still

00:18:13,720 --> 00:18:17,890
using representations of you

00:18:15,090 --> 00:18:19,510
representations of your face to train

00:18:17,890 --> 00:18:22,120
the models and optimize your models so

00:18:19,510 --> 00:18:24,250
to the extent that the law believes that

00:18:22,120 --> 00:18:26,830
that kind of like derivative data is

00:18:24,250 --> 00:18:29,050
your data clearer if you still has the

00:18:26,830 --> 00:18:32,020
ability to kind of use your information

00:18:29,050 --> 00:18:36,520
against you and up until people will

00:18:32,020 --> 00:18:39,010
recognize the the the process that

00:18:36,520 --> 00:18:41,920
clearly uses in technology that they use

00:18:39,010 --> 00:18:45,220
in fact to to to to to do these things

00:18:41,920 --> 00:18:46,360
it's gonna be very easy for them to kind

00:18:45,220 --> 00:18:49,570
of like Stricker meant a lot because

00:18:46,360 --> 00:18:51,580
it's you can't make a prima facie case

00:18:49,570 --> 00:18:54,370
that clear view actually has your

00:18:51,580 --> 00:18:55,870
information just based on what we know

00:18:54,370 --> 00:18:57,610
about them and just not even based on

00:18:55,870 --> 00:18:59,440
the fact that they're able to to match

00:18:57,610 --> 00:19:01,930
up your face because when you train a

00:18:59,440 --> 00:19:04,960
model you do away with all the training

00:19:01,930 --> 00:19:06,910
data and ultimately you can actually

00:19:04,960 --> 00:19:09,160
have a new set of the well but the whole

00:19:06,910 --> 00:19:11,760
the gist of deep learning is that the

00:19:09,160 --> 00:19:13,990
application is able to predict or

00:19:11,760 --> 00:19:16,390
understand things that it has not seen

00:19:13,990 --> 00:19:17,860
before so once the model was trained and

00:19:16,390 --> 00:19:20,110
you've saved the model weights and you

00:19:17,860 --> 00:19:22,030
say the model state and are now using it

00:19:20,110 --> 00:19:24,400
with like a completely brand new picture

00:19:22,030 --> 00:19:26,140
um you're not aware of the fact that

00:19:24,400 --> 00:19:28,030
within a model state all these other

00:19:26,140 --> 00:19:31,120
pictures that belong to you are actually

00:19:28,030 --> 00:19:33,640
still there so legally speaking if you

00:19:31,120 --> 00:19:35,230
know if you have a judge they are able

00:19:33,640 --> 00:19:39,070
to agree with you and a lawyer that's

00:19:35,230 --> 00:19:40,750
able to a mom articulate this if clear

00:19:39,070 --> 00:19:43,060
view if you have a right to for your

00:19:40,750 --> 00:19:44,680
data to be deleted it means that clear

00:19:43,060 --> 00:19:46,480
you would have to retrain the models

00:19:44,680 --> 00:19:47,650
without your data to make it such that

00:19:46,480 --> 00:19:49,960
they're actually not using the data

00:19:47,650 --> 00:19:52,180
anymore and that's prohibitively

00:19:49,960 --> 00:19:54,070
expensive because as I showed you before

00:19:52,180 --> 00:19:55,960
where I had to set up a cluster of

00:19:54,070 --> 00:19:59,710
Amazon do I be your servers to actually

00:19:55,960 --> 00:20:01,000
train this model because of the fact

00:19:59,710 --> 00:20:02,830
that clearly is training on three

00:20:01,000 --> 00:20:05,049
billion three billion people

00:20:02,830 --> 00:20:07,029
Bunji pictures at 700,000 pictures and

00:20:05,049 --> 00:20:09,340
as I'm doing it becomes a little bit

00:20:07,029 --> 00:20:10,960
less primitively expensive to start

00:20:09,340 --> 00:20:15,490
training models with pictures that you

00:20:10,960 --> 00:20:16,600
don't have the right to so but again

00:20:15,490 --> 00:20:18,789
that's an argument that's gonna have to

00:20:16,600 --> 00:20:20,110
be made and that's an argument that a

00:20:18,789 --> 00:20:21,730
lot of people are going to call that

00:20:20,110 --> 00:20:23,080
going to have to understand before they

00:20:21,730 --> 00:20:24,429
can actually start exercising those

00:20:23,080 --> 00:20:26,350
rights there are people that are

00:20:24,429 --> 00:20:28,210
currently doing in a regular CCP

00:20:26,350 --> 00:20:29,679
erequest such as give me all the

00:20:28,210 --> 00:20:31,179
pictures that you have on me delete all

00:20:29,679 --> 00:20:33,070
the pictures are you having me but as

00:20:31,179 --> 00:20:34,570
far as asking clearly to retrain the

00:20:33,070 --> 00:20:36,010
models without your pictures that's

00:20:34,570 --> 00:20:37,600
something I have not seen anyone go as

00:20:36,010 --> 00:20:40,899
far as doing and I think that's really

00:20:37,600 --> 00:20:43,059
were you're going to have the cost

00:20:40,899 --> 00:20:44,769
associated with this technology that's

00:20:43,059 --> 00:20:46,840
going to make companies like clear you a

00:20:44,769 --> 00:20:52,049
lot less a lot more reluctant to

00:20:46,840 --> 00:20:55,570
actually do this stuff Thanks quickly

00:20:52,049 --> 00:20:57,580
thank you thank you very much Sam are

00:20:55,570 --> 00:21:01,539
you done yeah you want to close it up

00:20:57,580 --> 00:21:03,880
with any final comments yeah the source

00:21:01,539 --> 00:21:05,529
code for this this is this is actually

00:21:03,880 --> 00:21:08,440
Jupiter notebook where I was going to

00:21:05,529 --> 00:21:10,480
demonstrate the the distance metric that

00:21:08,440 --> 00:21:12,370
you can actually use to analyze one

00:21:10,480 --> 00:21:14,289
picture versus another because when you

00:21:12,370 --> 00:21:16,630
convert a picture from you know pixels

00:21:14,289 --> 00:21:19,240
and to something that a machine learning

00:21:16,630 --> 00:21:21,309
model can can understand it pretty much

00:21:19,240 --> 00:21:23,260
converts that into a Multi multi

00:21:21,309 --> 00:21:24,940
dimensional vector and it's just a

00:21:23,260 --> 00:21:27,250
matter of figuring out like which vector

00:21:24,940 --> 00:21:30,100
is closest to another vector which is a

00:21:27,250 --> 00:21:32,440
very simple mathematical operation and

00:21:30,100 --> 00:21:34,690
you can do this for any kind of picture

00:21:32,440 --> 00:21:36,130
it's just a matter of like processing it

00:21:34,690 --> 00:21:38,460
correctly such that the pictures of the

00:21:36,130 --> 00:21:41,260
right size and this the right color and

00:21:38,460 --> 00:21:43,450
what else the source code itself I can

00:21:41,260 --> 00:21:46,570
certainly like show you if you're

00:21:43,450 --> 00:21:48,370
interested in looking at it I because of

00:21:46,570 --> 00:21:51,610
the fact that I had to deploy this an

00:21:48,370 --> 00:21:54,490
AWS I ended up using no Jess for a lot

00:21:51,610 --> 00:21:56,529
of the processing and then for the

00:21:54,490 --> 00:21:58,779
actual machine learning model arm in

00:21:56,529 --> 00:22:01,809
terms of object detection and object

00:21:58,779 --> 00:22:04,240
classification I use the library called

00:22:01,809 --> 00:22:06,580
image AI which is actually a high-level

00:22:04,240 --> 00:22:09,549
wrapper for the temperature flow and

00:22:06,580 --> 00:22:11,710
caris libraries which made it very very

00:22:09,549 --> 00:22:14,080
easy to actually just process a lot of

00:22:11,710 --> 00:22:16,720
this information there are also a few

00:22:14,080 --> 00:22:19,060
other utilities that I use primarily a

00:22:16,720 --> 00:22:20,980
I'm peg which is an open source like

00:22:19,060 --> 00:22:22,000
encoding her encoding application that

00:22:20,980 --> 00:22:25,750
makes it such that you can actually

00:22:22,000 --> 00:22:29,110
slice images and kind of format them

00:22:25,750 --> 00:22:30,520
into different encoding so that was yeah

00:22:29,110 --> 00:22:34,060
I can I can show more details about that

00:22:30,520 --> 00:22:37,030
if you have questions but yeah that's

00:22:34,060 --> 00:22:40,270
pretty much the gist of it yeah okay um

00:22:37,030 --> 00:22:46,120
Sam thank you very much for fitting us

00:22:40,270 --> 00:22:47,620
in in this unusual session I as just to

00:22:46,120 --> 00:22:49,690
reiterate what we're going to do so

00:22:47,620 --> 00:22:52,180
we're going to share this in the general

00:22:49,690 --> 00:22:53,710
channel in slack and give people the

00:22:52,180 --> 00:22:55,750
opportunity to watch this in their own

00:22:53,710 --> 00:22:57,820
time and then if you're available

00:22:55,750 --> 00:23:00,760
tomorrow - uh - maybe continue some of

00:22:57,820 --> 00:23:04,540
these conversations on slack you can do

00:23:00,760 --> 00:23:07,060
that by text or we've got a core

00:23:04,540 --> 00:23:08,620
functionality in slack so it may be you

00:23:07,060 --> 00:23:09,760
want to organize yourself a session

00:23:08,620 --> 00:23:11,920
where you can talk through some of these

00:23:09,760 --> 00:23:13,780
issues in a bit more but I was really it

00:23:11,920 --> 00:23:15,100
was really fantastic and I'm really

00:23:13,780 --> 00:23:20,170
pleased we managed to fit this in

00:23:15,100 --> 00:23:22,000
because yeah me too thank you yeah this

00:23:20,170 --> 00:23:23,890
is primarily - supposed to be like a

00:23:22,000 --> 00:23:27,150
discussion piece because the the

00:23:23,890 --> 00:23:29,410
technical stuff is it's very deep but

00:23:27,150 --> 00:23:31,330
it's just one of those things that I

00:23:29,410 --> 00:23:34,360
I've noticed that a lot of people

00:23:31,330 --> 00:23:35,860
haven't really talked about despite the

00:23:34,360 --> 00:23:38,800
fact that that's really where you good I

00:23:35,860 --> 00:23:40,570
have the ability to make any changes may

00:23:38,800 --> 00:23:43,030
that be changing the law or changes

00:23:40,570 --> 00:23:44,800
include ease behavior so I just wanted

00:23:43,030 --> 00:23:47,080
to go into a bit more detail about that

00:23:44,800 --> 00:23:49,620
and also kind of share the how easy this

00:23:47,080 --> 00:23:49,620

YouTube URL: https://www.youtube.com/watch?v=GNSy3oOg8F4


