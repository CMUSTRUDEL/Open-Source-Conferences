Title: Miriam Posner - CSVConf 2017
Publication date: 2017-06-04
Playlist: CSVConf 2017 - Day 1 - Room A
Description: 
	
Captions: 
	00:00:01,900 --> 00:00:06,100
hi I'm so glad people came I wasn't sure

00:00:04,750 --> 00:00:10,870
if anyone would actually care about this

00:00:06,100 --> 00:00:13,210
so I'm glad you did I actually went to

00:00:10,870 --> 00:00:14,620
college in Portland that reads it anyone

00:00:13,210 --> 00:00:16,630
else there reading in here I know

00:00:14,620 --> 00:00:19,650
Gabriella's we got it yeah all right so

00:00:16,630 --> 00:00:23,170
so cool so it's awesome to be back here

00:00:19,650 --> 00:00:24,369
and I teach digital humanities at UCLA

00:00:23,170 --> 00:00:26,050
and I wasn't sure coming in if people

00:00:24,369 --> 00:00:28,539
would actually know what that is or not

00:00:26,050 --> 00:00:33,519
does does anyone's like who knows what

00:00:28,539 --> 00:00:34,870
that is maybe sort of okay cool well the

00:00:33,519 --> 00:00:36,820
fact is like if you don't know what it

00:00:34,870 --> 00:00:38,170
is you're in good company a lot of

00:00:36,820 --> 00:00:39,850
people don't know what it is and there's

00:00:38,170 --> 00:00:42,969
even a website called like what is

00:00:39,850 --> 00:00:44,620
digital humanities comm I think every

00:00:42,969 --> 00:00:48,129
time you refresh it you get a different

00:00:44,620 --> 00:00:50,890
definition it's very frustrating I like

00:00:48,129 --> 00:00:53,110
to say it's the use of digital tools to

00:00:50,890 --> 00:00:55,030
explore humanities questions and I

00:00:53,110 --> 00:00:57,309
always say explore and not answer

00:00:55,030 --> 00:01:00,100
because as you probably know the

00:00:57,309 --> 00:01:02,590
humanities isn't really about definitive

00:01:00,100 --> 00:01:04,719
answers to questions like you can't just

00:01:02,590 --> 00:01:07,600
be like there's one interpretation of

00:01:04,719 --> 00:01:10,569
Jane Eyre or one interpretation of like

00:01:07,600 --> 00:01:12,520
medieval art you're always kind of

00:01:10,569 --> 00:01:15,729
gesturing toward interpretation rather

00:01:12,520 --> 00:01:19,569
than coming to distinct conclusions and

00:01:15,729 --> 00:01:23,200
because of that we have some particular

00:01:19,569 --> 00:01:25,509
needs and difficulties in our field that

00:01:23,200 --> 00:01:27,639
I was hoping might be interesting to you

00:01:25,509 --> 00:01:29,439
I was hoping they might be interesting

00:01:27,639 --> 00:01:31,539
enough to even get you to like think

00:01:29,439 --> 00:01:34,240
about working on some projects or or

00:01:31,539 --> 00:01:36,429
tools or talking to us about getting

00:01:34,240 --> 00:01:43,139
involved because as you'll see in a

00:01:36,429 --> 00:01:45,729
minute we have some recent needs okay so

00:01:43,139 --> 00:01:48,609
why study data in the humanities

00:01:45,729 --> 00:01:52,270
classroom as you as you know we probably

00:01:48,609 --> 00:01:53,739
have some humanities majors in here the

00:01:52,270 --> 00:01:57,279
humanities you know is about

00:01:53,739 --> 00:01:59,859
interpretation because reading you know

00:01:57,279 --> 00:02:01,749
we love paradox and changing the terms

00:01:59,859 --> 00:02:04,840
of the debate that's kind of our thing

00:02:01,749 --> 00:02:08,170
and and that's not necessarily something

00:02:04,840 --> 00:02:10,299
one associates with data except that as

00:02:08,170 --> 00:02:15,040
you know like the entire cultural record

00:02:10,299 --> 00:02:17,560
is slowly or quickly becoming digitized

00:02:15,040 --> 00:02:19,750
and it's become important I think to

00:02:17,560 --> 00:02:22,780
help students and other people who think

00:02:19,750 --> 00:02:25,989
about the humanities to not cede all of

00:02:22,780 --> 00:02:27,879
that digitized cultural record to people

00:02:25,989 --> 00:02:31,390
who who are not trained in the

00:02:27,879 --> 00:02:33,370
humanities so we we've been excuse me

00:02:31,390 --> 00:02:36,670
we've been at UCLA really working hard

00:02:33,370 --> 00:02:40,239
on helping students to think about data

00:02:36,670 --> 00:02:42,640
as a representation of one view of

00:02:40,239 --> 00:02:44,200
reality so developing some fluency and

00:02:42,640 --> 00:02:47,010
literacy with data but also

00:02:44,200 --> 00:02:49,390
understanding it in context and

00:02:47,010 --> 00:02:52,569
certainly not the only way to think

00:02:49,390 --> 00:02:56,590
about the world right now we have about

00:02:52,569 --> 00:02:58,239
70 students in our D H minor and we're

00:02:56,590 --> 00:03:01,090
growing pretty fast we've only been

00:02:58,239 --> 00:03:04,180
around for about five years and I think

00:03:01,090 --> 00:03:06,190
BH programs are popping up all over the

00:03:04,180 --> 00:03:08,019
all over the world I mean certainly in

00:03:06,190 --> 00:03:11,799
the United States I think they probably

00:03:08,019 --> 00:03:15,909
nip number in the hundreds at least so

00:03:11,799 --> 00:03:17,170
so it's really a growing field at you

00:03:15,909 --> 00:03:20,709
see you later on the quarter system

00:03:17,170 --> 00:03:23,799
which is ten weeks filling our intro

00:03:20,709 --> 00:03:25,419
class which I usually teach we have ten

00:03:23,799 --> 00:03:29,769
weeks to get students up to speed very

00:03:25,419 --> 00:03:32,769
very quickly and our students are really

00:03:29,769 --> 00:03:35,169
lovely but they tend not to come in with

00:03:32,769 --> 00:03:39,250
a ton of data literacy or indeed

00:03:35,169 --> 00:03:46,449
technical literacy the typical BH minor

00:03:39,250 --> 00:03:48,310
is an undergrad non-stem major their

00:03:46,449 --> 00:03:50,410
experience with technology is usually

00:03:48,310 --> 00:03:54,010
limited to like Microsoft Office you

00:03:50,410 --> 00:03:56,709
know Word PowerPoint and maybe Excel

00:03:54,010 --> 00:04:00,819
maybe maybe Photoshop or you know the

00:03:56,709 --> 00:04:03,280
Adobe Creative Suite and we have ten

00:04:00,819 --> 00:04:06,340
weeks in the quarter system to get from

00:04:03,280 --> 00:04:08,650
like an absolute zero to data literacy

00:04:06,340 --> 00:04:10,780
while also trying to incorporate a lot

00:04:08,650 --> 00:04:13,150
of theoretical reading and discussion

00:04:10,780 --> 00:04:18,159
about like what the humanities are what

00:04:13,150 --> 00:04:22,240
data is etc etc so to try to get them

00:04:18,159 --> 00:04:24,190
there you know we want to teach them how

00:04:22,240 --> 00:04:26,320
to work with data in a basic way but we

00:04:24,190 --> 00:04:28,330
also want them to be able to put a data

00:04:26,320 --> 00:04:28,849
set into context with a lot of critical

00:04:28,330 --> 00:04:33,050
reading

00:04:28,849 --> 00:04:35,599
and research because otherwise you know

00:04:33,050 --> 00:04:37,999
a data set visualized on its own doesn't

00:04:35,599 --> 00:04:40,520
really mean anything so it's like if

00:04:37,999 --> 00:04:42,469
you're working with data about comic

00:04:40,520 --> 00:04:45,289
book characters which which is one data

00:04:42,469 --> 00:04:47,300
set we've used in the past and you're

00:04:45,289 --> 00:04:49,639
trying to visualize genders of comic

00:04:47,300 --> 00:04:51,770
book characters we want you reading all

00:04:49,639 --> 00:04:54,439
the critical secondary literature on

00:04:51,770 --> 00:04:57,819
like gender and comic books and

00:04:54,439 --> 00:05:02,479
narrative art in addition to doing that

00:04:57,819 --> 00:05:05,509
data base and statistical work and so

00:05:02,479 --> 00:05:09,619
the assignment that we use in my D h101

00:05:05,509 --> 00:05:13,689
class is to everyone kind of adopts a

00:05:09,619 --> 00:05:15,889
dataset like in sitcoms you know people

00:05:13,689 --> 00:05:18,349
people will have to like adoptive bag of

00:05:15,889 --> 00:05:20,179
flour and treat it as their baby for for

00:05:18,349 --> 00:05:22,369
a few weeks and it's kind of like that

00:05:20,179 --> 00:05:24,740
but with a data set for four groups of

00:05:22,369 --> 00:05:26,809
students it's kind of their baby for the

00:05:24,740 --> 00:05:28,879
for the quarter and they have to get

00:05:26,809 --> 00:05:31,249
from zero to being able to visualize it

00:05:28,879 --> 00:05:32,749
map it write a narrative about it and

00:05:31,249 --> 00:05:35,930
then put the whole thing on a website

00:05:32,749 --> 00:05:39,740
and it's like a Swiss watch like nothing

00:05:35,930 --> 00:05:42,789
can fall out of place ever because if we

00:05:39,740 --> 00:05:45,379
do the whole course goes off the rails

00:05:42,789 --> 00:05:47,569
and I've noticed I wanted to share with

00:05:45,379 --> 00:05:50,029
you some features of the kinds of data

00:05:47,569 --> 00:05:53,229
sets that my students can work with

00:05:50,029 --> 00:05:55,430
versus the ones they can't work with

00:05:53,229 --> 00:05:56,839
these might be surprising to you because

00:05:55,430 --> 00:05:59,149
your work you're used to working with

00:05:56,839 --> 00:06:00,769
people who have some data literacy but

00:05:59,149 --> 00:06:05,300
I've noticed some very specific things

00:06:00,769 --> 00:06:06,979
about data my students can work with so

00:06:05,300 --> 00:06:08,629
first of all they need some context to

00:06:06,979 --> 00:06:12,229
the data set they need some background

00:06:08,629 --> 00:06:17,199
about where it came from how is recorded

00:06:12,229 --> 00:06:20,329
so not just not just stuff about like

00:06:17,199 --> 00:06:22,129
you know what kinds of characters are in

00:06:20,329 --> 00:06:25,579
a field but actually like where did that

00:06:22,129 --> 00:06:27,439
field come from they need some kind of

00:06:25,579 --> 00:06:29,689
model like it was really helpful for

00:06:27,439 --> 00:06:31,039
them when they were doing visualization

00:06:29,689 --> 00:06:35,360
of the data set about comic book

00:06:31,039 --> 00:06:38,749
characters to see 5:38 work on those on

00:06:35,360 --> 00:06:41,870
those characters my students can't work

00:06:38,749 --> 00:06:44,060
with api's I know we all love api's and

00:06:41,870 --> 00:06:45,980
things like that but they're not they're

00:06:44,060 --> 00:06:48,020
not out of place yet where they can they

00:06:45,980 --> 00:06:49,220
can do that I mean I can do it at the

00:06:48,020 --> 00:06:51,440
beginning of the quarter and get the

00:06:49,220 --> 00:06:53,540
data for them and prepare it but the

00:06:51,440 --> 00:06:55,910
less I have to do in advance the better

00:06:53,540 --> 00:07:00,350
if I don't have to learn someone API

00:06:55,910 --> 00:07:02,960
then I'm then I'm a lot happier they

00:07:00,350 --> 00:07:04,700
can't they so they so in keeping with

00:07:02,960 --> 00:07:07,130
the the title of this conference they

00:07:04,700 --> 00:07:09,370
love CFCs they can't work with XML or

00:07:07,130 --> 00:07:11,150
JSON or turtle or anything like that

00:07:09,370 --> 00:07:12,800
they need to be able to like

00:07:11,150 --> 00:07:14,600
double-click the thing and open it in

00:07:12,800 --> 00:07:17,090
Excel because they want to see the

00:07:14,600 --> 00:07:18,410
structure of the data set and they want

00:07:17,090 --> 00:07:20,440
to be able to drop it into something

00:07:18,410 --> 00:07:26,660
like tableau and just immediately

00:07:20,440 --> 00:07:28,040
visualize it and the ideal size for my

00:07:26,660 --> 00:07:30,110
group is like two thousand records

00:07:28,040 --> 00:07:32,530
because it's too big for them to

00:07:30,110 --> 00:07:37,460
individually like change every record

00:07:32,530 --> 00:07:39,830
okay but not so big it'll crash Excel so

00:07:37,460 --> 00:07:41,480
these are like hard learned lessons that

00:07:39,830 --> 00:07:44,900
I've picked up over the years of

00:07:41,480 --> 00:07:46,280
teaching beginners and I was hoping you

00:07:44,900 --> 00:07:48,710
know maybe people would find this

00:07:46,280 --> 00:07:51,500
compelling enough to think about

00:07:48,710 --> 00:07:54,920
creating like training data sets when

00:07:51,500 --> 00:07:56,870
they're building out larger like api's

00:07:54,920 --> 00:07:58,610
and linked data and stuff that is

00:07:56,870 --> 00:08:01,070
awesome and wonderful but also maybe

00:07:58,610 --> 00:08:02,560
think about smaller training data sets

00:08:01,070 --> 00:08:04,940
for students who are getting started

00:08:02,560 --> 00:08:06,890
because the good news is like they

00:08:04,940 --> 00:08:09,290
become very fluent very quickly they

00:08:06,890 --> 00:08:10,760
learn so fast it's scary and they'll

00:08:09,290 --> 00:08:12,560
learn your API and they'll learn about

00:08:10,760 --> 00:08:15,080
sparkle queries and they'll learn about

00:08:12,560 --> 00:08:16,070
all that stuff but they need to practice

00:08:15,080 --> 00:08:18,620
with something a little bit more

00:08:16,070 --> 00:08:21,080
manageable

00:08:18,620 --> 00:08:23,000
I don't know how interesting this is to

00:08:21,080 --> 00:08:25,940
you this is the suite of tools that we

00:08:23,000 --> 00:08:28,370
tend to use in my class maybe these are

00:08:25,940 --> 00:08:31,160
familiar data basic is a wonderful like

00:08:28,370 --> 00:08:33,500
teaching tool for students you can drop

00:08:31,160 --> 00:08:36,530
a CSV in and it'll tell you like what

00:08:33,500 --> 00:08:38,900
each of the fields are open refine for

00:08:36,530 --> 00:08:42,800
cleaning Cardo for mapping although it

00:08:38,900 --> 00:08:47,290
mad about their new interface raw is

00:08:42,800 --> 00:08:50,300
like a really nice of data visualization

00:08:47,290 --> 00:08:54,140
package tableau cytoscape Fusion Tables

00:08:50,300 --> 00:08:54,730
WordPress p5.js which I just wanted to

00:08:54,140 --> 00:08:56,529
fly

00:08:54,730 --> 00:08:58,269
does something that were more and more

00:08:56,529 --> 00:09:02,380
interested in using for our deep

00:08:58,269 --> 00:09:08,910
students does anyone know p5 do you want

00:09:02,380 --> 00:09:08,910
to clean what it is yeah

00:09:13,500 --> 00:09:19,209
that's exactly right and and so actually

00:09:16,570 --> 00:09:21,310
the one of the people Casey Rios and Ben

00:09:19,209 --> 00:09:24,459
fry designed processing for like

00:09:21,310 --> 00:09:27,370
artistic coding Casey Rios is at UCLA

00:09:24,459 --> 00:09:30,250
and the person who ported it to

00:09:27,370 --> 00:09:32,199
JavaScript Lauren McCarthy is also at

00:09:30,250 --> 00:09:35,589
UCLA as of this year so a lot of our

00:09:32,199 --> 00:09:37,839
design students come in learning p5

00:09:35,589 --> 00:09:40,750
already and what's great about p5 is

00:09:37,839 --> 00:09:44,380
that as opposed to d3 which I also love

00:09:40,750 --> 00:09:47,410
and use a lot p5 takes as you're

00:09:44,380 --> 00:09:49,600
primitive like not a bar chart or you

00:09:47,410 --> 00:09:53,260
know a scatter plot but like a circle or

00:09:49,600 --> 00:09:55,269
a square so if you're interested in

00:09:53,260 --> 00:09:57,310
doing some experimental visualization

00:09:55,269 --> 00:10:00,040
you can have like a circle bounce

00:09:57,310 --> 00:10:02,980
against a square every time like female

00:10:00,040 --> 00:10:04,750
comes up in your gender in your gender

00:10:02,980 --> 00:10:07,990
category and I'll explain why that's

00:10:04,750 --> 00:10:11,680
interesting in a minute it is really not

00:10:07,990 --> 00:10:14,440
immediately compelling ok so I wanted to

00:10:11,680 --> 00:10:16,420
give you a quick look at some of the

00:10:14,440 --> 00:10:18,790
work my students do after a quarter oh I

00:10:16,420 --> 00:10:23,050
can't because it's down perhaps I'll

00:10:18,790 --> 00:10:24,699
share this out on my Twitter feed in a

00:10:23,050 --> 00:10:26,860
moment but I did want to say like they

00:10:24,699 --> 00:10:29,889
get pretty far you'd be surprised in 10

00:10:26,860 --> 00:10:33,220
weeks they get pretty far this was using

00:10:29,889 --> 00:10:34,899
a data set about all the performances

00:10:33,220 --> 00:10:36,459
from the New York Philharmonic which I

00:10:34,899 --> 00:10:40,779
think Dan Fowler shared with me

00:10:36,459 --> 00:10:43,060
initially and they were able to show the

00:10:40,779 --> 00:10:44,889
influence of German composers in the

00:10:43,060 --> 00:10:46,300
early years of the New York Phil which

00:10:44,889 --> 00:10:50,380
was you know pretty good work for a

00:10:46,300 --> 00:10:52,600
bunch of undergrads and I wanted to talk

00:10:50,380 --> 00:10:55,149
about this tool wish list that we have

00:10:52,600 --> 00:10:58,410
in the humanities that have to do with

00:10:55,149 --> 00:11:01,930
our specific way of looking at the world

00:10:58,410 --> 00:11:05,380
I don't think I can play this for you

00:11:01,930 --> 00:11:06,460
because my Wi-Fi connection is down but

00:11:05,380 --> 00:11:10,320
maybe you've seen this

00:11:06,460 --> 00:11:13,780
map of slave ships that that was inflate

00:11:10,320 --> 00:11:18,310
it was it was drawn from the voyages

00:11:13,780 --> 00:11:20,500
database of the travels of vessel King

00:11:18,310 --> 00:11:22,570
and slaved people and it's a really

00:11:20,500 --> 00:11:26,380
really powerful visualization you can

00:11:22,570 --> 00:11:29,920
see the ships traveling over time you

00:11:26,380 --> 00:11:32,440
can kind of slide back and forth but I

00:11:29,920 --> 00:11:34,240
wanted to emphasize it not because it's

00:11:32,440 --> 00:11:36,970
an inherently powerful visualization

00:11:34,240 --> 00:11:38,080
which it is but it also shows something

00:11:36,970 --> 00:11:40,720
that a lot of people in the humanities

00:11:38,080 --> 00:11:42,700
are trying to do all the time and really

00:11:40,720 --> 00:11:45,790
having a hard time with which is showing

00:11:42,700 --> 00:11:48,310
time space and movement all at the same

00:11:45,790 --> 00:11:49,990
time like everybody thinks there's some

00:11:48,310 --> 00:11:53,350
tool you can just drop a data set in

00:11:49,990 --> 00:11:54,610
where you have like a scrubber you know

00:11:53,350 --> 00:11:56,500
and you can move it back and forth and

00:11:54,610 --> 00:11:59,170
see how people migrate it or see how an

00:11:56,500 --> 00:12:01,060
object traveled and it's like it's the

00:11:59,170 --> 00:12:03,850
most common request I get and one of the

00:12:01,060 --> 00:12:04,840
hardest to fulfill for some reason I

00:12:03,850 --> 00:12:07,060
don't know it's interesting to think

00:12:04,840 --> 00:12:10,660
about like why that's so important to

00:12:07,060 --> 00:12:16,120
humanists and it's hard for us to do it

00:12:10,660 --> 00:12:18,730
without custom programming I think that

00:12:16,120 --> 00:12:19,960
humanists think about uncertainty in a

00:12:18,730 --> 00:12:23,650
way that's a little different from

00:12:19,960 --> 00:12:25,360
statisticians in the sense that the

00:12:23,650 --> 00:12:27,430
techniques I've seen in statistics for

00:12:25,360 --> 00:12:29,650
visualizing uncertainty depends on

00:12:27,430 --> 00:12:32,530
quantifying like either a margin of

00:12:29,650 --> 00:12:34,620
error or a degree of uncertainty but for

00:12:32,530 --> 00:12:37,420
us uncertainty is more about like

00:12:34,620 --> 00:12:42,160
epistemological uncertainty or like

00:12:37,420 --> 00:12:45,610
ontological uncertainty this is a this

00:12:42,160 --> 00:12:48,250
is a pretty standard you know network

00:12:45,610 --> 00:12:51,810
visualization of some data we gathered

00:12:48,250 --> 00:12:55,090
about the early race film industry and

00:12:51,810 --> 00:12:56,860
you know is fine there's is all the

00:12:55,090 --> 00:12:59,320
people involved in the industry and

00:12:56,860 --> 00:13:02,020
they're connected via the film's they

00:12:59,320 --> 00:13:04,030
worked on together but I think what was

00:13:02,020 --> 00:13:06,070
really interesting to us in this project

00:13:04,030 --> 00:13:08,350
was trying to figure out what a race

00:13:06,070 --> 00:13:12,820
film was because any individual

00:13:08,350 --> 00:13:16,240
criterion for a race film like directed

00:13:12,820 --> 00:13:18,760
by a black director or contains an

00:13:16,240 --> 00:13:19,720
all-black cast any individual criterion

00:13:18,760 --> 00:13:21,760
will fail

00:13:19,720 --> 00:13:23,770
because the race film industry was a

00:13:21,760 --> 00:13:26,410
community of practice it wasn't like a

00:13:23,770 --> 00:13:28,510
binary category that a film could sit in

00:13:26,410 --> 00:13:30,340
and we were really interested in showing

00:13:28,510 --> 00:13:32,020
like some of these films were really

00:13:30,340 --> 00:13:35,140
race films and some of them were kind of

00:13:32,020 --> 00:13:37,480
not race films and we didn't really have

00:13:35,140 --> 00:13:42,190
a good technique in our repertoire for

00:13:37,480 --> 00:13:44,410
for showing that kind of strangeness and

00:13:42,190 --> 00:13:47,110
fuzziness in our data so we love

00:13:44,410 --> 00:13:52,690
thinking about fuzziness and strangeness

00:13:47,110 --> 00:13:57,460
and how to depict that we're also always

00:13:52,690 --> 00:14:01,000
interested in multi-perspective ality I

00:13:57,460 --> 00:14:02,650
wanted to show this mat because in a way

00:14:01,000 --> 00:14:07,240
it's pretty straightforward it's a map

00:14:02,650 --> 00:14:10,240
of Harlem in the 1920s and you can pull

00:14:07,240 --> 00:14:13,090
down a menu and map these different

00:14:10,240 --> 00:14:15,370
events but what's striking about this

00:14:13,090 --> 00:14:16,930
map to people who spend time with it is

00:14:15,370 --> 00:14:19,090
that like you realize looking at the

00:14:16,930 --> 00:14:20,590
categories that this isn't digital heart

00:14:19,090 --> 00:14:23,050
I mean this isn't Harlem for people who

00:14:20,590 --> 00:14:25,720
lived there in the 20s this is Harlem

00:14:23,050 --> 00:14:28,600
for the police who were surveilling

00:14:25,720 --> 00:14:32,760
Harlem like assault domestic assault on

00:14:28,600 --> 00:14:35,500
police automobile crash right now like

00:14:32,760 --> 00:14:37,360
so right now there's there's there's one

00:14:35,500 --> 00:14:39,190
map of Harlem but would it be cool if

00:14:37,360 --> 00:14:40,900
you could like flip it so then it was

00:14:39,190 --> 00:14:43,120
from someone else's perspective like

00:14:40,900 --> 00:14:45,040
this is the police view of Harlem well

00:14:43,120 --> 00:14:46,450
what did Harlem look to someone look

00:14:45,040 --> 00:14:49,600
like to someone who actually lives there

00:14:46,450 --> 00:14:54,370
it's cool to think about we don't really

00:14:49,600 --> 00:14:57,190
have a way of doing it so Warren

00:14:54,370 --> 00:14:59,950
McCarthy and I the one who developed the

00:14:57,190 --> 00:15:01,690
JavaScript port for p5 have just

00:14:59,950 --> 00:15:03,070
convened a series of workshops where

00:15:01,690 --> 00:15:05,890
we're kind of working through some of

00:15:03,070 --> 00:15:10,030
these issues it's called scope lab the

00:15:05,890 --> 00:15:12,790
feminist data workshop that really

00:15:10,030 --> 00:15:15,400
thinks about uncertainty and contingency

00:15:12,790 --> 00:15:17,110
really seriously so we're working on it

00:15:15,400 --> 00:15:18,970
we're hoping maybe you'll think about

00:15:17,110 --> 00:15:21,730
working on it to talk to me about

00:15:18,970 --> 00:15:23,760
working on it and I think that's great

00:15:21,730 --> 00:15:41,790
thank you

00:15:23,760 --> 00:15:44,910
I think I yeah made it through yeah the

00:15:41,790 --> 00:15:47,269
other point collateral benefit I see

00:15:44,910 --> 00:15:49,709
with you cytoscape what Miz Vera

00:15:47,269 --> 00:15:56,180
particular reason because when I try to

00:15:49,709 --> 00:15:56,180
use it I was very frustrated surprise it

00:15:56,990 --> 00:16:16,949
kind of has yeah in Indy eight what do

00:16:00,060 --> 00:16:17,519
you use yeah very cool yeah that's it

00:16:16,949 --> 00:16:19,800
really

00:16:17,519 --> 00:16:21,360
that's a really good question so we do

00:16:19,800 --> 00:16:23,670
to the youth site escape I know Thomas

00:16:21,360 --> 00:16:26,699
and I both use sign escapes like when

00:16:23,670 --> 00:16:28,800
we're doing network graph because only

00:16:26,699 --> 00:16:33,389
because guess II stopped working more or

00:16:28,800 --> 00:16:37,350
less and so so we switched to cytoscape

00:16:33,389 --> 00:16:39,510
which is fine we sometimes use pole

00:16:37,350 --> 00:16:42,779
audio which is another kind of web-based

00:16:39,510 --> 00:16:44,490
interface for doing network graph what

00:16:42,779 --> 00:16:47,519
I've found about network graph in the

00:16:44,490 --> 00:16:49,230
humanities is that humanists sometimes

00:16:47,519 --> 00:16:51,089
are interested in like traditional

00:16:49,230 --> 00:16:53,760
measures of networks like various kinds

00:16:51,089 --> 00:16:55,440
of sensuality and stuff but more often

00:16:53,760 --> 00:16:58,440
they're just wanting to like see

00:16:55,440 --> 00:17:02,279
connections so it would be nice if there

00:16:58,440 --> 00:17:03,870
was like a beginner level network graph

00:17:02,279 --> 00:17:07,319
tool that could handle a lot of

00:17:03,870 --> 00:17:08,880
different nodes but didn't have all the

00:17:07,319 --> 00:17:16,549
bells and whistles that like cytoscape

00:17:08,880 --> 00:17:16,549
org se has I'm gonna go

00:17:18,300 --> 00:17:23,280
and I thought about the problem fighting

00:17:20,520 --> 00:17:25,950
alone helpful patience bit funny

00:17:23,280 --> 00:17:28,320
contracture the powerful not suppose

00:17:25,950 --> 00:17:29,700
just because of the idea like taking

00:17:28,320 --> 00:17:32,850
people we don't know much about how I

00:17:29,700 --> 00:17:35,220
want environment to allow the web on

00:17:32,850 --> 00:17:49,080
jobs for programmers welded you have a

00:17:35,220 --> 00:17:51,360
lot of levels of it's really true like

00:17:49,080 --> 00:17:53,490
like what you say that that we're kind

00:17:51,360 --> 00:17:55,740
of immediately moving them away from

00:17:53,490 --> 00:17:58,350
actually dealing with like whatever the

00:17:55,740 --> 00:17:59,880
data is at its most basic level by by

00:17:58,350 --> 00:18:02,370
asking them to like visualize it

00:17:59,880 --> 00:18:05,700
immediately and I do know people who

00:18:02,370 --> 00:18:10,650
take that approach where they don't you

00:18:05,700 --> 00:18:12,780
know they start very granular with like

00:18:10,650 --> 00:18:14,850
what is data like what's the difference

00:18:12,780 --> 00:18:19,080
between a document and like an

00:18:14,850 --> 00:18:21,150
individual record I find this I don't

00:18:19,080 --> 00:18:23,370
know if this is true or not my I guess

00:18:21,150 --> 00:18:25,920
my my suspicion is that my students want

00:18:23,370 --> 00:18:27,330
to see things right away like they want

00:18:25,920 --> 00:18:28,920
to know what they're dealing with right

00:18:27,330 --> 00:18:31,890
away so the quicker we can get to

00:18:28,920 --> 00:18:35,340
visualization the more comfortable they

00:18:31,890 --> 00:18:37,560
are but I also see some very compelling

00:18:35,340 --> 00:18:40,670
reasons to get them programming with

00:18:37,560 --> 00:18:40,670
Python quickly

00:18:50,090 --> 00:18:54,230
yeah every year I'm like I'm going to

00:18:52,130 --> 00:19:33,800
teach this class differently experience

00:18:54,230 --> 00:19:35,090
for sure yeah that is that is so true I

00:19:33,800 --> 00:19:37,430
mean that's kind of one of the most

00:19:35,090 --> 00:19:39,590
satisfying things to me is seeing the

00:19:37,430 --> 00:19:41,780
students having those conversations and

00:19:39,590 --> 00:19:45,380
actually I find that happens most often

00:19:41,780 --> 00:19:46,960
when they're cleaning the data so that's

00:19:45,380 --> 00:19:48,620
why I love teaching them openrefine

00:19:46,960 --> 00:19:50,690
because they have to make these

00:19:48,620 --> 00:19:52,670
decisions about okay well you know like

00:19:50,690 --> 00:19:54,950
we have too many fields here which ones

00:19:52,670 --> 00:19:57,860
are we going to get rid of and like oh

00:19:54,950 --> 00:19:59,870
well if we get rid of like you know this

00:19:57,860 --> 00:20:04,400
element then you won't be able to track

00:19:59,870 --> 00:20:06,260
it or like if we clean up this language

00:20:04,400 --> 00:20:08,570
and standardize the vocabulary we're

00:20:06,260 --> 00:20:10,610
losing this nuance and so they really

00:20:08,570 --> 00:20:12,800
see it very directly when they're trying

00:20:10,610 --> 00:20:14,600
to like aggregate terms and openrefine

00:20:12,800 --> 00:20:16,010
and sometimes they get it and sometimes

00:20:14,600 --> 00:20:18,650
they just don't want any part of it

00:20:16,010 --> 00:20:20,300
they're like you know I don't want that

00:20:18,650 --> 00:20:22,160
you know like there's a field it's

00:20:20,300 --> 00:20:25,730
called statistics it's fine like don't

00:20:22,160 --> 00:20:29,050
make me you know talk about the area in

00:20:25,730 --> 00:20:29,050
the humanities at all yes

00:20:37,550 --> 00:20:44,850
still today today's that but I'm curious

00:20:41,280 --> 00:21:05,460
if you can comment on textual

00:20:44,850 --> 00:21:07,710
information around yeah I mean it

00:21:05,460 --> 00:21:08,370
actually it's kind of not what you might

00:21:07,710 --> 00:21:10,320
expect

00:21:08,370 --> 00:21:12,210
like I know data people are always very

00:21:10,320 --> 00:21:14,520
interested in tracking provenance and

00:21:12,210 --> 00:21:16,830
talking like changes made to the data

00:21:14,520 --> 00:21:18,390
set over time and they're not kind of

00:21:16,830 --> 00:21:21,270
there yet they're not thinking about

00:21:18,390 --> 00:21:22,710
data in that way it what they find most

00:21:21,270 --> 00:21:25,050
helpful is actually talking to the

00:21:22,710 --> 00:21:27,090
person who if they're if paper records

00:21:25,050 --> 00:21:28,740
exist like taking the paper records and

00:21:27,090 --> 00:21:30,540
entering them into some kind of

00:21:28,740 --> 00:21:32,730
structured form because they don't

00:21:30,540 --> 00:21:36,000
understand how data gets from like out

00:21:32,730 --> 00:21:38,550
in the world to like structured data

00:21:36,000 --> 00:21:40,679
that can work with so they really like

00:21:38,550 --> 00:21:43,080
to like see you know for example take

00:21:40,679 --> 00:21:45,330
the New York Phil collection they'd like

00:21:43,080 --> 00:21:47,870
to see the document that like describes

00:21:45,330 --> 00:21:50,880
these performances and then how someone

00:21:47,870 --> 00:21:54,500
transposed those messy categories onto a

00:21:50,880 --> 00:21:54,500
spreadsheet or whatever

00:22:16,210 --> 00:22:20,990
yes I'm glad you asked that because it's

00:22:19,490 --> 00:22:23,510
such a good point I subscribe to that

00:22:20,990 --> 00:22:25,850
newsletter too and love it I find that

00:22:23,510 --> 00:22:27,290
like student I mean my humanities

00:22:25,850 --> 00:22:28,880
students like it's not that you couldn't

00:22:27,290 --> 00:22:31,340
make a humanities argument out of like

00:22:28,880 --> 00:22:33,200
municipal water records but they're not

00:22:31,340 --> 00:22:35,890
at a place where they can see that yet

00:22:33,200 --> 00:22:39,260
so they need like traditional cultural

00:22:35,890 --> 00:22:42,140
artifacts like the you know like the

00:22:39,260 --> 00:22:43,820
Philharmonic performance or like you

00:22:42,140 --> 00:22:45,800
know costume design over the years

00:22:43,820 --> 00:22:47,120
things like that where they can have an

00:22:45,800 --> 00:22:49,130
easier time seeing how to make an

00:22:47,120 --> 00:22:51,530
argument that speaks to the humanities

00:22:49,130 --> 00:22:54,620
about it and finding those data sets is

00:22:51,530 --> 00:22:56,630
just awful like if anyone here has tried

00:22:54,620 --> 00:22:58,460
to do it they can back me up there's

00:22:56,630 --> 00:23:00,020
just like a grapevine where we all tell

00:22:58,460 --> 00:23:03,350
each other about these things like Dan

00:23:00,020 --> 00:23:05,240
told me about the New York filthy you

00:23:03,350 --> 00:23:09,170
know 538 will contend to put out an

00:23:05,240 --> 00:23:10,820
interesting data set so those of us who

00:23:09,170 --> 00:23:12,710
do this kind of work have been talking

00:23:10,820 --> 00:23:26,960
for years about like aggregating it

00:23:12,710 --> 00:23:29,750
somewhere yes well one could imagine a

00:23:26,960 --> 00:23:31,730
different dataset pretty easily although

00:23:29,750 --> 00:23:35,690
I don't know that it exists like

00:23:31,730 --> 00:23:38,060
understanding the neighborhood I guess

00:23:35,690 --> 00:23:40,280
and one could also imagine just like

00:23:38,060 --> 00:23:43,430
switching to a different dataset via

00:23:40,280 --> 00:23:44,660
this menu I think what would be more

00:23:43,430 --> 00:23:47,300
kind of interesting and challenging

00:23:44,660 --> 00:23:49,910
would be seeing features on the map

00:23:47,300 --> 00:23:51,890
actually change as they reflect the way

00:23:49,910 --> 00:23:55,280
in which people perceive them like this

00:23:51,890 --> 00:23:57,890
partition map really reflects like an

00:23:55,280 --> 00:23:59,750
authoritative view of the way space

00:23:57,890 --> 00:24:01,430
works whereas if someone's actually

00:23:59,750 --> 00:24:05,050
navigating their neighborhood wouldn't

00:24:01,430 --> 00:24:07,520
it be cool if you could like you know

00:24:05,050 --> 00:24:10,190
different features would change in size

00:24:07,520 --> 00:24:11,990
and shape as as they took on a different

00:24:10,190 --> 00:24:13,640
importance to a person who lived there

00:24:11,990 --> 00:24:16,930
like maybe the church would be really

00:24:13,640 --> 00:24:20,270
big I know it's not statistically

00:24:16,930 --> 00:24:25,280
accurate but sometimes to the humanities

00:24:20,270 --> 00:24:27,970
like that's not as important yeah I

00:24:25,280 --> 00:24:27,970
think we need to wrap up

00:24:33,040 --> 00:24:37,180

YouTube URL: https://www.youtube.com/watch?v=SfZYGnuDpUc


